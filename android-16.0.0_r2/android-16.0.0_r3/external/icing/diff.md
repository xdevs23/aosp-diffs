```diff
diff --git a/Android.bp b/Android.bp
index 84e8c62..137675d 100644
--- a/Android.bp
+++ b/Android.bp
@@ -56,69 +56,46 @@ cc_defaults {
         "-fvisibility=hidden",
 
         "-Bsymbolic",
+
+        // TODO(b/420960001): Enable once libeigen is available to icing and appsearch.
+        "-DICING_DISABLE_EIGEN",
     ],
     apex_available: ["com.android.appsearch"],
 }
 
 cc_library_shared {
-    name: "libisolated_storage_service",
+    name: "libicing_anywhere",
     srcs: ["isolated_storage_service/payload/*.cc"],
     shared_libs: [
         "libbinder_ndk",
-        "libvm_payload#current",
-        "libprotobuf-cpp-lite",
         "liblog",
         "libicu",
-        "libbase",
-    ],
-    static_libs: [
-        "libicing.microdroid",
-        "icing-c-proto",
-        "libutf",
-        "libz",
-        "com.android.isolated_storage_service.aidl-ndk",
-    ],
-    min_sdk_version: "Tiramisu",
-    apex_available: ["com.android.appsearch"],
-}
 
-// Microdroid version of Icing has statically linked libz.
-cc_library_static {
-    name: "libicing.microdroid",
-    defaults: ["libicing_defaults"],
-    srcs: [
-        "icing/**/*.cc",
-    ],
-    exclude_srcs: [
-        "icing/**/*-test-*",
-        "icing/**/*-test.*",
-        "icing/**/*_test.cc",
-        "icing/**/*_benchmark.cc",
-        "icing/testing/**/*",
-        "icing/tokenization/reverse_jni/**/*",
-        "icing/tokenization/simple/**/*",
-        "icing/tools/**/*",
-        "icing/transform/map/**/*",
-        "icing/transform/simple/**/*",
+        // TODO(b/413761935)
+        // not available on host, so has to be loaded dynamically when this is used in the VM
+        // "libvm_payload#current",
     ],
-    header_libs: ["jni_headers"],
+    header_libs: ["vm_payload_headers"],
+    stl: "libc++_static",
     static_libs: [
+        "libprotobuf-cpp-lite",
+        "libbase",
         "icing-c-proto",
         "libutf",
         "libz",
+        "com.android.isolated_storage_service.aidl-ndk",
     ],
-    shared_libs: [
-        "libicu",
-        "liblog",
-        "libprotobuf-cpp-lite",
+    whole_static_libs: [
+        "libicing",
     ],
-    version_script: "icing/jni.lds",
     min_sdk_version: "Tiramisu",
+    apex_available: ["com.android.appsearch"],
+    version_script: "isolated_storage_service/iss.lds",
 }
 
 // TODO(b/193244409): Use the filegroup libicing_test_common along with
 //                    libicing_defaults to build libicing.
-cc_library_shared {
+cc_library_static {
     name: "libicing",
     defaults: ["libicing_defaults"],
     srcs: [
@@ -140,15 +117,16 @@ cc_library_shared {
     static_libs: [
         "icing-c-proto",
         "libutf",
+        "libz",
+        "libprotobuf-cpp-lite",
     ],
     shared_libs: [
         "libicu",
         "liblog",
-        "libprotobuf-cpp-lite",
-        "libz",
     ],
     version_script: "icing/jni.lds",
     min_sdk_version: "Tiramisu",
+    visibility: [":__subpackages__"],
 }
 
 filegroup {
diff --git a/CMakeLists.txt b/CMakeLists.txt
index 4b7c752..22afb9c 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -16,7 +16,10 @@ cmake_minimum_required(VERSION 3.22.1)
 
 project(icing)
 
-add_definitions("-DICING_REVERSE_JNI_SEGMENTATION=1")
+add_definitions(
+        "-DICING_REVERSE_JNI_SEGMENTATION=1"
+        "-DICING_DISABLE_EIGEN"
+)
 set(VERSION_SCRIPT "${CMAKE_CURRENT_SOURCE_DIR}/icing/jni.lds")
 set(CMAKE_CXX_STANDARD 17)
 set(CMAKE_SHARED_LINKER_FLAGS
diff --git a/icing/feature-flags.h b/icing/feature-flags.h
index 0231fe5..2ebabbb 100644
--- a/icing/feature-flags.h
+++ b/icing/feature-flags.h
@@ -26,7 +26,10 @@ class FeatureFlags {
                         bool enable_repeated_field_joins,
                         bool enable_embedding_backup_generation,
                         bool enable_schema_database,
-                        bool release_backup_schema_file_if_overlay_present)
+                        bool release_backup_schema_file_if_overlay_present,
+                        bool enable_strict_page_byte_size_limit,
+                        bool enable_smaller_decompression_buffer_size,
+                        bool enable_eigen_embedding_scoring)
       : allow_circular_schema_definitions_(allow_circular_schema_definitions),
         enable_scorable_properties_(enable_scorable_properties),
         enable_embedding_quantization_(enable_embedding_quantization),
@@ -34,7 +37,11 @@ class FeatureFlags {
         enable_embedding_backup_generation_(enable_embedding_backup_generation),
         enable_schema_database_(enable_schema_database),
         release_backup_schema_file_if_overlay_present_(
-            release_backup_schema_file_if_overlay_present) {}
+            release_backup_schema_file_if_overlay_present),
+        enable_strict_page_byte_size_limit_(enable_strict_page_byte_size_limit),
+        enable_smaller_decompression_buffer_size_(
+            enable_smaller_decompression_buffer_size),
+        enable_eigen_embedding_scoring_(enable_eigen_embedding_scoring) {}
 
   bool allow_circular_schema_definitions() const {
     return allow_circular_schema_definitions_;
@@ -62,6 +69,18 @@ class FeatureFlags {
     return release_backup_schema_file_if_overlay_present_;
   }
 
+  bool enable_strict_page_byte_size_limit() const {
+    return enable_strict_page_byte_size_limit_;
+  }
+
+  bool enable_smaller_decompression_buffer_size() const {
+    return enable_smaller_decompression_buffer_size_;
+  }
+
+  bool enable_eigen_embedding_scoring() const {
+    return enable_eigen_embedding_scoring_;
+  }
+
  private:
   // Whether to allow circular references in the schema definition. This was
   // added in the Android U timeline and is not a trunk-stable flag.
@@ -83,6 +102,17 @@ class FeatureFlags {
   bool enable_schema_database_;
 
   bool release_backup_schema_file_if_overlay_present_;
+
+  // Whether to enable strict page byte size limit enforcement in
+  // ResultRetrieverV2.
+  bool enable_strict_page_byte_size_limit_;
+
+  bool enable_smaller_decompression_buffer_size_;
+
+  // Whether to enable the Eigen library for embedding scoring.
+  // If set to true **and** Eigen is compiled in (when ICING_DISABLE_EIGEN is
+  // not defined), Eigen will be used for embedding scoring.
+  bool enable_eigen_embedding_scoring_;
 };
 
 }  // namespace lib
diff --git a/icing/file/file-backed-proto.h b/icing/file/file-backed-proto.h
index 65566c6..3504f96 100644
--- a/icing/file/file-backed-proto.h
+++ b/icing/file/file-backed-proto.h
@@ -196,20 +196,24 @@ FileBackedProto<ProtoT>::ReadInternal() const {
                 << " of size: " << file_size;
 
   Header header;
-  if (!filesystem_->PRead(fd.get(), &header, sizeof(Header), /*offset=*/0)) {
+  if (filesystem_->PRead(fd.get(), &header, sizeof(Header), /*offset=*/0) !=
+      sizeof(Header)) {
     return absl_ports::InternalError(
         absl_ports::StrCat("Unable to read header of: ", file_path_));
   }
 
   if (header.magic != Header::kMagic) {
-    return absl_ports::InternalError(
-        absl_ports::StrCat("Invalid header kMagic for: ", file_path_));
+    ICING_LOG(ERROR) << "Invalid header magic for FileBackedProto "
+                     << file_path_ << ". Expected: " << Header::kMagic
+                     << ", actual: " << header.magic;
+    return absl_ports::InternalError(absl_ports::StrCat(
+        "Invalid header magic for FileBackedProto: ", file_path_));
   }
 
   int proto_size = file_size - sizeof(Header);
   auto buffer = std::make_unique<uint8_t[]>(proto_size);
-  if (!filesystem_->PRead(fd.get(), buffer.get(), proto_size,
-                          /*offset=*/sizeof(Header))) {
+  if (filesystem_->PRead(fd.get(), buffer.get(), proto_size,
+                         /*offset=*/sizeof(Header)) != proto_size) {
     return absl_ports::InternalError(
         absl_ports::StrCat("File read failed: ", file_path_));
   }
diff --git a/icing/file/file-backed-vector.h b/icing/file/file-backed-vector.h
index 8bd7161..04ee7c3 100644
--- a/icing/file/file-backed-vector.h
+++ b/icing/file/file-backed-vector.h
@@ -701,9 +701,12 @@ FileBackedVector<T>::InitializeExistingFile(
   // Make sure the header is still valid before we use any of its values. This
   // should technically be included in the header_checksum check below, but this
   // is a quick/fast check that can save us from an extra crc computation.
-  if (header->kMagic != FileBackedVector<T>::Header::kMagic) {
-    return absl_ports::InternalError(
-        absl_ports::StrCat("Invalid header kMagic for ", file_path));
+  if (header->magic != Header::kMagic) {
+    ICING_LOG(ERROR) << "Invalid header magic for FileBackedVector "
+                     << file_path << ". Expected: " << Header::kMagic
+                     << ", actual: " << header->magic;
+    return absl_ports::InternalError(absl_ports::StrCat(
+        "Invalid header magic for FileBackedVector: ", file_path));
   }
 
   // Check header
diff --git a/icing/file/file-backed-vector_test.cc b/icing/file/file-backed-vector_test.cc
index 4561e39..c7fbedc 100644
--- a/icing/file/file-backed-vector_test.cc
+++ b/icing/file/file-backed-vector_test.cc
@@ -1364,7 +1364,7 @@ TEST_F(FileBackedVectorTest, InitCorruptHeaderFails) {
   // to corruption of the header.
   FileBackedVector<char>::Header header;
   ASSERT_THAT(filesystem_.PRead(fd_, &header, sizeof(header), /*offset=*/0),
-              IsTrue());
+              Eq(sizeof(header)));
   header.num_elements = 1;
   ASSERT_THAT(filesystem_.PWrite(fd_, /*offset=*/0, &header, sizeof(header)),
               IsTrue());
@@ -1396,7 +1396,7 @@ TEST_F(FileBackedVectorTest, InitHeaderElementSizeTooBigFails) {
   // of the underlying file.
   FileBackedVector<char>::Header header;
   ASSERT_THAT(filesystem_.PRead(fd_, &header, sizeof(header), /*offset=*/0),
-              IsTrue());
+              Eq(sizeof(header)));
   int64_t file_size = filesystem_.GetFileSize(fd_);
   int64_t allocated_elements_size = file_size - sizeof(header);
   header.num_elements = (allocated_elements_size / sizeof(char)) + 1;
diff --git a/icing/file/filesystem.cc b/icing/file/filesystem.cc
index cd905e7..6f033aa 100644
--- a/icing/file/filesystem.cc
+++ b/icing/file/filesystem.cc
@@ -26,11 +26,14 @@
 
 #include <algorithm>
 #include <cerrno>
+#include <cstddef>
 #include <cstdint>
+#include <cstring>
+#include <memory>
 #include <unordered_set>
+#include <vector>
 
 #include "icing/absl_ports/str_cat.h"
-#include "icing/legacy/core/icing-string-util.h"
 #include "icing/util/logging.h"
 
 using std::vector;
@@ -125,8 +128,14 @@ bool ListDirectoryInternal(const char* dir_name,
                            const std::unordered_set<std::string>& exclude,
                            bool recursive, const char* prefix,
                            std::vector<std::string>* entries) {
-  DIR* dir = opendir(dir_name);
-  if (!dir) {
+  auto closer = [](DIR* dir) {
+    if (closedir(dir) != 0) {
+      ICING_LOG(ERROR) << "Error closing dir (" << errno << ") "
+                       << strerror(errno);
+    }
+  };
+  std::unique_ptr<DIR, decltype(closer)> dir(opendir(dir_name), closer);
+  if (dir == nullptr) {
     LogOpenError("Unable to open directory ", dir_name, ": ", errno);
     return false;
   }
@@ -136,7 +145,7 @@ bool ListDirectoryInternal(const char* dir_name,
   // may be statically allocated, so don't free it.
   dirent* p;
   // readdir's implementation seems to be thread safe.
-  while ((p = readdir(dir)) != nullptr) {
+  while ((p = readdir(dir.get())) != nullptr) {
     std::string file_name(p->d_name);
     if (file_name == "." || file_name == ".." ||
         exclude.find(file_name) != exclude.end()) {
@@ -155,9 +164,6 @@ bool ListDirectoryInternal(const char* dir_name,
       }
     }
   }
-  if (closedir(dir) != 0) {
-    ICING_LOG(ERROR) << "Error closing " << dir_name << " " << strerror(errno);
-  }
   return true;
 }
 
@@ -182,7 +188,8 @@ bool Filesystem::DeleteFile(const char* file_name) const {
   ICING_VLOG(1) << "Deleting file " << file_name;
   int ret = unlink(file_name);
   if (ret != 0 && errno != ENOENT) {
-    ICING_LOG(ERROR) << "Deleting file " << file_name << " failed: " << strerror(errno);
+    ICING_LOG(ERROR) << "Deleting file " << file_name << " failed: (" << errno
+                     << ") " << strerror(errno);
     return false;
   }
   return true;
@@ -191,7 +198,8 @@ bool Filesystem::DeleteFile(const char* file_name) const {
 bool Filesystem::DeleteDirectory(const char* dir_name) const {
   int ret = rmdir(dir_name);
   if (ret != 0 && errno != ENOENT) {
-    ICING_LOG(ERROR) << "Deleting directory " << dir_name << " failed: " << strerror(errno);
+    ICING_LOG(ERROR) << "Deleting directory " << dir_name << " failed: ("
+                     << errno << ") " << strerror(errno);
     return false;
   }
   return true;
@@ -204,7 +212,8 @@ bool Filesystem::DeleteDirectoryRecursively(const char* dir_name) const {
     if (errno == ENOENT) {
       return true;  // If directory didn't exist, this was successful.
     }
-    ICING_LOG(ERROR) << "Stat " << dir_name << " failed: " << strerror(errno);
+    ICING_LOG(ERROR) << "Stat " << dir_name << " failed: (" << errno << ") "
+                     << strerror(errno);
     return false;
   }
   vector<std::string> entries;
@@ -217,7 +226,8 @@ bool Filesystem::DeleteDirectoryRecursively(const char* dir_name) const {
        ++i) {
     std::string filename = std::string(dir_name) + '/' + *i;
     if (stat(filename.c_str(), &st) < 0) {
-      ICING_LOG(ERROR) << "Stat " << filename << " failed: " << strerror(errno);
+      ICING_LOG(ERROR) << "Stat " << filename << " failed: (" << errno << ") "
+                       << strerror(errno);
       success = false;
     } else if (S_ISDIR(st.st_mode)) {
       success = DeleteDirectoryRecursively(filename.c_str()) && success;
@@ -240,7 +250,8 @@ bool Filesystem::FileExists(const char* file_name) const {
     exists = S_ISREG(st.st_mode) != 0;
   } else {
     if (errno != ENOENT) {
-      ICING_LOG(ERROR) << "Unable to stat file " << file_name << ": " << strerror(errno);
+      ICING_LOG(ERROR) << "Unable to stat file " << file_name << ": (" << errno
+                       << ") " << strerror(errno);
     }
     exists = false;
   }
@@ -254,7 +265,8 @@ bool Filesystem::DirectoryExists(const char* dir_name) const {
     exists = S_ISDIR(st.st_mode) != 0;
   } else {
     if (errno != ENOENT) {
-      ICING_LOG(ERROR) << "Unable to stat directory " << dir_name << ": " << strerror(errno);
+      ICING_LOG(ERROR) << "Unable to stat directory " << dir_name << ": ("
+                       << errno << ") " << strerror(errno);
     }
     exists = false;
   }
@@ -365,11 +377,8 @@ int Filesystem::OpenForRead(const char* file_name) const {
 int64_t Filesystem::GetFileSize(int fd) const {
   struct stat st;
   if (fstat(fd, &st) < 0) {
-    if (errno == ENOENT) {
-      ICING_VLOG(1) << "Unable to stat file: " << strerror(errno);
-    } else {
-      ICING_LOG(WARNING) << "Unable to stat file: " << strerror(errno);
-    }
+      ICING_LOG(WARNING) << "Unable to stat file: (" << errno << ") "
+                         << strerror(errno);
     return kBadFileSize;
   }
   return st.st_size;
@@ -379,9 +388,11 @@ int64_t Filesystem::GetFileSize(const char* filename) const {
   struct stat st;
   if (stat(filename, &st) < 0) {
     if (errno == ENOENT) {
-      ICING_VLOG(1) << "Unable to stat file " << filename << ": " << strerror(errno);
+      ICING_VLOG(1) << "Unable to stat file " << filename << ": "
+          << strerror(errno);
     } else {
-      ICING_LOG(WARNING) << "Unable to stat file " << filename << ": " << strerror(errno);
+      ICING_LOG(WARNING) << "Unable to stat file " << filename << ": (" << errno
+                         << ") " << strerror(errno);
     }
     return kBadFileSize;
   }
@@ -390,7 +401,8 @@ int64_t Filesystem::GetFileSize(const char* filename) const {
 
 bool Filesystem::Truncate(int fd, int64_t new_size) const {
   if (ftruncate(fd, new_size) != 0) {
-    ICING_LOG(ERROR) << "Unable to truncate file: " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to truncate file: (" << errno << ") "
+                     << strerror(errno);
     return false;
   }
   lseek(fd, new_size, SEEK_SET);
@@ -409,7 +421,8 @@ bool Filesystem::Truncate(const char* filename, int64_t new_size) const {
 
 bool Filesystem::Grow(int fd, int64_t new_size) const {
   if (ftruncate(fd, new_size) != 0) {
-    ICING_LOG(ERROR) << "Unable to grow file: " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to grow file: (" << errno << ") "
+                     << strerror(errno);
     return false;
   }
 
@@ -434,7 +447,7 @@ bool Filesystem::Write(int fd, const void* data, size_t data_size) const {
     size_t chunk_size = std::min<size_t>(write_len, 64u * 1024);
     ssize_t wrote = write(fd, data, chunk_size);
     if (wrote < 0) {
-      ICING_LOG(ERROR) << "Bad write: " << strerror(errno);
+      ICING_LOG(ERROR) << "Bad write: (" << errno << ") " << strerror(errno);
       return false;
     }
     data = static_cast<const uint8_t*>(data) + wrote;
@@ -469,7 +482,7 @@ bool Filesystem::CopyFile(const char* src, const char* dst) const {
   }
   uint64_t size = GetFileSize(*src_fd);
   std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-  if (!Read(*src_fd, buf.get(), size)) {
+  if (Read(*src_fd, buf.get(), size) != size) {
     return false;
   }
   return Write(*dst_fd, buf.get(), size);
@@ -477,15 +490,21 @@ bool Filesystem::CopyFile(const char* src, const char* dst) const {
 
 bool Filesystem::CopyDirectory(const char* src_dir, const char* dst_dir,
                                bool recursive) const {
-  DIR* dir = opendir(src_dir);
-  if (!dir) {
+  auto closer = [](DIR* dir) {
+    if (closedir(dir) != 0) {
+      ICING_LOG(ERROR) << "Error closing dir (" << errno << ") "
+                       << strerror(errno);
+    }
+  };
+  std::unique_ptr<DIR, decltype(closer)> dir(opendir(src_dir), closer);
+  if (dir == nullptr) {
     LogOpenError("Unable to open directory ", src_dir, ": ", errno);
     return false;
   }
 
   dirent* p;
   // readdir's implementation seems to be thread safe.
-  while ((p = readdir(dir)) != nullptr) {
+  while ((p = readdir(dir.get())) != nullptr) {
     std::string file_name(p->d_name);
     if (file_name == "." || file_name == "..") {
       continue;
@@ -511,9 +530,6 @@ bool Filesystem::CopyDirectory(const char* src_dir, const char* dst_dir,
       }
     }
   }
-  if (closedir(dir) != 0) {
-    ICING_LOG(ERROR) << "Error closing " << src_dir << ": " << strerror(errno);
-  }
   return true;
 }
 
@@ -525,7 +541,7 @@ bool Filesystem::PWrite(int fd, off_t offset, const void* data,
     size_t chunk_size = std::min<size_t>(write_len, 64u * 1024);
     ssize_t wrote = pwrite(fd, data, chunk_size, offset);
     if (wrote < 0) {
-      ICING_LOG(ERROR) << "Bad write: " << strerror(errno);
+      ICING_LOG(ERROR) << "Bad write: (" << errno << ") " << strerror(errno);
       return false;
     }
     data = static_cast<const uint8_t*>(data) + wrote;
@@ -547,45 +563,78 @@ bool Filesystem::PWrite(const char* filename, off_t offset, const void* data,
   return success;
 }
 
-bool Filesystem::Read(int fd, void* buf, size_t buf_size) const {
-  ssize_t read_status = read(fd, buf, buf_size);
-  if (read_status < 0) {
-    ICING_LOG(ERROR) << "Bad read: " << strerror(errno);
-    return false;
+ssize_t Filesystem::Read(int fd, void* buf, size_t buf_size) const {
+  // convenience for pointer arithmetic below.
+  char* buf_ptr = static_cast<char*>(buf);
+  ssize_t processed_size = 0;
+  while (processed_size < buf_size) {
+    ssize_t read_status =
+        read(fd, buf_ptr + processed_size, buf_size - processed_size);
+    if (read_status < 0) {
+      ICING_LOG(ERROR) << "Bad read: (" << errno << ") " << strerror(errno);
+      return read_status;
+    }
+    if (read_status < buf_size - processed_size) {
+      ICING_LOG(ERROR) << "Read less than requested: " << read_status << " < "
+                       << buf_size - processed_size;
+    }
+    if (read_status == 0) {
+      // EOF. Finish reading.
+      return processed_size;
+    }
+    processed_size += read_status;
   }
-  return true;
+  return processed_size;
 }
 
-bool Filesystem::Read(const char* filename, void* buf, size_t buf_size) const {
+ssize_t Filesystem::Read(const char* filename, void* buf,
+                         size_t buf_size) const {
   int fd = OpenForRead(filename);
   if (fd == -1) {
-    return false;
+    return -1;
   }
 
-  bool success = Read(fd, buf, buf_size);
+  ssize_t bytes_read = Read(fd, buf, buf_size);
   close(fd);
-  return success;
-}
-
-bool Filesystem::PRead(int fd, void* buf, size_t buf_size, off_t offset) const {
-  ssize_t read_status = pread(fd, buf, buf_size, offset);
-  if (read_status < 0) {
-    ICING_LOG(ERROR) << "Bad read: " << strerror(errno);
-    return false;
+  return bytes_read;
+}
+
+ssize_t Filesystem::PRead(int fd, void* buf, size_t buf_size,
+                          off_t offset) const {
+  // convenience for pointer arithmetic below.
+  char* buf_ptr = static_cast<char*>(buf);
+  size_t processed_size = 0;
+  while (processed_size < buf_size) {
+    ssize_t read_status =
+        pread(fd, buf_ptr + processed_size, buf_size - processed_size,
+              offset + processed_size);
+    if (read_status < 0) {
+      ICING_LOG(ERROR) << "Bad read: (" << errno << ") " << strerror(errno);
+      return read_status;
+    }
+    if (read_status < buf_size - processed_size) {
+      ICING_LOG(ERROR) << "Read less than requested: " << read_status << " < "
+                       << buf_size - processed_size;
+    }
+    if (read_status == 0) {
+      // EOF. Finish reading.
+      return processed_size;
+    }
+    processed_size += read_status;
   }
-  return true;
+  return processed_size;
 }
 
-bool Filesystem::PRead(const char* filename, void* buf, size_t buf_size,
-                       off_t offset) const {
+ssize_t Filesystem::PRead(const char* filename, void* buf, size_t buf_size,
+                          off_t offset) const {
   int fd = OpenForRead(filename);
   if (fd == -1) {
-    return false;
+    return -1;
   }
 
-  bool success = PRead(fd, buf, buf_size, offset);
+  ssize_t bytes_read = PRead(fd, buf, buf_size, offset);
   close(fd);
-  return success;
+  return bytes_read;
 }
 
 bool Filesystem::DataSync(int fd) const {
@@ -596,7 +645,8 @@ bool Filesystem::DataSync(int fd) const {
 #endif
 
   if (result < 0) {
-    ICING_LOG(ERROR) << "Unable to sync data: " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to sync data: (" << errno << ") "
+                     << strerror(errno);
     return false;
   }
   return true;
@@ -604,7 +654,8 @@ bool Filesystem::DataSync(int fd) const {
 
 bool Filesystem::RenameFile(const char* old_name, const char* new_name) const {
   if (rename(old_name, new_name) < 0) {
-    ICING_LOG(ERROR) << "Unable to rename file " << old_name << " to " << new_name << ": " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to rename file " << old_name << " to "
+                     << new_name << ": (" << errno << ") " << strerror(errno);
     return false;
   }
   return true;
@@ -642,7 +693,8 @@ bool Filesystem::CreateDirectory(const char* dir_name) const {
     if (mkdir(dir_name, S_IRUSR | S_IWUSR | S_IXUSR) == 0) {
       success = true;
     } else {
-      ICING_LOG(ERROR) << "Creating directory " << dir_name << " failed: " << strerror(errno);
+      ICING_LOG(ERROR) << "Creating directory " << dir_name << " failed: ("
+                       << errno << ") " << strerror(errno);
     }
   }
   return success;
@@ -662,7 +714,8 @@ bool Filesystem::CreateDirectoryRecursively(const char* dir_name) const {
 int64_t Filesystem::GetDiskUsage(int fd) const {
   struct stat st;
   if (fstat(fd, &st) < 0) {
-    ICING_LOG(ERROR) << "Unable to stat file: " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to stat file: (" << errno << ") "
+                     << strerror(errno);
     return kBadFileSize;
   }
   return st.st_blocks * kStatBlockSize;
@@ -671,7 +724,8 @@ int64_t Filesystem::GetDiskUsage(int fd) const {
 int64_t Filesystem::GetFileDiskUsage(const char* path) const {
   struct stat st;
   if (stat(path, &st) != 0) {
-    ICING_LOG(ERROR) << "Unable to stat " << path << ": " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to stat " << path << ": (" << errno << ") "
+                     << strerror(errno);
     return kBadFileSize;
   }
   return st.st_blocks * kStatBlockSize;
@@ -680,7 +734,8 @@ int64_t Filesystem::GetFileDiskUsage(const char* path) const {
 int64_t Filesystem::GetDiskUsage(const char* path) const {
   struct stat st;
   if (stat(path, &st) != 0) {
-    ICING_LOG(ERROR) << "Unable to stat " << path << ": " << strerror(errno);
+    ICING_LOG(ERROR) << "Unable to stat " << path << ": (" << errno << ") "
+                     << strerror(errno);
     return kBadFileSize;
   }
   int64_t result = st.st_blocks * kStatBlockSize;
diff --git a/icing/file/filesystem.h b/icing/file/filesystem.h
index dd2c5d1..71eba0b 100644
--- a/icing/file/filesystem.h
+++ b/icing/file/filesystem.h
@@ -183,11 +183,11 @@ class Filesystem {
   // Reads from a file. Returns true if data was successfully read out. If the
   // file is seekable, read starts at the file offset, and the file offset is
   // incremented by number of bytes read.
-  virtual bool Read(int fd, void* buf, size_t buf_size) const;
-  virtual bool Read(const char* filename, void* buf, size_t buf_size) const;
-  virtual bool PRead(int fd, void* buf, size_t buf_size, off_t offset) const;
-  virtual bool PRead(const char* filename, void* buf, size_t buf_size,
-                     off_t offset) const;
+  virtual ssize_t Read(int fd, void* buf, size_t buf_size) const;
+  virtual ssize_t Read(const char* filename, void* buf, size_t buf_size) const;
+  virtual ssize_t PRead(int fd, void* buf, size_t buf_size, off_t offset) const;
+  virtual ssize_t PRead(const char* filename, void* buf, size_t buf_size,
+                        off_t offset) const;
 
   // Syncs the file to disk (fdatasync). Returns true on success.
   virtual bool DataSync(int fd) const;
diff --git a/icing/file/filesystem_test.cc b/icing/file/filesystem_test.cc
index 214180e..378ef98 100644
--- a/icing/file/filesystem_test.cc
+++ b/icing/file/filesystem_test.cc
@@ -17,8 +17,11 @@
 #include "icing/file/filesystem.h"
 
 #include <algorithm>
+#include <chrono>
 #include <cstdint>
+#include <cstring>
 #include <string>
+#include <thread>
 #include <unordered_set>
 #include <vector>
 
@@ -419,38 +422,89 @@ TEST_F(FilesystemTest, ReadWrite) {
   EXPECT_TRUE(filesystem.Write(fd, data.c_str(), strlen(data.c_str())));
 
   std::string hello;
-  hello.resize(strlen("hello"));
-  EXPECT_TRUE(filesystem.Read(foo_file.c_str(), &hello[0], strlen("hello")));
+  size_t hello_len = strlen("hello");
+  hello.resize(hello_len);
+  EXPECT_THAT(filesystem.Read(foo_file.c_str(), &hello[0], hello_len),
+              Eq(hello_len));
   EXPECT_THAT(hello, Eq("hello"));
 
   // Read starts from wherever file offset is at the moment.
   filesystem.SetPosition(fd, 0);
   hello.clear();
-  hello.resize(strlen("hello"));
-  EXPECT_TRUE(filesystem.Read(fd, &hello[0], strlen("hello")));
+  hello.resize(hello_len);
+  EXPECT_THAT(filesystem.Read(fd, &hello[0], hello_len), Eq(hello_len));
   EXPECT_THAT(hello, Eq("hello"));
 
   // Shouldn't need to move file offset anymore since file offset gets updated
   // after the read.
   std::string world;
-  world.resize(strlen(" world"));
-  EXPECT_TRUE(filesystem.Read(fd, &world[0], strlen(" world")));
+  size_t world_len = strlen(" world");
+  world.resize(world_len);
+  EXPECT_THAT(filesystem.Read(fd, &world[0], world_len), Eq(world_len));
   EXPECT_THAT(world, Eq(" world"));
 
   // PRead should not be dependent on the file offset
   world.clear();
-  world.resize(strlen(" world"));
-  EXPECT_TRUE(
-      filesystem.PRead(fd, &world[0], strlen(" world"), strlen("hello")));
+  world.resize(world_len);
+  EXPECT_THAT(filesystem.PRead(fd, &world[0], world_len, hello_len),
+              Eq(world_len));
   EXPECT_THAT(world, Eq(" world"));
 
   hello.clear();
-  hello.resize(strlen("hello"));
-  EXPECT_TRUE(
-      filesystem.PRead(foo_file.c_str(), &hello[0], strlen("hello"), 0));
+  hello.resize(hello_len);
+  EXPECT_THAT(filesystem.PRead(foo_file.c_str(), &hello[0], hello_len, 0),
+              Eq(hello_len));
   EXPECT_THAT(hello, Eq("hello"));
 }
 
+TEST_F(FilesystemTest, ReadInChunks) {
+  int pipe_fd[2];
+  ASSERT_THAT(pipe(pipe_fd), Eq(0));
+  ScopedFd read_fd(pipe_fd[0]);
+  ScopedFd write_fd(pipe_fd[1]);
+
+  std::string read_data(200, 'a');
+  bool read_success = false;
+  Filesystem filesystem;
+  auto read_callable = [&]() {
+    read_success = filesystem.Read(read_fd.get(), &read_data[0],
+                                   read_data.size()) == read_data.size();
+  };
+
+  std::string write_chunks(50, 'b');
+  auto write_callable = [&]() {
+    for (int i = 0; i < 4; ++i) {
+      filesystem.Write(write_fd.get(), &write_chunks[0], write_chunks.size());
+      std::this_thread::sleep_for(std::chrono::milliseconds(1));
+    }
+  };
+
+  std::thread read_thread(read_callable);
+  std::thread write_thread(write_callable);
+  read_thread.join();
+  write_thread.join();
+  EXPECT_TRUE(read_success);
+  std::string expected_data(200, 'b');
+  EXPECT_THAT(read_data, Eq(expected_data));
+}
+
+TEST_F(FilesystemTest, ReadFileSmallerThanBufferSize) {
+  Filesystem filesystem;
+  const std::string foo_file = temp_dir_ + "/foo_file";
+  ScopedFd fd(filesystem.OpenForWrite(foo_file.c_str()));;
+  ASSERT_TRUE(fd.is_valid());
+
+  std::string write_buf(100, 'b');
+  ASSERT_TRUE(filesystem.Write(fd.get(), &write_buf[0], write_buf.length()));
+
+  std::string read_buf(200, 'a');
+  EXPECT_THAT(filesystem.PRead(fd.get(), &read_buf[0], read_buf.length(), 0),
+              Eq(write_buf.length()));
+
+  std::string expected_read_buf = std::string(100, 'b') + std::string(100, 'a');
+  EXPECT_THAT(read_buf, Eq(expected_read_buf));
+}
+
 TEST_F(FilesystemTest, CopyDirectory) {
   Filesystem filesystem;
 
diff --git a/icing/file/marker-file_test.cc b/icing/file/marker-file_test.cc
index cd7d655..ba51769 100644
--- a/icing/file/marker-file_test.cc
+++ b/icing/file/marker-file_test.cc
@@ -123,8 +123,7 @@ TEST_F(MarkerFileTest, CreateWithExistingFileShouldFail) {
   EXPECT_THAT(filesystem_.FileExists(file_path.c_str()), IsTrue());
   EXPECT_THAT(filesystem_.GetFileSize(file_path.c_str()), Eq(4));
   char buf[4];
-  EXPECT_THAT(filesystem_.Read(file_path.c_str(), buf, /*buf_size=*/4),
-              IsTrue());
+  EXPECT_THAT(filesystem_.Read(file_path.c_str(), buf, /*buf_size=*/4), Eq(4));
   EXPECT_THAT(std::string(buf, 4), Eq("test"));
 }
 
diff --git a/icing/file/memory-mapped-file-backed-proto-log.h b/icing/file/memory-mapped-file-backed-proto-log.h
index cc8f35f..ab0ddcc 100644
--- a/icing/file/memory-mapped-file-backed-proto-log.h
+++ b/icing/file/memory-mapped-file-backed-proto-log.h
@@ -31,6 +31,7 @@
 #include "icing/file/memory-mapped-file.h"
 #include "icing/legacy/core/icing-string-util.h"
 #include "icing/util/crc32.h"
+#include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -159,6 +160,9 @@ MemoryMappedFileBackedProtoLog<ProtoT>::ValidateAndGetProtoSize(
     ProtoMetadata proto_metadata) {
   uint8_t magic_number = proto_metadata >> 24;
   if (magic_number != kProtoMagic) {
+    ICING_LOG(ERROR)
+        << "Invalid header magic for MemoryMappedFileBackedProtoLog. Expected: "
+        << kProtoMagic << ", actual: " << magic_number;
     return absl_ports::InvalidArgumentError(
         "Proto metadata has invalid magic number");
   }
diff --git a/icing/file/memory-mapped-file_test.cc b/icing/file/memory-mapped-file_test.cc
index 16f76e6..8c3891d 100644
--- a/icing/file/memory-mapped-file_test.cc
+++ b/icing/file/memory-mapped-file_test.cc
@@ -161,8 +161,9 @@ TEST_F(MemoryMappedFileTest, CreateWithPreMappingInfo) {
     ASSERT_TRUE(sfd.is_valid());
     int buf_size = 10;
     auto buf = std::make_unique<char[]>(buf_size);
-    ASSERT_TRUE(filesystem_.PRead(sfd.get(), buf.get(), buf_size,
-                                  pre_mapping_file_offset));
+    ASSERT_THAT(filesystem_.PRead(sfd.get(), buf.get(), buf_size,
+                                  pre_mapping_file_offset),
+                Eq(buf_size));
     EXPECT_THAT(buf.get()[0], Eq('a'));
   }
 }
@@ -300,8 +301,9 @@ TEST_F(MemoryMappedFileTest, GrowAndRemapIfNecessary) {
   ASSERT_TRUE(sfd.is_valid());
   int buf_size = 1;
   auto buf = std::make_unique<char[]>(buf_size);
-  ASSERT_TRUE(filesystem_.PRead(sfd.get(), buf.get(), buf_size,
-                                pre_mapping_file_offset));
+  ASSERT_THAT(filesystem_.PRead(sfd.get(), buf.get(), buf_size,
+                                pre_mapping_file_offset),
+              Eq(buf_size));
   EXPECT_THAT(buf.get()[0], Eq('a'));
 }
 
diff --git a/icing/file/mock-filesystem.h b/icing/file/mock-filesystem.h
index 32817d4..02740f6 100644
--- a/icing/file/mock-filesystem.h
+++ b/icing/file/mock-filesystem.h
@@ -299,15 +299,15 @@ class MockFilesystem : public Filesystem {
                size_t data_size),
               (const));
 
-  MOCK_METHOD(bool, Read, (int fd, void* buf, size_t buf_size), (const));
+  MOCK_METHOD(ssize_t, Read, (int fd, void* buf, size_t buf_size), (const));
 
-  MOCK_METHOD(bool, Read, (const char* filename, void* buf, size_t buf_size),
+  MOCK_METHOD(ssize_t, Read, (const char* filename, void* buf, size_t buf_size),
               (const));
 
-  MOCK_METHOD(bool, PRead, (int fd, void* buf, size_t buf_size, off_t offset),
-              (const));
+  MOCK_METHOD(ssize_t, PRead,
+              (int fd, void* buf, size_t buf_size, off_t offset), (const));
 
-  MOCK_METHOD(bool, PRead,
+  MOCK_METHOD(ssize_t, PRead,
               (const char* filename, void* buf, size_t buf_size, off_t offset),
               (const));
 
diff --git a/icing/file/persistent-hash-map.cc b/icing/file/persistent-hash-map.cc
index 148c7ea..3daeadd 100644
--- a/icing/file/persistent-hash-map.cc
+++ b/icing/file/persistent-hash-map.cc
@@ -29,6 +29,7 @@
 #include "icing/file/memory-mapped-file.h"
 #include "icing/file/persistent-storage.h"
 #include "icing/util/crc32.h"
+#include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -504,8 +505,13 @@ PersistentHashMap::InitializeExistingFiles(const Filesystem& filesystem,
 
   // Magic should be the same.
   if (persistent_hash_map->info().magic != Info::kMagic) {
+    ICING_LOG(ERROR) << "Invalid header magic for PersistentHashMap "
+                     << persistent_hash_map->working_path_
+                     << ". Expected: " << Info::kMagic
+                     << ", actual: " << persistent_hash_map->info().magic;
     return absl_ports::FailedPreconditionError(
-        "PersistentHashMap header magic mismatch");
+        absl_ports::StrCat("Invalid header magic for PersistentHashMap: ",
+                           persistent_hash_map->working_path_));
   }
 
   // Value type size should be consistent.
diff --git a/icing/file/persistent-hash-map_test.cc b/icing/file/persistent-hash-map_test.cc
index d2e211d..6accfbb 100644
--- a/icing/file/persistent-hash-map_test.cc
+++ b/icing/file/persistent-hash-map_test.cc
@@ -235,8 +235,9 @@ TEST_P(PersistentHashMapTest, InitializeNewFiles) {
 
   // Check info section
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                PersistentHashMap::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                PersistentHashMap::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
   EXPECT_THAT(info.magic, Eq(Info::kMagic));
   EXPECT_THAT(info.value_type_size, Eq(sizeof(int)));
   EXPECT_THAT(info.max_load_factor_percent,
@@ -246,8 +247,9 @@ TEST_P(PersistentHashMapTest, InitializeNewFiles) {
 
   // Check crcs section
   Crcs crcs;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                PersistentHashMap::kCrcsMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                PersistentHashMap::kCrcsMetadataFileOffset),
+              Eq(sizeof(Crcs)));
   // # of elements in bucket_storage should be 1, so it should have non-zero
   // all storages crc value.
   EXPECT_THAT(crcs.component_crcs.storages_crc, Ne(0));
@@ -487,12 +489,14 @@ TEST_P(PersistentHashMapTest,
     ASSERT_TRUE(metadata_sfd.is_valid());
 
     Crcs crcs;
-    ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                  PersistentHashMap::kCrcsMetadataFileOffset));
+    ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                  PersistentHashMap::kCrcsMetadataFileOffset),
+                Eq(sizeof(Crcs)));
 
     Info info;
-    ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                  PersistentHashMap::kInfoMetadataFileOffset));
+    ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                  PersistentHashMap::kInfoMetadataFileOffset),
+                Eq(sizeof(Info)));
 
     // Manually change magic and update checksums.
     info.magic += kCorruptedValueOffset;
@@ -515,7 +519,7 @@ TEST_P(PersistentHashMapTest,
     EXPECT_THAT(persistent_hash_map_or,
                 StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
     EXPECT_THAT(persistent_hash_map_or.status().error_message(),
-                HasSubstr("PersistentHashMap header magic mismatch"));
+                HasSubstr("Invalid header magic for PersistentHashMap"));
   }
 }
 
@@ -612,8 +616,9 @@ TEST_P(PersistentHashMapTest, InitializeExistingFilesWithWrongAllCrc) {
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Crcs crcs;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                PersistentHashMap::kCrcsMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                PersistentHashMap::kCrcsMetadataFileOffset),
+              Eq(sizeof(Crcs)));
 
   // Manually corrupt all_crc
   crcs.all_crc += kCorruptedValueOffset;
@@ -656,8 +661,9 @@ TEST_P(PersistentHashMapTest,
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                PersistentHashMap::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                PersistentHashMap::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
 
   // Modify info, but don't update the checksum. This would be similar to
   // corruption of info.
@@ -863,8 +869,9 @@ TEST_P(PersistentHashMapTest,
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                PersistentHashMap::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                PersistentHashMap::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
   EXPECT_THAT(info.max_load_factor_percent,
               Eq(options.max_load_factor_percent));
 
diff --git a/icing/file/portable-file-backed-proto-log.h b/icing/file/portable-file-backed-proto-log.h
index b498563..9f9cbb5 100644
--- a/icing/file/portable-file-backed-proto-log.h
+++ b/icing/file/portable-file-backed-proto-log.h
@@ -53,6 +53,7 @@
 #ifndef ICING_FILE_PORTABLE_FILE_BACKED_PROTO_LOG_H_
 #define ICING_FILE_PORTABLE_FILE_BACKED_PROTO_LOG_H_
 
+#include <algorithm>
 #include <cstddef>
 #include <cstdint>
 #include <cstring>
@@ -60,7 +61,6 @@
 #include <string>
 #include <string_view>
 #include <utility>
-#include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
@@ -73,7 +73,6 @@
 #include "icing/portable/endian.h"
 #include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
-#include "icing/portable/zlib.h"
 #include "icing/util/bit-util.h"
 #include "icing/util/crc32.h"
 #include "icing/util/data-loss.h"
@@ -111,20 +110,43 @@ class PortableFileBackedProtoLog {
     // BEST_COMPRESSION = 9
     const int32_t compression_level;
 
+    // The threshold in bytes for compression if enabled. If the proto is larger
+    // than or equal to this threshold, it will be compressed.
+    const uint32_t compression_threshold_bytes;
+
+    // Level of memory usage for compression if enabled, BEST_MEMORY = 1,
+    // BEST_COMPRESSION and SPEED = 9
+    const int32_t compression_mem_level;
+
+    // Whether to use a smaller decompression buffer size. If false, the
+    // decompression buffer size will be the default size of 64MiB.
+    const bool enable_smaller_decompression_buffer_size;
+
     // Must specify values for options.
     Options() = delete;
-    explicit Options(
-        bool compress_in,
-        const int32_t max_proto_size_in = constants::kMaxProtoSize,
-        const int32_t compression_level_in = kDefaultCompressionLevel)
+    explicit Options(bool compress_in, const int32_t max_proto_size_in,
+                     const int32_t compression_level_in,
+                     const uint32_t compression_threshold_bytes_in,
+                     const int32_t compression_mem_level_in,
+                     const bool enable_smaller_decompression_buffer_size_in)
         : compress(compress_in),
           max_proto_size(max_proto_size_in),
-          compression_level(compression_level_in) {}
+          compression_level(compression_level_in),
+          compression_threshold_bytes(compression_threshold_bytes_in),
+          compression_mem_level(compression_mem_level_in),
+          enable_smaller_decompression_buffer_size(
+              enable_smaller_decompression_buffer_size_in) {}
   };
 
   // Level of compression, BEST_SPEED = 1, BEST_COMPRESSION = 9
   static constexpr int kDefaultCompressionLevel = 3;
 
+  // The default compression threshold is 0, which means always compress.
+  static constexpr uint32_t kDefaultCompressionThresholdBytes = 0;
+
+  // The compression ratio to use for decompression buffer size.
+  static constexpr int kProtoCompressionRatio = 3;
+
   // Number of bytes we reserve for the heading at the beginning of the proto
   // log. We reserve this so the header can grow without running into the
   // contents of the proto log, triggering an unnecessary migration of the data.
@@ -503,7 +525,10 @@ class PortableFileBackedProtoLog {
   PortableFileBackedProtoLog(const Filesystem* filesystem,
                              const std::string& file_path,
                              std::unique_ptr<Header> header, int64_t file_size,
-                             int32_t compression_level);
+                             int32_t compression_level,
+                             uint32_t compression_threshold_bytes,
+                             int32_t compression_mem_level,
+                             bool enable_smaller_decompression_buffer_size);
 
   // Initializes a new proto log.
   //
@@ -589,18 +614,27 @@ class PortableFileBackedProtoLog {
   std::unique_ptr<Header> header_;
   int64_t file_size_;
   const int32_t compression_level_;
+  const uint32_t compression_threshold_bytes_;
+  const int32_t compression_mem_level_;
+  const bool enable_smaller_decompression_buffer_size_;
 };
 
 template <typename ProtoT>
 PortableFileBackedProtoLog<ProtoT>::PortableFileBackedProtoLog(
     const Filesystem* filesystem, const std::string& file_path,
     std::unique_ptr<Header> header, int64_t file_size,
-    int32_t compression_level)
+    int32_t compression_level, uint32_t compression_threshold_bytes,
+    int32_t compression_mem_level,
+    bool enable_smaller_decompression_buffer_size)
     : filesystem_(filesystem),
       file_path_(file_path),
       header_(std::move(header)),
       file_size_(file_size),
-      compression_level_(compression_level) {
+      compression_level_(compression_level),
+      compression_threshold_bytes_(compression_threshold_bytes),
+      compression_mem_level_(compression_mem_level),
+      enable_smaller_decompression_buffer_size_(
+          enable_smaller_decompression_buffer_size) {
   fd_.reset(filesystem_->OpenForAppend(file_path.c_str()));
 }
 
@@ -639,6 +673,13 @@ PortableFileBackedProtoLog<ProtoT>::Create(const Filesystem* filesystem,
         options.compression_level));
   }
 
+  if (options.compression_mem_level < 1 || options.compression_mem_level > 9) {
+    return absl_ports::InvalidArgumentError(
+        IcingStringUtil::StringPrintf("options.compression_mem_level must be "
+                                      "between 1 and 9 inclusive, was %d",
+                                      options.compression_mem_level));
+  }
+
   if (!filesystem->FileExists(file_path.c_str())) {
     return InitializeNewFile(filesystem, file_path, options);
   }
@@ -674,16 +715,38 @@ PortableFileBackedProtoLog<ProtoT>::InitializeNewFile(
   header->SetMaxProtoSize(options.max_proto_size);
   header->SetHeaderChecksum(header->CalculateHeaderChecksum());
 
-  if (!filesystem->Write(file_path.c_str(), header.get(), sizeof(Header))) {
-    return absl_ports::InternalError(
-        absl_ports::StrCat("Failed to write header for file: ", file_path));
+  {
+    ScopedFd fd(filesystem->OpenForWrite(file_path.c_str()));
+    if (!fd.is_valid()) {
+      return absl_ports::InternalError(
+          absl_ports::StrCat("Failed to open file for write: ", file_path));
+    }
+
+    if (!filesystem->Write(fd.get(), header.get(), sizeof(Header))) {
+      return absl_ports::InternalError(
+          absl_ports::StrCat("Failed to write header for file: ", file_path));
+    }
+
+    // Sync the file to disk to ensure that the header is flushed to disk.
+    // - Otherwise, if the app crashes before the header is flushed, the next
+    //   initialize may fail.
+    // - This is especially important for this class, since it is used to store
+    //   ground truth data. If magic or checksum is wrong, then Icing cannot
+    //   recover it from this state and therefore end up with entire data loss.
+    if (!filesystem->DataSync(fd.get())) {
+      return absl_ports::InternalError(
+          absl_ports::StrCat("Failed to sync file: ", file_path));
+    }
   }
 
   CreateResult create_result = {
       std::unique_ptr<PortableFileBackedProtoLog<ProtoT>>(
           new PortableFileBackedProtoLog<ProtoT>(
               filesystem, file_path, std::move(header),
-              /*file_size=*/kHeaderReservedBytes, options.compression_level)),
+              /*file_size=*/kHeaderReservedBytes, options.compression_level,
+              options.compression_threshold_bytes,
+              options.compression_mem_level,
+              options.enable_smaller_decompression_buffer_size)),
       /*data_loss=*/DataLoss::NONE, /*recalculated_checksum=*/false};
 
   return create_result;
@@ -697,13 +760,17 @@ PortableFileBackedProtoLog<ProtoT>::InitializeExistingFile(
     const Options& options, int64_t file_size) {
   bool header_changed = false;
   if (file_size < kHeaderReservedBytes) {
+    ICING_LOG(ERROR) << "Invalid file size for PortableFileBackedProtoLog "
+                     << file_path
+                     << " for header reserved bytes. File size: " << file_size
+                     << ", header reserved bytes: " << kHeaderReservedBytes;
     return absl_ports::InternalError(
         absl_ports::StrCat("File header too short for: ", file_path));
   }
 
   std::unique_ptr<Header> header = std::make_unique<Header>();
-  if (!filesystem->PRead(file_path.c_str(), header.get(), sizeof(Header),
-                         /*offset=*/0)) {
+  if (filesystem->PRead(file_path.c_str(), header.get(), sizeof(Header),
+                        /*offset=*/0) != sizeof(Header)) {
     return absl_ports::InternalError(
         absl_ports::StrCat("Failed to read header for file: ", file_path));
   }
@@ -712,8 +779,11 @@ PortableFileBackedProtoLog<ProtoT>::InitializeExistingFile(
   // is covered by the header_checksum check below, but this is a quick check
   // that can save us from an extra crc computation.
   if (header->GetMagic() != Header::kMagic) {
-    return absl_ports::InternalError(
-        absl_ports::StrCat("Invalid header kMagic for file: ", file_path));
+    ICING_LOG(ERROR) << "Invalid header magic for PortableFileBackedProtoLog "
+                     << file_path << ". Expected: " << Header::kMagic
+                     << ", actual: " << header->GetMagic();
+    return absl_ports::InternalError(absl_ports::StrCat(
+        "Invalid header magic for PortableFileBackedProtoLog: ", file_path));
   }
 
   if (header->GetHeaderChecksum() != header->CalculateHeaderChecksum()) {
@@ -816,9 +886,11 @@ PortableFileBackedProtoLog<ProtoT>::InitializeExistingFile(
 
   CreateResult create_result = {
       std::unique_ptr<PortableFileBackedProtoLog<ProtoT>>(
-          new PortableFileBackedProtoLog<ProtoT>(filesystem, file_path,
-                                                 std::move(header), file_size,
-                                                 options.compression_level)),
+          new PortableFileBackedProtoLog<ProtoT>(
+              filesystem, file_path, std::move(header), file_size,
+              options.compression_level, options.compression_threshold_bytes,
+              options.compression_mem_level,
+              options.enable_smaller_decompression_buffer_size)),
       data_loss, recalculated_checksum};
 
   return create_result;
@@ -922,7 +994,14 @@ PortableFileBackedProtoLog<ProtoT>::WriteProto(const ProtoT& proto) {
   if (header_->GetCompressFlag()) {
     protobuf_ports::GzipOutputStream::Options options;
     options.format = protobuf_ports::GzipOutputStream::ZLIB;
-    options.compression_level = compression_level_;
+
+    if (proto_size >= compression_threshold_bytes_) {
+      options.compression_level = compression_level_;
+    } else {
+      options.compression_level = 0;
+    }
+    options.buffer_size =
+        std::min(protobuf_ports::kDefaultBufferSize, proto_size);
 
     protobuf_ports::GzipOutputStream compressing_stream(&proto_stream, options);
 
@@ -990,7 +1069,8 @@ PortableFileBackedProtoLog<ProtoT>::ReadProto(int64_t file_offset) const {
                                       static_cast<long long>(file_size_ - 1)));
   }
   auto buf = std::make_unique<char[]>(stored_size);
-  if (!filesystem_->PRead(fd_.get(), buf.get(), stored_size, file_offset)) {
+  if (filesystem_->PRead(fd_.get(), buf.get(), stored_size, file_offset) !=
+      stored_size) {
     return absl_ports::InternalError("");
   }
 
@@ -1003,7 +1083,13 @@ PortableFileBackedProtoLog<ProtoT>::ReadProto(int64_t file_offset) const {
   // Deserialize proto
   ProtoT proto;
   if (header_->GetCompressFlag()) {
-    protobuf_ports::GzipInputStream decompress_stream(&proto_stream);
+    // Buffer size of -1 will default to kDefaultBufferSize.
+    int64_t buffer_size = -1;
+    if (enable_smaller_decompression_buffer_size_) {
+      buffer_size = kProtoCompressionRatio * stored_size;
+    }
+    protobuf_ports::GzipInputStream decompress_stream(
+        &proto_stream, protobuf_ports::GzipInputStream::AUTO, buffer_size);
     proto.ParseFromZeroCopyStream(&decompress_stream);
   } else {
     proto.ParseFromZeroCopyStream(&proto_stream);
@@ -1047,7 +1133,8 @@ libtextclassifier3::Status PortableFileBackedProtoLog<ProtoT>::EraseProto(
     // The xored string is the same as the original string because 0 xor 0 =
     // 0, 1 xor 0 = 1.
     // Read the compressed proto out.
-    if (!filesystem_->PRead(fd_.get(), buf.get(), stored_size, file_offset)) {
+    if (filesystem_->PRead(fd_.get(), buf.get(), stored_size, file_offset) !=
+        stored_size) {
       return absl_ports::InternalError("");
     }
     const std::string_view xored_str(buf.get(), stored_size);
@@ -1168,7 +1255,8 @@ PortableFileBackedProtoLog<ProtoT>::ReadProtoMetadata(
         static_cast<long long>(file_size)));
   }
 
-  if (!filesystem->PRead(fd, &portable_metadata, metadata_size, file_offset)) {
+  if (filesystem->PRead(fd, &portable_metadata, metadata_size, file_offset) !=
+      metadata_size) {
     return absl_ports::InternalError("");
   }
 
diff --git a/icing/file/portable-file-backed-proto-log_benchmark.cc b/icing/file/portable-file-backed-proto-log_benchmark.cc
index e6935ab..f075841 100644
--- a/icing/file/portable-file-backed-proto-log_benchmark.cc
+++ b/icing/file/portable-file-backed-proto-log_benchmark.cc
@@ -13,14 +13,16 @@
 // limitations under the License.
 
 #include <cstdint>
+#include <memory>
 #include <random>
+#include <string>
 
 #include "testing/base/public/benchmark.h"
-#include "gmock/gmock.h"
 #include "icing/document-builder.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/legacy/core/icing-string-util.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/random-string.h"
@@ -55,6 +57,23 @@ namespace lib {
 
 namespace {
 
+std::unique_ptr<PortableFileBackedProtoLog<DocumentProto>> CreateProtoLog(
+    const Filesystem& filesystem, const std::string& file_path,
+    int max_proto_size, bool compress) {
+  return PortableFileBackedProtoLog<DocumentProto>::Create(
+             &filesystem, file_path,
+             PortableFileBackedProtoLog<DocumentProto>::Options(
+                 compress, max_proto_size,
+                 PortableFileBackedProtoLog<
+                     DocumentProto>::kDefaultCompressionLevel,
+                 PortableFileBackedProtoLog<
+                     DocumentProto>::kDefaultCompressionThresholdBytes,
+                 protobuf_ports::kDefaultMemLevel,
+                 /*enable_smaller_decompression_buffer_size=*/true))
+      .ValueOrDie()
+      .proto_log;
+}
+
 void BM_Write(benchmark::State& state) {
   const Filesystem filesystem;
   int string_length = state.range(0);
@@ -66,12 +85,8 @@ void BM_Write(benchmark::State& state) {
   // Make sure it doesn't already exist.
   filesystem.DeleteFile(file_path.c_str());
 
-  auto proto_log = PortableFileBackedProtoLog<DocumentProto>::Create(
-                       &filesystem, file_path,
-                       PortableFileBackedProtoLog<DocumentProto>::Options(
-                           compress, max_proto_size))
-                       .ValueOrDie()
-                       .proto_log;
+  auto proto_log =
+      CreateProtoLog(filesystem, file_path, max_proto_size, compress);
 
   DocumentProto document = DocumentBuilder().SetKey("namespace", "uri").Build();
 
@@ -119,12 +134,8 @@ void BM_Read(benchmark::State& state) {
   // Make sure it doesn't already exist.
   filesystem.DeleteFile(file_path.c_str());
 
-  auto proto_log = PortableFileBackedProtoLog<DocumentProto>::Create(
-                       &filesystem, file_path,
-                       PortableFileBackedProtoLog<DocumentProto>::Options(
-                           compress, max_proto_size))
-                       .ValueOrDie()
-                       .proto_log;
+  auto proto_log =
+      CreateProtoLog(filesystem, file_path, max_proto_size, compress);
 
   DocumentProto document = DocumentBuilder().SetKey("namespace", "uri").Build();
 
@@ -174,12 +185,8 @@ void BM_Erase(benchmark::State& state) {
   // Make sure it doesn't already exist.
   filesystem.DeleteFile(file_path.c_str());
 
-  auto proto_log = PortableFileBackedProtoLog<DocumentProto>::Create(
-                       &filesystem, file_path,
-                       PortableFileBackedProtoLog<DocumentProto>::Options(
-                           compress, max_proto_size))
-                       .ValueOrDie()
-                       .proto_log;
+  auto proto_log =
+      CreateProtoLog(filesystem, file_path, max_proto_size, compress);
 
   DocumentProto document = DocumentBuilder().SetKey("namespace", "uri").Build();
 
@@ -213,12 +220,8 @@ void BM_UpdateChecksum(benchmark::State& state) {
   // Make sure it doesn't already exist.
   filesystem.DeleteFile(file_path.c_str());
 
-  auto proto_log = PortableFileBackedProtoLog<DocumentProto>::Create(
-                       &filesystem, file_path,
-                       PortableFileBackedProtoLog<DocumentProto>::Options(
-                           compress, max_proto_size))
-                       .ValueOrDie()
-                       .proto_log;
+  auto proto_log =
+      CreateProtoLog(filesystem, file_path, max_proto_size, compress);
 
   DocumentProto document = DocumentBuilder().SetKey("namespace", "uri").Build();
 
@@ -255,12 +258,8 @@ void BM_UpdateChecksumWithCachedChecksum(benchmark::State& state) {
   // Make sure it doesn't already exist.
   filesystem.DeleteFile(file_path.c_str());
 
-  auto proto_log = PortableFileBackedProtoLog<DocumentProto>::Create(
-                       &filesystem, file_path,
-                       PortableFileBackedProtoLog<DocumentProto>::Options(
-                           compress, max_proto_size))
-                       .ValueOrDie()
-                       .proto_log;
+  auto proto_log =
+      CreateProtoLog(filesystem, file_path, max_proto_size, compress);
 
   DocumentProto document = DocumentBuilder().SetKey("namespace", "uri").Build();
 
@@ -299,12 +298,8 @@ void BM_UpdateChecksumOnlyForTail(benchmark::State& state) {
   // Make sure it doesn't already exist.
   filesystem.DeleteFile(file_path.c_str());
 
-  auto proto_log = PortableFileBackedProtoLog<DocumentProto>::Create(
-                       &filesystem, file_path,
-                       PortableFileBackedProtoLog<DocumentProto>::Options(
-                           compress, max_proto_size))
-                       .ValueOrDie()
-                       .proto_log;
+  auto proto_log =
+      CreateProtoLog(filesystem, file_path, max_proto_size, compress);
 
   DocumentProto document = DocumentBuilder().SetKey("namespace", "uri").Build();
 
diff --git a/icing/file/portable-file-backed-proto-log_test.cc b/icing/file/portable-file-backed-proto-log_test.cc
index 587bfdc..ca12ad0 100644
--- a/icing/file/portable-file-backed-proto-log_test.cc
+++ b/icing/file/portable-file-backed-proto-log_test.cc
@@ -16,16 +16,26 @@
 
 #include <cstdint>
 #include <cstdlib>
+#include <memory>
+#include <string>
+#include <utility>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
 #include "icing/file/filesystem.h"
+#include "icing/file/memory-mapped-file.h"
 #include "icing/file/mock-filesystem.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/crc32.h"
+#include "icing/util/data-loss.h"
+#include "icing/util/status-macros.h"
 
 namespace icing {
 namespace lib {
@@ -33,14 +43,11 @@ namespace lib {
 namespace {
 
 using ::icing::lib::portable_equals_proto::EqualsProto;
-using ::testing::A;
 using ::testing::Eq;
 using ::testing::Gt;
 using ::testing::HasSubstr;
 using ::testing::Not;
 using ::testing::NotNull;
-using ::testing::Pair;
-using ::testing::Return;
 
 using Header = PortableFileBackedProtoLog<DocumentProto>::Header;
 
@@ -56,6 +63,19 @@ void WriteHeader(Filesystem filesystem, const std::string& file_path,
   filesystem.Write(file_path.c_str(), &header, sizeof(Header));
 }
 
+libtextclassifier3::StatusOr<std::pair<int64_t, int64_t>>
+WriteProtoAndReturnOffsetAndSize(
+    PortableFileBackedProtoLog<DocumentProto>* proto_log,
+    const DocumentProto& document) {
+  ICING_ASSIGN_OR_RETURN(int64_t document_log_size_before,
+                         proto_log->GetElementsFileSize());
+  ICING_ASSIGN_OR_RETURN(int64_t offset, proto_log->WriteProto(document));
+  ICING_ASSIGN_OR_RETURN(int64_t document_log_size_after,
+                         proto_log->GetElementsFileSize());
+  int64_t size_written = document_log_size_after - document_log_size_before;
+  return std::make_pair(offset, size_written);
+}
+
 class PortableFileBackedProtoLogTest : public ::testing::Test {
  protected:
   // Adds a user-defined default construct because a const member variable may
@@ -75,7 +95,11 @@ class PortableFileBackedProtoLogTest : public ::testing::Test {
   bool compress_ = true;
   int32_t compression_level_ =
       PortableFileBackedProtoLog<DocumentProto>::kDefaultCompressionLevel;
+  uint32_t compression_threshold_bytes_ = PortableFileBackedProtoLog<
+      DocumentProto>::kDefaultCompressionThresholdBytes;
+  int32_t compression_mem_level_ = protobuf_ports::kDefaultMemLevel;
   int64_t max_proto_size_ = 256 * 1024;  // 256 KiB
+  bool enable_smaller_decompression_buffer_size_ = true;
 };
 
 TEST_F(PortableFileBackedProtoLogTest, Initialize) {
@@ -84,7 +108,9 @@ TEST_F(PortableFileBackedProtoLogTest, Initialize) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size_, compression_level_)));
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
   EXPECT_THAT(create_result.proto_log, NotNull());
   EXPECT_FALSE(create_result.has_data_loss());
   EXPECT_FALSE(create_result.recalculated_checksum);
@@ -93,17 +119,41 @@ TEST_F(PortableFileBackedProtoLogTest, Initialize) {
   ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
                   &filesystem_, file_path_,
                   PortableFileBackedProtoLog<DocumentProto>::Options(
-                      !compress_, max_proto_size_, compression_level_)),
+                      !compress_, max_proto_size_, compression_level_,
+                      compression_threshold_bytes_, compression_mem_level_,
+                      enable_smaller_decompression_buffer_size_)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
+TEST_F(PortableFileBackedProtoLogTest, NewAndEmptyFileShouldFlushHeader) {
+  // Mock the filesystem to verify that DataSync is called.
+  auto mock_filesystem = std::make_unique<MockFilesystem>();
+  EXPECT_CALL(*mock_filesystem, DataSync(_)).Times(1);
+
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            mock_filesystem.get(), file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
+    EXPECT_THAT(create_result.proto_log, NotNull());
+    EXPECT_FALSE(create_result.has_data_loss());
+    EXPECT_FALSE(create_result.recalculated_checksum);
+  }
+}
+
 TEST_F(PortableFileBackedProtoLogTest, InitializeValidatesOptions) {
   // max_proto_size must be greater than 0
   int invalid_max_proto_size = 0;
   ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
                   &filesystem_, file_path_,
                   PortableFileBackedProtoLog<DocumentProto>::Options(
-                      compress_, invalid_max_proto_size, compression_level_)),
+                      compress_, invalid_max_proto_size, compression_level_,
+                      compression_threshold_bytes_, compression_mem_level_,
+                      enable_smaller_decompression_buffer_size_)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // max_proto_size must be under 16 MiB
@@ -111,7 +161,9 @@ TEST_F(PortableFileBackedProtoLogTest, InitializeValidatesOptions) {
   ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
                   &filesystem_, file_path_,
                   PortableFileBackedProtoLog<DocumentProto>::Options(
-                      compress_, invalid_max_proto_size, compression_level_)),
+                      compress_, invalid_max_proto_size, compression_level_,
+                      compression_threshold_bytes_, compression_mem_level_,
+                      enable_smaller_decompression_buffer_size_)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // compression_level must be between 0 and 9 inclusive
@@ -119,7 +171,9 @@ TEST_F(PortableFileBackedProtoLogTest, InitializeValidatesOptions) {
   ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
                   &filesystem_, file_path_,
                   PortableFileBackedProtoLog<DocumentProto>::Options(
-                      compress_, max_proto_size_, invalid_compression_level)),
+                      compress_, max_proto_size_, invalid_compression_level,
+                      compression_threshold_bytes_, compression_mem_level_,
+                      enable_smaller_decompression_buffer_size_)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
   // compression_level must be between 0 and 9 inclusive
@@ -127,8 +181,32 @@ TEST_F(PortableFileBackedProtoLogTest, InitializeValidatesOptions) {
   ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
                   &filesystem_, file_path_,
                   PortableFileBackedProtoLog<DocumentProto>::Options(
-                      compress_, max_proto_size_, invalid_compression_level)),
+                      compress_, max_proto_size_, invalid_compression_level,
+                      compression_threshold_bytes_, compression_mem_level_,
+                      enable_smaller_decompression_buffer_size_)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+
+  // compression_mem_level must be between 1 and 9 inclusive
+  int invalid_compression_mem_level = 0;
+  ASSERT_THAT(
+      PortableFileBackedProtoLog<DocumentProto>::Create(
+          &filesystem_, file_path_,
+          PortableFileBackedProtoLog<DocumentProto>::Options(
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, invalid_compression_mem_level,
+              enable_smaller_decompression_buffer_size_)),
+      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+
+  // compression_mem_level must be between 1 and 9 inclusive
+  invalid_compression_mem_level = 10;
+  ASSERT_THAT(
+      PortableFileBackedProtoLog<DocumentProto>::Create(
+          &filesystem_, file_path_,
+          PortableFileBackedProtoLog<DocumentProto>::Options(
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, invalid_compression_mem_level,
+              enable_smaller_decompression_buffer_size_)),
+      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
 TEST_F(PortableFileBackedProtoLogTest, ReservedSpaceForHeader) {
@@ -137,7 +215,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReservedSpaceForHeader) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size_, compression_level_)));
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
 
   // With no protos written yet, the log should be minimum the size of the
   // reserved header space.
@@ -152,7 +232,9 @@ TEST_F(PortableFileBackedProtoLogTest, WriteProtoTooLarge) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size, compression_level_)));
+              compress_, max_proto_size, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
   auto proto_log = std::move(create_result.proto_log);
   ASSERT_FALSE(create_result.has_data_loss());
 
@@ -169,7 +251,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadProtoWrongKProtoMagic) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size_, compression_level_)));
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
   auto proto_log = std::move(create_result.proto_log);
   ASSERT_FALSE(create_result.has_data_loss());
 
@@ -203,7 +287,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteUncompressedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                /*compress_in=*/false, max_proto_size_, compression_level_)));
+                /*compress_in=*/false, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -250,7 +336,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteUncompressedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                /*compress_in=*/false, max_proto_size_, compression_level_)));
+                /*compress_in=*/false, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto recreated_proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -272,7 +360,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteCompressedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                /*compress_in=*/true, max_proto_size_, compression_level_)));
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -319,7 +409,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteCompressedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                /*compress_in=*/true, max_proto_size_, compression_level_)));
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto recreated_proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -356,7 +448,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteDifferentCompressionLevel) {
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
                 /*compress_in=*/true, max_proto_size_,
-                /*compression_level_in=*/3)));
+                /*compression_level_in=*/3,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -381,7 +475,9 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteDifferentCompressionLevel) {
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
                 /*compress_in=*/true, max_proto_size_,
-                /*compression_level_in=*/9)));
+                /*compression_level_in=*/9,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto recreated_proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -410,7 +506,223 @@ TEST_F(PortableFileBackedProtoLogTest, ReadWriteDifferentCompressionLevel) {
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
                 /*compress_in=*/true, max_proto_size_,
-                /*compression_level=*/0)));
+                /*compression_level_in=*/0,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
+    auto recreated_proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Check the first proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Check the second proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+
+    // Write a third proto
+    ICING_ASSERT_OK_AND_ASSIGN(document3_offset,
+                               recreated_proto_log->WriteProto(document3));
+
+    ASSERT_GT(document3_offset, document2_offset);
+
+    // Check the third proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document3_offset),
+                IsOkAndHolds(EqualsProto(document3)));
+  }
+}
+
+TEST_F(PortableFileBackedProtoLogTest, ReadWriteDifferentCompressionMemLevel) {
+  int document1_offset;
+  int document2_offset;
+  int document3_offset;
+
+  // The first proto to write that's close to the max size. Leave some room for
+  // the rest of the proto properties.
+  std::string long_str(max_proto_size_ - 1024, 'a');
+  DocumentProto document1 = DocumentBuilder()
+                                .SetKey("namespace1", "uri1")
+                                .AddStringProperty("long_str", long_str)
+                                .Build();
+  DocumentProto document2 =
+      DocumentBuilder().SetKey("namespace2", "uri2").Build();
+  DocumentProto document3 =
+      DocumentBuilder().SetKey("namespace3", "uri3").Build();
+
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                compression_threshold_bytes_,
+                /*compression_mem_level_in=*/8,
+                enable_smaller_decompression_buffer_size_)));
+    auto proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Write the first proto
+    ICING_ASSERT_OK_AND_ASSIGN(document1_offset,
+                               proto_log->WriteProto(document1));
+
+    // Check that what we read is what we wrote
+    ASSERT_THAT(proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    ICING_ASSERT_OK(proto_log->PersistToDisk());
+  }
+
+  // Make a new proto_log with the same file_path but different compression mem
+  // level, and make sure we can still read from and write to the same
+  // underlying file.
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                compression_threshold_bytes_,
+                /*compression_mem_level_in=*/1,
+                enable_smaller_decompression_buffer_size_)));
+    auto recreated_proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Check the first proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Write a second proto
+    ICING_ASSERT_OK_AND_ASSIGN(document2_offset,
+                               recreated_proto_log->WriteProto(document2));
+
+    ASSERT_GT(document2_offset, document1_offset);
+
+    // Check the second proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+
+    ICING_ASSERT_OK(recreated_proto_log->PersistToDisk());
+  }
+
+  // One more time but with 9 compression mem level
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                compression_threshold_bytes_,
+                /*compression_mem_level_in=*/9,
+                enable_smaller_decompression_buffer_size_)));
+    auto recreated_proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Check the first proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Check the second proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+
+    // Write a third proto
+    ICING_ASSERT_OK_AND_ASSIGN(document3_offset,
+                               recreated_proto_log->WriteProto(document3));
+
+    ASSERT_GT(document3_offset, document2_offset);
+
+    // Check the third proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document3_offset),
+                IsOkAndHolds(EqualsProto(document3)));
+  }
+}
+
+TEST_F(PortableFileBackedProtoLogTest,
+       ReadWriteEnableAndDisableSmallerDecompressionBufferSize) {
+  int document1_offset;
+  int document2_offset;
+  int document3_offset;
+
+  // The first proto to write that's close to the max size. Leave some room for
+  // the rest of the proto properties.
+  std::string long_str(max_proto_size_ - 1024, 'a');
+  DocumentProto document1 = DocumentBuilder()
+                                .SetKey("namespace1", "uri1")
+                                .AddStringProperty("long_str", long_str)
+                                .Build();
+  DocumentProto document2 =
+      DocumentBuilder().SetKey("namespace2", "uri2").Build();
+  DocumentProto document3 =
+      DocumentBuilder().SetKey("namespace3", "uri3").Build();
+
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                /*enable_smaller_decompression_buffer_size_in=*/false)));
+    auto proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Write the first proto
+    ICING_ASSERT_OK_AND_ASSIGN(document1_offset,
+                               proto_log->WriteProto(document1));
+
+    // Check that what we read is what we wrote
+    ASSERT_THAT(proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    ICING_ASSERT_OK(proto_log->PersistToDisk());
+  }
+
+  // Make a new proto_log with the same file_path with smaller decompression
+  // buffer size enabled, and make sure we can still read from and write to the
+  // same underlying file.
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                /*enable_smaller_decompression_buffer_size_in=*/true)));
+    auto recreated_proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Check the first proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Write a second proto
+    ICING_ASSERT_OK_AND_ASSIGN(document2_offset,
+                               recreated_proto_log->WriteProto(document2));
+
+    ASSERT_GT(document2_offset, document1_offset);
+
+    // Check the second proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+
+    ICING_ASSERT_OK(recreated_proto_log->PersistToDisk());
+  }
+
+  // One more time but with smaller decompression buffer size disabled
+  {
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                /*enable_smaller_decompression_buffer_size_in=*/false)));
     auto recreated_proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -454,7 +766,9 @@ TEST_F(PortableFileBackedProtoLogTest,
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
                 /*compress_in=*/true, max_proto_size_,
-                /*compression_level_in=*/3)));
+                /*compression_level_in=*/3, compression_threshold_bytes_,
+                compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -476,7 +790,9 @@ TEST_F(PortableFileBackedProtoLogTest,
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
                 /*compress_in=*/true, max_proto_size_,
-                /*compression_level_in=*/0)));
+                /*compression_level_in=*/0, compression_threshold_bytes_,
+                compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -494,6 +810,221 @@ TEST_F(PortableFileBackedProtoLogTest,
   }
 }
 
+TEST_F(PortableFileBackedProtoLogTest, CompressionThreshold) {
+  // Create document1 with size of 1024 bytes.
+  int64_t document1_size = 1024;
+  int64_t document1_offset;
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("namespace1", "uri1")
+          .AddStringProperty("long_str", std::string(990, 'a'))
+          .Build();
+  ASSERT_THAT(document1.ByteSizeLong(), Eq(document1_size));
+
+  // Create document2 with size of 900 bytes.
+  int64_t document2_size = 900;
+  int64_t document2_offset;
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("namespace1", "uri1")
+          .AddStringProperty("long_str", std::string(866, 'a'))
+          .Build();
+  ASSERT_THAT(document2.ByteSizeLong(), Eq(document2_size));
+
+  {
+    // Create a proto_log with compression threshold of 1000 bytes
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_,
+                /*compression_level_in=*/3,
+                /*compression_threshold_bytes_in=*/1000, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
+    auto proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        auto document1_write_result,
+        WriteProtoAndReturnOffsetAndSize(proto_log.get(), document1));
+    document1_offset = document1_write_result.first;
+    int64_t document1_size_written = document1_write_result.second;
+    // Check that what we read is what we wrote
+    ASSERT_THAT(proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+    // The document should be compressed since it's size is larger than the
+    // compression threshold.
+    ASSERT_LT(document1_size_written, document1_size);
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        auto document2_write_result,
+        WriteProtoAndReturnOffsetAndSize(proto_log.get(), document2));
+    document2_offset = document2_write_result.first;
+    int64_t document2_size_written = document2_write_result.second;
+    // Check that what we read is what we wrote
+    ASSERT_THAT(proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+    // The document should be uncompressed since it's size is smaller than the
+    // compression threshold.
+    ASSERT_GE(document2_size_written, document2_size);
+
+    ICING_ASSERT_OK(proto_log->PersistToDisk());
+  }
+
+  {
+    // Make a new proto_log with the same file_path, and make sure we can still
+    // read and write to the same underlying file.
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_,
+                /*compression_level_in=*/3,
+                /*compression_threshold_bytes_in=*/1000, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
+    auto recreated_proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Check the first proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Check the second proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+
+    // Write a third proto
+    DocumentProto document3 =
+        DocumentBuilder().SetKey("namespace3", "uri3").Build();
+    ICING_ASSERT_OK_AND_ASSIGN(int64_t document3_offset,
+                               recreated_proto_log->WriteProto(document3));
+    ASSERT_GT(document3_offset, document2_offset);
+    // Check the third proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document3_offset),
+                IsOkAndHolds(EqualsProto(document3)));
+  }
+}
+
+TEST_F(PortableFileBackedProtoLogTest, ChangingCompressionThresholdIsOk) {
+  // Create document1 with size of 1024 bytes.
+  int64_t document1_size = 1024;
+  int64_t document1_offset;
+  int64_t document1_size_written;
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("namespace1", "uri1")
+          .AddStringProperty("long_str", std::string(990, 'a'))
+          .Build();
+  ASSERT_THAT(document1.ByteSizeLong(), Eq(document1_size));
+
+  // Create document2 with size of 900 bytes.
+  int64_t document2_size = 900;
+  int64_t document2_offset;
+  int64_t document2_size_written;
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("namespace1", "uri1")
+          .AddStringProperty("long_str", std::string(866, 'a'))
+          .Build();
+  ASSERT_THAT(document2.ByteSizeLong(), Eq(document2_size));
+
+  {
+    // Create a proto_log with compression threshold of 1000 bytes
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_,
+                /*compression_level_in=*/3,
+                /*compression_threshold_bytes_in=*/1000, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
+    auto proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        auto document1_write_result,
+        WriteProtoAndReturnOffsetAndSize(proto_log.get(), document1));
+    document1_offset = document1_write_result.first;
+    document1_size_written = document1_write_result.second;
+    // Check that what we read is what we wrote
+    ASSERT_THAT(proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+    // The document should be compressed since it's size is larger than the
+    // compression threshold.
+    ASSERT_LT(document1_size_written, document1_size);
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        auto document2_write_result,
+        WriteProtoAndReturnOffsetAndSize(proto_log.get(), document2));
+    document2_offset = document2_write_result.first;
+    document2_size_written = document2_write_result.second;
+    // Check that what we read is what we wrote
+    ASSERT_THAT(proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+    // The document should be uncompressed since it's size is smaller than the
+    // compression threshold.
+    ASSERT_GE(document2_size_written, document2_size);
+
+    ICING_ASSERT_OK(proto_log->PersistToDisk());
+  }
+
+  {
+    // Make a new proto_log with the same file_path with a different compression
+    // threshold, and make sure we can still read and write to the same
+    // underlying file.
+    ICING_ASSERT_OK_AND_ASSIGN(
+        PortableFileBackedProtoLog<DocumentProto>::CreateResult create_result,
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                /*compress_in=*/true, max_proto_size_,
+                /*compression_level_in=*/3,
+                /*compression_threshold_bytes_in=*/100, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
+    auto recreated_proto_log = std::move(create_result.proto_log);
+    ASSERT_FALSE(create_result.has_data_loss());
+
+    // Check the first proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document1_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Check the second proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document2_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+
+    // Write document1 again as the third proto;
+    ICING_ASSERT_OK_AND_ASSIGN(
+        auto document3_write_result,
+        WriteProtoAndReturnOffsetAndSize(recreated_proto_log.get(), document1));
+    int64_t document3_offset = document3_write_result.first;
+    int64_t document3_size_written = document3_write_result.second;
+    // With this new compression threshold, document1 should still be
+    // compressed.
+    ASSERT_EQ(document3_size_written, document1_size_written);
+    ASSERT_GT(document3_offset, document2_offset);
+    // Check the third proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document3_offset),
+                IsOkAndHolds(EqualsProto(document1)));
+
+    // Write document2 again as the fourth proto;
+    ICING_ASSERT_OK_AND_ASSIGN(
+        auto document4_write_result,
+        WriteProtoAndReturnOffsetAndSize(recreated_proto_log.get(), document2));
+    int64_t document4_offset = document4_write_result.first;
+    int64_t document4_size_written = document4_write_result.second;
+    // With this new compression threshold, document2 should now be compressed.
+    ASSERT_LT(document4_size_written, document2_size_written);
+    ASSERT_LT(document4_size_written, document2_size);
+    ASSERT_GT(document4_offset, document3_offset);
+    // Check the fourth proto
+    ASSERT_THAT(recreated_proto_log->ReadProto(document4_offset),
+                IsOkAndHolds(EqualsProto(document2)));
+  }
+}
+
 TEST_F(PortableFileBackedProtoLogTest, CorruptHeader) {
   {
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -501,7 +1032,9 @@ TEST_F(PortableFileBackedProtoLogTest, CorruptHeader) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto recreated_proto_log = std::move(create_result.proto_log);
     EXPECT_FALSE(create_result.has_data_loss());
   }
@@ -518,7 +1051,9 @@ TEST_F(PortableFileBackedProtoLogTest, CorruptHeader) {
     ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
                     &filesystem_, file_path_,
                     PortableFileBackedProtoLog<DocumentProto>::Options(
-                        compress_, max_proto_size_, compression_level_)),
+                        compress_, max_proto_size_, compression_level_,
+                        compression_threshold_bytes_, compression_mem_level_,
+                        enable_smaller_decompression_buffer_size_)),
                 StatusIs(libtextclassifier3::StatusCode::INTERNAL,
                          HasSubstr("Invalid header checksum")));
   }
@@ -531,7 +1066,9 @@ TEST_F(PortableFileBackedProtoLogTest, DifferentMagic) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto recreated_proto_log = std::move(create_result.proto_log);
     EXPECT_FALSE(create_result.has_data_loss());
 
@@ -547,12 +1084,16 @@ TEST_F(PortableFileBackedProtoLogTest, DifferentMagic) {
 
   {
     // Reinitialize the same proto_log
-    ASSERT_THAT(PortableFileBackedProtoLog<DocumentProto>::Create(
-                    &filesystem_, file_path_,
-                    PortableFileBackedProtoLog<DocumentProto>::Options(
-                        compress_, max_proto_size_, compression_level_)),
-                StatusIs(libtextclassifier3::StatusCode::INTERNAL,
-                         HasSubstr("Invalid header kMagic")));
+    ASSERT_THAT(
+        PortableFileBackedProtoLog<DocumentProto>::Create(
+            &filesystem_, file_path_,
+            PortableFileBackedProtoLog<DocumentProto>::Options(
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)),
+        StatusIs(
+            libtextclassifier3::StatusCode::INTERNAL,
+            HasSubstr("Invalid header magic for PortableFileBackedProtoLog")));
   }
 }
 
@@ -573,7 +1114,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     EXPECT_FALSE(create_result.has_data_loss());
 
@@ -600,7 +1143,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     EXPECT_FALSE(create_result.has_data_loss());
     EXPECT_THAT(create_result.data_loss, Eq(DataLoss::NONE));
@@ -622,7 +1167,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -668,7 +1215,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     EXPECT_TRUE(create_result.has_data_loss());
     EXPECT_THAT(create_result.data_loss, Eq(DataLoss::COMPLETE));
@@ -697,7 +1246,9 @@ TEST_F(PortableFileBackedProtoLogTest, DirtyBitFalseAlarmKeepsData) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -727,7 +1278,9 @@ TEST_F(PortableFileBackedProtoLogTest, DirtyBitFalseAlarmKeepsData) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     EXPECT_FALSE(create_result.has_data_loss());
 
@@ -759,7 +1312,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -805,7 +1360,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_TRUE(create_result.has_data_loss());
     ASSERT_THAT(create_result.data_loss, Eq(DataLoss::PARTIAL));
@@ -830,7 +1387,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -853,7 +1412,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
 
     // We previously persisted to disk so everything should be in a perfect
     // state.
@@ -873,7 +1434,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -897,7 +1460,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
 
     // We previously persisted to disk so everything should be in a perfect
     // state.
@@ -916,7 +1481,9 @@ TEST_F(PortableFileBackedProtoLogTest, DirtyBitIsFalseAfterPutAndDestructor) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -941,7 +1508,9 @@ TEST_F(PortableFileBackedProtoLogTest, DirtyBitIsFalseAfterPutAndDestructor) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
 
     // We previously persisted to disk so everything should be in a perfect
     // state.
@@ -961,7 +1530,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -987,7 +1558,9 @@ TEST_F(PortableFileBackedProtoLogTest,
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
 
     // We previously persisted to disk so everything should be in a perfect
     // state.
@@ -1010,7 +1583,9 @@ TEST_F(PortableFileBackedProtoLogTest, Iterator) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size_, compression_level_)));
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
   auto proto_log = std::move(create_result.proto_log);
   ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1050,7 +1625,9 @@ TEST_F(PortableFileBackedProtoLogTest, UpdateChecksum) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1070,7 +1647,9 @@ TEST_F(PortableFileBackedProtoLogTest, UpdateChecksum) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1100,7 +1679,9 @@ TEST_F(PortableFileBackedProtoLogTest, EraseProtoShouldSetZero) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size_, compression_level_)));
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
   auto proto_log = std::move(create_result.proto_log);
   ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1136,7 +1717,9 @@ TEST_F(PortableFileBackedProtoLogTest, EraseProtoShouldReturnNotFound) {
       PortableFileBackedProtoLog<DocumentProto>::Create(
           &filesystem_, file_path_,
           PortableFileBackedProtoLog<DocumentProto>::Options(
-              compress_, max_proto_size_, compression_level_)));
+              compress_, max_proto_size_, compression_level_,
+              compression_threshold_bytes_, compression_mem_level_,
+              enable_smaller_decompression_buffer_size_)));
   auto proto_log = std::move(create_result.proto_log);
   ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1178,7 +1761,9 @@ TEST_F(PortableFileBackedProtoLogTest, ChecksumShouldBeCorrectWithErasedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1206,7 +1791,9 @@ TEST_F(PortableFileBackedProtoLogTest, ChecksumShouldBeCorrectWithErasedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1226,7 +1813,9 @@ TEST_F(PortableFileBackedProtoLogTest, ChecksumShouldBeCorrectWithErasedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                /*compression_threshold_bytes_in=*/0, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     ASSERT_FALSE(create_result.has_data_loss());
 
@@ -1248,7 +1837,9 @@ TEST_F(PortableFileBackedProtoLogTest, ChecksumShouldBeCorrectWithErasedProto) {
         PortableFileBackedProtoLog<DocumentProto>::Create(
             &filesystem_, file_path_,
             PortableFileBackedProtoLog<DocumentProto>::Options(
-                compress_, max_proto_size_, compression_level_)));
+                compress_, max_proto_size_, compression_level_,
+                compression_threshold_bytes_, compression_mem_level_,
+                enable_smaller_decompression_buffer_size_)));
     auto proto_log = std::move(create_result.proto_log);
     EXPECT_FALSE(create_result.has_data_loss());
   }
diff --git a/icing/file/posting_list/flash-index-storage-header.h b/icing/file/posting_list/flash-index-storage-header.h
index f7b331c..67fc4a6 100644
--- a/icing/file/posting_list/flash-index-storage-header.h
+++ b/icing/file/posting_list/flash-index-storage-header.h
@@ -62,7 +62,7 @@ class HeaderBlock {
   static libtextclassifier3::StatusOr<HeaderBlock> Read(
       const Filesystem* filesystem, int fd, int block_size) {
     std::unique_ptr<uint8_t[]> buffer = std::make_unique<uint8_t[]>(block_size);
-    if (!filesystem->PRead(fd, buffer.get(), block_size, 0)) {
+    if (filesystem->PRead(fd, buffer.get(), block_size, 0) != block_size) {
       return absl_ports::InternalError("Unable to reader header block!");
     }
     return HeaderBlock(filesystem, std::move(buffer), block_size);
diff --git a/icing/file/posting_list/flash-index-storage.cc b/icing/file/posting_list/flash-index-storage.cc
index 2198d2c..68f8e4c 100644
--- a/icing/file/posting_list/flash-index-storage.cc
+++ b/icing/file/posting_list/flash-index-storage.cc
@@ -21,15 +21,23 @@
 #include <cerrno>
 #include <cinttypes>
 #include <cstdint>
+#include <cstring>
 #include <memory>
+#include <string>
+#include <utility>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/absl_ports/str_cat.h"
+#include "icing/file/filesystem.h"
+#include "icing/file/posting_list/flash-index-storage-header.h"
 #include "icing/file/posting_list/index-block.h"
 #include "icing/file/posting_list/posting-list-common.h"
+#include "icing/file/posting_list/posting-list-identifier.h"
+#include "icing/file/posting_list/posting-list-used.h"
 #include "icing/legacy/core/icing-string-util.h"
+#include "icing/store/document-id.h"
 #include "icing/util/logging.h"
 #include "icing/util/math-util.h"
 #include "icing/util/status-macros.h"
@@ -110,20 +118,24 @@ bool FlashIndexStorage::InitHeader() {
   // Look for an existing file size.
   int64_t file_size = filesystem_->GetFileSize(storage_sfd_.get());
   if (file_size == Filesystem::kBadFileSize) {
-    ICING_LOG(ERROR) << "Could not initialize main index. Bad file size.";
+    ICING_LOG(ERROR)
+        << "Could not initialize flash index storage. Bad file size. Path: "
+        << index_filename_;
     return false;
   }
 
   if (file_size == 0) {
     if (!CreateHeader()) {
-      ICING_LOG(ERROR)
-          << "Could not initialize main index. Unable to create header.";
+      ICING_LOG(ERROR) << "Could not initialize flash index storage. Unable to "
+                          "create header. Path: "
+                       << index_filename_;
       return false;
     }
   } else {
     if (!OpenHeader(file_size)) {
-      ICING_LOG(ERROR)
-          << "Could not initialize main index. Unable to open header.";
+      ICING_LOG(ERROR) << "Could not initialize flash index storage. Unable to "
+                          "open header. Path: "
+                       << index_filename_;
       return false;
     }
   }
@@ -181,25 +193,32 @@ bool FlashIndexStorage::OpenHeader(int64_t file_size) {
       HeaderBlock read_header,
       HeaderBlock::Read(filesystem_, storage_sfd_.get(), block_size), false);
   if (read_header.header()->magic != HeaderBlock::Header::kMagic) {
-    ICING_LOG(ERROR) << "Index header block wrong magic";
+    ICING_LOG(ERROR) << "Invalid FlashIndexStorage header for "
+                     << index_filename_ << ": wrong magic. Expected: "
+                     << HeaderBlock::Header::kMagic
+                     << ", actual: " << read_header.header()->magic;
     return false;
   }
   if (file_size % read_header.header()->block_size != 0) {
-    ICING_LOG(ERROR) << "Index size " << file_size
-                     << " not a multiple of block size "
+    ICING_LOG(ERROR) << "Invalid FlashIndexStorage header for "
+                     << index_filename_ << ": file size " << file_size
+                     << " is not a multiple of block size "
                      << read_header.header()->block_size;
     return false;
   }
 
   if (file_size < static_cast<int64_t>(read_header.header()->block_size)) {
-    ICING_LOG(ERROR) << "Index size " << file_size
-                     << " shorter than block size "
+    ICING_LOG(ERROR) << "Invalid FlashIndexStorage header for "
+                     << index_filename_ << ": file size " << file_size
+                     << " is shorter than block size "
                      << read_header.header()->block_size;
     return false;
   }
 
   if (read_header.header()->block_size % getpagesize() != 0) {
-    ICING_LOG(ERROR) << "Block size " << read_header.header()->block_size
+    ICING_LOG(ERROR) << "Invalid FlashIndexStorage header for "
+                     << index_filename_ << ": block size "
+                     << read_header.header()->block_size
                      << " is not a multiple of page size " << getpagesize();
     return false;
   }
@@ -211,7 +230,8 @@ bool FlashIndexStorage::OpenHeader(int64_t file_size) {
     // still use the main index, but reads/writes won't be as efficient in terms
     // of flash IO because the 'blocks' that we're reading are actually multiple
     // pages long.
-    ICING_LOG(ERROR) << "Block size of existing header ("
+    ICING_LOG(ERROR) << "Invalid FlashIndexStorage header for "
+                     << index_filename_ << ": block size of existing header ("
                      << read_header.header()->block_size
                      << ") does not match the requested block size ("
                      << block_size << "). Defaulting to existing block size "
@@ -244,7 +264,8 @@ bool FlashIndexStorage::OpenHeader(int64_t file_size) {
 bool FlashIndexStorage::PersistToDisk() {
   // First, write header.
   if (!header_block_->Write(storage_sfd_.get())) {
-    ICING_LOG(ERROR) << "Write index header failed: " << strerror(errno);
+    ICING_LOG(ERROR) << "Write index header failed: (" << errno << ") "
+                     << strerror(errno);
     return false;
   }
 
@@ -535,7 +556,8 @@ int FlashIndexStorage::GrowIndex() {
   if (!filesystem_->Grow(
           storage_sfd_.get(),
           static_cast<uint64_t>(num_blocks_ + 1) * block_size())) {
-    ICING_VLOG(1) << "Error growing index file: " << strerror(errno);
+    ICING_LOG(ERROR) << "Error growing index file: (" << errno << ") "
+                     << strerror(errno);
     return kInvalidBlockIndex;
   }
 
diff --git a/icing/file/posting_list/index-block.cc b/icing/file/posting_list/index-block.cc
index 3fa397c..1f47da2 100644
--- a/icing/file/posting_list/index-block.cc
+++ b/icing/file/posting_list/index-block.cc
@@ -67,7 +67,8 @@ IndexBlock::CreateFromPreexistingIndexBlockRegion(
   }
 
   BlockHeader header;
-  if (!filesystem->PRead(fd, &header, sizeof(BlockHeader), block_file_offset)) {
+  if (filesystem->PRead(fd, &header, sizeof(BlockHeader), block_file_offset) !=
+      sizeof(BlockHeader)) {
     return absl_ports::InternalError("PRead block header error");
   }
 
@@ -284,8 +285,8 @@ libtextclassifier3::Status IndexBlock::FreePostingListImpl(
 libtextclassifier3::StatusOr<IndexBlock::BlockHeader> IndexBlock::ReadHeader()
     const {
   BlockHeader header;
-  if (!filesystem_->PRead(fd_, &header, sizeof(BlockHeader),
-                          block_file_offset_)) {
+  if (filesystem_->PRead(fd_, &header, sizeof(BlockHeader),
+                         block_file_offset_) != sizeof(BlockHeader)) {
     return absl_ports::InternalError(
         absl_ports::StrCat("PRead block header error: ", strerror(errno)));
   }
@@ -301,8 +302,9 @@ libtextclassifier3::StatusOr<IndexBlock::BlockHeader> IndexBlock::ReadHeader()
 libtextclassifier3::StatusOr<std::unique_ptr<uint8_t[]>>
 IndexBlock::ReadPostingList(PostingListIndex posting_list_index) const {
   auto posting_list_buffer = std::make_unique<uint8_t[]>(posting_list_bytes_);
-  if (!filesystem_->PRead(fd_, posting_list_buffer.get(), posting_list_bytes_,
-                          get_posting_list_file_offset(posting_list_index))) {
+  if (filesystem_->PRead(fd_, posting_list_buffer.get(), posting_list_bytes_,
+                         get_posting_list_file_offset(posting_list_index)) !=
+      posting_list_bytes_) {
     return absl_ports::InternalError(
         absl_ports::StrCat("PRead posting list error: ", strerror(errno)));
   }
diff --git a/icing/file/version-util.cc b/icing/file/version-util.cc
index e37c469..bb9f528 100644
--- a/icing/file/version-util.cc
+++ b/icing/file/version-util.cc
@@ -30,6 +30,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/index/index.h"
 #include "icing/proto/initialize.pb.h"
+#include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -45,10 +46,15 @@ libtextclassifier3::StatusOr<VersionInfo> ReadV1VersionInfo(
   // 1. Read the version info.
   const std::string v1_version_filepath =
       MakeVersionFilePath(version_file_dir, kVersionFilenameV1);
+  bool file_exists = filesystem.FileExists(v1_version_filepath.c_str());
+  ICING_LOG(INFO) << "v1 version file exists: " << file_exists;
+
   VersionInfo existing_version_info(-1, -1);
-  if (filesystem.FileExists(v1_version_filepath.c_str()) &&
-      !filesystem.PRead(v1_version_filepath.c_str(), &existing_version_info,
-                        sizeof(VersionInfo), /*offset=*/0)) {
+  if (file_exists &&
+      filesystem.PRead(v1_version_filepath.c_str(), &existing_version_info,
+                       sizeof(VersionInfo),
+                       /*offset=*/0) != sizeof(VersionInfo)) {
+    ICING_LOG(ERROR) << "Failed to read v1 version file";
     return absl_ports::InternalError("Failed to read v1 version file");
   }
 
@@ -56,6 +62,12 @@ libtextclassifier3::StatusOr<VersionInfo> ReadV1VersionInfo(
   libtextclassifier3::StatusOr<int> existing_flash_index_magic =
       Index::ReadFlashIndexMagic(&filesystem, index_base_dir);
   if (!existing_flash_index_magic.ok()) {
+    ICING_LOG(WARNING) << "Cannot read index flash index magic for v1 version "
+                          "check. Error code: "
+                       << existing_flash_index_magic.status().error_code()
+                       << ", message: "
+                       << existing_flash_index_magic.status().error_message();
+
     if (absl_ports::IsNotFound(existing_flash_index_magic.status())) {
       // Flash index magic doesn't exist. In this case, we're unable to
       // determine the version change state correctly (regardless of the
@@ -67,7 +79,10 @@ libtextclassifier3::StatusOr<VersionInfo> ReadV1VersionInfo(
     // Real error.
     return std::move(existing_flash_index_magic).status();
   }
-  if (existing_flash_index_magic.ValueOrDie() == kVersionZeroFlashIndexMagic) {
+
+  int flash_index_magic = existing_flash_index_magic.ValueOrDie();
+  ICING_LOG(INFO) << "Index flash index magic: " << flash_index_magic;
+  if (flash_index_magic == kVersionZeroFlashIndexMagic) {
     existing_version_info.version = 0;
     if (existing_version_info.max_version == -1) {
       existing_version_info.max_version = 0;
@@ -83,6 +98,9 @@ libtextclassifier3::StatusOr<IcingSearchEngineVersionProto> ReadV2VersionInfo(
   // IcingSearchEngineVersionProto as a file-backed proto.
   const std::string v2_version_filepath =
       MakeVersionFilePath(version_file_dir, kVersionFilenameV2);
+  ICING_LOG(INFO) << "v2 version file exists: "
+                  << filesystem.FileExists(v2_version_filepath.c_str());
+
   FileBackedProto<IcingSearchEngineVersionProto> v2_version_file(
       filesystem, v2_version_filepath);
   ICING_ASSIGN_OR_RETURN(const IcingSearchEngineVersionProto* v2_version_proto,
@@ -112,6 +130,11 @@ libtextclassifier3::StatusOr<IcingSearchEngineVersionProto> ReadVersion(
   // 2. Read the v2 version file
   auto v2_version_proto = ReadV2VersionInfo(filesystem, version_file_dir);
   if (!v2_version_proto.ok()) {
+    ICING_LOG(WARNING) << "Cannot read v2 version file. Error code: "
+                       << v2_version_proto.status().error_code()
+                       << ", message: "
+                       << v2_version_proto.status().error_message();
+
     if (!absl_ports::IsNotFound(v2_version_proto.status())) {
       // Real error.
       return std::move(v2_version_proto).status();
@@ -141,6 +164,11 @@ libtextclassifier3::StatusOr<IcingSearchEngineVersionProto> ReadVersion(
       // should have been written.
       // Return an invalid version number in this case and trigger rebuilding
       // everything.
+      ICING_LOG(WARNING)
+          << "v1 version file has a version number greater or equal to "
+             "kFirstV2Version, but failed to read v2 version file. Return "
+             "version -1 and rebuild everything.";
+
       version_proto.set_version(-1);
       version_proto.set_max_version(v1_version_info.max_version);
     }
@@ -153,6 +181,10 @@ libtextclassifier3::StatusOr<IcingSearchEngineVersionProto> ReadVersion(
   IcingSearchEngineVersionProto v2_version_proto_value =
       std::move(v2_version_proto).ValueOrDie();
   if (v1_version_info.version != v2_version_proto_value.version()) {
+    ICING_LOG(WARNING)
+        << "v1 and v2 version files have different version numbers, probably "
+           "due to roll forward. Return version -1 and rebuild everything.";
+
     v2_version_proto_value.set_version(-1);
     v2_version_proto_value.mutable_enabled_features()->Clear();
   }
@@ -165,26 +197,51 @@ libtextclassifier3::Status WriteV1Version(const Filesystem& filesystem,
                                           const VersionInfo& version_info) {
   ScopedFd scoped_fd(filesystem.OpenForWrite(
       MakeVersionFilePath(version_file_dir, kVersionFilenameV1).c_str()));
-  if (!scoped_fd.is_valid() ||
-      !filesystem.PWrite(scoped_fd.get(), /*offset=*/0, &version_info,
-                         sizeof(VersionInfo)) ||
-      !filesystem.DataSync(scoped_fd.get())) {
+  if (!scoped_fd.is_valid()) {
+    ICING_LOG(ERROR) << "Failed to open v1 version file for write";
+    return absl_ports::InternalError(
+        "Failed to open v1 version file for write");
+  }
+
+  if (!filesystem.PWrite(scoped_fd.get(), /*offset=*/0, &version_info,
+                         sizeof(VersionInfo))) {
+    ICING_LOG(ERROR) << "Failed to write v1 version file";
     return absl_ports::InternalError("Failed to write v1 version file");
   }
+
+  if (!filesystem.DataSync(scoped_fd.get())) {
+    ICING_LOG(ERROR) << "Failed to sync v1 version file";
+    return absl_ports::InternalError("Failed to sync v1 version file");
+  }
+
+  ICING_LOG(INFO)
+      << "Successfully write and sync v1 version file with version = "
+      << version_info.version;
   return libtextclassifier3::Status::OK;
 }
 
 libtextclassifier3::Status WriteV2Version(
     const Filesystem& filesystem, const std::string& version_file_dir,
     std::unique_ptr<IcingSearchEngineVersionProto> version_proto) {
+  int32_t version = version_proto->version();
+
+  // FileBackedProto::Write also syncs the file, so we don't need to call
+  // DataSync explicitly.
   FileBackedProto<IcingSearchEngineVersionProto> v2_version_file(
       filesystem, MakeVersionFilePath(version_file_dir, kVersionFilenameV2));
   libtextclassifier3::Status v2_write_status =
       v2_version_file.Write(std::move(version_proto));
   if (!v2_write_status.ok()) {
+    ICING_LOG(ERROR) << "Failed to write v2 version file. Error code: "
+                     << v2_write_status.error_code()
+                     << ", message: " << v2_write_status.error_message();
     return absl_ports::InternalError(absl_ports::StrCat(
         "Failed to write v2 version file: ", v2_write_status.error_message()));
   }
+
+  ICING_LOG(INFO)
+      << "Successfully write and sync v2 version file with version = "
+      << version;
   return libtextclassifier3::Status::OK;
 }
 
@@ -333,6 +390,10 @@ bool ShouldRebuildDerivedFiles(const VersionInfo& existing_version_info,
         // version 6 -> version 7 upgrade, no need to rebuild
         break;
       }
+      case 7: {
+        // version 7 -> version 8 upgrade, no need to rebuild
+        break;
+      }
       default:
         // This should not happen. Rebuild anyway if unsure.
         should_rebuild |= true;
diff --git a/icing/file/version-util.h b/icing/file/version-util.h
index 586a9c7..2a1fb39 100644
--- a/icing/file/version-util.h
+++ b/icing/file/version-util.h
@@ -39,7 +39,7 @@ namespace version_util {
 // - Version 3: M-2024-02. Schema is compatible with v1 and v2.
 // - Version 4: Android V base. Schema is compatible with v1, v2 and v3.
 // - Version 5: M-2025-02. Schema is compatible with v1, v2, v3 and v4.
-inline static constexpr int32_t kVersion = 7;
+inline static constexpr int32_t kVersion = 8;
 inline static constexpr int32_t kVersionOne = 1;
 inline static constexpr int32_t kVersionTwo = 2;
 inline static constexpr int32_t kVersionThree = 3;
diff --git a/icing/graph/graph-interface.h b/icing/graph/graph-interface.h
new file mode 100644
index 0000000..6605f28
--- /dev/null
+++ b/icing/graph/graph-interface.h
@@ -0,0 +1,74 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_GRAPH_GRAPH_INTERFACE_H_
+#define ICING_GRAPH_GRAPH_INTERFACE_H_
+
+#include <memory>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+
+namespace icing {
+namespace lib {
+
+namespace graph {
+
+// Graph interface with integer node id and given EdgeType.
+template <typename EdgeType>
+class GraphInterface {
+ public:
+  // Edge iterator interface.
+  class EdgeIteratorIf {
+   public:
+    virtual ~EdgeIteratorIf() = default;
+
+    // Advances to the next edge.
+    //
+    // Returns:
+    // - OK if successfully advanced to the next edge.
+    // - RESOURCE_EXHAUSTED_ERROR if there is no more edge to advance to.
+    // - Any other errors from the underlying implementation.
+    virtual libtextclassifier3::Status Advance() = 0;
+
+    // Gets the current edge.
+    //
+    // REQUIRES: preceding Advance() succeeded.
+    virtual const EdgeType& Get() const = 0;
+  };
+
+  virtual ~GraphInterface() = default;
+
+  virtual int GetNumNodes() const = 0;
+
+  // Returns an iterator to the (out) edges of the given node.
+  //
+  // Returns:
+  // - On success, a non-null unique pointer of EdgeIteratorIf. If there is no
+  //   edge for a valid node_id, then it should still return a valid iterator
+  //   with no edge to advance to.
+  // - INVALID_ARGUMENT_ERROR if node_id is invalid.
+  // - Any other errors from the underlying implementation.
+  virtual libtextclassifier3::StatusOr<std::unique_ptr<EdgeIteratorIf>>
+  GetEdgesIterator(int node_id) const = 0;
+
+  // Add GetInEdgesIterator if needed.
+};
+
+}  // namespace graph
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_GRAPH_GRAPH_INTERFACE_H_
diff --git a/icing/graph/simple-graph.h b/icing/graph/simple-graph.h
new file mode 100644
index 0000000..13088b3
--- /dev/null
+++ b/icing/graph/simple-graph.h
@@ -0,0 +1,107 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_GRAPH_SIMPLE_GRAPH_H_
+#define ICING_GRAPH_SIMPLE_GRAPH_H_
+
+#include <memory>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/graph/graph-interface.h"
+
+namespace icing {
+namespace lib {
+
+namespace graph {
+
+// A simple in-memory graph data structure without edge weights.
+// - Node ids are from 0 to GetNumNodes() - 1.
+// - Edges only contain the connected node ids, and are stored in adjacent
+//   lists in memory.
+class SimpleGraph : public GraphInterface<int> {
+ public:
+  // Builder class for SimpleGraph.
+  class Builder {
+   public:
+    explicit Builder(int num_nodes) : out_(num_nodes) {}
+
+    // Builds the graph. It is undefined behavior to use the builder after this
+    // call.
+    SimpleGraph Build() { return SimpleGraph(std::move(out_)); }
+
+    // Adds an edge from node u to node v.
+    //
+    // REQUIRES: 0 <= u, v < num_nodes.
+    Builder& AddEdge(int u, int v) {
+      out_[u].insert(v);
+      return *this;
+    }
+
+   private:
+    std::vector<std::unordered_set<int>> out_;
+  };
+
+  int GetNumNodes() const override { return out_edges_.size(); }
+
+  libtextclassifier3::StatusOr<std::unique_ptr<EdgeIteratorIf>>
+  GetEdgesIterator(int node_id) const override {
+    if (node_id < 0 || node_id >= GetNumNodes()) {
+      return absl_ports::InvalidArgumentError("Invalid node id.");
+    }
+    return std::make_unique<EdgeIterator>(out_edges_[node_id].cbegin(),
+                                          out_edges_[node_id].size());
+  }
+
+ private:
+  class EdgeIterator : public EdgeIteratorIf {
+   public:
+    explicit EdgeIterator(std::unordered_set<int>::const_iterator it, int len)
+        : it_(std::move(it)), len_(len), num_advanced_(0) {}
+
+    libtextclassifier3::Status Advance() override {
+      if (num_advanced_ >= len_) {
+        return absl_ports::OutOfRangeError("No more edges to advance to.");
+      }
+      if (num_advanced_ != 0) {
+        ++it_;
+      }
+      ++num_advanced_;
+      return libtextclassifier3::Status::OK;
+    }
+
+    const int& Get() const override { return *it_; }
+
+   private:
+    std::unordered_set<int>::const_iterator it_;
+    int len_;
+    int num_advanced_;
+  };
+
+  explicit SimpleGraph(std::vector<std::unordered_set<int>>&& out_edges)
+      : out_edges_(std::move(out_edges)) {}
+
+  std::vector<std::unordered_set<int>> out_edges_;
+};
+
+}  // namespace graph
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_GRAPH_SIMPLE_GRAPH_H_
diff --git a/icing/icing-search-engine.cc b/icing/icing-search-engine.cc
index ee3fced..7b41733 100644
--- a/icing/icing-search-engine.cc
+++ b/icing/icing-search-engine.cc
@@ -19,6 +19,7 @@
 #include <cstdint>
 #include <functional>
 #include <memory>
+#include <optional>
 #include <string>
 #include <string_view>
 #include <unordered_map>
@@ -192,17 +193,17 @@ libtextclassifier3::Status ValidateResultSpec(
          result_grouping.entry_groupings()) {
       const std::string& name_space = entry.namespace_();
       const std::string& schema = entry.schema();
-      auto entry_id_or = document_store->GetResultGroupingEntryId(
-          result_grouping_type, name_space, schema);
-      if (!entry_id_or.ok()) {
+      std::optional<int32_t> entry_id =
+          document_store->GetResultGroupingEntryId(result_grouping_type,
+                                                   name_space, schema);
+      if (!entry_id.has_value()) {
         continue;
       }
-      int32_t entry_id = entry_id_or.ValueOrDie();
-      if (unique_entry_ids.find(entry_id) != unique_entry_ids.end()) {
+      if (unique_entry_ids.find(*entry_id) != unique_entry_ids.end()) {
         return absl_ports::InvalidArgumentError(
             "Entry Ids must be unique across result groups.");
       }
-      unique_entry_ids.insert(entry_id);
+      unique_entry_ids.insert(*entry_id);
     }
   }
   return libtextclassifier3::Status::OK;
@@ -388,11 +389,12 @@ InitializeStatsProto::RecoveryCause TranslateMarkerProtoToRecoveryCause(
 // enforcement.
 libtextclassifier3::StatusOr<TokenizedDocument> PrepareDocumentForIndexing(
     const SchemaStore* schema_store,
-    const LanguageSegmenter* language_segmenter, DocumentProto&& document) {
+    const LanguageSegmenter* language_segmenter, int64_t current_time_ms,
+    DocumentProto&& document) {
   ICING_ASSIGN_OR_RETURN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store, language_segmenter,
-                                std::move(document)));
+                                current_time_ms, std::move(document)));
 
   // TODO(b/384947619): apply dependency enforcement.
 
@@ -508,7 +510,10 @@ IcingSearchEngine::IcingSearchEngine(
                      options_.enable_repeated_field_joins(),
                      options_.enable_embedding_backup_generation(),
                      options_.enable_schema_database(),
-                     options_.release_backup_schema_file_if_overlay_present()),
+                     options_.release_backup_schema_file_if_overlay_present(),
+                     options_.enable_strict_page_byte_size_limit(),
+                     options_.enable_smaller_decompression_buffer_size(),
+                     options_.enable_eigen_embedding_scoring()),
       filesystem_(std::move(filesystem)),
       icing_filesystem_(std::move(icing_filesystem)),
       clock_(std::move(clock)),
@@ -521,6 +526,9 @@ IcingSearchEngine::~IcingSearchEngine() {
     if (PersistToDisk(PersistType::FULL).status().code() != StatusProto::OK) {
       ICING_LOG(ERROR)
           << "Error persisting to disk in IcingSearchEngine destructor";
+    } else {
+      ICING_LOG(INFO)
+          << "Done persisting to disk in IcingSearchEngine destructor";
     }
   }
 }
@@ -566,7 +574,8 @@ libtextclassifier3::Status IcingSearchEngine::CheckInitMarkerFile(
   libtextclassifier3::Status status;
   if (file_exists &&
       filesystem_->PRead(marker_file_fd->get(), &network_init_attempts,
-                         sizeof(network_init_attempts), /*offset=*/0)) {
+                         sizeof(network_init_attempts),
+                         /*offset=*/0) == sizeof(network_init_attempts)) {
     host_init_attempts = GNetworkToHostL(network_init_attempts);
     if (host_init_attempts > kMaxUnsuccessfulInitAttempts) {
       // We're tried and failed to init too many times. We need to throw
@@ -640,6 +649,8 @@ InitializeResultProto IcingSearchEngine::InternalInitialize() {
     result_status->set_message(
         "Delete propagation is enabled but qualified id join index v3 is not "
         "enabled.");
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::OPTIONS_VALIDATION);
     return result_proto;
   }
 
@@ -665,6 +676,8 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
   ICING_RETURN_ERROR_IF_NULL(initialize_stats);
   // Make sure the base directory exists
   if (!filesystem_->CreateDirectoryRecursively(options_.base_dir().c_str())) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::BASE_DIRECTORY_CREATION);
     return absl_ports::InternalError(absl_ports::StrCat(
         "Could not create directory: ", options_.base_dir()));
   }
@@ -673,6 +686,8 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
   // max number of init attempts.
   libtextclassifier3::Status status = CheckInitMarkerFile(initialize_stats);
   if (!status.ok() && !absl_ports::IsDataLoss(status)) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::INIT_MARKER_FILE);
     return status;
   }
 
@@ -686,10 +701,24 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
   // Read version file, determine the state change and rebuild derived files if
   // needed.
   const std::string index_dir = MakeIndexDirectoryPath(options_.base_dir());
-  ICING_ASSIGN_OR_RETURN(
-      IcingSearchEngineVersionProto stored_version_proto,
-      version_util::ReadVersion(
-          *filesystem_, /*version_file_dir=*/options_.base_dir(), index_dir));
+  auto stored_version_proto_or = version_util::ReadVersion(
+      *filesystem_, /*version_file_dir=*/options_.base_dir(), index_dir);
+  if (!stored_version_proto_or.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::READ_VERSION_FILE);
+    ICING_LOG(ERROR) << "Failed to read version file. Error: "
+                     << stored_version_proto_or.status().error_code()
+                     << ", message: "
+                     << stored_version_proto_or.status().error_message();
+    return std::move(stored_version_proto_or).status();
+  }
+  IcingSearchEngineVersionProto stored_version_proto =
+      std::move(stored_version_proto_or).ValueOrDie();
+  ICING_LOG(INFO)
+      << "Successfully read version proto from existing dataset. Version: "
+      << stored_version_proto.version()
+      << ", max_version: " << stored_version_proto.max_version();
+
   version_util::VersionInfo stored_version_info =
       version_util::GetVersionInfoFromProto(stored_version_proto);
   version_util::StateChange version_state_change =
@@ -707,10 +736,15 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
   bool perform_schema_database_migration =
       version_util::SchemaDatabaseMigrationRequired(stored_version_proto) &&
       options_.enable_schema_database();
-  ICING_RETURN_IF_ERROR(SchemaStore::MigrateSchema(
+  auto migrate_status = SchemaStore::MigrateSchema(
       filesystem_.get(), MakeSchemaDirectoryPath(options_.base_dir()),
       version_state_change, version_util::kVersion,
-      perform_schema_database_migration));
+      perform_schema_database_migration);
+  if (!migrate_status.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::MIGRATE_SCHEMA);
+    return migrate_status;
+  }
 
   // Step 2: Discard derived files that need to be rebuilt
   derived_file_util::DerivedFilesRebuildInfo required_derived_files_rebuild =
@@ -719,17 +753,32 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
   if (existing_marker_proto != nullptr) {
     required_derived_files_rebuild.RebuildAll();
   }
-  ICING_RETURN_IF_ERROR(DiscardDerivedFiles(required_derived_files_rebuild));
+  auto discard_status = DiscardDerivedFiles(required_derived_files_rebuild);
+  if (!discard_status.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::DISCARD_DERIVED_FILES);
+    return discard_status;
+  }
 
   // Step 3: update version files. We need to update both the V1 and V2
   // version files.
-  ICING_RETURN_IF_ERROR(version_util::WriteV1Version(
+  auto write_version_status = version_util::WriteV1Version(
       *filesystem_, /*version_file_dir=*/options_.base_dir(),
-      version_util::GetVersionInfoFromProto(current_version_proto)));
-  ICING_RETURN_IF_ERROR(version_util::WriteV2Version(
+      version_util::GetVersionInfoFromProto(current_version_proto));
+  if (!write_version_status.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::WRITE_VERSION_FILE);
+    return write_version_status;
+  }
+  write_version_status = version_util::WriteV2Version(
       *filesystem_, /*version_file_dir=*/options_.base_dir(),
       std::make_unique<IcingSearchEngineVersionProto>(
-          std::move(current_version_proto))));
+          std::move(current_version_proto)));
+  if (!write_version_status.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::WRITE_VERSION_FILE);
+    return write_version_status;
+  }
 
   ICING_RETURN_IF_ERROR(InitializeSchemaStore(initialize_stats));
 
@@ -748,13 +797,24 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
   // TODO(b/156383798) : Resolve how to specify the locale.
   language_segmenter_factory::SegmenterOptions segmenter_options(
       ULOC_US, jni_cache_.get(), enable_icu);
-  TC3_ASSIGN_OR_RETURN(language_segmenter_, language_segmenter_factory::Create(
-                                                std::move(segmenter_options)));
+  auto language_segmenter_or =
+      language_segmenter_factory::Create(std::move(segmenter_options));
+  if (!language_segmenter_or.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::LANGUAGE_SEGMENTER_CREATION);
+    return std::move(language_segmenter_or).status();
+  }
+  language_segmenter_ = std::move(language_segmenter_or).ValueOrDie();
 
   NormalizerOptions normalizer_options(
       /*max_term_byte_size=*/options_.max_token_length(), enable_icu);
-  TC3_ASSIGN_OR_RETURN(normalizer_,
-                       normalizer_factory::Create(normalizer_options));
+  auto normalizer_or = normalizer_factory::Create(normalizer_options);
+  if (!normalizer_or.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::NORMALIZER_CREATION);
+    return std::move(normalizer_or).status();
+  }
+  normalizer_ = std::move(normalizer_or).ValueOrDie();
 
   libtextclassifier3::Status index_init_status;
   if (absl_ports::IsNotFound(schema_store_->GetSchema().status())) {
@@ -782,6 +842,8 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
              .ok() ||
         !EmbeddingIndex::Discard(*filesystem_, embedding_index_dir).ok() ||
         !filesystem_->DeleteDirectoryRecursively(blob_store_dir.c_str())) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::DISCARD_COMPONENTS);
       return absl_ports::InternalError(absl_ports::StrCat(
           "Could not delete directories: ", index_dir, ", ", integer_index_dir,
           ", ", qualified_id_join_index_dir, ", ", embedding_index_dir, ", ",
@@ -790,9 +852,15 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
 
     // Initialize (empty) blob store.
     if (options_.enable_blob_store()) {
-      ICING_RETURN_IF_ERROR(
+      auto blob_store_init_status =
           InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
-                              options_.blob_store_compression_level()));
+                              options_.blob_store_compression_level(),
+                              options_.blob_store_compression_mem_level());
+      if (!blob_store_init_status.ok()) {
+        initialize_stats->set_failure_stage(
+            InitializeStatsProto::FailureStage::BLOB_STORE_INSTANTIATION);
+        return blob_store_init_status;
+      }
     }
 
     // Initialize (empty) document store.
@@ -825,9 +893,15 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
     // We just need to re-initialize each component here.
 
     if (options_.enable_blob_store()) {
-      ICING_RETURN_IF_ERROR(
+      auto blob_store_init_status =
           InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
-                              options_.blob_store_compression_level()));
+                              options_.blob_store_compression_level(),
+                              options_.blob_store_compression_mem_level());
+      if (!blob_store_init_status.ok()) {
+        initialize_stats->set_failure_stage(
+            InitializeStatsProto::FailureStage::BLOB_STORE_INSTANTIATION);
+        return blob_store_init_status;
+      }
     }
 
     // Initialize document store. This also rebuilds all derived files in the
@@ -868,9 +942,15 @@ libtextclassifier3::Status IcingSearchEngine::InitializeMembers(
 
     // Initialize blob store.
     if (options_.enable_blob_store()) {
-      ICING_RETURN_IF_ERROR(
+      auto blob_store_init_status =
           InitializeBlobStore(options_.orphan_blob_time_to_live_ms(),
-                              options_.blob_store_compression_level()));
+                              options_.blob_store_compression_level(),
+                              options_.blob_store_compression_mem_level());
+      if (!blob_store_init_status.ok()) {
+        initialize_stats->set_failure_stage(
+            InitializeStatsProto::FailureStage::BLOB_STORE_INSTANTIATION);
+        return blob_store_init_status;
+      }
     }
 
     // Initialize document store. This also rebuilds all derived files in the
@@ -936,13 +1016,21 @@ libtextclassifier3::Status IcingSearchEngine::InitializeSchemaStore(
       MakeSchemaDirectoryPath(options_.base_dir());
   // Make sure the sub-directory exists
   if (!filesystem_->CreateDirectoryRecursively(schema_store_dir.c_str())) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::SCHEMA_STORE_DIRECTORY_CREATION);
     return absl_ports::InternalError(
         absl_ports::StrCat("Could not create directory: ", schema_store_dir));
   }
-  ICING_ASSIGN_OR_RETURN(
-      schema_store_,
+
+  auto schema_store_or =
       SchemaStore::Create(filesystem_.get(), schema_store_dir, clock_.get(),
-                          &feature_flags_, initialize_stats));
+                          &feature_flags_, initialize_stats);
+  if (!schema_store_or.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::SCHEMA_STORE_INSTANTIATION);
+    return schema_store_or.status();
+  }
+  schema_store_ = std::move(schema_store_or).ValueOrDie();
 
   return libtextclassifier3::Status::OK;
 }
@@ -956,22 +1044,33 @@ libtextclassifier3::StatusOr<bool> IcingSearchEngine::InitializeDocumentStore(
       MakeDocumentDirectoryPath(options_.base_dir());
   // Make sure the sub-directory exists
   if (!filesystem_->CreateDirectoryRecursively(document_dir.c_str())) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::DOCUMENT_STORE_DIRECTORY_CREATION);
     return absl_ports::InternalError(
         absl_ports::StrCat("Could not create directory: ", document_dir));
   }
-  ICING_ASSIGN_OR_RETURN(
-      DocumentStore::CreateResult create_result,
-      DocumentStore::Create(
-          filesystem_.get(), document_dir, clock_.get(), schema_store_.get(),
-          &feature_flags_, force_recovery_and_revalidate_documents,
-          /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
-          options_.compression_level(), initialize_stats));
+
+  auto create_result_or = DocumentStore::Create(
+      filesystem_.get(), document_dir, clock_.get(), schema_store_.get(),
+      &feature_flags_, force_recovery_and_revalidate_documents,
+      /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
+      options_.compression_level(), options_.compression_threshold_bytes(),
+      options_.compression_mem_level(), initialize_stats);
+  if (!create_result_or.ok()) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::DOCUMENT_STORE_INSTANTIATION);
+    return std::move(create_result_or).status();
+  }
+  DocumentStore::CreateResult create_result =
+      std::move(create_result_or).ValueOrDie();
+
   document_store_ = std::move(create_result.document_store);
   return create_result.derived_files_regenerated;
 }
 
 libtextclassifier3::Status IcingSearchEngine::InitializeBlobStore(
-    int32_t orphan_blob_time_to_live_ms, int32_t blob_store_compression_level) {
+    int32_t orphan_blob_time_to_live_ms, int32_t blob_store_compression_level,
+    int32_t blob_store_compression_mem_level) {
   std::string blob_dir = MakeBlobDirectoryPath(options_.base_dir());
   // Make sure the sub-directory exists
   if (!filesystem_->CreateDirectoryRecursively(blob_dir.c_str())) {
@@ -981,10 +1080,10 @@ libtextclassifier3::Status IcingSearchEngine::InitializeBlobStore(
 
   ICING_ASSIGN_OR_RETURN(
       auto blob_store_or,
-      BlobStore::Create(filesystem_.get(), blob_dir, clock_.get(),
-                        orphan_blob_time_to_live_ms,
-                        blob_store_compression_level,
-                        options_.manage_blob_files()));
+      BlobStore::Create(
+          filesystem_.get(), blob_dir, clock_.get(),
+          orphan_blob_time_to_live_ms, blob_store_compression_level,
+          blob_store_compression_mem_level, options_.manage_blob_files()));
   blob_store_ = std::make_unique<BlobStore>(std::move(blob_store_or));
   return libtextclassifier3::Status::OK;
 }
@@ -997,6 +1096,8 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
   const std::string index_dir = MakeIndexDirectoryPath(options_.base_dir());
   // Make sure the sub-directory exists
   if (!filesystem_->CreateDirectoryRecursively(index_dir.c_str())) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::TERM_INDEX_DIRECTORY);
     return absl_ports::InternalError(
         absl_ports::StrCat("Could not create directory: ", index_dir));
   }
@@ -1011,6 +1112,8 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
   if (!index_or.ok()) {
     if (!filesystem_->DeleteDirectoryRecursively(index_dir.c_str()) ||
         !filesystem_->CreateDirectoryRecursively(index_dir.c_str())) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::TERM_INDEX_DIRECTORY);
       return absl_ports::InternalError(
           absl_ports::StrCat("Could not recreate directory: ", index_dir));
     }
@@ -1018,9 +1121,14 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
     index_recovery_cause = InitializeStatsProto::IO_ERROR;
 
     // Try recreating it from scratch and re-indexing everything.
-    ICING_ASSIGN_OR_RETURN(index_,
-                           Index::Create(index_options, filesystem_.get(),
-                                         icing_filesystem_.get()));
+    index_or = Index::Create(index_options, filesystem_.get(),
+                             icing_filesystem_.get());
+    if (!index_or.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::TERM_INDEX_INSTANTIATION);
+      return std::move(index_or).status();
+    }
+    index_ = std::move(index_or).ValueOrDie();
   } else {
     // Index was created fine.
     index_ = std::move(index_or).ValueOrDie();
@@ -1038,17 +1146,27 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
                            options_.integer_index_bucket_split_threshold(),
                            options_.pre_mapping_fbv());
   if (!integer_index_or.ok()) {
-    ICING_RETURN_IF_ERROR(
-        IntegerIndex::Discard(*filesystem_, integer_index_dir));
+    auto discard_status =
+        IntegerIndex::Discard(*filesystem_, integer_index_dir);
+    if (!discard_status.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::INTEGER_INDEX_DIRECTORY);
+      return discard_status;
+    }
 
     integer_index_recovery_cause = InitializeStatsProto::IO_ERROR;
 
     // Try recreating it from scratch and re-indexing everything.
-    ICING_ASSIGN_OR_RETURN(
-        integer_index_,
+    integer_index_or =
         IntegerIndex::Create(*filesystem_, std::move(integer_index_dir),
                              options_.integer_index_bucket_split_threshold(),
-                             options_.pre_mapping_fbv()));
+                             options_.pre_mapping_fbv());
+    if (!integer_index_or.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::INTEGER_INDEX_INSTANTIATION);
+      return std::move(integer_index_or).status();
+    }
+    integer_index_ = std::move(integer_index_or).ValueOrDie();
   } else {
     // Integer index was created fine.
     integer_index_ = std::move(integer_index_or).ValueOrDie();
@@ -1067,14 +1185,25 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
     // V2 qualified id join index depends on document store derived files, so we
     // have to rebuild it from scratch if
     // document_store_derived_files_regenerated is true.
-    ICING_RETURN_IF_ERROR(QualifiedIdJoinIndex::Discard(
-        *filesystem_, qualified_id_join_index_dir));
+    auto discard_status = QualifiedIdJoinIndex::Discard(
+        *filesystem_, qualified_id_join_index_dir);
+    if (!discard_status.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::
+              QUALIFIED_ID_JOIN_INDEX_DIRECTORY);
+      return discard_status;
+    }
 
-    ICING_ASSIGN_OR_RETURN(
-        qualified_id_join_index_,
-        CreateQualifiedIdJoinIndex(*filesystem_,
-                                   std::move(qualified_id_join_index_dir),
-                                   options_, feature_flags_));
+    auto qualified_id_join_index_or = CreateQualifiedIdJoinIndex(
+        *filesystem_, qualified_id_join_index_dir, options_, feature_flags_);
+    if (!qualified_id_join_index_or.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::
+              QUALIFIED_ID_JOIN_INDEX_INSTANTIATION);
+      return std::move(qualified_id_join_index_or).status();
+    }
+    qualified_id_join_index_ =
+        std::move(qualified_id_join_index_or).ValueOrDie();
 
     qualified_id_join_index_recovery_cause =
         InitializeStatsProto::DEPENDENCIES_CHANGED;
@@ -1082,17 +1211,29 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
     auto qualified_id_join_index_or = CreateQualifiedIdJoinIndex(
         *filesystem_, qualified_id_join_index_dir, options_, feature_flags_);
     if (!qualified_id_join_index_or.ok()) {
-      ICING_RETURN_IF_ERROR(QualifiedIdJoinIndex::Discard(
-          *filesystem_, qualified_id_join_index_dir));
+      auto discard_status = QualifiedIdJoinIndex::Discard(
+          *filesystem_, qualified_id_join_index_dir);
+      if (!discard_status.ok()) {
+        initialize_stats->set_failure_stage(
+            InitializeStatsProto::FailureStage::
+                QUALIFIED_ID_JOIN_INDEX_DIRECTORY);
+        return discard_status;
+      }
 
       qualified_id_join_index_recovery_cause = InitializeStatsProto::IO_ERROR;
 
       // Try recreating it from scratch and rebuild everything.
-      ICING_ASSIGN_OR_RETURN(
-          qualified_id_join_index_,
-          CreateQualifiedIdJoinIndex(*filesystem_,
-                                     std::move(qualified_id_join_index_dir),
-                                     options_, feature_flags_));
+      qualified_id_join_index_or = CreateQualifiedIdJoinIndex(
+          *filesystem_, std::move(qualified_id_join_index_dir), options_,
+          feature_flags_);
+      if (!qualified_id_join_index_or.ok()) {
+        initialize_stats->set_failure_stage(
+            InitializeStatsProto::FailureStage::
+                QUALIFIED_ID_JOIN_INDEX_INSTANTIATION);
+        return std::move(qualified_id_join_index_or).status();
+      }
+      qualified_id_join_index_ =
+          std::move(qualified_id_join_index_or).ValueOrDie();
     } else {
       // Qualified id join index was created fine.
       qualified_id_join_index_ =
@@ -1111,15 +1252,24 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
   auto embedding_index_or = EmbeddingIndex::Create(
       filesystem_.get(), embedding_dir, clock_.get(), &feature_flags_);
   if (!embedding_index_or.ok()) {
-    ICING_RETURN_IF_ERROR(EmbeddingIndex::Discard(*filesystem_, embedding_dir));
+    auto discard_status = EmbeddingIndex::Discard(*filesystem_, embedding_dir);
+    if (!discard_status.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::EMBEDDING_INDEX_DIRECTORY);
+      return discard_status;
+    }
 
     embedding_index_recovery_cause = InitializeStatsProto::IO_ERROR;
 
     // Try recreating it from scratch and re-indexing everything.
-    ICING_ASSIGN_OR_RETURN(
-        embedding_index_,
-        EmbeddingIndex::Create(filesystem_.get(), embedding_dir, clock_.get(),
-                               &feature_flags_));
+    embedding_index_or = EmbeddingIndex::Create(
+        filesystem_.get(), embedding_dir, clock_.get(), &feature_flags_);
+    if (!embedding_index_or.ok()) {
+      initialize_stats->set_failure_stage(
+          InitializeStatsProto::FailureStage::EMBEDDING_INDEX_INSTANTIATION);
+      return std::move(embedding_index_or).status();
+    }
+    embedding_index_ = std::move(embedding_index_or).ValueOrDie();
   } else {
     // Embedding index was created fine.
     embedding_index_ = std::move(embedding_index_or).ValueOrDie();
@@ -1156,6 +1306,11 @@ libtextclassifier3::Status IcingSearchEngine::InitializeIndex(
           embedding_index_recovery_cause);
     }
   }
+  if (!restore_result.status.ok() &&
+      !absl_ports::IsDataLoss(restore_result.status)) {
+    initialize_stats->set_failure_stage(
+        InitializeStatsProto::FailureStage::RESTORE_INDEX);
+  }
   return restore_result.status;
 }
 
@@ -1282,12 +1437,13 @@ SetSchemaResultProto IcingSearchEngine::SetSchema(
     } else if (!set_schema_result.old_schema_type_ids_changed.empty() ||
                !set_schema_result.schema_types_incompatible_by_id.empty() ||
                !set_schema_result.schema_types_deleted_by_id.empty()) {
-      status = document_store_->OptimizedUpdateSchemaStore(schema_store_.get(),
-                                                           set_schema_result);
-      if (!status.ok()) {
-        TransformStatus(status, result_status);
+      auto update_status_or = document_store_->OptimizedUpdateSchemaStore(
+          schema_store_.get(), set_schema_result);
+      if (!update_status_or.ok()) {
+        TransformStatus(update_status_or.status(), result_status);
         return result_proto;
       }
+      result_proto.set_deleted_document_count(update_status_or.ValueOrDie());
     }
 
     if (lost_previous_schema || index_incompatible) {
@@ -1332,7 +1488,6 @@ SetSchemaResultProto IcingSearchEngine::SetSchema(
         }
       }
     }
-
     result_status->set_code(StatusProto::OK);
   } else {
     result_status->set_code(StatusProto::FAILED_PRECONDITION);
@@ -1459,8 +1614,11 @@ PutResultProto IcingSearchEngine::Put(DocumentProto&& document) {
     return result_proto;
   }
 
-  auto tokenized_document_or = PrepareDocumentForIndexing(
-      schema_store_.get(), language_segmenter_.get(), std::move(document));
+  int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
+
+  auto tokenized_document_or =
+      PrepareDocumentForIndexing(schema_store_.get(), language_segmenter_.get(),
+                                 current_time_ms, std::move(document));
   if (!tokenized_document_or.ok()) {
     TransformStatus(tokenized_document_or.status(), result_status);
     return result_proto;
@@ -1469,8 +1627,7 @@ PutResultProto IcingSearchEngine::Put(DocumentProto&& document) {
       std::move(tokenized_document_or).ValueOrDie());
 
   auto put_result_or = document_store_->Put(
-      tokenized_document.document(), tokenized_document.num_string_tokens(),
-      put_document_stats);
+      tokenized_document.document_wrapper(), put_document_stats);
   if (!put_result_or.ok()) {
     TransformStatus(put_result_or.status(), result_status);
     return result_proto;
@@ -1517,7 +1674,6 @@ PutResultProto IcingSearchEngine::Put(DocumentProto&& document) {
   if (!index_status.ok()) {
     // If we encountered a failure or cannot resolve an internal error while
     // indexing this document, then mark it as deleted.
-    int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
     libtextclassifier3::Status delete_status =
         document_store_->Delete(document_id, current_time_ms);
     if (!delete_status.ok()) {
@@ -2018,19 +2174,28 @@ libtextclassifier3::StatusOr<int> IcingSearchEngine::PropagateDelete(
 
 PersistToDiskResultProto IcingSearchEngine::PersistToDisk(
     PersistType::Code persist_type) {
-  ICING_VLOG(1) << "Persisting data to disk";
+  ICING_LOG(INFO) << "Persisting data to disk";
 
   PersistToDiskResultProto result_proto;
   StatusProto* result_status = result_proto.mutable_status();
 
   absl_ports::unique_lock l(&mutex_);
   if (!initialized_) {
+    ICING_LOG(WARNING) << "Attempt to persist data to disk for an "
+                          "uninitialized IcingSearchEngine.";
     result_status->set_code(StatusProto::FAILED_PRECONDITION);
     result_status->set_message("IcingSearchEngine has not been initialized!");
     return result_proto;
   }
 
   auto status = InternalPersistToDisk(persist_type);
+  if (status.ok()) {
+    ICING_LOG(INFO) << "PersistToDisk completed.";
+  } else {
+    ICING_LOG(ERROR) << "PersistToDisk failed. Error code: "
+                     << status.error_code()
+                     << ", message: " << status.error_message();
+  }
   TransformStatus(status, result_status);
   return result_proto;
 }
@@ -2042,7 +2207,7 @@ PersistToDiskResultProto IcingSearchEngine::PersistToDisk(
 // 2. Copy data needed to a tmp directory.
 // 3. Swap current directory and tmp directory.
 OptimizeResultProto IcingSearchEngine::Optimize() {
-  ICING_VLOG(1) << "Optimizing icing storage";
+  ICING_LOG(INFO) << "Optimizing icing storage";
 
   OptimizeResultProto result_proto;
   StatusProto* result_status = result_proto.mutable_status();
@@ -2324,6 +2489,7 @@ OptimizeResultProto IcingSearchEngine::Optimize() {
       Filesystem::SanitizeFileSize(after_size));
 
   TransformStatus(doc_store_optimize_result_status, result_status);
+  ICING_LOG(INFO) << "Finished optimizing icing storage";
   return result_proto;
 }
 
@@ -2340,29 +2506,35 @@ GetOptimizeInfoResultProto IcingSearchEngine::GetOptimizeInfo() {
     return result_proto;
   }
 
+  int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
+
   // Read the optimize status to get the time that we last ran.
   std::string optimize_status_filename =
       absl_ports::StrCat(options_.base_dir(), "/", kOptimizeStatusFilename);
   FileBackedProto<OptimizeStatusProto> optimize_status_file(
       *filesystem_, optimize_status_filename);
   auto optimize_status_or = optimize_status_file.Read();
-  int64_t current_time = clock_->GetSystemTimeMilliseconds();
 
-  if (optimize_status_or.ok()) {
-    // If we have trouble reading the status or this is the first time that
-    // we've ever run, don't set this field.
+  if (!optimize_status_or.ok()) {
+    // We have trouble reading the status; or we've never run optimize before.
+    result_proto.set_no_previous_optimize_info(true);
+  } else {
     int64_t time_since_last_optimize_ms;
     if (options_.calculate_time_since_last_attempted_optimize()) {
       time_since_last_optimize_ms = GetTimeSinceLastOptimizeMs(
-          current_time, *optimize_status_or.ValueOrDie());
+          current_time_ms, *optimize_status_or.ValueOrDie());
     } else {
       time_since_last_optimize_ms =
-          current_time - optimize_status_or.ValueOrDie()
-                             ->last_successful_optimize_run_time_ms();
+          current_time_ms - optimize_status_or.ValueOrDie()
+                                ->last_successful_optimize_run_time_ms();
     }
     result_proto.set_time_since_last_optimize_ms(time_since_last_optimize_ms);
   }
 
+  // Get stats from ResultStateManager.
+  result_proto.set_num_active_result_states(
+      result_state_manager_->GetNumActiveResultStates(current_time_ms));
+
   // Get stats from DocumentStore
   auto doc_store_optimize_info_or = document_store_->GetOptimizeInfo();
   if (!doc_store_optimize_info_or.ok()) {
@@ -2763,9 +2935,9 @@ SearchResultProto IcingSearchEngine::InternalSearch(
   std::unique_ptr<Timer> component_timer = clock_->GetNewTimer();
   // CacheAndRetrieveFirstPage and retrieves the document protos and snippets if
   // requested
-  auto result_retriever_or =
-      ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get());
+  auto result_retriever_or = ResultRetrieverV2::Create(
+      document_store_.get(), schema_store_.get(), language_segmenter_.get(),
+      normalizer_.get(), &feature_flags_);
   if (!result_retriever_or.ok()) {
     TransformStatus(result_retriever_or.status(), result_status);
     query_stats->set_document_retrieval_latency_ms(
@@ -2779,7 +2951,7 @@ SearchResultProto IcingSearchEngine::InternalSearch(
       page_result_info_or = result_state_manager_->CacheAndRetrieveFirstPage(
           std::move(ranker), std::move(parent_result_adjustment_info),
           std::move(child_result_adjustment_info), result_spec,
-          *document_store_, *result_retriever, current_time_ms);
+          *document_store_, *result_retriever, current_time_ms, query_stats);
   if (!page_result_info_or.ok()) {
     TransformStatus(page_result_info_or.status(), result_status);
     query_stats->set_document_retrieval_latency_ms(
@@ -2909,6 +3081,14 @@ IcingSearchEngine::QueryScoringResults IcingSearchEngine::ProcessQueryAndScore(
 }
 
 SearchResultProto IcingSearchEngine::GetNextPage(uint64_t next_page_token) {
+  GetNextPageRequestProto request_proto;
+  request_proto.set_next_page_token(next_page_token);
+
+  return GetNextPage(std::move(request_proto));
+}
+
+SearchResultProto IcingSearchEngine::GetNextPage(
+    GetNextPageRequestProto&& get_next_page_request) {
   SearchResultProto result_proto;
   StatusProto* result_status = result_proto.mutable_status();
 
@@ -2926,9 +3106,9 @@ SearchResultProto IcingSearchEngine::GetNextPage(uint64_t next_page_token) {
     return result_proto;
   }
 
-  auto result_retriever_or =
-      ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get());
+  auto result_retriever_or = ResultRetrieverV2::Create(
+      document_store_.get(), schema_store_.get(), language_segmenter_.get(),
+      normalizer_.get(), &feature_flags_);
   if (!result_retriever_or.ok()) {
     TransformStatus(result_retriever_or.status(), result_status);
     return result_proto;
@@ -2936,14 +3116,32 @@ SearchResultProto IcingSearchEngine::GetNextPage(uint64_t next_page_token) {
   std::unique_ptr<ResultRetrieverV2> result_retriever =
       std::move(result_retriever_or).ValueOrDie();
 
+  uint64_t next_page_token = get_next_page_request.next_page_token();
   int64_t current_time_ms = clock_->GetSystemTimeMilliseconds();
   libtextclassifier3::StatusOr<std::pair<uint64_t, PageResult>>
       page_result_info_or = result_state_manager_->GetNextPage(
-          next_page_token, *result_retriever, current_time_ms);
+          next_page_token,
+          get_next_page_request.max_results_to_retrieve_from_page(),
+          *result_retriever, current_time_ms);
   if (!page_result_info_or.ok()) {
     if (absl_ports::IsNotFound(page_result_info_or.status())) {
-      // NOT_FOUND means an empty result.
+      // - If calling GetNextPage with an invalid page token, return OK with an
+      //   empty result.
+      // - If the token is valid but getting NOT_FOUND error, then it is likely
+      //   that the corresponding ResultState has been removed due to cache
+      //   eviction (caused by cache budget limit exceeded or
+      //   SetSchema/Optimize). In this case, we should return an additional
+      //   (warning) field to the client indicating that the pagination is
+      //   incomplete.
       result_status->set_code(StatusProto::OK);
+
+      if (next_page_token != kInvalidNextPageToken) {
+        result_proto.set_page_token_not_found(true);
+        query_stats->set_page_token_type(
+            QueryStatsProto::PageTokenType::NOT_FOUND);
+      } else {
+        query_stats->set_page_token_type(QueryStatsProto::PageTokenType::EMPTY);
+      }
     } else {
       // Real error, pass up.
       TransformStatus(page_result_info_or.status(), result_status);
@@ -2983,6 +3181,7 @@ SearchResultProto IcingSearchEngine::GetNextPage(uint64_t next_page_token) {
   query_stats->set_num_results_with_snippets(
       page_result_info.second.num_results_with_snippets);
   query_stats->set_num_joined_results_returned_current_page(child_count);
+  query_stats->set_page_token_type(QueryStatsProto::PageTokenType::VALID);
 
   return result_proto;
 }
@@ -3116,6 +3315,8 @@ IcingSearchEngine::OptimizeDocumentStore(
 
   // result_state_manager_ depends on document_store_. So we need to reset it at
   // the same time that we reset the document_store_.
+  ICING_LOG(INFO) << "Resetting result state manager due to optimize. All "
+                     "existing result states will be invalidated.";
   result_state_manager_.reset();
   document_store_.reset();
 
@@ -3143,7 +3344,9 @@ IcingSearchEngine::OptimizeDocumentStore(
         schema_store_.get(), &feature_flags_,
         /*force_recovery_and_revalidate_documents=*/false,
         /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
-        options_.compression_level(), /*initialize_stats=*/nullptr);
+        options_.compression_level(), options_.compression_threshold_bytes(),
+        options_.compression_mem_level(),
+        /*initialize_stats=*/nullptr);
     // TODO(b/144458732): Implement a more robust version of
     // TC_ASSIGN_OR_RETURN that can support error logging.
     if (!create_result_or.ok()) {
@@ -3171,7 +3374,9 @@ IcingSearchEngine::OptimizeDocumentStore(
       schema_store_.get(), &feature_flags_,
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
-      options_.compression_level(), /*initialize_stats=*/nullptr);
+      options_.compression_level(), options_.compression_threshold_bytes(),
+      options_.compression_mem_level(),
+      /*initialize_stats=*/nullptr);
   if (!create_result_or.ok()) {
     // Unable to create DocumentStore from the new file. Mark as uninitialized
     // and return INTERNAL.
@@ -3281,7 +3486,7 @@ IcingSearchEngine::RestoreIndexIfNeeded() {
     libtextclassifier3::Status status;
     libtextclassifier3::StatusOr<TokenizedDocument> tokenized_document_or =
         PrepareDocumentForIndexing(schema_store_.get(),
-                                   language_segmenter_.get(),
+                                   language_segmenter_.get(), current_time_ms,
                                    std::move(document));
     if (!tokenized_document_or.ok()) {
       status = std::move(tokenized_document_or).status();
@@ -3600,6 +3805,29 @@ libtextclassifier3::Status IcingSearchEngine::ClearAllIndices() {
   return libtextclassifier3::Status::OK;
 }
 
+ResetResultProto IcingSearchEngine::ClearAndDestroy() {
+  absl_ports::unique_lock l(&mutex_);
+  return ClearAndDestroyInternal();
+}
+
+ResetResultProto IcingSearchEngine::ClearAndDestroyInternal() {
+  ICING_LOG(INFO) << "Removing Icing Search Engine directory: "
+                  << options_.base_dir() << ".";
+
+  ResetResultProto result_proto;
+  StatusProto* result_status = result_proto.mutable_status();
+
+  initialized_ = false;
+  ResetMembers();
+  if (!filesystem_->DeleteDirectoryRecursively(options_.base_dir().c_str())) {
+    result_status->set_code(StatusProto::INTERNAL);
+    return result_proto;
+  }
+
+  result_status->set_code(StatusProto::OK);
+  return result_proto;
+}
+
 ResetResultProto IcingSearchEngine::Reset() {
   absl_ports::unique_lock l(&mutex_);
   return ResetInternal();
@@ -3611,9 +3839,7 @@ ResetResultProto IcingSearchEngine::ResetInternal() {
   ResetResultProto result_proto;
   StatusProto* result_status = result_proto.mutable_status();
 
-  initialized_ = false;
-  ResetMembers();
-  if (!filesystem_->DeleteDirectoryRecursively(options_.base_dir().c_str())) {
+  if (ClearAndDestroyInternal().status().code() != StatusProto::OK) {
     result_status->set_code(StatusProto::INTERNAL);
     return result_proto;
   }
diff --git a/icing/icing-search-engine.h b/icing/icing-search-engine.h
index ac34063..5011592 100644
--- a/icing/icing-search-engine.h
+++ b/icing/icing-search-engine.h
@@ -445,6 +445,11 @@ class IcingSearchEngine {
   //   ABORTED if failed to get results but existing data is not affected
   //   FAILED_PRECONDITION IcingSearchEngine has not been initialized yet
   //   INTERNAL_ERROR on any other errors
+  SearchResultProto GetNextPage(GetNextPageRequestProto&& get_next_page_request)
+      ICING_LOCKS_EXCLUDED(mutex_);
+
+  // TODO: b/417644758 - Remove this method once all old callers are migrated to
+  // the new GetNextPage API. Internally, this should just be used in tests.
   SearchResultProto GetNextPage(uint64_t next_page_token)
       ICING_LOCKS_EXCLUDED(mutex_);
 
@@ -610,6 +615,13 @@ class IcingSearchEngine {
   //   INTERNAL_ERROR if internal state is no longer consistent
   ResetResultProto Reset() ICING_LOCKS_EXCLUDED(mutex_);
 
+  // Clears all data from Icing. Clients DO need to call Initialize again.
+  //
+  // Returns:
+  //   OK on success
+  //   INTERNAL_ERROR if failed to delete underlying files
+  ResetResultProto ClearAndDestroy() ICING_LOCKS_EXCLUDED(mutex_);
+
   // Disallow copy and move.
   IcingSearchEngine(const IcingSearchEngine&) = delete;
   IcingSearchEngine& operator=(const IcingSearchEngine&) = delete;
@@ -688,6 +700,10 @@ class IcingSearchEngine {
   // underlying files and initializes a fresh index.
   ResetResultProto ResetInternal() ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
+  // Resets all members and clears all data from Icing.
+  ResetResultProto ClearAndDestroyInternal()
+      ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
+
   // Checks for the existence of the init marker file. If the failed init count
   // exceeds kMaxUnsuccessfulInitAttempts, all data is deleted and the index is
   // initialized from scratch. The updated count (original failed init count + 1
@@ -758,8 +774,8 @@ class IcingSearchEngine {
   //   OK on success
   //   FAILED_PRECONDITION if initialize_stats is null
   libtextclassifier3::Status InitializeBlobStore(
-      int32_t orphan_blob_time_to_live_ms, int32_t compression_level)
-      ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
+      int32_t orphan_blob_time_to_live_ms, int32_t compression_level,
+      int32_t compression_mem_level) ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
   // Do any initialization/recovery necessary to create term index, integer
   // index, and qualified id join index instances.
diff --git a/icing/icing-search-engine_blob_test.cc b/icing/icing-search-engine_blob_test.cc
index b13d258..2c0d075 100644
--- a/icing/icing-search-engine_blob_test.cc
+++ b/icing/icing-search-engine_blob_test.cc
@@ -47,6 +47,7 @@ static constexpr int64_t kBlobInfoTTLMs = 7 * 24 * 60 * 60 * 1000;  // 1 Week
 namespace {
 
 using ::icing::lib::portable_equals_proto::EqualsProto;
+using ::testing::Eq;
 using ::testing::IsEmpty;
 using ::testing::SizeIs;
 using ::testing::UnorderedElementsAre;
@@ -234,7 +235,7 @@ TEST_P(IcingSearchEngineBlobTest, WriteAndReadBlob) {
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<unsigned char[]> buf =
         std::make_unique<unsigned char[]>(size);
-    EXPECT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
+    EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
     EXPECT_EQ(expected_data, actual_data);
@@ -372,7 +373,7 @@ TEST_P(IcingSearchEngineBlobTest, WriteAndReadBlobByDocument) {
 
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    EXPECT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
+    EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -478,7 +479,7 @@ TEST_P(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskFull) {
     ScopedFd read_fd(GetScopedFdFromBlobProto(read_blob_proto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    EXPECT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
+    EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
     EXPECT_EQ(expected_data, actual_data);
@@ -522,7 +523,7 @@ TEST_P(IcingSearchEngineBlobTest, ReadBlobWithPersistToDiskLite) {
     ScopedFd read_fd(GetScopedFdFromBlobProto(read_blob_proto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    EXPECT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
+    EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
     EXPECT_EQ(expected_data, actual_data);
@@ -585,8 +586,7 @@ TEST_P(IcingSearchEngineBlobTest, BlobOptimize) {
 
   uint64_t size = filesystem()->GetFileSize(*read_fd);
   std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-  filesystem()->Read(read_fd.get(), buf.get(), size);
-  close(read_fd.get());
+  EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
 
   std::string expected_data = std::string(data.begin(), data.end());
   std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -699,7 +699,6 @@ TEST_P(IcingSearchEngineBlobTest, ReferenceCount) {
 
   ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
   ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
-  close(write_fd.get());
 
   BlobProto commitBlobProto = icing.CommitBlob(blob_handle);
   ASSERT_THAT(commitBlobProto.status(), ProtoIsOk());
@@ -731,7 +730,7 @@ TEST_P(IcingSearchEngineBlobTest, ReferenceCount) {
     ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    ASSERT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
+    ASSERT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -748,7 +747,7 @@ TEST_P(IcingSearchEngineBlobTest, ReferenceCount) {
 
     uint64_t size = filesystem()->GetFileSize(*read_fd2);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    ASSERT_TRUE(filesystem()->Read(read_fd2.get(), buf.get(), size));
+    ASSERT_THAT(filesystem()->Read(read_fd2.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -781,7 +780,6 @@ TEST_P(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
 
   ScopedFd write_fd(GetScopedFdFromBlobProto(writeBlobProto));
   ASSERT_TRUE(filesystem()->Write(write_fd.get(), data.data(), data.size()));
-  close(write_fd.get());
 
   BlobProto commitBlobProto = icing.CommitBlob(blob_handle);
   ASSERT_THAT(commitBlobProto.status(), ProtoIsOk());
@@ -842,7 +840,7 @@ TEST_P(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
     ScopedFd read_fd(GetScopedFdFromBlobProto(readBlobProto));
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    ASSERT_TRUE(filesystem()->Read(read_fd.get(), buf.get(), size));
+    ASSERT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -859,7 +857,7 @@ TEST_P(IcingSearchEngineBlobTest, ReferenceCountNestedDocument) {
 
     uint64_t size = filesystem()->GetFileSize(*read_fd2);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    ASSERT_TRUE(filesystem()->Read(read_fd2.get(), buf.get(), size));
+    ASSERT_THAT(filesystem()->Read(read_fd2.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -931,8 +929,7 @@ TEST_P(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
 
     uint64_t size = filesystem()->GetFileSize(*read_fd);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    filesystem()->Read(read_fd.get(), buf.get(), size);
-    close(read_fd.get());
+    EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -951,8 +948,7 @@ TEST_P(IcingSearchEngineBlobTest, OptimizeMultipleReferenceDocument) {
 
     uint64_t size = filesystem()->GetFileSize(*read_fd2);
     std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-    filesystem()->Read(read_fd2.get(), buf.get(), size);
-    close(read_fd2.get());
+    EXPECT_THAT(filesystem()->Read(read_fd2.get(), buf.get(), size), Eq(size));
 
     std::string expected_data = std::string(data.begin(), data.end());
     std::string actual_data = std::string(buf.get(), buf.get() + size);
@@ -1160,8 +1156,7 @@ TEST_P(IcingSearchEngineBlobTest, OptimizeBlobHandlesNoTTL) {
 
   uint64_t size = filesystem()->GetFileSize(*read_fd);
   std::unique_ptr<uint8_t[]> buf = std::make_unique<uint8_t[]>(size);
-  filesystem()->Read(read_fd.get(), buf.get(), size);
-  close(read_fd.get());
+  EXPECT_THAT(filesystem()->Read(read_fd.get(), buf.get(), size), Eq(size));
 
   std::string expected_data = std::string(data.begin(), data.end());
   std::string actual_data = std::string(buf.get(), buf.get() + size);
diff --git a/icing/icing-search-engine_fuzz_test.cc b/icing/icing-search-engine_fuzz_test.cc
index 6f1cf69..f95cf5e 100644
--- a/icing/icing-search-engine_fuzz_test.cc
+++ b/icing/icing-search-engine_fuzz_test.cc
@@ -12,20 +12,23 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-#include <cstddef>
-#include <cstdint>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "gmock/gmock.h"
+#include "testing/fuzzing/fuzztest.h"
 #include "icing/document-builder.h"
+#include "icing/file/filesystem.h"
 #include "icing/icing-search-engine.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/initialize.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
 #include "icing/proto/search.pb.h"
+#include "icing/proto/status.pb.h"
 #include "icing/proto/term.pb.h"
 #include "icing/schema-builder.h"
+#include "icing/testing/common-matchers.h"
 #include "icing/testing/test-data.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/util/icu-data-file-helper.h"
@@ -40,32 +43,28 @@ IcingSearchEngineOptions Setup() {
   return icing_options;
 }
 
-DocumentProto MakeDocument(const uint8_t* data, size_t size) {
-  // TODO (sidchhabra): Added more optimized fuzzing techniques.
-  DocumentProto document;
-  std::string string_prop(reinterpret_cast<const char*>(data), size);
+DocumentProto MakeDocument(const std::string& data) {
   return DocumentBuilder()
       .SetKey("namespace", "uri1")
       .SetSchema("Message")
-      .AddStringProperty("body", string_prop)
+      .AddStringProperty("body", data)
+      .SetCreationTimestampMs(0L)
       .Build();
 }
 
-SearchSpecProto SetSearchSpec(const uint8_t* data, size_t size) {
+SearchSpecProto SetSearchSpec(const std::string& data) {
   SearchSpecProto search_spec;
-  search_spec.set_term_match_type(TermMatchType::PREFIX);
-  // TODO (sidchhabra): Added more optimized fuzzing techniques.
-  std::string query_string(reinterpret_cast<const char*>(data), size);
-  search_spec.set_query(query_string);
+  search_spec.set_term_match_type(TermMatchType::EXACT_ONLY);
+  search_spec.set_query(data);
   return search_spec;
 }
 
-extern "C" int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) {
+void StringFuzzTest(const std::string& data) {
   // Initialize
   IcingSearchEngineOptions icing_options = Setup();
   std::string icu_data_file_path = GetTestFilePath("icing/icu.dat");
   if (!icu_data_file_helper::SetUpIcuDataFile(icu_data_file_path).ok()) {
-    return 1;
+    return;
   }
   IcingSearchEngine icing(icing_options);
   const Filesystem filesystem_;
@@ -84,18 +83,21 @@ extern "C" int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) {
   icing.SetSchema(schema_proto);
 
   // Index
-  DocumentProto document = MakeDocument(data, size);
+  DocumentProto document = MakeDocument(data);
   icing.Put(document);
 
   // Query
-  SearchSpecProto search_spec = SetSearchSpec(data, size);
+  SearchSpecProto search_spec = SetSearchSpec(data);
   ScoringSpecProto scoring_spec;
   scoring_spec.set_rank_by(ScoringSpecProto::RankingStrategy::DOCUMENT_SCORE);
-  ResultSpecProto result_spec;
-  libtextclassifier3::StatusOr<SearchResultProto> result =
-      icing.Search(search_spec, scoring_spec, result_spec);
-  return 0;
+  SearchResultProto result = icing.Search(search_spec, scoring_spec,
+                                          ResultSpecProto::default_instance());
+  EXPECT_THAT(result.results(0).document().uri(), document.uri());
 }
+// TODO(b/416553583): Add more advanced fuzz tests including emojis and
+// decomposed characters.
+FUZZ_TEST(TestSuite, StringFuzzTest)
+    .WithDomains(/* data= */ fuzztest::InRegexp("[a-z]+"));
 
 }  // namespace
 }  // namespace lib
diff --git a/icing/icing-search-engine_initialization_test.cc b/icing/icing-search-engine_initialization_test.cc
index 5fc862b..d51254c 100644
--- a/icing/icing-search-engine_initialization_test.cc
+++ b/icing/icing-search-engine_initialization_test.cc
@@ -57,6 +57,7 @@
 #include "icing/legacy/index/icing-mock-filesystem.h"
 #include "icing/portable/endian.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/debug.pb.h"
 #include "icing/proto/document.pb.h"
@@ -96,6 +97,7 @@
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/tokenized-document.h"
 #include "unicode/uloc.h"
@@ -543,6 +545,99 @@ TEST_F(IcingSearchEngineInitializationTest,
   }
 }
 
+TEST_F(IcingSearchEngineInitializationTest,
+       OutOfRangeCompressionMemLevelReturnsInvalidArgument) {
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+
+  // Mem level must be between 1 and 9 inclusive.
+  options.set_compression_mem_level(-1);
+  {
+    IcingSearchEngine icing(options, GetTestJniCache());
+    EXPECT_THAT(icing.Initialize().status(),
+                ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  }
+
+  options.set_compression_mem_level(10);
+  {
+    IcingSearchEngine icing(options, GetTestJniCache());
+    EXPECT_THAT(icing.Initialize().status(),
+                ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  }
+
+  options.set_compression_mem_level(0);
+  {
+    IcingSearchEngine icing(options, GetTestJniCache());
+    EXPECT_THAT(icing.Initialize().status(),
+                ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  }
+}
+
+TEST_F(IcingSearchEngineInitializationTest,
+       OutOfRangeBlobStoreCompressionMemLevelReturnsInvalidArgument) {
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+
+  // Mem level must be between 1 and 9 inclusive.
+  options.set_blob_store_compression_mem_level(-1);
+  {
+    IcingSearchEngine icing(options, GetTestJniCache());
+    EXPECT_THAT(icing.Initialize().status(),
+                ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  }
+
+  options.set_blob_store_compression_mem_level(10);
+  {
+    IcingSearchEngine icing(options, GetTestJniCache());
+    EXPECT_THAT(icing.Initialize().status(),
+                ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  }
+
+  options.set_blob_store_compression_mem_level(0);
+  {
+    IcingSearchEngine icing(options, GetTestJniCache());
+    EXPECT_THAT(icing.Initialize().status(),
+                ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
+  }
+}
+
+TEST_F(IcingSearchEngineInitializationTest,
+       ReinitializingWithDifferentCompressionMemLevelOk) {
+  DocumentProto document =
+      DocumentBuilder()
+          .SetKey("icing", "fake_type/0")
+          .SetSchema("Message")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .AddStringProperty("body", "message body")
+          .AddInt64Property("indexableInteger", 123)
+          .Build();
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  {
+    // Initialize and put document
+    IcingSearchEngine icing(options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+    ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document).status(), ProtoIsOk());
+    ASSERT_THAT(icing.PersistToDisk(PersistType::FULL).status(), ProtoIsOk());
+  }
+
+  // Reinitialize with different compression mem level and check that the
+  // document is still searchable.
+  options.set_compression_mem_level(1);
+  IcingSearchEngine icing(options, GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_query("message");
+  search_spec.set_term_match_type(TermMatchType::EXACT_ONLY);
+  SearchResultProto expected_search_result_proto;
+  expected_search_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document;
+  EXPECT_THAT(
+      icing.Search(search_spec, GetDefaultScoringSpec(),
+                   ResultSpecProto::default_instance()),
+      EqualsSearchResultIgnoreStatsAndScores(expected_search_result_proto));
+}
+
 TEST_F(IcingSearchEngineInitializationTest, FailToCreateDocStore) {
   auto mock_filesystem = std::make_unique<MockFilesystem>();
   // This fails DocumentStore::Create()
@@ -1294,14 +1389,18 @@ TEST_F(IcingSearchEngineInitializationTest, RecoverFromInconsistentOptimize) {
     std::string doc_store_dir = GetDocumentDir();
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(filesystem(), doc_store_dir, &fake_clock,
-                              schema_store.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            filesystem(), doc_store_dir, &fake_clock, schema_store.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
@@ -1473,23 +1572,29 @@ TEST_F(IcingSearchEngineInitializationTest,
             filesystem(), GetBlobDir(), &fake_clock,
             /*orphan_blob_time_to_live_ms=*/0,
             PortableFileBackedProtoLog<BlobInfoProto>::kDefaultCompressionLevel,
+            protobuf_ports::kDefaultMemLevel,
             /*manage_blob_files=*/true));
 
     // Puts message2 into DocumentStore but doesn't index it.
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(filesystem(), GetDocumentDir(), &fake_clock,
-                              schema_store.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            filesystem(), GetDocumentDir(), &fake_clock, schema_store.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
-    ICING_EXPECT_OK(document_store->Put(message2));
+    ICING_EXPECT_OK(
+        document_store->Put(document_util::CreateDocumentWrapper(message2)));
   }
 
   // Mock filesystem to observe and check the behavior of all indices.
@@ -4378,7 +4483,8 @@ TEST_F(IcingSearchEngineInitializationTest,
         QualifiedIdJoinIndexImplV3::Create(
             filesystem, GetQualifiedIdJoinIndexDir(), *feature_flags_));
     EXPECT_THAT(qualified_id_join_index, Pointee(IsEmpty()));
-    EXPECT_THAT(qualified_id_join_index->Get(/*parent_document_id=*/0),
+    EXPECT_THAT(qualified_id_join_index->GetDocumentJoinIdPairArrayView(
+                    /*parent_document_id=*/0),
                 IsOkAndHolds(IsEmpty()));
   }
 }
@@ -5443,14 +5549,18 @@ TEST_F(IcingSearchEngineInitializationTest,
     std::string doc_store_dir = GetDocumentDir();
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(filesystem(), doc_store_dir, fake_clock.get(),
-                              schema_store.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            filesystem(), doc_store_dir, fake_clock.get(), schema_store.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
@@ -6092,23 +6202,29 @@ TEST_P(IcingSearchEngineInitializationVersionChangeTest,
             filesystem(), GetBlobDir(), &fake_clock,
             /*orphan_blob_time_to_live_ms=*/0,
             PortableFileBackedProtoLog<BlobInfoProto>::kDefaultCompressionLevel,
+            protobuf_ports::kDefaultMemLevel,
             /*manage_blob_files=*/true));
 
     // Put message into DocumentStore
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(filesystem(), GetDocumentDir(), &fake_clock,
-                              schema_store.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            filesystem(), GetDocumentDir(), &fake_clock, schema_store.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                               document_store->Put(message));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result,
+        document_store->Put(document_util::CreateDocumentWrapper(message)));
     DocumentId doc_id = put_result.new_document_id;
 
     // Index doc_id with incorrect data
@@ -6174,8 +6290,10 @@ TEST_P(IcingSearchEngineInitializationVersionChangeTest,
             .Build();
     ICING_ASSERT_OK_AND_ASSIGN(
         TokenizedDocument tokenized_document,
-        TokenizedDocument::Create(schema_store.get(), lang_segmenter_.get(),
-                                  std::move(incorrect_message)));
+        TokenizedDocument::Create(
+            schema_store.get(), lang_segmenter_.get(),
+            /*current_time_ms=*/fake_clock.GetSystemTimeMilliseconds(),
+            std::move(incorrect_message)));
     ICING_ASSERT_OK(index_processor.IndexDocument(tokenized_document, doc_id,
                                                   put_result.old_document_id));
 
@@ -7005,9 +7123,9 @@ TEST_P(IcingSearchEngineInitializationSchemaDatabaseMigrationTest,
                            .SetCardinality(CARDINALITY_OPTIONAL))
           .Build();
   SchemaTypeConfigProto db1_email_type_with_db =
-      SchemaTypeConfigBuilder(db1_email_type).SetDatabase("db1").Build();
+      SchemaTypeConfigBuilder(db1_email_type).SetDatabase("db1/").Build();
   SchemaTypeConfigProto db2_email_type_with_db =
-      SchemaTypeConfigBuilder(db2_email_type).SetDatabase("db2").Build();
+      SchemaTypeConfigBuilder(db2_email_type).SetDatabase("db2/").Build();
 
   SchemaProto previous_version_db1_schema;
   SchemaProto previous_version_db2_schema;
@@ -7075,18 +7193,12 @@ TEST_P(IcingSearchEngineInitializationSchemaDatabaseMigrationTest,
     EXPECT_THAT(icing.Initialize().status(), ProtoIsOk());
     // 1. Set schema.
     if (options.enable_schema_database()) {
-      // Can only set schema for a single database at a time.
-      ASSERT_THAT(icing
-                      .SetSchema(CreateSetSchemaRequestProto(
-                          previous_version_db1_schema,
-                          previous_version_db1_schema.types(0).database(),
-                          /*ignore_errors_and_delete_documents=*/false))
-                      .status(),
-                  ProtoIsOk());
+      // Use the SetSchemaRequestProto with empty database field to populate
+      // both databases at once.
       ASSERT_THAT(icing
                       .SetSchema(CreateSetSchemaRequestProto(
-                          previous_version_db2_schema,
-                          previous_version_db2_schema.types(0).database(),
+                          previous_version_schema,
+                          /*database=*/"",
                           /*ignore_errors_and_delete_documents=*/false))
                       .status(),
                   ProtoIsOk());
@@ -7166,9 +7278,9 @@ TEST_P(IcingSearchEngineInitializationSchemaDatabaseMigrationTest,
   // Verify GetSchema
   if (enable_schema_database) {
     SchemaTypeConfigProto db1_email_type_with_db =
-        SchemaTypeConfigBuilder(db1_email_type).SetDatabase("db1").Build();
+        SchemaTypeConfigBuilder(db1_email_type).SetDatabase("db1/").Build();
     SchemaTypeConfigProto db2_email_type_with_db =
-        SchemaTypeConfigBuilder(db2_email_type).SetDatabase("db2").Build();
+        SchemaTypeConfigBuilder(db2_email_type).SetDatabase("db2/").Build();
     SchemaProto full_schema_with_database = SchemaBuilder()
                                                 .AddType(db1_email_type_with_db)
                                                 .AddType(db2_email_type_with_db)
@@ -7190,14 +7302,14 @@ TEST_P(IcingSearchEngineInitializationSchemaDatabaseMigrationTest,
     expected_get_schema_result_proto_db1.mutable_status()->set_code(
         StatusProto::OK);
     *expected_get_schema_result_proto_db1.mutable_schema() = db1_schema;
-    EXPECT_THAT(icing.GetSchema("db1"),
+    EXPECT_THAT(icing.GetSchema("db1/"),
                 EqualsProto(expected_get_schema_result_proto_db1));
 
     GetSchemaResultProto expected_get_schema_result_proto_db2;
     expected_get_schema_result_proto_db2.mutable_status()->set_code(
         StatusProto::OK);
     *expected_get_schema_result_proto_db2.mutable_schema() = db2_schema;
-    EXPECT_THAT(icing.GetSchema("db2"),
+    EXPECT_THAT(icing.GetSchema("db2/"),
                 EqualsProto(expected_get_schema_result_proto_db2));
   } else {
     GetSchemaResultProto expected_get_schema_result_proto;
diff --git a/icing/icing-search-engine_optimize_test.cc b/icing/icing-search-engine_optimize_test.cc
index cd36074..76cf181 100644
--- a/icing/icing-search-engine_optimize_test.cc
+++ b/icing/icing-search-engine_optimize_test.cc
@@ -75,6 +75,7 @@ using ::testing::Ge;
 using ::testing::Gt;
 using ::testing::HasSubstr;
 using ::testing::Lt;
+using ::testing::Ne;
 using ::testing::Return;
 using ::testing::SizeIs;
 
@@ -230,14 +231,15 @@ TEST_F(IcingSearchEngineOptimizeTest,
       document2;
   SearchResultProto search_result_proto =
       icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
-  EXPECT_THAT(search_result_proto.next_page_token(), Gt(kInvalidNextPageToken));
   uint64_t next_page_token = search_result_proto.next_page_token();
+
   // Since the token is a random number, we don't need to verify
   expected_search_result_proto.set_next_page_token(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
-  // Now document1 is still to be fetched.
 
+  // Now there are more pages to be fetched (document1). Call Optimize.
   OptimizeResultProto optimize_result_proto;
   optimize_result_proto.mutable_status()->set_code(StatusProto::OK);
   optimize_result_proto.mutable_status()->set_message("");
@@ -246,9 +248,10 @@ TEST_F(IcingSearchEngineOptimizeTest,
   ASSERT_THAT(actual_result, EqualsProto(optimize_result_proto));
 
   // Tries to fetch the second page, no results since all tokens have been
-  // invalidated during Optimize()
+  // invalidated during Optimize().
   expected_search_result_proto.clear_results();
   expected_search_result_proto.clear_next_page_token();
+  expected_search_result_proto.set_page_token_not_found(true);
   search_result_proto = icing.GetNextPage(next_page_token);
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
@@ -361,10 +364,17 @@ TEST_F(IcingSearchEngineOptimizeTest, GetOptimizeInfoHasCorrectStats) {
           .AddStringProperty("body", "message body one")
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
           .Build();
-  DocumentProto document2 = DocumentBuilder()
-                                .SetKey("namespace", "uri2")
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("Message")
+          .AddStringProperty("body", "message body two")
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  DocumentProto document3 = DocumentBuilder()
+                                .SetKey("namespace", "uri3")
                                 .SetSchema("Message")
-                                .AddStringProperty("body", "message body two")
+                                .AddStringProperty("body", "message body three")
                                 .SetCreationTimestampMs(100)
                                 .SetTtlMs(500)
                                 .Build();
@@ -385,9 +395,13 @@ TEST_F(IcingSearchEngineOptimizeTest, GetOptimizeInfoHasCorrectStats) {
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
+    // Set schema and add 2 documents.
     ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
     ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
 
     // Only have active documents, nothing is optimizable yet.
     optimize_info = icing.GetOptimizeInfo();
@@ -395,32 +409,64 @@ TEST_F(IcingSearchEngineOptimizeTest, GetOptimizeInfoHasCorrectStats) {
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
-    // Deletes document1
+    // Send a search request to create a result state.
+    SearchSpecProto search_spec;
+    search_spec.set_query("body:message");
+    search_spec.set_term_match_type(TermMatchType::EXACT_ONLY);
+    ResultSpecProto result_spec;
+    result_spec.set_num_per_page(1);
+    SearchResultProto search_result =
+        icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
+    ASSERT_THAT(search_result.status(), ProtoIsOk());
+    ASSERT_THAT(search_result.results_size(), Eq(1));
+    ASSERT_THAT(search_result.next_page_token(), Ne(kInvalidNextPageToken));
+
+    optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
+    EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Eq(0));
+    EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(1));
+
+    // Deletes document1 and document2.
     ASSERT_THAT(icing.Delete("namespace", "uri1").status(), ProtoIsOk());
+    ASSERT_THAT(icing.Delete("namespace", "uri2").status(), ProtoIsOk());
 
     optimize_info = icing.GetOptimizeInfo();
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
-    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(1));
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(2));
     EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Gt(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
     int64_t first_estimated_optimizable_bytes =
         optimize_info.estimated_optimizable_bytes();
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(1));
 
-    // Add a second document, but it'll be expired since the time (1000) is
+    // Add third document, but it'll be expired since the time (1000) is
     // greater than the document's creation timestamp (100) + the document's ttl
     // (500)
-    ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document3).status(), ProtoIsOk());
 
     optimize_info = icing.GetOptimizeInfo();
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
-    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(2));
+    EXPECT_THAT(optimize_info.optimizable_docs(), Eq(3));
     EXPECT_THAT(optimize_info.estimated_optimizable_bytes(),
                 Gt(first_estimated_optimizable_bytes));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(1));
 
     // Optimize
     ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+
+    // Result state manager is reset after optimize.
+    optimize_info = icing.GetOptimizeInfo();
+    EXPECT_THAT(optimize_info.status(), ProtoIsOk());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
   }
 
   {
@@ -440,6 +486,8 @@ TEST_F(IcingSearchEngineOptimizeTest, GetOptimizeInfoHasCorrectStats) {
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(4000));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
   }
 }
 
@@ -487,6 +535,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Call some APIs
     ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
@@ -501,6 +551,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(2));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -536,6 +588,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(500));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize again -- this should fail because of the mock filesystem.
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -567,6 +621,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(1300));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize again -- this should fail because of the mock filesystem, but
     // the time since last optimize should be populated.
@@ -598,6 +654,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(2700));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -655,6 +713,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.estimated_optimizable_bytes(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Call some APIs
     ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
@@ -669,6 +729,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(2));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(0));
+    EXPECT_TRUE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -704,6 +766,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(500));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize again -- this should fail because of the mock filesystem.
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -740,6 +804,8 @@ TEST_F(IcingSearchEngineOptimizeTest,
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.optimizable_docs(), Eq(0));
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(1300));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
+    EXPECT_THAT(optimize_info.num_active_result_states(), Eq(0));
 
     // Optimize again -- this should fail because of the mock filesystem.
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -764,6 +830,7 @@ TEST_F(IcingSearchEngineOptimizeTest,
     GetOptimizeInfoResultProto optimize_info = icing.GetOptimizeInfo();
     EXPECT_THAT(optimize_info.status(), ProtoIsOk());
     EXPECT_THAT(optimize_info.time_since_last_optimize_ms(), Eq(4000));
+    EXPECT_FALSE(optimize_info.no_previous_optimize_info());
 
     // Optimize
     OptimizeResultProto optimize_result = icing.Optimize();
@@ -2170,6 +2237,7 @@ TEST_F(IcingSearchEngineOptimizeTest,
           .Build();
   IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
   icing_options.set_compression_level(3);
+  icing_options.set_compression_threshold_bytes(0);
   int64_t document_log_size_compression_3;
   int64_t document_log_size_after_opti_no_compression;
   int64_t document_log_size_after_opti_compression_3;
diff --git a/icing/icing-search-engine_put_test.cc b/icing/icing-search-engine_put_test.cc
index 37df1a1..82187b3 100644
--- a/icing/icing-search-engine_put_test.cc
+++ b/icing/icing-search-engine_put_test.cc
@@ -45,6 +45,7 @@
 #include "icing/proto/term.pb.h"
 #include "icing/proto/usage.pb.h"
 #include "icing/schema-builder.h"
+#include "icing/store/document-log-creator.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/jni-test-helpers.h"
@@ -602,6 +603,114 @@ TEST_F(IcingSearchEnginePutTest, PutDocumentWithInvalidBlobHandle) {
               ProtoStatusIs(StatusProto::INVALID_ARGUMENT));
 }
 
+TEST_F(IcingSearchEnginePutTest, DocumentCompressionThreshold) {
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("Message").AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("body")
+                  .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                  .SetCardinality(CARDINALITY_REQUIRED)))
+          .Build();
+
+  // Create document1 with size of 1024 bytes.
+  int64_t document1_size = 1024;
+  DocumentProto document1 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("Message")
+          .AddStringProperty("body", std::string(979, 'a'))
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  ASSERT_THAT(document1.ByteSizeLong(), Eq(document1_size));
+
+  // Create document2 with size of 900 bytes.
+  int64_t document2_size = 900;
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("Message")
+          .AddStringProperty("body", std::string(855, 'a'))
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  ASSERT_THAT(document2.ByteSizeLong(), Eq(document2_size));
+
+  // Create icing instance with compression threshold of 1000 bytes.
+  IcingSearchEngineOptions icing_options = GetDefaultIcingOptions();
+  icing_options.set_compression_level(3);
+
+  int64_t document_log_size_full_compression;
+  int64_t document_log_size_part_compression;
+  int64_t document_log_size_no_compression;
+  const std::string document_log_path =
+      icing_options.base_dir() + "/document_dir/" +
+      DocumentLogCreator::GetDocumentLogFilename();
+
+  // Set the compression threshold to 1000 bytes to only compress document1.
+  {
+    icing_options.set_compression_threshold_bytes(1000);
+    IcingSearchEngine icing(icing_options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+    ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+    ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+    ASSERT_THAT(icing.PersistToDisk(PersistType::FULL).status(), ProtoIsOk());
+
+    document_log_size_part_compression =
+        filesystem()->GetFileSize(document_log_path.c_str());
+
+    // Calling Optimize() will not change the size of the document log since
+    // the compression setting is the same.
+    ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+    ASSERT_EQ(filesystem()->GetFileSize(document_log_path.c_str()),
+              document_log_size_part_compression);
+  }
+
+  // Set the compression threshold to 900 bytes to compress both documents.
+  {
+    icing_options.set_compression_threshold_bytes(900);
+    IcingSearchEngine icing(icing_options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Call Optimize() to refresh the document log with the new compression
+    // threshold.
+    ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+    document_log_size_full_compression =
+        filesystem()->GetFileSize(document_log_path.c_str());
+
+    // Calling Optimize() again will not change the size of the document log
+    // since the compression setting is the same.
+    ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+    ASSERT_EQ(filesystem()->GetFileSize(document_log_path.c_str()),
+              document_log_size_full_compression);
+  }
+
+  // Set the compression threshold to 10000 bytes will turn off compression.
+  {
+    icing_options.set_compression_threshold_bytes(10000);
+    IcingSearchEngine icing(icing_options, GetTestJniCache());
+    ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+    // Call Optimize() to refresh the document log with the new compression
+    // threshold.
+    ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+    document_log_size_no_compression =
+        filesystem()->GetFileSize(document_log_path.c_str());
+
+    // Calling Optimize() again will not change the size of the document log
+    // since the compression setting is the same.
+    ASSERT_THAT(icing.Optimize().status(), ProtoIsOk());
+    ASSERT_EQ(filesystem()->GetFileSize(document_log_path.c_str()),
+              document_log_size_no_compression);
+  }
+
+  // Check that no_compression > part_compression > full_compression
+  ASSERT_GT(document_log_size_part_compression,
+            document_log_size_full_compression);
+  ASSERT_GT(document_log_size_no_compression,
+            document_log_size_part_compression);
+}
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/icing-search-engine_schema_test.cc b/icing/icing-search-engine_schema_test.cc
index 269daaa..d9767b1 100644
--- a/icing/icing-search-engine_schema_test.cc
+++ b/icing/icing-search-engine_schema_test.cc
@@ -12,6 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+#include <algorithm>
 #include <cstdint>
 #include <limits>
 #include <memory>
@@ -866,8 +867,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
   // - 'b': int64 type, indexed.
   SchemaTypeConfigProto db1_type =
       SchemaTypeConfigBuilder()
-          .SetType("db1_type")
-          .SetDatabase("db1")
+          .SetType("db1/type")
+          .SetDatabase("db1/")
           .AddProperty(PropertyConfigBuilder()
                            .SetName("a")
                            .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
@@ -880,18 +881,18 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
   SetSchemaResultProto set_schema_result =
       icing.SetSchema(CreateSetSchemaRequestProto(
-          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
+          db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db1_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   DocumentProto db1_document =
       DocumentBuilder()
           .SetKey("namespace", "uri1")
-          .SetSchema("db1_type")
+          .SetSchema("db1/type")
           .AddStringProperty("a", "message body")
           .AddInt64Property("b", 123)
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
@@ -930,8 +931,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
   // - 'c': int64 type, indexed.
   SchemaTypeConfigProto db2_type =
       SchemaTypeConfigBuilder()
-          .SetType("db2_type")
-          .SetDatabase("db2")
+          .SetType("db2/type")
+          .SetDatabase("db2/")
           .AddProperty(
               PropertyConfigBuilder()
                   .SetName("a")
@@ -944,18 +945,18 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
           .Build();
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
   set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
-      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/false));
+      db2_schema, "db2/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db2_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db2/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   DocumentProto db2_document =
       DocumentBuilder()
           .SetKey("namespace", "uri2")
-          .SetSchema("db2_type")
+          .SetSchema("db2/type")
           .AddStringProperty("a", "message body")
           .AddInt64Property("c", 123)
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
@@ -999,7 +1000,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
   expected_get_schema_result_proto_db1_full.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db1_full.mutable_schema() = db1_schema;
-  EXPECT_THAT(icing.GetSchema("db1"),
+  EXPECT_THAT(icing.GetSchema("db1/"),
               EqualsProto(expected_get_schema_result_proto_db1_full));
 
   // Get db2 schema
@@ -1007,7 +1008,182 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaMultipleDatabases) {
   expected_get_schema_result_proto_db2_full.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db2_full.mutable_schema() = db2_schema;
-  EXPECT_THAT(icing.GetSchema("db2"),
+  EXPECT_THAT(icing.GetSchema("db2/"),
+              EqualsProto(expected_get_schema_result_proto_db2_full));
+}
+
+TEST_F(IcingSearchEngineSchemaTest,
+       SetSchemaWithEmptyDatabaseResetsFullSchema) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+  // Create and set schema in db1 with 2 properties:
+  // - 'a': string type, indexed.
+  // - 'b': int64 type, indexed.
+  SchemaTypeConfigProto db1_type =
+      SchemaTypeConfigBuilder()
+          .SetType("db1/type")
+          .SetDatabase("db1/")
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("a")
+                           .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("b")
+                           .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .Build();
+  SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
+  SetSchemaResultProto set_schema_result =
+      icing.SetSchema(CreateSetSchemaRequestProto(
+          db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/false));
+  // Ignore latency numbers. They're covered elsewhere.
+  set_schema_result.clear_latency_ms();
+  SetSchemaResultProto expected_set_schema_result;
+  expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type");
+  EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
+
+  DocumentProto db1_document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri1")
+          .SetSchema("db1/type")
+          .AddStringProperty("a", "message body")
+          .AddInt64Property("b", 123)
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  ASSERT_THAT(icing.Put(db1_document).status(), ProtoIsOk());
+
+  SearchResultProto expected_search_result_proto_db1;
+  expected_search_result_proto_db1.mutable_status()->set_code(StatusProto::OK);
+  *expected_search_result_proto_db1.mutable_results()
+       ->Add()
+       ->mutable_document() = db1_document;
+
+  // Verify term search
+  SearchSpecProto search_spec1;
+  search_spec1.set_query("message");
+  search_spec1.set_term_match_type(TermMatchType::EXACT_ONLY);
+
+  SearchResultProto actual_results =
+      icing.Search(search_spec1, GetDefaultScoringSpec(),
+                   ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results, EqualsSearchResultIgnoreStatsAndScores(
+                                  expected_search_result_proto_db1));
+
+  // Verify numeric (integer) search
+  SearchSpecProto search_spec2;
+  search_spec2.set_query("b == 123");
+  search_spec2.add_enabled_features(std::string(kNumericSearchFeature));
+
+  actual_results = icing.Search(search_spec2, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results, EqualsSearchResultIgnoreStatsAndScores(
+                                  expected_search_result_proto_db1));
+
+  // Reset the full schema. Add a type each for db1 and db2.
+  SchemaTypeConfigProto db1_type_2 =
+      SchemaTypeConfigBuilder()
+          .SetType("db1/type_2")
+          .SetDatabase("db1/")
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("d")
+                           .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .Build();
+  SchemaTypeConfigProto db2_type =
+      SchemaTypeConfigBuilder()
+          .SetType("db2/type")
+          .SetDatabase("db2/")
+          .AddProperty(
+              PropertyConfigBuilder()
+                  .SetName("a")
+                  .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                  .SetCardinality(CARDINALITY_REQUIRED))
+          .AddProperty(PropertyConfigBuilder()
+                           .SetName("c")
+                           .SetDataTypeInt64(NUMERIC_MATCH_RANGE)
+                           .SetCardinality(CARDINALITY_REQUIRED))
+          .Build();
+  SchemaProto full_schema = SchemaBuilder()
+                                .AddType(db1_type)
+                                .AddType(db1_type_2)
+                                .AddType(db2_type)
+                                .Build();
+
+  // Set the full schema using an empty database.
+  SetSchemaRequestProto set_schema_request;
+  *set_schema_request.mutable_schema() = full_schema;
+  set_schema_request.set_ignore_errors_and_delete_documents(false);
+  set_schema_request.clear_database();
+  set_schema_result = icing.SetSchema(std::move(set_schema_request));
+  std::sort(set_schema_result.mutable_new_schema_types()->begin(),
+            set_schema_result.mutable_new_schema_types()->end());
+  // Ignore latency numbers. They're covered elsewhere.
+  set_schema_result.clear_latency_ms();
+  expected_set_schema_result = SetSchemaResultProto();
+  expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type_2");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db2/type");
+  EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
+
+  DocumentProto db2_document =
+      DocumentBuilder()
+          .SetKey("namespace", "uri2")
+          .SetSchema("db2/type")
+          .AddStringProperty("a", "message body")
+          .AddInt64Property("c", 123)
+          .SetCreationTimestampMs(kDefaultCreationTimestampMs)
+          .Build();
+  EXPECT_THAT(icing.Put(db2_document).status(), ProtoIsOk());
+
+  SearchResultProto expected_search_result_proto_both_docs;
+  expected_search_result_proto_both_docs.mutable_status()->set_code(
+      StatusProto::OK);
+  *expected_search_result_proto_both_docs.mutable_results()
+       ->Add()
+       ->mutable_document() = db2_document;
+  *expected_search_result_proto_both_docs.mutable_results()
+       ->Add()
+       ->mutable_document() = db1_document;
+
+  // Verify term search: will get both documents for query "a:message".
+  actual_results = icing.Search(search_spec1, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results, EqualsSearchResultIgnoreStatsAndScores(
+                                  expected_search_result_proto_both_docs));
+
+  // Verify numeric (integer) search: will only get first document for query
+  // "b == 123".
+  actual_results = icing.Search(search_spec2, GetDefaultScoringSpec(),
+                                ResultSpecProto::default_instance());
+  EXPECT_THAT(actual_results, EqualsSearchResultIgnoreStatsAndScores(
+                                  expected_search_result_proto_db1));
+
+  // Get full schema
+  GetSchemaResultProto expected_get_schema_result_proto_full;
+  expected_get_schema_result_proto_full.mutable_status()->set_code(
+      StatusProto::OK);
+  *expected_get_schema_result_proto_full.mutable_schema() = full_schema;
+  EXPECT_THAT(icing.GetSchema(),
+              EqualsProto(expected_get_schema_result_proto_full));
+
+  // Get db1 schema
+  GetSchemaResultProto expected_get_schema_result_proto_db1_full;
+  expected_get_schema_result_proto_db1_full.mutable_status()->set_code(
+      StatusProto::OK);
+  *expected_get_schema_result_proto_db1_full.mutable_schema() =
+      SchemaBuilder().AddType(db1_type).AddType(db1_type_2).Build();
+  EXPECT_THAT(icing.GetSchema("db1/"),
+              EqualsProto(expected_get_schema_result_proto_db1_full));
+
+  // Get db2 schema
+  GetSchemaResultProto expected_get_schema_result_proto_db2_full;
+  expected_get_schema_result_proto_db2_full.mutable_status()->set_code(
+      StatusProto::OK);
+  *expected_get_schema_result_proto_db2_full.mutable_schema() =
+      SchemaBuilder().AddType(db2_type).Build();
+  EXPECT_THAT(icing.GetSchema("db2/"),
               EqualsProto(expected_get_schema_result_proto_db2_full));
 }
 
@@ -1020,8 +1196,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
   // - 'c': int64 type, indexed.
   SchemaTypeConfigProto db1_type =
       SchemaTypeConfigBuilder()
-          .SetType("db1_type")
-          .SetDatabase("db1")
+          .SetType("db1/type")
+          .SetDatabase("db1/")
           .AddProperty(PropertyConfigBuilder()
                            .SetName("b")
                            .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
@@ -1034,12 +1210,12 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
   SetSchemaResultProto set_schema_result =
       icing.SetSchema(CreateSetSchemaRequestProto(
-          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
+          db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db1_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Add a schema for db2:
@@ -1047,8 +1223,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
   // - 'd': int64 type, indexed.
   SchemaTypeConfigProto db2_type =
       SchemaTypeConfigBuilder()
-          .SetType("db2_type")
-          .SetDatabase("db2")
+          .SetType("db2/type")
+          .SetDatabase("db2/")
           .AddProperty(
               PropertyConfigBuilder()
                   .SetName("b")
@@ -1061,19 +1237,19 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
           .Build();
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
   set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
-      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/false));
+      db2_schema, "db2/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db2_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db2/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Add documents
   DocumentProto db1_document1 =
       DocumentBuilder()
           .SetKey("namespace", "uri1")
-          .SetSchema("db1_type")
+          .SetSchema("db1/type")
           .AddStringProperty("b", "message body")
           .AddInt64Property("c", 123)
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
@@ -1081,7 +1257,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
   DocumentProto db2_document =
       DocumentBuilder()
           .SetKey("namespace", "uri2")
-          .SetSchema("db2_type")
+          .SetSchema("db2/type")
           .AddStringProperty("b", "message body")
           .AddInt64Property("d", 123)
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
@@ -1138,20 +1314,20 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
           .Build());
   db1_schema = SchemaBuilder().AddType(db1_type).Build();
   set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
-      db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
+      db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
   expected_set_schema_result.mutable_index_incompatible_changed_schema_types()
-      ->Add("db1_type");
+      ->Add("db1/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Add new document
   DocumentProto db1_document2 =
       DocumentBuilder()
           .SetKey("namespace", "uri3")
-          .SetSchema("db1_type")
+          .SetSchema("db1/type")
           .AddStringProperty("a", "message body")
           .AddStringProperty("b", "string value")
           .AddInt64Property("c", 123)
@@ -1214,7 +1390,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
   expected_get_schema_result_proto_db1_full.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db1_full.mutable_schema() = db1_schema;
-  EXPECT_THAT(icing.GetSchema("db1"),
+  EXPECT_THAT(icing.GetSchema("db1/"),
               EqualsProto(expected_get_schema_result_proto_db1_full));
 
   // Get db2 schema
@@ -1222,7 +1398,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaUpdateExistingDatabaseOk) {
   expected_get_schema_result_proto_db2_full.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db2_full.mutable_schema() = db2_schema;
-  EXPECT_THAT(icing.GetSchema("db2"),
+  EXPECT_THAT(icing.GetSchema("db2/"),
               EqualsProto(expected_get_schema_result_proto_db2_full));
 }
 
@@ -1235,8 +1411,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
   // - 'c': int64 type, indexed.
   SchemaTypeConfigProto db1_type =
       SchemaTypeConfigBuilder()
-          .SetType("db1_type")
-          .SetDatabase("db1")
+          .SetType("db1/type")
+          .SetDatabase("db1/")
           .AddProperty(PropertyConfigBuilder()
                            .SetName("b")
                            .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
@@ -1249,12 +1425,12 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
   SetSchemaResultProto set_schema_result =
       icing.SetSchema(CreateSetSchemaRequestProto(
-          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/true));
+          db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/true));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db1_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Add a schema for db2:
@@ -1262,8 +1438,8 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
   // - 'd': int64 type, indexed.
   SchemaTypeConfigProto db2_type =
       SchemaTypeConfigBuilder()
-          .SetType("db2_type")
-          .SetDatabase("db2")
+          .SetType("db2/type")
+          .SetDatabase("db2/")
           .AddProperty(
               PropertyConfigBuilder()
                   .SetName("b")
@@ -1276,19 +1452,19 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
           .Build();
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
   set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
-      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/true));
+      db2_schema, "db2/", /*ignore_errors_and_delete_documents=*/true));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db2_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db2/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Add documents
   DocumentProto db1_document1 =
       DocumentBuilder()
           .SetKey("namespace", "uri1")
-          .SetSchema("db1_type")
+          .SetSchema("db1/type")
           .AddStringProperty("b", "message body")
           .AddInt64Property("c", 123)
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
@@ -1296,7 +1472,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
   DocumentProto db2_document =
       DocumentBuilder()
           .SetKey("namespace", "uri2")
-          .SetSchema("db2_type")
+          .SetSchema("db2/type")
           .AddStringProperty("b", "message body")
           .AddInt64Property("d", 123)
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
@@ -1344,19 +1520,20 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
   //   - 'd': int64 type, indexed.
   db1_schema = SchemaProto();
   set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
-      db1_schema, "db1", /*ignore_errors_and_delete_documents=*/true));
+      db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/true));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_deleted_schema_types()->Add("db1_type");
+  expected_set_schema_result.mutable_deleted_schema_types()->Add("db1/type");
+  expected_set_schema_result.set_deleted_document_count(1);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Adding new document fails because db1_type is deleted.
   DocumentProto db1_document2 =
       DocumentBuilder()
           .SetKey("namespace", "uri3")
-          .SetSchema("db1_type")
+          .SetSchema("db1/type")
           .AddStringProperty("a", "message body")
           .AddStringProperty("b", "string value")
           .AddInt64Property("c", 123)
@@ -1405,7 +1582,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
               EqualsProto(expected_get_schema_result_proto_full));
 
   // Get db1 schema should return NOT_FOUND.
-  EXPECT_THAT(icing.GetSchema("db1").status(),
+  EXPECT_THAT(icing.GetSchema("db1/").status(),
               ProtoStatusIs(StatusProto::NOT_FOUND));
 
   // Get db2 schema
@@ -1413,7 +1590,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaEmptySchemaClearsDatabase) {
   expected_get_schema_result_proto_db2_full.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db2_full.mutable_schema() = db2_schema;
-  EXPECT_THAT(icing.GetSchema("db2"),
+  EXPECT_THAT(icing.GetSchema("db2/"),
               EqualsProto(expected_get_schema_result_proto_db2_full));
 }
 
@@ -2739,6 +2916,7 @@ TEST_F(
   expected_set_schema_result.mutable_index_incompatible_changed_schema_types()
       ->Add("Email");
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.set_deleted_document_count(0);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Verify term search
@@ -2905,6 +3083,7 @@ TEST_F(IcingSearchEngineSchemaTest,
   expected_set_schema_result.mutable_join_incompatible_changed_schema_types()
       ->Add("Email");
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.set_deleted_document_count(0);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Verify join search: join a query for `name:person` with a child query for
@@ -3036,6 +3215,7 @@ TEST_F(
   expected_set_schema_result.mutable_index_incompatible_changed_schema_types()
       ->Add("Email");
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.set_deleted_document_count(0);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Verify term search
@@ -3205,6 +3385,7 @@ TEST_F(
   expected_set_schema_result.mutable_join_incompatible_changed_schema_types()
       ->Add("Email");
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.set_deleted_document_count(0);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Verify join search: join a query for `name:person` with a child query for
@@ -3321,6 +3502,7 @@ TEST_F(IcingSearchEngineSchemaTest,
   expected_set_schema_result.mutable_index_incompatible_changed_schema_types()
       ->Add("Person");
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
+  expected_set_schema_result.set_deleted_document_count(2);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Both documents should be deleted now.
@@ -3388,7 +3570,6 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaRevalidatesDocumentsAndReturnsOk) {
   expected_set_schema_result_proto.mutable_status()->set_message(
       "Schema is incompatible.");
   expected_set_schema_result_proto.add_incompatible_schema_types("email");
-
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result_proto));
 
   // Force set it
@@ -3399,6 +3580,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaRevalidatesDocumentsAndReturnsOk) {
   set_schema_result.clear_latency_ms();
   expected_set_schema_result_proto.mutable_status()->set_code(StatusProto::OK);
   expected_set_schema_result_proto.mutable_status()->clear_message();
+  expected_set_schema_result_proto.set_deleted_document_count(1);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result_proto));
 
   GetResultProto expected_get_result_proto;
@@ -3474,6 +3656,7 @@ TEST_F(IcingSearchEngineSchemaTest, SetSchemaDeletesDocumentsAndReturnsOk) {
   set_schema_result.clear_latency_ms();
   expected_result.mutable_status()->set_code(StatusProto::OK);
   expected_result.mutable_status()->clear_message();
+  expected_result.set_deleted_document_count(1);
   EXPECT_THAT(set_schema_result, EqualsProto(expected_result));
 
   // "email" document is still there
@@ -3523,8 +3706,8 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseOk) {
   // Add a schema for db1:
   SchemaTypeConfigProto db1_type =
       SchemaTypeConfigBuilder()
-          .SetType("db1_type")
-          .SetDatabase("db1")
+          .SetType("db1/type")
+          .SetDatabase("db1/")
           .AddProperty(PropertyConfigBuilder()
                            .SetName("a")
                            .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
@@ -3538,19 +3721,19 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseOk) {
   SchemaProto db1_schema = SchemaBuilder().AddType(db1_type).Build();
   SetSchemaResultProto set_schema_result =
       icing.SetSchema(CreateSetSchemaRequestProto(
-          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
+          db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db1_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // Add a schema for db2:
   SchemaTypeConfigProto db2_type =
       SchemaTypeConfigBuilder()
-          .SetType("db2_type")
-          .SetDatabase("db2")
+          .SetType("db2/type")
+          .SetDatabase("db2/")
           .AddProperty(
               PropertyConfigBuilder()
                   .SetName("a")
@@ -3564,12 +3747,12 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseOk) {
 
   SchemaProto db2_schema = SchemaBuilder().AddType(db2_type).Build();
   set_schema_result = icing.SetSchema(CreateSetSchemaRequestProto(
-      db2_schema, "db2", /*ignore_errors_and_delete_documents=*/false));
+      db2_schema, "db2/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   expected_set_schema_result = SetSchemaResultProto();
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db2_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db2/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   // GetSchema per database
@@ -3577,13 +3760,13 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseOk) {
   expected_get_schema_result_proto_db1.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db1.mutable_schema() = db1_schema;
-  EXPECT_THAT(icing.GetSchema("db1"),
+  EXPECT_THAT(icing.GetSchema("db1/"),
               EqualsProto(expected_get_schema_result_proto_db1));
   GetSchemaResultProto expected_get_schema_result_proto_db2;
   expected_get_schema_result_proto_db2.mutable_status()->set_code(
       StatusProto::OK);
   *expected_get_schema_result_proto_db2.mutable_schema() = db2_schema;
-  EXPECT_THAT(icing.GetSchema("db2"),
+  EXPECT_THAT(icing.GetSchema("db2/"),
               EqualsProto(expected_get_schema_result_proto_db2));
 
   // Get full schema
@@ -3611,8 +3794,8 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseNotFound) {
   SchemaProto db1_schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_type")
-                       .SetDatabase("db1")
+                       .SetType("db1/type")
+                       .SetDatabase("db1/")
                        .AddProperty(PropertyConfigBuilder()
                                         .SetName("a")
                                         .SetDataTypeString(TERM_MATCH_EXACT,
@@ -3625,12 +3808,12 @@ TEST_F(IcingSearchEngineSchemaTest, GetSchemaDatabaseNotFound) {
           .Build();
   SetSchemaResultProto set_schema_result =
       icing.SetSchema(CreateSetSchemaRequestProto(
-          db1_schema, "db1", /*ignore_errors_and_delete_documents=*/false));
+          db1_schema, "db1/", /*ignore_errors_and_delete_documents=*/false));
   // Ignore latency numbers. They're covered elsewhere.
   set_schema_result.clear_latency_ms();
   SetSchemaResultProto expected_set_schema_result;
   expected_set_schema_result.mutable_status()->set_code(StatusProto::OK);
-  expected_set_schema_result.mutable_new_schema_types()->Add("db1_type");
+  expected_set_schema_result.mutable_new_schema_types()->Add("db1/type");
   EXPECT_THAT(set_schema_result, EqualsProto(expected_set_schema_result));
 
   get_schema_result_proto = icing.GetSchema("nonexistent_db");
diff --git a/icing/icing-search-engine_search_test.cc b/icing/icing-search-engine_search_test.cc
index 46040a4..c80930c 100644
--- a/icing/icing-search-engine_search_test.cc
+++ b/icing/icing-search-engine_search_test.cc
@@ -19,6 +19,7 @@
 #include <memory>
 #include <string>
 #include <string_view>
+#include <tuple>
 #include <utility>
 #include <vector>
 
@@ -71,9 +72,10 @@ using ::testing::DoubleEq;
 using ::testing::DoubleNear;
 using ::testing::ElementsAre;
 using ::testing::Eq;
-using ::testing::Gt;
 using ::testing::HasSubstr;
 using ::testing::IsEmpty;
+using ::testing::IsFalse;
+using ::testing::IsTrue;
 using ::testing::Lt;
 using ::testing::Ne;
 using ::testing::SizeIs;
@@ -936,10 +938,11 @@ TEST_F(IcingSearchEngineSearchTest, SearchShouldReturnMultiplePages) {
       document4;
   SearchResultProto search_result_proto =
       icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
-  EXPECT_THAT(search_result_proto.next_page_token(), Gt(kInvalidNextPageToken));
   uint64_t next_page_token = search_result_proto.next_page_token();
+
   // Since the token is a random number, we don't need to verify
   expected_search_result_proto.set_next_page_token(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
 
@@ -950,6 +953,7 @@ TEST_F(IcingSearchEngineSearchTest, SearchShouldReturnMultiplePages) {
   *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
       document2;
   search_result_proto = icing.GetNextPage(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
 
@@ -961,12 +965,153 @@ TEST_F(IcingSearchEngineSearchTest, SearchShouldReturnMultiplePages) {
   // token.
   expected_search_result_proto.clear_next_page_token();
   search_result_proto = icing.GetNextPage(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(),
+              Eq(kInvalidNextPageToken));  // No more results.
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
+}
+
+TEST_F(IcingSearchEngineSearchTest,
+       SearchShouldReturnMultiplePages_withMaxResultsLimit) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  // Creates and inserts 5 documents
+  DocumentProto document1 = CreateMessageDocument("namespace", "uri1");
+  DocumentProto document2 = CreateMessageDocument("namespace", "uri2");
+  DocumentProto document3 = CreateMessageDocument("namespace", "uri3");
+  DocumentProto document4 = CreateMessageDocument("namespace", "uri4");
+  DocumentProto document5 = CreateMessageDocument("namespace", "uri5");
+  ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document3).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document4).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document5).status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::PREFIX);
+  search_spec.set_query("message");
+
+  ResultSpecProto result_spec;
+  result_spec.set_num_per_page(2);
 
-  // No more results
+  // Searches and gets the first page, 2 results
+  SearchResultProto expected_search_result_proto;
+  expected_search_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document5;
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document4;
+  SearchResultProto search_result_proto =
+      icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
+  uint64_t next_page_token = search_result_proto.next_page_token();
+
+  // Since the token is a random number, we don't need to verify
+  expected_search_result_proto.set_next_page_token(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
+  EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
+                                       expected_search_result_proto));
+
+  // Second page, with a max limit of 1 result
   expected_search_result_proto.clear_results();
-  search_result_proto = icing.GetNextPage(next_page_token);
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document3;
+  GetNextPageRequestProto get_next_page_request;
+  get_next_page_request.set_next_page_token(next_page_token);
+  get_next_page_request.set_max_results_to_retrieve_from_page(1);
+  search_result_proto = icing.GetNextPage(std::move(get_next_page_request));
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
+  EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
+                                       expected_search_result_proto));
+
+  // Third page, 2 results
+  expected_search_result_proto.clear_results();
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document2;
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document1;
+  get_next_page_request = GetNextPageRequestProto();
+  get_next_page_request.set_next_page_token(next_page_token);
+  search_result_proto = icing.GetNextPage(std::move(get_next_page_request));
+  // Because there are no more results, we should not return the next page
+  // token.
+  expected_search_result_proto.clear_next_page_token();
+  EXPECT_THAT(search_result_proto.next_page_token(),
+              Eq(kInvalidNextPageToken));  // No more results.
+  EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
+                                       expected_search_result_proto));
+}
+
+TEST_F(IcingSearchEngineSearchTest,
+       SearchShouldReturnMultiplePages_maxResultsLimitLargerThanPageSize) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  // Creates and inserts 5 documents
+  DocumentProto document1 = CreateMessageDocument("namespace", "uri1");
+  DocumentProto document2 = CreateMessageDocument("namespace", "uri2");
+  DocumentProto document3 = CreateMessageDocument("namespace", "uri3");
+  DocumentProto document4 = CreateMessageDocument("namespace", "uri4");
+  DocumentProto document5 = CreateMessageDocument("namespace", "uri5");
+  ASSERT_THAT(icing.Put(document1).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document2).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document3).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document4).status(), ProtoIsOk());
+  ASSERT_THAT(icing.Put(document5).status(), ProtoIsOk());
+
+  SearchSpecProto search_spec;
+  search_spec.set_term_match_type(TermMatchType::PREFIX);
+  search_spec.set_query("message");
+
+  ResultSpecProto result_spec;
+  result_spec.set_num_per_page(2);
+
+  // Searches and gets the first page -- this should return 2 results
+  SearchResultProto expected_search_result_proto;
+  expected_search_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document5;
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document4;
+  SearchResultProto search_result_proto =
+      icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
+  uint64_t next_page_token = search_result_proto.next_page_token();
+
+  // Since the token is a random number, we don't need to verify
+  expected_search_result_proto.set_next_page_token(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
+  EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
+                                       expected_search_result_proto));
+
+  // Second page with a max limit of 5. This should still only return 2
+  // results.
+  expected_search_result_proto.clear_results();
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document3;
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document2;
+  GetNextPageRequestProto get_next_page_request;
+  get_next_page_request.set_next_page_token(next_page_token);
+  get_next_page_request.set_max_results_to_retrieve_from_page(5);
+  search_result_proto = icing.GetNextPage(std::move(get_next_page_request));
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
+  EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
+                                       expected_search_result_proto));
+
+  // Third page, only 1 result left.
+  expected_search_result_proto.clear_results();
+  *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
+      document1;
+  get_next_page_request = GetNextPageRequestProto();
+  get_next_page_request.set_next_page_token(next_page_token);
+  search_result_proto = icing.GetNextPage(std::move(get_next_page_request));
+  // Because there are no more results, we should not return the next page
+  // token.
+  expected_search_result_proto.clear_next_page_token();
+  EXPECT_THAT(search_result_proto.next_page_token(),
+              Eq(kInvalidNextPageToken));  // No more results.
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
 }
@@ -1008,10 +1153,11 @@ TEST_F(IcingSearchEngineSearchTest,
       document4;
   SearchResultProto search_result_proto =
       icing.Search(search_spec, scoring_spec, result_spec);
-  EXPECT_THAT(search_result_proto.next_page_token(), Gt(kInvalidNextPageToken));
   uint64_t next_page_token = search_result_proto.next_page_token();
+
   // Since the token is a random number, we don't need to verify
   expected_search_result_proto.set_next_page_token(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
 
@@ -1022,6 +1168,7 @@ TEST_F(IcingSearchEngineSearchTest,
   *expected_search_result_proto.mutable_results()->Add()->mutable_document() =
       document2;
   search_result_proto = icing.GetNextPage(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
 
@@ -1033,12 +1180,8 @@ TEST_F(IcingSearchEngineSearchTest,
   // token.
   expected_search_result_proto.clear_next_page_token();
   search_result_proto = icing.GetNextPage(next_page_token);
-  EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
-                                       expected_search_result_proto));
-
-  // No more results
-  expected_search_result_proto.clear_results();
-  search_result_proto = icing.GetNextPage(next_page_token);
+  EXPECT_THAT(search_result_proto.next_page_token(),
+              Eq(kInvalidNextPageToken));  // No more results.
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
 }
@@ -1094,7 +1237,7 @@ TEST_F(IcingSearchEngineSearchTest, ShouldReturnMultiplePagesWithSnippets) {
       icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
   ASSERT_THAT(search_result.status(), ProtoIsOk());
   ASSERT_THAT(search_result.results(), SizeIs(2));
-  ASSERT_THAT(search_result.next_page_token(), Gt(kInvalidNextPageToken));
+  ASSERT_THAT(search_result.next_page_token(), Ne(kInvalidNextPageToken));
 
   const DocumentProto& document_result_1 = search_result.results(0).document();
   EXPECT_THAT(document_result_1, EqualsProto(document5));
@@ -1123,7 +1266,7 @@ TEST_F(IcingSearchEngineSearchTest, ShouldReturnMultiplePagesWithSnippets) {
   search_result = icing.GetNextPage(search_result.next_page_token());
   ASSERT_THAT(search_result.status(), ProtoIsOk());
   ASSERT_THAT(search_result.results(), SizeIs(2));
-  ASSERT_THAT(search_result.next_page_token(), Gt(kInvalidNextPageToken));
+  ASSERT_THAT(search_result.next_page_token(), Ne(kInvalidNextPageToken));
 
   const DocumentProto& document_result_3 = search_result.results(0).document();
   EXPECT_THAT(document_result_3, EqualsProto(document3));
@@ -1173,7 +1316,7 @@ TEST_F(IcingSearchEngineSearchTest, ShouldInvalidateNextPageToken) {
       document2;
   SearchResultProto search_result_proto =
       icing.Search(search_spec, GetDefaultScoringSpec(), result_spec);
-  EXPECT_THAT(search_result_proto.next_page_token(), Gt(kInvalidNextPageToken));
+  EXPECT_THAT(search_result_proto.next_page_token(), Ne(kInvalidNextPageToken));
   uint64_t next_page_token = search_result_proto.next_page_token();
   // Since the token is a random number, we don't need to verify
   expected_search_result_proto.set_next_page_token(next_page_token);
@@ -1184,9 +1327,12 @@ TEST_F(IcingSearchEngineSearchTest, ShouldInvalidateNextPageToken) {
   // Invalidates token
   icing.InvalidateNextPageToken(next_page_token);
 
-  // Tries to fetch the second page, no result since it's invalidated
+  // Tries to fetch the second page, no result since it's invalidated. Also
+  // page_token_not_found should be set to true in order to hint the client that
+  // the pagination is incomplete.
   expected_search_result_proto.clear_results();
   expected_search_result_proto.clear_next_page_token();
+  expected_search_result_proto.set_page_token_not_found(true);
   search_result_proto = icing.GetNextPage(next_page_token);
   EXPECT_THAT(search_result_proto, EqualsSearchResultIgnoreStatsAndScores(
                                        expected_search_result_proto));
@@ -4720,7 +4866,7 @@ TEST_F(IcingSearchEngineSearchTest, QueryStatsProtoTest) {
   search_result = icing.GetNextPage(search_result.next_page_token());
   ASSERT_THAT(search_result.status(), ProtoIsOk());
   ASSERT_THAT(search_result.results(), SizeIs(2));
-  ASSERT_THAT(search_result.next_page_token(), Gt(kInvalidNextPageToken));
+  ASSERT_THAT(search_result.next_page_token(), Ne(kInvalidNextPageToken));
 
   exp_stats = QueryStatsProto();
   exp_stats.set_is_first_page(false);
@@ -4731,6 +4877,7 @@ TEST_F(IcingSearchEngineSearchTest, QueryStatsProtoTest) {
   exp_stats.set_document_retrieval_latency_ms(5);
   exp_stats.set_lock_acquisition_latency_ms(5);
   exp_stats.set_num_joined_results_returned_current_page(0);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::VALID);
   EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
 
   // Third page, 1 result with 0 snippets
@@ -4748,6 +4895,75 @@ TEST_F(IcingSearchEngineSearchTest, QueryStatsProtoTest) {
   exp_stats.set_document_retrieval_latency_ms(5);
   exp_stats.set_lock_acquisition_latency_ms(5);
   exp_stats.set_num_joined_results_returned_current_page(0);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::VALID);
+  EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
+
+  // Fetch the next page with kInvalidNextPageToken.
+  search_result = icing.GetNextPage(kInvalidNextPageToken);
+  ASSERT_THAT(search_result.status(), ProtoIsOk());
+  ASSERT_THAT(search_result.results(), IsEmpty());
+  ASSERT_THAT(search_result.next_page_token(), Eq(kInvalidNextPageToken));
+
+  exp_stats = QueryStatsProto();
+  exp_stats.set_is_first_page(false);
+  exp_stats.set_lock_acquisition_latency_ms(5);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::EMPTY);
+  EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
+}
+
+TEST_F(IcingSearchEngineSearchTest, GetNextPage_withNotFoundPageToken) {
+  auto fake_clock = std::make_unique<FakeClock>();
+  fake_clock->SetTimerElapsedMilliseconds(5);
+
+  TestIcingSearchEngine icing(GetDefaultIcingOptions(),
+                              std::make_unique<Filesystem>(),
+                              std::make_unique<IcingFilesystem>(),
+                              std::move(fake_clock), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+  // Call GetNextPage with a not found page token.
+  SearchResultProto search_result = icing.GetNextPage(/*next_page_token=*/123);
+  ASSERT_THAT(search_result.status(), ProtoIsOk());
+  ASSERT_THAT(search_result.results(), IsEmpty());
+  ASSERT_THAT(search_result.next_page_token(), Eq(kInvalidNextPageToken));
+  // page_token_not_found is set to true.
+  // - Usually the client uses a valid page token to fetch the next page. If the
+  //   page token is not found, it is "likely" that the corresponding
+  //   ResultState has been removed due to cache eviction.
+  // - If the client really tries to fetch the next page with an non-existing
+  //   page token, then we cannot tell whether the search is "invalid" or
+  //   "incomplete". Still, it is just a hint warning field for the 1st case.
+  EXPECT_THAT(search_result.page_token_not_found(), IsTrue());
+
+  QueryStatsProto exp_stats = QueryStatsProto();
+  exp_stats.set_is_first_page(false);
+  exp_stats.set_lock_acquisition_latency_ms(5);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::NOT_FOUND);
+  EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
+}
+
+TEST_F(IcingSearchEngineSearchTest, GetNextPage_withInvalidPageToken) {
+  auto fake_clock = std::make_unique<FakeClock>();
+  fake_clock->SetTimerElapsedMilliseconds(5);
+
+  TestIcingSearchEngine icing(GetDefaultIcingOptions(),
+                              std::make_unique<Filesystem>(),
+                              std::make_unique<IcingFilesystem>(),
+                              std::move(fake_clock), GetTestJniCache());
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+
+  // Call GetNextPage with kInvalidNextPageToken.
+  SearchResultProto search_result = icing.GetNextPage(kInvalidNextPageToken);
+  ASSERT_THAT(search_result.status(), ProtoIsOk());
+  ASSERT_THAT(search_result.results(), IsEmpty());
+  ASSERT_THAT(search_result.next_page_token(), Eq(kInvalidNextPageToken));
+  // page_token_not_found should be false.
+  EXPECT_THAT(search_result.page_token_not_found(), IsFalse());
+
+  QueryStatsProto exp_stats = QueryStatsProto();
+  exp_stats.set_is_first_page(false);
+  exp_stats.set_lock_acquisition_latency_ms(5);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::EMPTY);
   EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
 }
 
@@ -5034,6 +5250,7 @@ TEST_F(IcingSearchEngineSearchTest, JoinQueryStatsProtoTest) {
   exp_stats.set_document_retrieval_latency_ms(5);
   exp_stats.set_lock_acquisition_latency_ms(5);
   exp_stats.set_num_joined_results_returned_current_page(1);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::VALID);
   EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
 
   // Third page, 0 child docs.
@@ -5052,6 +5269,7 @@ TEST_F(IcingSearchEngineSearchTest, JoinQueryStatsProtoTest) {
   exp_stats.set_document_retrieval_latency_ms(5);
   exp_stats.set_lock_acquisition_latency_ms(5);
   exp_stats.set_num_results_with_snippets(0);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::VALID);
   ASSERT_THAT(search_result,
               EqualsSearchResultIgnoreStatsAndScores(expected_result3));
   EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
@@ -5066,6 +5284,7 @@ TEST_F(IcingSearchEngineSearchTest, JoinQueryStatsProtoTest) {
   exp_stats = QueryStatsProto();
   exp_stats.set_is_first_page(false);
   exp_stats.set_lock_acquisition_latency_ms(5);
+  exp_stats.set_page_token_type(QueryStatsProto::PageTokenType::EMPTY);
   EXPECT_THAT(search_result.query_stats(), EqualsProto(exp_stats));
 }
 
@@ -7745,7 +7964,7 @@ TEST_F(IcingSearchEngineSearchTest, HasPropertyQueryNestedDocument) {
 }
 
 class IcingSearchEngineEmbeddingSearchTest
-    : public ::testing::TestWithParam<bool> {
+    : public ::testing::TestWithParam<std::tuple<bool, bool>> {
  protected:
   void SetUp() override {
     if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
@@ -7774,6 +7993,9 @@ class IcingSearchEngineEmbeddingSearchTest
 };
 
 TEST_P(IcingSearchEngineEmbeddingSearchTest, EmbeddingSearch) {
+  bool get_embedding_match_info = std::get<0>(GetParam());
+  bool enable_eigen_embedding_scoring = std::get<1>(GetParam());
+
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
@@ -7822,7 +8044,9 @@ TEST_P(IcingSearchEngineEmbeddingSearchTest, EmbeddingSearch) {
                              CreateVector("my_model_v2", {0.6, 0.7, -0.8}))
           .Build();
 
-  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  options.set_enable_eigen_embedding_scoring(enable_eigen_embedding_scoring);
+  IcingSearchEngine icing(options, GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
   ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
   ASSERT_THAT(icing.Put(document0).status(), ProtoIsOk());
@@ -7850,7 +8074,6 @@ TEST_P(IcingSearchEngineEmbeddingSearchTest, EmbeddingSearch) {
   scoring_spec.set_rank_by(
       ScoringSpecProto::RankingStrategy::ADVANCED_SCORING_EXPRESSION);
 
-  bool get_embedding_match_info = GetParam();
   ResultSpecProto result_spec = ResultSpecProto::default_instance();
   result_spec.mutable_snippet_spec()->set_num_to_snippet(3);
   result_spec.mutable_snippet_spec()->set_num_matches_per_property(5);
@@ -8168,10 +8391,12 @@ TEST_P(IcingSearchEngineEmbeddingSearchTest, EmbeddingSearch) {
   }
 }
 
-INSTANTIATE_TEST_SUITE_P(IcingSearchEngineEmbeddingSearchTest,
-                         IcingSearchEngineEmbeddingSearchTest,
-                         testing::Values(/*enable_embedding_quantization=*/true,
-                                         false));
+INSTANTIATE_TEST_SUITE_P(
+    IcingSearchEngineEmbeddingSearchTest, IcingSearchEngineEmbeddingSearchTest,
+    testing::Values(std::make_tuple(/*get_embedding_match_info=*/false,
+                                    /*enable_eigen_embedding_scoring=*/false),
+                    std::make_tuple(false, true), std::make_tuple(true, false),
+                    std::make_tuple(true, true)));
 
 TEST_F(IcingSearchEngineSearchTest, CannotScoreUnqueriedEmbedding) {
   SchemaProto schema =
@@ -8339,7 +8564,37 @@ TEST_F(IcingSearchEngineSearchTest, AdditionalScores) {
               DoubleNear(0 + 0.5, kEps));
 }
 
-TEST_F(IcingSearchEngineSearchTest, EmbeddingSearchWithQuantizedProperty) {
+class IcingSearchEngineEmbeddingSearchQuantizationTest
+    : public ::testing::TestWithParam<bool> {
+ protected:
+  void SetUp() override {
+    if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
+      // If we've specified using the reverse-JNI method for segmentation (i.e.
+      // not ICU), then we won't have the ICU data file included to set up.
+      // Technically, we could choose to use reverse-JNI for segmentation AND
+      // include an ICU data file, but that seems unlikely and our current BUILD
+      // setup doesn't do this.
+      // File generated via icu_data_file rule in //icing/BUILD.
+      std::string icu_data_file_path =
+          GetTestFilePath("icing/icu.dat");
+      ICING_ASSERT_OK(
+          icu_data_file_helper::SetUpIcuDataFile(icu_data_file_path));
+    }
+    filesystem_.CreateDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  void TearDown() override {
+    filesystem_.DeleteDirectoryRecursively(GetTestBaseDir().c_str());
+  }
+
+  const Filesystem* filesystem() const { return &filesystem_; }
+
+ private:
+  Filesystem filesystem_;
+};
+
+TEST_P(IcingSearchEngineEmbeddingSearchQuantizationTest,
+       EmbeddingSearchWithQuantizedProperty) {
   constexpr float eps = 0.0001f;
 
   SchemaProto schema =
@@ -8385,7 +8640,9 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearchWithQuantizedProperty) {
           .AddVectorProperty("embeddingQuantized", vector1, vector2)
           .Build();
 
-  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+  IcingSearchEngineOptions options = GetDefaultIcingOptions();
+  options.set_enable_eigen_embedding_scoring(GetParam());
+  IcingSearchEngine icing(options, GetTestJniCache());
   ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
   ASSERT_THAT(icing.SetSchema(schema).status(), ProtoIsOk());
   ASSERT_THAT(icing.Put(document_with_original_embedding).status(),
@@ -8457,6 +8714,11 @@ TEST_F(IcingSearchEngineSearchTest, EmbeddingSearchWithQuantizedProperty) {
   EXPECT_THAT(results.results(1).additional_scores(0), DoubleNear(256.45, eps));
 }
 
+INSTANTIATE_TEST_SUITE_P(
+    IcingSearchEngineEmbeddingSearchQuantizationTest,
+    IcingSearchEngineEmbeddingSearchQuantizationTest,
+    testing::Values(/*enable_eigen_embedding_scoring=*/true, false));
+
 TEST_F(IcingSearchEngineSearchTest,
        AdditionalScoresOnlyAllowedInAdvancedScoring) {
   SchemaProto schema =
diff --git a/icing/icing-search-engine_test.cc b/icing/icing-search-engine_test.cc
index cb17905..446e958 100644
--- a/icing/icing-search-engine_test.cc
+++ b/icing/icing-search-engine_test.cc
@@ -1780,6 +1780,49 @@ TEST_F(IcingSearchEngineTest, GetDebugInfoWithSchemaNoDocumentsSucceeds) {
   ASSERT_THAT(result.status(), ProtoIsOk());
 }
 
+TEST_F(IcingSearchEngineTest, ClearAndDestroySucceeds) {
+  IcingSearchEngine icing(GetDefaultIcingOptions(), GetTestJniCache());
+
+  // Obtain empty size of the base directory.
+  int64_t empty_state_size =
+      filesystem()->GetFileDiskUsage(GetTestBaseDir().c_str());
+
+  ASSERT_THAT(icing.Initialize().status(), ProtoIsOk());
+  ASSERT_THAT(icing.SetSchema(CreateMessageSchema()).status(), ProtoIsOk());
+
+  // Simple put and get
+  ASSERT_THAT(icing.Put(CreateMessageDocument("namespace", "uri")).status(),
+              ProtoIsOk());
+
+  GetResultProto expected_get_result_proto;
+  expected_get_result_proto.mutable_status()->set_code(StatusProto::OK);
+  *expected_get_result_proto.mutable_document() =
+      CreateMessageDocument("namespace", "uri");
+  ASSERT_THAT(
+      icing.Get("namespace", "uri", GetResultSpecProto::default_instance()),
+      EqualsProto(expected_get_result_proto));
+
+  // Sanity check that things have been added
+  EXPECT_THAT(filesystem()->GetDiskUsage(GetTestBaseDir().c_str()),
+              Gt(empty_state_size));
+  EXPECT_EQ(filesystem()->DirectoryExists(GetTestBaseDir().c_str()), true);
+
+  // Clear all data for the icing instance
+  ResetResultProto clear_result = icing.ClearAndDestroy();
+  EXPECT_THAT(clear_result.status(), ProtoIsOk());
+
+  // Check that the directory no longer exists after deletion.
+  EXPECT_EQ(filesystem()->DirectoryExists(GetTestBaseDir().c_str()), false);
+
+  // Try to put and get again, but it should fail since the instance is
+  // uninitialized.
+  EXPECT_THAT(icing.Put(CreateMessageDocument("namespace", "uri")).status(),
+              ProtoStatusIs(StatusProto::FAILED_PRECONDITION));
+  EXPECT_THAT(
+      icing.Get("namespace", "uri", GetResultSpecProto::default_instance())
+          .status(),
+      ProtoStatusIs(StatusProto::FAILED_PRECONDITION));
+}
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/index/embed/doc-hit-info-iterator-embedding.cc b/icing/index/embed/doc-hit-info-iterator-embedding.cc
index 292fb03..9c7c4a5 100644
--- a/icing/index/embed/doc-hit-info-iterator-embedding.cc
+++ b/icing/index/embed/doc-hit-info-iterator-embedding.cc
@@ -44,13 +44,17 @@ libtextclassifier3::StatusOr<std::unique_ptr<DocHitInfoIteratorEmbedding>>
 DocHitInfoIteratorEmbedding::Create(
     const PropertyProto::VectorProto* query,
     SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
-    double score_low, double score_high, bool get_embedding_match_info,
+    double score_low, double score_high,
     EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map,
+    std::vector<double>* global_scores,
+    std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>*
+        global_section_infos,
     const EmbeddingIndex* embedding_index, const DocumentStore* document_store,
     const SchemaStore* schema_store, int64_t current_time_ms) {
   ICING_RETURN_ERROR_IF_NULL(query);
   ICING_RETURN_ERROR_IF_NULL(embedding_index);
   ICING_RETURN_ERROR_IF_NULL(info_map);
+  ICING_RETURN_ERROR_IF_NULL(global_scores);
   ICING_RETURN_ERROR_IF_NULL(document_store);
   ICING_RETURN_ERROR_IF_NULL(schema_store);
 
@@ -74,8 +78,8 @@ DocHitInfoIteratorEmbedding::Create(
   return std::unique_ptr<DocHitInfoIteratorEmbedding>(
       new DocHitInfoIteratorEmbedding(
           query, metric_type, std::move(embedding_scorer), score_low,
-          score_high, get_embedding_match_info, info_map, embedding_index,
-          std::move(pl_accessor), document_store, schema_store,
+          score_high, info_map, global_scores, global_section_infos,
+          embedding_index, std::move(pl_accessor), document_store, schema_store,
           current_time_ms));
 }
 
@@ -151,10 +155,9 @@ DocHitInfoIteratorEmbedding::AdvanceToNextUnfilteredDocument() {
       // current_allowed_sections_mask_ should be assigned to kSectionIdMaskNone
       // by AdvanceToNextEmbeddingHit, and the embedding hit should have been
       // skipped above.
-      ICING_ASSIGN_OR_RETURN(
-          quantization_type,
-          schema_store_.GetQuantizationType(
-              schema_type_id_, current_section_id));
+      ICING_ASSIGN_OR_RETURN(quantization_type,
+                             schema_store_.GetQuantizationType(
+                                 schema_type_id_, current_section_id));
     }
 
     // Calculate the semantic score.
@@ -170,11 +173,13 @@ DocHitInfoIteratorEmbedding::AdvanceToNextUnfilteredDocument() {
       if (matched_infos == nullptr) {
         matched_infos = &(info_map_[doc_hit_info_.document_id()]);
       }
-      matched_infos->AppendScore(semantic_score);
-      if (get_embedding_match_info_) {
+      ICING_RETURN_IF_ERROR(
+          matched_infos->AppendScore(global_scores_, semantic_score));
+      if (global_section_infos_ != nullptr) {
         // Add the section info for this embedding match.
-        matched_infos->AppendSectionInfo(current_section_id,
-                                         current_section_match_count);
+        ICING_RETURN_IF_ERROR(matched_infos->AppendSectionInfo(
+            *global_section_infos_, current_section_id,
+            current_section_match_count));
       }
     }
     ++current_section_match_count;
diff --git a/icing/index/embed/doc-hit-info-iterator-embedding.h b/icing/index/embed/doc-hit-info-iterator-embedding.h
index ed2f972..45ca307 100644
--- a/icing/index/embed/doc-hit-info-iterator-embedding.h
+++ b/icing/index/embed/doc-hit-info-iterator-embedding.h
@@ -18,7 +18,6 @@
 #include <cstdint>
 #include <memory>
 #include <string>
-#include <string_view>
 #include <utility>
 #include <vector>
 
@@ -61,8 +60,11 @@ class DocHitInfoIteratorEmbedding
       std::unique_ptr<DocHitInfoIteratorEmbedding>>
   Create(const PropertyProto::VectorProto* query,
          SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
-         double score_low, double score_high, bool get_embedding_match_info,
+         double score_low, double score_high,
          EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map,
+         std::vector<double>* global_scores,
+         std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>*
+             global_section_infos,
          const EmbeddingIndex* embedding_index,
          const DocumentStore* document_store, const SchemaStore* schema_store,
          int64_t current_time_ms);
@@ -95,8 +97,11 @@ class DocHitInfoIteratorEmbedding
       const PropertyProto::VectorProto* query,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
       std::unique_ptr<EmbeddingScorer> embedding_scorer, double score_low,
-      double score_high, bool get_embedding_match_info,
+      double score_high,
       EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map,
+      std::vector<double>* global_scores,
+      std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>*
+          global_section_infos,
       const EmbeddingIndex* embedding_index,
       std::unique_ptr<PostingListEmbeddingHitAccessor> posting_list_accessor,
       const DocumentStore* document_store, const SchemaStore* schema_store,
@@ -106,8 +111,9 @@ class DocHitInfoIteratorEmbedding
         embedding_scorer_(std::move(embedding_scorer)),
         score_low_(score_low),
         score_high_(score_high),
-        get_embedding_match_info_(get_embedding_match_info),
         info_map_(*info_map),
+        global_scores_(*global_scores),
+        global_section_infos_(global_section_infos),
         embedding_index_(*embedding_index),
         posting_list_accessor_(std::move(posting_list_accessor)),
         cached_embedding_hits_idx_(0),
@@ -153,11 +159,12 @@ class DocHitInfoIteratorEmbedding
   double score_low_;
   double score_high_;
 
-  // Snippet arguments
-  bool get_embedding_match_info_;
-
   // MatchInfo map
   EmbeddingQueryResults::EmbeddingQueryMatchInfoMap& info_map_;  // Does not own
+  std::vector<double>& global_scores_;                           // Does not own
+  // Nullable, and does not own. If null, section info will not be populated.
+  std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>*
+      global_section_infos_;
 
   // Access to embeddings index data
   const EmbeddingIndex& embedding_index_;
diff --git a/icing/index/embed/embedding-index.cc b/icing/index/embed/embedding-index.cc
index 028d85a..722e971 100644
--- a/icing/index/embed/embedding-index.cc
+++ b/icing/index/embed/embedding-index.cc
@@ -215,7 +215,11 @@ libtextclassifier3::Status EmbeddingIndex::Initialize() {
           "Incorrect metadata file size");
     }
     if (info().magic != Info::kMagic) {
-      return absl_ports::FailedPreconditionError("Incorrect magic value");
+      ICING_LOG(ERROR) << "Invalid header magic for EmbeddingIndex "
+                       << working_path_ << ". Expected: " << Info::kMagic
+                       << ", actual: " << info().magic;
+      return absl_ports::FailedPreconditionError(absl_ports::StrCat(
+          "Invalid header magic for EmbeddingIndex: ", working_path_));
     }
     ICING_RETURN_IF_ERROR(CreateStorageDataIfNonEmpty());
     ICING_RETURN_IF_ERROR(InitializeExistingStorage());
@@ -576,18 +580,30 @@ libtextclassifier3::StatusOr<float> EmbeddingIndex::ScoreEmbeddingHit(
       quantization_type == EmbeddingIndexingConfig::QuantizationType::NONE) {
     ICING_ASSIGN_OR_RETURN(const float* vector,
                            GetEmbeddingVector(hit, dimension));
-    semantic_score = scorer.Score(dimension,
-                                  /*v1=*/query.values().data(),
-                                  /*v2=*/vector);
+    if (feature_flags_->enable_eigen_embedding_scoring()) {
+      semantic_score = scorer.EigenScore(dimension,
+                                         /*v1=*/query.values().data(),
+                                         /*v2=*/vector);
+    } else {
+      semantic_score = scorer.Score(dimension,
+                                    /*v1=*/query.values().data(),
+                                    /*v2=*/vector);
+    }
   } else {
     ICING_ASSIGN_OR_RETURN(const char* data,
                            GetQuantizedEmbeddingVector(hit, dimension));
     Quantizer quantizer(data);
     const uint8_t* quantized_vector =
         reinterpret_cast<const uint8_t*>(data + sizeof(Quantizer));
-    semantic_score = scorer.Score(dimension,
-                                  /*v1=*/query.values().data(),
-                                  /*v2=*/quantized_vector, quantizer);
+    if (feature_flags_->enable_eigen_embedding_scoring()) {
+      semantic_score = scorer.EigenScore(dimension,
+                                         /*v1=*/query.values().data(),
+                                         /*v2=*/quantized_vector, quantizer);
+    } else {
+      semantic_score = scorer.Score(dimension,
+                                    /*v1=*/query.values().data(),
+                                    /*v2=*/quantized_vector, quantizer);
+    }
   }
   return semantic_score;
 }
diff --git a/icing/index/embed/embedding-index_test.cc b/icing/index/embed/embedding-index_test.cc
index 12ba95e..16c5cec 100644
--- a/icing/index/embed/embedding-index_test.cc
+++ b/icing/index/embed/embedding-index_test.cc
@@ -36,6 +36,7 @@
 #include "icing/index/embed/quantizer.h"
 #include "icing/index/hit/hit.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/schema-builder.h"
 #include "icing/schema/schema-store.h"
@@ -48,6 +49,7 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/util/clock.h"
 #include "icing/util/crc32.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -83,14 +85,18 @@ class EmbeddingIndexTest : public Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -122,12 +128,12 @@ class EmbeddingIndexTest : public Test {
                             .SetCardinality(CARDINALITY_OPTIONAL)))
             .Build(),
         /*ignore_errors_and_delete_documents=*/false));
-    ICING_ASSERT_OK(document_store_->Put(
-        DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-    ICING_ASSERT_OK(document_store_->Put(
-        DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
-    ICING_ASSERT_OK(document_store_->Put(
-        DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+    ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+        DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+    ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+        DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
+    ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+        DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   }
 
   void TearDown() override {
diff --git a/icing/index/embed/embedding-query-results.h b/icing/index/embed/embedding-query-results.h
index a90ad10..15c597d 100644
--- a/icing/index/embed/embedding-query-results.h
+++ b/icing/index/embed/embedding-query-results.h
@@ -15,21 +15,33 @@
 #ifndef ICING_INDEX_EMBED_EMBEDDING_QUERY_RESULTS_H_
 #define ICING_INDEX_EMBED_EMBEDDING_QUERY_RESULTS_H_
 
+#include <cstdint>
 #include <memory>
+#include <optional>
 #include <unordered_map>
 #include <vector>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
 #include "icing/legacy/core/icing-packed-pod.h"
 #include "icing/proto/search.pb.h"
 #include "icing/schema/section.h"
+#include "icing/scoring/advanced_scoring/double-list.h"
 #include "icing/store/document-id.h"
+#include "icing/util/embedding-util.h"
+#include "icing/util/status-macros.h"
 
 namespace icing {
 namespace lib {
 
+// Stores the matched embedding infos for a single document.
 struct EmbeddingMatchInfos {
-  // A vector of semantic scores of matched embeddings.
-  std::vector<double> scores;
+  // [score_start_index, score_end_index) is the range of score indexes in the
+  // global_scores vector. If embedding section info is enabled, the same range
+  // will be used for section infos in global_section_infos as well.
+  int32_t score_start_index = 0;
+  int32_t score_end_index = 0;
 
   struct EmbeddingMatchSectionInfo {
     // The position of the matched embedding vector in a section relative to
@@ -56,33 +68,72 @@ struct EmbeddingMatchInfos {
   static_assert(icing_is_packed_pod<EmbeddingMatchSectionInfo>::value,
                 "go/icing-ubsan");
 
-  // A vector of section infos on the matched embeddings. This will be nullptr
-  // if embedding match info is not enabled for this query.
-  //
-  // When non-null, section_infos must have a 1:1 mapping with the scores
-  // vector.
-  std::unique_ptr<std::vector<EmbeddingMatchSectionInfo>> section_infos;
-
   EmbeddingMatchInfos() = default;
-
   EmbeddingMatchInfos(const EmbeddingMatchInfos& other) = delete;
   EmbeddingMatchInfos& operator=(const EmbeddingMatchInfos& other) = delete;
 
-  // Appends a score to the scores vector.
-  void AppendScore(double score) { scores.push_back(score); }
+  // Appends a score to the scores vector, which is stored in the global_scores
+  // vector. score_start_index and score_end_index will be updated accordingly.
+  //
+  // Returns:
+  //   - OK, if the score is appended successfully.
+  //   - FailedPreconditionError, if the score is not contiguous with the
+  //     existing scores.
+  libtextclassifier3::Status AppendScore(std::vector<double>& global_scores,
+                                         double score) {
+    if (score_end_index == 0) {
+      score_start_index = score_end_index = global_scores.size();
+    }
+    if (score_end_index != global_scores.size()) {
+      return absl_ports::FailedPreconditionError(
+          "Scores for the same document should be contiguous.");
+    }
+    global_scores.push_back(score);
+    score_end_index += 1;
+    return libtextclassifier3::Status::OK;
+  }
 
-  // Appends a section info to the section_infos vector, allocating if needed.
-  void AppendSectionInfo(SectionId section_id, int position) {
-    if (!section_infos) {
-      section_infos =
-          std::make_unique<std::vector<EmbeddingMatchSectionInfo>>();
+  // Appends a section info to the section info vector, which is stored in the
+  // global_section_infos vector.
+  //
+  // Returns:
+  //   - OK, if the section info is appended successfully.
+  //   - FailedPreconditionError, if the section info is not appended
+  //     immediately after AppendScore.
+  libtextclassifier3::Status AppendSectionInfo(
+      std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>&
+          global_section_infos,
+      SectionId section_id, int position) {
+    if (score_end_index != global_section_infos.size() + 1) {
+      return absl_ports::FailedPreconditionError(
+          "Section infos must be appended immediately after AppendScore.");
     }
-    section_infos->push_back({.position = position, .section_id = section_id});
+    global_section_infos.push_back(
+        {.position = position, .section_id = section_id});
+    return libtextclassifier3::Status::OK;
   }
 };
 
 // A class to store results generated from embedding queries.
-struct EmbeddingQueryResults {
+class EmbeddingQueryResults {
+ public:
+  // Creates an empty EmbeddingQueryResults instance.
+  EmbeddingQueryResults() : EmbeddingQueryResults(/*num_query_vectors=*/0) {}
+
+  // Creates an EmbeddingQueryResults instance with the given number of query
+  // vectors.
+  EmbeddingQueryResults(int num_query_vectors)
+      : result_infos_size_(embedding_util::kEmbeddingQueryMetricTypes.size() *
+                           num_query_vectors),
+        result_infos_(
+            std::make_unique<std::optional<EmbeddingQueryMatchInfoMap>[]>(
+                result_infos_size_)) {}
+
+  int GetNumQueryVectors() const {
+    return result_infos_size_ /
+           embedding_util::kEmbeddingQueryMetricTypes.size();
+  }
+
   // Maps from DocumentId to matched embedding infos for that document.
   // For each document, its embedding match info consists of two vectors:
   // - The scores vector, which will be used in the advanced scoring language
@@ -93,11 +144,35 @@ struct EmbeddingQueryResults {
   using EmbeddingQueryMatchInfoMap =
       std::unordered_map<DocumentId, EmbeddingMatchInfos>;
 
-  // Maps from (query_vector_index, metric_type) to EmbeddingQueryMatchInfoMap.
-  std::unordered_map<
-      int, std::unordered_map<SearchSpecProto::EmbeddingQueryMetricType::Code,
-                              EmbeddingQueryMatchInfoMap>>
-      result_infos;
+  // A centralized vector of scores for all documents. This is used to store the
+  // scores for the "this.matchedSemanticScores(...)" function.
+  std::unique_ptr<std::vector<double>> global_scores =
+      std::make_unique<std::vector<double>>();
+
+  // A centralized vector of EmbeddingMatchSectionInfo for all documents. This
+  // is used to store the section infos for the embedding query.
+  std::unique_ptr<std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>>
+      global_section_infos = std::make_unique<
+          std::vector<EmbeddingMatchInfos::EmbeddingMatchSectionInfo>>();
+
+  // Get or create the MatchedInfo map for the given query_vector_index and
+  // metric_type.
+  //
+  // Returns:
+  //   - The pointer to the EmbeddingQueryMatchInfoMap map, if the map is found
+  //     or created.
+  //   - InvalidArgumentError, if the index is out of bounds.
+  libtextclassifier3::StatusOr<EmbeddingQueryMatchInfoMap*>
+  GetOrCreateMatchInfoMap(
+      int query_vector_index,
+      SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) const {
+    ICING_ASSIGN_OR_RETURN(int index,
+                           GetResultInfoIndex(query_vector_index, metric_type));
+    if (!result_infos_[index].has_value()) {
+      result_infos_[index] = EmbeddingQueryMatchInfoMap();
+    }
+    return &result_infos_[index].value();
+  }
 
   // Get the MatchedInfo map for the given query_vector_index and metric_type.
   // Returns nullptr if (query_vector_index, metric_type) does not exist in the
@@ -105,17 +180,12 @@ struct EmbeddingQueryResults {
   const EmbeddingQueryMatchInfoMap* GetMatchInfoMap(
       int query_vector_index,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) const {
-    // Check if a mapping exists for the query_vector_index
-    auto outer_it = result_infos.find(query_vector_index);
-    if (outer_it == result_infos.end()) {
-      return nullptr;
-    }
-    // Check if a mapping exists for the metric_type
-    auto inner_it = outer_it->second.find(metric_type);
-    if (inner_it == outer_it->second.end()) {
+    libtextclassifier3::StatusOr<int> index =
+        GetResultInfoIndex(query_vector_index, metric_type);
+    if (!index.ok() || !result_infos_[index.ValueOrDie()].has_value()) {
       return nullptr;
     }
-    return &inner_it->second;
+    return &result_infos_[index.ValueOrDie()].value();
   }
 
   // Returns the matched infos for the given query_vector_index, metric_type,
@@ -139,19 +209,62 @@ struct EmbeddingQueryResults {
   }
 
   // Returns the matched scores for the given query_vector_index, metric_type,
-  // and doc_id. Returns nullptr if (query_vector_index, metric_type, doc_id)
-  // does not exist in the result_scores map.
-  const std::vector<double>* GetMatchedScoresForDocument(
+  // and doc_id. Returns an empty DoubleList if (query_vector_index,
+  // metric_type, doc_id) does not exist in the result_scores map.
+  //
+  // The returned DoubleList is a non-owning view of the scores vector stored
+  // within the EmbeddingQueryResults instance. The caller must ensure the
+  // lifetime of the EmbeddingQueryResults exceeds the lifetime of the returned
+  // DoubleList.
+  DoubleList GetMatchedScoresForDocument(
       int query_vector_index,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
       DocumentId doc_id) const {
     const EmbeddingMatchInfos* match_infos =
         GetMatchedInfosForDocument(query_vector_index, metric_type, doc_id);
     if (match_infos == nullptr) {
-      return nullptr;
+      return DoubleList();
     }
-    return &match_infos->scores;
+    return GetMatchedScoresFromEmbeddingMatchInfos(*match_infos);
   };
+
+  // Returns the matched scores for the given EmbeddingMatchInfos, which stores
+  // the match infos for a single document.
+  //
+  // The returned DoubleList is a non-owning view of the scores vector stored
+  // within the EmbeddingQueryResults instance. The caller must ensure the
+  // lifetime of the EmbeddingQueryResults exceeds the lifetime of the returned
+  // DoubleList.
+  DoubleList GetMatchedScoresFromEmbeddingMatchInfos(
+      const EmbeddingMatchInfos& match_infos) const {
+    return DoubleList(
+        global_scores->data() + match_infos.score_start_index,
+        match_infos.score_end_index - match_infos.score_start_index);
+  }
+
+ private:
+  // Maps from (query_vector_index, metric_type) to EmbeddingQueryMatchInfoMap.
+  int result_infos_size_;
+  std::unique_ptr<std::optional<EmbeddingQueryMatchInfoMap>[]> result_infos_;
+
+  // Returns the index of the result info for the given query_vector_index and
+  // metric_type.
+  //
+  // Returns:
+  //   - The index of the result info, if the index is valid.
+  //   - InvalidArgumentError, if the index is out of bounds.
+  libtextclassifier3::StatusOr<int> GetResultInfoIndex(
+      int query_vector_index,
+      SearchSpecProto::EmbeddingQueryMetricType::Code metric_type) const {
+    int index =
+        query_vector_index * embedding_util::kEmbeddingQueryMetricTypes.size() +
+        (metric_type - embedding_util::kEmbeddingQueryMetricTypes[0]);
+    if (result_infos_ == nullptr || index < 0 || index >= result_infos_size_) {
+      return absl_ports::InvalidArgumentError(
+          "result_infos_ index out of bounds.");
+    }
+    return index;
+  }
 };
 
 }  // namespace lib
diff --git a/icing/index/embed/embedding-scorer.cc b/icing/index/embed/embedding-scorer.cc
index 0a3ed6c..64007d4 100644
--- a/icing/index/embed/embedding-scorer.cc
+++ b/icing/index/embed/embedding-scorer.cc
@@ -26,6 +26,11 @@
 #include "icing/index/embed/quantizer.h"
 #include "icing/proto/search.pb.h"
 
+#ifndef ICING_DISABLE_EIGEN
+#include <Eigen/Core>
+#include <Eigen/Dense>
+#endif  // ICING_DISABLE_EIGEN
+
 namespace icing {
 namespace lib {
 
@@ -85,6 +90,30 @@ float CalculateEuclideanDistance(int dimension, const T1* v1, const T2* v2,
   return std::sqrt(result);
 }
 
+#ifndef ICING_DISABLE_EIGEN
+// Returns a lazily-evaluated (due to the return type "auto") expression that
+// dequantizes the quantized vector.
+//
+// It requires that the scale factor is not 0. If it is 0, the caller should
+// handle the case specifically.
+inline auto DequantizeEigenVector(
+    const Quantizer& quantizer,
+    Eigen::Ref<const Eigen::VectorX<uint8_t>> quantized_vec) {
+  return (quantized_vec.cast<float>().array() / quantizer.scale_factor() +
+          quantizer.float_min())
+      .matrix();
+}
+
+float EigenCosine(Eigen::Ref<const Eigen::VectorXf> v1,
+                  Eigen::Ref<const Eigen::VectorXf> v2) {
+  float divisor = v1.norm() * v2.norm();
+  if (divisor == 0.0) {
+    return 0.0;
+  }
+  return v1.dot(v2) / divisor;
+}
+#endif  // ICING_DISABLE_EIGEN
+
 }  // namespace
 
 libtextclassifier3::StatusOr<std::unique_ptr<EmbeddingScorer>>
@@ -136,5 +165,103 @@ float EuclideanDistanceEmbeddingScorer::Score(
   return CalculateEuclideanDistance(dimension, v1, v2, quantizer);
 }
 
+#ifndef ICING_DISABLE_EIGEN
+float CosineEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                        const float* v2) const {
+  Eigen::Map<const Eigen::VectorXf> vec1(v1, dimension);
+  Eigen::Map<const Eigen::VectorXf> vec2(v2, dimension);
+  return EigenCosine(vec1, vec2);
+}
+
+float DotProductEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                            const float* v2) const {
+  Eigen::Map<const Eigen::VectorXf> vec1(v1, dimension);
+  Eigen::Map<const Eigen::VectorXf> vec2(v2, dimension);
+  return vec1.dot(vec2);
+}
+
+float EuclideanDistanceEmbeddingScorer::EigenScore(int dimension,
+                                                   const float* v1,
+                                                   const float* v2) const {
+  Eigen::Map<const Eigen::VectorXf> vec1(v1, dimension);
+  Eigen::Map<const Eigen::VectorXf> vec2(v2, dimension);
+  return (vec1 - vec2).norm();
+}
+
+float CosineEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                        const uint8_t* v2,
+                                        const Quantizer& quantizer) const {
+  Eigen::Map<const Eigen::VectorXf> vec1(v1, dimension);
+  Eigen::Map<const Eigen::Matrix<uint8_t, Eigen::Dynamic, 1>> vec2(v2,
+                                                                   dimension);
+  if (quantizer.scale_factor() == 0.0) {
+    return EigenCosine(
+        vec1, Eigen::VectorXf::Constant(dimension, quantizer.float_min()));
+  }
+  return EigenCosine(vec1, DequantizeEigenVector(quantizer, vec2));
+}
+
+float DotProductEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                            const uint8_t* v2,
+                                            const Quantizer& quantizer) const {
+  Eigen::Map<const Eigen::VectorXf> vec1(v1, dimension);
+  Eigen::Map<const Eigen::Matrix<uint8_t, Eigen::Dynamic, 1>> vec2(v2,
+                                                                   dimension);
+  if (quantizer.scale_factor() == 0.0) {
+    return vec1.dot(
+        Eigen::VectorXf::Constant(dimension, quantizer.float_min()));
+  }
+  return vec1.dot(DequantizeEigenVector(quantizer, vec2));
+}
+
+float EuclideanDistanceEmbeddingScorer::EigenScore(
+    int dimension, const float* v1, const uint8_t* v2,
+    const Quantizer& quantizer) const {
+  Eigen::Map<const Eigen::VectorXf> vec1(v1, dimension);
+  Eigen::Map<const Eigen::Matrix<uint8_t, Eigen::Dynamic, 1>> vec2(v2,
+                                                                   dimension);
+  if (quantizer.scale_factor() == 0.0) {
+    return (vec1.array() - quantizer.float_min()).matrix().norm();
+  }
+  return (vec1 - DequantizeEigenVector(quantizer, vec2)).norm();
+}
+#else   // ICING_DISABLE_EIGEN
+// If Eigen is disabled, just fall back to the regular Score() function.
+
+float CosineEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                        const float* v2) const {
+  return Score(dimension, v1, v2);
+}
+
+float DotProductEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                            const float* v2) const {
+  return Score(dimension, v1, v2);
+}
+
+float EuclideanDistanceEmbeddingScorer::EigenScore(int dimension,
+                                                   const float* v1,
+                                                   const float* v2) const {
+  return Score(dimension, v1, v2);
+}
+
+float CosineEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                        const uint8_t* v2,
+                                        const Quantizer& quantizer) const {
+  return Score(dimension, v1, v2, quantizer);
+}
+
+float DotProductEmbeddingScorer::EigenScore(int dimension, const float* v1,
+                                            const uint8_t* v2,
+                                            const Quantizer& quantizer) const {
+  return Score(dimension, v1, v2, quantizer);
+}
+
+float EuclideanDistanceEmbeddingScorer::EigenScore(
+    int dimension, const float* v1, const uint8_t* v2,
+    const Quantizer& quantizer) const {
+  return Score(dimension, v1, v2, quantizer);
+}
+#endif  // ICING_DISABLE_EIGEN
+
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/index/embed/embedding-scorer.h b/icing/index/embed/embedding-scorer.h
index b0e0f75..403616a 100644
--- a/icing/index/embed/embedding-scorer.h
+++ b/icing/index/embed/embedding-scorer.h
@@ -35,6 +35,11 @@ class EmbeddingScorer {
   virtual float Score(int dimension, const float* v1, const uint8_t* v2,
                       const Quantizer& quantizer) const = 0;
 
+  virtual float EigenScore(int dimension, const float* v1,
+                           const float* v2) const = 0;
+  virtual float EigenScore(int dimension, const float* v1, const uint8_t* v2,
+                           const Quantizer& quantizer) const = 0;
+
   virtual ~EmbeddingScorer() = default;
 };
 
@@ -43,6 +48,11 @@ class CosineEmbeddingScorer : public EmbeddingScorer {
   float Score(int dimension, const float* v1, const float* v2) const override;
   float Score(int dimension, const float* v1, const uint8_t* v2,
               const Quantizer& quantizer) const override;
+
+  float EigenScore(int dimension, const float* v1,
+                   const float* v2) const override;
+  float EigenScore(int dimension, const float* v1, const uint8_t* v2,
+                   const Quantizer& quantizer) const override;
 };
 
 class DotProductEmbeddingScorer : public EmbeddingScorer {
@@ -50,6 +60,11 @@ class DotProductEmbeddingScorer : public EmbeddingScorer {
   float Score(int dimension, const float* v1, const float* v2) const override;
   float Score(int dimension, const float* v1, const uint8_t* v2,
               const Quantizer& quantizer) const override;
+
+  float EigenScore(int dimension, const float* v1,
+                   const float* v2) const override;
+  float EigenScore(int dimension, const float* v1, const uint8_t* v2,
+                   const Quantizer& quantizer) const override;
 };
 
 class EuclideanDistanceEmbeddingScorer : public EmbeddingScorer {
@@ -57,6 +72,11 @@ class EuclideanDistanceEmbeddingScorer : public EmbeddingScorer {
   float Score(int dimension, const float* v1, const float* v2) const override;
   float Score(int dimension, const float* v1, const uint8_t* v2,
               const Quantizer& quantizer) const override;
+
+  float EigenScore(int dimension, const float* v1,
+                   const float* v2) const override;
+  float EigenScore(int dimension, const float* v1, const uint8_t* v2,
+                   const Quantizer& quantizer) const override;
 };
 
 }  // namespace lib
diff --git a/icing/index/embed/embedding-scorer_test.cc b/icing/index/embed/embedding-scorer_test.cc
index 162b969..035526d 100644
--- a/icing/index/embed/embedding-scorer_test.cc
+++ b/icing/index/embed/embedding-scorer_test.cc
@@ -14,8 +14,11 @@
 
 #include "icing/index/embed/embedding-scorer.h"
 
+#include <algorithm>
 #include <cstdint>
 #include <memory>
+#include <random>
+#include <tuple>
 #include <vector>
 
 #include "gtest/gtest.h"
@@ -120,6 +123,120 @@ TEST(EmbeddingScorerTest, Euclidean) {
               expected_euclidean, eps_quantized);
 }
 
+class EmbeddingScorerEigenTest
+    : public testing::TestWithParam<
+          std::tuple<SearchSpecProto::EmbeddingQueryMetricType::Code, int>> {
+ protected:
+  void SetUp() override {
+    metric_ = std::get<0>(GetParam());
+    dimension_ = std::get<1>(GetParam());
+    ICING_ASSERT_OK_AND_ASSIGN(embedding_scorer_,
+                               EmbeddingScorer::Create(metric_));
+
+    // Initialize random number generator
+    random_ = std::default_random_engine(std::random_device()());
+    dist_ = std::uniform_real_distribution<float>(-3.0f, 3.0f);
+  }
+
+  // Generates a random vector of the specified dimension.
+  std::vector<float> GenerateRandomVector() {
+    std::vector<float> vec(dimension_);
+    for (int i = 0; i < dimension_; ++i) {
+      vec[i] = dist_(random_);
+    }
+    return vec;
+  }
+
+  std::vector<float> GenerateRandomConstantVector() {
+    float value = dist_(random_);
+    std::vector<float> vec(dimension_, value);
+    return vec;
+  }
+
+  const int kNumRandomPairs = 1000;
+  const float kEps = 0.001f;
+
+  SearchSpecProto::EmbeddingQueryMetricType::Code metric_;
+  int dimension_;
+  std::unique_ptr<EmbeddingScorer> embedding_scorer_;
+  std::default_random_engine random_;
+  std::uniform_real_distribution<float> dist_;
+};
+
+// Test that the EigenScore function matches the Score function for a variety
+// of random vectors.
+TEST_P(EmbeddingScorerEigenTest, EigenScoreMatchesScore) {
+  for (int i = 0; i < kNumRandomPairs; ++i) {
+    std::vector<float> v1 = GenerateRandomVector();
+    std::vector<float> v2 = GenerateRandomVector();
+
+    // Compare scores
+    float score_val =
+        embedding_scorer_->Score(dimension_, v1.data(), v2.data());
+    float eigen_score_val =
+        embedding_scorer_->EigenScore(dimension_, v1.data(), v2.data());
+    ASSERT_NEAR(score_val, eigen_score_val, kEps);
+  }
+}
+
+// Test that the EigenScore function matches the Score function for a variety
+// of random quantized vectors.
+TEST_P(EmbeddingScorerEigenTest, EigenScoreMatchesScoreForQuantizedVectors) {
+  for (int i = 0; i < kNumRandomPairs; ++i) {
+    std::vector<float> v1 = GenerateRandomVector();
+    std::vector<float> v2 = GenerateRandomVector();
+
+    // Quantize v2
+    auto v2_minmax_pair = std::minmax_element(v2.begin(), v2.end());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        Quantizer quantizer,
+        Quantizer::Create(*v2_minmax_pair.first, *v2_minmax_pair.second));
+    std::vector<uint8_t> v2_quantized = QuantizeVector(v2, quantizer);
+
+    // Compare scores
+    float score_val = embedding_scorer_->Score(dimension_, v1.data(),
+                                               v2_quantized.data(), quantizer);
+    float eigen_score_val = embedding_scorer_->EigenScore(
+        dimension_, v1.data(), v2_quantized.data(), quantizer);
+    ASSERT_NEAR(score_val, eigen_score_val, kEps);
+  }
+}
+
+// Test that the EigenScore function matches the Score function for constant
+// vectors (i.e. all values are the same) to be quantized.
+TEST_P(EmbeddingScorerEigenTest,
+       EigenScoreMatchesScoreForQuantizedConstantVectors) {
+  for (int i = 0; i < kNumRandomPairs; ++i) {
+    std::vector<float> v1 = GenerateRandomVector();
+    std::vector<float> v2 = GenerateRandomConstantVector();
+
+    // Check that v2 is constant.
+    auto v2_minmax_pair = std::minmax_element(v2.begin(), v2.end());
+    ASSERT_TRUE(*v2_minmax_pair.first == *v2_minmax_pair.second);
+    // Quantize v2
+    ICING_ASSERT_OK_AND_ASSIGN(
+        Quantizer quantizer,
+        Quantizer::Create(*v2_minmax_pair.first, *v2_minmax_pair.second));
+    ASSERT_EQ(quantizer.scale_factor(), 0.f);
+    std::vector<uint8_t> v2_quantized = QuantizeVector(v2, quantizer);
+
+    // Compare scores
+    float score_val = embedding_scorer_->Score(dimension_, v1.data(),
+                                               v2_quantized.data(), quantizer);
+    float eigen_score_val = embedding_scorer_->EigenScore(
+        dimension_, v1.data(), v2_quantized.data(), quantizer);
+    ASSERT_NEAR(score_val, eigen_score_val, kEps);
+  }
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    EigenVsScoreComparison, EmbeddingScorerEigenTest,
+    testing::Combine(
+        testing::Values(SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT,
+                        SearchSpecProto::EmbeddingQueryMetricType::COSINE,
+                        SearchSpecProto::EmbeddingQueryMetricType::EUCLIDEAN),
+        testing::Values(128, 512, 768, 1024)));
+
 }  // namespace
 
 }  // namespace lib
diff --git a/icing/index/embed/quantizer.h b/icing/index/embed/quantizer.h
index 099c96d..7095263 100644
--- a/icing/index/embed/quantizer.h
+++ b/icing/index/embed/quantizer.h
@@ -74,6 +74,9 @@ class Quantizer {
     return (quantized / scale_factor_) + float_min_;
   }
 
+  float float_min() const { return float_min_; }
+  float scale_factor() const { return scale_factor_; }
+
  private:
   static constexpr uint8_t kMaxQuantizedValue =
       std::numeric_limits<uint8_t>::max();
diff --git a/icing/index/embedding-indexing-handler_test.cc b/icing/index/embedding-indexing-handler_test.cc
index f2352a5..9066fc5 100644
--- a/icing/index/embedding-indexing-handler_test.cc
+++ b/icing/index/embedding-indexing-handler_test.cc
@@ -31,6 +31,7 @@
 #include "icing/index/embed/embedding-index.h"
 #include "icing/index/embed/quantizer.h"
 #include "icing/index/hit/hit.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document_wrapper.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -198,14 +199,18 @@ class EmbeddingIndexingHandlerTest : public ::testing::Test {
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult doc_store_create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(doc_store_create_result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -271,11 +276,13 @@ TEST_F(EmbeddingIndexingHandlerTest, HandleEmbeddingSection) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
 
   ASSERT_THAT(embedding_index_->last_added_document_id(),
@@ -346,11 +353,13 @@ TEST_F(EmbeddingIndexingHandlerTest, EmbeddingShouldNotBeIndexedIfDisabled) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
 
   ASSERT_THAT(embedding_index_->last_added_document_id(),
@@ -403,11 +412,13 @@ TEST_F(EmbeddingIndexingHandlerTest, HandleNestedEmbeddingSection) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
 
   ASSERT_THAT(embedding_index_->last_added_document_id(),
@@ -482,9 +493,11 @@ TEST_F(EmbeddingIndexingHandlerTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
-  ICING_ASSERT_OK(document_store_->Put(tokenized_document.document()));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK(document_store_->Put(tokenized_document.document_wrapper()));
 
   static constexpr DocumentId kCurrentDocumentId = 3;
   embedding_index_->set_last_added_document_id(kCurrentDocumentId);
@@ -546,11 +559,13 @@ TEST_F(EmbeddingIndexingHandlerTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -627,19 +642,23 @@ TEST_F(EmbeddingIndexingHandlerTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document1,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document1)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document1)));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document2,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document2)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document2)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(tokenized_document1.document()));
+      document_store_->Put(tokenized_document1.document_wrapper()));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(tokenized_document2.document()));
+      document_store_->Put(tokenized_document2.document_wrapper()));
   DocumentId document_id2 = put_result2.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
diff --git a/icing/index/index-processor_benchmark.cc b/icing/index/index-processor_benchmark.cc
index 7adaac4..c0052bb 100644
--- a/icing/index/index-processor_benchmark.cc
+++ b/icing/index/index-processor_benchmark.cc
@@ -258,8 +258,9 @@ void BM_IndexDocumentWithOneProperty(benchmark::State& state) {
 
   DocumentProto input_document = CreateDocumentWithOneProperty(state.range(0));
   TokenizedDocument tokenized_document(std::move(
-      TokenizedDocument::Create(schema_store.get(), language_segmenter.get(),
-                                input_document)
+      TokenizedDocument::Create(
+          schema_store.get(), language_segmenter.get(),
+          /*current_time_ms=*/clock.GetSystemTimeMilliseconds(), input_document)
           .ValueOrDie()));
 
   DocumentId old_document_id = kInvalidDocumentId;
@@ -338,8 +339,9 @@ void BM_IndexDocumentWithTenProperties(benchmark::State& state) {
   DocumentProto input_document =
       CreateDocumentWithTenProperties(state.range(0));
   TokenizedDocument tokenized_document(std::move(
-      TokenizedDocument::Create(schema_store.get(), language_segmenter.get(),
-                                input_document)
+      TokenizedDocument::Create(
+          schema_store.get(), language_segmenter.get(),
+          /*current_time_ms=*/clock.GetSystemTimeMilliseconds(), input_document)
           .ValueOrDie()));
 
   DocumentId old_document_id = kInvalidDocumentId;
@@ -418,8 +420,9 @@ void BM_IndexDocumentWithDiacriticLetters(benchmark::State& state) {
   DocumentProto input_document =
       CreateDocumentWithDiacriticLetters(state.range(0));
   TokenizedDocument tokenized_document(std::move(
-      TokenizedDocument::Create(schema_store.get(), language_segmenter.get(),
-                                input_document)
+      TokenizedDocument::Create(
+          schema_store.get(), language_segmenter.get(),
+          /*current_time_ms=*/clock.GetSystemTimeMilliseconds(), input_document)
           .ValueOrDie()));
 
   DocumentId old_document_id = kInvalidDocumentId;
@@ -497,8 +500,9 @@ void BM_IndexDocumentWithHiragana(benchmark::State& state) {
 
   DocumentProto input_document = CreateDocumentWithHiragana(state.range(0));
   TokenizedDocument tokenized_document(std::move(
-      TokenizedDocument::Create(schema_store.get(), language_segmenter.get(),
-                                input_document)
+      TokenizedDocument::Create(
+          schema_store.get(), language_segmenter.get(),
+          /*current_time_ms=*/clock.GetSystemTimeMilliseconds(), input_document)
           .ValueOrDie()));
 
   DocumentId old_document_id = kInvalidDocumentId;
diff --git a/icing/index/index-processor_test.cc b/icing/index/index-processor_test.cc
index cba75f6..d42a84d 100644
--- a/icing/index/index-processor_test.cc
+++ b/icing/index/index-processor_test.cc
@@ -48,6 +48,7 @@
 #include "icing/join/qualified-id-join-indexing-handler.h"
 #include "icing/legacy/index/icing-filesystem.h"
 #include "icing/legacy/index/icing-mock-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -288,14 +289,18 @@ class IndexProcessorTest : public Test {
     ASSERT_TRUE(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(create_result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -393,8 +398,10 @@ TEST_F(IndexProcessorTest, NoTermMatchTypeContent) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -411,8 +418,10 @@ TEST_F(IndexProcessorTest, NoValidContent) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -429,8 +438,10 @@ TEST_F(IndexProcessorTest, OneDoc) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -466,8 +477,10 @@ TEST_F(IndexProcessorTest, MultipleDocs) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -489,8 +502,10 @@ TEST_F(IndexProcessorTest, MultipleDocs) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId1,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -551,8 +566,10 @@ TEST_F(IndexProcessorTest, DocWithNestedProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -580,8 +597,10 @@ TEST_F(IndexProcessorTest, DocWithRepeatedProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -618,8 +637,10 @@ TEST_F(IndexProcessorTest, HitBufferExhaustedTest) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -642,8 +663,10 @@ TEST_F(IndexProcessorTest, LexiconExhaustedTest) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -680,8 +703,10 @@ TEST_F(IndexProcessorTest, TooLongTokens) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -727,8 +752,10 @@ TEST_F(IndexProcessorTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(8));
 
   EXPECT_THAT(
@@ -773,8 +800,10 @@ TEST_F(IndexProcessorTest, NonPrefixedContentPrefixQuery) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -789,8 +818,10 @@ TEST_F(IndexProcessorTest, NonPrefixedContentPrefixQuery) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId1,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -817,8 +848,10 @@ TEST_F(IndexProcessorTest, TokenNormalization) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -833,8 +866,10 @@ TEST_F(IndexProcessorTest, TokenNormalization) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId1,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -864,8 +899,10 @@ TEST_F(IndexProcessorTest, OutOfOrderDocumentIds) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId1,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -888,8 +925,10 @@ TEST_F(IndexProcessorTest, OutOfOrderDocumentIds) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -946,8 +985,10 @@ TEST_F(IndexProcessorTest, OutOfOrderDocumentIdsInRecoveryMode) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor.IndexDocument(tokenized_document, kDocumentId1,
                                     /*old_document_id=*/kInvalidDocumentId),
@@ -971,8 +1012,10 @@ TEST_F(IndexProcessorTest, OutOfOrderDocumentIdsInRecoveryMode) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor.IndexDocument(tokenized_document, kDocumentId0,
                                     /*old_document_id=*/kInvalidDocumentId),
@@ -1013,8 +1056,10 @@ TEST_F(IndexProcessorTest, NonAsciiIndexing) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -1049,8 +1094,10 @@ TEST_F(IndexProcessorTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document_one));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document_one));
   EXPECT_THAT(
       index_processor_->IndexDocument(tokenized_document, kDocumentId0,
                                       /*old_document_id=*/kInvalidDocumentId),
@@ -1072,8 +1119,10 @@ TEST_F(IndexProcessorTest, IndexingDocAutomaticMerge) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   Index::Options options(index_dir_,
                          /*index_merge_size=*/document.ByteSizeLong() * 100,
                          /*lite_index_sort_at_indexing=*/true,
@@ -1140,8 +1189,10 @@ TEST_F(IndexProcessorTest, IndexingDocMergeFailureResets) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
 
   // 2. Recreate the index with the mock filesystem and a merge size that will
   // only allow one document to be added before requiring a merge.
@@ -1198,8 +1249,10 @@ TEST_F(IndexProcessorTest, ExactVerbatimProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(1));
 
   EXPECT_THAT(
@@ -1232,8 +1285,10 @@ TEST_F(IndexProcessorTest, PrefixVerbatimProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(1));
 
   EXPECT_THAT(
@@ -1268,8 +1323,10 @@ TEST_F(IndexProcessorTest, VerbatimPropertyDoesntMatchSubToken) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(1));
 
   EXPECT_THAT(
@@ -1301,8 +1358,10 @@ TEST_F(IndexProcessorTest, Rfc822PropertyExact) {
                                .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(7));
 
   EXPECT_THAT(
@@ -1352,8 +1411,10 @@ TEST_F(IndexProcessorTest, Rfc822PropertyExactShouldNotReturnPrefix) {
                                .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(7));
 
   EXPECT_THAT(
@@ -1384,8 +1445,10 @@ TEST_F(IndexProcessorTest, Rfc822PropertyPrefix) {
                                .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(7));
 
   EXPECT_THAT(
@@ -1437,8 +1500,10 @@ TEST_F(IndexProcessorTest, Rfc822PropertyNoMatch) {
                                .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(7));
 
   EXPECT_THAT(
@@ -1470,8 +1535,10 @@ TEST_F(IndexProcessorTest, ExactUrlProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(7));
 
   EXPECT_THAT(
@@ -1530,8 +1597,10 @@ TEST_F(IndexProcessorTest, ExactUrlPropertyDoesNotMatchPrefix) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(8));
 
   EXPECT_THAT(
@@ -1574,8 +1643,10 @@ TEST_F(IndexProcessorTest, PrefixUrlProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(7));
 
   EXPECT_THAT(
@@ -1628,8 +1699,10 @@ TEST_F(IndexProcessorTest, PrefixUrlPropertyNoMatch) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(8));
 
   EXPECT_THAT(
@@ -1682,8 +1755,10 @@ TEST_F(IndexProcessorTest, IndexableIntegerProperty) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   // Expected to have 1 integer section.
   EXPECT_THAT(tokenized_document.integer_sections(), SizeIs(1));
 
@@ -1714,8 +1789,10 @@ TEST_F(IndexProcessorTest, IndexableIntegerPropertyNoMatch) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          document));
   // Expected to have 1 integer section.
   EXPECT_THAT(tokenized_document.integer_sections(), SizeIs(1));
 
diff --git a/icing/index/integer-section-indexing-handler_test.cc b/icing/index/integer-section-indexing-handler_test.cc
index 0f70387..b1c7841 100644
--- a/icing/index/integer-section-indexing-handler_test.cc
+++ b/icing/index/integer-section-indexing-handler_test.cc
@@ -28,10 +28,12 @@
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
+#include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
 #include "icing/index/numeric/integer-index.h"
 #include "icing/index/numeric/numeric-index.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -169,14 +171,18 @@ class IntegerSectionIndexingHandlerTest : public ::testing::Test {
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult doc_store_create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(doc_store_create_result.document_store);
   }
 
@@ -232,11 +238,13 @@ TEST_F(IntegerSectionIndexingHandlerTest, HandleIntegerSection) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
 
   ASSERT_THAT(integer_index_->last_added_document_id(), Eq(kInvalidDocumentId));
   // Handle document.
@@ -284,11 +292,13 @@ TEST_F(IntegerSectionIndexingHandlerTest, HandleNestedIntegerSection) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(nested_document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(nested_document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
 
   ASSERT_THAT(integer_index_->last_added_document_id(), Eq(kInvalidDocumentId));
   // Handle nested_document.
@@ -349,11 +359,13 @@ TEST_F(IntegerSectionIndexingHandlerTest, HandleShouldSkipEmptyIntegerSection) {
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
 
   ASSERT_THAT(integer_index_->last_added_document_id(), Eq(kInvalidDocumentId));
   // Handle document. Index data should remain unchanged since there is no
@@ -392,9 +404,11 @@ TEST_F(IntegerSectionIndexingHandlerTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
-  ICING_ASSERT_OK(document_store_->Put(tokenized_document.document()));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK(document_store_->Put(tokenized_document.document_wrapper()));
 
   static constexpr DocumentId kCurrentDocumentId = 3;
   integer_index_->set_last_added_document_id(kCurrentDocumentId);
@@ -453,11 +467,13 @@ TEST_F(IntegerSectionIndexingHandlerTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<IntegerSectionIndexingHandler> handler,
@@ -531,18 +547,22 @@ TEST_F(IntegerSectionIndexingHandlerTest,
           .Build();
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document1,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document1)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document1)));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document2,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document2)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document2)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(tokenized_document1.document()));
+      document_store_->Put(tokenized_document1.document_wrapper()));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(tokenized_document2.document()));
+      document_store_->Put(tokenized_document2.document_wrapper()));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<IntegerSectionIndexingHandler> handler,
diff --git a/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc b/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc
index b783c48..058d13e 100644
--- a/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-by-uri_test.cc
@@ -26,6 +26,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/iterator/doc-hit-info-iterator-test-util.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/schema-builder.h"
@@ -36,6 +37,7 @@
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -66,14 +68,18 @@ class DocHitInfoIteratorByUriTest : public ::testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, test_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
   }
 
@@ -121,11 +127,16 @@ TEST_F(DocHitInfoIteratorByUriTest, MatchesSomeDocuments) {
                                 .SetKey("namespace", "email/3")
                                 .SetSchema("email")
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document2));
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result.new_document_id;
 
   // Create a search spec with uri filters that only match document1 and
@@ -158,12 +169,17 @@ TEST_F(DocHitInfoIteratorByUriTest, MatchesAllDocuments) {
                                 .SetKey("namespace", "email/3")
                                 .SetSchema("email")
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result.new_document_id;
 
   // Create a search spec with uri filters that match all documents.
@@ -196,12 +212,17 @@ TEST_F(DocHitInfoIteratorByUriTest, NonexistentUriIsOk) {
                                 .SetKey("namespace", "email/3")
                                 .SetSchema("email")
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result.new_document_id;
 
   // Create a search spec with a nonexistent uri in uri filters.
@@ -235,10 +256,15 @@ TEST_F(DocHitInfoIteratorByUriTest, AllNonexistentUriShouldReturnEmptyResults) {
                                 .SetKey("namespace", "email/3")
                                 .SetSchema("email")
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1));
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document2));
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
 
   // Create a search spec with all nonexistent uris.
   SearchSpecProto search_spec;
@@ -269,11 +295,16 @@ TEST_F(DocHitInfoIteratorByUriTest, MultipleNamespaces) {
                                 .SetKey("namespace2", "email/3")
                                 .SetSchema("email")
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document2));
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result.new_document_id;
 
   // Create a search spec with uri filters that match document1 and document3 in
@@ -314,14 +345,21 @@ TEST_F(DocHitInfoIteratorByUriTest, DuplicatedUriIsOk) {
                                 .SetKey("namespace", "email/4")
                                 .SetSchema("email")
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result.new_document_id;
 
   // Create a search spec with duplicated uri filters. The result document ids
diff --git a/icing/index/iterator/doc-hit-info-iterator-data-holder.h b/icing/index/iterator/doc-hit-info-iterator-data-holder.h
new file mode 100644
index 0000000..981fb9e
--- /dev/null
+++ b/icing/index/iterator/doc-hit-info-iterator-data-holder.h
@@ -0,0 +1,80 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_INDEX_ITERATOR_DOC_HIT_INFO_ITERATOR_DATA_HOLDER_H_
+#define ICING_INDEX_ITERATOR_DOC_HIT_INFO_ITERATOR_DATA_HOLDER_H_
+
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/schema/section.h"
+#include "icing/util/status-macros.h"
+
+namespace icing {
+namespace lib {
+
+// An iterator that simply takes ownership of an object.
+template <typename T>
+class DocHitInfoIteratorDataHolder : public DocHitInfoIterator {
+ public:
+  explicit DocHitInfoIteratorDataHolder(
+      std::unique_ptr<DocHitInfoIterator> delegate, std::unique_ptr<T> data)
+      : delegate_(std::move(delegate)), data_(std::move(data)) {}
+
+  libtextclassifier3::Status Advance() override {
+    auto result = delegate_->Advance();
+    doc_hit_info_ = delegate_->doc_hit_info();
+    return result;
+  }
+
+  libtextclassifier3::StatusOr<TrimmedNode> TrimRightMostNode() && override {
+    ICING_ASSIGN_OR_RETURN(TrimmedNode trimmed_delegate,
+                           std::move(*delegate_).TrimRightMostNode());
+    if (trimmed_delegate.iterator_ != nullptr) {
+      trimmed_delegate.iterator_ =
+          std::make_unique<DocHitInfoIteratorDataHolder>(
+              std::move(trimmed_delegate.iterator_), std::move(data_));
+    }
+    return trimmed_delegate;
+  }
+
+  void MapChildren(const ChildrenMapper& mapper) override {
+    delegate_ = mapper(std::move(delegate_));
+  }
+
+  CallStats GetCallStats() const override { return delegate_->GetCallStats(); }
+
+  std::string ToString() const override { return delegate_->ToString(); }
+
+  void PopulateMatchedTermsStats(
+      std::vector<TermMatchInfo>* matched_terms_stats,
+      SectionIdMask filtering_section_mask) const override {
+    return delegate_->PopulateMatchedTermsStats(matched_terms_stats,
+                                                filtering_section_mask);
+  }
+
+ private:
+  std::unique_ptr<DocHitInfoIterator> delegate_;
+  std::unique_ptr<T> data_;
+};
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_INDEX_ITERATOR_DOC_HIT_INFO_ITERATOR_DATA_HOLDER_H_
diff --git a/icing/index/iterator/doc-hit-info-iterator-filter_test.cc b/icing/index/iterator/doc-hit-info-iterator-filter_test.cc
index 00cdb71..75e68f8 100644
--- a/icing/index/iterator/doc-hit-info-iterator-filter_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-filter_test.cc
@@ -32,6 +32,7 @@
 #include "icing/index/iterator/doc-hit-info-iterator-and.h"
 #include "icing/index/iterator/doc-hit-info-iterator-test-util.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/query/query-utils.h"
@@ -45,6 +46,7 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -64,6 +66,9 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
       PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+      PortableFileBackedProtoLog<
+          DocumentWrapper>::kDefaultCompressionThresholdBytes,
+      protobuf_ports::kDefaultMemLevel,
       /*initialize_stats=*/nullptr);
 }
 
@@ -120,7 +125,8 @@ class DocHitInfoIteratorDeletedFilterTest : public ::testing::Test {
 };
 
 TEST_F(DocHitInfoIteratorDeletedFilterTest, EmptyOriginalIterator) {
-  ICING_ASSERT_OK(document_store_->Put(test_document1_));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
 
   std::unique_ptr<DocHitInfoIterator> original_iterator_empty =
       std::make_unique<DocHitInfoIteratorDummy>();
@@ -133,14 +139,20 @@ TEST_F(DocHitInfoIteratorDeletedFilterTest, EmptyOriginalIterator) {
 }
 
 TEST_F(DocHitInfoIteratorDeletedFilterTest, DeletedDocumentsAreFiltered) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(test_document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document2_)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(test_document3_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document3_)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // Deletes test document 2
@@ -163,14 +175,20 @@ TEST_F(DocHitInfoIteratorDeletedFilterTest, DeletedDocumentsAreFiltered) {
 }
 
 TEST_F(DocHitInfoIteratorDeletedFilterTest, NonExistingDocumentsAreFiltered) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(test_document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document2_)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(test_document3_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document3_)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // Document ids 7, 8, 9 are not existing
@@ -316,8 +334,10 @@ TEST_F(DocHitInfoIteratorNamespaceFilterTest, EmptyOriginalIterator) {
 
 TEST_F(DocHitInfoIteratorNamespaceFilterTest,
        NonexistentNamespacesReturnsEmpty) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_namespace1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_)));
   DocumentId document_id1 = put_result1.new_document_id;
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
 
@@ -336,8 +356,10 @@ TEST_F(DocHitInfoIteratorNamespaceFilterTest,
 }
 
 TEST_F(DocHitInfoIteratorNamespaceFilterTest, NoNamespacesReturnsAll) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_namespace1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
@@ -357,14 +379,20 @@ TEST_F(DocHitInfoIteratorNamespaceFilterTest, NoNamespacesReturnsAll) {
 
 TEST_F(DocHitInfoIteratorNamespaceFilterTest,
        FilterOutExistingDocumentFromDifferentNamespace) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_namespace1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_namespace1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_namespace1_)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document1_namespace2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace2_)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1),
@@ -387,17 +415,25 @@ TEST_F(DocHitInfoIteratorNamespaceFilterTest,
 }
 
 TEST_F(DocHitInfoIteratorNamespaceFilterTest, FilterForMultipleNamespacesOk) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_namespace1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_namespace1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_namespace1_)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document1_namespace2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace2_)));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document1_namespace3_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace3_)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {
@@ -512,8 +548,10 @@ TEST_F(DocHitInfoIteratorSchemaTypeFilterTest, EmptyOriginalIterator) {
 
 TEST_F(DocHitInfoIteratorSchemaTypeFilterTest,
        NonexistentSchemaTypeReturnsEmpty) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_schema1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
 
@@ -532,8 +570,10 @@ TEST_F(DocHitInfoIteratorSchemaTypeFilterTest,
 }
 
 TEST_F(DocHitInfoIteratorSchemaTypeFilterTest, NoSchemaTypesReturnsAll) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_schema1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
@@ -553,11 +593,15 @@ TEST_F(DocHitInfoIteratorSchemaTypeFilterTest, NoSchemaTypesReturnsAll) {
 
 TEST_F(DocHitInfoIteratorSchemaTypeFilterTest,
        FilterOutExistingDocumentFromDifferentSchemaTypes) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_schema1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_schema2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_schema2_)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1),
@@ -578,14 +622,20 @@ TEST_F(DocHitInfoIteratorSchemaTypeFilterTest,
 }
 
 TEST_F(DocHitInfoIteratorSchemaTypeFilterTest, FilterForMultipleSchemaTypesOk) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_schema1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_schema2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_schema2_)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3_schema3_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document3_schema3_)));
   DocumentId document_id3 = put_result3.new_document_id;
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1),
                                            DocHitInfo(document_id2),
@@ -610,28 +660,34 @@ TEST_F(DocHitInfoIteratorSchemaTypeFilterTest, FilterForMultipleSchemaTypesOk) {
 TEST_F(DocHitInfoIteratorSchemaTypeFilterTest,
        FilterIsExactForSchemaTypePolymorphism) {
   // Add some irrelevant documents.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_schema1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_schema2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_schema2_)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Create a person document and an artist document, where the artist should be
   // able to be interpreted as a person by polymorphism.
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "person")
-                               .SetSchema("person")
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "person")
+              .SetSchema("person")
+              .Build())));
   DocumentId person_document_id = person_put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult artist_put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "artist")
-                               .SetSchema("artist")
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "artist")
+              .SetSchema("artist")
+              .Build())));
   DocumentId artist_document_id = artist_put_result.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {
@@ -669,27 +725,30 @@ TEST_F(DocHitInfoIteratorSchemaTypeFilterTest,
   // Create an email and a message document.
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "email")
-                               .SetSchema("email")
-                               .Build()));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "email")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = email_put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult message_put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "message")
-                               .SetSchema("message")
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "message")
+              .SetSchema("message")
+              .Build())));
   DocumentId message_document_id = message_put_result.new_document_id;
 
   // Create a emailMessage document, which the should be able to be interpreted
   // as both an email and a message by polymorphism.
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_message_put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "emailMessage")
-                               .SetSchema("emailMessage")
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "emailMessage")
+              .SetSchema("emailMessage")
+              .Build())));
   DocumentId email_message_document_id =
       email_message_put_result.new_document_id;
 
@@ -796,8 +855,9 @@ TEST_F(DocHitInfoIteratorExpirationFilterTest, TtlZeroIsntFilteredOut) {
                                .SetCreationTimestampMs(0)
                                .SetTtlMs(0)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
@@ -829,8 +889,9 @@ TEST_F(DocHitInfoIteratorExpirationFilterTest, BeforeTtlNotFilteredOut) {
                                .SetCreationTimestampMs(1)
                                .SetTtlMs(100)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
@@ -862,8 +923,9 @@ TEST_F(DocHitInfoIteratorExpirationFilterTest, EqualTtlFilteredOut) {
                                .SetCreationTimestampMs(50)
                                .SetTtlMs(100)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
@@ -896,8 +958,9 @@ TEST_F(DocHitInfoIteratorExpirationFilterTest, PastTtlFilteredOut) {
                                .SetCreationTimestampMs(50)
                                .SetTtlMs(100)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::vector<DocHitInfo> doc_hit_infos = {DocHitInfo(document_id1)};
@@ -1005,23 +1068,28 @@ TEST_F(DocHitInfoIteratorFilterTest, CombineAllFiltersOk) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store->Put(document1_namespace1_schema1_));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store->Put(document2_namespace1_schema1_));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(document2_namespace1_schema1_)));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store->Put(document3_namespace2_schema1_));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(document3_namespace2_schema1_)));
   DocumentId document_id3 = put_result3.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result4,
-      document_store->Put(document4_namespace1_schema2_));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(document4_namespace1_schema2_)));
   DocumentId document_id4 = put_result4.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result5,
-      document_store->Put(document5_namespace1_schema1_));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(document5_namespace1_schema1_)));
   DocumentId document_id5 = put_result5.new_document_id;
 
   // Deletes document2, causing it to be filtered out
@@ -1056,15 +1124,18 @@ TEST_F(DocHitInfoIteratorFilterTest, CombineAllFiltersOk) {
 TEST_F(DocHitInfoIteratorFilterTest, SectionIdMasksArePopulatedCorrectly) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(document1_namespace1_schema1_));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(document2_namespace1_schema1_));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_namespace1_schema1_)));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(document3_namespace2_schema1_));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document3_namespace2_schema1_)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   SectionIdMask section_id_mask1 = 0b01001001;  // hits in sections 0, 3, 6
@@ -1113,15 +1184,18 @@ TEST_F(DocHitInfoIteratorFilterTest, GetCallStats) {
 TEST_F(DocHitInfoIteratorFilterTest, TrimFilterIterator) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(document1_namespace1_schema1_));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document1_namespace1_schema1_)));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(document2_namespace1_schema1_));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document2_namespace1_schema1_)));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(document3_namespace2_schema1_));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document3_namespace2_schema1_)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // Build an interator tree like:
diff --git a/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc b/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc
index 3c29c1e..36c68af 100644
--- a/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-property-in-schema_test.cc
@@ -19,6 +19,7 @@
 #include <utility>
 #include <vector>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
@@ -29,6 +30,7 @@
 #include "icing/index/iterator/doc-hit-info-iterator-all-document-id.h"
 #include "icing/index/iterator/doc-hit-info-iterator-test-util.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/schema-builder.h"
@@ -40,6 +42,7 @@
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -100,14 +103,18 @@ class DocHitInfoIteratorPropertyInSchemaTest : public ::testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, test_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
   }
 
@@ -134,8 +141,9 @@ class DocHitInfoIteratorPropertyInSchemaTest : public ::testing::Test {
 TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
        AdvanceToDocumentWithIndexedProperty) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   auto original_iterator = std::make_unique<DocHitInfoIteratorAllDocumentId>(
@@ -155,8 +163,9 @@ TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
 TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
        AdvanceToDocumentWithUnindexedProperty) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   auto original_iterator = std::make_unique<DocHitInfoIteratorAllDocumentId>(
@@ -174,7 +183,8 @@ TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
 }
 
 TEST_F(DocHitInfoIteratorPropertyInSchemaTest, NoMatchWithUndefinedProperty) {
-  ICING_EXPECT_OK(document_store_->Put(document1_));
+  ICING_EXPECT_OK(
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
 
   auto original_iterator = std::make_unique<DocHitInfoIteratorAllDocumentId>(
       document_store_->num_documents());
@@ -189,8 +199,9 @@ TEST_F(DocHitInfoIteratorPropertyInSchemaTest, NoMatchWithUndefinedProperty) {
 TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
        CorrectlySetsSectionIdMasksAndPopulatesTermMatchInfo) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   // Arbitrary section ids for the documents in the DocHitInfoIterators.
@@ -252,11 +263,13 @@ TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
 
 TEST_F(DocHitInfoIteratorPropertyInSchemaTest,
        FindPropertyDefinedByMultipleTypes) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2_)));
   DocumentId document_id2 = put_result2.new_document_id;
   auto original_iterator = std::make_unique<DocHitInfoIteratorAllDocumentId>(
       document_store_->num_documents());
diff --git a/icing/index/iterator/doc-hit-info-iterator-section-restrict.cc b/icing/index/iterator/doc-hit-info-iterator-section-restrict.cc
index f6e440d..d8e1c99 100644
--- a/icing/index/iterator/doc-hit-info-iterator-section-restrict.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-section-restrict.cc
@@ -21,7 +21,6 @@
 #include <string_view>
 #include <unordered_map>
 #include <utility>
-#include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
@@ -29,12 +28,12 @@
 #include "icing/absl_ports/str_cat.h"
 #include "icing/absl_ports/str_join.h"
 #include "icing/index/hit/doc-hit-info.h"
+#include "icing/index/iterator/doc-hit-info-iterator-data-holder.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
 #include "icing/index/iterator/section-restrict-data.h"
 #include "icing/proto/search.pb.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
-#include "icing/store/document-filter-data.h"
 #include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/util/status-macros.h"
@@ -42,51 +41,6 @@
 namespace icing {
 namespace lib {
 
-// An iterator that simply takes ownership of SectionRestrictData.
-class SectionRestrictDataHolderIterator : public DocHitInfoIterator {
- public:
-  explicit SectionRestrictDataHolderIterator(
-      std::unique_ptr<DocHitInfoIterator> delegate,
-      std::unique_ptr<SectionRestrictData> data)
-      : delegate_(std::move(delegate)), data_(std::move(data)) {}
-
-  libtextclassifier3::Status Advance() override {
-    auto result = delegate_->Advance();
-    doc_hit_info_ = delegate_->doc_hit_info();
-    return result;
-  }
-
-  libtextclassifier3::StatusOr<TrimmedNode> TrimRightMostNode() && override {
-    ICING_ASSIGN_OR_RETURN(TrimmedNode trimmed_delegate,
-                           std::move(*delegate_).TrimRightMostNode());
-    if (trimmed_delegate.iterator_ != nullptr) {
-      trimmed_delegate.iterator_ =
-          std::make_unique<SectionRestrictDataHolderIterator>(
-              std::move(trimmed_delegate.iterator_), std::move(data_));
-    }
-    return trimmed_delegate;
-  }
-
-  void MapChildren(const ChildrenMapper& mapper) override {
-    delegate_ = mapper(std::move(delegate_));
-  }
-
-  CallStats GetCallStats() const override { return delegate_->GetCallStats(); }
-
-  std::string ToString() const override { return delegate_->ToString(); }
-
-  void PopulateMatchedTermsStats(
-      std::vector<TermMatchInfo>* matched_terms_stats,
-      SectionIdMask filtering_section_mask) const override {
-    return delegate_->PopulateMatchedTermsStats(matched_terms_stats,
-                                                filtering_section_mask);
-  }
-
- private:
-  std::unique_ptr<DocHitInfoIterator> delegate_;
-  std::unique_ptr<SectionRestrictData> data_;
-};
-
 DocHitInfoIteratorSectionRestrict::DocHitInfoIteratorSectionRestrict(
     std::unique_ptr<DocHitInfoIterator> delegate, SectionRestrictData* data)
     : delegate_(std::move(delegate)), data_(data) {}
@@ -103,8 +57,8 @@ DocHitInfoIteratorSectionRestrict::ApplyRestrictions(
       document_store, schema_store, current_time_ms, type_property_filters);
   std::unique_ptr<DocHitInfoIterator> result =
       ApplyRestrictions(std::move(iterator), data.get());
-  return std::make_unique<SectionRestrictDataHolderIterator>(std::move(result),
-                                                             std::move(data));
+  return std::make_unique<DocHitInfoIteratorDataHolder<SectionRestrictData>>(
+      std::move(result), std::move(data));
 }
 
 std::unique_ptr<DocHitInfoIterator>
@@ -124,8 +78,8 @@ DocHitInfoIteratorSectionRestrict::ApplyRestrictions(
       document_store, schema_store, current_time_ms, type_property_filters);
   std::unique_ptr<DocHitInfoIterator> result =
       ApplyRestrictions(std::move(iterator), data.get());
-  return std::make_unique<SectionRestrictDataHolderIterator>(std::move(result),
-                                                             std::move(data));
+  return std::make_unique<DocHitInfoIteratorDataHolder<SectionRestrictData>>(
+      std::move(result), std::move(data));
 }
 
 std::unique_ptr<DocHitInfoIterator>
diff --git a/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc b/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc
index a97f2a8..c955f52 100644
--- a/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc
+++ b/icing/index/iterator/doc-hit-info-iterator-section-restrict_test.cc
@@ -17,6 +17,7 @@
 #include <memory>
 #include <set>
 #include <string>
+#include <unordered_map>
 #include <utility>
 #include <vector>
 
@@ -27,9 +28,11 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/hit/doc-hit-info.h"
+#include "icing/index/hit/hit.h"
 #include "icing/index/iterator/doc-hit-info-iterator-and.h"
 #include "icing/index/iterator/doc-hit-info-iterator-test-util.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/term.pb.h"
@@ -42,6 +45,7 @@
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -105,14 +109,18 @@ class DocHitInfoIteratorSectionRestrictTest : public ::testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, test_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
   }
 
@@ -139,8 +147,9 @@ class DocHitInfoIteratorSectionRestrictTest : public ::testing::Test {
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        PopulateMatchedTermsStats_IncludesHitWithMatchingSection) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   // Arbitrary section ids for the documents in the DocHitInfoIterators.
@@ -205,8 +214,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest, EmptyOriginalIterator) {
 
 TEST_F(DocHitInfoIteratorSectionRestrictTest, IncludesHitWithMatchingSection) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   SectionIdMask section_id_mask = 1U << kIndexedSectionId0;
@@ -233,8 +243,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest, IncludesHitWithMatchingSection) {
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        IncludesHitWithMultipleMatchingSectionsWithMultipleSectionRestricts) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   SectionIdMask section_id_mask = 1U << kIndexedSectionId0;
@@ -265,8 +276,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest,
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        IncludesHitWithMultipleMatchingSectionsWithSingleSectionRestrict) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   SectionIdMask section_id_mask = 1U << kIndexedSectionId0;
@@ -296,8 +308,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest,
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        IncludesHitWithSingleMatchingSectionsWithMultiSectionRestrict) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   SectionIdMask section_id_mask = 1U << kIndexedSectionId1;
@@ -346,8 +359,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest, NoMatchingDocumentFilterData) {
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        DoesntIncludeHitWithWrongSectionName) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   SectionIdMask section_id_mask = 1U << kIndexedSectionId0;
@@ -376,8 +390,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest,
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        DoesntIncludeHitWithNoSectionIds) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create a hit that doesn't exist in any sections, so it shouldn't match any
@@ -404,8 +419,9 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest,
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        DoesntIncludeHitWithDifferentSectionId) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id = put_result.new_document_id;
 
   // Anything that's not 0, which is the indexed property
@@ -455,14 +471,17 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest, GetCallStats) {
 TEST_F(DocHitInfoIteratorSectionRestrictTest,
        TrimSectionRestrictIterator_TwoLayer) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2_)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3_)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // 0 is the indexed property
@@ -516,11 +535,13 @@ TEST_F(DocHitInfoIteratorSectionRestrictTest,
 
 TEST_F(DocHitInfoIteratorSectionRestrictTest, TrimSectionRestrictIterator) {
   // Populate the DocumentStore's FilterCache with this document's data
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1_)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2_)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 0 is the indexed property
diff --git a/icing/index/lite/lite-index-header.h b/icing/index/lite/lite-index-header.h
index 1aba130..1677d69 100644
--- a/icing/index/lite/lite-index-header.h
+++ b/icing/index/lite/lite-index-header.h
@@ -22,6 +22,7 @@
 #include "icing/legacy/core/icing-string-util.h"
 #include "icing/store/document-id.h"
 #include "icing/util/crc32.h"
+#include "icing/util/logging.h"
 
 namespace icing {
 namespace lib {
@@ -55,7 +56,7 @@ class LiteIndex_Header {
 class LiteIndex_HeaderImpl : public LiteIndex_Header {
  public:
   struct HeaderData {
-    static const uint32_t kMagic = 0xC2EAD682;
+    static constexpr uint32_t kMagic = 0xC2EAD682;
 
     uint32_t lite_index_crc;
     uint32_t magic;
@@ -74,6 +75,10 @@ class LiteIndex_HeaderImpl : public LiteIndex_Header {
   explicit LiteIndex_HeaderImpl(HeaderData *hdr) : hdr_(hdr) {}
 
   bool check_magic() const override {
+    if (hdr_->magic != HeaderData::kMagic) {
+      ICING_LOG(ERROR) << "Invalid header magic for LiteIndex. Expected: "
+                       << HeaderData::kMagic << ", actual: " << hdr_->magic;
+    }
     return hdr_->magic == HeaderData::kMagic;
   }
 
diff --git a/icing/index/lite/lite-index.cc b/icing/index/lite/lite-index.cc
index 3862206..c683016 100644
--- a/icing/index/lite/lite-index.cc
+++ b/icing/index/lite/lite-index.cc
@@ -195,7 +195,10 @@ libtextclassifier3::Status LiteIndex::Initialize() {
 
     // Check integrity.
     if (!header_->check_magic()) {
-      status = absl_ports::InternalError("Lite index header magic mismatch");
+      ICING_LOG(ERROR) << "Invalid header magic for LiteIndex "
+                       << options_.filename_base;
+      status = absl_ports::InternalError(absl_ports::StrCat(
+          "Invalid header magic for LiteIndex: ", options_.filename_base));
       goto error;
     }
     Crc32 expected_crc(header_->lite_index_crc());
diff --git a/icing/index/numeric/integer-index-storage.cc b/icing/index/numeric/integer-index-storage.cc
index 9566737..033c64a 100644
--- a/icing/index/numeric/integer-index-storage.cc
+++ b/icing/index/numeric/integer-index-storage.cc
@@ -46,6 +46,7 @@
 #include "icing/schema/section.h"
 #include "icing/store/document-id.h"
 #include "icing/util/crc32.h"
+#include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -928,7 +929,13 @@ IntegerIndexStorage::InitializeExistingFiles(
   // Validate other values of info and options.
   // Magic should be consistent with the codebase.
   if (integer_index_storage->info().magic != Info::kMagic) {
-    return absl_ports::FailedPreconditionError("Incorrect magic value");
+    ICING_LOG(ERROR) << "Invalid header magic for IntegerIndexStorage "
+                     << integer_index_storage->working_path_
+                     << ". Expected: " << Info::kMagic
+                     << ", actual: " << integer_index_storage->info().magic;
+    return absl_ports::FailedPreconditionError(
+        absl_ports::StrCat("Invalid header magic for IntegerIndexStorage: ",
+                           integer_index_storage->working_path_));
   }
 
   return integer_index_storage;
diff --git a/icing/index/numeric/integer-index-storage_test.cc b/icing/index/numeric/integer-index-storage_test.cc
index 62c8e87..01cef0b 100644
--- a/icing/index/numeric/integer-index-storage_test.cc
+++ b/icing/index/numeric/integer-index-storage_test.cc
@@ -309,15 +309,17 @@ TEST_P(IntegerIndexStorageTest, InitializeNewFiles) {
 
   // Check info section
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                IntegerIndexStorage::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                IntegerIndexStorage::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
   EXPECT_THAT(info.magic, Eq(Info::kMagic));
   EXPECT_THAT(info.num_data, Eq(0));
 
   // Check crcs section
   Crcs crcs;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                IntegerIndexStorage::kCrcsMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                IntegerIndexStorage::kCrcsMetadataFileOffset),
+              Eq(sizeof(Crcs)));
   // # of elements in sorted_buckets should be 1, so it should have non-zero
   // all storages crc value.
   EXPECT_THAT(crcs.component_crcs.storages_crc, Ne(0));
@@ -518,8 +520,9 @@ TEST_P(IntegerIndexStorageTest,
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Crcs crcs;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                IntegerIndexStorage::kCrcsMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                IntegerIndexStorage::kCrcsMetadataFileOffset),
+              Eq(sizeof(Crcs)));
 
   // Manually corrupt all_crc
   crcs.all_crc += kCorruptedValueOffset;
@@ -567,8 +570,9 @@ TEST_P(IntegerIndexStorageTest,
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                IntegerIndexStorage::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                IntegerIndexStorage::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
 
   // Modify info, but don't update the checksum. This would be similar to
   // corruption of info.
diff --git a/icing/index/numeric/integer-index.cc b/icing/index/numeric/integer-index.cc
index 62fb215..36148d4 100644
--- a/icing/index/numeric/integer-index.cc
+++ b/icing/index/numeric/integer-index.cc
@@ -35,6 +35,7 @@
 #include "icing/index/numeric/posting-list-integer-index-serializer.h"
 #include "icing/store/document-id.h"
 #include "icing/util/crc32.h"
+#include "icing/util/logging.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -494,7 +495,13 @@ IntegerIndex::InitializeExistingFiles(
 
   // Validate magic.
   if (integer_index->info().magic != Info::kMagic) {
-    return absl_ports::FailedPreconditionError("Incorrect magic value");
+    ICING_LOG(ERROR) << "Invalid header magic for IntegerIndex "
+                     << integer_index->working_path_
+                     << ". Expected: " << Info::kMagic
+                     << ", actual: " << integer_index->info().magic;
+    return absl_ports::FailedPreconditionError(
+        absl_ports::StrCat("Invalid header magic for IntegerIndex: ",
+                           integer_index->working_path_));
   }
 
   // If num_data_threshold_for_bucket_split mismatches, then return error to let
diff --git a/icing/index/numeric/integer-index_test.cc b/icing/index/numeric/integer-index_test.cc
index 619abc4..5b0d6c7 100644
--- a/icing/index/numeric/integer-index_test.cc
+++ b/icing/index/numeric/integer-index_test.cc
@@ -20,15 +20,20 @@
 #include <string>
 #include <string_view>
 #include <type_traits>
+#include <unordered_set>
+#include <utility>
 #include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/absl_ports/str_cat.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
+#include "icing/file/persistent-storage.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
@@ -36,6 +41,7 @@
 #include "icing/index/numeric/integer-index-storage.h"
 #include "icing/index/numeric/numeric-index.h"
 #include "icing/index/numeric/posting-list-integer-index-serializer.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/schema-builder.h"
@@ -46,6 +52,10 @@
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/clock.h"
+#include "icing/util/crc32.h"
+#include "icing/util/document-util.h"
+#include "icing/util/status-macros.h"
 
 namespace icing {
 namespace lib {
@@ -92,14 +102,18 @@ class NumericIndexIntegerTest : public ::testing::Test {
         filesystem_.CreateDirectoryRecursively(document_store_dir.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult doc_store_create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir, &clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir, &clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(doc_store_create_result.document_store);
   }
 
@@ -167,14 +181,18 @@ class NumericIndexIntegerTest : public ::testing::Test {
 
     ICING_ASSIGN_OR_RETURN(
         DocumentStore::CreateResult doc_store_create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir, &clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir, &clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(doc_store_create_result.document_store);
     return std::move(doc_store_optimize_result.document_id_old_to_new);
   }
@@ -413,49 +431,51 @@ TYPED_TEST(NumericIndexIntegerTest, WildcardStorageQuery) {
   // Put 11 docs of "TypeA" into the document store.
   DocumentProto doc =
       DocumentBuilder().SetKey("ns1", "uri0").SetSchema("TypeA").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri3").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri4").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri5").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri6").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri7").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri8").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri9").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri10").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri1").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri2").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri3").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri4").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri5").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri6").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri7").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri8").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri9").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri10").Build())));
 
   // Put 5 docs of "TypeB" into the document store.
   doc = DocumentBuilder(doc).SetUri("uri11").SetSchema("TypeB").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri12").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri13").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri14").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri15").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri16").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri17").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri18").Build()));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri19").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri20").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri12").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri13").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri14").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri15").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri16").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri17").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri18").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri19").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri20").Build())));
 
   // Ids are assigned alphabetically, so the property ids are:
   // TypeA.desiredProperty = 0
@@ -1180,8 +1200,9 @@ TEST_P(IntegerIndexTest, InitializeNewFiles) {
 
   // Check info section
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                IntegerIndex::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                IntegerIndex::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
   EXPECT_THAT(info.magic, Eq(Info::kMagic));
   EXPECT_THAT(info.last_added_document_id, Eq(kInvalidDocumentId));
   EXPECT_THAT(info.num_data_threshold_for_bucket_split,
@@ -1189,8 +1210,9 @@ TEST_P(IntegerIndexTest, InitializeNewFiles) {
 
   // Check crcs section
   Crcs crcs;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                IntegerIndex::kCrcsMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                IntegerIndex::kCrcsMetadataFileOffset),
+              Eq(sizeof(Crcs)));
   // There are no storages initially, so storages_crc should be 0.
   EXPECT_THAT(crcs.component_crcs.storages_crc, Eq(0));
   EXPECT_THAT(crcs.component_crcs.info_crc,
@@ -1376,8 +1398,9 @@ TEST_P(IntegerIndexTest, InitializeExistingFilesWithWrongAllCrcShouldFail) {
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Crcs crcs;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
-                                IntegerIndex::kCrcsMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &crcs, sizeof(Crcs),
+                                IntegerIndex::kCrcsMetadataFileOffset),
+              Eq(sizeof(Crcs)));
 
   // Manually corrupt all_crc
   crcs.all_crc += kCorruptedValueOffset;
@@ -1425,8 +1448,9 @@ TEST_P(IntegerIndexTest, InitializeExistingFilesWithCorruptedInfoShouldFail) {
   ASSERT_TRUE(metadata_sfd.is_valid());
 
   Info info;
-  ASSERT_TRUE(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
-                                IntegerIndex::kInfoMetadataFileOffset));
+  ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), &info, sizeof(Info),
+                                IntegerIndex::kInfoMetadataFileOffset),
+              Eq(sizeof(Info)));
 
   // Modify info, but don't update the checksum. This would be similar to
   // corruption of info.
@@ -1656,49 +1680,51 @@ TEST_P(IntegerIndexTest, WildcardStoragePersistenceQuery) {
   // Put 11 docs of "TypeA" into the document store.
   DocumentProto doc =
       DocumentBuilder().SetKey("ns1", "uri0").SetSchema("TypeA").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri3").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri4").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri5").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri6").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri7").Build()));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri8").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri9").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri10").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri1").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri2").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri3").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri4").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri5").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri6").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri7").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri8").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri9").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri10").Build())));
 
   // Put 10 docs of "TypeB" into the document store.
   doc = DocumentBuilder(doc).SetUri("uri11").SetSchema("TypeB").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri12").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri13").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri14").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri15").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri16").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri17").Build()));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri18").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri19").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri20").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri12").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri13").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri14").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri15").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri16").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri17").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri18").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri19").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri20").Build())));
 
   {
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -2040,49 +2066,51 @@ TEST_P(IntegerIndexTest, WildcardStorageWorksAfterOptimize) {
   // Put 11 docs of "TypeA" into the document store.
   DocumentProto doc =
       DocumentBuilder().SetKey("ns1", "uri0").SetSchema("TypeA").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri3").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri4").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri5").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri6").Build()));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri7").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri8").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri9").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri10").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri1").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri2").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri3").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri4").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri5").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri6").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri7").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri8").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri9").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri10").Build())));
 
   // Put 10 docs of "TypeB" into the document store.
   doc = DocumentBuilder(doc).SetUri("uri11").SetSchema("TypeB").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri12").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri13").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri14").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri15").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri16").Build()));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri17").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri18").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri19").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri20").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri12").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri13").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri14").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri15").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri16").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri17").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri18").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri19").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri20").Build())));
 
   {
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -2330,27 +2358,28 @@ TEST_P(IntegerIndexTest, WildcardStorageAvailableIndicesAfterOptimize) {
   // Put 11 docs of "TypeA" into the document store.
   DocumentProto doc =
       DocumentBuilder().SetKey("ns1", "uri0").SetSchema("TypeA").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri3").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri4").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri5").Build()));
   ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri6").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri7").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri8").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri9").Build()));
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri10").Build()));
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri1").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri2").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri3").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri4").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri5").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri6").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri7").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri8").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri9").Build())));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri10").Build())));
 
   {
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -2446,7 +2475,8 @@ TEST_P(IntegerIndexTest, WildcardStorageAvailableIndicesAfterOptimize) {
   // Add a new doc (docid==5) and a hit for desiredProperty. This should still
   // be placed into the wildcard integer storage.
   doc = DocumentBuilder().SetKey("ns1", "uri11").SetSchema("TypeA").Build();
-  ICING_ASSERT_OK(this->doc_store_->Put(doc));
+  ICING_ASSERT_OK(
+      this->doc_store_->Put(document_util::CreateDocumentWrapper(doc)));
   Index(integer_index.get(), desired_property, /*document_id=*/5,
         typea_desired_prop_id, /*keys=*/{12});
   EXPECT_THAT(integer_index->num_property_indices(), Eq(1));
@@ -2458,8 +2488,8 @@ TEST_P(IntegerIndexTest, WildcardStorageAvailableIndicesAfterOptimize) {
 
   // Add a new doc (docid==6) and a hit for undesiredProperty. This should still
   // be placed into the wildcard integer storage.
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri12").Build()));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri12").Build())));
   Index(integer_index.get(), undesired_property, /*document_id=*/6,
         typea_undesired_prop_id, /*keys=*/{3});
   EXPECT_THAT(integer_index->num_property_indices(), Eq(1));
@@ -2472,8 +2502,8 @@ TEST_P(IntegerIndexTest, WildcardStorageAvailableIndicesAfterOptimize) {
 
   // Add a new doc (docid==7) and a hit for otherProperty1. This should be given
   // its own individual storage.
-  ICING_ASSERT_OK(
-      this->doc_store_->Put(DocumentBuilder(doc).SetUri("uri13").Build()));
+  ICING_ASSERT_OK(this->doc_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder(doc).SetUri("uri13").Build())));
   Index(integer_index.get(), other_property_1, /*document_id=*/7,
         typea_other1_prop_id, /*keys=*/{3});
   EXPECT_THAT(integer_index->num_property_indices(), Eq(2));
diff --git a/icing/index/property-existence-indexing-handler.cc b/icing/index/property-existence-indexing-handler.cc
index 0b4d87f..408897a 100644
--- a/icing/index/property-existence-indexing-handler.cc
+++ b/icing/index/property-existence-indexing-handler.cc
@@ -92,7 +92,8 @@ libtextclassifier3::Status PropertyExistenceIndexingHandler::Handle(
       index_.Edit(document_id, /*section_id=*/0, /*namespace_id=*/0);
   std::unordered_set<std::string> meta_tokens;
   ConstructPropertyExistenceMetaToken(
-      /*current_path=*/"", tokenized_document.document(), meta_tokens);
+      /*current_path=*/"", tokenized_document.document_wrapper().document(),
+      meta_tokens);
   for (const std::string& meta_token : meta_tokens) {
     status = editor.BufferTerm(meta_token, TermMatchType::EXACT_ONLY);
     if (!status.ok()) {
diff --git a/icing/index/property-existence-indexing-handler_test.cc b/icing/index/property-existence-indexing-handler_test.cc
index 8905bc5..f9c7715 100644
--- a/icing/index/property-existence-indexing-handler_test.cc
+++ b/icing/index/property-existence-indexing-handler_test.cc
@@ -35,6 +35,7 @@
 #include "icing/index/index.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/document_wrapper.pb.h"
@@ -160,14 +161,18 @@ class PropertyExistenceIndexingHandlerTest : public Test {
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult doc_store_create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(doc_store_create_result.document_store);
   }
 
@@ -249,27 +254,33 @@ TEST_F(PropertyExistenceIndexingHandlerTest, HandlePropertyExistence) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document0,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document0)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document0)));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document1,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document1)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document1)));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document2,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document2)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document2)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result0,
-      document_store_->Put(tokenized_document0.document()));
+      document_store_->Put(tokenized_document0.document_wrapper()));
   DocumentId document_id0 = put_result0.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(tokenized_document1.document()));
+      document_store_->Put(tokenized_document1.document_wrapper()));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(tokenized_document2.document()));
+      document_store_->Put(tokenized_document2.document_wrapper()));
   DocumentId document_id2 = put_result2.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -380,11 +391,13 @@ TEST_F(PropertyExistenceIndexingHandlerTest, HandleNestedPropertyExistence) {
   // Handle root_document
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_root_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(root_document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(root_document)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_root_document.document()));
+      document_store_->Put(tokenized_root_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<PropertyExistenceIndexingHandler> handler,
@@ -486,27 +499,33 @@ TEST_F(PropertyExistenceIndexingHandlerTest, SingleEmptyStringIsNonExisting) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document0,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document0)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document0)));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document1,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document1)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document1)));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document2,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document2)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document2)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result0,
-      document_store_->Put(tokenized_document0.document()));
+      document_store_->Put(tokenized_document0.document_wrapper()));
   DocumentId document_id0 = put_result0.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(tokenized_document1.document()));
+      document_store_->Put(tokenized_document1.document_wrapper()));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(tokenized_document2.document()));
+      document_store_->Put(tokenized_document2.document_wrapper()));
   DocumentId document_id2 = put_result2.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
diff --git a/icing/index/term-indexing-handler_test.cc b/icing/index/term-indexing-handler_test.cc
index 577e80b..e5d2204 100644
--- a/icing/index/term-indexing-handler_test.cc
+++ b/icing/index/term-indexing-handler_test.cc
@@ -39,6 +39,7 @@
 #include "icing/index/iterator/doc-hit-info-iterator.h"
 #include "icing/index/property-existence-indexing-handler.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/document_wrapper.pb.h"
@@ -176,14 +177,18 @@ class TermIndexingHandlerTest : public Test {
         filesystem_.CreateDirectoryRecursively(document_store_dir_.c_str()));
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult doc_store_create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(doc_store_create_result.document_store);
   }
 
@@ -261,12 +266,14 @@ TEST_F(TermIndexingHandlerTest, HandleBothStringSectionAndPropertyExistence) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
 
   EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
@@ -326,12 +333,14 @@ TEST_F(TermIndexingHandlerTest,
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(tokenized_document.document()));
+      document_store_->Put(tokenized_document.document_wrapper()));
   DocumentId document_id = put_result.new_document_id;
 
   EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
@@ -405,29 +414,35 @@ TEST_F(TermIndexingHandlerTest, HandleIntoLiteIndex_sortInIndexingTriggered) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document0,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document0)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document0)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result0,
-      document_store_->Put(tokenized_document0.document()));
+      document_store_->Put(tokenized_document0.document_wrapper()));
   DocumentId document_id0 = put_result0.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document1,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document1)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document1)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(tokenized_document1.document()));
+      document_store_->Put(tokenized_document1.document_wrapper()));
   DocumentId document_id1 = put_result1.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document2,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document2)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document2)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(tokenized_document2.document()));
+      document_store_->Put(tokenized_document2.document_wrapper()));
   DocumentId document_id2 = put_result2.new_document_id;
   EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
 
@@ -553,29 +568,35 @@ TEST_F(TermIndexingHandlerTest, HandleIntoLiteIndex_enableSortInIndexing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document0,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document0)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document0)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result0,
-      document_store_->Put(tokenized_document0.document()));
+      document_store_->Put(tokenized_document0.document_wrapper()));
   DocumentId document_id0 = put_result0.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document1,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document1)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document1)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(tokenized_document1.document()));
+      document_store_->Put(tokenized_document1.document_wrapper()));
   DocumentId document_id1 = put_result1.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document2,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document2)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document2)));
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(tokenized_document2.document()));
+      document_store_->Put(tokenized_document2.document_wrapper()));
   DocumentId document_id2 = put_result2.new_document_id;
   EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
 
diff --git a/icing/jni/icing-search-engine-jni.cc b/icing/jni/icing-search-engine-jni.cc
index 4101b36..3c5aca1 100644
--- a/icing/jni/icing-search-engine-jni.cc
+++ b/icing/jni/icing-search-engine-jni.cc
@@ -14,7 +14,8 @@
 
 #include <jni.h>
 
-#include <string>
+#include <cstdint>
+#include <memory>
 #include <string_view>
 #include <utility>
 
@@ -33,6 +34,7 @@
 #include "icing/proto/status.pb.h"
 #include "icing/proto/storage.pb.h"
 #include "icing/proto/usage.pb.h"
+#include "icing/util/clock.h"
 #include "icing/util/logging.h"
 #include <google/protobuf/message_lite.h>
 
@@ -313,6 +315,39 @@ jbyteArray nativeGetNextPage(JNIEnv* env, jclass clazz, jobject object,
   return SerializeProtoToJniByteArray(env, next_page_result_proto);
 }
 
+// TODO: b/417644758 - pre-register this method.
+JNIEXPORT jbyteArray JNICALL
+Java_com_google_android_icing_IcingSearchEngineImpl_nativeGetNextPageWithRequestProto(
+    JNIEnv* env, jclass clazz, jobject object,
+    jbyteArray get_next_page_request_bytes,
+    jlong java_to_native_start_timestamp_ms) {
+  icing::lib::IcingSearchEngine* icing =
+      GetIcingSearchEnginePointer(env, object);
+
+  const std::unique_ptr<const icing::lib::Clock> clock =
+      std::make_unique<icing::lib::Clock>();
+  int32_t java_to_native_jni_latency_ms =
+      clock->GetSystemTimeMilliseconds() - java_to_native_start_timestamp_ms;
+
+  icing::lib::GetNextPageRequestProto get_next_page_request_proto;
+  if (!ParseProtoFromJniByteArray(env, get_next_page_request_bytes,
+                                  &get_next_page_request_proto)) {
+    ICING_LOG(icing::lib::ERROR) << "Failed to parse GetNextPageRequestProto "
+                                    "in nativeGetNextPageWithRequestProto";
+    return nullptr;
+  }
+  icing::lib::SearchResultProto next_page_result_proto =
+      icing->GetNextPage(std::move(get_next_page_request_proto));
+
+  icing::lib::QueryStatsProto* query_stats =
+      next_page_result_proto.mutable_query_stats();
+  query_stats->set_java_to_native_jni_latency_ms(java_to_native_jni_latency_ms);
+  query_stats->set_native_to_java_start_timestamp_ms(
+      clock->GetSystemTimeMilliseconds());
+
+  return SerializeProtoToJniByteArray(env, next_page_result_proto);
+}
+
 void nativeInvalidateNextPageToken(JNIEnv* env, jclass clazz, jobject object,
                                    jlong next_page_token) {
   icing::lib::IcingSearchEngine* icing =
@@ -550,6 +585,18 @@ jbyteArray nativeReset(JNIEnv* env, jclass clazz, jobject object) {
   return SerializeProtoToJniByteArray(env, reset_result_proto);
 }
 
+JNIEXPORT jbyteArray JNICALL
+Java_com_google_android_icing_IcingSearchEngineImpl_nativeClearAndDestroy(
+    JNIEnv* env, jclass clazz, jobject object) {
+  icing::lib::IcingSearchEngine* icing =
+      GetIcingSearchEnginePointer(env, object);
+
+  icing::lib::ResetResultProto clear_and_destroy_proto =
+      icing->ClearAndDestroy();
+
+  return SerializeProtoToJniByteArray(env, clear_and_destroy_proto);
+}
+
 jbyteArray nativeSearchSuggestions(JNIEnv* env, jclass clazz, jobject object,
                                    jbyteArray suggestion_spec_bytes) {
   icing::lib::IcingSearchEngine* icing =
diff --git a/icing/join/document-dependency-processor.cc b/icing/join/document-dependency-processor.cc
new file mode 100644
index 0000000..b27c18d
--- /dev/null
+++ b/icing/join/document-dependency-processor.cc
@@ -0,0 +1,177 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/join/document-dependency-processor.h"
+
+#include <cstdint>
+#include <optional>
+#include <string_view>
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/join/qualified-id.h"
+#include "icing/proto/document.pb.h"
+#include "icing/schema/joinable-property.h"
+#include "icing/store/document-filter-data.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+#include "icing/util/status-macros.h"
+#include "icing/util/timestamp-util.h"
+#include "icing/util/tokenized-document.h"
+
+namespace icing {
+namespace lib {
+
+/* static */ libtextclassifier3::StatusOr<DocumentDependencyProcessor>
+DocumentDependencyProcessor::Create(
+    const DocumentStore* document_store,
+    const std::vector<TokenizedDocument>& batch_documents_to_add,
+    int64_t current_time_ms) {
+  ICING_RETURN_ERROR_IF_NULL(document_store);
+
+  std::unordered_map<QualifiedId, int, QualifiedId::Hasher>
+      qualified_id_to_batch_idx;
+  for (int i = 0; i < batch_documents_to_add.size(); ++i) {
+    const TokenizedDocument& tokenized_document = batch_documents_to_add[i];
+
+    // Ensure that the new document is not expired.
+    int64_t expiration_timestamp_ms =
+        timestamp_util::CalculateRawExpirationTimestampMs(
+            tokenized_document.document_wrapper()
+                .document()
+                .creation_timestamp_ms(),
+            tokenized_document.document_wrapper().document().ttl_ms());
+    if (expiration_timestamp_ms <= current_time_ms) {
+      return absl_ports::InvalidArgumentError("The new document is expired.");
+    }
+
+    QualifiedId qualified_id(
+        tokenized_document.document_wrapper().document().namespace_(),
+        tokenized_document.document_wrapper().document().uri());
+    qualified_id_to_batch_idx.insert({std::move(qualified_id), i});
+  }
+
+  return DocumentDependencyProcessor(document_store, batch_documents_to_add,
+                                     std::move(qualified_id_to_batch_idx),
+                                     current_time_ms);
+}
+
+libtextclassifier3::StatusOr<DocumentDependencyProcessor::EvaluateResult>
+DocumentDependencyProcessor::Evaluate() {
+  EvaluateResult result;
+  result.outer_dependency_document_ids.resize(batch_documents_to_add_.size());
+
+  // Validate the dependencies and construct the dependent graph.
+  for (int i = 0; i < batch_documents_to_add_.size(); ++i) {
+    const TokenizedDocument& tokenized_document = batch_documents_to_add_[i];
+
+    // Iterate through all qualified id joinable properties of the tokenized
+    // document.
+    for (const JoinableProperty<std::string_view>& dep_qualified_id_prop :
+         tokenized_document.qualified_id_join_properties()) {
+      if (dep_qualified_id_prop.metadata.delete_propagation_type ==
+          JoinableConfig::DeletePropagationType::NONE) {
+        // If delete propagation is NONE, then the referenced documents are
+        // not required to be present, so skip the check for this joinable
+        // property.
+        continue;
+      }
+
+      // Otherwise, the referenced documents are required to be present.
+      // For each of the qualified id string:
+      // - Validate and check it should match a document in either the same
+      //   batch of new documents to add or the document store.
+      // - Add the dependency document id (out of the batch) into result.
+      for (std::string_view dep_qualified_id_str :
+           dep_qualified_id_prop.values) {
+        ICING_RETURN_IF_ERROR(ValidateDependency(
+            dep_qualified_id_str, result.outer_dependency_document_ids[i]));
+      }
+    }
+
+    // Check if this document to add is replacing an expired document.
+    auto existing_doc_id_or = document_store_.GetDocumentId(
+        tokenized_document.document_wrapper().document().namespace_(),
+        tokenized_document.document_wrapper().document().uri());
+    if (existing_doc_id_or.ok()) {
+      DocumentId existing_doc_id = existing_doc_id_or.ValueOrDie();
+      std::optional<DocumentFilterData> filter_data =
+          document_store_.GetNonDeletedDocumentFilterData(existing_doc_id);
+      if (filter_data.has_value() &&
+          filter_data->expiration_timestamp_ms() <= current_time_ms_) {
+        result.existing_expired_doc_ids_to_replace.insert(existing_doc_id);
+      }
+    }
+  }
+  return result;
+}
+
+libtextclassifier3::Status DocumentDependencyProcessor::ValidateDependency(
+    std::string_view dep_qualified_id_str,
+    std::unordered_set<DocumentId>& outer_dep_doc_ids) const {
+  if (dep_qualified_id_str.empty()) {
+    // Allow empty qualified id.
+    return libtextclassifier3::Status::OK;
+  }
+
+  // Attempt to parse the qualified id string.
+  auto dep_qualified_id_or = QualifiedId::Parse(dep_qualified_id_str);
+  if (!dep_qualified_id_or.ok()) {
+    // Incorrect format of qualified id string. Return INVALID_ARGUMENT_ERROR
+    // for unsatisfied dependency.
+    return absl_ports::InvalidArgumentError("Invalid qualified id string.");
+  }
+  QualifiedId dep_qualified_id = std::move(dep_qualified_id_or).ValueOrDie();
+
+  // Case 1: check if the dependency document is in the same batch of new
+  //         documents.
+  auto itr = qualified_id_to_batch_idx_.find(dep_qualified_id);
+  if (itr != qualified_id_to_batch_idx_.end()) {
+    // We've already validated that the document in the batch is not expired, so
+    // we don't need to check it again here.
+    return libtextclassifier3::Status::OK;
+  }
+
+  // Case 2: check if the dependency document is alive in the document store.
+  auto dep_doc_id_or = document_store_.GetDocumentId(
+      dep_qualified_id.name_space(), dep_qualified_id.uri());
+  if (!dep_doc_id_or.ok()) {
+    if (absl_ports::IsNotFound(dep_doc_id_or.status())) {
+      // Document not found in the document store. Return INVALID_ARGUMENT_ERROR
+      // for unsatisfied dependency.
+      return absl_ports::InvalidArgumentError(
+          "A dependency document is not found.");
+    }
+    // Real error.
+    return std::move(dep_doc_id_or).status();
+  }
+  DocumentId dep_doc_id = dep_doc_id_or.ValueOrDie();
+
+  if (!document_store_.IsDocumentAlive(dep_doc_id, current_time_ms_)) {
+    return absl_ports::InvalidArgumentError(
+        "A dependency document is not alive.");
+  }
+
+  outer_dep_doc_ids.insert(dep_doc_id);
+
+  return libtextclassifier3::Status::OK;
+}
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/join/document-dependency-processor.h b/icing/join/document-dependency-processor.h
new file mode 100644
index 0000000..7ae0820
--- /dev/null
+++ b/icing/join/document-dependency-processor.h
@@ -0,0 +1,144 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_JOIN_DOCUMENT_DEPENDENCY_PROCESSOR_H_
+#define ICING_JOIN_DOCUMENT_DEPENDENCY_PROCESSOR_H_
+
+#include <cstdint>
+#include <string_view>
+#include <unordered_map>
+#include <unordered_set>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/join/qualified-id.h"
+#include "icing/proto/document.pb.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+#include "icing/util/tokenized-document.h"
+
+namespace icing {
+namespace lib {
+
+// This class evaluates the dependency of the documents to be added. Currently,
+// dependencies are defined solely by delete propagation.
+class DocumentDependencyProcessor {
+ public:
+  // Creates a DocumentDependencyProcessor for the given batch of documents to
+  // add.
+  //
+  // Returns:
+  //   - A DocumentDependencyProcessor on success.
+  //   - INVALID_ARGUMENT_ERROR if any of the document in the batch is expired.
+  static libtextclassifier3::StatusOr<DocumentDependencyProcessor> Create(
+      const DocumentStore* document_store,
+      const std::vector<TokenizedDocument>& batch_documents_to_add,
+      int64_t current_time_ms);
+
+  // Evaluates the document dependencies:
+  // - Validates the dependencies. For each document in the batch, its
+  //   dependencies (parent documents with delete propagation enabled in the
+  //   schema) must be present in either the same batch of new documents or the
+  //   document store.
+  // - Attaches some additional information to the result for the caller.
+  //
+  // Returns:
+  //   - An EvaluateResult object containing essential evaluation result
+  //     information on success.
+  //   - INVALID_ARGUMENT_ERROR if the validation fails, e.g. any of the
+  //     dependencies (referenced parent documents) are not present.
+  //   - Any error from document store or schema store.
+  struct EvaluateResult {
+    // A vector of sets to store dependency document ids out of the batch, for
+    // each document in batch_documents_to_add_. Note that the index of the
+    // vector corresponds to the index of the document in
+    // batch_documents_to_add_.
+    //
+    // Note: only dependency documents out of the batch are included. IOW the
+    //   relations between documents in the batch are not included.
+    //
+    // The caller must propagate (std::min) the expiration timestamps of the
+    // dependency documents down to the batch documents to add.
+    std::vector<std::unordered_set<DocumentId>> outer_dependency_document_ids;
+
+    // A set of existing document ids that are expired and will be replaced by
+    // the new documents in the batch.
+    //
+    // The caller must run delete propagation against these documents to remove
+    // their (expired) children from ground truth. Otherwise, it is possible
+    // that when Icing rebuilds derived files, an already expired child document
+    // becomes alive again. For example, consider a parent document A and child
+    // document B:
+    // - t = 0: put A with raw expiration timestamp 100.
+    // - t = 10: put B with raw expiration timestamp 1000. Its final expiration
+    //   timestamp is min(100, 1000) = 100.
+    // - t = 200: both A and B are expired.
+    // - t = 300: replace (expired) A with raw expiration timestamp 2000.
+    // - t = 500: the device reboots.
+    //   - When initializing Icing, derived files are discarded and rebuilt.
+    //   - Since we lost the previously propagated expiration timestamp of B
+    //     (100), when recomputing from ground truth, it becomes min(1000, 2000)
+    //     = 1000 and B becomes alive again.
+    //   - This causes privacy issue since the replaced A may have unaware child
+    //     documents.
+    std::unordered_set<DocumentId> existing_expired_doc_ids_to_replace;
+  };
+  libtextclassifier3::StatusOr<EvaluateResult> Evaluate();
+
+ private:
+  explicit DocumentDependencyProcessor(
+      const DocumentStore* document_store,
+      const std::vector<TokenizedDocument>& batch_documents_to_add,
+      std::unordered_map<QualifiedId, int, QualifiedId::Hasher>
+          qualified_id_to_batch_idx,
+      int64_t current_time_ms)
+      : document_store_(*document_store),
+        batch_documents_to_add_(batch_documents_to_add),
+        qualified_id_to_batch_idx_(std::move(qualified_id_to_batch_idx)),
+        current_time_ms_(current_time_ms) {}
+
+  // Helper function to validate a dependency's qualified id string:
+  // - Is valid or not. Note that empty qualified id string is allowed and will
+  //   be skipped.
+  // - Satisfies the dependency: matches a document in either the same batch of
+  //   new documents to add or the document store.
+  //
+  // Also add the dependency document id (out of the batch) into
+  // outer_dep_doc_ids.
+  //
+  // Returns:
+  //   - OK on success.
+  //   - INVALID_ARGUMENT_ERROR if dep_qualified_id_str is invalid or the
+  //     document referenced by the qualified id is not present.
+  //   - Any error from document store.
+  libtextclassifier3::Status ValidateDependency(
+      std::string_view dep_qualified_id_str,
+      std::unordered_set<DocumentId>& outer_dep_doc_ids) const;
+
+  const DocumentStore& document_store_;
+  const std::vector<TokenizedDocument>& batch_documents_to_add_;
+
+  // A map for mapping qualified id to the index of batch_documents_to_add_.
+  std::unordered_map<QualifiedId, int, QualifiedId::Hasher>
+      qualified_id_to_batch_idx_;
+
+  int64_t current_time_ms_;
+};
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_JOIN_DOCUMENT_DEPENDENCY_PROCESSOR_H_
diff --git a/icing/join/document-dependency-processor_test.cc b/icing/join/document-dependency-processor_test.cc
new file mode 100644
index 0000000..0613e28
--- /dev/null
+++ b/icing/join/document-dependency-processor_test.cc
@@ -0,0 +1,1119 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/join/document-dependency-processor.h"
+
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/document-builder.h"
+#include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
+#include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/portable/gzip_stream.h"
+#include "icing/portable/platform.h"
+#include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
+#include "icing/proto/schema.pb.h"
+#include "icing/proto/scoring.pb.h"
+#include "icing/proto/search.pb.h"
+#include "icing/schema-builder.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+#include "icing/testing/common-matchers.h"
+#include "icing/testing/fake-clock.h"
+#include "icing/testing/test-data.h"
+#include "icing/testing/test-feature-flags.h"
+#include "icing/testing/tmp-directory.h"
+#include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
+#include "icing/util/document-util.h"
+#include "icing/util/icu-data-file-helper.h"
+#include "icing/util/tokenized-document.h"
+#include "unicode/uloc.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::testing::ElementsAre;
+using ::testing::HasSubstr;
+using ::testing::IsEmpty;
+using ::testing::IsTrue;
+using ::testing::UnorderedElementsAre;
+
+class DocumentDependencyProcessorTest : public ::testing::Test {
+ protected:
+  void SetUp() override {
+    feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    ASSERT_THAT(feature_flags_->enable_repeated_field_joins(), IsTrue());
+
+    test_dir_ = GetTestTempDir() + "/document_dependency_processor_test";
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(test_dir_.c_str()),
+                IsTrue());
+
+    schema_store_dir_ = test_dir_ + "/schema_store";
+    doc_store_dir_ = test_dir_ + "/doc_store";
+
+    if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
+      ICING_ASSERT_OK(
+          // File generated via icu_data_file rule in //icing/BUILD.
+          icu_data_file_helper::SetUpIcuDataFile(
+              GetTestFilePath("icing/icu.dat")));
+    }
+
+    language_segmenter_factory::SegmenterOptions options(ULOC_US);
+    ICING_ASSERT_OK_AND_ASSIGN(
+        lang_segmenter_,
+        language_segmenter_factory::Create(std::move(options)));
+
+    ASSERT_THAT(
+        filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()),
+        IsTrue());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        schema_store_, SchemaStore::Create(&filesystem_, schema_store_dir_,
+                                           &fake_clock_, feature_flags_.get()));
+
+    SchemaProto schema =
+        SchemaBuilder()
+            .AddType(SchemaTypeConfigBuilder().SetType("Person").AddProperty(
+                PropertyConfigBuilder()
+                    .SetName("Name")
+                    .SetDataTypeString(TERM_MATCH_PREFIX, TOKENIZER_PLAIN)
+                    .SetCardinality(CARDINALITY_OPTIONAL)))
+            .AddType(
+                SchemaTypeConfigBuilder()
+                    .SetType("Email")
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("receiver")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
+                                     .SetCardinality(CARDINALITY_REPEATED))
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("sender")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_NONE)
+                                     .SetCardinality(CARDINALITY_REPEATED)))
+            .AddType(
+                SchemaTypeConfigBuilder()
+                    .SetType("Label")
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("target")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
+                                     .SetCardinality(CARDINALITY_REPEATED))
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("softTarget")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_NONE)
+                                     .SetCardinality(CARDINALITY_REPEATED)))
+
+            .Build();
+    ASSERT_THAT(schema_store_->SetSchema(
+                    schema, /*ignore_errors_and_delete_documents=*/false),
+                IsOk());
+
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
+                IsTrue());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::CreateResult create_result,
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
+    doc_store_ = std::move(create_result.document_store);
+  }
+
+  void TearDown() override {
+    doc_store_.reset();
+    schema_store_.reset();
+    lang_segmenter_.reset();
+
+    filesystem_.DeleteDirectoryRecursively(test_dir_.c_str());
+  }
+
+  std::unique_ptr<FeatureFlags> feature_flags_;
+  Filesystem filesystem_;
+  FakeClock fake_clock_;
+  std::string test_dir_;
+  std::string schema_store_dir_;
+  std::string doc_store_dir_;
+
+  std::unique_ptr<LanguageSegmenter> lang_segmenter_;
+  std::unique_ptr<SchemaStore> schema_store_;
+  std::unique_ptr<DocumentStore> doc_store_;
+};
+
+TEST_F(DocumentDependencyProcessorTest,
+       Create_alreadyExpiredDocumentShouldFail) {
+  fake_clock_.SetSystemTimeMilliseconds(500);
+
+  DocumentProto email1 = DocumentBuilder()
+                             .SetCreationTimestampMs(100)
+                             .SetTtlMs(400)
+                             .SetKey("namespace", "email")
+                             .SetSchema("Email")
+                             .Build();
+  DocumentProto email2 = DocumentBuilder()
+                             .SetCreationTimestampMs(100)
+                             .SetTtlMs(300)
+                             .SetKey("namespace", "email")
+                             .SetSchema("Email")
+                             .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email2));
+
+  std::vector<TokenizedDocument> batch_documents_to_add1;
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_email1));
+
+  EXPECT_THAT(DocumentDependencyProcessor::Create(
+                  doc_store_.get(), batch_documents_to_add1,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("The new document is expired.")));
+
+  std::vector<TokenizedDocument> batch_documents_to_add2;
+  batch_documents_to_add2.push_back(std::move(tokenized_doc_email2));
+
+  EXPECT_THAT(DocumentDependencyProcessor::Create(
+                  doc_store_.get(), batch_documents_to_add2,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("The new document is expired.")));
+}
+
+TEST_F(DocumentDependencyProcessorTest, Evaluate) {
+  // This is a general test case to evaluate a batch of documents with all the
+  // possible scenarios:
+  // - Replace existing documents (i.e. replace documents that were previously
+  //   added into the document store).
+  // - Add new documents.
+  //
+  // And both of them have dependencies on existing, replaced and new documents.
+
+  // Create person1, person2, email1, label1, label2, label3 with the following
+  // relation:
+  //
+  // person1        person2 --> email1        label1 --> label2 --> label3
+  DocumentProto person1 = DocumentBuilder()
+                              .SetKey("namespace", "person1")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Alice")
+                              .Build();
+  DocumentProto person2 = DocumentBuilder()
+                              .SetKey("namespace", "person2")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Bob")
+                              .Build();
+  DocumentProto email1 = DocumentBuilder()
+                             .SetKey("namespace", "email1")
+                             .SetSchema("Email")
+                             .AddStringProperty("receiver", "namespace#person2")
+                             .Build();
+  DocumentProto label1 = DocumentBuilder()
+                             .SetKey("namespace", "label1")
+                             .SetSchema("Label")
+                             .Build();
+  DocumentProto label2 = DocumentBuilder()
+                             .SetKey("namespace", "label2")
+                             .SetSchema("Label")
+                             .AddStringProperty("target", "namespace#label1")
+                             .Build();
+  DocumentProto label3 = DocumentBuilder()
+                             .SetKey("namespace", "label3")
+                             .SetSchema("Label")
+                             .AddStringProperty("target", "namespace#label2")
+                             .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label3,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label3));
+
+  std::vector<TokenizedDocument> batch_documents_to_add1;
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_person1));
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_person2));
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_email1));
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_label1));
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_label2));
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_label3));
+
+  // Evaluate all of them together should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor1,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add1,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result1,
+      processor1.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result1.outer_dependency_document_ids,
+              ElementsAre(IsEmpty(), IsEmpty(), IsEmpty(), IsEmpty(), IsEmpty(),
+                          IsEmpty()));
+  // No replaced expired documents.
+  EXPECT_THAT(result1.existing_expired_doc_ids_to_replace, IsEmpty());
+
+  // Put them into the document store.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result_person1,
+      doc_store_->Put(
+          batch_documents_to_add1[0].document_wrapper()));  // person1
+  ICING_ASSERT_OK(doc_store_->Put(
+      batch_documents_to_add1[1].document_wrapper()));  // person2
+  ICING_ASSERT_OK(doc_store_->Put(
+      batch_documents_to_add1[2].document_wrapper()));  // email1
+  ICING_ASSERT_OK(doc_store_->Put(
+      batch_documents_to_add1[3].document_wrapper()));  // label1
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result_label2,
+      doc_store_->Put(
+          batch_documents_to_add1[4].document_wrapper()));  // label2
+  ICING_ASSERT_OK(doc_store_->Put(
+      batch_documents_to_add1[5].document_wrapper()));  // label3
+  DocumentId doc_id_person1 = put_result_person1.new_document_id;
+  DocumentId doc_id_label2 = put_result_label2.new_document_id;
+
+  // Replace existing person2, email1, label1 and add new label4, label5 to make
+  // the following relation:
+  // (person1, label2, label3 are not changed).
+  //
+  // person1 -------+              +--------> label4 <--------+
+  // (unchanged)    |              |          (NEW)           |
+  //                v              |             |            |
+  //              email1 -----> label5           |         label2 -----> label3
+  //              (REPLACED)     (NEW)           |         (unchanged)
+  //                ^              ^             |            ^
+  //                |              |             v            |
+  // person2 -------+              +--------- label1 ---------+
+  // (REPLACED)                               (REPLACED)
+  DocumentProto person2_to_replace = DocumentBuilder()
+                                         .SetKey("namespace", "person2")
+                                         .SetSchema("Person")
+                                         .AddStringProperty("Name", "Robert")
+                                         .Build();
+  DocumentProto email1_to_replace =
+      DocumentBuilder()
+          .SetKey("namespace", "email1")
+          .SetSchema("Email")
+          .AddStringProperty("receiver", "namespace#person1",
+                             "namespace#person2")
+          .Build();
+  DocumentProto label1_to_replace =
+      DocumentBuilder()
+          .SetKey("namespace", "label1")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#label4")
+          .Build();
+  DocumentProto label4 =
+      DocumentBuilder()
+          .SetKey("namespace", "label4")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#label2", "namespace#label5")
+          .Build();
+  DocumentProto label5 =
+      DocumentBuilder()
+          .SetKey("namespace", "label5")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#label1", "namespace#email1")
+          .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person2_to_replace,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person2_to_replace));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email1_to_replace,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          email1_to_replace));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label1_to_replace,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          label1_to_replace));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label4,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label5,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label5));
+
+  std::vector<TokenizedDocument> batch_documents_to_add2;
+  batch_documents_to_add2.push_back(
+      std::move(tokenized_doc_person2_to_replace));
+  batch_documents_to_add2.push_back(std::move(tokenized_doc_email1_to_replace));
+  batch_documents_to_add2.push_back(std::move(tokenized_doc_label1_to_replace));
+  batch_documents_to_add2.push_back(std::move(tokenized_doc_label4));
+  batch_documents_to_add2.push_back(std::move(tokenized_doc_label5));
+
+  // Evaluate all of them together should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor2,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add2,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result2,
+      processor2.Evaluate());
+  EXPECT_THAT(
+      result2.outer_dependency_document_ids,
+      ElementsAre(
+          IsEmpty(),  // person2 has no outer dependency.
+          UnorderedElementsAre(
+              doc_id_person1),  // email1 has an outer dependency on person1.
+          IsEmpty(),            // label1 has no outer dependency.
+          UnorderedElementsAre(
+              doc_id_label2),  // label4 has an outer dependency on label2.
+          IsEmpty()            // label5 has no outer dependency.
+          ));
+  // No replaced expired documents.
+  EXPECT_THAT(result2.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_singleDocumentWithoutDependency) {
+  // Set the current time to 0.
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create a person document with expiration timestamp 2000.
+  DocumentProto person = DocumentBuilder()
+                             .SetCreationTimestampMs(0)
+                             .SetTtlMs(2000)
+                             .SetKey("namespace", "person")
+                             .SetSchema("Person")
+                             .AddStringProperty("Name", "Alice")
+                             .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), person));
+
+  std::vector<TokenizedDocument> batch_documents_to_add1;
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_person));
+
+  // Evaluate person should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor1,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add1,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result1,
+      processor1.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result1.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  // No replaced expired documents.
+  EXPECT_THAT(result1.existing_expired_doc_ids_to_replace, IsEmpty());
+
+  // Put person into the document store.
+  ICING_ASSERT_OK(doc_store_->Put(
+      batch_documents_to_add1[0].document_wrapper()));  // person
+
+  // Set the current time to 1000.
+  fake_clock_.SetSystemTimeMilliseconds(1000);
+
+  // Replace person with expiration timestamp 1300.
+  DocumentProto person_to_replace1 = DocumentBuilder()
+                                         .SetCreationTimestampMs(1000)
+                                         .SetTtlMs(300)
+                                         .SetKey("namespace", "person")
+                                         .SetSchema("Person")
+                                         .AddStringProperty("Name", "Bob")
+                                         .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person_to_replace1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person_to_replace1));
+
+  std::vector<TokenizedDocument> batch_documents_to_add2;
+  batch_documents_to_add2.push_back(
+      std::move(tokenized_doc_person_to_replace1));
+
+  // Evaluate person (replaced 1) should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor2,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add2,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result2,
+      processor2.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result2.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  // No replaced expired documents.
+  EXPECT_THAT(result2.existing_expired_doc_ids_to_replace, IsEmpty());
+
+  // Put person (replaced 1) into the document store.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result_person_to_replace1,
+      doc_store_->Put(batch_documents_to_add2[0]
+                          .document_wrapper()));  // person_to_replace1
+  DocumentId doc_id_person_to_replace1 =
+      put_result_person_to_replace1.new_document_id;
+
+  // Set the current time to 2000.
+  fake_clock_.SetSystemTimeMilliseconds(2000);
+
+  // Replace person with expiration timestamp 3000.
+  DocumentProto person_to_replace2 = DocumentBuilder()
+                                         .SetCreationTimestampMs(2000)
+                                         .SetTtlMs(1000)
+                                         .SetKey("namespace", "person")
+                                         .SetSchema("Person")
+                                         .AddStringProperty("Name", "Bob")
+                                         .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person_to_replace2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person_to_replace2));
+
+  std::vector<TokenizedDocument> batch_documents_to_add3;
+  batch_documents_to_add3.push_back(
+      std::move(tokenized_doc_person_to_replace2));
+
+  // Evaluate person (replaced 2) should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor3,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add3,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result3,
+      processor3.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result3.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  // Since at t = 2000 the original person document (doc_id_person_to_replace1)
+  // is expired, it should be detected.
+  EXPECT_THAT(result3.existing_expired_doc_ids_to_replace,
+              UnorderedElementsAre(doc_id_person_to_replace1));
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_nonExistentReferencedDocumentShouldFail) {
+  DocumentProto email = DocumentBuilder()
+                            .SetKey("namespace", "email")
+                            .SetSchema("Email")
+                            .AddStringProperty("receiver", "namespace#person")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+
+  // Evaluate should fail since email's referenced document ("namespace#person")
+  // with delete propagation enabled doesn't exist.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  EXPECT_THAT(processor.Evaluate(),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("A dependency document is not found")));
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_invalidReferencedQualifiedIdShouldFail) {
+  DocumentProto email =
+      DocumentBuilder()
+          .SetKey("namespace", "email")
+          .SetSchema("Email")
+          .AddStringProperty("receiver", "invalid_qualified_id")
+          .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+
+  // Evaluate should fail since email contains an invalid qualified id in a
+  // joinable property with delete propagation enabled.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  EXPECT_THAT(processor.Evaluate(),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("Invalid qualified id string")));
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_emptyQualifiedIdStringShouldSucceed) {
+  DocumentProto email = DocumentBuilder()
+                            .SetKey("namespace", "email")
+                            .SetSchema("Email")
+                            .AddStringProperty("receiver", "")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+
+  // Evaluate should succeed since empty qualified id string is allowed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentDependencyProcessor::EvaluateResult result,
+                             processor.Evaluate());
+  EXPECT_THAT(result.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  EXPECT_THAT(result.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_allReferencedDocumentsInBatchShouldSucceed) {
+  // Create person1, person2, email with the following relation:
+  //
+  // person1 -------+
+  //                |
+  //                v
+  //              email
+  //                ^
+  //                |
+  // person2 -------+
+  //
+  // (email has 2 parent documents person1 and person2)
+  DocumentProto person1 = DocumentBuilder()
+                              .SetKey("namespace", "person1")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Alice")
+                              .Build();
+  DocumentProto person2 = DocumentBuilder()
+                              .SetKey("namespace", "person2")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Bob")
+                              .Build();
+  DocumentProto email = DocumentBuilder()
+                            .SetKey("namespace", "email")
+                            .SetSchema("Email")
+                            .AddStringProperty("receiver", "namespace#person1",
+                                               "namespace#person2")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_person2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          person2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_person1));
+  batch_documents_to_add.push_back(std::move(tokenized_doc_person2));
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+
+  // Evaluate all of them together should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentDependencyProcessor::EvaluateResult result,
+                             processor.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result.outer_dependency_document_ids,
+              ElementsAre(IsEmpty(), IsEmpty(), IsEmpty()));
+  EXPECT_THAT(result.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_selfReferenceInBatchShouldSucceed) {
+  // Create label document having a self reference on "target" property with
+  // delete propagation enabled.
+  DocumentProto label = DocumentBuilder()
+                            .SetKey("namespace", "label")
+                            .SetSchema("Label")
+                            .AddStringProperty("target", "namespace#label")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label));
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_label));
+
+  // Evaluate should succeed since the referenced document is present in the
+  // same batch of documents to add.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentDependencyProcessor::EvaluateResult result,
+                             processor.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  EXPECT_THAT(result.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_cycleReferenceInBatchShouldSucceed) {
+  // Create label1, label2, label3 with the following relation:
+  //
+  // label1 -> label2 -> label3
+  //   ^                   |
+  //   |                   |
+  //   +-------------------+
+  DocumentProto label1 = DocumentBuilder()
+                             .SetKey("namespace", "label1")
+                             .SetSchema("Label")
+                             .AddStringProperty("target", "namespace#label3")
+                             .Build();
+  DocumentProto label2 = DocumentBuilder()
+                             .SetKey("namespace", "label2")
+                             .SetSchema("Label")
+                             .AddStringProperty("target", "namespace#label1")
+                             .Build();
+  DocumentProto label3 = DocumentBuilder()
+                             .SetKey("namespace", "label3")
+                             .SetSchema("Label")
+                             .AddStringProperty("target", "namespace#label2")
+                             .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_label3,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), label3));
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_label1));
+  batch_documents_to_add.push_back(std::move(tokenized_doc_label2));
+  batch_documents_to_add.push_back(std::move(tokenized_doc_label3));
+
+  // Evaluate should succeed since the all referenced documents are present in
+  // the same batch of documents to add.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentDependencyProcessor::EvaluateResult result,
+                             processor.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result.outer_dependency_document_ids,
+              ElementsAre(IsEmpty(), IsEmpty(), IsEmpty()));
+  EXPECT_THAT(result.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_allReferencedDocumentsInDocumentStoreShouldSucceed) {
+  // Create person1, person2, email with the following relation:
+  //
+  // person1 -------+
+  //                |
+  //                v
+  //              email
+  //                ^
+  //                |
+  // person2 -------+
+  //
+  // (email has 2 parent documents person1 and person2)
+  DocumentProto person1 = DocumentBuilder()
+                              .SetKey("namespace", "person1")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Alice")
+                              .Build();
+  DocumentProto person2 = DocumentBuilder()
+                              .SetKey("namespace", "person2")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Bob")
+                              .Build();
+  DocumentProto email = DocumentBuilder()
+                            .SetKey("namespace", "email")
+                            .SetSchema("Email")
+                            .AddStringProperty("receiver", "namespace#person1",
+                                               "namespace#person2")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  // Put person1, person2 into the document store.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result_person1,
+      doc_store_->Put(document_util::CreateDocumentWrapper(person1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result_person2,
+      doc_store_->Put(document_util::CreateDocumentWrapper(person2)));
+  DocumentId doc_id_person1 = put_result_person1.new_document_id;
+  DocumentId doc_id_person2 = put_result_person2.new_document_id;
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+
+  // Evaluate email should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentDependencyProcessor::EvaluateResult result,
+                             processor.Evaluate());
+  EXPECT_THAT(
+      result.outer_dependency_document_ids,
+      ElementsAre(UnorderedElementsAre(doc_id_person1, doc_id_person2)));
+  EXPECT_THAT(result.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_expiredReferencedDocumentInDocumentStoreShouldFail) {
+  fake_clock_.SetSystemTimeMilliseconds(500);
+
+  // Create person1, person2, email with the following relation:
+  //
+  // person1 -------+
+  //                |
+  //                v
+  //              email
+  //                ^
+  //                |
+  // person2 -------+
+  //
+  // (email has 2 parent documents person1 and person2)
+  DocumentProto person1 = DocumentBuilder()
+                              .SetKey("namespace", "person1")
+                              .SetTtlMs(1000)
+                              .SetCreationTimestampMs(500)
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Alice")
+                              .Build();
+  DocumentProto person2 = DocumentBuilder()
+                              .SetKey("namespace", "person2")
+                              .SetTtlMs(100)
+                              .SetCreationTimestampMs(500)
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Bob")
+                              .Build();
+  DocumentProto email = DocumentBuilder()
+                            .SetKey("namespace", "email")
+                            .SetSchema("Email")
+                            .AddStringProperty("receiver", "namespace#person1",
+                                               "namespace#person2")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  // Put person1, person2 into the document store.
+  ICING_ASSERT_OK(
+      doc_store_->Put(document_util::CreateDocumentWrapper(person1)));
+  ICING_ASSERT_OK(
+      doc_store_->Put(document_util::CreateDocumentWrapper(person2)));
+
+  // Adjust the current time to make person2 expired, but person1 is still
+  // alive.
+  fake_clock_.SetSystemTimeMilliseconds(1000);
+
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+
+  // Evaluate email should fail since one of email's referenced documents
+  // (person2) with delete propagation enabled is expired.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  EXPECT_THAT(processor.Evaluate(),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("A dependency document is not alive")));
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_deletedReferencedDocumentInDocumentStoreShouldFail) {
+  // Create person1, person2, email with the following relation:
+  //
+  // person1 -------+
+  //                |
+  //                v
+  //              email
+  //                ^
+  //                |
+  // person2 -------+
+  //
+  // (email has 2 parent documents person1 and person2)
+  DocumentProto person1 = DocumentBuilder()
+                              .SetKey("namespace", "person1")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Alice")
+                              .Build();
+  DocumentProto person2 = DocumentBuilder()
+                              .SetKey("namespace", "person2")
+                              .SetSchema("Person")
+                              .AddStringProperty("Name", "Bob")
+                              .Build();
+  DocumentProto email = DocumentBuilder()
+                            .SetKey("namespace", "email")
+                            .SetSchema("Email")
+                            .AddStringProperty("receiver", "namespace#person1",
+                                               "namespace#person2")
+                            .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email));
+
+  // Put person1, person2 into the document store.
+  ICING_ASSERT_OK(
+      doc_store_->Put(document_util::CreateDocumentWrapper(person1)));
+  ICING_ASSERT_OK(
+      doc_store_->Put(document_util::CreateDocumentWrapper(person2)));
+
+  // Delete person2.
+  ICING_ASSERT_OK(doc_store_->Delete(
+      "namespace", "person2",
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+
+  // Evaluate email should fail since one of email's referenced documents
+  // (person2) with delete propagation enabled is deleted.
+  std::vector<TokenizedDocument> batch_documents_to_add;
+  batch_documents_to_add.push_back(std::move(tokenized_doc_email));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  EXPECT_THAT(processor.Evaluate(),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("A dependency document is not alive")));
+}
+
+TEST_F(DocumentDependencyProcessorTest,
+       Evaluate_withoutDeletePropagationShouldAlwaysSucceed) {
+  fake_clock_.SetSystemTimeMilliseconds(500);
+
+  // Create email document having an invalid qualified id string on "sender"
+  // property with delete propagation disabled. Evaluate should succeed since
+  // Icing will ignore invalid qualified id with delete propagation disabled.
+  DocumentProto email1 =
+      DocumentBuilder()
+          .SetKey("namespace", "email")
+          .SetSchema("Email")
+          .AddStringProperty("sender", "invalid_qualified_id")
+          .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email1));
+  std::vector<TokenizedDocument> batch_documents_to_add1;
+  batch_documents_to_add1.push_back(std::move(tokenized_doc_email1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor1,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add1,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result1,
+      processor1.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result1.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  EXPECT_THAT(result1.existing_expired_doc_ids_to_replace, IsEmpty());
+
+  // Create email document having a valid qualified id string on "sender"
+  // property with delete propagation disabled, but the referenced document
+  // doesn't exist. Evaluate should succeed since Icing will ignore non-existent
+  // referenced document with delete propagation disabled.
+  DocumentProto email2 = DocumentBuilder()
+                             .SetKey("namespace", "email")
+                             .SetSchema("Email")
+                             .AddStringProperty("sender", "namespace#person")
+                             .Build();
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email2_1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email2));
+  std::vector<TokenizedDocument> batch_documents_to_add2_1;
+  batch_documents_to_add2_1.push_back(std::move(tokenized_doc_email2_1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor2_1,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add2_1,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result2_1,
+      processor2_1.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result2_1.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  EXPECT_THAT(result2_1.existing_expired_doc_ids_to_replace, IsEmpty());
+
+  // Add person document into the document store to make email2's referenced
+  // document exist.
+  DocumentProto person = DocumentBuilder()
+                             .SetTtlMs(100)
+                             .SetCreationTimestampMs(500)
+                             .SetKey("namespace", "person")
+                             .SetSchema("Person")
+                             .AddStringProperty("Name", "Test Name")
+                             .Build();
+  ICING_ASSERT_OK(
+      doc_store_->Put(document_util::CreateDocumentWrapper(person)));
+
+  // Evaluate email2 again. Should succeed.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email2_2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email2));
+  std::vector<TokenizedDocument> batch_documents_to_add2_2;
+  batch_documents_to_add2_2.push_back(std::move(tokenized_doc_email2_2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor2_2,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add2_2,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result2_2,
+      processor2_2.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result2_2.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  EXPECT_THAT(result2_2.existing_expired_doc_ids_to_replace, IsEmpty());
+
+  // Evaluate email2 again with a different current time which makes person
+  // document expired. Since delete propagation is disabled, Evaluate should
+  // still succeed.
+  fake_clock_.SetSystemTimeMilliseconds(1000);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_doc_email2_3,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(), email2));
+  std::vector<TokenizedDocument> batch_documents_to_add2_3;
+  batch_documents_to_add2_3.push_back(std::move(tokenized_doc_email2_3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor processor2_3,
+      DocumentDependencyProcessor::Create(
+          doc_store_.get(), batch_documents_to_add2_3,
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentDependencyProcessor::EvaluateResult result2_3,
+      processor2_3.Evaluate());
+  // No dependency documents out of the batch.
+  EXPECT_THAT(result2_3.outer_dependency_document_ids, ElementsAre(IsEmpty()));
+  EXPECT_THAT(result2_3.existing_expired_doc_ids_to_replace, IsEmpty());
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/join/document-dependent-graph.cc b/icing/join/document-dependent-graph.cc
new file mode 100644
index 0000000..6665b83
--- /dev/null
+++ b/icing/join/document-dependent-graph.cc
@@ -0,0 +1,127 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/join/document-dependent-graph.h"
+
+#include <memory>
+#include <optional>
+#include <utility>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/graph/graph-interface.h"
+#include "icing/join/qualified-id-join-index.h"
+#include "icing/schema/joinable-property.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-filter-data.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+#include "icing/util/status-macros.h"
+
+namespace icing {
+namespace lib {
+
+/* static */ libtextclassifier3::StatusOr<
+    std::unique_ptr<DocumentDependentGraph>>
+DocumentDependentGraph::Create(const SchemaStore* schema_store,
+                               const DocumentStore* doc_store,
+                               const QualifiedIdJoinIndex* join_index) {
+  ICING_RETURN_ERROR_IF_NULL(schema_store);
+  ICING_RETURN_ERROR_IF_NULL(doc_store);
+  ICING_RETURN_ERROR_IF_NULL(join_index);
+
+  if (join_index->version() != QualifiedIdJoinIndex::Version::kV3) {
+    return absl_ports::InvalidArgumentError(
+        "DocumentDependentGraph only supports QualifiedIdJoinIndex version "
+        "V3.");
+  }
+
+  return std::unique_ptr<DocumentDependentGraph>(
+      new DocumentDependentGraph(schema_store, doc_store, join_index));
+}
+
+int DocumentDependentGraph::GetNumNodes() const {
+  DocumentId last_stored_doc_id = doc_store_.last_added_document_id();
+  if (last_stored_doc_id == kInvalidDocumentId) {
+    return 0;
+  }
+  // There are documents from 0 to last_stored_doc_id, so num nodes
+  // should be last_stored_doc_id + 1.
+  return last_stored_doc_id + 1;
+}
+
+libtextclassifier3::StatusOr<
+    std::unique_ptr<typename graph::GraphInterface<DocumentId>::EdgeIteratorIf>>
+DocumentDependentGraph::GetEdgesIterator(int node_id) const {
+  if (node_id < 0 || node_id >= GetNumNodes()) {
+    return absl_ports::InvalidArgumentError("Invalid node id.");
+  }
+
+  DocumentId doc_id = static_cast<DocumentId>(node_id);
+  if (!doc_store_.GetNonDeletedDocumentFilterData(doc_id).has_value()) {
+    // Return an iterator with no edge to advance to for a deleted document.
+    return std::make_unique<EdgeIterator>(
+        schema_store_, doc_store_,
+        QualifiedIdJoinIndex::DocumentJoinIdPairArrayView(/*data=*/nullptr,
+                                                          /*size=*/0));
+  }
+
+  ICING_ASSIGN_OR_RETURN(
+      QualifiedIdJoinIndex::DocumentJoinIdPairArrayView data_array_view,
+      join_index_.GetDocumentJoinIdPairArrayView(doc_id));
+  return std::make_unique<EdgeIterator>(schema_store_, doc_store_,
+                                        std::move(data_array_view));
+}
+
+libtextclassifier3::Status DocumentDependentGraph::EdgeIterator::Advance() {
+  while (++curr_idx_ < join_data_array_view_.size()) {
+    DocumentId next_doc_id = join_data_array_view_[curr_idx_].document_id();
+    JoinablePropertyId next_joinable_property_id =
+        join_data_array_view_[curr_idx_].joinable_property_id();
+
+    // Dedupe document id.
+    if (next_doc_id == curr_) {
+      continue;
+    }
+
+    // Lookup the schema type id of the next document.
+    std::optional<DocumentFilterData> next_doc_filter_data =
+        doc_store_.GetNonDeletedDocumentFilterData(next_doc_id);
+    if (!next_doc_filter_data.has_value() ||
+        next_doc_filter_data->schema_type_id() == kInvalidSchemaTypeId) {
+      continue;
+    }
+
+    // Get the joinable property metadata.
+    ICING_ASSIGN_OR_RETURN(
+        const JoinablePropertyMetadata* metadata,
+        schema_store_.GetJoinablePropertyMetadata(
+            next_doc_filter_data->schema_type_id(), next_joinable_property_id));
+
+    if (metadata->delete_propagation_type ==
+        JoinableConfig::DeletePropagationType::PROPAGATE_FROM) {
+      // Found a joinable property hit with delete propagation PROPAGATE_FROM.
+      // It means the next document is a dependent of the current document, so
+      // stop here, record the doc id and return success.
+      curr_ = next_doc_id;
+      return libtextclassifier3::Status::OK;
+    }
+  }
+
+  return absl_ports::ResourceExhaustedError("No more edges to advance to.");
+}
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/join/document-dependent-graph.h b/icing/join/document-dependent-graph.h
new file mode 100644
index 0000000..f516400
--- /dev/null
+++ b/icing/join/document-dependent-graph.h
@@ -0,0 +1,102 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_JOIN_DOCUMENT_DEPENDENT_GRAPH_H_
+#define ICING_JOIN_DOCUMENT_DEPENDENT_GRAPH_H_
+
+#include <memory>
+#include <utility>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/graph/graph-interface.h"
+#include "icing/join/qualified-id-join-index.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+
+namespace icing {
+namespace lib {
+
+// Document dependent graph using qualified id join index v3 as the data source.
+// This class is just an interface for the dependent graph and does not own any
+// data. Instead, it reads data from the given data sources and returns
+// dependent relations.
+//
+// Dependent graph:
+// - The nodes are the documents, and the node id type is DocumentId.
+// - The edges are directed and represent the dependencies between documents.
+//   For example, an edge A -> B means:
+//   - A is a dependency of B.
+//   - B is a dependent of A.
+//   - If A is deleted or expired, then B should be deleted or expired as well.
+class DocumentDependentGraph : public graph::GraphInterface<DocumentId> {
+ public:
+  // Creates a document dependent graph object.
+  //
+  // Returns:
+  //   - Non-null unique pointer of DocumentDependentGraph on success.
+  //   - FAILED_PRECONDITION_ERROR if any data source is null.
+  //   - INVALID_ARGUMENT_ERROR if join_index is not version V3.
+  //   - Any errors from the underlying data source.
+  static libtextclassifier3::StatusOr<std::unique_ptr<DocumentDependentGraph>>
+  Create(const SchemaStore* schema_store, const DocumentStore* doc_store,
+         const QualifiedIdJoinIndex* join_index);
+
+  int GetNumNodes() const override;
+
+  libtextclassifier3::StatusOr<std::unique_ptr<EdgeIteratorIf>>
+  GetEdgesIterator(int node_id) const override;
+
+ private:
+  class EdgeIterator : public EdgeIteratorIf {
+   public:
+    explicit EdgeIterator(
+        const SchemaStore& schema_store, const DocumentStore& doc_store,
+        QualifiedIdJoinIndex::DocumentJoinIdPairArrayView join_data_array_view)
+        : schema_store_(schema_store),
+          doc_store_(doc_store),
+          join_data_array_view_(std::move(join_data_array_view)),
+          curr_idx_(-1),
+          curr_(kInvalidDocumentId) {}
+
+    libtextclassifier3::Status Advance() override;
+
+    const DocumentId& Get() const override { return curr_; }
+
+   private:
+    const SchemaStore& schema_store_;  // Does not own.
+    const DocumentStore& doc_store_;   // Does not own.
+
+    QualifiedIdJoinIndex::DocumentJoinIdPairArrayView join_data_array_view_;
+    int curr_idx_;
+    DocumentId curr_;
+  };
+
+  explicit DocumentDependentGraph(const SchemaStore* schema_store,
+                                  const DocumentStore* doc_store,
+                                  const QualifiedIdJoinIndex* join_index)
+      : schema_store_(*schema_store),
+        doc_store_(*doc_store),
+        join_index_(*join_index) {}
+
+  const SchemaStore& schema_store_;         // Does not own.
+  const DocumentStore& doc_store_;          // Does not own.
+  const QualifiedIdJoinIndex& join_index_;  // Does not own.
+};
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_JOIN_DOCUMENT_DEPENDENT_GRAPH_H_
diff --git a/icing/join/document-dependent-graph_test.cc b/icing/join/document-dependent-graph_test.cc
new file mode 100644
index 0000000..1d36050
--- /dev/null
+++ b/icing/join/document-dependent-graph_test.cc
@@ -0,0 +1,858 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/join/document-dependent-graph.h"
+
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/document-builder.h"
+#include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
+#include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/graph/graph-interface.h"
+#include "icing/join/document-join-id-pair.h"
+#include "icing/join/qualified-id-join-index-impl-v2.h"
+#include "icing/join/qualified-id-join-index-impl-v3.h"
+#include "icing/join/qualified-id-join-indexing-handler.h"
+#include "icing/portable/gzip_stream.h"
+#include "icing/portable/platform.h"
+#include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
+#include "icing/proto/schema.pb.h"
+#include "icing/proto/scoring.pb.h"
+#include "icing/proto/search.pb.h"
+#include "icing/schema-builder.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+#include "icing/testing/common-matchers.h"
+#include "icing/testing/fake-clock.h"
+#include "icing/testing/test-data.h"
+#include "icing/testing/test-feature-flags.h"
+#include "icing/testing/tmp-directory.h"
+#include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
+#include "icing/util/icu-data-file-helper.h"
+#include "icing/util/status-macros.h"
+#include "icing/util/tokenized-document.h"
+#include "unicode/uloc.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::testing::ElementsAre;
+using ::testing::Eq;
+using ::testing::HasSubstr;
+using ::testing::IsEmpty;
+using ::testing::IsFalse;
+using ::testing::IsTrue;
+using ::testing::NotNull;
+
+class DocumentDependentGraphTest : public ::testing::Test {
+ protected:
+  void SetUp() override {
+    feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    ASSERT_THAT(feature_flags_->enable_repeated_field_joins(), IsTrue());
+
+    test_dir_ = GetTestTempDir() + "/document_dependent_graph_test";
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(test_dir_.c_str()),
+                IsTrue());
+
+    schema_store_dir_ = test_dir_ + "/schema_store";
+    doc_store_dir_ = test_dir_ + "/doc_store";
+    join_index_dir_ = test_dir_ + "/join_index";
+
+    if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
+      ICING_ASSERT_OK(
+          // File generated via icu_data_file rule in //icing/BUILD.
+          icu_data_file_helper::SetUpIcuDataFile(
+              GetTestFilePath("icing/icu.dat")));
+    }
+
+    language_segmenter_factory::SegmenterOptions options(ULOC_US);
+    ICING_ASSERT_OK_AND_ASSIGN(
+        lang_segmenter_,
+        language_segmenter_factory::Create(std::move(options)));
+
+    ASSERT_THAT(
+        filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()),
+        IsTrue());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        schema_store_, SchemaStore::Create(&filesystem_, schema_store_dir_,
+                                           &fake_clock_, feature_flags_.get()));
+
+    SchemaProto schema =
+        SchemaBuilder()
+            .AddType(
+                SchemaTypeConfigBuilder()
+                    .SetType("Label")
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("target")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
+                                     .SetCardinality(CARDINALITY_REPEATED))
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("target2")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
+                                     .SetCardinality(CARDINALITY_REPEATED))
+                    .AddProperty(PropertyConfigBuilder()
+                                     .SetName("softTarget")
+                                     .SetDataTypeJoinableString(
+                                         JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                                         DELETE_PROPAGATION_TYPE_NONE)
+                                     .SetCardinality(CARDINALITY_REPEATED)))
+
+            .Build();
+    ICING_ASSERT_OK(schema_store_->SetSchema(
+        schema, /*ignore_errors_and_delete_documents=*/false));
+
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
+                IsTrue());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::CreateResult create_result,
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
+    doc_store_ = std::move(create_result.document_store);
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        join_index_, QualifiedIdJoinIndexImplV3::Create(
+                         filesystem_, join_index_dir_, *feature_flags_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        join_indexing_handler_,
+        QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
+                                               join_index_.get()));
+  }
+
+  void TearDown() override {
+    join_indexing_handler_.reset();
+
+    join_index_.reset();
+    doc_store_.reset();
+    schema_store_.reset();
+    lang_segmenter_.reset();
+
+    filesystem_.DeleteDirectoryRecursively(test_dir_.c_str());
+  }
+
+  // Helper function to batch add documents.
+  libtextclassifier3::Status AddDocuments(
+      std::vector<DocumentProto> documents) {
+    // Tokenize all documents.
+    std::vector<TokenizedDocument> tokenized_documents;
+    tokenized_documents.reserve(documents.size());
+    for (DocumentProto& document : documents) {
+      ICING_ASSIGN_OR_RETURN(
+          TokenizedDocument tokenized_document,
+          TokenizedDocument::Create(
+              schema_store_.get(), lang_segmenter_.get(),
+              /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+              std::move(document)));
+      tokenized_documents.push_back(std::move(tokenized_document));
+    }
+
+    // Put all documents into the document store and get document ids.
+    std::vector<DocumentStore::PutResult> put_results;
+    put_results.reserve(documents.size());
+    for (const TokenizedDocument& tokenized_document : tokenized_documents) {
+      ICING_ASSIGN_OR_RETURN(
+          DocumentStore::PutResult put_result,
+          doc_store_->Put(tokenized_document.document_wrapper()));
+      put_results.push_back(std::move(put_result));
+    }
+
+    // Index all documents.
+    for (int i = 0; i < tokenized_documents.size(); ++i) {
+      ICING_RETURN_IF_ERROR(join_indexing_handler_->Handle(
+          tokenized_documents[i], put_results[i].new_document_id,
+          put_results[i].old_document_id, /*recovery_mode=*/false,
+          /*put_document_stats=*/nullptr));
+    }
+    return libtextclassifier3::Status::OK;
+  }
+
+  libtextclassifier3::StatusOr<std::vector<DocumentId>> GetEdgesOfNode(
+      const DocumentDependentGraph& graph, int node_id) {
+    ICING_ASSIGN_OR_RETURN(
+        std::unique_ptr<
+            typename graph::GraphInterface<DocumentId>::EdgeIteratorIf>
+            edge_itr,
+        graph.GetEdgesIterator(node_id));
+    std::vector<DocumentId> edges;
+    while (edge_itr->Advance().ok()) {
+      edges.push_back(edge_itr->Get());
+    }
+    return edges;
+  }
+
+  std::unique_ptr<FeatureFlags> feature_flags_;
+  Filesystem filesystem_;
+  FakeClock fake_clock_;
+  std::string test_dir_;
+  std::string schema_store_dir_;
+  std::string doc_store_dir_;
+  std::string join_index_dir_;
+
+  std::unique_ptr<LanguageSegmenter> lang_segmenter_;
+  std::unique_ptr<SchemaStore> schema_store_;
+  std::unique_ptr<DocumentStore> doc_store_;
+  std::unique_ptr<QualifiedIdJoinIndexImplV3> join_index_;
+
+  std::unique_ptr<QualifiedIdJoinIndexingHandler> join_indexing_handler_;
+};
+
+TEST_F(DocumentDependentGraphTest, CreationWithNullPointerShouldFail) {
+  EXPECT_THAT(
+      DocumentDependentGraph::Create(/*schema_store=*/nullptr, doc_store_.get(),
+                                     join_index_.get()),
+      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
+  EXPECT_THAT(
+      DocumentDependentGraph::Create(schema_store_.get(), /*doc_store=*/nullptr,
+                                     join_index_.get()),
+      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
+  EXPECT_THAT(
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     /*join_index=*/nullptr),
+      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       CreationWithWrongJoinIndexVersionShouldFail) {
+  std::string join_index_v2_dir = test_dir_ + "/join_index_v2";
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<QualifiedIdJoinIndexImplV2> join_index_v2,
+      QualifiedIdJoinIndexImplV2::Create(filesystem_, join_index_v2_dir,
+                                         /*pre_mapping_fbv=*/false));
+
+  EXPECT_THAT(DocumentDependentGraph::Create(
+                  schema_store_.get(), doc_store_.get(), join_index_v2.get()),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT,
+                       HasSubstr("DocumentDependentGraph only supports "
+                                 "QualifiedIdJoinIndex version V3.")));
+}
+
+TEST_F(DocumentDependentGraphTest, GetNumNodes) {
+  // Put and index 4 documents.
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 =
+      DocumentBuilder().SetKey("namespace", "uri/1").SetSchema("Label").Build();
+  DocumentProto doc2 =
+      DocumentBuilder().SetKey("namespace", "uri/2").SetSchema("Label").Build();
+  DocumentProto doc3 =
+      DocumentBuilder().SetKey("namespace", "uri/3").SetSchema("Label").Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3}));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  EXPECT_THAT(graph->GetNumNodes(), Eq(4));
+}
+
+TEST_F(DocumentDependentGraphTest, GetNumNodes_emptyStorage) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  EXPECT_THAT(graph->GetNumNodes(), Eq(0));
+}
+
+TEST_F(DocumentDependentGraphTest, GetNumNodes_withReplacedDocuments) {
+  // Put and index 1 document.
+  DocumentProto doc =
+      DocumentBuilder().SetKey("namespace", "uri").SetSchema("Label").Build();
+  ICING_ASSERT_OK(AddDocuments({doc}));
+
+  // Replace the document with new content.
+  DocumentProto doc_replaced = DocumentBuilder()
+                                   .SetKey("namespace", "uri")
+                                   .SetSchema("Label")
+                                   .AddStringProperty("target", "namespace#uri")
+                                   .Build();
+  ICING_ASSERT_OK(AddDocuments({doc_replaced}));
+
+  // Sanity check.
+  ASSERT_THAT(doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+              IsFalse());
+  ASSERT_THAT(doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+              IsTrue());
+
+  // Even though document 0 is replaced, num nodes should still be 2 since it is
+  // computed based on last stored doc id.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  EXPECT_THAT(graph->GetNumNodes(), Eq(2));
+}
+
+TEST_F(DocumentDependentGraphTest, GetNumNodes_withDeletedDocuments) {
+  // Put and index 1 document.
+  DocumentProto doc =
+      DocumentBuilder().SetKey("namespace", "uri").SetSchema("Label").Build();
+  ICING_ASSERT_OK(AddDocuments({doc}));
+
+  // Delete the document.
+  ICING_ASSERT_OK(doc_store_->Delete(
+      /*document_id=*/0,
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+
+  // Sanity check.
+  ASSERT_THAT(doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+              IsFalse());
+
+  // Even though document 0 is deleted, num nodes should still be 1 since it is
+  // computed based on last stored doc id.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  EXPECT_THAT(graph->GetNumNodes(), Eq(1));
+}
+
+TEST_F(DocumentDependentGraphTest, GetNumNodes_withExpiredDocuments) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Put and index 1 document which expires at 1000 ms.
+  DocumentProto doc = DocumentBuilder()
+                          .SetCreationTimestampMs(0)
+                          .SetTtlMs(1000)
+                          .SetKey("namespace", "uri")
+                          .SetSchema("Label")
+                          .Build();
+  ICING_ASSERT_OK(AddDocuments({doc}));
+
+  // Adjust the clock to expire the document.
+  fake_clock_.SetSystemTimeMilliseconds(2000);
+
+  // Sanity check.
+  ASSERT_THAT(doc_store_->GetAliveDocumentFilterData(
+                  /*document_id=*/0,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsFalse());
+  ASSERT_THAT(doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+              IsTrue());
+
+  // Even though document 0 is expired, num nodes should still be 1 since it is
+  // computed based on last stored doc id.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  EXPECT_THAT(graph->GetNumNodes(), Eq(1));
+}
+
+TEST_F(DocumentDependentGraphTest, GetEdgesIterator) {
+  // Put and index 5 documents with the following relations:
+  //
+  // doc0 ---+
+  //         |
+  //         +---> Doc2 --> Doc3
+  //         |
+  // doc1 ---+
+  //   |
+  //   +---------> Doc4
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 =
+      DocumentBuilder().SetKey("namespace", "uri/1").SetSchema("Label").Build();
+  DocumentProto doc2 =
+      DocumentBuilder()
+          .SetKey("namespace", "uri/2")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#uri/0", "namespace#uri/1")
+          .Build();
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetKey("namespace", "uri/3")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/2")
+                           .Build();
+  DocumentProto doc4 = DocumentBuilder()
+                           .SetKey("namespace", "uri/4")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3, doc4}));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(5));
+
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0),
+              IsOkAndHolds(ElementsAre(2)));
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/1),
+              IsOkAndHolds(ElementsAre(2, 4)));
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/2),
+              IsOkAndHolds(ElementsAre(3)));
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/3), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/4), IsOkAndHolds(IsEmpty()));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       GetEdgesIterator_withoutDeletePropagationShouldNotBeIncludedIntoEdges) {
+  // Put and index 2 documents with the following relations:
+  //
+  // doc0 --(no delete propagation)--> doc1
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("softTarget", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(2));
+
+  // Even though doc0 and doc1 have join relation, since the delete propagation
+  // type of "softTarget" is NONE, it should not be included into the dependent
+  // edges.
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/0))));
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0), IsOkAndHolds(IsEmpty()));
+}
+
+TEST_F(DocumentDependentGraphTest, GetEdgesIterator_shouldDedupeDocumentIds) {
+  // Put and index 2 documents with the following relations:
+  //
+  // doc0 -> doc1
+  //
+  // And doc0, doc1 can be joined by multiple joinable properties with delete
+  // propagation enabled.
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .AddStringProperty("target2", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(2));
+
+  // doc0 should have 2 join relations with doc1, but doc1 should be returned
+  // only once by the iterator.
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/2))));
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0),
+              IsOkAndHolds(ElementsAre(1)));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       GetEdgesIterator_replacedDocument_removeEdges) {
+  // Put and index 3 documents with the following relations:
+  //
+  // doc0 -> doc1 -> doc2
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2}));
+
+  // Replace doc1 with new relations.
+  // doc0  doc1_replaced -> doc2
+  DocumentProto doc1_replaced =
+      DocumentBuilder().SetKey("namespace", "uri/1").SetSchema("Label").Build();
+  ICING_ASSERT_OK(AddDocuments({doc1_replaced}));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(4));
+
+  // Sanity check: join indexing handler handled migrate parent, so doc id 1
+  // should be migrated to 3. Doc 0 should still contain the original relation
+  // with doc 1.
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1))));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
+      IsOkAndHolds(IsEmpty()));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+      IsOkAndHolds(IsEmpty()));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/2, /*joinable_property_id=*/1))));
+
+  // Doc 0 should skip the edge to doc 1, since doc 1 was replaced.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0), IsOkAndHolds(IsEmpty()));
+  // Doc 1 should return empty iterator since it was replaced.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/1), IsOkAndHolds(IsEmpty()));
+  // Doc 2 should remain the same.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/2), IsOkAndHolds(IsEmpty()));
+  // Doc 3 should contain 2.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/3),
+              IsOkAndHolds(ElementsAre(2)));
+}
+
+TEST_F(DocumentDependentGraphTest, GetEdgesIterator_replacedDocument_addEdges) {
+  // Put and index 4 documents with the following relations:
+  //
+  // doc0 -> doc1 -> doc2 -> doc3
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetKey("namespace", "uri/3")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/2")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3}));
+
+  // Replace doc2 with new relations.
+  // doc0 -> doc1 -> doc2_replaced -> doc3
+  //   |                  ^
+  //   |                  |
+  //   +------------------+
+  DocumentProto doc2_replaced =
+      DocumentBuilder()
+          .SetKey("namespace", "uri/2")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#uri/1", "namespace#uri/0")
+          .Build();
+  ICING_ASSERT_OK(AddDocuments({doc2_replaced}));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(5));
+
+  // Sanity check: join indexing handler handled migrate parent, so doc id 2
+  // should be migrated to 4. Doc 1 should still contain the original relation
+  // with doc 2.
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/4, /*joinable_property_id=*/1))));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/2, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/4, /*joinable_property_id=*/1))));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+      IsOkAndHolds(IsEmpty()));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+      IsOkAndHolds(IsEmpty()));
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/4),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/3, /*joinable_property_id=*/1))));
+
+  // Doc 0 should contain both edges to doc 1 and doc 4.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0),
+              IsOkAndHolds(ElementsAre(1, 4)));
+  // Doc 1 should skip the edge to doc 2, since doc 2 was replaced.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/1),
+              IsOkAndHolds(ElementsAre(4)));
+  // Doc 2 should return empty iterator since it was replaced.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/2), IsOkAndHolds(IsEmpty()));
+  // Doc 3 should remain the same.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/3), IsOkAndHolds(IsEmpty()));
+  // Doc 4 should contain 3.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/4),
+              IsOkAndHolds(ElementsAre(3)));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       GetEdgesIterator_deletedParentShouldReturnEmptyIterator) {
+  // Put and index 3 documents with the following relations:
+  //
+  // doc0 -> doc1
+  //  |
+  //  +----> doc2
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2}));
+
+  // Delete doc0.
+  ICING_ASSERT_OK(doc_store_->Delete(
+      /*document_id=*/0,
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(3));
+
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/2, /*joinable_property_id=*/1))));
+  // Since doc0 is deleted, the iterator should return empty.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0), IsOkAndHolds(IsEmpty()));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       GetEdgesIterator_deletedChildShouldBeSkipped) {
+  // Put and index 3 documents with the following relations:
+  //
+  // doc0 -> doc1
+  //  |
+  //  +----> doc2
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2}));
+
+  // Delete doc1.
+  ICING_ASSERT_OK(doc_store_->Delete(
+      /*document_id=*/1,
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(3));
+
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/2, /*joinable_property_id=*/1))));
+  // Since doc1 is deleted, the iterator of doc0 should skip doc1.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0),
+              IsOkAndHolds(ElementsAre(2)));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       GetEdgesIterator_expiredParentShouldNotBeSkipped) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Put and index 3 documents with the following relations:
+  //
+  // doc0 -> doc1
+  //  |
+  //  +----> doc2
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(1000)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2}));
+
+  // Adjust the clock to expire doc0.
+  fake_clock_.SetSystemTimeMilliseconds(2000);
+  ASSERT_THAT(doc_store_->GetAliveDocumentFilterData(
+                  /*document_id=*/0,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsFalse());
+  ASSERT_THAT(doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+              IsTrue());
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(3));
+
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/2, /*joinable_property_id=*/1))));
+  // We should still be able to get all of doc0's edges.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0),
+              IsOkAndHolds(ElementsAre(1, 2)));
+}
+
+TEST_F(DocumentDependentGraphTest,
+       GetEdgesIterator_expiredChildShouldNotBeSkipped) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Put and index 3 documents with the following relations:
+  //
+  // doc0 -> doc1
+  //  |
+  //  +----> doc2
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(1000)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2}));
+
+  // Adjust the clock to expire doc1.
+  fake_clock_.SetSystemTimeMilliseconds(2000);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+  ASSERT_THAT(graph->GetNumNodes(), Eq(3));
+
+  ASSERT_THAT(
+      join_index_->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+      IsOkAndHolds(ElementsAre(
+          DocumentJoinIdPair(/*document_id=*/1, /*joinable_property_id=*/1),
+          DocumentJoinIdPair(/*document_id=*/2, /*joinable_property_id=*/1))));
+  // We should still be able to get doc1 from doc0's edge iterator.
+  EXPECT_THAT(GetEdgesOfNode(*graph, /*node_id=*/0),
+              IsOkAndHolds(ElementsAre(1, 2)));
+}
+
+TEST_F(DocumentDependentGraphTest, GetEdgesIterator_invalidNodeIdShouldFail) {
+  ASSERT_THAT(doc_store_->last_added_document_id(), Eq(kInvalidDocumentId));
+  ASSERT_THAT(join_index_->last_added_document_id(), Eq(kInvalidDocumentId));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<DocumentDependentGraph> graph,
+      DocumentDependentGraph::Create(schema_store_.get(), doc_store_.get(),
+                                     join_index_.get()));
+
+  EXPECT_THAT(graph->GetNumNodes(), Eq(0));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/-2),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/-1),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/0),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/1),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/2),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/kInvalidDocumentId),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+
+  // Put and index 2 documents.
+  DocumentProto doc0 =
+      DocumentBuilder().SetKey("namespace", "uri/0").SetSchema("Label").Build();
+  DocumentProto doc1 =
+      DocumentBuilder().SetKey("namespace", "uri/1").SetSchema("Label").Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+  ASSERT_THAT(doc_store_->last_added_document_id(), Eq(1));
+  ASSERT_THAT(join_index_->last_added_document_id(), Eq(1));
+
+  EXPECT_THAT(graph->GetNumNodes(), Eq(2));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/-2),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/-1),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/0), IsOkAndHolds(NotNull()));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/1), IsOkAndHolds(NotNull()));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/2),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(graph->GetEdgesIterator(/*node_id=*/kInvalidDocumentId),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/join/expiration-timestamp-util.cc b/icing/join/expiration-timestamp-util.cc
new file mode 100644
index 0000000..ed518d4
--- /dev/null
+++ b/icing/join/expiration-timestamp-util.cc
@@ -0,0 +1,159 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/join/expiration-timestamp-util.h"
+
+#include <algorithm>
+#include <cstdint>
+#include <limits>
+#include <memory>
+#include <optional>
+#include <queue>
+#include <unordered_set>
+#include <utility>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/graph/graph-interface.h"
+#include "icing/join/document-dependent-graph.h"
+#include "icing/join/qualified-id-join-index.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-filter-data.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+#include "icing/util/logging.h"
+#include "icing/util/status-macros.h"
+
+namespace icing {
+namespace lib {
+
+/* static */ libtextclassifier3::Status
+ExpirationTimestampUtil::SingleDocumentPropagation(
+    DocumentId document_id,
+    const std::unordered_set<DocumentId>& dependency_doc_ids,
+    const SchemaStore& schema_store,
+    const QualifiedIdJoinIndex& qualified_id_join_index,
+    DocumentStore& document_store, int64_t current_time_ms) {
+  // This function implements the algorithm to:
+  // - Update the given document's expiration timestamp by its given
+  //   dependencies. Mostly its dependencies are determined by the dependency
+  //   evaluation. See DocumentDependencyProcessor for more details.
+  // - Propagate the expiration timestamp to all of the given document's
+  //   non-deleted dependents (and their dependents, and so on), based on the
+  //   dependent graph.
+  //
+  // For example:
+  // - dependency_doc_ids = {depcy1, depcy2}
+  // - dependent_graph contains the edges of the following graph.
+  //
+  //                 +--------> dept1 ------+
+  //                 |                      |
+  //                 |                      v
+  // depcy1 --> document_id --> dept2 --> dept3
+  //                 ^            |
+  //                 |            v
+  // depcy2 ---------+          dept4
+  //
+  // The algorithm will:
+  // - Update document_id's expiration timestamp by min(depcy1_exp_ts,
+  //   depcy2_exp_ts) if this min value is smaller than the document's current
+  //   expiration timestamp.
+  // - BFS traverse: propagate the expiration timestamp to dept1, dept2, dept3,
+  //   and dept4. Early stop if any of the dependents' expiration timestamp is
+  //   not smaller than the propagated value.
+
+  // Step 1.0: get the min expiration timestamp of the dependencies.
+  int64_t min_depcy_exp_ts_ms = std::numeric_limits<int64_t>::max();
+  for (DocumentId depcy_doc_id : dependency_doc_ids) {
+    std::optional<DocumentFilterData> doc_filter_data =
+        document_store.GetAliveDocumentFilterData(depcy_doc_id,
+                                                  current_time_ms);
+    if (!doc_filter_data.has_value()) {
+      // This really shouldn't happen since they were validated in the caller
+      // side by DocumentDependencyProcessor.
+      ICING_LOG(ERROR) << "A dependency document is not alive after dependency "
+                          "evaluation. This should never happen.";
+      return absl_ports::InternalError(
+          "A dependency document is not alive after dependency evaluation.");
+    }
+    min_depcy_exp_ts_ms = std::min(min_depcy_exp_ts_ms,
+                                   doc_filter_data->expiration_timestamp_ms());
+  }
+
+  // Step 1.1: update min expiration timestamp from dependencies to the
+  //           document.
+  //
+  // Note:
+  // - UpdateDocumentExpirationTimestamp only overwrites the new expiration
+  //   timestamp if the new value is smaller than the existing one, so it is
+  //   safe to call this method directly.
+  // - final_exp_ts is the final expiration timestamp of the document.
+  //   - If min_depcy_exp_ts_ms is smaller than the document's current (raw)
+  //     expiration timestamp, final_exp_ts will be min_depcy_exp_ts_ms.
+  //   - Otherwise, final_exp_ts will be the document's (raw) expiration
+  //     timestamp.
+  ICING_ASSIGN_OR_RETURN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result,
+      document_store.UpdateDocumentExpirationTimestamp(document_id,
+                                                       min_depcy_exp_ts_ms));
+  int64_t final_exp_ts = update_result.final_expiration_timestamp_ms;
+
+  // Step 2: run BFS to propagate final_exp_ts to all dependents. In most cases,
+  //         a new document won't have any dependents at this point. Only alive
+  //         document replacement will have dependents to update.
+  ICING_ASSIGN_OR_RETURN(
+      std::unique_ptr<DocumentDependentGraph> dependent_graph,
+      DocumentDependentGraph::Create(&schema_store, &document_store,
+                                     &qualified_id_join_index));
+
+  std::unordered_set<DocumentId> visited_doc_ids;
+  std::queue<DocumentId> que;
+  visited_doc_ids.insert(document_id);
+  que.push(document_id);
+  while (!que.empty()) {
+    DocumentId curr_doc_id = que.front();
+    que.pop();
+
+    ICING_ASSIGN_OR_RETURN(
+        std::unique_ptr<graph::GraphInterface<DocumentId>::EdgeIteratorIf> itr,
+        dependent_graph->GetEdgesIterator(curr_doc_id));
+    while (itr->Advance().ok()) {
+      DocumentId next_doc_id = itr->Get();
+      if (!visited_doc_ids.insert(next_doc_id).second) {
+        // Already visited.
+        continue;
+      }
+
+      // Update the next document's expiration timestamp. Push into the queue
+      // only if the expiration timestamp is updated.
+      //
+      // Note: it is safe to call UpdateDocumentExpirationTimestamp directly and
+      //   return if getting an error here, because DocumentDependentGraph
+      //   returns edges to non deleted documents and at this point next_doc_id
+      //   is guaranteed to be valid and non-deleted.
+      ICING_ASSIGN_OR_RETURN(
+          DocumentStore::UpdateDocumentExpirationTimestampResult
+              dependent_update_result,
+          document_store.UpdateDocumentExpirationTimestamp(next_doc_id,
+                                                           final_exp_ts));
+      if (dependent_update_result.was_updated) {
+        que.push(next_doc_id);
+      }
+    }
+  }
+  return libtextclassifier3::Status::OK;
+}
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/join/expiration-timestamp-util.h b/icing/join/expiration-timestamp-util.h
new file mode 100644
index 0000000..759772a
--- /dev/null
+++ b/icing/join/expiration-timestamp-util.h
@@ -0,0 +1,82 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_JOIN_EXPIRATION_TIMESTAMP_UTIL_H_
+#define ICING_JOIN_EXPIRATION_TIMESTAMP_UTIL_H_
+
+#include <cstdint>
+#include <unordered_set>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/join/qualified-id-join-index.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-id.h"
+#include "icing/store/document-store.h"
+
+namespace icing {
+namespace lib {
+
+class ExpirationTimestampUtil {
+ public:
+  // Updates the given single document's expiration timestamp by its
+  // dependencies. Also propagates the expiration timestamp to all of its
+  // "non-deleted" dependents (and their dependents, and so on), based on the
+  // dependent graph stored in the join index.
+  //
+  // Note:
+  // - The implementation is designed for updating a single document in (single)
+  //   Put API.
+  // - To make it efficient, currently it only allows a smaller expiration
+  //   timestamp to be propagated down. IOW, if the new expiration timestamp is
+  //   larger than the existing one, the existing one will be kept and stop
+  //   propagation.
+  // - Therefore, we can run simple BFS instead of Bellman-Ford algorithm, and
+  //   the time complexity is better.
+  // - In the future, if we decide to support updating (1) multiple documents on
+  //   the subgraph for batch API (2) larger expiration timestamp, then:
+  //   - Running K times BFS (K = number of documents to update) is not
+  //     efficient.
+  //   - Bellman-Ford algorithm is not efficient enough either, especially when
+  //     there are cycles in the dependent graph.
+  //   - We should consider running the SCC + topological sort algorithm to
+  //     propagate the expiration timestamp in linear time complexity.
+  //   - For optimization, subgraph SCC and topological sort can be performed,
+  //     but this requires to store the reverse dependent edges for determining
+  //     the subgraph that requires updating.
+  //
+  // Parameters:
+  //   - document_id: the single document id to update.
+  //   - dependency_doc_ids: dependencies of the document_id.
+  //   - schema_store: the schema store.
+  //   - qualified_id_join_index: the qualified id join index.
+  //   - document_store.
+  //   - current_time_ms.
+  //
+  // Returns:
+  //   - OK on success, and the expiration timestamps (which are stored in
+  //     DocumentStore -> DocumentFilterData cache) of the document and its
+  //     dependents are updated.
+  //   - Any error from document store, schema store, or join index.
+  static libtextclassifier3::Status SingleDocumentPropagation(
+      DocumentId document_id,
+      const std::unordered_set<DocumentId>& dependency_doc_ids,
+      const SchemaStore& schema_store,
+      const QualifiedIdJoinIndex& qualified_id_join_index,
+      DocumentStore& document_store, int64_t current_time_ms);
+};
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_JOIN_EXPIRATION_TIMESTAMP_UTIL_H_
diff --git a/icing/join/expiration-timestamp-util_test.cc b/icing/join/expiration-timestamp-util_test.cc
new file mode 100644
index 0000000..531dfc5
--- /dev/null
+++ b/icing/join/expiration-timestamp-util_test.cc
@@ -0,0 +1,947 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/join/expiration-timestamp-util.h"
+
+#include <memory>
+#include <optional>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/document-builder.h"
+#include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
+#include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/join/qualified-id-join-index-impl-v3.h"
+#include "icing/join/qualified-id-join-indexing-handler.h"
+#include "icing/portable/gzip_stream.h"
+#include "icing/portable/platform.h"
+#include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
+#include "icing/proto/schema.pb.h"
+#include "icing/proto/scoring.pb.h"
+#include "icing/proto/search.pb.h"
+#include "icing/schema-builder.h"
+#include "icing/schema/schema-store.h"
+#include "icing/store/document-filter-data.h"
+#include "icing/store/document-store.h"
+#include "icing/testing/common-matchers.h"
+#include "icing/testing/fake-clock.h"
+#include "icing/testing/test-data.h"
+#include "icing/testing/test-feature-flags.h"
+#include "icing/testing/tmp-directory.h"
+#include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
+#include "icing/util/icu-data-file-helper.h"
+#include "icing/util/status-macros.h"
+#include "icing/util/tokenized-document.h"
+#include "unicode/uloc.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::testing::Eq;
+using ::testing::IsFalse;
+using ::testing::IsTrue;
+using ::testing::Optional;
+using ::testing::Property;
+
+class ExpirationTimestampUtilTest : public ::testing::Test {
+ protected:
+  void SetUp() override {
+    feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    ASSERT_THAT(feature_flags_->enable_repeated_field_joins(), IsTrue());
+
+    test_dir_ = GetTestTempDir() + "/expiration_timestamp_util_test";
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(test_dir_.c_str()),
+                IsTrue());
+
+    schema_store_dir_ = test_dir_ + "/schema_store";
+    doc_store_dir_ = test_dir_ + "/doc_store";
+    qualified_id_join_index_dir_ = test_dir_ + "/qualified_id_join_index";
+
+    if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
+      ICING_ASSERT_OK(
+          // File generated via icu_data_file rule in //icing/BUILD.
+          icu_data_file_helper::SetUpIcuDataFile(
+              GetTestFilePath("icing/icu.dat")));
+    }
+
+    language_segmenter_factory::SegmenterOptions options(ULOC_US);
+    ICING_ASSERT_OK_AND_ASSIGN(
+        lang_segmenter_,
+        language_segmenter_factory::Create(std::move(options)));
+
+    ASSERT_THAT(
+        filesystem_.CreateDirectoryRecursively(schema_store_dir_.c_str()),
+        IsTrue());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        schema_store_, SchemaStore::Create(&filesystem_, schema_store_dir_,
+                                           &fake_clock_, feature_flags_.get()));
+
+    SchemaProto schema =
+        SchemaBuilder()
+            .AddType(SchemaTypeConfigBuilder().SetType("Label").AddProperty(
+                PropertyConfigBuilder()
+                    .SetName("target")
+                    .SetDataTypeJoinableString(
+                        JOINABLE_VALUE_TYPE_QUALIFIED_ID,
+                        DELETE_PROPAGATION_TYPE_PROPAGATE_FROM)
+                    .SetCardinality(CARDINALITY_REPEATED)))
+
+            .Build();
+    ASSERT_THAT(schema_store_->SetSchema(
+                    schema, /*ignore_errors_and_delete_documents=*/false),
+                IsOk());
+
+    ASSERT_THAT(filesystem_.CreateDirectoryRecursively(doc_store_dir_.c_str()),
+                IsTrue());
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::CreateResult create_result,
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
+    doc_store_ = std::move(create_result.document_store);
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        qualified_id_join_index_,
+        QualifiedIdJoinIndexImplV3::Create(
+            filesystem_, qualified_id_join_index_dir_, *feature_flags_));
+
+    ICING_ASSERT_OK_AND_ASSIGN(
+        qualified_id_join_indexing_handler_,
+        QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
+                                               qualified_id_join_index_.get()));
+  }
+
+  void TearDown() override {
+    qualified_id_join_indexing_handler_.reset();
+
+    qualified_id_join_index_.reset();
+    doc_store_.reset();
+    schema_store_.reset();
+    lang_segmenter_.reset();
+
+    filesystem_.DeleteDirectoryRecursively(test_dir_.c_str());
+  }
+
+  // Helper function to batch add documents.
+  libtextclassifier3::Status AddDocuments(
+      std::vector<DocumentProto> documents) {
+    // Tokenize all documents.
+    std::vector<TokenizedDocument> tokenized_documents;
+    tokenized_documents.reserve(documents.size());
+    for (DocumentProto& document : documents) {
+      ICING_ASSIGN_OR_RETURN(
+          TokenizedDocument tokenized_document,
+          TokenizedDocument::Create(
+              schema_store_.get(), lang_segmenter_.get(),
+              /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+              std::move(document)));
+      tokenized_documents.push_back(std::move(tokenized_document));
+    }
+
+    // Put all documents into the document store and get document ids.
+    std::vector<DocumentStore::PutResult> put_results;
+    put_results.reserve(documents.size());
+    for (const TokenizedDocument& tokenized_document : tokenized_documents) {
+      ICING_ASSIGN_OR_RETURN(
+          DocumentStore::PutResult put_result,
+          doc_store_->Put(tokenized_document.document_wrapper()));
+      put_results.push_back(std::move(put_result));
+    }
+
+    // Index all documents.
+    for (int i = 0; i < tokenized_documents.size(); ++i) {
+      ICING_RETURN_IF_ERROR(qualified_id_join_indexing_handler_->Handle(
+          tokenized_documents[i], put_results[i].new_document_id,
+          put_results[i].old_document_id, /*recovery_mode=*/false,
+          /*put_document_stats=*/nullptr));
+    }
+    return libtextclassifier3::Status::OK;
+  }
+
+  std::unique_ptr<FeatureFlags> feature_flags_;
+  Filesystem filesystem_;
+  FakeClock fake_clock_;
+  std::string test_dir_;
+  std::string schema_store_dir_;
+  std::string doc_store_dir_;
+  std::string qualified_id_join_index_dir_;
+
+  std::unique_ptr<LanguageSegmenter> lang_segmenter_;
+  std::unique_ptr<SchemaStore> schema_store_;
+  std::unique_ptr<DocumentStore> doc_store_;
+  std::unique_ptr<QualifiedIdJoinIndexImplV3> qualified_id_join_index_;
+
+  std::unique_ptr<QualifiedIdJoinIndexingHandler>
+      qualified_id_join_indexing_handler_;
+};
+
+TEST_F(ExpirationTimestampUtilTest, SingleDocumentPropagation) {
+  // General test for SingleDocumentPropagation.
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create docs with the following (raw) expiration timestamps and relations:
+  //
+  //                     +------> dept1 (30) -------+
+  //                     |                          |
+  //                     |                          v
+  // depcy1 (10) ---> doc (5) --> dept2 (30) --> dept3 (30)
+  //                     ^           |
+  //                     |           v
+  // depcy2 (2) ---------+        dept4 (30)
+  DocumentProto depcy1 = DocumentBuilder()
+                             .SetCreationTimestampMs(0)
+                             .SetTtlMs(10)
+                             .SetKey("namespace", "depcy1")
+                             .SetSchema("Label")
+                             .Build();
+  DocumentProto depcy2 = DocumentBuilder()
+                             .SetCreationTimestampMs(0)
+                             .SetTtlMs(2)
+                             .SetKey("namespace", "depcy2")
+                             .SetSchema("Label")
+                             .Build();
+  DocumentProto doc =
+      DocumentBuilder()
+          .SetCreationTimestampMs(0)
+          .SetTtlMs(5)
+          .SetKey("namespace", "doc")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#depcy1", "namespace#depcy2")
+          .Build();
+  DocumentProto dept1 = DocumentBuilder()
+                            .SetCreationTimestampMs(0)
+                            .SetTtlMs(30)
+                            .SetKey("namespace", "dept1")
+                            .SetSchema("Label")
+                            .AddStringProperty("target", "namespace#doc")
+                            .Build();
+  DocumentProto dept2 = DocumentBuilder()
+                            .SetCreationTimestampMs(0)
+                            .SetTtlMs(30)
+                            .SetKey("namespace", "dept2")
+                            .SetSchema("Label")
+                            .AddStringProperty("target", "namespace#doc")
+                            .Build();
+  DocumentProto dept3 =
+      DocumentBuilder()
+          .SetCreationTimestampMs(0)
+          .SetTtlMs(30)
+          .SetKey("namespace", "dept3")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#dept1", "namespace#dept2")
+          .Build();
+  DocumentProto dept4 = DocumentBuilder()
+                            .SetCreationTimestampMs(0)
+                            .SetTtlMs(30)
+                            .SetKey("namespace", "dept4")
+                            .SetSchema("Label")
+                            .AddStringProperty("target", "namespace#dept2")
+                            .Build();
+  // Add all documents. Note that they will have document ids 0, 1, 2, 3, 4,
+  // 5, 6.
+  ICING_ASSERT_OK(
+      AddDocuments({depcy1, depcy2, doc, dept1, dept2, dept3, dept4}));
+
+  // Run the expiration timestamp propagation on doc (id 2) with its
+  // dependencies depcy1 and depcy2 (id 0 and 1).
+  //
+  // The expiration timestamps should become:
+  //                     +------> dept1 (2) -------+
+  //                     |                         |
+  //                     |                         v
+  // depcy1 (10) ---> doc (2) --> dept2 (2) --> dept3 (2)
+  //                     ^           |
+  //                     |           v
+  // depcy2 (2) ---------+        dept4 (2)
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/2, /*dependency_doc_ids=*/{0, 1},
+                  *schema_store_, *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+
+  // depcy1 and depcy2 should not be updated.
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(10))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+
+  // Verify doc, dept1, dept2, dept3, and dept4's expiration timestamps are
+  // updated.
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/3),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/4),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/5),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/6),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+}
+
+TEST_F(
+    ExpirationTimestampUtilTest,
+    SingleDocumentPropagation_updateFromDependency_shouldUpdateToSmallerExpTs) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create doc0 and doc1 with raw expiration timestamps 10 and 2.
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(2)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+
+  // Create doc2 with raw expiration timestamp 5 and with the following
+  // relations:
+  //
+  // doc0 (10) --+
+  //             |
+  //             +---> doc2 (5)
+  //             |
+  // doc1 (2) ---+
+  DocumentProto doc2 =
+      DocumentBuilder()
+          .SetCreationTimestampMs(0)
+          .SetTtlMs(5)
+          .SetKey("namespace", "uri/2")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#uri/0", "namespace#uri/1")
+          .Build();
+  ICING_ASSERT_OK(AddDocuments({doc2}));
+
+  // Sanity check on the document filter data before propagation.
+  ASSERT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(10))));
+  ASSERT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  ASSERT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(5))));
+
+  // Run the expiration timestamp propagation on doc2 with its dependencies doc0
+  // and doc1. Doc2's expiration timestamp should be updated to 2.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/2, /*dependency_doc_ids=*/{0, 1},
+                  *schema_store_, *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+}
+
+TEST_F(
+    ExpirationTimestampUtilTest,
+    SingleDocumentPropagation_updateFromDependency_shouldIgnoreGreaterExpTs) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create doc0 and doc1 with raw expiration timestamps 10 and 15.
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(15)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+
+  // Create doc2 with raw expiration timestamp 5 and with the following
+  // relations:
+  //
+  // doc0 (10) --+
+  //             |
+  //             +---> doc2 (5)
+  //             |
+  // doc1 (15) --+
+  DocumentProto doc2 =
+      DocumentBuilder()
+          .SetCreationTimestampMs(0)
+          .SetTtlMs(5)
+          .SetKey("namespace", "uri/2")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#uri/0", "namespace#uri/1")
+          .Build();
+  ICING_ASSERT_OK(AddDocuments({doc2}));
+
+  // Sanity check on the document filter data before propagation.
+  ASSERT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(10))));
+  ASSERT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(15))));
+  ASSERT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(5))));
+
+  // Run the expiration timestamp propagation on doc2 with its dependencies doc0
+  // and doc1. Since all of its dependencies have greater expiration timestamps,
+  // doc2's expiration timestamp should remain 5 after propagation.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/2, /*dependency_doc_ids=*/{0, 1},
+                  *schema_store_, *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(5))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_updateFromDependency_selfCycle) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create a document with a self cycle relation.
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/0")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0}));
+
+  // Run the expiration timestamp propagation on doc0.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{0}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(10))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_smallerExpTs) {
+  // Note: in the actual integration with IcingSearchEngine, the only case to
+  //   propagate to dependent is when replacing an existing parent document, but
+  //   for testing purpose, we can just simply create all documents at once and
+  //   run the algorithm on the target document directly without creating
+  //   replacement scenario.
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following (raw) expiration timestamps and
+  // relations:
+  //
+  // doc0 (2) ---> doc1 (5) ----> doc3 (1)
+  //    |
+  //    +--------> doc2 (10) ---> doc4 (3)
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(2)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(5)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(1)
+                           .SetKey("namespace", "uri/3")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  DocumentProto doc4 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(3)
+                           .SetKey("namespace", "uri/4")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/2")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3, doc4}));
+
+  // Run the expiration timestamp propagation on doc0. It should propagate to
+  // doc1, doc2, and doc4.
+  //
+  // Final graph:
+  // doc0 (2) ----> doc1 (2) ----> doc3 (1)
+  //    |
+  //    +---------> doc2 (2) ----> doc4 (2)
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/3),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(1))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/4),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_greaterExpTs) {
+  // Note: in the actual integration with IcingSearchEngine, the only case to
+  //   propagate to dependent is when replacing an existing parent document, but
+  //   for testing purpose, we can just simply create all documents at once and
+  //   run the algorithm on the target document directly without creating
+  //   replacement scenario.
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following (raw) expiration timestamps and
+  // relations:
+  //
+  // doc0 (15) ---> doc1 (5) ----> doc3 (1)
+  //    |
+  //    +---------> doc2 (10) ---> doc4 (3)
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(15)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(5)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(1)
+                           .SetKey("namespace", "uri/3")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  DocumentProto doc4 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(3)
+                           .SetKey("namespace", "uri/4")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/2")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3, doc4}));
+
+  // Run the expiration timestamp propagation on doc0. Since it has greater
+  // expiration timestamp than all of its dependents, no dependents' expiration
+  // timestamps should be updated.
+  //
+  // Final graph:
+  // doc0 (15) ---> doc1 (5) ----> doc3 (1)
+  //    |
+  //    +---------> doc2 (10) ---> doc4 (3)
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(15))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(5))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(10))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/3),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(1))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/4),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(3))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_expTsShouldOnlyDecrease) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following raw expiration timestamps and
+  // relations:
+  //
+  // doc0 (raw 10) --+
+  //                 |
+  //                 +---> doc2 (raw 8)
+  //                 |
+  // doc1 (raw 5) ---+
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(5)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc2 =
+      DocumentBuilder()
+          .SetCreationTimestampMs(0)
+          .SetTtlMs(8)
+          .SetKey("namespace", "uri/2")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#uri/0", "namespace#uri/1")
+          .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2}));
+
+  // Run the expiration timestamp propagation on doc2. It should have
+  // (expiration ts, raw expiration ts) = (5, 8).
+  //
+  // doc0 (10, 10) --+
+  //                 |
+  //                 +---> doc2 (5, 8)
+  //                 |
+  // doc1 (5, 5) ----+
+  ASSERT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/2, /*dependency_doc_ids=*/{0, 1},
+                  *schema_store_, *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  std::optional<DocumentFilterData> filter_data =
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2);
+  ASSERT_THAT(filter_data->expiration_timestamp_ms(), Eq(5));
+  ASSERT_THAT(filter_data->raw_expiration_timestamp_ms(), Eq(8));
+
+  // Create doc3 with raw expiration timestamp 7 and the same key as doc1.
+  // Use it to replace doc1.
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(7)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc3}));
+
+  // Run the expiration timestamp propagation on doc3.
+  //
+  // doc0 (10, 10) --+
+  //                 |
+  //                 +---> doc2 (_, 8)
+  //                 |
+  // doc3 (7, 7) ----+
+  //
+  // According to the graph, if doc2 had been added after doc0 and doc3, then it
+  // should've had expiration timestamp 7 after propagation. But since doc3 is a
+  // replacement update now and the BFS algorithm only decreases the expiration
+  // timestamp of doc2 without considering potential increase caused by
+  // dependency replacement, doc2 should still have expiration timestamp 5.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/3, /*dependency_doc_ids=*/{}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(5))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_cycle) {
+  // Note: in the actual integration with IcingSearchEngine, the only case to
+  //   propagate to dependent is when replacing an existing parent document, but
+  //   for testing purpose, we can just simply create all documents at once and
+  //   run the algorithm on the target document directly without creating
+  //   replacement scenario.
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following raw expiration timestamps and
+  // relations:
+  //
+  // doc0 (raw 2) ----> doc1 (raw 5)
+  //    ^                   |
+  //    |                   |
+  //    |                   v
+  // doc3 (raw 7) <---- doc2 (raw 8)
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(2)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/3")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(5)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(8)
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(7)
+                           .SetKey("namespace", "uri/3")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/2")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3}));
+
+  // Run the expiration timestamp propagation on doc0.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{3}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+
+  // All of them should have expiration timestamp 2.
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/3),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_shouldSkipDeleted) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following (raw) expiration timestamps and
+  // relations:
+  //
+  // doc0 (5) ---> doc1 (10)
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(5)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+
+  // Delete doc1.
+  ICING_ASSERT_OK(doc_store_->Delete(
+      /*document_id=*/1,
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+
+  // Run the expiration timestamp propagation on doc0. doc1 should be skipped
+  // since it's deleted.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(5))));
+  EXPECT_THAT(doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+              IsFalse());
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_shouldSkipExpired) {
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following (raw) expiration timestamps and
+  // relations:
+  //
+  // doc0 (30) ---> doc1 (10)
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(30)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(10)
+                           .SetKey("namespace", "uri/1")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/0")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1}));
+
+  // Adjust the current time to 20. It makes doc1 expired.
+  fake_clock_.SetSystemTimeMilliseconds(20);
+
+  // Run the expiration timestamp propagation on doc0. doc1 is still traversed
+  // and we attempt to set the propagated expiration timestamp, but the new
+  // value is always larger than the existing one, so it's skipped.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(30))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(10))));
+}
+
+TEST_F(ExpirationTimestampUtilTest,
+       SingleDocumentPropagation_propgateToDependents_noBellmanFord) {
+  // Note: in the actual integration with IcingSearchEngine, this update
+  //   scenario is not possible. But for testing purpose, we want to make sure
+  //   the algorithm doesn't traverse nodes on a cycle for multiple times, which
+  //   has bad time complexity of O(V*E).
+  fake_clock_.SetSystemTimeMilliseconds(0);
+
+  // Create documents with the following raw expiration timestamps and
+  // relations:
+  //
+  // doc0 (raw 4) ----> doc1 (raw 8) <---------+
+  //                         |                 |
+  //                         |                 |
+  //                         v                 |
+  //                    doc2 (raw 5) ---> doc3 (raw 2)
+  DocumentProto doc0 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(4)
+                           .SetKey("namespace", "uri/0")
+                           .SetSchema("Label")
+                           .Build();
+  DocumentProto doc1 =
+      DocumentBuilder()
+          .SetCreationTimestampMs(0)
+          .SetTtlMs(8)
+          .SetKey("namespace", "uri/1")
+          .SetSchema("Label")
+          .AddStringProperty("target", "namespace#uri/0", "namespace#uri/3")
+          .Build();
+  DocumentProto doc2 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(5)
+                           .SetKey("namespace", "uri/2")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/1")
+                           .Build();
+  DocumentProto doc3 = DocumentBuilder()
+                           .SetCreationTimestampMs(0)
+                           .SetTtlMs(2)
+                           .SetKey("namespace", "uri/3")
+                           .SetSchema("Label")
+                           .AddStringProperty("target", "namespace#uri/2")
+                           .Build();
+  ICING_ASSERT_OK(AddDocuments({doc0, doc1, doc2, doc3}));
+
+  // Run the expiration timestamp propagation on doc0.
+  EXPECT_THAT(ExpirationTimestampUtil::SingleDocumentPropagation(
+                  /*document_id=*/0, /*dependency_doc_ids=*/{}, *schema_store_,
+                  *qualified_id_join_index_, *doc_store_,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+
+  // - According to the definition of the dependency, doc1, doc2, and doc3
+  //   should've had expiration timestamp 2.
+  // - But here, we're not running Bellman-Ford algorithm, so when starting from
+  //   doc0, the expiration timestamp of doc3 is not propagated. So doc3 should
+  //   remain 2, and doc1 and doc2 should be updated to 4.
+  //
+  // Note: in reality, when we added doc3, another round of propagation
+  //   should've propagated doc3's expiration timestamp to others, so we will
+  //   never get this incorrect scenario in production. If we really need batch
+  //   update for doc0 and doc3, then we should consider SCC + topological sort
+  //   (linear) algorithm, as mentioned in the docstring of
+  //   SingleDocumentPropagation.
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/0),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(4))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/1),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(4))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/2),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(4))));
+  EXPECT_THAT(
+      doc_store_->GetNonDeletedDocumentFilterData(/*document_id=*/3),
+      Optional(Property(&DocumentFilterData::expiration_timestamp_ms, Eq(2))));
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/join/join-children-fetcher-impl-v3.cc b/icing/join/join-children-fetcher-impl-v3.cc
index 456c3ba..52a6373 100644
--- a/icing/join/join-children-fetcher-impl-v3.cc
+++ b/icing/join/join-children-fetcher-impl-v3.cc
@@ -114,8 +114,9 @@ JoinChildrenFetcherImplV3::GetChildren(DocumentId parent_doc_id) const {
   // Otherwise, fetch the children from the qualified id join index and cache
   // the result.
   ICING_ASSIGN_OR_RETURN(
-      std::vector<DocumentJoinIdPair> child_document_join_id_pairs,
-      qualified_id_join_index_.Get(parent_doc_id));
+      QualifiedIdJoinIndex::DocumentJoinIdPairArrayView
+          child_join_id_pairs_array_view,
+      qualified_id_join_index_.GetDocumentJoinIdPairArrayView(parent_doc_id));
 
   // Filter and construct child_scored_document_hits for the given parent doc
   // id.
@@ -140,10 +141,10 @@ JoinChildrenFetcherImplV3::GetChildren(DocumentId parent_doc_id) const {
   //     set, or the joinable property does not match the one specified in the
   //     join spec.
   std::vector<ScoredDocumentHit> child_scored_document_hits;
-  for (const DocumentJoinIdPair& child_document_join_id_pair :
-       child_document_join_id_pairs) {
+  for (const DocumentJoinIdPair& child_join_id_pair :
+       child_join_id_pairs_array_view) {
     if (auto filter_itr = child_join_id_pair_to_scored_document_hit_map_.find(
-            child_document_join_id_pair);
+            child_join_id_pair);
         filter_itr != child_join_id_pair_to_scored_document_hit_map_.end()) {
       child_scored_document_hits.push_back(filter_itr->second);
     }
diff --git a/icing/join/join-children-fetcher-impl-v3_test.cc b/icing/join/join-children-fetcher-impl-v3_test.cc
index 9a39157..3188d97 100644
--- a/icing/join/join-children-fetcher-impl-v3_test.cc
+++ b/icing/join/join-children-fetcher-impl-v3_test.cc
@@ -32,6 +32,7 @@
 #include "icing/join/qualified-id-join-index-impl-v2.h"
 #include "icing/join/qualified-id-join-index-impl-v3.h"
 #include "icing/join/qualified-id-join-indexing-handler.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/document_wrapper.pb.h"
@@ -69,6 +70,8 @@ class JoinChildrenFetcherImplV3Test : public ::testing::Test {
  protected:
   void SetUp() override {
     feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    fake_clock_.SetSystemTimeMilliseconds(123);
+
     base_dir_ = GetTestTempDir() + "/icing_test";
     ASSERT_THAT(filesystem_.CreateDirectoryRecursively(base_dir_.c_str()),
                 IsTrue());
@@ -131,14 +134,18 @@ class JoinChildrenFetcherImplV3Test : public ::testing::Test {
                 IsTrue());
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(create_result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(
@@ -158,12 +165,15 @@ class JoinChildrenFetcherImplV3Test : public ::testing::Test {
 
   libtextclassifier3::StatusOr<DocumentId> PutAndIndexDocument(
       const DocumentProto& document) {
-    ICING_ASSIGN_OR_RETURN(DocumentStore::PutResult put_result,
-                           doc_store_->Put(document));
     ICING_ASSIGN_OR_RETURN(
         TokenizedDocument tokenized_document,
-        TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                  document));
+        TokenizedDocument::Create(
+            schema_store_.get(), lang_segmenter_.get(),
+            /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+            std::move(document)));
+    ICING_ASSIGN_OR_RETURN(
+        DocumentStore::PutResult put_result,
+        doc_store_->Put(tokenized_document.document_wrapper()));
 
     ICING_ASSIGN_OR_RETURN(
         std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -489,12 +499,14 @@ TEST_F(JoinChildrenFetcherImplV3Test,
   ICING_ASSERT_OK_AND_ASSIGN(DocumentId message3_id,
                              PutAndIndexDocument(message3));
   // Sanity check for the join index.
-  ASSERT_THAT(qualified_id_join_index_->Get(person1_id),
-              IsOkAndHolds(ElementsAre(DocumentJoinIdPair(message1_id, 0),
-                                       DocumentJoinIdPair(message2_id, 1),
-                                       DocumentJoinIdPair(message3_id, 0))));
-  ASSERT_THAT(qualified_id_join_index_->Get(person2_id),
-              IsOkAndHolds(ElementsAre(DocumentJoinIdPair(message2_id, 0))));
+  ASSERT_THAT(
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(person1_id),
+      IsOkAndHolds(ElementsAre(DocumentJoinIdPair(message1_id, 0),
+                               DocumentJoinIdPair(message2_id, 1),
+                               DocumentJoinIdPair(message3_id, 0))));
+  ASSERT_THAT(
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(person2_id),
+      IsOkAndHolds(ElementsAre(DocumentJoinIdPair(message2_id, 0))));
 
   ScoredDocumentHit scored_doc_hit_message1(message1_id, kSectionIdMaskNone,
                                             /*score=*/1.0);
@@ -596,13 +608,16 @@ TEST_F(JoinChildrenFetcherImplV3Test,
   ICING_ASSERT_OK_AND_ASSIGN(DocumentId email3_id, PutAndIndexDocument(email3));
   ICING_ASSERT_OK_AND_ASSIGN(DocumentId email4_id, PutAndIndexDocument(email4));
   // Sanity check for the join index.
-  ASSERT_THAT(qualified_id_join_index_->Get(person1_id),
-              IsOkAndHolds(ElementsAre(DocumentJoinIdPair(email1_id, 0),
-                                       DocumentJoinIdPair(email2_id, 0))));
-  ASSERT_THAT(qualified_id_join_index_->Get(person2_id),
-              IsOkAndHolds(ElementsAre(DocumentJoinIdPair(email3_id, 0))));
-  ASSERT_THAT(qualified_id_join_index_->Get(person3_id),
-              IsOkAndHolds(ElementsAre(DocumentJoinIdPair(email4_id, 0))));
+  ASSERT_THAT(
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(person1_id),
+      IsOkAndHolds(ElementsAre(DocumentJoinIdPair(email1_id, 0),
+                               DocumentJoinIdPair(email2_id, 0))));
+  ASSERT_THAT(
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(person2_id),
+      IsOkAndHolds(ElementsAre(DocumentJoinIdPair(email3_id, 0))));
+  ASSERT_THAT(
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(person3_id),
+      IsOkAndHolds(ElementsAre(DocumentJoinIdPair(email4_id, 0))));
 
   ScoredDocumentHit scored_doc_hit_email1(email1_id, kSectionIdMaskNone,
                                           /*score=*/1.0);
diff --git a/icing/join/join-processor.cc b/icing/join/join-processor.cc
index 9b6aa2a..8bb6a32 100644
--- a/icing/join/join-processor.cc
+++ b/icing/join/join-processor.cc
@@ -228,9 +228,13 @@ JoinProcessor::GetPropagatedChildDocumentsToDelete(
     DocumentId doc_id_to_expand = que.front();
     que.pop();
 
-    ICING_ASSIGN_OR_RETURN(std::vector<DocumentJoinIdPair> child_join_id_pairs,
-                           qualified_id_join_index_->Get(doc_id_to_expand));
-    for (const DocumentJoinIdPair& child_join_id_pair : child_join_id_pairs) {
+    ICING_ASSIGN_OR_RETURN(
+        QualifiedIdJoinIndex::DocumentJoinIdPairArrayView
+            child_join_id_pairs_array_view,
+        qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+            doc_id_to_expand));
+    for (const DocumentJoinIdPair& child_join_id_pair :
+         child_join_id_pairs_array_view) {
       if (child_documents_to_delete.find(child_join_id_pair.document_id()) !=
               child_documents_to_delete.end() ||
           deleted_document_ids.find(child_join_id_pair.document_id()) !=
diff --git a/icing/join/join-processor_test.cc b/icing/join/join-processor_test.cc
index dd88bd1..460a1b3 100644
--- a/icing/join/join-processor_test.cc
+++ b/icing/join/join-processor_test.cc
@@ -37,6 +37,7 @@
 #include "icing/join/qualified-id-join-index-impl-v3.h"
 #include "icing/join/qualified-id-join-index.h"
 #include "icing/join/qualified-id-join-indexing-handler.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/document_wrapper.pb.h"
@@ -83,6 +84,8 @@ class JoinProcessorTest : public ::testing::Test {
 
   void SetUp() override {
     feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    fake_clock_.SetSystemTimeMilliseconds(123);
+
     test_dir_ = GetTestTempDir() + "/icing_join_processor_test";
     ASSERT_THAT(filesystem_.CreateDirectoryRecursively(test_dir_.c_str()),
                 IsTrue());
@@ -186,14 +189,18 @@ class JoinProcessorTest : public ::testing::Test {
                 IsTrue());
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(create_result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(qualified_id_join_index_,
@@ -231,12 +238,15 @@ class JoinProcessorTest : public ::testing::Test {
 
   libtextclassifier3::StatusOr<DocumentId> PutAndIndexDocument(
       const DocumentProto& document) {
-    ICING_ASSIGN_OR_RETURN(DocumentStore::PutResult put_result,
-                           doc_store_->Put(document));
     ICING_ASSIGN_OR_RETURN(
         TokenizedDocument tokenized_document,
-        TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                  document));
+        TokenizedDocument::Create(
+            schema_store_.get(), lang_segmenter_.get(),
+            /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+            std::move(document)));
+    ICING_ASSIGN_OR_RETURN(
+        DocumentStore::PutResult put_result,
+        doc_store_->Put(tokenized_document.document_wrapper()));
 
     ICING_ASSIGN_OR_RETURN(
         std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -999,7 +1009,8 @@ TYPED_TEST(JoinProcessorTest, GetPropagatedChildDocumentsToDelete) {
                            "support delete propagation")));
   } else {
     // Sanity check.
-    ASSERT_THAT(this->qualified_id_join_index_->Get(person_doc_id),
+    ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                    person_doc_id),
                 IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                     message_doc_id, /*joinable_property_id=*/2))));
 
@@ -1041,7 +1052,8 @@ TYPED_TEST(
                              this->PutAndIndexDocument(message));
 
   // Sanity check.
-  ASSERT_THAT(this->qualified_id_join_index_->Get(person_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  person_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   message_doc_id, /*joinable_property_id=*/0))));
 
@@ -1084,7 +1096,8 @@ TYPED_TEST(
   ICING_ASSERT_OK(this->PutAndIndexDocument(message));
 
   // Sanity check.
-  ASSERT_THAT(this->qualified_id_join_index_->Get(person_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  person_doc_id),
               IsOkAndHolds(IsEmpty()));
 
   JoinProcessor join_processor(
@@ -1131,7 +1144,8 @@ TYPED_TEST(JoinProcessorTest,
 
   // Sanity check.
   ASSERT_THAT(
-      this->qualified_id_join_index_->Get(person_doc_id),
+      this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+          person_doc_id),
       IsOkAndHolds(ElementsAre(
           DocumentJoinIdPair(message_doc_id, /*joinable_property_id=*/0),
           DocumentJoinIdPair(message_doc_id, /*joinable_property_id=*/2))));
@@ -1188,7 +1202,8 @@ TYPED_TEST(JoinProcessorTest,
 
   // Sanity check.
   ASSERT_THAT(
-      this->qualified_id_join_index_->Get(person_doc_id),
+      this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+          person_doc_id),
       IsOkAndHolds(ElementsAre(
           DocumentJoinIdPair(message1_doc_id, /*joinable_property_id=*/2),
           DocumentJoinIdPair(message2_doc_id, /*joinable_property_id=*/2))));
@@ -1244,10 +1259,12 @@ TYPED_TEST(
                              this->PutAndIndexDocument(message));
 
   // Sanity check.
-  ASSERT_THAT(this->qualified_id_join_index_->Get(person1_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  person1_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   message_doc_id, /*joinable_property_id=*/2))));
-  ASSERT_THAT(this->qualified_id_join_index_->Get(person2_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  person2_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   message_doc_id, /*joinable_property_id=*/1))));
 
@@ -1413,21 +1430,25 @@ TYPED_TEST(JoinProcessorTest,
   // Sanity check for migration: put label1 2nd time.
   ASSERT_THAT(label1_doc_id_new, Ne(label1_doc_id_old));
   // Old label1's doc id should get children = [].
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label1_doc_id_old),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label1_doc_id_old),
               IsOkAndHolds(IsEmpty()));
   // New label1's doc id should get children = [label2_doc_id].
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label1_doc_id_new),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label1_doc_id_new),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   label2_doc_id, /*joinable_property_id=*/0))));
   // label2 should get children = [label3_doc_id].
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label2_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label2_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   label3_doc_id, /*joinable_property_id=*/0))));
   // label3 should get children = [label1_doc_id_new]. label1_doc_id_old will
   // not be returned because when putting label1 for the 1st time, label3 was
   // not present yet, and label1_doc_id_old will not be added to label3's
   // children list.
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label3_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label3_doc_id),
               IsOkAndHolds(
                   ElementsAre(DocumentJoinIdPair(label1_doc_id_new,
                                                  /*joinable_property_id=*/0))));
@@ -1479,7 +1500,8 @@ TYPED_TEST(JoinProcessorTest,
                              this->PutAndIndexDocument(label));
 
   // Sanity check.
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   label_doc_id, /*joinable_property_id=*/0))));
 
@@ -1559,13 +1581,16 @@ TYPED_TEST(
   ASSERT_THAT(this->doc_store_->GetAliveDocumentFilterData(label3_doc_id,
                                                            current_time_ms),
               Ne(std::nullopt));
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label1_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label1_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   label2_doc_id, /*joinable_property_id=*/0))));
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label2_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label2_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   label3_doc_id, /*joinable_property_id=*/0))));
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label3_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label3_doc_id),
               IsOkAndHolds(IsEmpty()));
 
   JoinProcessor join_processor(
@@ -1618,10 +1643,12 @@ TYPED_TEST(
   ASSERT_THAT(this->doc_store_->GetAliveDocumentFilterData(
                   label2_doc_id, this->fake_clock_.GetSystemTimeMilliseconds()),
               Eq(std::nullopt));
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label1_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label1_doc_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   label2_doc_id, /*joinable_property_id=*/0))));
-  ASSERT_THAT(this->qualified_id_join_index_->Get(label2_doc_id),
+  ASSERT_THAT(this->qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  label2_doc_id),
               IsOkAndHolds(IsEmpty()));
 
   JoinProcessor join_processor(
diff --git a/icing/join/qualified-id-join-index-impl-v2.cc b/icing/join/qualified-id-join-index-impl-v2.cc
index fb5bd33..5086aad 100644
--- a/icing/join/qualified-id-join-index-impl-v2.cc
+++ b/icing/join/qualified-id-join-index-impl-v2.cc
@@ -336,9 +336,9 @@ libtextclassifier3::Status QualifiedIdJoinIndexImplV2::Optimize(
   }
 
   // Reinitialize qualified id join index.
-  if (!filesystem_.PRead(GetMetadataFilePath(working_path_).c_str(),
-                         metadata_buffer_.get(), kMetadataFileSize,
-                         /*offset=*/0)) {
+  if (filesystem_.PRead(GetMetadataFilePath(working_path_).c_str(),
+                        metadata_buffer_.get(), kMetadataFileSize,
+                        /*offset=*/0) != kMetadataFileSize) {
     return absl_ports::InternalError("Fail to read metadata file");
   }
   ICING_ASSIGN_OR_RETURN(
@@ -461,9 +461,9 @@ QualifiedIdJoinIndexImplV2::InitializeExistingFiles(
     bool pre_mapping_fbv) {
   // PRead metadata file.
   auto metadata_buffer = std::make_unique<uint8_t[]>(kMetadataFileSize);
-  if (!filesystem.PRead(GetMetadataFilePath(working_path).c_str(),
-                        metadata_buffer.get(), kMetadataFileSize,
-                        /*offset=*/0)) {
+  if (filesystem.PRead(GetMetadataFilePath(working_path).c_str(),
+                       metadata_buffer.get(), kMetadataFileSize,
+                       /*offset=*/0) != kMetadataFileSize) {
     return absl_ports::InternalError("Fail to read metadata file");
   }
 
diff --git a/icing/join/qualified-id-join-index-impl-v2.h b/icing/join/qualified-id-join-index-impl-v2.h
index 379f0b8..007f8fe 100644
--- a/icing/join/qualified-id-join-index-impl-v2.h
+++ b/icing/join/qualified-id-join-index-impl-v2.h
@@ -158,8 +158,8 @@ class QualifiedIdJoinIndexImplV2 : public QualifiedIdJoinIndex {
   }
 
   // v3 only API. Returns UNIMPLEMENTED_ERROR.
-  libtextclassifier3::StatusOr<std::vector<DocumentJoinIdPair>> Get(
-      DocumentId parent_document_id) const override {
+  libtextclassifier3::StatusOr<DocumentJoinIdPairArrayView>
+  GetDocumentJoinIdPairArrayView(DocumentId parent_document_id) const override {
     return absl_ports::UnimplementedError("This API is not supported in V2");
   }
 
diff --git a/icing/join/qualified-id-join-index-impl-v2_test.cc b/icing/join/qualified-id-join-index-impl-v2_test.cc
index 01c972e..64c38a0 100644
--- a/icing/join/qualified-id-join-index-impl-v2_test.cc
+++ b/icing/join/qualified-id-join-index-impl-v2_test.cc
@@ -131,7 +131,7 @@ TEST_F(QualifiedIdJoinIndexImplV2Test, InitializeNewFiles) {
       filesystem_.PRead(metadata_file_path.c_str(), metadata_buffer.get(),
                         QualifiedIdJoinIndexImplV2::kMetadataFileSize,
                         /*offset=*/0),
-      IsTrue());
+      Eq(QualifiedIdJoinIndexImplV2::kMetadataFileSize));
 
   // Check info section
   const Info* info = reinterpret_cast<const Info*>(
@@ -372,7 +372,7 @@ TEST_F(QualifiedIdJoinIndexImplV2Test,
     ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
                                   QualifiedIdJoinIndexImplV2::kMetadataFileSize,
                                   /*offset=*/0),
-                IsTrue());
+                Eq(QualifiedIdJoinIndexImplV2::kMetadataFileSize));
 
     // Manually change magic and update checksum
     Crcs* crcs = reinterpret_cast<Crcs*>(
@@ -425,7 +425,7 @@ TEST_F(QualifiedIdJoinIndexImplV2Test,
     ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
                                   QualifiedIdJoinIndexImplV2::kMetadataFileSize,
                                   /*offset=*/0),
-                IsTrue());
+                Eq(QualifiedIdJoinIndexImplV2::kMetadataFileSize));
 
     // Manually corrupt all_crc
     Crcs* crcs = reinterpret_cast<Crcs*>(
@@ -474,7 +474,7 @@ TEST_F(QualifiedIdJoinIndexImplV2Test,
     ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
                                   QualifiedIdJoinIndexImplV2::kMetadataFileSize,
                                   /*offset=*/0),
-                IsTrue());
+                Eq(QualifiedIdJoinIndexImplV2::kMetadataFileSize));
 
     // Modify info, but don't update the checksum. This would be similar to
     // corruption of info.
diff --git a/icing/join/qualified-id-join-index-impl-v3.cc b/icing/join/qualified-id-join-index-impl-v3.cc
index bff564e..09a7468 100644
--- a/icing/join/qualified-id-join-index-impl-v3.cc
+++ b/icing/join/qualified-id-join-index-impl-v3.cc
@@ -145,15 +145,16 @@ libtextclassifier3::Status QualifiedIdJoinIndexImplV3::Put(
   return libtextclassifier3::Status::OK;
 }
 
-libtextclassifier3::StatusOr<std::vector<DocumentJoinIdPair>>
-QualifiedIdJoinIndexImplV3::Get(DocumentId parent_document_id) const {
+libtextclassifier3::StatusOr<QualifiedIdJoinIndex::DocumentJoinIdPairArrayView>
+QualifiedIdJoinIndexImplV3::GetDocumentJoinIdPairArrayView(
+    DocumentId parent_document_id) const {
   if (parent_document_id < 0 || parent_document_id == kInvalidDocumentId) {
     return absl_ports::InvalidArgumentError("Invalid parent document id");
   }
 
   if (parent_document_id >=
       parent_document_id_to_child_array_info_->num_elements()) {
-    return std::vector<DocumentJoinIdPair>();
+    return DocumentJoinIdPairArrayView(/*data=*/nullptr, /*len=*/0);
   }
 
   // Get the child array info for the parent.
@@ -161,7 +162,7 @@ QualifiedIdJoinIndexImplV3::Get(DocumentId parent_document_id) const {
       const ArrayInfo* array_info,
       parent_document_id_to_child_array_info_->Get(parent_document_id));
   if (!array_info->IsValid()) {
-    return std::vector<DocumentJoinIdPair>();
+    return DocumentJoinIdPairArrayView(/*data=*/nullptr, /*len=*/0);
   }
 
   // Safe check to avoid out-of-bound access. This should never happen unless
@@ -174,11 +175,11 @@ QualifiedIdJoinIndexImplV3::Get(DocumentId parent_document_id) const {
         std::to_string(child_document_join_id_pair_array_->num_elements())));
   }
 
-  // Get the DocumentJoinIdPair array and return the child DocumentJoinIdPairs.
+  // Get the DocumentJoinIdPair array ptr and return the array view.
   ICING_ASSIGN_OR_RETURN(
       const DocumentJoinIdPair* ptr,
       child_document_join_id_pair_array_->Get(array_info->index));
-  return std::vector<DocumentJoinIdPair>(ptr, ptr + array_info->used_length);
+  return DocumentJoinIdPairArrayView(ptr, array_info->used_length);
 }
 
 libtextclassifier3::Status QualifiedIdJoinIndexImplV3::MigrateParent(
@@ -460,7 +461,13 @@ QualifiedIdJoinIndexImplV3::InitializeExistingFiles(
 
   // Validate magic.
   if (join_index->info().magic != Info::kMagic) {
-    return absl_ports::FailedPreconditionError("Incorrect magic value");
+    ICING_LOG(ERROR) << "Invalid header magic for QualifiedIdJoinIndexImplV3 "
+                     << join_index->working_path_
+                     << ". Expected: " << Info::kMagic
+                     << ", actual: " << join_index->info().magic;
+    return absl_ports::FailedPreconditionError(absl_ports::StrCat(
+        "Invalid header magic for QualifiedIdJoinIndexImplV3: ",
+        join_index->working_path_));
   }
 
   return join_index;
diff --git a/icing/join/qualified-id-join-index-impl-v3.h b/icing/join/qualified-id-join-index-impl-v3.h
index 30483df..e387505 100644
--- a/icing/join/qualified-id-join-index-impl-v3.h
+++ b/icing/join/qualified-id-join-index-impl-v3.h
@@ -154,13 +154,16 @@ class QualifiedIdJoinIndexImplV3 : public QualifiedIdJoinIndex {
       const DocumentJoinIdPair& child_document_join_id_pair,
       std::vector<DocumentId>&& parent_document_ids) override;
 
-  // Gets the list of joinable children for the given parent document id.
+  // Gets an array view of all joinable children for the given parent document
+  // id.
   //
   // Returns:
-  //   - A list of children's DocumentJoinIdPair on success
+  //   - A DocumentJoinIdPairArrayView object on success. If there is no edge
+  //     for a valid node_id, then an array view with data() == nullptr and
+  //     size() == 0 will be returned
   //   - Any FileBackedVector errors
-  libtextclassifier3::StatusOr<std::vector<DocumentJoinIdPair>> Get(
-      DocumentId parent_document_id) const override;
+  libtextclassifier3::StatusOr<DocumentJoinIdPairArrayView>
+  GetDocumentJoinIdPairArrayView(DocumentId parent_document_id) const override;
 
   // Migrates existing join data for a parent document from old_document_id to
   // new_document_id.
diff --git a/icing/join/qualified-id-join-index-impl-v3_test.cc b/icing/join/qualified-id-join-index-impl-v3_test.cc
index 114cab7..f270838 100644
--- a/icing/join/qualified-id-join-index-impl-v3_test.cc
+++ b/icing/join/qualified-id-join-index-impl-v3_test.cc
@@ -31,6 +31,7 @@
 #include "icing/file/memory-mapped-file.h"
 #include "icing/file/persistent-storage.h"
 #include "icing/join/document-join-id-pair.h"
+#include "icing/join/qualified-id-join-index.h"
 #include "icing/store/document-id.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/test-feature-flags.h"
@@ -43,15 +44,18 @@ namespace lib {
 namespace {
 
 using ::testing::ElementsAre;
+using ::testing::ElementsAreArray;
 using ::testing::Eq;
 using ::testing::Gt;
 using ::testing::HasSubstr;
 using ::testing::IsEmpty;
 using ::testing::IsFalse;
+using ::testing::IsNull;
 using ::testing::IsTrue;
 using ::testing::Lt;
 using ::testing::Ne;
 using ::testing::Not;
+using ::testing::NotNull;
 using ::testing::Pointee;
 using ::testing::SizeIs;
 
@@ -111,7 +115,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, InitializeNewFiles) {
       filesystem_.PRead(metadata_file_path.c_str(), metadata_buffer.get(),
                         QualifiedIdJoinIndexImplV3::kMetadataFileSize,
                         /*offset=*/0),
-      IsTrue());
+      Eq(QualifiedIdJoinIndexImplV3::kMetadataFileSize));
 
   // Check info section
   const Info* info = reinterpret_cast<const Info*>(
@@ -324,9 +328,9 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
                              QualifiedIdJoinIndexImplV3::Create(
                                  filesystem_, working_path_, *feature_flags_));
   EXPECT_THAT(index2, Pointee(SizeIs(2)));
-  EXPECT_THAT(index2->Get(/*parent_document_id=*/0),
+  EXPECT_THAT(index2->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
               IsOkAndHolds(ElementsAre(child_join_id_pair1)));
-  EXPECT_THAT(index2->Get(/*parent_document_id=*/1),
+  EXPECT_THAT(index2->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
 }
 
@@ -360,9 +364,9 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
                              QualifiedIdJoinIndexImplV3::Create(
                                  filesystem_, working_path_, *feature_flags_));
   EXPECT_THAT(index2, Pointee(SizeIs(2)));
-  EXPECT_THAT(index2->Get(/*parent_document_id=*/0),
+  EXPECT_THAT(index2->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
               IsOkAndHolds(ElementsAre(child_join_id_pair1)));
-  EXPECT_THAT(index2->Get(/*parent_document_id=*/1),
+  EXPECT_THAT(index2->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
 }
 
@@ -400,9 +404,9 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
         QualifiedIdJoinIndexImplV3::Create(filesystem_, working_path_,
                                            *feature_flags_));
     EXPECT_THAT(index, Pointee(SizeIs(2)));
-    EXPECT_THAT(index->Get(/*parent_document_id=*/0),
+    EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
                 IsOkAndHolds(ElementsAre(child_join_id_pair1)));
-    EXPECT_THAT(index->Get(/*parent_document_id=*/1),
+    EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
                 IsOkAndHolds(ElementsAre(child_join_id_pair2)));
   }
 }
@@ -433,7 +437,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
     ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
                                   QualifiedIdJoinIndexImplV3::kMetadataFileSize,
                                   /*offset=*/0),
-                IsTrue());
+                Eq(QualifiedIdJoinIndexImplV3::kMetadataFileSize));
 
     // Manually change magic and update checksum
     Crcs* crcs = reinterpret_cast<Crcs*>(
@@ -453,10 +457,12 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
 
   // Attempt to create the qualified id join index with different magic. This
   // should fail.
-  EXPECT_THAT(QualifiedIdJoinIndexImplV3::Create(filesystem_, working_path_,
-                                                 *feature_flags_),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION,
-                       HasSubstr("Incorrect magic value")));
+  EXPECT_THAT(
+      QualifiedIdJoinIndexImplV3::Create(filesystem_, working_path_,
+                                         *feature_flags_),
+      StatusIs(
+          libtextclassifier3::StatusCode::FAILED_PRECONDITION,
+          HasSubstr("Invalid header magic for QualifiedIdJoinIndexImplV3")));
 }
 
 TEST_F(QualifiedIdJoinIndexImplV3Test,
@@ -485,7 +491,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
     ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
                                   QualifiedIdJoinIndexImplV3::kMetadataFileSize,
                                   /*offset=*/0),
-                IsTrue());
+                Eq(QualifiedIdJoinIndexImplV3::kMetadataFileSize));
 
     // Manually corrupt all_crc
     Crcs* crcs = reinterpret_cast<Crcs*>(
@@ -533,7 +539,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
     ASSERT_THAT(filesystem_.PRead(metadata_sfd.get(), metadata_buffer.get(),
                                   QualifiedIdJoinIndexImplV3::kMetadataFileSize,
                                   /*offset=*/0),
-                IsTrue());
+                Eq(QualifiedIdJoinIndexImplV3::kMetadataFileSize));
 
     // Modify info, but don't update the checksum. This would be similar to
     // corruption of info.
@@ -682,16 +688,18 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Put) {
   EXPECT_THAT(index, Pointee(SizeIs(6)));
 
   // Verify Get API.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
               IsOkAndHolds(ElementsAre(child_join_id_pair4)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/1),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
               IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2,
                                        child_join_id_pair5)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
               IsOkAndHolds(ElementsAre(child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/4), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/5),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/4),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/5),
               IsOkAndHolds(ElementsAre(child_join_id_pair6)));
 }
 
@@ -726,29 +734,31 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
   EXPECT_THAT(index, Pointee(SizeIs(13)));
 
   // Verify Get API.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/1),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/2),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
       IsOkAndHolds(ElementsAre(child_join_id_pair2, child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/4),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/4),
               IsOkAndHolds(ElementsAre(child_join_id_pair1)));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/5),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/5),
       IsOkAndHolds(ElementsAre(child_join_id_pair2, child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/6), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/6),
+              IsOkAndHolds(IsEmpty()));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/7),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/7),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/8),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/8),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/9), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/10),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/9),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/10),
               IsOkAndHolds(ElementsAre(child_join_id_pair1)));
 }
 
@@ -784,29 +794,31 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
   EXPECT_THAT(index, Pointee(SizeIs(13)));
 
   // Verify Get API.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/1),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/2),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
       IsOkAndHolds(ElementsAre(child_join_id_pair2, child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/4),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/4),
               IsOkAndHolds(ElementsAre(child_join_id_pair1)));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/5),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/5),
       IsOkAndHolds(ElementsAre(child_join_id_pair2, child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/6), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/6),
+              IsOkAndHolds(IsEmpty()));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/7),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/7),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair3)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/8),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/8),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/9), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/10),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/9),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/10),
               IsOkAndHolds(ElementsAre(child_join_id_pair1)));
 }
 
@@ -834,10 +846,11 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
   // Get API should return empty result for document 0 to 9.
   for (DocumentId parent_doc_id = 0; parent_doc_id < kParentDocumentId;
        ++parent_doc_id) {
-    EXPECT_THAT(index->Get(parent_doc_id), IsOkAndHolds(IsEmpty()));
+    EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(parent_doc_id),
+                IsOkAndHolds(IsEmpty()));
   }
   // Get API should return the child document for document 10.
-  EXPECT_THAT(index->Get(kParentDocumentId),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(kParentDocumentId),
               IsOkAndHolds(ElementsAre(child_join_id_pair)));
 }
 
@@ -885,8 +898,9 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
   }
   EXPECT_THAT(index, Pointee(SizeIs(102)));
 
-  EXPECT_THAT(index->Get(parent1), IsOkAndHolds(child_join_id_pairs));
-  EXPECT_THAT(index->Get(parent2),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(parent1),
+              IsOkAndHolds(ElementsAreArray(child_join_id_pairs)));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(parent2),
               IsOkAndHolds(ElementsAre(child_join_id_pair2)));
 }
 
@@ -995,11 +1009,11 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, PutShouldSkipInvalidParentDocumentId) {
   EXPECT_THAT(index, Pointee(SizeIs(3)));
 
   // Verify Get API.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/1),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
               IsOkAndHolds(ElementsAre(child_join_id_pair)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
               IsOkAndHolds(ElementsAre(child_join_id_pair)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
               IsOkAndHolds(ElementsAre(child_join_id_pair)));
 }
 
@@ -1020,24 +1034,105 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
   EXPECT_THAT(index, Pointee(IsEmpty()));
 }
 
-TEST_F(QualifiedIdJoinIndexImplV3Test, GetEmptyIndex) {
+TEST_F(QualifiedIdJoinIndexImplV3Test, DocumentJoinIdPairArrayView) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+
+  // Add 2 children for parent document 0.
+  DocumentJoinIdPair child_join_id_pair1(/*document_id=*/100,
+                                         /*joinable_property_id=*/20);
+  DocumentJoinIdPair child_join_id_pair2(/*document_id=*/101,
+                                         /*joinable_property_id=*/2);
+  EXPECT_THAT(index->Put(child_join_id_pair1,
+                         /*parent_document_ids=*/std::vector<DocumentId>{0}),
+              IsOk());
+  EXPECT_THAT(index->Put(child_join_id_pair2,
+                         /*parent_document_ids=*/std::vector<DocumentId>{0}),
+              IsOk());
+
+  EXPECT_THAT(index, Pointee(SizeIs(2)));
+
+  // Get array view. Test each STL style method.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      QualifiedIdJoinIndex::DocumentJoinIdPairArrayView array_view1,
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0));
+  EXPECT_THAT(array_view1, Not(IsEmpty()));
+  EXPECT_THAT(array_view1.data(), NotNull());
+  EXPECT_THAT(array_view1, SizeIs(2));
+  EXPECT_THAT(array_view1.begin(), NotNull());
+  EXPECT_THAT(array_view1.end(), NotNull());
+  EXPECT_THAT(array_view1,
+              ElementsAre(child_join_id_pair1, child_join_id_pair2));
+
+  // Add 1 more child for parent document 0.
+  DocumentJoinIdPair child_join_id_pair3(/*document_id=*/102,
+                                         /*joinable_property_id=*/2);
+  EXPECT_THAT(index->Put(child_join_id_pair3,
+                         /*parent_document_ids=*/std::vector<DocumentId>{0}),
+              IsOk());
+
+  // Get array view again. Test each STL style method.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      QualifiedIdJoinIndex::DocumentJoinIdPairArrayView array_view2,
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0));
+  EXPECT_THAT(array_view2, Not(IsEmpty()));
+  EXPECT_THAT(array_view2.data(), NotNull());
+  EXPECT_THAT(array_view2, SizeIs(3));
+  EXPECT_THAT(array_view2.begin(), NotNull());
+  EXPECT_THAT(array_view2.end(), NotNull());
+  EXPECT_THAT(array_view2, ElementsAre(child_join_id_pair1, child_join_id_pair2,
+                                       child_join_id_pair3));
+}
+
+TEST_F(QualifiedIdJoinIndexImplV3Test, EmptyDocumentJoinIdPairArrayView) {
   // Create new qualified id join index
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
                              QualifiedIdJoinIndexImplV3::Create(
                                  filesystem_, working_path_, *feature_flags_));
   EXPECT_THAT(index, Pointee(IsEmpty()));
 
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/1), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/4), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/5), IsOkAndHolds(IsEmpty()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      QualifiedIdJoinIndex::DocumentJoinIdPairArrayView array_view,
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0));
+  EXPECT_THAT(array_view, IsEmpty());
+  EXPECT_THAT(array_view.data(), IsNull());
+  EXPECT_THAT(array_view.size(), Eq(0));
+  EXPECT_THAT(array_view.begin(), IsNull());
+  EXPECT_THAT(array_view.end(), IsNull());
+
+  // Use colon to iterate the array_view. There should be no crash and no-op.
+  for (const DocumentJoinIdPair& _ : array_view) {
+    ADD_FAILURE() << "Unexpectedly iterated the empty array_view.";
+  }
+}
+
+TEST_F(QualifiedIdJoinIndexImplV3Test,
+       GetDocumentJoinIdPairArrayView_emptyIndex) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+  EXPECT_THAT(index, Pointee(IsEmpty()));
+
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/4),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/5),
+              IsOkAndHolds(IsEmpty()));
 }
 
 TEST_F(
     QualifiedIdJoinIndexImplV3Test,
-    GetShouldReturnEmptyResultWithoutAccessingArrayForNonExistingLargeParent) {
+    GetDocumentJoinIdPairArrayView_shouldReturnEmptyArrayViewForNonExistingLargeParent) {
   // Create new qualified id join index
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
                              QualifiedIdJoinIndexImplV3::Create(
@@ -1049,29 +1144,61 @@ TEST_F(
       child_join_id_pair, /*parent_document_ids=*/std::vector<DocumentId>{1}));
   EXPECT_THAT(index, Pointee(SizeIs(1)));
 
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/1),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
               IsOkAndHolds(ElementsAre(child_join_id_pair)));
 
   // Now, only parent document id 1 is in the index, so the FileBackedVector has
   // been resized to fit parent document id 1.
   // Get API for parent document id greater than 1 should return empty result
   // without accessing the FileBackedVector.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(kMaxDocumentId), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(kMaxDocumentId),
+              IsOkAndHolds(IsEmpty()));
 }
 
-TEST_F(QualifiedIdJoinIndexImplV3Test,
-       GetShouldReturnInvalidArgumentErrorForInvalidParentDocumentId) {
+TEST_F(
+    QualifiedIdJoinIndexImplV3Test,
+    GetDocumentJoinIdPairArrayView_shouldReturnEmptyArrayViewForParentWithNoChildren) {
+  // Create new qualified id join index
+  ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
+                             QualifiedIdJoinIndexImplV3::Create(
+                                 filesystem_, working_path_, *feature_flags_));
+
+  // Add a child for parent document id 2.
+  DocumentJoinIdPair child_join_id_pair(/*document_id=*/100,
+                                        /*joinable_property_id=*/20);
+  ICING_ASSERT_OK(index->Put(
+      child_join_id_pair, /*parent_document_ids=*/std::vector<DocumentId>{2}));
+  EXPECT_THAT(index, Pointee(SizeIs(1)));
+
+  // Since parent array info FBV is resized to fit parent document id 2, parent
+  // document 0 and 1 should also have array info element with invalid data
+  // index for the 2nd FBV.
+  //
+  // Getting array view for parent document 0 and 1 should return empty result
+  // when seeing invalid data index.
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
+              IsOkAndHolds(IsEmpty()));
+}
+
+TEST_F(
+    QualifiedIdJoinIndexImplV3Test,
+    GetDocumentJoinIdPairArrayView_shouldReturnInvalidArgumentErrorForInvalidParentDocumentId) {
   // Create new qualified id join index
   ICING_ASSERT_OK_AND_ASSIGN(std::unique_ptr<QualifiedIdJoinIndexImplV3> index,
                              QualifiedIdJoinIndexImplV3::Create(
                                  filesystem_, working_path_, *feature_flags_));
 
-  EXPECT_THAT(index->Get(/*parent_document_id=*/-1),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/-1),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-  EXPECT_THAT(index->Get(kInvalidDocumentId),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(kInvalidDocumentId),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
@@ -1099,15 +1226,17 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, MigrateParent) {
   // Sanity check.
   ASSERT_THAT(index, Pointee(SizeIs(2)));
   ASSERT_THAT(
-      index->Get(parent_doc_id1),
+      index->GetDocumentJoinIdPairArrayView(parent_doc_id1),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
-  ASSERT_THAT(index->Get(parent_doc_id2), IsOkAndHolds(IsEmpty()));
+  ASSERT_THAT(index->GetDocumentJoinIdPairArrayView(parent_doc_id2),
+              IsOkAndHolds(IsEmpty()));
 
   // Migrate parent document id 1 to 1024.
   EXPECT_THAT(index->MigrateParent(parent_doc_id1, parent_doc_id2), IsOk());
-  EXPECT_THAT(index->Get(parent_doc_id1), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(parent_doc_id1),
+              IsOkAndHolds(IsEmpty()));
   EXPECT_THAT(
-      index->Get(parent_doc_id2),
+      index->GetDocumentJoinIdPairArrayView(parent_doc_id2),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
 }
 
@@ -1142,18 +1271,20 @@ TEST_F(QualifiedIdJoinIndexImplV3Test,
   // Sanity check.
   ASSERT_THAT(index, Pointee(SizeIs(2)));
   ASSERT_THAT(
-      index->Get(parent_doc_id1),
+      index->GetDocumentJoinIdPairArrayView(parent_doc_id1),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
-  ASSERT_THAT(index->Get(parent_doc_id2), IsOkAndHolds(IsEmpty()));
+  ASSERT_THAT(index->GetDocumentJoinIdPairArrayView(parent_doc_id2),
+              IsOkAndHolds(IsEmpty()));
 
   // Migrate parent document id 1 to 30000. This will
   // cause parent_document_id_to_child_array_info being extended and remap. The
   // test verifies that addresses after remap are handled correctly without
   // crashing.
   EXPECT_THAT(index->MigrateParent(parent_doc_id1, parent_doc_id2), IsOk());
-  EXPECT_THAT(index->Get(parent_doc_id1), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(parent_doc_id1),
+              IsOkAndHolds(IsEmpty()));
   EXPECT_THAT(
-      index->Get(parent_doc_id2),
+      index->GetDocumentJoinIdPairArrayView(parent_doc_id2),
       IsOkAndHolds(ElementsAre(child_join_id_pair1, child_join_id_pair2)));
   int64_t file_size_after = filesystem_.GetFileSize(array_working_path.c_str());
   ASSERT_THAT(file_size_after, Ne(Filesystem::kBadFileSize));
@@ -1274,7 +1405,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Optimize) {
   // - Child docs 101, 104, 105 become 11, 13, 14.
   // - Child docs 103, 107 are deleted.
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/0),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
       IsOkAndHolds(ElementsAre(
           DocumentJoinIdPair(/*document_id=*/11, /*joinable_property_id=*/0),
           DocumentJoinIdPair(/*document_id=*/13, /*joinable_property_id=*/0),
@@ -1284,20 +1415,23 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Optimize) {
   // - Child docs 102, 105 become 12, 14.
   // - Child doc 103 is deleted.
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/1),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
       IsOkAndHolds(ElementsAre(
           DocumentJoinIdPair(/*document_id=*/12, /*joinable_property_id=*/0),
           DocumentJoinIdPair(/*document_id=*/14, /*joinable_property_id=*/0))));
 
   // Verify document 2 (originally document 4)
   // - Child doc 103 is deleted.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+              IsOkAndHolds(IsEmpty()));
 
   // Verify document 3 and 4:
   // - These 2 doc ids don't exist after optimize.
   // - The relations for the original document 3 and 4 should be deleted.
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/4), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/4),
+              IsOkAndHolds(IsEmpty()));
 
   // Verify Put API should work normally after Optimize().
   DocumentJoinIdPair another_child_join_id_pair(/*document_id=*/16,
@@ -1311,7 +1445,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Optimize) {
   EXPECT_THAT(index, Pointee(SizeIs(8)));
   EXPECT_THAT(index->last_added_document_id(), Eq(16));
   EXPECT_THAT(
-      index->Get(/*parent_document_id=*/0),
+      index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
       IsOkAndHolds(ElementsAre(DocumentJoinIdPair(/*document_id=*/11,
                                                   /*joinable_property_id=*/0),
                                DocumentJoinIdPair(/*document_id=*/13,
@@ -1319,9 +1453,9 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Optimize) {
                                DocumentJoinIdPair(/*document_id=*/14,
                                                   /*joinable_property_id=*/0),
                                another_child_join_id_pair)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
               IsOkAndHolds(ElementsAre(another_child_join_id_pair)));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
               IsOkAndHolds(ElementsAre(another_child_join_id_pair)));
 }
 
@@ -1491,10 +1625,14 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, OptimizeDeleteAllDocuments) {
       IsOk());
   EXPECT_THAT(index, Pointee(IsEmpty()));
   EXPECT_THAT(index->last_added_document_id(), Eq(new_last_added_document_id));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/1), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/3), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/3),
+              IsOkAndHolds(IsEmpty()));
 }
 
 TEST_F(QualifiedIdJoinIndexImplV3Test, Clear) {
@@ -1534,9 +1672,12 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Clear) {
   EXPECT_THAT(index->Clear(), IsOk());
   EXPECT_THAT(index, Pointee(IsEmpty()));
   EXPECT_THAT(index->last_added_document_id(), Eq(kInvalidDocumentId));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/0), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/1), IsOkAndHolds(IsEmpty()));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/2), IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/0),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/1),
+              IsOkAndHolds(IsEmpty()));
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/2),
+              IsOkAndHolds(IsEmpty()));
 
   // Join index should be able to work normally after Clear().
   EXPECT_THAT(index->Put(child_join_id_pair4,
@@ -1546,7 +1687,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Clear) {
 
   EXPECT_THAT(index, Pointee(SizeIs(1)));
   EXPECT_THAT(index->last_added_document_id(), Eq(105));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/5),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/5),
               IsOkAndHolds(ElementsAre(child_join_id_pair4)));
 
   ICING_ASSERT_OK(index->PersistToDisk());
@@ -1558,7 +1699,7 @@ TEST_F(QualifiedIdJoinIndexImplV3Test, Clear) {
                                                 *feature_flags_));
   EXPECT_THAT(index, Pointee(SizeIs(1)));
   EXPECT_THAT(index->last_added_document_id(), Eq(105));
-  EXPECT_THAT(index->Get(/*parent_document_id=*/5),
+  EXPECT_THAT(index->GetDocumentJoinIdPairArrayView(/*parent_document_id=*/5),
               IsOkAndHolds(ElementsAre(child_join_id_pair4)));
 }
 
diff --git a/icing/join/qualified-id-join-index.h b/icing/join/qualified-id-join-index.h
index 55427c1..c24c2aa 100644
--- a/icing/join/qualified-id-join-index.h
+++ b/icing/join/qualified-id-join-index.h
@@ -18,7 +18,6 @@
 #include <cstdint>
 #include <memory>
 #include <string>
-#include <string_view>
 #include <utility>
 #include <vector>
 
@@ -52,6 +51,37 @@ class QualifiedIdJoinIndex : public PersistentStorage {
         const = 0;
   };
 
+  // An STL style array view object of DocumentJoinIdPairs for a given parent
+  // document id. This is only used in V3.
+  class DocumentJoinIdPairArrayView {
+   public:
+    using value_type = DocumentJoinIdPair;
+    using iterator = const DocumentJoinIdPair*;
+    using const_iterator = const DocumentJoinIdPair*;
+
+    explicit DocumentJoinIdPairArrayView(const DocumentJoinIdPair* data,
+                                         int size)
+        : data_(data), size_(size) {}
+
+    const DocumentJoinIdPair* data() const { return data_; }
+
+    int size() const { return size_; }
+
+    bool empty() const { return size_ == 0 || data_ == nullptr; }
+
+    iterator begin() { return data_; }
+    iterator end() { return data_ + size_; }
+
+    const_iterator begin() const { return data_; }
+    const_iterator end() const { return data_ + size_; }
+
+    const DocumentJoinIdPair& operator[](int idx) const { return data_[idx]; }
+
+   private:
+    const DocumentJoinIdPair* data_;
+    int size_;
+  };
+
   enum class Version { kV2, kV3 };
 
   static constexpr WorkingPathType kWorkingPathType =
@@ -107,14 +137,16 @@ class QualifiedIdJoinIndex : public PersistentStorage {
   GetIterator(SchemaTypeId schema_type_id,
               JoinablePropertyId joinable_property_id) const = 0;
 
-  // (v3 only) Gets the list of joinable children for the given parent document
-  // id.
+  // (v3 only) Gets an array view of all joinable children for the given parent
+  // document id.
   //
   // Returns:
-  //   - A list of children's DocumentJoinIdPair on success
+  //   - A DocumentJoinIdPairArrayView object on success. If there is no edge
+  //     for a valid node_id, then an array view with data() == nullptr and
+  //     size() == 0 will be returned
   //   - Any FileBackedVector errors
-  virtual libtextclassifier3::StatusOr<std::vector<DocumentJoinIdPair>> Get(
-      DocumentId parent_document_id) const = 0;
+  virtual libtextclassifier3::StatusOr<DocumentJoinIdPairArrayView>
+  GetDocumentJoinIdPairArrayView(DocumentId parent_document_id) const = 0;
 
   // Migrates existing join data for a parent document from old_document_id to
   // new_document_id if necessary.
diff --git a/icing/join/qualified-id-join-indexing-handler-v2_test.cc b/icing/join/qualified-id-join-indexing-handler-v2_test.cc
index b131efc..87d0fb9 100644
--- a/icing/join/qualified-id-join-indexing-handler-v2_test.cc
+++ b/icing/join/qualified-id-join-indexing-handler-v2_test.cc
@@ -32,6 +32,7 @@
 #include "icing/join/qualified-id-join-index.h"
 #include "icing/join/qualified-id-join-indexing-handler.h"
 #include "icing/join/qualified-id.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -153,14 +154,18 @@ class QualifiedIdJoinIndexingHandlerV2Test : public ::testing::Test {
                 IsTrue());
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(create_result.document_store);
 
     // Get FakeType related ids.
@@ -267,14 +272,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test, HandleJoinableProperty) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(referenced_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(ref_tokenized_document.document_wrapper()));
   DocumentId ref_doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id,
-      doc_store_->GetNamespaceId(referenced_document.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint(
-      /*namespace_id=*/ref_doc_ns_id, /*target_str=*/referenced_document.uri());
+      /*namespace_id=*/ref_doc_ns_id,
+      /*target_str=*/ref_tokenized_document.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint),
               IsOkAndHolds(ref_doc_id));
 
@@ -286,12 +302,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test, HandleJoinableProperty) {
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result, doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
   // Handle document.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -326,15 +345,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test, HandleNestedJoinableProperty) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store_->Put(referenced_document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store_->Put(ref_tokenized_document1.document_wrapper()));
   DocumentId ref_doc_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id1,
-      doc_store_->GetNamespaceId(referenced_document1.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document1.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint1(
       /*namespace_id=*/ref_doc_ns_id1,
-      /*target_str=*/referenced_document1.uri());
+      /*target_str=*/ref_tokenized_document1.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint1),
               IsOkAndHolds(ref_doc_id1));
 
@@ -346,15 +375,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test, HandleNestedJoinableProperty) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "two")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store_->Put(referenced_document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store_->Put(ref_tokenized_document2.document_wrapper()));
   DocumentId ref_doc_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id2,
-      doc_store_->GetNamespaceId(referenced_document2.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document2.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint2(
       /*namespace_id=*/ref_doc_ns_id2,
-      /*target_str=*/referenced_document2.uri());
+      /*target_str=*/ref_tokenized_document2.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint2),
               IsOkAndHolds(ref_doc_id2));
 
@@ -378,25 +417,28 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test, HandleNestedJoinableProperty) {
           .AddStringProperty(std::string(kPropertyQualifiedId2),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(nested_document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                nested_document));
+      TokenizedDocument nested_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(nested_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(nested_tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
-  // Handle nested_document.
+  // Handle nested_tokenized_document.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(kInvalidDocumentId));
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
       QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
                                              qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, doc_id, put_result.old_document_id,
-                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
-      IsOk());
+  EXPECT_THAT(handler->Handle(
+                  nested_tokenized_document, doc_id, put_result.old_document_id,
+                  /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
+              IsOk());
 
   // Verify the state of qualified_id_join_index_ after Handle().
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(), Eq(doc_id));
@@ -440,13 +482,16 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              std::string(kInvalidFormatQualifiedId))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
   // Handle document. Should ignore invalid format qualified id.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -484,13 +529,16 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
               std::string(kPropertyQualifiedId),
               absl_ports::StrCat(kUnknownNamespace, "#", "ref_type/1"))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
   // Handle document.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -520,13 +568,17 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test, HandleShouldSkipEmptyQualifiedId) {
                                .SetKey("icing", "fake_type/1")
                                .SetSchema(std::string(kFakeType))
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
+
   ASSERT_THAT(tokenized_document.qualified_id_join_properties(), IsEmpty());
 
   // Handle document.
@@ -562,14 +614,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(referenced_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(ref_tokenized_document.document_wrapper()));
   DocumentId ref_doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id,
-      doc_store_->GetNamespaceId(referenced_document.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint(
-      /*namespace_id=*/ref_doc_ns_id, /*target_str=*/referenced_document.uri());
+      /*namespace_id=*/ref_doc_ns_id,
+      /*target_str=*/ref_tokenized_document.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint),
               IsOkAndHolds(ref_doc_id));
 
@@ -581,11 +644,13 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK(doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK(doc_store_->Put(tokenized_document.document_wrapper()));
 
   qualified_id_join_index_->set_last_added_document_id(ref_doc_id);
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -637,14 +702,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(referenced_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(ref_tokenized_document.document_wrapper()));
   DocumentId ref_doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id,
-      doc_store_->GetNamespaceId(referenced_document.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint(
-      /*namespace_id=*/ref_doc_ns_id, /*target_str=*/referenced_document.uri());
+      /*namespace_id=*/ref_doc_ns_id,
+      /*target_str=*/ref_tokenized_document.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint),
               IsOkAndHolds(ref_doc_id));
 
@@ -656,12 +732,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result, doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -715,14 +794,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(referenced_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(ref_tokenized_document.document_wrapper()));
   DocumentId ref_doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id,
-      doc_store_->GetNamespaceId(referenced_document.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint(
-      /*namespace_id=*/ref_doc_ns_id, /*target_str=*/referenced_document.uri());
+      /*namespace_id=*/ref_doc_ns_id,
+      /*target_str=*/ref_tokenized_document.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint),
               IsOkAndHolds(ref_doc_id));
 
@@ -734,12 +824,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result, doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -774,14 +867,25 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store_->Put(referenced_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument ref_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(referenced_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store_->Put(ref_tokenized_document.document_wrapper()));
   DocumentId ref_doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       NamespaceId ref_doc_ns_id,
-      doc_store_->GetNamespaceId(referenced_document.namespace_()));
+      doc_store_->GetNamespaceId(
+          ref_tokenized_document.document_wrapper().document().namespace_()));
   NamespaceIdFingerprint ref_doc_nsid_uri_fingerprint(
-      /*namespace_id=*/ref_doc_ns_id, /*target_str=*/referenced_document.uri());
+      /*namespace_id=*/ref_doc_ns_id,
+      /*target_str=*/ref_tokenized_document.document_wrapper()
+          .document()
+          .uri());
   ASSERT_THAT(doc_store_->GetDocumentId(ref_doc_nsid_uri_fingerprint),
               IsOkAndHolds(ref_doc_id));
 
@@ -793,12 +897,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV2Test,
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, doc_store_->Put(document));
-  DocumentId doc_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result, doc_store_->Put(tokenized_document.document_wrapper()));
+  DocumentId doc_id = put_result.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
diff --git a/icing/join/qualified-id-join-indexing-handler-v3_test.cc b/icing/join/qualified-id-join-indexing-handler-v3_test.cc
index 7649424..3b47dbb 100644
--- a/icing/join/qualified-id-join-indexing-handler-v3_test.cc
+++ b/icing/join/qualified-id-join-indexing-handler-v3_test.cc
@@ -29,6 +29,7 @@
 #include "icing/join/qualified-id-join-index-impl-v3.h"
 #include "icing/join/qualified-id-join-indexing-handler.h"
 #include "icing/join/qualified-id.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -150,14 +151,18 @@ class QualifiedIdJoinIndexingHandlerV3Test : public ::testing::Test {
                 IsTrue());
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     doc_store_ = std::move(create_result.document_store);
 
     // Get FakeType related ids.
@@ -246,8 +251,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleJoinableProperty) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result,
-                             doc_store_->Put(parent_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result,
+      doc_store_->Put(parent_tokenized_document.document_wrapper()));
 
   // Create and put child document. Also tokenize it.
   DocumentProto child_document =
@@ -257,12 +269,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleJoinableProperty) {
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(child_document));
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(child_document)));
+      TokenizedDocument child_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
 
   // Handle document.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -271,18 +286,19 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleJoinableProperty) {
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
       QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
                                              qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/false,
-                      /*put_document_stats=*/nullptr),
-      IsOk());
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/false,
+                  /*put_document_stats=*/nullptr),
+              IsOk());
 
   // Verify the state of qualified_id_join_index_ after Handle().
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
   EXPECT_THAT(qualified_id_join_index_, Pointee(SizeIs(1)));
   EXPECT_THAT(
-      qualified_id_join_index_->Get(parent_put_result.new_document_id),
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+          parent_put_result.new_document_id),
       IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
           child_put_result.new_document_id, fake_type_joinable_property_id_))));
 }
@@ -295,8 +311,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleNestedJoinableProperty) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result1,
-                             doc_store_->Put(parent_document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document1,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result1,
+      doc_store_->Put(parent_tokenized_document1.document_wrapper()));
 
   // Create and put parent document2.
   DocumentProto parent_document2 =
@@ -305,8 +328,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleNestedJoinableProperty) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "two")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result2,
-                             doc_store_->Put(parent_document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document2,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result2,
+      doc_store_->Put(parent_tokenized_document2.document_wrapper()));
 
   // Create and put child document:
   // - kPropertyNestedDoc.kPropertyQualifiedId refers to parent_document2.
@@ -328,12 +358,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleNestedJoinableProperty) {
           .AddStringProperty(std::string(kPropertyQualifiedId2),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(child_document));
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                child_document));
+      TokenizedDocument child_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
 
   // Handle nested_document.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -342,21 +375,23 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleNestedJoinableProperty) {
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
       QualifiedIdJoinIndexingHandler::Create(&fake_clock_, doc_store_.get(),
                                              qualified_id_join_index_.get()));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/false,
-                      /*put_document_stats=*/nullptr),
-      IsOk());
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/false,
+                  /*put_document_stats=*/nullptr),
+              IsOk());
 
   // Verify the state of qualified_id_join_index_ after Handle().
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
   EXPECT_THAT(qualified_id_join_index_, Pointee(SizeIs(2)));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result1.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result1.new_document_id),
               IsOkAndHolds(ElementsAre(
                   DocumentJoinIdPair(child_put_result.new_document_id,
                                      nested_type_joinable_property_id_))));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result2.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result2.new_document_id),
               IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
                   child_put_result.new_document_id,
                   nested_type_nested_joinable_property_id_))));
@@ -378,12 +413,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              std::string(kInvalidFormatQualifiedId))
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(tokenized_document.document_wrapper()));
 
   // Handle document. Should ignore invalid format qualified id.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -412,13 +450,16 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleShouldSkipEmptyQualifiedId) {
                                .SetKey("icing", "fake_type/1")
                                .SetSchema(std::string(kFakeType))
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(document)));
   ASSERT_THAT(tokenized_document.qualified_id_join_properties(), IsEmpty());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(tokenized_document.document_wrapper()));
 
   // Handle document.
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
@@ -449,8 +490,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleShouldMigrateParent) {
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result,
-                             doc_store_->Put(parent_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result,
+      doc_store_->Put(parent_tokenized_document.document_wrapper()));
 
   // Create and put child and grandchild document with relations:
   // parent_document <- child_document <- grandchild_document
@@ -469,6 +517,7 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleShouldMigrateParent) {
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "icing#fake_type/1")
           .Build();
+  DocumentProto child_document_replaced = child_document;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -476,26 +525,34 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleShouldMigrateParent) {
                                              qualified_id_join_index_.get()));
 
   // Put and index child document.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(child_document));
-  ASSERT_THAT(child_put_result.old_document_id, Eq(kInvalidDocumentId));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument child_tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                child_document));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
+  ASSERT_THAT(child_put_result.old_document_id, Eq(kInvalidDocumentId));
+
   ICING_ASSERT_OK(handler->Handle(
       child_tokenized_document, child_put_result.new_document_id,
       child_put_result.old_document_id,
       /*recovery_mode=*/false, /*put_document_stats=*/nullptr));
 
   // Put and index grandchild document.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult grandchild_put_result,
-                             doc_store_->Put(grandchild_document));
-  ASSERT_THAT(grandchild_put_result.old_document_id, Eq(kInvalidDocumentId));
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument grandchild_tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(grandchild_document)));
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(grandchild_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult grandchild_put_result,
+      doc_store_->Put(grandchild_tokenized_document.document_wrapper()));
+  ASSERT_THAT(grandchild_put_result.old_document_id, Eq(kInvalidDocumentId));
+
   ICING_ASSERT_OK(handler->Handle(
       grandchild_tokenized_document, grandchild_put_result.new_document_id,
       grandchild_put_result.old_document_id,
@@ -507,40 +564,53 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test, HandleShouldMigrateParent) {
               Eq(grandchild_put_result.new_document_id));
   ASSERT_THAT(qualified_id_join_index_, Pointee(SizeIs(2)));
   ASSERT_THAT(
-      qualified_id_join_index_->Get(parent_put_result.new_document_id),
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+          parent_put_result.new_document_id),
       IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
           child_put_result.new_document_id, fake_type_joinable_property_id_))));
-  ASSERT_THAT(qualified_id_join_index_->Get(child_put_result.new_document_id),
+  ASSERT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  child_put_result.new_document_id),
               IsOkAndHolds(ElementsAre(
                   DocumentJoinIdPair(grandchild_put_result.new_document_id,
                                      fake_type_joinable_property_id_))));
 
   // Update the child document and index it again.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result2,
-                             doc_store_->Put(child_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument child_tokenized_document_replaced,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document_replaced)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result2,
+      doc_store_->Put(child_tokenized_document_replaced.document_wrapper()));
   ASSERT_THAT(child_put_result2.old_document_id,
               Eq(child_put_result.new_document_id));
 
   // Handle should migrate.
-  EXPECT_THAT(handler->Handle(
-                  child_tokenized_document, child_put_result2.new_document_id,
-                  child_put_result2.old_document_id, /*recovery_mode=*/false,
-                  /*put_document_stats=*/nullptr),
-              IsOk());
+  EXPECT_THAT(
+      handler->Handle(child_tokenized_document_replaced,
+                      child_put_result2.new_document_id,
+                      child_put_result2.old_document_id,
+                      /*recovery_mode=*/false, /*put_document_stats=*/nullptr),
+      IsOk());
   EXPECT_THAT(qualified_id_join_index_, Pointee(SizeIs(3)));
   // Get() with parent document id should return DocumentJoinIdPairs for both
   // old and new child document id.
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result.new_document_id),
               IsOkAndHolds(ElementsAre(
                   DocumentJoinIdPair(child_put_result.new_document_id,
                                      fake_type_joinable_property_id_),
                   DocumentJoinIdPair(child_put_result2.new_document_id,
                                      fake_type_joinable_property_id_))));
   // Get() with old child document id should return empty list.
-  EXPECT_THAT(qualified_id_join_index_->Get(child_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  child_put_result.new_document_id),
               IsOkAndHolds(IsEmpty()));
   // Get() with new child document id should return grandchild join id pair.
-  EXPECT_THAT(qualified_id_join_index_->Get(child_put_result2.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  child_put_result2.new_document_id),
               IsOkAndHolds(ElementsAre(
                   DocumentJoinIdPair(grandchild_put_result.new_document_id,
                                      fake_type_joinable_property_id_))));
@@ -555,23 +625,33 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result,
-                             doc_store_->Put(parent_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result,
+      doc_store_->Put(parent_tokenized_document.document_wrapper()));
 
   // Create and put child document. Also tokenize it.
-  DocumentProto document =
+  DocumentProto child_document =
       DocumentBuilder()
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument child_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
 
   qualified_id_join_index_->set_last_added_document_id(
       parent_put_result.new_document_id);
@@ -585,7 +665,7 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
 
   // Handling document with kInvalidDocumentId should cause a failure.
   EXPECT_THAT(
-      handler->Handle(tokenized_document, kInvalidDocumentId,
+      handler->Handle(child_tokenized_document, kInvalidDocumentId,
                       child_put_result.old_document_id, /*recovery_mode=*/false,
                       /*put_document_stats=*/nullptr),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
@@ -597,14 +677,15 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
 
   // Recovery mode should get the same result.
   EXPECT_THAT(
-      handler->Handle(tokenized_document, kInvalidDocumentId,
+      handler->Handle(child_tokenized_document, kInvalidDocumentId,
                       child_put_result.old_document_id, /*recovery_mode=*/true,
                       /*put_document_stats=*/nullptr),
       StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(parent_put_result.new_document_id));
   EXPECT_THAT(qualified_id_join_index_, Pointee(IsEmpty()));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result.new_document_id),
               IsOkAndHolds(IsEmpty()));
 }
 
@@ -617,23 +698,33 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result,
-                             doc_store_->Put(parent_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result,
+      doc_store_->Put(parent_tokenized_document.document_wrapper()));
 
   // Create and put child document. Also tokenize it.
-  DocumentProto document =
+  DocumentProto child_document =
       DocumentBuilder()
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument child_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -646,17 +737,18 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
       child_put_result.new_document_id);
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/false,
-                      /*put_document_stats=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/false,
+                  /*put_document_stats=*/nullptr),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
   // Verify the state of qualified_id_join_index_ after Handle(). Both index
   // data and last_added_document_id should remain unchanged.
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
   EXPECT_THAT(qualified_id_join_index_, Pointee(IsEmpty()));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result.new_document_id),
               IsOkAndHolds(IsEmpty()));
 
   // Handling document with document_id < last_added_document_id should cause a
@@ -665,17 +757,18 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
       child_put_result.new_document_id + 1);
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id + 1));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/false,
-                      /*put_document_stats=*/nullptr),
-      StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/false,
+                  /*put_document_stats=*/nullptr),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
   // Verify the state of qualified_id_join_index_ after Handle(). Both index
   // data and last_added_document_id should remain unchanged.
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id + 1));
   EXPECT_THAT(qualified_id_join_index_, Pointee(IsEmpty()));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result.new_document_id),
               IsOkAndHolds(IsEmpty()));
 }
 
@@ -688,23 +781,33 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result,
-                             doc_store_->Put(parent_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result,
+      doc_store_->Put(parent_tokenized_document.document_wrapper()));
 
   // Create and put child document. Also tokenize it.
-  DocumentProto document =
+  DocumentProto child_document =
       DocumentBuilder()
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument child_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -717,16 +820,17 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
       child_put_result.new_document_id - 1);
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id - 1));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/true,
-                      /*put_document_stats=*/nullptr),
-      IsOk());
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/true,
+                  /*put_document_stats=*/nullptr),
+              IsOk());
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
   EXPECT_THAT(qualified_id_join_index_, Pointee(SizeIs(1)));
   EXPECT_THAT(
-      qualified_id_join_index_->Get(parent_put_result.new_document_id),
+      qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+          parent_put_result.new_document_id),
       IsOkAndHolds(ElementsAre(DocumentJoinIdPair(
           child_put_result.new_document_id, fake_type_joinable_property_id_))));
 }
@@ -740,23 +844,33 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
           .SetSchema(std::string(kReferencedType))
           .AddStringProperty(std::string(kPropertyName), "one")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult parent_put_result,
-                             doc_store_->Put(parent_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument parent_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(parent_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult parent_put_result,
+      doc_store_->Put(parent_tokenized_document.document_wrapper()));
 
   // Create and put child document. Also tokenize it.
-  DocumentProto document =
+  DocumentProto child_document =
       DocumentBuilder()
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kPropertyQualifiedId),
                              "pkg$db/ns#ref_type/1")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult child_put_result,
-                             doc_store_->Put(document));
   ICING_ASSERT_OK_AND_ASSIGN(
-      TokenizedDocument tokenized_document,
-      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                std::move(document)));
+      TokenizedDocument child_tokenized_document,
+      TokenizedDocument::Create(
+          schema_store_.get(), lang_segmenter_.get(),
+          /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds(),
+          std::move(child_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult child_put_result,
+      doc_store_->Put(child_tokenized_document.document_wrapper()));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<QualifiedIdJoinIndexingHandler> handler,
@@ -771,15 +885,16 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
       child_put_result.new_document_id);
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/true,
-                      /*put_document_stats=*/nullptr),
-      IsOk());
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/true,
+                  /*put_document_stats=*/nullptr),
+              IsOk());
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id));
   EXPECT_THAT(qualified_id_join_index_, Pointee(IsEmpty()));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result.new_document_id),
               IsOkAndHolds(IsEmpty()));
 
   // Handle document with document_id < last_added_document_id in recovery mode.
@@ -789,15 +904,16 @@ TEST_F(QualifiedIdJoinIndexingHandlerV3Test,
       child_put_result.new_document_id + 1);
   ASSERT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id + 1));
-  EXPECT_THAT(
-      handler->Handle(tokenized_document, child_put_result.new_document_id,
-                      child_put_result.old_document_id, /*recovery_mode=*/true,
-                      /*put_document_stats=*/nullptr),
-      IsOk());
+  EXPECT_THAT(handler->Handle(
+                  child_tokenized_document, child_put_result.new_document_id,
+                  child_put_result.old_document_id, /*recovery_mode=*/true,
+                  /*put_document_stats=*/nullptr),
+              IsOk());
   EXPECT_THAT(qualified_id_join_index_->last_added_document_id(),
               Eq(child_put_result.new_document_id + 1));
   EXPECT_THAT(qualified_id_join_index_, Pointee(IsEmpty()));
-  EXPECT_THAT(qualified_id_join_index_->Get(parent_put_result.new_document_id),
+  EXPECT_THAT(qualified_id_join_index_->GetDocumentJoinIdPairArrayView(
+                  parent_put_result.new_document_id),
               IsOkAndHolds(IsEmpty()));
 }
 
diff --git a/icing/join/qualified-id.h b/icing/join/qualified-id.h
index eb6606a..4b26e60 100644
--- a/icing/join/qualified-id.h
+++ b/icing/join/qualified-id.h
@@ -15,8 +15,11 @@
 #ifndef ICING_JOIN_QUALIFIED_ID_H_
 #define ICING_JOIN_QUALIFIED_ID_H_
 
+#include <cstddef>
+#include <functional>
 #include <string>
 #include <string_view>
+#include <utility>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 
@@ -34,6 +37,13 @@ namespace lib {
 // - Raw namespace and uri cannot be empty.
 class QualifiedId {
  public:
+  struct Hasher {
+    std::size_t operator()(const QualifiedId& qualified_id) const {
+      return std::hash<std::string>()(qualified_id.name_space_) ^
+             std::hash<std::string>()(qualified_id.uri_);
+    }
+  };
+
   static constexpr char kEscapeChar = '\\';
   static constexpr char kNamespaceUriSeparator = '#';
 
@@ -51,6 +61,10 @@ class QualifiedId {
   explicit QualifiedId(std::string name_space, std::string uri)
       : name_space_(std::move(name_space)), uri_(std::move(uri)) {}
 
+  bool operator==(const QualifiedId& other) const {
+    return name_space_ == other.name_space_ && uri_ == other.uri_;
+  }
+
   const std::string& name_space() const { return name_space_; }
   const std::string& uri() const { return uri_; }
 
diff --git a/icing/legacy/index/icing-dynamic-trie.cc b/icing/legacy/index/icing-dynamic-trie.cc
index e665272..75dc737 100644
--- a/icing/legacy/index/icing-dynamic-trie.cc
+++ b/icing/legacy/index/icing-dynamic-trie.cc
@@ -535,7 +535,7 @@ bool IcingDynamicTrie::IcingDynamicTrieStorage::Init() {
   if (!hdr_.Init(hdr_mmapper_.address(),
                  IcingMMapper::system_page_size() - sizeof(Crcs)) ||
       !hdr_.Verify()) {
-    ICING_LOG(ERROR) << "Trie reading header failed";
+    ICING_LOG(ERROR) << "Trie reading header failed. Path: " << file_basename_;
     goto failed;
   }
 
@@ -958,7 +958,8 @@ bool IcingDynamicTrie::IcingDynamicTrieStorage::Header::Init(
   uint32_t magic;
   memcpy(&magic, buf, sizeof(magic));
   if (magic != kMagic) {
-    ICING_LOG(ERROR) << "Trie header magic mismatch";
+    ICING_LOG(ERROR) << "Invalid header magic for IcingDynamicTrie. Expected: "
+                     << kMagic << ", actual: " << magic;
     return false;
   }
   uint32_t len;
diff --git a/icing/legacy/index/icing-filesystem.cc b/icing/legacy/index/icing-filesystem.cc
index 175e075..d601abd 100644
--- a/icing/legacy/index/icing-filesystem.cc
+++ b/icing/legacy/index/icing-filesystem.cc
@@ -129,15 +129,21 @@ bool ListDirectoryInternal(const char *dir_name,
                            const std::unordered_set<std::string> &exclude,
                            bool recursive, const char *prefix,
                            std::vector<std::string> *entries) {
-  DIR *dir = opendir(dir_name);
-  if (!dir) {
+  auto closer = [](DIR *dir) {
+    if (closedir(dir) != 0) {
+      ICING_LOG(ERROR) << "Error closing dir (" << errno << ") "
+                       << strerror(errno);
+    }
+  };
+  std::unique_ptr<DIR, decltype(closer)> dir(opendir(dir_name), closer);
+  if (dir == nullptr) {
     LogOpenError("Unable to open directory ", dir_name, ": ", errno);
     return false;
   }
 
   dirent *p;
   // readdir's implementation seems to be thread safe.
-  while ((p = readdir(dir)) != nullptr) {
+  while ((p = readdir(dir.get())) != nullptr) {
     std::string file_name(p->d_name);
     if (file_name == "." || file_name == ".." ||
         exclude.find(file_name) != exclude.end()) {
@@ -156,9 +162,6 @@ bool ListDirectoryInternal(const char *dir_name,
       }
     }
   }
-  if (closedir(dir) != 0) {
-    ICING_LOG(ERROR) << "Error closing " << dir_name << ": " << strerror(errno);
-  }
   return true;
 }
 
diff --git a/icing/monkey_test/icing-monkey-test-runner.cc b/icing/monkey_test/icing-monkey-test-runner.cc
index 14b4e02..0636dab 100644
--- a/icing/monkey_test/icing-monkey-test-runner.cc
+++ b/icing/monkey_test/icing-monkey-test-runner.cc
@@ -67,6 +67,11 @@ bool GetRandomBoolean(MonkeyTestRandomEngine* random) {
   return dist(*random) == 1;
 }
 
+int GetRandomInt(MonkeyTestRandomEngine* random, int min, int max) {
+  std::uniform_int_distribution<> dist(min, max);
+  return dist(*random);
+}
+
 SearchSpecProto GenerateRandomSearchSpecProto(
     MonkeyTestRandomEngine* random,
     MonkeyDocumentGenerator* document_generator) {
@@ -553,6 +558,9 @@ void IcingMonkeyTestRunner::CreateIcingSearchEngine() {
       GetRandomBoolean(&random_));
   icing_options.set_enable_embedding_index(true);
   icing_options.set_enable_embedding_quantization(GetRandomBoolean(&random_));
+  icing_options.set_compression_threshold_bytes(
+      GetRandomInt(&random_, /*min=*/0, /*max=*/10000));
+  icing_options.set_enable_eigen_embedding_scoring(GetRandomBoolean(&random_));
   icing_ = std::make_unique<IcingSearchEngine>(icing_options);
   ASSERT_THAT(icing_->Initialize().status(), ProtoIsOk());
 }
diff --git a/icing/portable/gzip_stream.cc b/icing/portable/gzip_stream.cc
index f00a993..744dfc4 100644
--- a/icing/portable/gzip_stream.cc
+++ b/icing/portable/gzip_stream.cc
@@ -18,14 +18,13 @@
 // smaller libprotobuf-lite instead.
 
 #include "icing/portable/gzip_stream.h"
+
 #include "icing/util/logging.h"
 
 namespace icing {
 namespace lib {
 namespace protobuf_ports {
 
-static const int kDefaultBufferSize = 65536;
-
 GzipInputStream::GzipInputStream(ZeroCopyInputStream* sub_stream, Format format,
                                  int buffer_size)
     : format_(format), sub_stream_(sub_stream), zerror_(Z_OK), byte_count_(0) {
@@ -179,7 +178,8 @@ GzipOutputStream::Options::Options()
     : format(GZIP),
       buffer_size(kDefaultBufferSize),
       compression_level(Z_DEFAULT_COMPRESSION),
-      compression_strategy(Z_DEFAULT_STRATEGY) {}
+      compression_strategy(Z_DEFAULT_STRATEGY),
+      mem_level(kDefaultMemLevel) {}
 
 GzipOutputStream::GzipOutputStream(ZeroCopyOutputStream* sub_stream) {
   Init(sub_stream, Options());
@@ -214,10 +214,10 @@ void GzipOutputStream::Init(ZeroCopyOutputStream* sub_stream,
   if (options.format == ZLIB) {
     windowBitsFormat = 0;
   }
-  zerror_ =
-      deflateInit2(&zcontext_, options.compression_level, Z_DEFLATED,
-                   /* windowBits */ 15 | windowBitsFormat,
-                   /* memLevel (default) */ 8, options.compression_strategy);
+  zerror_ = deflateInit2(&zcontext_, options.compression_level, Z_DEFLATED,
+                         /* windowBits */ 15 | windowBitsFormat,
+                         /* memLevel */ options.mem_level,
+                         options.compression_strategy);
 }
 
 GzipOutputStream::~GzipOutputStream() {
diff --git a/icing/portable/gzip_stream.h b/icing/portable/gzip_stream.h
index 8008a55..f195736 100644
--- a/icing/portable/gzip_stream.h
+++ b/icing/portable/gzip_stream.h
@@ -27,6 +27,8 @@
 #ifndef GOOGLE3_ICING_PORTABLE_GZIP_STREAM_H_
 #define GOOGLE3_ICING_PORTABLE_GZIP_STREAM_H_
 
+#include <cstdint>
+
 #include "icing/portable/zlib.h"
 #include <google/protobuf/io/zero_copy_stream_impl_lite.h>
 
@@ -34,6 +36,9 @@ namespace icing {
 namespace lib {
 namespace protobuf_ports {
 
+static constexpr int64_t kDefaultBufferSize = 64 * 1024;  // 64kb
+static constexpr int kDefaultMemLevel = 8;
+
 // A ZeroCopyInputStream that reads compressed data through zlib
 class GzipInputStream : public google::protobuf::io::ZeroCopyInputStream {
  public:
@@ -108,6 +113,16 @@ class GzipOutputStream : public google::protobuf::io::ZeroCopyOutputStream {
     // zlib.h for definitions of these constants.
     int compression_strategy;
 
+    // Used for deflateInit2.
+    // A number between 1 and 9, specifying how much memory should be allocated
+    // for the internal compression state.
+    // memLevel=1 uses minimum memory but is slow and reduces compression ratio;
+    // memLevel=9 uses maximum memory for optimal speed.
+    // The default value is 8.
+    //
+    // See the documentation for deflateInit2 in zlib.h for more details.
+    int mem_level;
+
     Options();  // Initializes with default values.
   };
 
diff --git a/icing/query/advanced_query_parser/query-visitor.cc b/icing/query/advanced_query_parser/query-visitor.cc
index 04624b7..d61987c 100644
--- a/icing/query/advanced_query_parser/query-visitor.cc
+++ b/icing/query/advanced_query_parser/query-visitor.cc
@@ -462,14 +462,20 @@ libtextclassifier3::StatusOr<PendingValue> QueryVisitor::SemanticSearchFunction(
   }
 
   // Create and return iterator.
-  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map =
-      &embedding_query_results_.result_infos[vector_index][metric_type];
+  ICING_ASSIGN_OR_RETURN(
+      EmbeddingQueryResults::EmbeddingQueryMatchInfoMap * info_map,
+      embedding_query_results_.GetOrCreateMatchInfoMap(vector_index,
+                                                       metric_type));
   ICING_ASSIGN_OR_RETURN(
       std::unique_ptr<DocHitInfoIterator> iterator,
       DocHitInfoIteratorEmbedding::Create(
           &search_spec_.embedding_query_vectors(vector_index), metric_type, low,
-          high, get_embedding_match_info_, info_map, &embedding_index_,
-          &document_store_, &schema_store_, current_time_ms_));
+          high, info_map, embedding_query_results_.global_scores.get(),
+          get_embedding_match_info_
+              ? embedding_query_results_.global_section_infos.get()
+              : nullptr,
+          &embedding_index_, &document_store_, &schema_store_,
+          current_time_ms_));
   return PendingValue(std::move(iterator));
 }
 
diff --git a/icing/query/advanced_query_parser/query-visitor.h b/icing/query/advanced_query_parser/query-visitor.h
index 746d921..2278f32 100644
--- a/icing/query/advanced_query_parser/query-visitor.h
+++ b/icing/query/advanced_query_parser/query-visitor.h
@@ -124,7 +124,8 @@ class QueryVisitor : public AbstractSyntaxTreeVisitor {
       const FeatureFlags* feature_flags,
       PendingPropertyRestricts pending_property_restricts, bool processing_not,
       int64_t current_time_ms)
-      : index_(*index),
+      : embedding_query_results_(search_spec.embedding_query_vectors_size()),
+        index_(*index),
         numeric_index_(*numeric_index),
         embedding_index_(*embedding_index),
         document_store_(*document_store),
diff --git a/icing/query/advanced_query_parser/query-visitor_test.cc b/icing/query/advanced_query_parser/query-visitor_test.cc
index 3c50b4a..0825dd1 100644
--- a/icing/query/advanced_query_parser/query-visitor_test.cc
+++ b/icing/query/advanced_query_parser/query-visitor_test.cc
@@ -47,6 +47,7 @@
 #include "icing/index/property-existence-indexing-handler.h"
 #include "icing/jni/jni-cache.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/search.pb.h"
 #include "icing/query/advanced_query_parser/abstract-syntax-tree.h"
@@ -57,6 +58,7 @@
 #include "icing/schema-builder.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
+#include "icing/scoring/advanced_scoring/double-list.h"
 #include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/store/namespace-id.h"
@@ -74,6 +76,7 @@
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/status-macros.h"
 #include "unicode/uloc.h"
@@ -88,7 +91,6 @@ using ::testing::DoubleNear;
 using ::testing::ElementsAre;
 using ::testing::IsEmpty;
 using ::testing::IsNull;
-using ::testing::Pointee;
 using ::testing::UnorderedElementsAre;
 
 constexpr float kEps = 0.000001;
@@ -165,20 +167,25 @@ SearchSpecProto CreateSearchSpec(std::string query,
       /*embedding_query_vectors=*/{}, EMBEDDING_METRIC_UNKNOWN);
 }
 
-bool ContainsMatchInfoEntry(const EmbeddingMatchInfos* match_info, double score,
+bool ContainsMatchInfoEntry(EmbeddingQueryResults& embedding_query_results,
+                            const EmbeddingMatchInfos* match_info, double score,
                             int position_in_section, SectionId section_id) {
-  if (match_info == nullptr || match_info->section_infos == nullptr ||
-      match_info->scores.empty()) {
-    return false;
-  }
-  if (match_info->scores.size() != match_info->section_infos->size()) {
+  if (match_info == nullptr ||
+      embedding_query_results.global_section_infos->empty()) {
     return false;
   }
 
-  for (int i = 0; i < match_info->scores.size(); ++i) {
-    if (std::fabs(match_info->scores[i] - score) < kEps &&
-        match_info->section_infos->at(i).position == position_in_section &&
-        match_info->section_infos->at(i).section_id == section_id) {
+  DoubleList matched_scores =
+      embedding_query_results.GetMatchedScoresFromEmbeddingMatchInfos(
+          *match_info);
+
+  for (int i = 0; i < matched_scores.size(); ++i) {
+    const EmbeddingMatchInfos::EmbeddingMatchSectionInfo& section_info =
+        embedding_query_results.global_section_infos->at(
+            i + match_info->score_start_index);
+    if (std::fabs(matched_scores.data()[i] - score) < kEps &&
+        section_info.position == position_in_section &&
+        section_info.section_id == section_id) {
       return true;
     }
   }
@@ -236,14 +243,18 @@ class QueryVisitorTest
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, store_dir_, &clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, store_dir_, &clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     Index::Options options(index_dir_.c_str(),
@@ -838,8 +849,8 @@ TEST_P(QueryVisitorTest, NumericComparatorDoesntAffectLaterTerms) {
   // - Doc0: ["-2", "-1", "1", "2"] and [-2, -1, 1, 2]
   // - Doc1: [-1]
   // - Doc2: ["2"] and [-1]
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   std::unique_ptr<NumericIndex<int64_t>::Editor> editor =
       numeric_index_->Edit("price", kDocumentId0, kSectionId0);
   ICING_ASSERT_OK(editor->BufferKey(-2));
@@ -855,14 +866,14 @@ TEST_P(QueryVisitorTest, NumericComparatorDoesntAffectLaterTerms) {
   ICING_ASSERT_OK(term_editor.BufferTerm("2", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(term_editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = numeric_index_->Edit("price", kDocumentId1, kSectionId0);
   ICING_ASSERT_OK(editor->BufferKey(-1));
   ICING_ASSERT_OK(std::move(*editor).IndexAllBufferedKeys());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = numeric_index_->Edit("price", kDocumentId2, kSectionId0);
   ICING_ASSERT_OK(editor->BufferKey(-1));
   ICING_ASSERT_OK(std::move(*editor).IndexAllBufferedKeys());
@@ -1455,22 +1466,22 @@ TEST_P(QueryVisitorTest, SingleMinusTerm) {
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -1499,22 +1510,22 @@ TEST_P(QueryVisitorTest, SingleNotTerm) {
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -1539,8 +1550,8 @@ TEST_P(QueryVisitorTest, NestedNotTerms) {
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -1548,16 +1559,16 @@ TEST_P(QueryVisitorTest, NestedNotTerms) {
   ICING_ASSERT_OK(editor.BufferTerm("baz", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.BufferTerm("baz", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -1587,8 +1598,8 @@ TEST_P(QueryVisitorTest, DeeplyNestedNotTerms) {
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -1596,16 +1607,16 @@ TEST_P(QueryVisitorTest, DeeplyNestedNotTerms) {
   ICING_ASSERT_OK(editor.BufferTerm("baz", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.BufferTerm("baz", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -1819,23 +1830,23 @@ TEST_P(QueryVisitorTest, AndOrNotPrecedence) {
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -1889,22 +1900,22 @@ TEST_P(QueryVisitorTest, PropertyFilter) {
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -1955,22 +1966,22 @@ TEST_P(QueryVisitorTest, MultiPropertyFilter) {
   SectionId prop2_section_id = 1;
   SectionId prop3_section_id = 2;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop3_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2035,22 +2046,22 @@ TEST_P(QueryVisitorTest, PropertyFilterNonNormalized) {
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2095,22 +2106,22 @@ TEST_P(QueryVisitorTest, PropertyFilterWithGrouping) {
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2153,22 +2164,22 @@ TEST_P(QueryVisitorTest, ValidNestedPropertyFilter) {
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2222,22 +2233,22 @@ TEST_P(QueryVisitorTest, InvalidNestedPropertyFilter) {
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2287,22 +2298,22 @@ TEST_P(QueryVisitorTest, NotWithPropertyFilter) {
   SectionId prop1_section_id = 0;
   SectionId prop2_section_id = 1;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2367,22 +2378,22 @@ TEST_P(QueryVisitorTest, PropertyFilterWithNot) {
   //   Doc2:
   //     prop1: ""
   //     prop2: "foo"
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2452,8 +2463,8 @@ TEST_P(QueryVisitorTest, SegmentationTest) {
   // ICU segmentation will break this into "" and "".
   // CFStringTokenizer (ios) will break this into "", "" and ""
   std::string query = CreateQuery("");
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("", TERM_MATCH_PREFIX));
@@ -2468,15 +2479,15 @@ TEST_P(QueryVisitorTest, SegmentationTest) {
   }
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop2_section_id,
                         /*namespace_id=*/0);
   if (IsCfStringTokenization()) {
@@ -2537,8 +2548,9 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
   // - Doc 0: Contains 'val0', 'val1', 'val2' in 'prop0'. Shouldn't match.
   DocumentProto doc =
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid0 = put_result0.new_document_id;
   Index::Editor editor = index_->Edit(docid0, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2548,8 +2560,9 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
 
   // - Doc 1: Contains 'val0', 'val1', 'val2' in 'prop1'. Should match.
   doc = DocumentBuilder(doc).SetUri("uri1").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid1 = put_result1.new_document_id;
   editor = index_->Edit(docid1, prop1_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2559,8 +2572,9 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
 
   // - Doc 2: Contains 'val0', 'val1', 'val2' in 'prop2'. Shouldn't match.
   doc = DocumentBuilder(doc).SetUri("uri2").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid2 = put_result2.new_document_id;
   editor = index_->Edit(docid2, prop2_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2570,8 +2584,9 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
 
   // - Doc 3: Contains 'val0' in 'prop0', 'val1' in 'prop1' etc. Should match.
   doc = DocumentBuilder(doc).SetUri("uri3").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid3 = put_result3.new_document_id;
   editor = index_->Edit(docid3, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2586,8 +2601,9 @@ TEST_P(QueryVisitorTest, PropertyRestrictsPopCorrectly) {
   // - Doc 4: Contains 'val1' in 'prop0', 'val2' in 'prop1', 'val0' in 'prop2'.
   //          Shouldn't match.
   doc = DocumentBuilder(doc).SetUri("uri4").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid4 = put_result4.new_document_id;
   editor = index_->Edit(docid4, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val1", TERM_MATCH_PREFIX));
@@ -2651,8 +2667,9 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
   // - Doc 0: Contains 'val0', 'val1', 'val2' in 'prop0'. Should match.
   DocumentProto doc =
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid0 = put_result0.new_document_id;
   Index::Editor editor = index_->Edit(docid0, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2662,8 +2679,9 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
 
   // - Doc 1: Contains 'val0', 'val1', 'val2' in 'prop1'. Shouldn't match.
   doc = DocumentBuilder(doc).SetUri("uri1").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid1 = put_result1.new_document_id;
   editor = index_->Edit(docid1, prop1_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2673,8 +2691,9 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
 
   // - Doc 2: Contains 'val0', 'val1', 'val2' in 'prop2'. Should match.
   doc = DocumentBuilder(doc).SetUri("uri2").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid2 = put_result2.new_document_id;
   editor = index_->Edit(docid2, prop2_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2684,8 +2703,9 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
 
   // - Doc 3: Contains 'val0' in 'prop0', 'val1' in 'prop1' etc. Should match.
   doc = DocumentBuilder(doc).SetUri("uri3").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid3 = put_result3.new_document_id;
   editor = index_->Edit(docid3, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val0", TERM_MATCH_PREFIX));
@@ -2700,8 +2720,9 @@ TEST_P(QueryVisitorTest, UnsatisfiablePropertyRestrictsPopCorrectly) {
   // - Doc 4: Contains 'val1' in 'prop0', 'val2' in 'prop1', 'val0' in 'prop2'.
   //          Shouldn't match.
   doc = DocumentBuilder(doc).SetUri("uri4").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid4 = put_result4.new_document_id;
   editor = index_->Edit(docid4, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("val1", TERM_MATCH_PREFIX));
@@ -2807,22 +2828,22 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedFunctionCalls) {
   // Section ids are assigned alphabetically.
   SectionId prop1_section_id = 0;
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, prop1_section_id,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId1, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("type").Build())));
   editor = index_->Edit(kDocumentId2, prop1_section_id,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2916,8 +2937,9 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
   NamespaceId ns_id = 0;
   DocumentProto doc =
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid0 = put_result0.new_document_id;
   Index::Editor editor = index_->Edit(kDocumentId0, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2925,7 +2947,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri1").Build())));
   DocumentId docid1 = put_result1.new_document_id;
   editor = index_->Edit(docid1, prop1_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2933,7 +2956,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri2").Build())));
   DocumentId docid2 = put_result2.new_document_id;
   editor = index_->Edit(docid2, prop2_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2941,7 +2965,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri3").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri3").Build())));
   DocumentId docid3 = put_result3.new_document_id;
   editor = index_->Edit(docid3, prop3_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2949,7 +2974,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result4,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri4").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri4").Build())));
   DocumentId docid4 = put_result4.new_document_id;
   editor = index_->Edit(docid4, prop4_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2957,7 +2983,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result5,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri5").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri5").Build())));
   DocumentId docid5 = put_result5.new_document_id;
   editor = index_->Edit(docid5, prop5_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2965,7 +2992,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result6,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri6").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri6").Build())));
   DocumentId docid6 = put_result6.new_document_id;
   editor = index_->Edit(docid6, prop6_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -2973,7 +3001,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsNarrowing) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result7,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri7").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri7").Build())));
   DocumentId docid7 = put_result7.new_document_id;
   editor = index_->Edit(docid7, prop7_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3076,8 +3105,9 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
   NamespaceId ns_id = 0;
   DocumentProto doc =
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid0 = put_result0.new_document_id;
   Index::Editor editor = index_->Edit(kDocumentId0, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3085,7 +3115,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri1").Build())));
   DocumentId docid1 = put_result1.new_document_id;
   editor = index_->Edit(docid1, prop1_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3093,7 +3124,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri2").Build())));
   DocumentId docid2 = put_result2.new_document_id;
   editor = index_->Edit(docid2, prop2_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3101,7 +3133,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri3").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri3").Build())));
   DocumentId docid3 = put_result3.new_document_id;
   editor = index_->Edit(docid3, prop3_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3109,7 +3142,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result4,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri4").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri4").Build())));
   DocumentId docid4 = put_result4.new_document_id;
   editor = index_->Edit(docid4, prop4_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3117,7 +3151,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result5,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri5").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri5").Build())));
   DocumentId docid5 = put_result5.new_document_id;
   editor = index_->Edit(docid5, prop5_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3125,7 +3160,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result6,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri6").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri6").Build())));
   DocumentId docid6 = put_result6.new_document_id;
   editor = index_->Edit(docid6, prop6_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3133,7 +3169,8 @@ TEST_P(QueryVisitorTest, SearchFunctionNestedPropertyRestrictsExpanding) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result7,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri7").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri7").Build())));
   DocumentId docid7 = put_result7.new_document_id;
   editor = index_->Edit(docid7, prop7_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3208,8 +3245,9 @@ TEST_P(QueryVisitorTest, QueryStringParameterHandlesPunctuation) {
   NamespaceId ns_id = 0;
   DocumentProto doc =
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid0 = put_result0.new_document_id;
   Index::Editor editor = index_->Edit(kDocumentId0, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3218,7 +3256,8 @@ TEST_P(QueryVisitorTest, QueryStringParameterHandlesPunctuation) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri1").Build())));
   DocumentId docid1 = put_result1.new_document_id;
   editor = index_->Edit(docid1, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -3226,7 +3265,8 @@ TEST_P(QueryVisitorTest, QueryStringParameterHandlesPunctuation) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri2").Build())));
   DocumentId docid2 = put_result2.new_document_id;
   editor = index_->Edit(docid2, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3327,8 +3367,9 @@ TEST_P(QueryVisitorTest, QueryStringParameterPropertyRestricts) {
   NamespaceId ns_id = 0;
   DocumentProto doc =
       DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(doc));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(document_util::CreateDocumentWrapper(doc)));
   DocumentId docid0 = put_result0.new_document_id;
   Index::Editor editor = index_->Edit(docid0, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3337,7 +3378,8 @@ TEST_P(QueryVisitorTest, QueryStringParameterPropertyRestricts) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri1").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri1").Build())));
   DocumentId docid1 = put_result1.new_document_id;
   editor = index_->Edit(docid1, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -3348,7 +3390,8 @@ TEST_P(QueryVisitorTest, QueryStringParameterPropertyRestricts) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(DocumentBuilder(doc).SetUri("uri2").Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder(doc).SetUri("uri2").Build())));
   DocumentId docid2 = put_result2.new_document_id;
   editor = index_->Edit(docid2, prop0_id, ns_id);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -3520,17 +3563,21 @@ TEST_P(QueryVisitorTest, PropertyDefinedFunctionReturnsMatchingDocuments) {
 
   // Document 0 has the term "foo" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("typeWithUrl").Build()));
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("typeWithUrl")
+                                               .Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   // Document 1 has the term "foo" and its schema DOESN'T have the url property.
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("typeWithoutUrl")
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("typeWithoutUrl")
+                                               .Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3538,7 +3585,10 @@ TEST_P(QueryVisitorTest, PropertyDefinedFunctionReturnsMatchingDocuments) {
 
   // Document 2 has the term "bar" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("typeWithUrl").Build()));
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri2")
+                                               .SetSchema("typeWithUrl")
+                                               .Build())));
   editor = index_->Edit(kDocumentId2, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -3569,17 +3619,21 @@ TEST_P(QueryVisitorTest,
 
   // Document 0 has the term "foo" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("typeWithUrl").Build()));
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("typeWithUrl")
+                                               .Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   // Document 1 has the term "foo" and its schema DOESN'T have the url property.
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("typeWithoutUrl")
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("typeWithoutUrl")
+                                               .Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3610,17 +3664,21 @@ TEST_P(QueryVisitorTest,
 
   // Document 0 has the term "foo" and its schema has the url property.
   ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("typeWithUrl").Build()));
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("typeWithUrl")
+                                               .Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   // Document 1 has the term "foo" and its schema DOESN'T have the url property.
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("typeWithoutUrl")
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("typeWithoutUrl")
+                                               .Build())));
   editor = index_->Edit(kDocumentId1, kSectionId1,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3680,8 +3738,8 @@ TEST_P(QueryVisitorTest, HasPropertyFunctionReturnsMatchingDocuments) {
       /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and has the "price" property.
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("Simple").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("Simple").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId0,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3691,16 +3749,16 @@ TEST_P(QueryVisitorTest, HasPropertyFunctionReturnsMatchingDocuments) {
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   // Document 1 has the term "foo" and doesn't have the "price" property.
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("Simple").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("Simple").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId0,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   // Document 2 has the term "bar" and has the "price" property.
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri2").SetSchema("Simple").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri2").SetSchema("Simple").Build())));
   editor = index_->Edit(kDocumentId2, kSectionId0,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("bar", TERM_MATCH_PREFIX));
@@ -3747,8 +3805,8 @@ TEST_P(QueryVisitorTest,
       /*ignore_errors_and_delete_documents=*/false));
 
   // Document 0 has the term "foo" and has the "price" property.
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("Simple").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("Simple").Build())));
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId0,
                                       /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3758,8 +3816,8 @@ TEST_P(QueryVisitorTest,
   ICING_ASSERT_OK(editor.IndexAllBufferedTerms());
 
   // Document 1 has the term "foo" and doesn't have the "price" property.
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("Simple").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("Simple").Build())));
   editor = index_->Edit(kDocumentId1, kSectionId0,
                         /*namespace_id=*/0);
   ICING_ASSERT_OK(editor.BufferTerm("foo", TERM_MATCH_PREFIX));
@@ -3968,10 +4026,10 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
 
   // Index two embedding vectors.
   PropertyProto::VectorProto vector0 =
@@ -4007,22 +4065,19 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0),
-      Pointee(UnorderedElementsAre(DoubleNear(1, kEps))));
+      UnorderedElementsAre(DoubleNear(1, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 0.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
-            ->section_infos,
-        IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // The query should match both vector0 and vector1.
@@ -4039,17 +4094,18 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0),
-      Pointee(UnorderedElementsAre(DoubleNear(1, kEps))));
+      UnorderedElementsAre(DoubleNear(1, kEps)));
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1),
-      Pointee(UnorderedElementsAre(DoubleNear(-1, kEps))));
+      UnorderedElementsAre(DoubleNear(-1, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 0.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
 
@@ -4057,23 +4113,13 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleLowerBound) {
     match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
-            ->section_infos,
-        IsNull());
-
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1)
-            ->section_infos,
-        IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // The query should match nothing, since there is no vector with a
@@ -4107,10 +4153,10 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
 
   // Index two embedding vectors.
   PropertyProto::VectorProto vector0 =
@@ -4146,22 +4192,19 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1),
-      Pointee(UnorderedElementsAre(DoubleNear(-1, kEps))));
+      UnorderedElementsAre(DoubleNear(-1, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 1.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1)
-            ->section_infos,
-        IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // The query should match both vector0 and vector1.
@@ -4178,17 +4221,18 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0),
-      Pointee(UnorderedElementsAre(DoubleNear(1, kEps))));
+      UnorderedElementsAre(DoubleNear(1, kEps)));
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1),
-      Pointee(UnorderedElementsAre(DoubleNear(-1, kEps))));
+      UnorderedElementsAre(DoubleNear(-1, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 0.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
 
@@ -4196,23 +4240,14 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSimpleUpperBound) {
     match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
 
   } else {
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
-            ->section_infos,
-        IsNull());
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId1)
-            ->section_infos,
-        IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // The query should match nothing, since there is no vector with a
@@ -4246,8 +4281,8 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
 
   // Index a embedding vector.
   PropertyProto::VectorProto vector = CreateVector("my_model", {0.1, 0.2, 0.3});
@@ -4282,22 +4317,19 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0),
-      Pointee(UnorderedElementsAre(DoubleNear(1, kEps))));
+      UnorderedElementsAre(DoubleNear(1, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 0.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/1,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/1,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(
-        query_results.embedding_query_results
-            .GetMatchedInfosForDocument(
-                /*query_vector_index=*/0, EMBEDDING_METRIC_COSINE, kDocumentId0)
-            ->section_infos,
-        IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // Create a query that overrides the metric to DOT_PRODUCT.
@@ -4314,24 +4346,21 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(DoubleNear(0.14, kEps))));
+      UnorderedElementsAre(DoubleNear(0.14, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 0.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0.14,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/0.14,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
     // Check section match info for document 0.
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // Create a query that overrides the metric to EUCLIDEAN.
@@ -4349,22 +4378,19 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMetricOverride) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_EUCLIDEAN, kDocumentId0),
-      Pointee(UnorderedElementsAre(DoubleNear(0, kEps))));
+      UnorderedElementsAre(DoubleNear(0, kEps)));
   if (GetParam().get_embedding_match_info) {
     // Check section match info for document 0.
     const EmbeddingMatchInfos* match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_EUCLIDEAN, kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/0,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_EUCLIDEAN,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 }
 
@@ -4386,10 +4412,10 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionRepeatedProperty) {
                                         .SetCardinality(CARDINALITY_REPEATED)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
 
   // Index vectors for document 0.
   // Section 0
@@ -4486,11 +4512,11 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionRepeatedProperty) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(-3, 7)));
+      UnorderedElementsAre(-3, 7));
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(6)));
+      UnorderedElementsAre(6));
 
   // Check results for document 0.
   ICING_ASSERT_OK(itr->Advance());
@@ -4500,11 +4526,11 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionRepeatedProperty) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2, 0, -3, 6, 3)));
+      UnorderedElementsAre(-2, 0, -3, 6, 3));
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2)));
+      UnorderedElementsAre(-2));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
 
@@ -4523,26 +4549,32 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionRepeatedProperty) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-2,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-3,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-3,
                                        /*position_in_section=*/2,
                                        /*section_id=*/kSectionId0));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/6,
                                        /*position_in_section=*/1,
                                        /*section_id=*/kSectionId0));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/0,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId1));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/3,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/3,
                                        /*position_in_section=*/1,
                                        /*section_id=*/kSectionId1));
     match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-2,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
 
@@ -4557,44 +4589,25 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionRepeatedProperty) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-3,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-3,
                                        /*position_in_section=*/1,
                                        /*section_id=*/kSectionId0));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/7,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/7,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
     match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/6,
                                        /*position_in_section=*/1,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId1)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId1)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 }
 
@@ -4621,10 +4634,10 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
 
   // Index 3 embedding vectors for document 0.
   ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
@@ -4685,11 +4698,11 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2, 0)));
+      UnorderedElementsAre(-2, 0));
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(4)));
+      UnorderedElementsAre(4));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
   if (GetParam().get_embedding_match_info) {
@@ -4698,32 +4711,25 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-2,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/0,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId1));
     match_infos =
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/4,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/4,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId2));
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // The query can match both document 0 and document 1:
@@ -4756,11 +4762,11 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(6)));
+      UnorderedElementsAre(6));
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      IsNull());
+      IsEmpty());
   // Check results for document 0.
   ICING_ASSERT_OK(itr->Advance());
   EXPECT_THAT(
@@ -4769,11 +4775,11 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      IsNull());
+      IsEmpty());
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(4)));
+      UnorderedElementsAre(4));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
   if (GetParam().get_embedding_match_info) {
@@ -4787,7 +4793,8 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/4,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/4,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId2));
 
@@ -4796,7 +4803,8 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/6,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
     match_infos =
@@ -4805,18 +4813,8 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionMultipleQueries) {
             kDocumentId1);
     EXPECT_THAT(match_infos, IsNull());
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/1, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId1)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 }
 
@@ -4839,10 +4837,10 @@ TEST_P(QueryVisitorTest,
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
 
   // Index 3 embedding vectors for document 0.
   ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
@@ -4889,7 +4887,7 @@ TEST_P(QueryVisitorTest,
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(6)));
+      UnorderedElementsAre(6));
   // Check results for document 0.
   ICING_ASSERT_OK(itr->Advance());
   EXPECT_THAT(itr->doc_hit_info(),
@@ -4898,7 +4896,7 @@ TEST_P(QueryVisitorTest,
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2, 0)));
+      UnorderedElementsAre(-2, 0));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
   if (GetParam().get_embedding_match_info) {
@@ -4907,10 +4905,12 @@ TEST_P(QueryVisitorTest,
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-2,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/0,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/0,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId1));
     match_infos =
@@ -4924,7 +4924,8 @@ TEST_P(QueryVisitorTest,
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/6,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
     match_infos =
@@ -4933,18 +4934,8 @@ TEST_P(QueryVisitorTest,
             kDocumentId0);
     EXPECT_THAT(match_infos, IsNull());
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId1)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // The same query appears twice, in which case all the scores in the results
@@ -4968,7 +4959,7 @@ TEST_P(QueryVisitorTest,
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(6, 6)));
+      UnorderedElementsAre(6, 6));
   // Check results for document 0.
   ICING_ASSERT_OK(itr->Advance());
   EXPECT_THAT(itr->doc_hit_info(),
@@ -4977,7 +4968,7 @@ TEST_P(QueryVisitorTest,
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2, 0, -2, 0)));
+      UnorderedElementsAre(-2, 0, -2, 0));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
 }
@@ -5000,10 +4991,10 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
                                         .SetCardinality(CARDINALITY_OPTIONAL)))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
 
   // Index terms
   Index::Editor editor = index_->Edit(kDocumentId0, kSectionId1,
@@ -5057,7 +5048,7 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(6)));
+      UnorderedElementsAre(6));
   // Check results for document 0.
   ICING_ASSERT_OK(itr->Advance());
   EXPECT_THAT(
@@ -5066,7 +5057,7 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      IsNull());
+      IsEmpty());
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
   if (GetParam().get_embedding_match_info) {
@@ -5082,16 +5073,13 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/6,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId1)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 
   // Perform another hybrid search:
@@ -5118,7 +5106,7 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2)));
+      UnorderedElementsAre(-2));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
 
@@ -5128,7 +5116,8 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId0);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/-2,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/-2,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
 
@@ -5137,22 +5126,13 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionHybridQueries) {
         query_results.embedding_query_results.GetMatchedInfosForDocument(
             /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
             kDocumentId1);
-    EXPECT_TRUE(ContainsMatchInfoEntry(match_infos, /*score=*/6,
+    EXPECT_TRUE(ContainsMatchInfoEntry(query_results.embedding_query_results,
+                                       match_infos, /*score=*/6,
                                        /*position_in_section=*/0,
                                        /*section_id=*/kSectionId0));
   } else {
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId0)
-                    ->section_infos,
-                IsNull());
-    EXPECT_THAT(query_results.embedding_query_results
-                    .GetMatchedInfosForDocument(
-                        /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT,
-                        kDocumentId1)
-                    ->section_infos,
-                IsNull());
+    EXPECT_THAT(*query_results.embedding_query_results.global_section_infos,
+                IsEmpty());
   }
 }
 
@@ -5175,10 +5155,10 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
       /*ignore_errors_and_delete_documents=*/false));
 
   // Create two documents.
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build()));
-  ICING_ASSERT_OK(document_store_->Put(
-      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build()));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri0").SetSchema("type").Build())));
+  ICING_ASSERT_OK(document_store_->Put(document_util::CreateDocumentWrapper(
+      DocumentBuilder().SetKey("ns", "uri1").SetSchema("type").Build())));
   // Add embedding vectors into different sections for the two documents.
   ICING_ASSERT_OK(embedding_index_->BufferEmbedding(
       BasicHit(kSectionId0, kDocumentId0),
@@ -5223,7 +5203,7 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId1),
-      Pointee(UnorderedElementsAre(2)));
+      UnorderedElementsAre(2));
   ICING_ASSERT_OK(itr->Advance());
   EXPECT_THAT(
       itr->doc_hit_info(),
@@ -5231,7 +5211,7 @@ TEST_P(QueryVisitorTest, SemanticSearchFunctionSectionRestriction) {
   EXPECT_THAT(
       query_results.embedding_query_results.GetMatchedScoresForDocument(
           /*query_vector_index=*/0, EMBEDDING_METRIC_DOT_PRODUCT, kDocumentId0),
-      Pointee(UnorderedElementsAre(-2)));
+      UnorderedElementsAre(-2));
   EXPECT_THAT(itr->Advance(),
               StatusIs(libtextclassifier3::StatusCode::RESOURCE_EXHAUSTED));
 }
@@ -5258,16 +5238,18 @@ TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionSimpleLowerBound) {
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri0")
-                                           .SetSchema("Simple")
-                                           .SetScore(4)
-                                           .Build()));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("Simple")
-                                           .SetScore(0)
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("Simple")
+                                               .SetScore(4)
+                                               .Build())));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("Simple")
+                                               .SetScore(0)
+                                               .Build())));
 
   // Test that `matchScoreExpression("this.documentScore()", 0)` matches
   // all documents.
@@ -5309,16 +5291,18 @@ TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionSimpleUpperBound) {
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri0")
-                                           .SetSchema("Simple")
-                                           .SetScore(4)
-                                           .Build()));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("Simple")
-                                           .SetScore(0)
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("Simple")
+                                               .SetScore(4)
+                                               .Build())));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("Simple")
+                                               .SetScore(0)
+                                               .Build())));
 
   // Test that `matchScoreExpression("this.documentScore()", -100, 100)` matches
   // all documents.
@@ -5360,24 +5344,27 @@ TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionComplex) {
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri0")
-                                           .SetSchema("Simple")
-                                           .SetScore(4)
-                                           .SetCreationTimestampMs(1)
-                                           .Build()));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("Simple")
-                                           .SetScore(2)
-                                           .SetCreationTimestampMs(2)
-                                           .Build()));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri2")
-                                           .SetSchema("Simple")
-                                           .SetScore(0)
-                                           .SetCreationTimestampMs(3)
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("Simple")
+                                               .SetScore(4)
+                                               .SetCreationTimestampMs(1)
+                                               .Build())));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("Simple")
+                                               .SetScore(2)
+                                               .SetCreationTimestampMs(2)
+                                               .Build())));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri2")
+                                               .SetSchema("Simple")
+                                               .SetScore(0)
+                                               .SetCreationTimestampMs(3)
+                                               .Build())));
 
   // Query with a complex score expression:
   //   `pow(this.creationTimestamp(), 2) + this.documentScore() - 1`.
@@ -5404,16 +5391,18 @@ TEST_P(QueryVisitorTest, MatchScoreExpressionFunctionWithEvaluationErrors) {
           .AddType(SchemaTypeConfigBuilder().SetType("Simple"))
           .Build(),
       /*ignore_errors_and_delete_documents=*/false));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri0")
-                                           .SetSchema("Simple")
-                                           .SetScore(4)
-                                           .Build()));
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("ns", "uri1")
-                                           .SetSchema("Simple")
-                                           .SetScore(0)
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri0")
+                                               .SetSchema("Simple")
+                                               .SetScore(4)
+                                               .Build())));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("ns", "uri1")
+                                               .SetSchema("Simple")
+                                               .SetScore(0)
+                                               .Build())));
 
   // Test that documents with evaluation errors will be filtered out.
   // Specifically, document1 will be filtered out because its document score is
diff --git a/icing/query/query-processor_benchmark.cc b/icing/query/query-processor_benchmark.cc
index ad125c9..13e3a50 100644
--- a/icing/query/query-processor_benchmark.cc
+++ b/icing/query/query-processor_benchmark.cc
@@ -30,6 +30,7 @@
 #include "icing/index/index.h"
 #include "icing/index/numeric/dummy-numeric-index.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/proto/term.pb.h"
@@ -49,6 +50,7 @@
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/logging.h"
 #include "unicode/uloc.h"
@@ -119,6 +121,9 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
       PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+      PortableFileBackedProtoLog<
+          DocumentWrapper>::kDefaultCompressionThresholdBytes,
+      protobuf_ports::kDefaultMemLevel,
       /*initialize_stats=*/nullptr);
 }
 
@@ -181,10 +186,11 @@ void BM_QueryOneTerm(benchmark::State& state) {
                              &feature_flags));
 
   DocumentId document_id = document_store
-                               ->Put(DocumentBuilder()
-                                         .SetKey("icing", "type1")
-                                         .SetSchema("type1")
-                                         .Build())
+                               ->Put(document_util::CreateDocumentWrapper(
+                                   DocumentBuilder()
+                                       .SetKey("icing", "type1")
+                                       .SetSchema("type1")
+                                       .Build()))
                                .ValueOrDie()
                                .new_document_id;
 
@@ -320,10 +326,11 @@ void BM_QueryFiveTerms(benchmark::State& state) {
                              &feature_flags));
 
   DocumentId document_id = document_store
-                               ->Put(DocumentBuilder()
-                                         .SetKey("icing", "type1")
-                                         .SetSchema("type1")
-                                         .Build())
+                               ->Put(document_util::CreateDocumentWrapper(
+                                   DocumentBuilder()
+                                       .SetKey("icing", "type1")
+                                       .SetSchema("type1")
+                                       .Build()))
                                .ValueOrDie()
                                .new_document_id;
 
@@ -477,10 +484,11 @@ void BM_QueryDiacriticTerm(benchmark::State& state) {
                              &feature_flags));
 
   DocumentId document_id = document_store
-                               ->Put(DocumentBuilder()
-                                         .SetKey("icing", "type1")
-                                         .SetSchema("type1")
-                                         .Build())
+                               ->Put(document_util::CreateDocumentWrapper(
+                                   DocumentBuilder()
+                                       .SetKey("icing", "type1")
+                                       .SetSchema("type1")
+                                       .Build()))
                                .ValueOrDie()
                                .new_document_id;
 
@@ -619,10 +627,11 @@ void BM_QueryHiragana(benchmark::State& state) {
                              &feature_flags));
 
   DocumentId document_id = document_store
-                               ->Put(DocumentBuilder()
-                                         .SetKey("icing", "type1")
-                                         .SetSchema("type1")
-                                         .Build())
+                               ->Put(document_util::CreateDocumentWrapper(
+                                   DocumentBuilder()
+                                       .SetKey("icing", "type1")
+                                       .SetSchema("type1")
+                                       .Build()))
                                .ValueOrDie()
                                .new_document_id;
 
diff --git a/icing/query/query-processor_test.cc b/icing/query/query-processor_test.cc
index b5d1f0f..7f101a5 100644
--- a/icing/query/query-processor_test.cc
+++ b/icing/query/query-processor_test.cc
@@ -41,6 +41,7 @@
 #include "icing/index/numeric/numeric-index.h"
 #include "icing/jni/jni-cache.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/logging.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -65,6 +66,7 @@
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/status-macros.h"
 #include "unicode/uloc.h"
@@ -89,6 +91,9 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
       PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+      PortableFileBackedProtoLog<
+          DocumentWrapper>::kDefaultCompressionThresholdBytes,
+      protobuf_ports::kDefaultMemLevel,
       /*initialize_stats=*/nullptr);
 }
 
@@ -303,17 +308,21 @@ TEST_F(QueryProcessorTest, EmptyQueryMatchAllDocuments) {
                   schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // We don't need to insert anything in the index since the empty query will
@@ -347,11 +356,13 @@ TEST_F(QueryProcessorTest, QueryTermNormalized) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -408,11 +419,13 @@ TEST_F(QueryProcessorTest, OneTermPrefixMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -464,11 +477,13 @@ TEST_F(QueryProcessorTest, OneTermPrefixMatchWithMaxSectionID) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -522,11 +537,13 @@ TEST_F(QueryProcessorTest, OneTermExactMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -578,11 +595,13 @@ TEST_F(QueryProcessorTest, AndSameTermExactMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -636,11 +655,13 @@ TEST_F(QueryProcessorTest, AndTwoTermExactMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -697,11 +718,13 @@ TEST_F(QueryProcessorTest, AndSameTermPrefixMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -755,11 +778,13 @@ TEST_F(QueryProcessorTest, AndTwoTermPrefixMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -817,11 +842,13 @@ TEST_F(QueryProcessorTest, AndTwoTermPrefixAndExactMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -879,17 +906,21 @@ TEST_F(QueryProcessorTest, OrTwoTermExactMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -955,17 +986,21 @@ TEST_F(QueryProcessorTest, OrTwoTermPrefixMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1031,17 +1066,21 @@ TEST_F(QueryProcessorTest, OrTwoTermPrefixAndExactMatch) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1105,17 +1144,21 @@ TEST_F(QueryProcessorTest, CombinedAndOrTerms) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
   // Populate the index
   SectionId section_id = 0;
@@ -1280,17 +1323,21 @@ TEST_F(QueryProcessorTest, OneGroup) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1348,17 +1395,21 @@ TEST_F(QueryProcessorTest, TwoGroups) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1419,17 +1470,21 @@ TEST_F(QueryProcessorTest, ManyLevelNestedGrouping) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1487,17 +1542,21 @@ TEST_F(QueryProcessorTest, OneLevelNestedGrouping) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1557,17 +1616,21 @@ TEST_F(QueryProcessorTest, ExcludeTerm) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that they'll bump the
   // last_added_document_id, which will give us the proper exclusion results
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1613,17 +1676,21 @@ TEST_F(QueryProcessorTest, ExcludeNonexistentTerm) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that they'll bump the
   // last_added_document_id, which will give us the proper exclusion results
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
   // Populate the index
   SectionId section_id = 0;
@@ -1667,17 +1734,21 @@ TEST_F(QueryProcessorTest, ExcludeAnd) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that they'll bump the
   // last_added_document_id, which will give us the proper exclusion results
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1754,17 +1825,21 @@ TEST_F(QueryProcessorTest, ExcludeOr) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that they'll bump the
   // last_added_document_id, which will give us the proper exclusion results
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1844,17 +1919,21 @@ TEST_F(QueryProcessorTest, WithoutTermFrequency) {
   // These documents don't actually match to the tokens in the index. We're
   // just inserting the documents so that the DocHitInfoIterators will see
   // that the document exists and not filter out the DocumentId as deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -1945,17 +2024,21 @@ TEST_F(QueryProcessorTest, DeletedFilter) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
   EXPECT_THAT(document_store_->Delete("namespace", "1",
                                       fake_clock_.GetSystemTimeMilliseconds()),
@@ -2013,17 +2096,21 @@ TEST_F(QueryProcessorTest, NamespaceFilter) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace2", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace2", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -2081,17 +2168,21 @@ TEST_F(QueryProcessorTest, SchemaTypeFilter) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Populate the index
@@ -2150,11 +2241,13 @@ TEST_F(QueryProcessorTest, PropertyFilterForOneDocument) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -2223,17 +2316,21 @@ TEST_F(QueryProcessorTest, PropertyFilterAcrossSchemaTypes) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId message_document_id = put_result2.new_document_id;
 
   // Populate the index
@@ -2298,17 +2395,21 @@ TEST_F(QueryProcessorTest, PropertyFilterWithinSchemaType) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId message_document_id = put_result2.new_document_id;
 
   // Populate the index
@@ -2391,11 +2492,13 @@ TEST_F(QueryProcessorTest, NestedPropertyFilter) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
 
   // Populate the index
@@ -2456,17 +2559,21 @@ TEST_F(QueryProcessorTest, PropertyFilterRespectsDifferentSectionIds) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId message_document_id = put_result2.new_document_id;
 
   // Populate the index
@@ -2521,11 +2628,13 @@ TEST_F(QueryProcessorTest, NonexistentPropertyFilterReturnsEmptyResults) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
 
   // Populate the index
@@ -2579,11 +2688,13 @@ TEST_F(QueryProcessorTest, UnindexedPropertyFilterReturnsEmptyResults) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
 
   // Populate the index
@@ -2640,17 +2751,21 @@ TEST_F(QueryProcessorTest, PropertyFilterTermAndUnrestrictedTerm) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId message_document_id = put_result2.new_document_id;
 
   // Poplate the index
@@ -2750,17 +2865,21 @@ TEST_F(QueryProcessorTest, TypePropertyFilter) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId message_document_id = put_result2.new_document_id;
 
   // Poplate the index
@@ -2881,17 +3000,21 @@ TEST_F(QueryProcessorTest, TypePropertyFilterWithSectionRestrict) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // schema types populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId email_document_id = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("message")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("message")
+                                                   .Build())));
   DocumentId message_document_id = put_result2.new_document_id;
 
   // Poplate the index
@@ -2979,12 +3102,13 @@ TEST_F(QueryProcessorTest, DocumentBeforeTtlNotFilteredOut) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "1")
-                               .SetSchema("email")
-                               .SetCreationTimestampMs(10)
-                               .SetTtlMs(100)
-                               .Build()));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .SetCreationTimestampMs(10)
+                                                   .SetTtlMs(100)
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -3044,12 +3168,13 @@ TEST_F(QueryProcessorTest, DocumentPastTtlFilteredOut) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "1")
-                               .SetSchema("email")
-                               .SetCreationTimestampMs(50)
-                               .SetTtlMs(100)
-                               .Build()));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .SetCreationTimestampMs(50)
+                                                   .SetTtlMs(100)
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -3107,33 +3232,36 @@ TEST_F(QueryProcessorTest, NumericFilter) {
               IsOk());
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "1")
-                               .SetSchema("transaction")
-                               .AddInt64Property("price", 10)
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "1")
+              .SetSchema("transaction")
+              .AddInt64Property("price", 10)
+              .Build())));
   DocumentId document_one_id = put_result1.new_document_id;
   ICING_ASSERT_OK(
       AddToNumericIndex(document_one_id, "price", price_section_id, 10));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "2")
-                               .SetSchema("transaction")
-                               .AddInt64Property("price", 25)
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "2")
+              .SetSchema("transaction")
+              .AddInt64Property("price", 25)
+              .Build())));
   DocumentId document_two_id = put_result2.new_document_id;
   ICING_ASSERT_OK(
       AddToNumericIndex(document_two_id, "price", price_section_id, 25));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "3")
-                               .SetSchema("transaction")
-                               .AddInt64Property("cost", 2)
-                               .Build()));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "3")
+                                                   .SetSchema("transaction")
+                                                   .AddInt64Property("cost", 2)
+                                                   .Build())));
   DocumentId document_three_id = put_result3.new_document_id;
   ICING_ASSERT_OK(
       AddToNumericIndex(document_three_id, "cost", cost_section_id, 2));
@@ -3212,11 +3340,12 @@ TEST_F(QueryProcessorTest, NumericFilterWithoutEnablingFeatureFails) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(DocumentBuilder()
-                               .SetKey("namespace", "1")
-                               .SetSchema("transaction")
-                               .AddInt64Property("price", 10)
-                               .Build()));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          DocumentBuilder()
+              .SetKey("namespace", "1")
+              .SetSchema("transaction")
+              .AddInt64Property("price", 10)
+              .Build())));
   DocumentId document_one_id = put_result1.new_document_id;
   ICING_ASSERT_OK(
       AddToNumericIndex(document_one_id, "price", price_section_id, 10));
@@ -3268,11 +3397,13 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
   //   Doc2:
   //     prop1: "foo bar"
   //     prop2: ""
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "0")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "0")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id0 = put_result0.new_document_id;
   EXPECT_THAT(
       AddTokenToIndex(document_id0, prop1_section_id, term_match_type, "foo"),
@@ -3281,11 +3412,13 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
       AddTokenToIndex(document_id0, prop2_section_id, term_match_type, "bar"),
       IsOk());
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id1 = put_result1.new_document_id;
   EXPECT_THAT(
       AddTokenToIndex(document_id1, prop1_section_id, term_match_type, "bar"),
@@ -3294,11 +3427,13 @@ TEST_F(QueryProcessorTest, GroupingInSectionRestriction) {
       AddTokenToIndex(document_id1, prop2_section_id, term_match_type, "foo"),
       IsOk());
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id2 = put_result2.new_document_id;
   EXPECT_THAT(
       AddTokenToIndex(document_id2, prop1_section_id, term_match_type, "foo"),
@@ -3387,11 +3522,13 @@ TEST_F(QueryProcessorTest, ParseAdvancedQueryShouldSetSearchStats) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId document_id = put_result.new_document_id;
 
   // Populate the index
@@ -3436,10 +3573,11 @@ TEST_F(QueryProcessorTest, UriFiltersIsNotTheRightMostNode) {
   ASSERT_THAT(schema_store_->SetSchema(
                   schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
-  ICING_ASSERT_OK(document_store_->Put(DocumentBuilder()
-                                           .SetKey("namespace", "uri1")
-                                           .SetSchema("email")
-                                           .Build()));
+  ICING_ASSERT_OK(document_store_->Put(
+      document_util::CreateDocumentWrapper(DocumentBuilder()
+                                               .SetKey("namespace", "uri1")
+                                               .SetSchema("email")
+                                               .Build())));
 
   SearchSpecProto search_spec;
   search_spec.set_term_match_type(TermMatchType::PREFIX);
diff --git a/icing/query/suggestion-processor_test.cc b/icing/query/suggestion-processor_test.cc
index 567eeae..a6d7b67 100644
--- a/icing/query/suggestion-processor_test.cc
+++ b/icing/query/suggestion-processor_test.cc
@@ -35,6 +35,7 @@
 #include "icing/index/term-metadata.h"
 #include "icing/jni/jni-cache.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/query/query-features.h"
 #include "icing/schema-builder.h"
@@ -50,9 +51,10 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
-#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer-factory.h"
+#include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -110,14 +112,18 @@ class SuggestionProcessorTest : public Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     Index::Options options(index_dir_,
@@ -208,17 +214,21 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_And) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId1 = put_result1.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -256,17 +266,21 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_AndNary) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId1 = put_result1.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -308,17 +322,21 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_Or) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId1 = put_result1.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -362,23 +380,29 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_OrNary) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "3")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "3")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId2 = put_result2.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -430,17 +454,21 @@ TEST_F(SuggestionProcessorTest, MultipleTermsTest_NormalizedTerm) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "2")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "2")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId1 = put_result1.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -493,11 +521,13 @@ TEST_F(SuggestionProcessorTest, NonExistentPrefixTest) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -529,11 +559,13 @@ TEST_F(SuggestionProcessorTest, PrefixTrailingSpaceTest) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -566,11 +598,13 @@ TEST_F(SuggestionProcessorTest, NormalizePrefixTest) {
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
                               TermMatchType::EXACT_ONLY, "foo"),
@@ -619,11 +653,13 @@ TEST_F(SuggestionProcessorTest, ParenthesesOperatorPrefixTest) {
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
                               TermMatchType::EXACT_ONLY, "foo"),
@@ -666,11 +702,13 @@ TEST_F(SuggestionProcessorTest, OtherSpecialPrefixTest) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -729,11 +767,13 @@ TEST_F(SuggestionProcessorTest, SemanticSearchPrefixTest) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
@@ -778,11 +818,13 @@ TEST_F(SuggestionProcessorTest, InvalidPrefixTest) {
   // These documents don't actually match to the tokens in the index. We're
   // inserting the documents to get the appropriate number of documents and
   // namespaces populated.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result0,
-                             document_store_->Put(DocumentBuilder()
-                                                      .SetKey("namespace1", "1")
-                                                      .SetSchema("email")
-                                                      .Build()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result0,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(DocumentBuilder()
+                                                   .SetKey("namespace1", "1")
+                                                   .SetSchema("email")
+                                                   .Build())));
   DocumentId documentId0 = put_result0.new_document_id;
 
   ASSERT_THAT(AddTokenToIndex(documentId0, kSectionId2,
diff --git a/icing/result/result-adjustment-info.cc b/icing/result/result-adjustment-info.cc
index 6ae911c..82ffb0b 100644
--- a/icing/result/result-adjustment-info.cc
+++ b/icing/result/result-adjustment-info.cc
@@ -29,7 +29,9 @@
 #include "icing/result/snippet-context.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
+#include "icing/scoring/advanced_scoring/double-list.h"
 #include "icing/store/document-id.h"
+#include "icing/util/embedding-util.h"
 #include "icing/util/logging.h"
 
 namespace icing {
@@ -47,45 +49,57 @@ SnippetContext::DocumentEmbeddingMatchInfoMap GetMatchInfoByDocumentAndSection(
     const std::unordered_set<DocumentId>& documents_to_include,
     int num_matches_per_property) {
   SnippetContext::DocumentEmbeddingMatchInfoMap result_map;
+  if (embedding_query_results.global_section_infos->empty()) {
+    // No section info indicates that embedding match info is not
+    // enabled.
+    return result_map;
+  }
+  if (embedding_query_results.global_section_infos->size() !=
+      embedding_query_results.global_scores->size()) {
+    // This should never happen.
+    ICING_LOG(ERROR) << "EmbeddingMatchInfos has mismatched section_infos and "
+                        "scores vectors. Global section_infos size: "
+                     << embedding_query_results.global_section_infos->size()
+                     << ", Global scores size: "
+                     << embedding_query_results.global_scores->size();
+    return result_map;
+  }
+
   // Maps from (document_id, section_id) to the match count for that section.
   std::unordered_map<DocumentId, std::unordered_map<SectionId, int>>
       section_match_count;
 
-  for (const auto& [query_vector_index, metric_type_map] :
-       embedding_query_results.result_infos) {
-    for (const auto& [metric_type, info_map] : metric_type_map) {
-      for (const auto& [doc_id, match_infos] : info_map) {
+  for (int query_vector_index = 0;
+       query_vector_index < embedding_query_results.GetNumQueryVectors();
+       ++query_vector_index) {
+    for (SearchSpecProto::EmbeddingQueryMetricType::Code metric_type :
+         embedding_util::kEmbeddingQueryMetricTypes) {
+      const EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map =
+          embedding_query_results.GetMatchInfoMap(query_vector_index,
+                                                  metric_type);
+      if (info_map == nullptr) {
+        continue;
+      }
+      for (const auto& [doc_id, match_infos] : *info_map) {
         if (documents_to_include.find(doc_id) == documents_to_include.end()) {
           continue;
         }
 
-        if (match_infos.section_infos == nullptr) {
-          // No section info indicates that embedding match info is not
-          // enabled.
-          continue;
-        }
-
-        if (match_infos.section_infos->size() != match_infos.scores.size()) {
-          // This should never happen.
-          ICING_LOG(ERROR)
-              << "EmbeddingMatchInfos has mismatched section_infos and "
-                 "scores vectors for document with id "
-              << doc_id
-              << ". Section_infos size: " << match_infos.section_infos->size()
-              << ", scores size: " << match_infos.scores.size();
-          continue;
-        }
-        for (int i = 0; i < match_infos.scores.size(); ++i) {
-          SectionId section_id = match_infos.section_infos->at(i).section_id;
-          if (section_match_count[doc_id][section_id] >=
+        DoubleList scores =
+            embedding_query_results.GetMatchedScoresFromEmbeddingMatchInfos(
+                match_infos);
+        for (int i = 0; i < scores.size(); ++i) {
+          const EmbeddingMatchInfos::EmbeddingMatchSectionInfo& section_info =
+              embedding_query_results.global_section_infos->at(
+                  i + match_infos.score_start_index);
+          if (section_match_count[doc_id][section_info.section_id] >=
               num_matches_per_property) {
             continue;
           }
           result_map[doc_id].push_back(SnippetContext::EmbeddingMatchInfoEntry(
-              match_infos.scores[i], metric_type,
-              match_infos.section_infos->at(i).position, query_vector_index,
-              section_id));
-          ++section_match_count[doc_id][section_id];
+              scores.data()[i], metric_type, section_info.position,
+              query_vector_index, section_info.section_id));
+          ++section_match_count[doc_id][section_info.section_id];
         }
       }
     }
diff --git a/icing/result/result-adjustment-info_test.cc b/icing/result/result-adjustment-info_test.cc
index d539016..0c0c841 100644
--- a/icing/result/result-adjustment-info_test.cc
+++ b/icing/result/result-adjustment-info_test.cc
@@ -147,49 +147,67 @@ TEST_F(ResultAdjustmentInfoTest,
       CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
                        EMBEDDING_METRIC_DOT_PRODUCT);
 
-  EmbeddingQueryResults embedding_query_results;
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
   EmbeddingMatchInfos& info_query0_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/0]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query0_doc0.AppendScore(1);
-  info_query0_doc0.AppendScore(1.7);
-  info_query0_doc0.AppendScore(3.3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/0,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/3);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 3.3);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/1);
   EmbeddingMatchInfos& info_query1_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query1_doc0.AppendScore(2);
-  info_query1_doc0.AppendScore(1.7);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 2);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/3,
+      /*position=*/2);
   EmbeddingMatchInfos& info_query1_doc1 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId1];
-  info_query1_doc1.AppendScore(6.66);
-  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+          kDocumentId1);
+  info_query1_doc1.AppendScore(*embedding_query_results.global_scores, 6.66);
+  info_query1_doc1.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/0);
   EmbeddingMatchInfos& info_query0_doc2 =
-      embedding_query_results
-          .result_infos[/*query_index=*/0][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId2];
-  info_query0_doc2.AppendScore(5.25);
-  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
-  info_query0_doc2.AppendScore(1.33);
-  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/4);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/0, EMBEDDING_METRIC_COSINE,
+          kDocumentId2);
+  info_query0_doc2.AppendScore(*embedding_query_results.global_scores, 5.25);
+  info_query0_doc2.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/0);
+  info_query0_doc2.AppendScore(*embedding_query_results.global_scores, 1.33);
+  info_query0_doc2.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/4);
   EmbeddingMatchInfos& info_query1_doc3 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId3];
-  info_query1_doc3.AppendScore(3.25);
-  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
-  info_query1_doc3.AppendScore(2.33);
-  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/2);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+          kDocumentId3);
+  info_query1_doc3.AppendScore(*embedding_query_results.global_scores, 3.25);
+  info_query1_doc3.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/1);
+  info_query1_doc3.AppendScore(*embedding_query_results.global_scores, 2.33);
+  info_query1_doc3.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/2);
 
   ResultAdjustmentInfo result_adjustment_info(
       search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
@@ -309,49 +327,67 @@ TEST_F(
       CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
                        EMBEDDING_METRIC_DOT_PRODUCT);
 
-  EmbeddingQueryResults embedding_query_results;
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
   EmbeddingMatchInfos& info_query0_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/0]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query0_doc0.AppendScore(1);
-  info_query0_doc0.AppendScore(1.7);
-  info_query0_doc0.AppendScore(3.3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/0,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/3);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 3.3);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/1);
   EmbeddingMatchInfos& info_query1_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query1_doc0.AppendScore(2);
-  info_query1_doc0.AppendScore(1.7);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 2);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/3,
+      /*position=*/2);
   EmbeddingMatchInfos& info_query1_doc1 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId1];
-  info_query1_doc1.AppendScore(6.66);
-  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+          kDocumentId1);
+  info_query1_doc1.AppendScore(*embedding_query_results.global_scores, 6.66);
+  info_query1_doc1.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/0);
   EmbeddingMatchInfos& info_query0_doc2 =
-      embedding_query_results
-          .result_infos[/*query_index=*/0][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId2];
-  info_query0_doc2.AppendScore(5.25);
-  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
-  info_query0_doc2.AppendScore(1.33);
-  info_query0_doc2.AppendSectionInfo(/*section_id=*/1, /*position=*/4);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/0, EMBEDDING_METRIC_COSINE,
+          kDocumentId2);
+  info_query0_doc2.AppendScore(*embedding_query_results.global_scores, 5.25);
+  info_query0_doc2.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/0);
+  info_query0_doc2.AppendScore(*embedding_query_results.global_scores, 1.33);
+  info_query0_doc2.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/4);
   EmbeddingMatchInfos& info_query1_doc3 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId3];
-  info_query1_doc3.AppendScore(3.25);
-  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
-  info_query1_doc3.AppendScore(2.33);
-  info_query1_doc3.AppendSectionInfo(/*section_id=*/1, /*position=*/2);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+          kDocumentId3);
+  info_query1_doc3.AppendScore(*embedding_query_results.global_scores, 3.25);
+  info_query1_doc3.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/1);
+  info_query1_doc3.AppendScore(*embedding_query_results.global_scores, 2.33);
+  info_query1_doc3.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/2);
 
   ResultAdjustmentInfo result_adjustment_info(
       search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
@@ -383,8 +419,8 @@ TEST_F(
                                     /*section_id=*/0)),
                             EqualsEmbeddingMatchInfoEntry(
                                 SnippetContext::EmbeddingMatchInfoEntry(
-                                    /*score=*/2, EMBEDDING_METRIC_DOT_PRODUCT,
-                                    /*position=*/0, /*query_vector_index=*/1,
+                                    /*score=*/1.7, EMBEDDING_METRIC_DOT_PRODUCT,
+                                    /*position=*/3, /*query_vector_index=*/0,
                                     /*section_id=*/0)),
                             EqualsEmbeddingMatchInfoEntry(
                                 SnippetContext::EmbeddingMatchInfoEntry(
@@ -422,33 +458,43 @@ TEST_F(
   SearchSpecProto search_spec =
       CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
                        EMBEDDING_METRIC_DOT_PRODUCT);
-  EmbeddingQueryResults embedding_query_results;
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
   EmbeddingMatchInfos& info_query0_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/0]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query0_doc0.AppendScore(1);
-  info_query0_doc0.AppendScore(1.7);
-  info_query0_doc0.AppendScore(3.3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/0,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/3);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 3.3);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/1);
   EmbeddingMatchInfos& info_query1_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query1_doc0.AppendScore(2);
-  info_query1_doc0.AppendScore(1.7);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 2);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/3,
+      /*position=*/2);
   EmbeddingMatchInfos& info_query1_doc1 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId1];
-  info_query1_doc1.AppendScore(6.66);
-  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+          kDocumentId1);
+  info_query1_doc1.AppendScore(*embedding_query_results.global_scores, 6.66);
+  info_query1_doc1.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/0);
 
   ResultAdjustmentInfo result_adjustment_info(
       search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
@@ -526,33 +572,43 @@ TEST_F(ResultAdjustmentInfoTest, NoSnippetingShouldReturnNull) {
   SearchSpecProto search_spec =
       CreateSearchSpec(TermMatchType::EXACT_ONLY, embedding_query_vectors,
                        SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT);
-  EmbeddingQueryResults embedding_query_results;
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
   EmbeddingMatchInfos& info_query0_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/0]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query0_doc0.AppendScore(1);
-  info_query0_doc0.AppendScore(1.7);
-  info_query0_doc0.AppendScore(3.3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/3);
-  info_query0_doc0.AppendSectionInfo(/*section_id=*/1, /*position=*/1);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/0,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/3);
+  info_query0_doc0.AppendScore(*embedding_query_results.global_scores, 3.3);
+  info_query0_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/1);
   EmbeddingMatchInfos& info_query1_doc0 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1]
-                       [search_spec.embedding_query_metric_type()]
-                       [kDocumentId0];
-  info_query1_doc0.AppendScore(2);
-  info_query1_doc0.AppendScore(1.7);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/0, /*position=*/0);
-  info_query1_doc0.AppendSectionInfo(/*section_id=*/3, /*position=*/2);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1,
+          search_spec.embedding_query_metric_type(), kDocumentId0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 2);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/0,
+      /*position=*/0);
+  info_query1_doc0.AppendScore(*embedding_query_results.global_scores, 1.7);
+  info_query1_doc0.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/3,
+      /*position=*/2);
   EmbeddingMatchInfos& info_query1_doc1 =
-      embedding_query_results
-          .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE]
-                       [kDocumentId1];
-  info_query1_doc1.AppendScore(6.66);
-  info_query1_doc1.AppendSectionInfo(/*section_id=*/1, /*position=*/0);
+      GetOrCreateEmbeddingMatchInfosForDocument(
+          embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+          kDocumentId1);
+  info_query1_doc1.AppendScore(*embedding_query_results.global_scores, 6.66);
+  info_query1_doc1.AppendSectionInfo(
+      *embedding_query_results.global_section_infos, /*section_id=*/1,
+      /*position=*/0);
 
   ResultAdjustmentInfo result_adjustment_info(
       search_spec, CreateScoringSpec(/*is_descending_order=*/true), result_spec,
diff --git a/icing/result/result-retriever-v2.cc b/icing/result/result-retriever-v2.cc
index 4d221f3..3d5104b 100644
--- a/icing/result/result-retriever-v2.cc
+++ b/icing/result/result-retriever-v2.cc
@@ -14,9 +14,11 @@
 
 #include "icing/result/result-retriever-v2.h"
 
+#include <algorithm>
 #include <cstddef>
 #include <cstdint>
 #include <memory>
+#include <optional>
 #include <string>
 #include <unordered_map>
 #include <utility>
@@ -24,6 +26,7 @@
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/mutex.h"
+#include "icing/feature-flags.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/result/page-result.h"
@@ -97,52 +100,55 @@ bool ApplySnippet(ResultAdjustmentInfo* adjustment_info,
 
 }  // namespace
 
-bool GroupResultLimiterV2::ShouldBeRemoved(
+std::optional<int> GroupResultLimiterV2::GetGroupResultLimitsIndex(
     const ScoredDocumentHit& scored_document_hit,
     const std::unordered_map<int32_t, int>& entry_id_group_id_map,
-    const DocumentStore& document_store, std::vector<int>& group_result_limits,
+    const DocumentStore& document_store,
     ResultSpecProto::ResultGroupingType result_group_type,
     int64_t current_time_ms) const {
+  if (result_group_type == ResultSpecProto::ResultGroupingType::
+                               ResultSpecProto_ResultGroupingType_NONE) {
+    // No limit. Return -1 to skip the group result limit.
+    return -1;
+  }
+
   auto document_filter_data_optional =
       document_store.GetAliveDocumentFilterData(
           scored_document_hit.document_id(), current_time_ms);
   if (!document_filter_data_optional) {
-    // The document doesn't exist.
-    return true;
+    // The document doesn't exist. Return std::nullopt to exclude the document.
+    return std::nullopt;
   }
-  NamespaceId namespace_id =
-      document_filter_data_optional.value().namespace_id();
-  SchemaTypeId schema_type_id =
-      document_filter_data_optional.value().schema_type_id();
-  auto entry_id_or = document_store.GetResultGroupingEntryId(
+  NamespaceId namespace_id = document_filter_data_optional->namespace_id();
+  SchemaTypeId schema_type_id = document_filter_data_optional->schema_type_id();
+
+  std::optional<int32_t> entry_id = document_store.GetResultGroupingEntryId(
       result_group_type, namespace_id, schema_type_id);
-  if (!entry_id_or.ok()) {
-    return false;
+  if (!entry_id.has_value()) {
+    // No limit. Return -1 to skip the group result limit.
+    return -1;
   }
-  int32_t entry_id = entry_id_or.ValueOrDie();
-  auto iter = entry_id_group_id_map.find(entry_id);
+
+  auto iter = entry_id_group_id_map.find(*entry_id);
   if (iter == entry_id_group_id_map.end()) {
     // If a ResultGrouping Entry Id isn't found in entry_id_group_id_map, then
     // there are no limits placed on results from this entry id.
-    return false;
-  }
-  int& count = group_result_limits.at(iter->second);
-  if (count <= 0) {
-    return true;
+    return -1;
   }
-  --count;
-  return false;
+  return iter->second;
 }
 
 libtextclassifier3::StatusOr<std::unique_ptr<ResultRetrieverV2>>
 ResultRetrieverV2::Create(
     const DocumentStore* doc_store, const SchemaStore* schema_store,
     const LanguageSegmenter* language_segmenter, const Normalizer* normalizer,
+    const FeatureFlags* feature_flags,
     std::unique_ptr<const GroupResultLimiterV2> group_result_limiter) {
   ICING_RETURN_ERROR_IF_NULL(doc_store);
   ICING_RETURN_ERROR_IF_NULL(schema_store);
   ICING_RETURN_ERROR_IF_NULL(language_segmenter);
   ICING_RETURN_ERROR_IF_NULL(normalizer);
+  ICING_RETURN_ERROR_IF_NULL(feature_flags);
   ICING_RETURN_ERROR_IF_NULL(group_result_limiter);
 
   ICING_ASSIGN_OR_RETURN(
@@ -151,11 +157,12 @@ ResultRetrieverV2::Create(
 
   return std::unique_ptr<ResultRetrieverV2>(
       new ResultRetrieverV2(doc_store, std::move(snippet_retriever),
-                            std::move(group_result_limiter)));
+                            std::move(group_result_limiter), feature_flags));
 }
 
 std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
-    ResultStateV2& result_state, int64_t current_time_ms) const {
+    ResultStateV2& result_state, int32_t max_results,
+    int64_t current_time_ms) const {
   absl_ports::unique_lock l(&result_state.mutex);
 
   // For calculating page
@@ -166,103 +173,49 @@ std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
   // Retrieve info
   std::vector<SearchResultProto::ResultProto> results;
   int32_t num_total_bytes = 0;
-  while (results.size() < result_state.num_per_page() &&
+  int desired_page_size = std::min(result_state.num_per_page(), max_results);
+  while (num_total_bytes < result_state.num_total_bytes_per_page_threshold() &&
+         results.size() < desired_page_size &&
          !result_state.scored_document_hits_ranker->empty()) {
-    JoinedScoredDocumentHit next_best_document_hit =
-        result_state.scored_document_hits_ranker->PopNext();
-    if (group_result_limiter_->ShouldBeRemoved(
-            next_best_document_hit.parent_scored_document_hit(),
-            result_state.entry_id_group_id_map(), doc_store_,
-            result_state.group_result_limits, result_state.result_group_type(),
-            current_time_ms)) {
-      continue;
-    }
-
-    DocumentId doc_id =
-        next_best_document_hit.parent_scored_document_hit().document_id();
-    libtextclassifier3::StatusOr<DocumentProto> document_or =
-        doc_store_.Get(doc_id);
-    if (!document_or.ok()) {
-      // Skip the document if getting errors.
-      ICING_LOG(WARNING) << "Fail to fetch document from document store: "
-                         << document_or.status().error_message();
-      continue;
-    }
-
-    DocumentProto document = std::move(document_or).ValueOrDie();
-    // Apply parent projection
-    ApplyProjection(result_state.parent_adjustment_info(), &document);
-
-    SearchResultProto::ResultProto result;
-    // Add parent snippet if requested.
-    if (ApplySnippet(result_state.parent_adjustment_info(), *snippet_retriever_,
-                     document, doc_id,
-                     next_best_document_hit.parent_scored_document_hit()
-                         .hit_section_id_mask(),
-                     &result)) {
-      ++num_results_with_snippets;
-    }
-
-    // Add the document, itself.
-    *result.mutable_document() = std::move(document);
-    result.set_score(next_best_document_hit.final_score());
-    const auto* parent_additional_scores =
-        next_best_document_hit.parent_scored_document_hit().additional_scores();
-    if (parent_additional_scores != nullptr) {
-      result.mutable_additional_scores()->Add(parent_additional_scores->begin(),
-                                              parent_additional_scores->end());
-    }
+    RetrieveResult result = Retrieve(result_state, current_time_ms);
+    if (result.result_proto.has_value()) {
+      if (result.has_parent_snippets) {
+        ++num_results_with_snippets;
+      }
 
-    // Retrieve child documents
-    for (const ScoredDocumentHit& child_scored_document_hit :
-         next_best_document_hit.child_scored_document_hits()) {
-      if (result.joined_results_size() >=
-          result_state.max_joined_children_per_parent_to_return()) {
+      // Apply byte size threshold enforcement only if it is not the first
+      // document. This ensures that at least one document is returned,
+      // otherwise it will get stuck forever since nothing is popped from the
+      // ranker.
+      //
+      // (Use subtraction to avoid integer overflow).
+      size_t result_bytes = result.result_proto->ByteSizeLong();
+      if (feature_flags_.enable_strict_page_byte_size_limit() &&
+          !results.empty() &&
+          result_bytes >= result_state.num_total_bytes_per_page_threshold() -
+                              num_total_bytes) {
+        // Exceeds the byte size threshold, so skip the current document. Also
+        // it remains in the ranker and will be included in the next page.
+        ICING_LOG(INFO) << "Skipping document due to byte size threshold. "
+                           "Current num docs: "
+                        << results.size()
+                        << ", total byte size: " << num_total_bytes
+                        << ", next doc byte size: " << result_bytes
+                        << ", threshold: "
+                        << result_state.num_total_bytes_per_page_threshold();
         break;
       }
 
-      DocumentId child_doc_id = child_scored_document_hit.document_id();
-      libtextclassifier3::StatusOr<DocumentProto> child_document_or =
-          doc_store_.Get(child_doc_id);
-      if (!child_document_or.ok()) {
-        // Skip the document if getting errors.
-        ICING_LOG(WARNING)
-            << "Fail to fetch child document from document store: "
-            << child_document_or.status().error_message();
-        continue;
-      }
+      results.push_back(std::move(*result.result_proto));
+      num_total_bytes += result_bytes;
 
-      DocumentProto child_document = std::move(child_document_or).ValueOrDie();
-      ApplyProjection(result_state.child_adjustment_info(), &child_document);
-
-      SearchResultProto::ResultProto* child_result =
-          result.add_joined_results();
-      // Add child snippet if requested.
-      ApplySnippet(result_state.child_adjustment_info(), *snippet_retriever_,
-                   child_document, child_doc_id,
-                   child_scored_document_hit.hit_section_id_mask(),
-                   child_result);
-
-      *child_result->mutable_document() = std::move(child_document);
-      child_result->set_score(child_scored_document_hit.score());
-      if (child_scored_document_hit.additional_scores() != nullptr) {
-        child_result->mutable_additional_scores()->Add(
-            child_scored_document_hit.additional_scores()->begin(),
-            child_scored_document_hit.additional_scores()->end());
+      // Decrement the counter of the group result limit in ResultState.
+      if (result.group_result_limits_index != -1) {
+        --result_state.group_result_limits[result.group_result_limits_index];
       }
     }
 
-    size_t result_bytes = result.ByteSizeLong();
-    results.push_back(std::move(result));
-
-    // Check if num_total_bytes + result_bytes reaches or exceeds
-    // num_total_bytes_per_page_threshold. Use subtraction to avoid integer
-    // overflow.
-    if (result_bytes >=
-        result_state.num_total_bytes_per_page_threshold() - num_total_bytes) {
-      break;
-    }
-    num_total_bytes += result_bytes;
+    result_state.scored_document_hits_ranker->Pop();
   }
 
   // Update numbers in ResultState
@@ -279,5 +232,113 @@ std::pair<PageResult, bool> ResultRetrieverV2::RetrieveNextPage(
       has_more_results);
 }
 
+ResultRetrieverV2::RetrieveResult ResultRetrieverV2::Retrieve(
+    ResultStateV2& result_state, int64_t current_time_ms) const {
+  const JoinedScoredDocumentHit& next_best_document_hit =
+      result_state.scored_document_hits_ranker->Top();
+
+  // Get the index of the group result limits for the given scored document hit,
+  // and check if the document should be excluded.
+  std::optional<int> idx = group_result_limiter_->GetGroupResultLimitsIndex(
+      next_best_document_hit.parent_scored_document_hit(),
+      result_state.entry_id_group_id_map(), doc_store_,
+      result_state.result_group_type(), current_time_ms);
+  if (!idx.has_value()) {
+    // Should exclude the document, so return an invalid result.
+    return {.result_proto = std::nullopt,
+            .group_result_limits_index = -1,
+            .has_parent_snippets = false};
+  }
+
+  if (*idx == -1) {
+    // No limit for the result document. Pass.
+  } else if (*idx < 0 || *idx >= result_state.group_result_limits.size()) {
+    // This should not happen. But let's check it anyway and log. Also set the
+    // index to -1 indicating that there is no limit.
+    ICING_LOG(WARNING) << "Get an invalid group result limits index: " << *idx;
+    *idx = -1;
+  } else if (result_state.group_result_limits[*idx] <= 0) {
+    // Should exclude the document since the group has no budget left, so
+    // return an invalid result.
+    return {.result_proto = std::nullopt,
+            .group_result_limits_index = -1,
+            .has_parent_snippets = false};
+  }
+
+  DocumentId doc_id =
+      next_best_document_hit.parent_scored_document_hit().document_id();
+  auto document_or = doc_store_.Get(doc_id);
+  if (!document_or.ok()) {
+    // Exclude the document if getting errors.
+    ICING_LOG(WARNING) << "Fail to fetch document from document store: "
+                       << document_or.status().error_message();
+    return {.result_proto = std::nullopt,
+            .group_result_limits_index = -1,
+            .has_parent_snippets = false};
+  }
+  DocumentProto document = std::move(document_or).ValueOrDie();
+
+  // Apply parent projection
+  ApplyProjection(result_state.parent_adjustment_info(), &document);
+
+  SearchResultProto::ResultProto result;
+  // Add parent snippet if requested.
+  bool has_parent_snippets = ApplySnippet(
+      result_state.parent_adjustment_info(), *snippet_retriever_, document,
+      doc_id,
+      next_best_document_hit.parent_scored_document_hit().hit_section_id_mask(),
+      &result);
+
+  // Add the document, itself.
+  *result.mutable_document() = std::move(document);
+  result.set_score(next_best_document_hit.final_score());
+  const auto* parent_additional_scores =
+      next_best_document_hit.parent_scored_document_hit().additional_scores();
+  if (parent_additional_scores != nullptr) {
+    result.mutable_additional_scores()->Add(parent_additional_scores->begin(),
+                                            parent_additional_scores->end());
+  }
+
+  // Retrieve child documents
+  for (const ScoredDocumentHit& child_scored_document_hit :
+       next_best_document_hit.child_scored_document_hits()) {
+    if (result.joined_results_size() >=
+        result_state.max_joined_children_per_parent_to_return()) {
+      break;
+    }
+
+    DocumentId child_doc_id = child_scored_document_hit.document_id();
+    libtextclassifier3::StatusOr<DocumentProto> child_document_or =
+        doc_store_.Get(child_doc_id);
+    if (!child_document_or.ok()) {
+      // Skip the document if getting errors.
+      ICING_LOG(WARNING) << "Fail to fetch child document from document store: "
+                         << child_document_or.status().error_message();
+      continue;
+    }
+
+    DocumentProto child_document = std::move(child_document_or).ValueOrDie();
+    ApplyProjection(result_state.child_adjustment_info(), &child_document);
+
+    SearchResultProto::ResultProto* child_result = result.add_joined_results();
+    // Add child snippet if requested.
+    ApplySnippet(result_state.child_adjustment_info(), *snippet_retriever_,
+                 child_document, child_doc_id,
+                 child_scored_document_hit.hit_section_id_mask(), child_result);
+
+    *child_result->mutable_document() = std::move(child_document);
+    child_result->set_score(child_scored_document_hit.score());
+    if (child_scored_document_hit.additional_scores() != nullptr) {
+      child_result->mutable_additional_scores()->Add(
+          child_scored_document_hit.additional_scores()->begin(),
+          child_scored_document_hit.additional_scores()->end());
+    }
+  }
+
+  return RetrieveResult{.result_proto = std::make_optional(std::move(result)),
+                        .group_result_limits_index = *idx,
+                        .has_parent_snippets = has_parent_snippets};
+}
+
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/result/result-retriever-v2.h b/icing/result/result-retriever-v2.h
index 7b1a364..0516feb 100644
--- a/icing/result/result-retriever-v2.h
+++ b/icing/result/result-retriever-v2.h
@@ -17,11 +17,13 @@
 
 #include <cstdint>
 #include <memory>
+#include <optional>
 #include <unordered_map>
 #include <utility>
-#include <vector>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/thread_annotations.h"
+#include "icing/feature-flags.h"
 #include "icing/proto/search.pb.h"
 #include "icing/result/page-result.h"
 #include "icing/result/result-state-v2.h"
@@ -41,12 +43,18 @@ class GroupResultLimiterV2 {
 
   virtual ~GroupResultLimiterV2() = default;
 
-  // Returns true if the scored_document_hit should be removed.
-  virtual bool ShouldBeRemoved(
+  // Gets the index of the group result limits for the given scored document
+  // hit.
+  //
+  // Returns:
+  //   - A valid index of the group result limits.
+  //   - -1 indicating that there is no limit for the result document.
+  //   - std::nullopt if the result document, its namespace, or its schema type
+  //     is not present. The caller should exclude the document from the page.
+  virtual std::optional<int> GetGroupResultLimitsIndex(
       const ScoredDocumentHit& scored_document_hit,
       const std::unordered_map<int32_t, int>& entry_id_group_id_map,
       const DocumentStore& document_store,
-      std::vector<int>& group_result_limits,
       ResultSpecProto::ResultGroupingType result_group_type,
       int64_t current_time_ms) const;
 };
@@ -63,7 +71,7 @@ class ResultRetrieverV2 {
   static libtextclassifier3::StatusOr<std::unique_ptr<ResultRetrieverV2>>
   Create(const DocumentStore* doc_store, const SchemaStore* schema_store,
          const LanguageSegmenter* language_segmenter,
-         const Normalizer* normalizer,
+         const Normalizer* normalizer, const FeatureFlags* feature_flags,
          std::unique_ptr<const GroupResultLimiterV2> group_result_limiter =
              std::make_unique<const GroupResultLimiterV2>());
 
@@ -72,8 +80,8 @@ class ResultRetrieverV2 {
   // out the next top rank documents from ResultState, retrieves the documents
   // from storage, updates ResultState, and finally wraps the result + other
   // information into PageResult. The expected number of documents to return is
-  // min(num_per_page, the number of all scored document hits) inside
-  // ResultState.
+  // min(max_results, num_per_page, the number of all scored document hits)
+  // inside ResultState.
   //
   // The number of snippets to return is based on the total number of snippets
   // needed and number of snippets that have already been returned previously
@@ -89,20 +97,54 @@ class ResultRetrieverV2 {
   // Returns:
   //   std::pair<PageResult, bool>
   std::pair<PageResult, bool> RetrieveNextPage(ResultStateV2& result_state,
-                                               int64_t current_time_ms) const;
+                                               int32_t max_results,
+                                               int64_t current_time_ms) const
+      ICING_LOCKS_EXCLUDED(result_state.mutex);
 
  private:
   explicit ResultRetrieverV2(
       const DocumentStore* doc_store,
       std::unique_ptr<SnippetRetriever> snippet_retriever,
-      std::unique_ptr<const GroupResultLimiterV2> group_result_limiter)
+      std::unique_ptr<const GroupResultLimiterV2> group_result_limiter,
+      const FeatureFlags* feature_flags)
       : doc_store_(*doc_store),
         snippet_retriever_(std::move(snippet_retriever)),
-        group_result_limiter_(std::move(group_result_limiter)) {}
+        group_result_limiter_(std::move(group_result_limiter)),
+        feature_flags_(*feature_flags) {}
+
+  // Helper function to construct a ResultProto by the next best document hit
+  // from the scored document hits ranker.
+  //
+  // REQUIRES: !result_state.scored_document_hits_ranker.empty()
+  struct RetrieveResult {
+    // The constructed result proto. If std::nullopt, then the document should
+    // be skipped.
+    std::optional<SearchResultProto::ResultProto> result_proto;
+
+    // The index of the group result limits for the result. The caller should
+    // decrement the corresponding result limit in
+    // result_state.group_result_limits after deciding to include the result
+    // document in the page.
+    // - It is guaranteed to be -1 or in the range of [0,
+    //   result_state.group_result_limits.size() - 1]. If it is -1, then it
+    //   means there is no limit for the result document.
+    // - Only used when the proto is not std::nullopt.
+    int group_result_limits_index;
+
+    // Whether the (parent) document of the result has snippets. Only used when
+    // the proto is not std::nullopt.
+    bool has_parent_snippets;
+  };
+
+  RetrieveResult Retrieve(ResultStateV2& result_state,
+                          int64_t current_time_ms) const
+      ICING_EXCLUSIVE_LOCKS_REQUIRED(result_state.mutex);
 
   const DocumentStore& doc_store_;
   std::unique_ptr<SnippetRetriever> snippet_retriever_;
   const std::unique_ptr<const GroupResultLimiterV2> group_result_limiter_;
+
+  const FeatureFlags& feature_flags_;
 };
 
 }  // namespace lib
diff --git a/icing/result/result-retriever-v2_group-result-limiter_test.cc b/icing/result/result-retriever-v2_group-result-limiter_test.cc
index 964e92e..50160c1 100644
--- a/icing/result/result-retriever-v2_group-result-limiter_test.cc
+++ b/icing/result/result-retriever-v2_group-result-limiter_test.cc
@@ -15,13 +15,18 @@
 #include <cstdint>
 #include <limits>
 #include <memory>
+#include <string>
+#include <utility>
 #include <vector>
 
 #include "gtest/gtest.h"
+#include "icing/absl_ports/mutex.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
+#include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -41,9 +46,11 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -99,14 +106,18 @@ class ResultRetrieverV2GroupResultLimiterTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, test_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
   }
 
@@ -142,8 +153,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -152,8 +164,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -181,12 +194,14 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Only the top ranked document in "namespace" (document2), should be
   // returned.
   auto [page_result, has_more_results] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   ASSERT_THAT(page_result.results, SizeIs(1));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document2));
   // Document1 has not been returned due to GroupResultLimiter, but since it was
@@ -204,8 +219,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -214,8 +230,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -243,11 +260,13 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // First page: empty page
   auto [page_result, has_more_results] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   ASSERT_THAT(page_result.results, IsEmpty());
   EXPECT_FALSE(has_more_results);
 }
@@ -262,8 +281,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -272,8 +292,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentProto document3 = DocumentBuilder()
@@ -282,8 +303,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(3)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocumentProto document4 = DocumentBuilder()
@@ -292,8 +314,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(4)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -323,11 +346,13 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // First page: document4 and document3 should be returned.
   auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   ASSERT_THAT(page_result1.results, SizeIs(2));
   EXPECT_THAT(page_result1.results.at(0).document(), EqualsProto(document4));
   EXPECT_THAT(page_result1.results.at(1).document(), EqualsProto(document3));
@@ -337,7 +362,8 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   // them will be filtered out by group result limiter, so we should get an
   // empty page.
   auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result2.results, SizeIs(0));
   EXPECT_FALSE(has_more_results2);
 }
@@ -352,8 +378,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -362,8 +389,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentProto document3 = DocumentBuilder()
@@ -372,8 +400,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(3)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocumentProto document4 = DocumentBuilder()
@@ -382,8 +411,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(4)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -414,13 +444,15 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // All documents in "namespace2" should be returned.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document4));
@@ -438,8 +470,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -448,8 +481,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -480,15 +514,17 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Only the top ranked document in "namespace" (document2), should be
   // returned. The presence of "nonexistentNamespace" in the same result
   // grouping should have no effect.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(1));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document2));
@@ -504,8 +540,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -514,8 +551,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -546,15 +584,17 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Only the top ranked document in "Document" (document2), should be
   // returned. The presence of "nonexistentNamespace" in the same result
   // grouping should have no effect.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(1));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document2));
@@ -571,8 +611,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -581,8 +622,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentProto document3 = DocumentBuilder()
@@ -591,8 +633,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(3)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocumentProto document4 = DocumentBuilder()
@@ -601,8 +644,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(4)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   DocumentProto document5 = DocumentBuilder()
@@ -611,8 +655,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(5)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             document_store_->Put(document5));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      document_store_->Put(document_util::CreateDocumentWrapper(document5)));
   DocumentId document_id5 = put_result5.new_document_id;
 
   DocumentProto document6 = DocumentBuilder()
@@ -621,8 +666,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(6)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result6,
-                             document_store_->Put(document6));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result6,
+      document_store_->Put(document_util::CreateDocumentWrapper(document6)));
   DocumentId document_id6 = put_result6.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -661,15 +707,17 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Only the top-ranked result in "namespace1" (document2) should be returned.
   // Only the top-ranked results across "namespace2" and "namespace3"
   // (document6, document5) should be returned.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document6));
@@ -688,8 +736,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -698,8 +747,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentProto document3 = DocumentBuilder()
@@ -708,8 +758,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(3)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocumentProto document4 = DocumentBuilder()
@@ -718,8 +769,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(4)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   DocumentProto document5 = DocumentBuilder()
@@ -728,8 +780,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(5)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             document_store_->Put(document5));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      document_store_->Put(document_util::CreateDocumentWrapper(document5)));
   DocumentId document_id5 = put_result5.new_document_id;
 
   DocumentProto document6 = DocumentBuilder()
@@ -738,8 +791,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(6)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result6,
-                             document_store_->Put(document6));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result6,
+      document_store_->Put(document_util::CreateDocumentWrapper(document6)));
   DocumentId document_id6 = put_result6.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -778,15 +832,17 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Only the top-ranked result in "Document" (document6) should be returned.
   // Only the top-ranked results across "Message" and "Person"
   // (document5, document3) should be returned.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document6));
@@ -805,8 +861,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -815,8 +872,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentProto document3 = DocumentBuilder()
@@ -825,8 +883,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(3)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocumentProto document4 = DocumentBuilder()
@@ -835,8 +894,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(4)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   DocumentProto document5 = DocumentBuilder()
@@ -845,8 +905,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(5)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             document_store_->Put(document5));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      document_store_->Put(document_util::CreateDocumentWrapper(document5)));
   DocumentId document_id5 = put_result5.new_document_id;
 
   DocumentProto document6 = DocumentBuilder()
@@ -855,8 +916,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(6)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result6,
-                             document_store_->Put(document6));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result6,
+      document_store_->Put(document_util::CreateDocumentWrapper(document6)));
   DocumentId document_id6 = put_result6.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -898,7 +960,8 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Only the top-ranked result in "namespace1xDocument" (document3)
   // should be returned.
@@ -907,8 +970,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document6));
@@ -926,8 +990,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -936,8 +1001,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -966,14 +1032,16 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // All documents in "namespace" should be returned. The presence of
   // "nonexistentNamespace" should have no effect.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document2));
@@ -990,8 +1058,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -1000,8 +1069,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -1030,14 +1100,16 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // All documents in "Document" should be returned. The presence of
   // "nonexistentDocument" should have no effect.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
   EXPECT_THAT(page_result.results.at(0).document(), EqualsProto(document2));
@@ -1054,8 +1126,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(1)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document2 = DocumentBuilder()
@@ -1064,8 +1137,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(2)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentProto document3 = DocumentBuilder()
@@ -1074,8 +1148,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(3)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocumentProto document4 = DocumentBuilder()
@@ -1084,8 +1159,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(4)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store_->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store_->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
 
   DocumentProto document5 = DocumentBuilder()
@@ -1094,8 +1170,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
                                 .SetScore(5)
                                 .SetCreationTimestampMs(1000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             document_store_->Put(document5));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      document_store_->Put(document_util::CreateDocumentWrapper(document5)));
   DocumentId document_id5 = put_result5.new_document_id;
 
   std::vector<ScoredDocumentHit> scored_document_hits = {
@@ -1122,13 +1199,13 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   entry = result_grouping->add_entry_groupings();
   entry->set_namespace_("namespace2");
 
-  // Get corpus ids.
-  ICING_ASSERT_OK_AND_ASSIGN(
-      CorpusId corpus_id1, document_store_->GetResultGroupingEntryId(
-                               result_grouping_type, "namespace1", "Document"));
-  ICING_ASSERT_OK_AND_ASSIGN(
-      CorpusId corpus_id2, document_store_->GetResultGroupingEntryId(
-                               result_grouping_type, "namespace2", "Document"));
+  // Get result grouping entry ids.
+  ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
+      int32_t entry_id1, document_store_->GetResultGroupingEntryId(
+                             result_grouping_type, "namespace1", "Document"));
+  ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
+      int32_t entry_id2, document_store_->GetResultGroupingEntryId(
+                             result_grouping_type, "namespace2", "Document"));
 
   // Creates a ResultState with 5 ScoredDocumentHits.
   ResultStateV2 result_state(
@@ -1141,22 +1218,24 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
     absl_ports::shared_lock l(&result_state.mutex);
 
     ASSERT_THAT(result_state.entry_id_group_id_map(),
-                UnorderedElementsAre(Pair(corpus_id1, 0), Pair(corpus_id2, 1)));
+                UnorderedElementsAre(Pair(entry_id1, 0), Pair(entry_id2, 1)));
     ASSERT_THAT(result_state.group_result_limits, ElementsAre(3, 1));
   }
 
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // document5, document4, document1 belong to namespace2 (with max_results =
   // 1).
-  // docuemnt3, document2 belong to namespace 1 (with max_results = 3).
+  // document3, document2 belong to namespace 1 (with max_results = 3).
   // Since num_per_page is 2, we expect to get document5 and document3 in the
   // first page.
   auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   ASSERT_THAT(page_result1.results, SizeIs(2));
   ASSERT_THAT(page_result1.results.at(0).document(), EqualsProto(document5));
   ASSERT_THAT(page_result1.results.at(1).document(), EqualsProto(document3));
@@ -1179,9 +1258,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
     // round, num_returned should still be 2, since document4 was "filtered out"
     // and should not be counted into num_returned.
     EXPECT_THAT(result_state.num_returned, Eq(2));
-    // corpus_id_group_id_map should be unchanged.
+    // entry_id_group_id_map should be unchanged.
     EXPECT_THAT(result_state.entry_id_group_id_map(),
-                UnorderedElementsAre(Pair(corpus_id1, 0), Pair(corpus_id2, 1)));
+                UnorderedElementsAre(Pair(entry_id1, 0), Pair(entry_id2, 1)));
     // GroupResultLimiter should decrement the # in group_result_limits.
     EXPECT_THAT(result_state.group_result_limits, ElementsAre(2, 0));
   }
@@ -1189,7 +1268,8 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
   // Although there are document2 and document1 left, since namespace2 has
   // reached its max results, document1 should be excluded from the second page.
   auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   ASSERT_THAT(page_result2.results, SizeIs(1));
   ASSERT_THAT(page_result2.results.at(0).document(), EqualsProto(document2));
   ASSERT_FALSE(has_more_results2);
@@ -1203,9 +1283,9 @@ TEST_F(ResultRetrieverV2GroupResultLimiterTest,
     // since document1 was "filtered out" and should not be counted into
     // num_returned.
     EXPECT_THAT(result_state.num_returned, Eq(3));
-    // corpus_id_group_id_map should be unchanged.
+    // entry_id_group_id_map should be unchanged.
     EXPECT_THAT(result_state.entry_id_group_id_map(),
-                UnorderedElementsAre(Pair(corpus_id1, 0), Pair(corpus_id2, 1)));
+                UnorderedElementsAre(Pair(entry_id1, 0), Pair(entry_id2, 1)));
     // GroupResultLimiter should decrement the # in group_result_limits.
     EXPECT_THAT(result_state.group_result_limits, ElementsAre(1, 0));
   }
diff --git a/icing/result/result-retriever-v2_projection_test.cc b/icing/result/result-retriever-v2_projection_test.cc
index dfe7bb7..40bf19d 100644
--- a/icing/result/result-retriever-v2_projection_test.cc
+++ b/icing/result/result-retriever-v2_projection_test.cc
@@ -27,6 +27,7 @@
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/embed/embedding-query-results.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -55,6 +56,7 @@
 #include "icing/transform/normalizer-factory.h"
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -200,14 +202,18 @@ class ResultRetrieverV2ProjectionTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, test_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
   }
 
@@ -282,8 +288,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTopLevelLeadNodeFieldPath) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -295,8 +302,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTopLevelLeadNodeFieldPath) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -330,13 +338,15 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTopLevelLeadNodeFieldPath) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results only contain the 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -380,8 +390,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionNestedLeafNodeFieldPath) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -400,8 +411,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionNestedLeafNodeFieldPath) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -434,14 +446,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionNestedLeafNodeFieldPath) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results only contain the 'sender.name'
   // property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -495,8 +509,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionIntermediateNodeFieldPath) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -515,8 +530,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionIntermediateNodeFieldPath) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -549,14 +565,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionIntermediateNodeFieldPath) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results only contain the 'sender'
   // property and all of the subproperties of 'sender'.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -613,8 +631,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleNestedFieldPaths) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -633,8 +652,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleNestedFieldPaths) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -668,14 +688,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleNestedFieldPaths) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results only contain the 'sender.name' and
   // 'sender.address' properties.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -724,8 +746,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionEmptyFieldPath) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -737,8 +760,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionEmptyFieldPath) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -770,13 +794,15 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionEmptyFieldPath) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results contain *no* properties.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -808,8 +834,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionInvalidFieldPath) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -821,8 +848,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionInvalidFieldPath) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -855,13 +883,15 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionInvalidFieldPath) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results contain *no* properties.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -893,8 +923,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionValidAndInvalidFieldPath) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -906,8 +937,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionValidAndInvalidFieldPath) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -941,13 +973,15 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionValidAndInvalidFieldPath) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned results only contain the 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -983,8 +1017,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesNoWildcards) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -995,8 +1030,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesNoWildcards) {
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1029,14 +1065,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesNoWildcards) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Email results only contain the 'name'
   // property and the returned Person results have all of their properties.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1073,8 +1111,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesWildcard) {
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1085,8 +1124,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesWildcard) {
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1121,14 +1161,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleTypesWildcard) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Email results only contain the 'name'
   // property and the returned Person results only contain the 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1165,8 +1207,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
           .AddStringProperty(
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1177,8 +1220,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1217,14 +1261,16 @@ TEST_F(ResultRetrieverV2ProjectionTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Email results only contain the 'body'
   // property and the returned Person results  only contain the 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1270,8 +1316,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
                   .AddStringProperty("emailAddress", "mr.body123@gmail.com")
                   .Build())
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1282,8 +1329,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1322,14 +1370,16 @@ TEST_F(ResultRetrieverV2ProjectionTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Email results only contain the 'sender.name'
   // property and the returned Person results only contain the 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1379,8 +1429,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
                   .AddStringProperty("emailAddress", "mr.body123@gmail.com")
                   .Build())
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1391,8 +1442,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1431,14 +1483,16 @@ TEST_F(ResultRetrieverV2ProjectionTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Email results only contain the 'sender.name'
   // property and the returned Person results contain no properties.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1476,8 +1530,10 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionJoinDocuments) {
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(person_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(person_document)));
   DocumentId person_document_id = put_result1.new_document_id;
 
   // 2. Add two Email documents
@@ -1491,8 +1547,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionJoinDocuments) {
               "body", "Oh what a beautiful morning! Oh what a beautiful day!")
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(put_result1,
-                             document_store_->Put(email_document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result1, document_store_->Put(
+                       document_util::CreateDocumentWrapper(email_document1)));
   DocumentId email_document_id1 = put_result1.new_document_id;
 
   DocumentProto email_document2 =
@@ -1504,8 +1561,10 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionJoinDocuments) {
           .AddStringProperty("body",
                              "Count all the sheep and tell them 'Hello'.")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(email_document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(email_document2)));
   DocumentId email_document_id2 = put_result2.new_document_id;
 
   // 3. Setup the joined scored results.
@@ -1569,15 +1628,17 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionJoinDocuments) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 7. Verify that the returned results:
   //    - Person docs only contain the "name" property.
   //    - Email docs only contain the "body" property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(1));
 
@@ -1628,8 +1689,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphism) {
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1640,8 +1702,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphism) {
           .AddStringProperty("name", "Joe Artist")
           .AddStringProperty("emailAddress", "artist@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1674,14 +1737,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphism) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Person and Artist results only contain the
   // 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1716,8 +1781,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTransitivePolymorphism) {
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1728,8 +1794,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTransitivePolymorphism) {
           .AddStringProperty("name", "Joe Musician")
           .AddStringProperty("emailAddress", "Musician@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1762,14 +1829,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionTransitivePolymorphism) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Person and Musician results only contain the
   // 'name' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1804,8 +1873,9 @@ TEST_F(ResultRetrieverV2ProjectionTest,
                                .SetSchema("Artist")
                                .AddStringProperty("name", "Joe Artist")
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id = put_result.new_document_id;
 
   // 2. Setup the scored results.
@@ -1838,14 +1908,16 @@ TEST_F(ResultRetrieverV2ProjectionTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned person document does not contain any property,
   // since 'emailAddress' is missing.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(1));
   DocumentProto projected_document = DocumentBuilder()
@@ -1867,8 +1939,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphismMerge) {
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_one));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_one)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   DocumentProto document_two =
@@ -1879,8 +1952,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphismMerge) {
           .AddStringProperty("name", "Joe Artist")
           .AddStringProperty("emailAddress", "artist@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_two));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(document_util::CreateDocumentWrapper(document_two)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // 2. Setup the scored results.
@@ -1918,15 +1992,17 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionPolymorphismMerge) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned Person results only contain the 'name'
   // property and the returned Artist results contain both the 'name' and
   // 'emailAddress' properties.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1963,8 +2039,9 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleParentPolymorphism) {
                                .AddStringProperty("phoneNumber", "12345")
                                .AddStringProperty("phoneModel", "pixel")
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id = put_result.new_document_id;
 
   // 2. Setup the scored results.
@@ -2003,14 +2080,16 @@ TEST_F(ResultRetrieverV2ProjectionTest, ProjectionMultipleParentPolymorphism) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // 5. Verify that the returned document only contains the 'name' and the
   // 'phoneNumber' property.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(1));
 
diff --git a/icing/result/result-retriever-v2_snippet_test.cc b/icing/result/result-retriever-v2_snippet_test.cc
index 09b691e..b2bf82c 100644
--- a/icing/result/result-retriever-v2_snippet_test.cc
+++ b/icing/result/result-retriever-v2_snippet_test.cc
@@ -29,6 +29,7 @@
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/embed/embedding-query-results.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -58,6 +59,7 @@
 #include "icing/transform/normalizer-factory.h"
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/snippet-helpers.h"
 #include "unicode/uloc.h"
@@ -147,14 +149,18 @@ class ResultRetrieverV2SnippetTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, test_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
   }
 
@@ -271,31 +277,35 @@ EmbeddingMatchSnippetProto CreateEmbeddingMatchSnippetProto(
 EmbeddingQueryResults CreateEmailEmbeddingQueryResults(int num_documents) {
   SectionId embedding1_section_id = 1;
   SectionId embedding2_section_id = 2;
-  EmbeddingQueryResults embedding_query_results;
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
 
   for (int doc_id = 0; doc_id < num_documents; ++doc_id) {
     EmbeddingMatchInfos& info_model1 =
-        embedding_query_results
-            .result_infos[/*query_index=*/0][EMBEDDING_METRIC_DOT_PRODUCT]
-                         [doc_id];
-    info_model1.AppendScore(1.1 + doc_id);
-    info_model1.AppendScore(2.2 + doc_id);
+        GetOrCreateEmbeddingMatchInfosForDocument(
+            embedding_query_results, /*query_index=*/0,
+            EMBEDDING_METRIC_DOT_PRODUCT, doc_id);
+    info_model1.AppendScore(*embedding_query_results.global_scores,
+                            1.1 + doc_id);
     // {2, 3, 4 + doc_id}, position 2
     info_model1.AppendSectionInfo(
-        embedding1_section_id,
+        *embedding_query_results.global_section_infos, embedding1_section_id,
         /*position_in_section_for_dimension_and_signature=*/1);
+    info_model1.AppendScore(*embedding_query_results.global_scores,
+                            2.2 + doc_id);
     // {-1, -2, -6 + doc_id}, position 1
     info_model1.AppendSectionInfo(
-        embedding2_section_id,
+        *embedding_query_results.global_section_infos, embedding2_section_id,
         /*position_in_section_for_dimension_and_signature=*/0);
 
     EmbeddingMatchInfos& info_model2 =
-        embedding_query_results
-            .result_infos[/*query_index=*/1][EMBEDDING_METRIC_COSINE][doc_id];
-    info_model2.AppendScore(3.3 + doc_id);
+        GetOrCreateEmbeddingMatchInfosForDocument(
+            embedding_query_results, /*query_index=*/1, EMBEDDING_METRIC_COSINE,
+            doc_id);
+    info_model2.AppendScore(*embedding_query_results.global_scores,
+                            3.3 + doc_id);
     // {1, 2, 3, 4 + doc_id}, position 1
     info_model2.AppendSectionInfo(
-        embedding1_section_id,
+        *embedding_query_results.global_section_infos, embedding1_section_id,
         /*position_in_section_for_dimension_and_signature=*/0);
   }
   return embedding_query_results;
@@ -305,15 +315,18 @@ TEST_F(ResultRetrieverV2SnippetTest,
        DefaultSnippetSpecShouldDisableSnippeting) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
@@ -326,7 +339,8 @@ TEST_F(ResultRetrieverV2SnippetTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   ResultSpecProto result_spec = CreateResultSpec(/*num_per_page=*/3);
 
@@ -345,8 +359,10 @@ TEST_F(ResultRetrieverV2SnippetTest,
       /*child_adjustment_info=*/nullptr, result_spec, *document_store_);
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).snippet(),
@@ -361,15 +377,18 @@ TEST_F(ResultRetrieverV2SnippetTest,
 TEST_F(ResultRetrieverV2SnippetTest, SimpleSnippeted) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
@@ -382,7 +401,8 @@ TEST_F(ResultRetrieverV2SnippetTest, SimpleSnippeted) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto result_spec = CreateResultSpec(/*num_per_page=*/3);
@@ -404,8 +424,10 @@ TEST_F(ResultRetrieverV2SnippetTest, SimpleSnippeted) {
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.num_results_with_snippets, Eq(3));
@@ -476,15 +498,18 @@ TEST_F(ResultRetrieverV2SnippetTest, SimpleSnippeted) {
 TEST_F(ResultRetrieverV2SnippetTest, OnlyOneDocumentSnippeted) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
@@ -497,7 +522,8 @@ TEST_F(ResultRetrieverV2SnippetTest, OnlyOneDocumentSnippeted) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
@@ -521,8 +547,10 @@ TEST_F(ResultRetrieverV2SnippetTest, OnlyOneDocumentSnippeted) {
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.num_results_with_snippets, Eq(1));
@@ -560,15 +588,18 @@ TEST_F(ResultRetrieverV2SnippetTest, OnlyOneDocumentSnippeted) {
 TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfo) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {
@@ -582,7 +613,8 @@ TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfo) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
@@ -613,8 +645,10 @@ TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfo) {
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.num_results_with_snippets, Eq(3));
@@ -738,15 +772,18 @@ TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfo) {
 TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfoDisabled) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {
@@ -760,7 +797,8 @@ TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfoDisabled) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
@@ -791,8 +829,10 @@ TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfoDisabled) {
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.num_results_with_snippets, Eq(3));
@@ -863,15 +903,18 @@ TEST_F(ResultRetrieverV2SnippetTest, SnippetWithGetEmbeddingMatchInfoDisabled) {
 TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
@@ -884,7 +927,8 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
@@ -914,8 +958,10 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeResults) {
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).snippet().entries(), Not(IsEmpty()));
@@ -927,15 +973,18 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeResults) {
 TEST_F(ResultRetrieverV2SnippetTest, ShouldNotSnippetAnyResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
@@ -948,7 +997,8 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldNotSnippetAnyResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
@@ -979,8 +1029,10 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldNotSnippetAnyResults) {
   // We can't return any snippets for this page.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).snippet().entries(), IsEmpty());
@@ -993,15 +1045,18 @@ TEST_F(ResultRetrieverV2SnippetTest,
        ShouldNotSnippetAnyResultsForNonPositiveNumMatchesPerProperty) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "subject"),
@@ -1014,7 +1069,8 @@ TEST_F(ResultRetrieverV2SnippetTest,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto snippet_spec = CreateSnippetSpec();
@@ -1047,8 +1103,10 @@ TEST_F(ResultRetrieverV2SnippetTest,
   // We can't return any snippets for this page even though num_to_snippet > 0.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.results.at(0).snippet().entries(), IsEmpty());
@@ -1060,28 +1118,34 @@ TEST_F(ResultRetrieverV2SnippetTest,
 TEST_F(ResultRetrieverV2SnippetTest, JoinSnippeted) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result1,
-      document_store_->Put(CreatePersonDocument(/*id=*/1)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/1))));
   DocumentId person_document_id1 = person_put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result2,
-      document_store_->Put(CreatePersonDocument(/*id=*/2)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/2))));
   DocumentId person_document_id2 = person_put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result3,
-      document_store_->Put(CreatePersonDocument(/*id=*/3)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/3))));
   DocumentId person_document_id3 = person_put_result3.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId email_document_id1 = email_put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId email_document_id2 = email_put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId email_document_id3 = email_put_result3.new_document_id;
 
   std::vector<SectionId> person_hit_section_ids = {
@@ -1124,7 +1188,8 @@ TEST_F(ResultRetrieverV2SnippetTest, JoinSnippeted) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create parent ResultSpec with custom snippet spec.
   ResultSpecProto parent_result_spec = CreateResultSpec(/*num_per_page=*/3);
@@ -1163,8 +1228,10 @@ TEST_F(ResultRetrieverV2SnippetTest, JoinSnippeted) {
 
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(3));
   EXPECT_THAT(page_result.num_results_with_snippets, Eq(3));
@@ -1304,24 +1371,29 @@ TEST_F(ResultRetrieverV2SnippetTest, JoinSnippeted) {
 TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllJoinedResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result1,
-      document_store_->Put(CreatePersonDocument(/*id=*/1)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/1))));
   DocumentId person_document_id1 = person_put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result2,
-      document_store_->Put(CreatePersonDocument(/*id=*/2)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/2))));
   DocumentId person_document_id2 = person_put_result2.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId email_document_id1 = email_put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId email_document_id2 = email_put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId email_document_id3 = email_put_result3.new_document_id;
 
   std::vector<SectionId> person_hit_section_ids = {
@@ -1359,7 +1431,8 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllJoinedResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create parent ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto parent_snippet_spec = CreateSnippetSpec();
@@ -1403,8 +1476,10 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllJoinedResults) {
   // should be snippeted.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
@@ -1432,24 +1507,29 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetAllJoinedResults) {
 TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeJoinedResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result1,
-      document_store_->Put(CreatePersonDocument(/*id=*/1)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/1))));
   DocumentId person_document_id1 = person_put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult person_put_result2,
-      document_store_->Put(CreatePersonDocument(/*id=*/2)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreatePersonDocument(/*id=*/2))));
   DocumentId person_document_id2 = person_put_result2.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result1,
-      document_store_->Put(CreateEmailDocument(/*id=*/1)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/1))));
   DocumentId email_document_id1 = email_put_result1.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result2,
-      document_store_->Put(CreateEmailDocument(/*id=*/2)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/2))));
   DocumentId email_document_id2 = email_put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result3,
-      document_store_->Put(CreateEmailDocument(/*id=*/3)));
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(CreateEmailDocument(/*id=*/3))));
   DocumentId email_document_id3 = email_put_result3.new_document_id;
 
   std::vector<SectionId> person_hit_section_ids = {
@@ -1487,7 +1567,8 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeJoinedResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Create parent ResultSpec with custom snippet spec.
   ResultSpecProto::SnippetSpecProto parent_snippet_spec = CreateSnippetSpec();
@@ -1531,8 +1612,10 @@ TEST_F(ResultRetrieverV2SnippetTest, ShouldSnippetSomeJoinedResults) {
   // snippeted.
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result.results, SizeIs(2));
 
diff --git a/icing/result/result-retriever-v2_test.cc b/icing/result/result-retriever-v2_test.cc
index 49899b1..c314c12 100644
--- a/icing/result/result-retriever-v2_test.cc
+++ b/icing/result/result-retriever-v2_test.cc
@@ -19,6 +19,7 @@
 #include <cstdint>
 #include <limits>
 #include <memory>
+#include <optional>
 #include <string>
 #include <unordered_map>
 #include <utility>
@@ -35,6 +36,7 @@
 #include "icing/file/mock-filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/document_wrapper.pb.h"
@@ -53,7 +55,6 @@
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-data.h"
-#include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
@@ -61,6 +62,7 @@
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -80,28 +82,30 @@ using ::testing::Return;
 using ::testing::SizeIs;
 using EntryIdMap = std::unordered_map<int32_t, int>;
 
-// Mock the behavior of GroupResultLimiter::ShouldBeRemoved.
+// Mock the behavior of GroupResultLimiter::GetGroupResultLimitsIndex: get
+// -1 to avoid excluding documents.
 class MockGroupResultLimiter : public GroupResultLimiterV2 {
  public:
   MockGroupResultLimiter() : GroupResultLimiterV2() {
-    ON_CALL(*this, ShouldBeRemoved).WillByDefault(Return(false));
+    ON_CALL(*this, GetGroupResultLimitsIndex).WillByDefault(Return(-1));
   }
 
-  MOCK_METHOD(bool, ShouldBeRemoved,
+  MOCK_METHOD(std::optional<int>, GetGroupResultLimitsIndex,
               (const ScoredDocumentHit&, const EntryIdMap&,
-               const DocumentStore&, std::vector<int>&,
-               ResultSpecProto::ResultGroupingType, int64_t),
+               const DocumentStore&, ResultSpecProto::ResultGroupingType,
+               int64_t),
               (const, override));
 };
 
-class ResultRetrieverV2Test : public ::testing::Test {
+class ResultRetrieverV2Test : public ::testing::TestWithParam<FeatureFlags> {
  protected:
   ResultRetrieverV2Test() : test_dir_(GetTestTempDir() + "/icing") {
     filesystem_.CreateDirectoryRecursively(test_dir_.c_str());
   }
 
   void SetUp() override {
-    feature_flags_ = std::make_unique<FeatureFlags>(GetTestFeatureFlags());
+    feature_flags_ = std::make_unique<FeatureFlags>(GetParam());
+
     if (!IsCfStringTokenization() && !IsReverseJniTokenization()) {
       ICING_ASSERT_OK(
           // File generated via icu_data_file rule in //icing/BUILD.
@@ -231,13 +235,17 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
       PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+      PortableFileBackedProtoLog<
+          DocumentWrapper>::kDefaultCompressionThresholdBytes,
+      protobuf_ports::kDefaultMemLevel,
       /*initialize_stats=*/nullptr);
 }
 
-TEST_F(ResultRetrieverV2Test, CreationWithNullPointerShouldFail) {
+TEST_P(ResultRetrieverV2Test, CreationWithNullPointerShouldFail) {
   EXPECT_THAT(
-      ResultRetrieverV2::Create(/*doc_store=*/nullptr, schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()),
+      ResultRetrieverV2::Create(
+          /*doc_store=*/nullptr, schema_store_.get(), language_segmenter_.get(),
+          normalizer_.get(), feature_flags_.get()),
       StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -249,19 +257,32 @@ TEST_F(ResultRetrieverV2Test, CreationWithNullPointerShouldFail) {
 
   EXPECT_THAT(
       ResultRetrieverV2::Create(doc_store.get(), /*schema_store=*/nullptr,
-                                language_segmenter_.get(), normalizer_.get()),
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()),
+      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
+  EXPECT_THAT(
+      ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
+                                /*language_segmenter=*/nullptr,
+                                normalizer_.get(), feature_flags_.get()),
+      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
+  EXPECT_THAT(
+      ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
+                                language_segmenter_.get(),
+                                /*normalizer=*/nullptr, feature_flags_.get()),
+      StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
+  EXPECT_THAT(
+      ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
+                                language_segmenter_.get(), normalizer_.get(),
+                                /*feature_flags=*/nullptr),
       StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
-  EXPECT_THAT(ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                        /*language_segmenter=*/nullptr,
-                                        normalizer_.get()),
-              StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
   EXPECT_THAT(ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
                                         language_segmenter_.get(),
-                                        /*normalizer=*/nullptr),
+                                        normalizer_.get(), feature_flags_.get(),
+                                        /*group_result_limiter=*/nullptr),
               StatusIs(libtextclassifier3::StatusCode::FAILED_PRECONDITION));
 }
 
-TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
+TEST_P(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
@@ -269,20 +290,30 @@ TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             doc_store->Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             doc_store->Put(CreateDocument(/*id=*/4)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/4))));
   DocumentId document_id4 = put_result4.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             doc_store->Put(CreateDocument(/*id=*/5)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/5))));
   DocumentId document_id5 = put_result5.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
@@ -297,7 +328,8 @@ TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   SearchResultProto::ResultProto result1;
   *result1.mutable_document() = CreateDocument(/*id=*/1);
@@ -325,7 +357,8 @@ TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
 
   // First page, 2 results
   auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result1.results,
               ElementsAre(EqualsProto(result1), EqualsProto(result2)));
   // num_results_with_snippets is 0 when there is no snippet.
@@ -337,7 +370,8 @@ TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
 
   // Second page, 2 results
   auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result2.results,
               ElementsAre(EqualsProto(result3), EqualsProto(result4)));
   // num_results_with_snippets is 0 when there is no snippet.
@@ -349,7 +383,8 @@ TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
 
   // Third page, 1 result
   auto [page_result3, has_more_results3] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result3.results, ElementsAre(EqualsProto(result5)));
   // num_results_with_snippets is 0 when there is no snippet.
   EXPECT_THAT(page_result3.num_results_with_snippets, Eq(0));
@@ -359,7 +394,7 @@ TEST_F(ResultRetrieverV2Test, ShouldRetrieveSimpleResults) {
   EXPECT_FALSE(has_more_results3);
 }
 
-TEST_F(ResultRetrieverV2Test, ShouldIgnoreNonInternalErrors) {
+TEST_P(ResultRetrieverV2Test, ShouldIgnoreNonInternalErrors) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
@@ -367,11 +402,15 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreNonInternalErrors) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
 
   DocumentId invalid_document_id = -1;
@@ -386,6 +425,7 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreNonInternalErrors) {
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
                                 language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get(),
                                 std::make_unique<MockGroupResultLimiter>()));
 
   SearchResultProto::ResultProto result1;
@@ -405,8 +445,10 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreNonInternalErrors) {
       *doc_store);
   PageResult page_result1 =
       result_retriever
-          ->RetrieveNextPage(result_state1,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state1,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   EXPECT_THAT(page_result1.results,
               ElementsAre(EqualsProto(result1), EqualsProto(result2)));
@@ -426,14 +468,16 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreNonInternalErrors) {
       *doc_store);
   PageResult page_result2 =
       result_retriever
-          ->RetrieveNextPage(result_state2,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state2,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   EXPECT_THAT(page_result2.results,
               ElementsAre(EqualsProto(result1), EqualsProto(result2)));
 }
 
-TEST_F(ResultRetrieverV2Test,
+TEST_P(ResultRetrieverV2Test,
        ShouldLimitNumChildDocumentsByMaxJoinedChildPerParent) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -451,8 +495,9 @@ TEST_F(ResultRetrieverV2Test,
           .AddStringProperty("name", "Joe Fox")
           .AddStringProperty("emailAddress", "ny152@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(person_document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(person_document1)));
   DocumentId person_document_id1 = put_result1.new_document_id;
 
   DocumentProto person_document2 =
@@ -463,8 +508,9 @@ TEST_F(ResultRetrieverV2Test,
           .AddStringProperty("name", "Meg Ryan")
           .AddStringProperty("emailAddress", "shopgirl@aol.com")
           .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(person_document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(person_document2)));
   DocumentId person_document_id2 = put_result2.new_document_id;
 
   // 2. Add 4 Email documents
@@ -475,7 +521,9 @@ TEST_F(ResultRetrieverV2Test,
                                       .AddStringProperty("name", "Test 1")
                                       .AddStringProperty("body", "Test 1")
                                       .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(put_result1, doc_store->Put(email_document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(email_document1)));
   DocumentId email_document_id1 = put_result1.new_document_id;
 
   DocumentProto email_document2 = DocumentBuilder()
@@ -485,7 +533,9 @@ TEST_F(ResultRetrieverV2Test,
                                       .AddStringProperty("name", "Test 2")
                                       .AddStringProperty("body", "Test 2")
                                       .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(put_result2, doc_store->Put(email_document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(email_document2)));
   DocumentId email_document_id2 = put_result2.new_document_id;
 
   DocumentProto email_document3 = DocumentBuilder()
@@ -495,8 +545,9 @@ TEST_F(ResultRetrieverV2Test,
                                       .AddStringProperty("name", "Test 3")
                                       .AddStringProperty("body", "Test 3")
                                       .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             doc_store->Put(email_document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      doc_store->Put(document_util::CreateDocumentWrapper(email_document3)));
   DocumentId email_document_id3 = put_result3.new_document_id;
 
   DocumentProto email_document4 = DocumentBuilder()
@@ -506,8 +557,9 @@ TEST_F(ResultRetrieverV2Test,
                                       .AddStringProperty("name", "Test 4")
                                       .AddStringProperty("body", "Test 4")
                                       .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             doc_store->Put(email_document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      doc_store->Put(document_util::CreateDocumentWrapper(email_document4)));
   DocumentId email_document_id4 = put_result4.new_document_id;
 
   // 3. Setup the joined scored results.
@@ -555,7 +607,8 @@ TEST_F(ResultRetrieverV2Test,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
   ResultStateV2 result_state(
       std::make_unique<
           PriorityQueueScoredDocumentHitsRanker<JoinedScoredDocumentHit>>(
@@ -583,14 +636,15 @@ TEST_F(ResultRetrieverV2Test,
   child3->set_score(3);
 
   auto [page_result, has_more_results] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result.results,
               ElementsAre(EqualsProto(result1), EqualsProto(result2)));
   // No more results.
   EXPECT_FALSE(has_more_results);
 }
 
-TEST_F(ResultRetrieverV2Test, ShouldIgnoreInternalErrors) {
+TEST_P(ResultRetrieverV2Test, ShouldIgnoreInternalErrors) {
   MockFilesystem mock_filesystem;
   EXPECT_CALL(mock_filesystem,
               PRead(A<int>(), A<void*>(), A<size_t>(), A<off_t>()))
@@ -604,11 +658,15 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreInternalErrors) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
@@ -622,6 +680,7 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreInternalErrors) {
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
                                 language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get(),
                                 std::make_unique<MockGroupResultLimiter>()));
 
   SearchResultProto::ResultProto result1;
@@ -638,15 +697,17 @@ TEST_F(ResultRetrieverV2Test, ShouldIgnoreInternalErrors) {
       *doc_store);
   PageResult page_result =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   // We mocked mock_filesystem to return an internal error when retrieving doc2,
   // so doc2 should be skipped and doc1 should still be returned.
   EXPECT_THAT(page_result.results, ElementsAre(EqualsProto(result1)));
 }
 
-TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
+TEST_P(ResultRetrieverV2Test, ShouldUpdateResultState) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
@@ -654,20 +715,30 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             doc_store->Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             doc_store->Put(CreateDocument(/*id=*/4)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/4))));
   DocumentId document_id4 = put_result4.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             doc_store->Put(CreateDocument(/*id=*/5)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/5))));
   DocumentId document_id5 = put_result5.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
@@ -682,7 +753,8 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   ResultStateV2 result_state(
       std::make_unique<
@@ -696,8 +768,10 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
   // First page, 2 results
   PageResult page_result1 =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result1.results, SizeIs(2));
   {
@@ -713,8 +787,10 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
   // Second page, 2 results
   PageResult page_result2 =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result2.results, SizeIs(2));
   {
@@ -730,8 +806,10 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
   // Third page, 1 result
   PageResult page_result3 =
       result_retriever
-          ->RetrieveNextPage(result_state,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              result_state,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result3.results, SizeIs(1));
   {
@@ -745,7 +823,7 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateResultState) {
   }
 }
 
-TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
+TEST_P(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
@@ -757,11 +835,15 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
                                             GetSectionId("Email", "body")};
   SectionIdMask hit_section_id_mask = CreateSectionIdMask(hit_section_ids);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits1 = {
       {document_id1, hit_section_id_mask, /*score=*/0},
@@ -782,14 +864,20 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
     ASSERT_THAT(num_total_hits_, Eq(2));
   }
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             doc_store->Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             doc_store->Put(CreateDocument(/*id=*/4)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/4))));
   DocumentId document_id4 = put_result4.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             doc_store->Put(CreateDocument(/*id=*/5)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/5))));
   DocumentId document_id5 = put_result5.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits2 = {
       {document_id3, hit_section_id_mask, /*score=*/0},
@@ -814,14 +902,17 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   // Should get 1 doc in the first page of result_state1, and num_total_hits
   // should be decremented by 1.
   PageResult page_result1 =
       result_retriever
-          ->RetrieveNextPage(*result_state1,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              *result_state1,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result1.results, SizeIs(1));
   EXPECT_THAT(num_total_hits_, Eq(4));
@@ -830,8 +921,10 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
   // should be decremented by 2.
   PageResult page_result2 =
       result_retriever
-          ->RetrieveNextPage(*result_state2,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              *result_state2,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result2.results, SizeIs(2));
   EXPECT_THAT(num_total_hits_, Eq(2));
@@ -841,8 +934,10 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
   // by 1.
   PageResult page_result3 =
       result_retriever
-          ->RetrieveNextPage(*result_state2,
-                             fake_clock_.GetSystemTimeMilliseconds())
+          ->RetrieveNextPage(
+              *result_state2,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              fake_clock_.GetSystemTimeMilliseconds())
           .first;
   ASSERT_THAT(page_result3.results, SizeIs(1));
   EXPECT_THAT(num_total_hits_, Eq(1));
@@ -858,7 +953,7 @@ TEST_F(ResultRetrieverV2Test, ShouldUpdateNumTotalHits) {
   EXPECT_THAT(num_total_hits_, Eq(0));
 }
 
-TEST_F(ResultRetrieverV2Test, ShouldLimitNumTotalBytesPerPage) {
+TEST_P(ResultRetrieverV2Test, ShouldLimitNumTotalBytesPerPage) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
@@ -866,11 +961,15 @@ TEST_F(ResultRetrieverV2Test, ShouldLimitNumTotalBytesPerPage) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
@@ -882,7 +981,8 @@ TEST_F(ResultRetrieverV2Test, ShouldLimitNumTotalBytesPerPage) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   SearchResultProto::ResultProto result1;
   *result1.mutable_document() = CreateDocument(/*id=*/1);
@@ -906,20 +1006,22 @@ TEST_F(ResultRetrieverV2Test, ShouldLimitNumTotalBytesPerPage) {
   // num_total_bytes_per_page_threshold and ResultRetriever should terminate
   // early even though # of results is still below num_per_page.
   auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result1.results, ElementsAre(EqualsProto(result1)));
   // Has more results.
   EXPECT_TRUE(has_more_results1);
 
   // Second page, result2.
   auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result2.results, ElementsAre(EqualsProto(result2)));
   // No more results.
   EXPECT_FALSE(has_more_results2);
 }
 
-TEST_F(ResultRetrieverV2Test,
+TEST_P(ResultRetrieverV2Test,
        ShouldReturnSingleLargeResultAboveNumTotalBytesPerPageThreshold) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
@@ -928,11 +1030,15 @@ TEST_F(ResultRetrieverV2Test,
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
@@ -944,7 +1050,8 @@ TEST_F(ResultRetrieverV2Test,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   SearchResultProto::ResultProto result1;
   *result1.mutable_document() = CreateDocument(/*id=*/1);
@@ -970,21 +1077,27 @@ TEST_F(ResultRetrieverV2Test,
   // First page. Should return single result1 even though its byte size exceeds
   // num_total_bytes_per_page_threshold.
   auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result1.results, ElementsAre(EqualsProto(result1)));
   // Has more results.
   EXPECT_TRUE(has_more_results1);
 
   // Second page, result2.
   auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result2.results, ElementsAre(EqualsProto(result2)));
   // No more results.
   EXPECT_FALSE(has_more_results2);
 }
 
-TEST_F(ResultRetrieverV2Test,
+TEST_P(ResultRetrieverV2Test,
        ShouldRetrieveNextResultWhenBelowNumTotalBytesPerPageThreshold) {
+  if (feature_flags_->enable_strict_page_byte_size_limit()) {
+    GTEST_SKIP() << "Test only applies to non-strict page byte size limit.";
+  }
+
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
@@ -992,11 +1105,15 @@ TEST_F(ResultRetrieverV2Test,
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
@@ -1008,7 +1125,8 @@ TEST_F(ResultRetrieverV2Test,
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<ResultRetrieverV2> result_retriever,
       ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
-                                language_segmenter_.get(), normalizer_.get()));
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
 
   SearchResultProto::ResultProto result1;
   *result1.mutable_document() = CreateDocument(/*id=*/1);
@@ -1036,13 +1154,202 @@ TEST_F(ResultRetrieverV2Test,
   // the retrieval process and thus include result2 into this page, even though
   // finally total bytes of result1 + result2 exceed the threshold.
   auto [page_result, has_more_results] = result_retriever->RetrieveNextPage(
-      result_state, fake_clock_.GetSystemTimeMilliseconds());
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
   EXPECT_THAT(page_result.results,
               ElementsAre(EqualsProto(result1), EqualsProto(result2)));
   // No more results.
   EXPECT_FALSE(has_more_results);
 }
 
+TEST_P(ResultRetrieverV2Test,
+       ShouldNotIncludeNextResultIfExceedingNumTotalBytesPerPageThreshold) {
+  if (!feature_flags_->enable_strict_page_byte_size_limit()) {
+    GTEST_SKIP() << "Test only applies to strict page byte size limit.";
+  }
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
+                          schema_store_.get(), *feature_flags_));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
+  DocumentId document_id1 = put_result1.new_document_id;
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
+  DocumentId document_id2 = put_result2.new_document_id;
+
+  std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
+                                            GetSectionId("Email", "body")};
+  SectionIdMask hit_section_id_mask = CreateSectionIdMask(hit_section_ids);
+  std::vector<ScoredDocumentHit> scored_document_hits = {
+      {document_id1, hit_section_id_mask, /*score=*/5},
+      {document_id2, hit_section_id_mask, /*score=*/0}};
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<ResultRetrieverV2> result_retriever,
+      ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
+
+  SearchResultProto::ResultProto result1;
+  *result1.mutable_document() = CreateDocument(/*id=*/1);
+  result1.set_score(5);
+  SearchResultProto::ResultProto result2;
+  *result2.mutable_document() = CreateDocument(/*id=*/2);
+  result2.set_score(0);
+
+  // result1.ByteSizeLong() < threshold < result1.ByteSizeLong() +
+  //                                      result2.ByteSizeLong().
+  int threshold = result1.ByteSizeLong() + 1;
+  ASSERT_THAT(result1.ByteSizeLong() + result2.ByteSizeLong(), Gt(threshold));
+
+  ResultSpecProto result_spec =
+      CreateResultSpec(/*num_per_page=*/2, ResultSpecProto::NAMESPACE);
+  result_spec.set_num_total_bytes_per_page_threshold(threshold);
+  ResultStateV2 result_state(
+      std::make_unique<
+          PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+          std::move(scored_document_hits),
+          /*is_descending=*/true),
+      /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+      result_spec, *doc_store);
+
+  // After retrieving result1, total bytes are still below the threshold and #
+  // of results is still below num_per_page, so ResultRetriever should continue
+  // the retrieval process. But when serializing result2, the byte size exceeds
+  // the threshold, so result2 should not be included.
+  auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
+  EXPECT_THAT(page_result1.results, ElementsAre(EqualsProto(result1)));
+  // More results.
+  EXPECT_TRUE(has_more_results1);
+
+  // Second page. Even though result2 was evaluated in the previous round but
+  // excluded, it should not be popped from the ranker and thus should be
+  // included in the second page.
+  auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
+  EXPECT_THAT(page_result2.results, ElementsAre(EqualsProto(result2)));
+  // No more results.
+  EXPECT_FALSE(has_more_results2);
+}
+
+TEST_P(ResultRetrieverV2Test,
+       ResultGroupingShouldDecrementOnlyWhenResultIsIncludedInThePage) {
+  if (!feature_flags_->enable_strict_page_byte_size_limit()) {
+    GTEST_SKIP() << "Test only applies to non-strict page byte size limit.";
+  }
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, test_dir_, &fake_clock_,
+                          schema_store_.get(), *feature_flags_));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
+  DocumentId document_id1 = put_result1.new_document_id;
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
+  DocumentId document_id2 = put_result2.new_document_id;
+
+  std::vector<SectionId> hit_section_ids = {GetSectionId("Email", "name"),
+                                            GetSectionId("Email", "body")};
+  SectionIdMask hit_section_id_mask = CreateSectionIdMask(hit_section_ids);
+  std::vector<ScoredDocumentHit> scored_document_hits = {
+      {document_id1, hit_section_id_mask, /*score=*/5},
+      {document_id2, hit_section_id_mask, /*score=*/0}};
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<ResultRetrieverV2> result_retriever,
+      ResultRetrieverV2::Create(doc_store.get(), schema_store_.get(),
+                                language_segmenter_.get(), normalizer_.get(),
+                                feature_flags_.get()));
+
+  SearchResultProto::ResultProto result1;
+  *result1.mutable_document() = CreateDocument(/*id=*/1);
+  result1.set_score(5);
+  SearchResultProto::ResultProto result2;
+  *result2.mutable_document() = CreateDocument(/*id=*/2);
+  result2.set_score(0);
+
+  // Create a ResultSpec that limits namespace "icing" to 10 results and the
+  // total bytes per page to result1.ByteSizeLong() + 1. This will force the
+  // result retriever to move result2 to the next page.
+  ResultSpecProto result_spec =
+      CreateResultSpec(/*num_per_page=*/10, ResultSpecProto::NAMESPACE);
+  result_spec.set_num_total_bytes_per_page_threshold(result1.ByteSizeLong() +
+                                                     1);
+
+  ResultSpecProto::ResultGrouping* result_grouping =
+      result_spec.add_result_groupings();
+  ResultSpecProto::ResultGrouping::Entry* entry =
+      result_grouping->add_entry_groupings();
+  result_grouping->set_max_results(2);
+  entry->set_namespace_("icing");
+
+  // Creates a ResultState with 2 ScoredDocumentHits.
+  ResultStateV2 result_state(
+      std::make_unique<
+          PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+          std::move(scored_document_hits), /*is_descending=*/true),
+      /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+      result_spec, *doc_store);
+
+  // First page: result1 should be returned.
+  auto [page_result1, has_more_results1] = result_retriever->RetrieveNextPage(
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
+  EXPECT_THAT(page_result1.results, ElementsAre(EqualsProto(result1)));
+  // Has more results.
+  EXPECT_TRUE(has_more_results1);
+
+  // Second page: result2 should be returned.
+  auto [page_result2, has_more_results2] = result_retriever->RetrieveNextPage(
+      result_state, /*max_results=*/std::numeric_limits<int32_t>::max(),
+      fake_clock_.GetSystemTimeMilliseconds());
+  EXPECT_THAT(page_result2.results, ElementsAre(EqualsProto(result2)));
+  // No more results.
+  EXPECT_FALSE(has_more_results2);
+}
+
+INSTANTIATE_TEST_SUITE_P(
+    ResultRetrieverV2Test, ResultRetrieverV2Test,
+    testing::Values(
+        FeatureFlags(/*allow_circular_schema_definitions=*/true,
+                     /*enable_scorable_properties=*/true,
+                     /*enable_embedding_quantization=*/true,
+                     /*enable_repeated_field_joins=*/true,
+                     /*enable_embedding_backup_generation=*/true,
+                     /*enable_schema_database=*/true,
+                     /*release_backup_schema_file_if_overlay_present=*/true,
+                     /*enable_strict_page_byte_size_limit=*/false,
+                     /*enable_smaller_decompression_buffer_size=*/true,
+                     /*enable_eigen_embedding_scoring=*/true),
+        FeatureFlags(/*allow_circular_schema_definitions=*/true,
+                     /*enable_scorable_properties=*/true,
+                     /*enable_embedding_quantization=*/true,
+                     /*enable_repeated_field_joins=*/true,
+                     /*enable_embedding_backup_generation=*/true,
+                     /*enable_schema_database=*/true,
+                     /*release_backup_schema_file_if_overlay_present=*/true,
+                     /*enable_strict_page_byte_size_limit=*/true,
+                     /*enable_smaller_decompression_buffer_size=*/true,
+                     /*enable_eigen_embedding_scoring=*/true)));
+
 }  // namespace
 
 }  // namespace lib
diff --git a/icing/result/result-state-manager.cc b/icing/result/result-state-manager.cc
index 382f7db..ebd0512 100644
--- a/icing/result/result-state-manager.cc
+++ b/icing/result/result-state-manager.cc
@@ -14,18 +14,24 @@
 
 #include "icing/result/result-state-manager.h"
 
+#include <cstdint>
+#include <limits>
 #include <memory>
 #include <queue>
 #include <utility>
 
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/absl_ports/canonical_errors.h"
+#include "icing/absl_ports/mutex.h"
+#include "icing/proto/logging.pb.h"
 #include "icing/result/page-result.h"
 #include "icing/result/result-adjustment-info.h"
 #include "icing/result/result-retriever-v2.h"
 #include "icing/result/result-state-v2.h"
 #include "icing/scoring/scored-document-hits-ranker.h"
+#include "icing/store/document-store.h"
 #include "icing/util/clock.h"
 #include "icing/util/logging.h"
-#include "icing/util/status-macros.h"
 
 namespace icing {
 namespace lib {
@@ -43,7 +49,8 @@ ResultStateManager::CacheAndRetrieveFirstPage(
     std::unique_ptr<ResultAdjustmentInfo> parent_adjustment_info,
     std::unique_ptr<ResultAdjustmentInfo> child_adjustment_info,
     const ResultSpecProto& result_spec, const DocumentStore& document_store,
-    const ResultRetrieverV2& result_retriever, int64_t current_time_ms) {
+    const ResultRetrieverV2& result_retriever, int64_t current_time_ms,
+    QueryStatsProto* query_stats) {
   if (ranker == nullptr) {
     return absl_ports::InvalidArgumentError("Should not provide null ranker");
   }
@@ -56,8 +63,9 @@ ResultStateManager::CacheAndRetrieveFirstPage(
 
   // Retrieve docs outside of ResultStateManager critical section.
   // Will enter ResultState critical section inside ResultRetriever.
-  auto [page_result, has_more_results] =
-      result_retriever.RetrieveNextPage(*result_state, current_time_ms);
+  auto [page_result, has_more_results] = result_retriever.RetrieveNextPage(
+      *result_state,
+      /*max_results=*/std::numeric_limits<int32_t>::max(), current_time_ms);
   if (!has_more_results) {
     // No more pages, won't store ResultState, returns directly
     return std::make_pair(kInvalidNextPageToken, std::move(page_result));
@@ -87,7 +95,7 @@ ResultStateManager::CacheAndRetrieveFirstPage(
     InternalInvalidateExpiredResultStates(kDefaultResultStateTtlInMs,
                                           current_time_ms);
     // Remove states to make room for this new state.
-    RemoveStatesIfNeeded(num_hits_to_add);
+    RemoveStatesIfNeeded(num_hits_to_add, query_stats);
     // Generate a new unique token and add it into result_state_map_.
     next_page_token = Add(std::move(result_state), current_time_ms);
   }
@@ -107,7 +115,7 @@ uint64_t ResultStateManager::Add(std::shared_ptr<ResultStateV2> result_state,
 }
 
 libtextclassifier3::StatusOr<std::pair<uint64_t, PageResult>>
-ResultStateManager::GetNextPage(uint64_t next_page_token,
+ResultStateManager::GetNextPage(uint64_t next_page_token, int32_t max_results,
                                 const ResultRetrieverV2& result_retriever,
                                 int64_t current_time_ms) {
   std::shared_ptr<ResultStateV2> result_state = nullptr;
@@ -128,8 +136,8 @@ ResultStateManager::GetNextPage(uint64_t next_page_token,
 
   // Retrieve docs outside of ResultStateManager critical section.
   // Will enter ResultState critical section inside ResultRetriever.
-  auto [page_result, has_more_results] =
-      result_retriever.RetrieveNextPage(*result_state, current_time_ms);
+  auto [page_result, has_more_results] = result_retriever.RetrieveNextPage(
+      *result_state, max_results, current_time_ms);
 
   if (!has_more_results) {
     {
@@ -144,6 +152,14 @@ ResultStateManager::GetNextPage(uint64_t next_page_token,
   return std::make_pair(next_page_token, std::move(page_result));
 }
 
+int ResultStateManager::GetNumActiveResultStates(int64_t current_time_ms) {
+  absl_ports::unique_lock l(&mutex_);
+
+  InternalInvalidateExpiredResultStates(kDefaultResultStateTtlInMs,
+                                        current_time_ms);
+  return result_state_map_.size();
+}
+
 void ResultStateManager::InvalidateResultState(uint64_t next_page_token) {
   if (next_page_token == kInvalidNextPageToken) {
     return;
@@ -181,16 +197,17 @@ uint64_t ResultStateManager::GetUniqueToken() {
   return new_token;
 }
 
-void ResultStateManager::RemoveStatesIfNeeded(int num_hits_to_add) {
+void ResultStateManager::RemoveStatesIfNeeded(int num_hits_to_add,
+                                              QueryStatsProto* query_stats) {
   if (result_state_map_.empty() || token_queue_.empty()) {
     return;
   }
 
   // 1. Check if this new result_state would take up the entire result state
-  // manager budget.
+  //    manager budget.
   if (num_hits_to_add > max_total_hits_) {
     // This single result state will exceed our budget. Drop everything else to
-    // accomodate it.
+    // accommodate it.
     InternalInvalidateAllResultStates();
     return;
   }
@@ -204,18 +221,33 @@ void ResultStateManager::RemoveStatesIfNeeded(int num_hits_to_add) {
   }
 
   // 3. If we're over budget, remove states from oldest to newest until we fit
-  // into our budget.
+  //    into our budget.
+  //
   // Note: num_total_hits_ may not be decremented immediately after invalidating
   // a result state, since other threads may still hold the shared pointer.
   // Thus, we have to check if token_queue_ is empty or not, since it is
   // possible that num_total_hits_ is non-zero and still greater than
   // max_total_hits_ when token_queue_ is empty. Still "eventually" it will be
   // decremented after the last thread releases the shared pointer.
+  int num_states_evicted = 0;
   while (!token_queue_.empty() && num_total_hits_ > max_total_hits_) {
+    ICING_LOG(WARNING) << "Evicting result state from token_queue_ due to "
+                          "budget limit. Current num_total_hits_: "
+                       << num_total_hits_;
+
     InternalInvalidateResultState(token_queue_.front().first);
+    ++num_states_evicted;
     token_queue_.pop();
   }
   invalidated_token_set_.clear();
+  if (num_states_evicted > 0) {
+    ICING_LOG(WARNING) << "Evicted " << num_states_evicted
+                       << " states. After eviction: " << num_total_hits_
+                       << " hits and " << token_queue_.size() << " states.";
+    if (query_stats != nullptr) {
+      query_stats->set_num_result_states_evicted(num_states_evicted);
+    }
+  }
 }
 
 void ResultStateManager::InternalInvalidateResultState(uint64_t token) {
diff --git a/icing/result/result-state-manager.h b/icing/result/result-state-manager.h
index a64ae2c..b370c59 100644
--- a/icing/result/result-state-manager.h
+++ b/icing/result/result-state-manager.h
@@ -16,21 +16,25 @@
 #define ICING_RESULT_RESULT_STATE_MANAGER_H_
 
 #include <atomic>
+#include <cstdint>
 #include <memory>
 #include <queue>
 #include <random>
 #include <unordered_map>
 #include <unordered_set>
+#include <utility>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/absl_ports/mutex.h"
+#include "icing/absl_ports/thread_annotations.h"
+#include "icing/proto/logging.pb.h"
 #include "icing/proto/search.pb.h"
 #include "icing/result/page-result.h"
 #include "icing/result/result-adjustment-info.h"
 #include "icing/result/result-retriever-v2.h"
 #include "icing/result/result-state-v2.h"
 #include "icing/scoring/scored-document-hits-ranker.h"
-#include "icing/util/clock.h"
+#include "icing/store/document-store.h"
 
 namespace icing {
 namespace lib {
@@ -77,10 +81,11 @@ class ResultStateManager {
       std::unique_ptr<ResultAdjustmentInfo> parent_adjustment_info,
       std::unique_ptr<ResultAdjustmentInfo> child_adjustment_info,
       const ResultSpecProto& result_spec, const DocumentStore& document_store,
-      const ResultRetrieverV2& result_retriever, int64_t current_time_ms)
-      ICING_LOCKS_EXCLUDED(mutex_);
+      const ResultRetrieverV2& result_retriever, int64_t current_time_ms,
+      QueryStatsProto* query_stats = nullptr) ICING_LOCKS_EXCLUDED(mutex_);
 
-  // Retrieves and returns PageResult for the next page.
+  // Retrieves and returns PageResult for the next page, retrieving at most
+  // max_results entries from the page.
   // The returned results won't exist in ResultStateManager anymore. If the
   // query has no more pages after this retrieval, the input token will be
   // invalidated.
@@ -93,8 +98,15 @@ class ResultStateManager {
   //   A token and PageResult wrapped by std::pair on success
   //   NOT_FOUND if failed to find any more results
   libtextclassifier3::StatusOr<std::pair<uint64_t, PageResult>> GetNextPage(
-      uint64_t next_page_token, const ResultRetrieverV2& result_retriever,
-      int64_t current_time_ms) ICING_LOCKS_EXCLUDED(mutex_);
+      uint64_t next_page_token, int32_t max_results,
+      const ResultRetrieverV2& result_retriever, int64_t current_time_ms)
+      ICING_LOCKS_EXCLUDED(mutex_);
+
+  // Returns the number of active result states currently in ResultStateManager.
+  // Note that this will invalidate expired result states before counting the
+  // number.
+  int GetNumActiveResultStates(int64_t current_time_ms)
+      ICING_LOCKS_EXCLUDED(mutex_);
 
   // Invalidates the result state associated with the given next-page token.
   void InvalidateResultState(uint64_t next_page_token)
@@ -150,7 +162,7 @@ class ResultStateManager {
 
   // Helper method to remove old states to make room for incoming states with
   // size num_hits_to_add.
-  void RemoveStatesIfNeeded(int num_hits_to_add)
+  void RemoveStatesIfNeeded(int num_hits_to_add, QueryStatsProto* query_stats)
       ICING_EXCLUSIVE_LOCKS_REQUIRED(mutex_);
 
   // Helper method to remove a result state from result_state_map_, the token
diff --git a/icing/result/result-state-manager_test.cc b/icing/result/result-state-manager_test.cc
index 463005e..45cc0f8 100644
--- a/icing/result/result-state-manager_test.cc
+++ b/icing/result/result-state-manager_test.cc
@@ -32,6 +32,7 @@
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/embed/embedding-query-results.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/query/query-terms.h"
 #include "icing/result/page-result.h"
@@ -54,6 +55,7 @@
 #include "icing/transform/normalizer-factory.h"
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -129,20 +131,25 @@ class ResultStateManagerTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult result,
-        DocumentStore::Create(&filesystem_, test_dir_, clock_.get(),
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, clock_.get(), schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(
-        result_retriever_, ResultRetrieverV2::Create(
-                               document_store_.get(), schema_store_.get(),
-                               language_segmenter_.get(), normalizer_.get()));
+        result_retriever_,
+        ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
+                                  language_segmenter_.get(), normalizer_.get(),
+                                  feature_flags_.get()));
   }
 
   void TearDown() override {
@@ -157,10 +164,15 @@ class ResultStateManagerTest : public testing::Test {
     document.set_uri(std::to_string(document_id));
     document.set_schema("Document");
     document.set_creation_timestamp_ms(1574365086666 + document_id);
-    document_store_->Put(document);
+
+    DocumentWrapper document_wrapper;
+    *document_wrapper.mutable_document() = std::move(document);
+
+    document_store_->Put(document_wrapper);
+
     return std::make_pair(
         ScoredDocumentHit(document_id, kSectionIdMaskNone, /*score=*/1),
-        std::move(document));
+        std::move(*document_wrapper.mutable_document()));
   }
 
   std::pair<std::vector<ScoredDocumentHit>, std::vector<DocumentProto>>
@@ -207,14 +219,20 @@ class ResultStateManagerTest : public testing::Test {
 };
 
 TEST_F(ResultStateManagerTest, ShouldCacheAndRetrieveFirstPageOnePage) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store().Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store().Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store().Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits = {
       {document_id1, kSectionIdMaskNone, /*score=*/1},
@@ -249,20 +267,30 @@ TEST_F(ResultStateManagerTest, ShouldCacheAndRetrieveFirstPageOnePage) {
 }
 
 TEST_F(ResultStateManagerTest, ShouldCacheAndRetrieveFirstPageMultiplePages) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store().Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store().Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store().Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store().Put(CreateDocument(/*id=*/4)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/4))));
   DocumentId document_id4 = put_result4.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             document_store().Put(CreateDocument(/*id=*/5)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/5))));
   DocumentId document_id5 = put_result5.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits = {
       {document_id1, kSectionIdMaskNone, /*score=*/1},
@@ -298,8 +326,9 @@ TEST_F(ResultStateManagerTest, ShouldCacheAndRetrieveFirstPageMultiplePages) {
   // Second page, 2 results
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info2,
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   EXPECT_THAT(page_result_info2.first, Eq(next_page_token));
   ASSERT_THAT(page_result_info2.second.results, SizeIs(2));
   EXPECT_THAT(page_result_info2.second.results.at(0).document(),
@@ -310,8 +339,9 @@ TEST_F(ResultStateManagerTest, ShouldCacheAndRetrieveFirstPageMultiplePages) {
   // Third page, 1 result
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info3,
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   EXPECT_THAT(page_result_info3.first, Eq(kInvalidNextPageToken));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
@@ -319,8 +349,9 @@ TEST_F(ResultStateManagerTest, ShouldCacheAndRetrieveFirstPageMultiplePages) {
 
   // No results
   EXPECT_THAT(
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()),
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()),
       StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
@@ -357,11 +388,15 @@ TEST_F(ResultStateManagerTest, EmptyRankerShouldReturnEmptyFirstPage) {
 }
 
 TEST_F(ResultStateManagerTest, ShouldAllowEmptyFirstPage) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store().Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store().Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits = {
       {document_id1, kSectionIdMaskNone, /*score=*/1},
@@ -396,17 +431,25 @@ TEST_F(ResultStateManagerTest, ShouldAllowEmptyFirstPage) {
 }
 
 TEST_F(ResultStateManagerTest, ShouldAllowEmptyLastPage) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store().Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store().Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store().Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store().Put(CreateDocument(/*id=*/4)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/4))));
   DocumentId document_id4 = put_result4.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits = {
       {document_id1, kSectionIdMaskNone, /*score=*/1},
@@ -450,8 +493,9 @@ TEST_F(ResultStateManagerTest, ShouldAllowEmptyLastPage) {
   // limiter, so we should get an empty page.
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info2,
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   EXPECT_THAT(page_result_info2.first, Eq(kInvalidNextPageToken));
   EXPECT_THAT(page_result_info2.second.results, IsEmpty());
 }
@@ -518,8 +562,9 @@ TEST_F(ResultStateManagerTest,
   clock()->SetSystemTimeMilliseconds(1000);
   // page_result_info1's token (page_result_info1.first) shouldn't be found.
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
@@ -567,18 +612,21 @@ TEST_F(ResultStateManagerTest,
   // 3. Then calling GetNextPage() on state 1 shouldn't get anything.
   clock()->SetSystemTimeMilliseconds(kDefaultResultStateTtlInMs + 1000);
   // page_result_info2's token (page_result_info2.first) should be found
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info2,
-                             result_state_manager.GetNextPage(
-                                 page_result_info2.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info2,
+      result_state_manager.GetNextPage(
+          page_result_info2.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   // We test the behavior by setting time back to 2s, to make sure the
   // invalidation of state 1 was done by the previous GetNextPage() instead of
   // the following GetNextPage().
   clock()->SetSystemTimeMilliseconds(2000);
   // page_result_info1's token (page_result_info1.first) shouldn't be found.
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
@@ -611,29 +659,42 @@ TEST_F(ResultStateManagerTest,
   clock()->SetSystemTimeMilliseconds(kDefaultResultStateTtlInMs + 1000);
   // page_result_info's token (page_result_info.first) shouldn't be found.
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
 TEST_F(ResultStateManagerTest, ShouldInvalidateOneToken) {
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store().Put(CreateDocument(/*id=*/1)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/1))));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store().Put(CreateDocument(/*id=*/2)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/2))));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store().Put(CreateDocument(/*id=*/3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/3))));
   DocumentId document_id3 = put_result3.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             document_store().Put(CreateDocument(/*id=*/4)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/4))));
   DocumentId document_id4 = put_result4.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result5,
-                             document_store().Put(CreateDocument(/*id=*/5)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result5,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/5))));
   DocumentId document_id5 = put_result5.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result6,
-                             document_store().Put(CreateDocument(/*id=*/6)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result6,
+      document_store().Put(
+          document_util::CreateDocumentWrapper(CreateDocument(/*id=*/6))));
   DocumentId document_id6 = put_result6.new_document_id;
   std::vector<ScoredDocumentHit> scored_document_hits1 = {
       {document_id1, kSectionIdMaskNone, /*score=*/1},
@@ -674,15 +735,18 @@ TEST_F(ResultStateManagerTest, ShouldInvalidateOneToken) {
 
   // page_result_info1's token (page_result_info1.first) shouldn't be found
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   // page_result_info2's token (page_result_info2.first) should still exist
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info2,
-                             result_state_manager.GetNextPage(
-                                 page_result_info2.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info2,
+      result_state_manager.GetNextPage(
+          page_result_info2.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   // Should get docs.
   ASSERT_THAT(page_result_info2.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info2.second.results.at(0).document(),
@@ -724,14 +788,16 @@ TEST_F(ResultStateManagerTest, ShouldInvalidateAllTokens) {
 
   // page_result_info1's token (page_result_info1.first) shouldn't be found
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   // page_result_info2's token (page_result_info2.first) shouldn't be found
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info2.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info2.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
@@ -781,22 +847,27 @@ TEST_F(ResultStateManagerTest, ShouldRemoveOldestResultState) {
           clock()->GetSystemTimeMilliseconds()));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info2,
-                             result_state_manager.GetNextPage(
-                                 page_result_info2.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info2,
+      result_state_manager.GetNextPage(
+          page_result_info2.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info2.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info2.second.results.at(0).document(),
               EqualsProto(document_protos2.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info3,
-                             result_state_manager.GetNextPage(
-                                 page_result_info3.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info3,
+      result_state_manager.GetNextPage(
+          page_result_info3.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
               EqualsProto(document_protos3.at(1)));
@@ -872,31 +943,38 @@ TEST_F(ResultStateManagerTest,
           document_store(), result_retriever(),
           clock()->GetSystemTimeMilliseconds()));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info1,
-                             result_state_manager.GetNextPage(
-                                 page_result_info1.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info1,
+      result_state_manager.GetNextPage(
+          page_result_info1.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info1.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info1.second.results.at(0).document(),
               EqualsProto(document_protos1.at(1)));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info2.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info2.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info3,
-                             result_state_manager.GetNextPage(
-                                 page_result_info3.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info3,
+      result_state_manager.GetNextPage(
+          page_result_info3.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
               EqualsProto(document_protos3.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info4,
-                             result_state_manager.GetNextPage(
-                                 page_result_info4.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info4,
+      result_state_manager.GetNextPage(
+          page_result_info4.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info4.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info4.second.results.at(0).document(),
               EqualsProto(document_protos4.at(1)));
@@ -999,40 +1077,49 @@ TEST_F(ResultStateManagerTest,
           clock()->GetSystemTimeMilliseconds()));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info2.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info2.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info3.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info3.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info4,
-                             result_state_manager.GetNextPage(
-                                 page_result_info4.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info4,
+      result_state_manager.GetNextPage(
+          page_result_info4.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info4.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info4.second.results.at(0).document(),
               EqualsProto(document_protos4.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info5,
-                             result_state_manager.GetNextPage(
-                                 page_result_info5.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info5,
+      result_state_manager.GetNextPage(
+          page_result_info5.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info5.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info5.second.results.at(0).document(),
               EqualsProto(document_protos5.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info6,
-                             result_state_manager.GetNextPage(
-                                 page_result_info6.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info6,
+      result_state_manager.GetNextPage(
+          page_result_info6.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info6.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info6.second.results.at(0).document(),
               EqualsProto(document_protos6.at(1)));
@@ -1126,35 +1213,43 @@ TEST_F(
           clock()->GetSystemTimeMilliseconds()));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info2.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info2.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info3,
-                             result_state_manager.GetNextPage(
-                                 page_result_info3.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info3,
+      result_state_manager.GetNextPage(
+          page_result_info3.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
               EqualsProto(document_protos3.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info4,
-                             result_state_manager.GetNextPage(
-                                 page_result_info4.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info4,
+      result_state_manager.GetNextPage(
+          page_result_info4.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info4.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info4.second.results.at(0).document(),
               EqualsProto(document_protos4.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info5,
-                             result_state_manager.GetNextPage(
-                                 page_result_info5.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info5,
+      result_state_manager.GetNextPage(
+          page_result_info5.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info5.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info5.second.results.at(0).document(),
               EqualsProto(document_protos5.at(1)));
@@ -1211,10 +1306,12 @@ TEST_F(ResultStateManagerTest, GetNextPageShouldDecreaseCurrentHitsCount) {
 
   // GetNextPage for result state 1 should return its result and decrement the
   // number of cached hits to 2.
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info1,
-                             result_state_manager.GetNextPage(
-                                 page_result_info1.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info1,
+      result_state_manager.GetNextPage(
+          page_result_info1.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info1.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info1.second.results.at(0).document(),
               EqualsProto(document_protos1.at(1)));
@@ -1236,30 +1333,37 @@ TEST_F(ResultStateManagerTest, GetNextPageShouldDecreaseCurrentHitsCount) {
           clock()->GetSystemTimeMilliseconds()));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info2,
-                             result_state_manager.GetNextPage(
-                                 page_result_info2.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info2,
+      result_state_manager.GetNextPage(
+          page_result_info2.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info2.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info2.second.results.at(0).document(),
               EqualsProto(document_protos2.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info3,
-                             result_state_manager.GetNextPage(
-                                 page_result_info3.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info3,
+      result_state_manager.GetNextPage(
+          page_result_info3.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
               EqualsProto(document_protos3.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info4,
-                             result_state_manager.GetNextPage(
-                                 page_result_info4.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info4,
+      result_state_manager.GetNextPage(
+          page_result_info4.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info4.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info4.second.results.at(0).document(),
               EqualsProto(document_protos4.at(1)));
@@ -1317,10 +1421,12 @@ TEST_F(ResultStateManagerTest,
 
   // GetNextPage for result state 1 should return its result and decrement the
   // number of cached hits to 2.
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info1,
-                             result_state_manager.GetNextPage(
-                                 page_result_info1.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info1,
+      result_state_manager.GetNextPage(
+          page_result_info1.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info1.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info1.second.results.at(0).document(),
               EqualsProto(document_protos1.at(1)));
@@ -1358,35 +1464,43 @@ TEST_F(ResultStateManagerTest,
           clock()->GetSystemTimeMilliseconds()));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info2.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info2.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info3,
-                             result_state_manager.GetNextPage(
-                                 page_result_info3.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info3,
+      result_state_manager.GetNextPage(
+          page_result_info3.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
               EqualsProto(document_protos3.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info4,
-                             result_state_manager.GetNextPage(
-                                 page_result_info4.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info4,
+      result_state_manager.GetNextPage(
+          page_result_info4.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info4.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info4.second.results.at(0).document(),
               EqualsProto(document_protos4.at(1)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info5,
-                             result_state_manager.GetNextPage(
-                                 page_result_info5.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info5,
+      result_state_manager.GetNextPage(
+          page_result_info5.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info5.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info5.second.results.at(0).document(),
               EqualsProto(document_protos5.at(1)));
@@ -1435,6 +1549,7 @@ TEST_F(ResultStateManagerTest,
   auto [scored_document_hits3, document_protos3] = AddScoredDocuments(
       {/*document_id=*/5, /*document_id=*/6, /*document_id=*/7,
        /*document_id=*/8, /*document_id=*/9, /*document_id=*/10});
+  QueryStatsProto query_stats;
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info3,
       result_state_manager.CacheAndRetrieveFirstPage(
@@ -1444,26 +1559,32 @@ TEST_F(ResultStateManagerTest,
           /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
           CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
           document_store(), result_retriever(),
-          clock()->GetSystemTimeMilliseconds()));
+          clock()->GetSystemTimeMilliseconds(), &query_stats));
   EXPECT_THAT(page_result_info3.first, Not(Eq(kInvalidNextPageToken)));
+  // Should set num_result_states_evicted since result state 1 and 2 were
+  // evicted.
+  EXPECT_THAT(query_stats.num_result_states_evicted(), Eq(2));
 
   // GetNextPage for result state 1 and 2 should return NOT_FOUND.
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info2.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info2.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
   // Only the next four results in state 3 should be retrievable.
   uint64_t next_page_token3 = page_result_info3.first;
   ICING_ASSERT_OK_AND_ASSIGN(
       page_result_info3,
-      result_state_manager.GetNextPage(next_page_token3, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token3, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   EXPECT_THAT(page_result_info3.first, Eq(next_page_token3));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
@@ -1471,8 +1592,9 @@ TEST_F(ResultStateManagerTest,
 
   ICING_ASSERT_OK_AND_ASSIGN(
       page_result_info3,
-      result_state_manager.GetNextPage(next_page_token3, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token3, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   EXPECT_THAT(page_result_info3.first, Eq(next_page_token3));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
@@ -1480,8 +1602,9 @@ TEST_F(ResultStateManagerTest,
 
   ICING_ASSERT_OK_AND_ASSIGN(
       page_result_info3,
-      result_state_manager.GetNextPage(next_page_token3, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token3, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   EXPECT_THAT(page_result_info3.first, Eq(next_page_token3));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
@@ -1489,8 +1612,9 @@ TEST_F(ResultStateManagerTest,
 
   ICING_ASSERT_OK_AND_ASSIGN(
       page_result_info3,
-      result_state_manager.GetNextPage(next_page_token3, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token3, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   // The final document should have been dropped because it exceeded the budget,
   // so the next page token of the second last round should be
   // kInvalidNextPageToken.
@@ -1501,8 +1625,9 @@ TEST_F(ResultStateManagerTest,
 
   // Double check that next_page_token3 is not retrievable anymore.
   EXPECT_THAT(
-      result_state_manager.GetNextPage(next_page_token3, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()),
+      result_state_manager.GetNextPage(
+          next_page_token3, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()),
       StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
@@ -1545,14 +1670,17 @@ TEST_F(ResultStateManagerTest,
 
   // state1 should have been evicted and state2 should still be retrievable.
   EXPECT_THAT(result_state_manager.GetNextPage(
-                  page_result_info1.first, result_retriever(),
-                  clock()->GetSystemTimeMilliseconds()),
+                  page_result_info1.first,
+                  /*max_results=*/std::numeric_limits<int32_t>::max(),
+                  result_retriever(), clock()->GetSystemTimeMilliseconds()),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  ICING_ASSERT_OK_AND_ASSIGN(page_result_info2,
-                             result_state_manager.GetNextPage(
-                                 page_result_info2.first, result_retriever(),
-                                 clock()->GetSystemTimeMilliseconds()));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      page_result_info2,
+      result_state_manager.GetNextPage(
+          page_result_info2.first,
+          /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info2.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info2.second.results.at(0).document(),
               EqualsProto(document_protos2.at(1)));
@@ -1596,8 +1724,9 @@ TEST_F(ResultStateManagerTest,
   // Second page, 2 results.
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info2,
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info2.second.results, SizeIs(2));
   EXPECT_THAT(page_result_info2.second.results.at(0).document(),
               EqualsProto(document_protos.at(2)));
@@ -1607,19 +1736,128 @@ TEST_F(ResultStateManagerTest,
   // Third page, 1 result.
   ICING_ASSERT_OK_AND_ASSIGN(
       PageResultInfo page_result_info3,
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()));
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()));
   ASSERT_THAT(page_result_info3.second.results, SizeIs(1));
   EXPECT_THAT(page_result_info3.second.results.at(0).document(),
               EqualsProto(document_protos.at(4)));
 
   // Fourth page, 0 results.
   EXPECT_THAT(
-      result_state_manager.GetNextPage(next_page_token, result_retriever(),
-                                       clock()->GetSystemTimeMilliseconds()),
+      result_state_manager.GetNextPage(
+          next_page_token, /*max_results=*/std::numeric_limits<int32_t>::max(),
+          result_retriever(), clock()->GetSystemTimeMilliseconds()),
       StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 }
 
+TEST_F(ResultStateManagerTest, GetNumActiveResultStates) {
+  auto [scored_document_hits1, document_protos1] = AddScoredDocuments(
+      {/*document_id=*/0, /*document_id=*/1, /*document_id=*/2});
+  auto [scored_document_hits2, document_protos2] = AddScoredDocuments(
+      {/*document_id=*/3, /*document_id=*/4, /*document_id=*/5});
+  auto [scored_document_hits3, document_protos3] = AddScoredDocuments(
+      {/*document_id=*/6, /*document_id=*/7, /*document_id=*/8});
+
+  ResultStateManager result_state_manager(
+      /*max_total_hits=*/std::numeric_limits<int>::max(), document_store());
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      PageResultInfo page_result_info1,
+      result_state_manager.CacheAndRetrieveFirstPage(
+          std::make_unique<
+              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+              std::move(scored_document_hits1), /*is_descending=*/true),
+          /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+          CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
+          document_store(), result_retriever(),
+          clock()->GetSystemTimeMilliseconds()));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      PageResultInfo page_result_info2,
+      result_state_manager.CacheAndRetrieveFirstPage(
+          std::make_unique<
+              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+              std::move(scored_document_hits2), /*is_descending=*/true),
+          /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+          CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
+          document_store(), result_retriever(),
+          clock()->GetSystemTimeMilliseconds()));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      PageResultInfo page_result_info3,
+      result_state_manager.CacheAndRetrieveFirstPage(
+          std::make_unique<
+              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+              std::move(scored_document_hits3), /*is_descending=*/true),
+          /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+          CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
+          document_store(), result_retriever(),
+          clock()->GetSystemTimeMilliseconds()));
+
+  EXPECT_THAT(result_state_manager.GetNumActiveResultStates(
+                  /*current_time_ms=*/clock()->GetSystemTimeMilliseconds()),
+              Eq(3));
+}
+
+TEST_F(ResultStateManagerTest,
+       GetNumActiveResultStatesShouldInvalidateExpiredResultStates) {
+  auto [scored_document_hits1, document_protos1] = AddScoredDocuments(
+      {/*document_id=*/0, /*document_id=*/1, /*document_id=*/2});
+  auto [scored_document_hits2, document_protos2] = AddScoredDocuments(
+      {/*document_id=*/3, /*document_id=*/4, /*document_id=*/5});
+  auto [scored_document_hits3, document_protos3] = AddScoredDocuments(
+      {/*document_id=*/6, /*document_id=*/7, /*document_id=*/8});
+
+  ResultStateManager result_state_manager(
+      /*max_total_hits=*/std::numeric_limits<int>::max(), document_store());
+
+  // Set time as 1s and add state.
+  clock()->SetSystemTimeMilliseconds(1000);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      PageResultInfo page_result_info1,
+      result_state_manager.CacheAndRetrieveFirstPage(
+          std::make_unique<
+              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+              std::move(scored_document_hits1), /*is_descending=*/true),
+          /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+          CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
+          document_store(), result_retriever(),
+          clock()->GetSystemTimeMilliseconds()));
+
+  // Set time as 10s and add state 2, state 3.
+  clock()->SetSystemTimeMilliseconds(10000);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      PageResultInfo page_result_info2,
+      result_state_manager.CacheAndRetrieveFirstPage(
+          std::make_unique<
+              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+              std::move(scored_document_hits2), /*is_descending=*/true),
+          /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+          CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
+          document_store(), result_retriever(),
+          clock()->GetSystemTimeMilliseconds()));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      PageResultInfo page_result_info3,
+      result_state_manager.CacheAndRetrieveFirstPage(
+          std::make_unique<
+              PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>>(
+              std::move(scored_document_hits3), /*is_descending=*/true),
+          /*parent_adjustment_info=*/nullptr, /*child_adjustment_info=*/nullptr,
+          CreateResultSpec(/*num_per_page=*/1, ResultSpecProto::NAMESPACE),
+          document_store(), result_retriever(),
+          clock()->GetSystemTimeMilliseconds()));
+
+  // 1. Set time as 1hr1s.
+  // 2. Then calling GetNumActiveResultStates() should invalidate state 1 and
+  //    return 2.
+  clock()->SetSystemTimeMilliseconds(kDefaultResultStateTtlInMs + 1000);
+  EXPECT_THAT(result_state_manager.GetNumActiveResultStates(
+                  /*current_time_ms=*/clock()->GetSystemTimeMilliseconds()),
+              Eq(2));
+}
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/result/result-state-manager_thread-safety_test.cc b/icing/result/result-state-manager_thread-safety_test.cc
index 5578c54..fd82de5 100644
--- a/icing/result/result-state-manager_thread-safety_test.cc
+++ b/icing/result/result-state-manager_thread-safety_test.cc
@@ -17,8 +17,13 @@
 #include <limits>
 #include <memory>
 #include <optional>
+#include <string>
 #include <thread>  // NOLINT
+#include <utility>
+#include <vector>
 
+#include "icing/text_classifier/lib3/utils/base/status.h"
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/document-builder.h"
@@ -26,11 +31,15 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
+#include "icing/portable/platform.h"
 #include "icing/result/page-result.h"
 #include "icing/result/result-retriever-v2.h"
 #include "icing/result/result-state-manager.h"
 #include "icing/schema/schema-store.h"
+#include "icing/schema/section.h"
 #include "icing/scoring/priority-queue-scored-document-hits-ranker.h"
+#include "icing/scoring/scored-document-hit.h"
 #include "icing/store/document-store.h"
 #include "icing/testing/common-matchers.h"
 #include "icing/testing/fake-clock.h"
@@ -38,10 +47,10 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
+#include "icing/tokenization/language-segmenter.h"
 #include "icing/transform/normalizer-factory.h"
 #include "icing/transform/normalizer-options.h"
 #include "icing/transform/normalizer.h"
-#include "icing/util/clock.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -61,14 +70,17 @@ ResultSpecProto CreateResultSpec(int num_per_page) {
   return result_spec;
 }
 
-DocumentProto CreateDocument(int document_id) {
-  return DocumentBuilder()
-      .SetNamespace("namespace")
-      .SetUri(std::to_string(document_id))
-      .SetSchema("Document")
-      .SetCreationTimestampMs(1574365086666 + document_id)
-      .SetScore(document_id)
-      .Build();
+DocumentWrapper CreateDocument(int document_id) {
+  DocumentWrapper document_wrapper;
+  *document_wrapper.mutable_document() =
+      DocumentBuilder()
+          .SetNamespace("namespace")
+          .SetUri(std::to_string(document_id))
+          .SetSchema("Document")
+          .SetCreationTimestampMs(1574365086666 + document_id)
+          .SetScore(document_id)
+          .Build();
+  return document_wrapper;
 }
 
 class ResultStateManagerThreadSafetyTest : public testing::Test {
@@ -109,20 +121,25 @@ class ResultStateManagerThreadSafetyTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult result,
-        DocumentStore::Create(&filesystem_, test_dir_, clock_.get(),
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, test_dir_, clock_.get(), schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(result.document_store);
 
     ICING_ASSERT_OK_AND_ASSIGN(
-        result_retriever_, ResultRetrieverV2::Create(
-                               document_store_.get(), schema_store_.get(),
-                               language_segmenter_.get(), normalizer_.get()));
+        result_retriever_,
+        ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
+                                  language_segmenter_.get(), normalizer_.get(),
+                                  feature_flags_.get()));
   }
 
   void TearDown() override {
@@ -194,12 +211,14 @@ TEST_F(ResultStateManagerThreadSafetyTest,
     ICING_ASSERT_OK_AND_ASSIGN(
         std::unique_ptr<ResultRetrieverV2> result_retriever,
         ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                  language_segmenter_.get(),
-                                  normalizer_.get()));
+                                  language_segmenter_.get(), normalizer_.get(),
+                                  feature_flags_.get()));
     ICING_ASSERT_OK_AND_ASSIGN(
         PageResultInfo page_result_info,
-        result_state_manager.GetNextPage(next_page_token, *result_retriever,
-                                         clock_->GetSystemTimeMilliseconds()));
+        result_state_manager.GetNextPage(
+            next_page_token,
+            /*max_results=*/std::numeric_limits<int32_t>::max(),
+            *result_retriever, clock_->GetSystemTimeMilliseconds()));
     page_results[thread_id] =
         std::make_optional<PageResultInfo>(std::move(page_result_info));
   };
@@ -297,12 +316,14 @@ TEST_F(ResultStateManagerThreadSafetyTest, InvalidateResultStateWhileUsing) {
     ICING_ASSERT_OK_AND_ASSIGN(
         std::unique_ptr<ResultRetrieverV2> result_retriever,
         ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                  language_segmenter_.get(),
-                                  normalizer_.get()));
+                                  language_segmenter_.get(), normalizer_.get(),
+                                  feature_flags_.get()));
 
     libtextclassifier3::StatusOr<PageResultInfo> page_result_info_or =
-        result_state_manager.GetNextPage(next_page_token, *result_retriever,
-                                         clock_->GetSystemTimeMilliseconds());
+        result_state_manager.GetNextPage(
+            next_page_token,
+            /*max_results=*/std::numeric_limits<int32_t>::max(),
+            *result_retriever, clock_->GetSystemTimeMilliseconds());
     if (page_result_info_or.ok()) {
       page_results[thread_id] = std::make_optional<PageResultInfo>(
           std::move(page_result_info_or).ValueOrDie());
@@ -392,8 +413,8 @@ TEST_F(ResultStateManagerThreadSafetyTest, MultipleResultStates) {
     ICING_ASSERT_OK_AND_ASSIGN(
         std::unique_ptr<ResultRetrieverV2> result_retriever,
         ResultRetrieverV2::Create(document_store_.get(), schema_store_.get(),
-                                  language_segmenter_.get(),
-                                  normalizer_.get()));
+                                  language_segmenter_.get(), normalizer_.get(),
+                                  feature_flags_.get()));
 
     // Retrieve the first page.
     // Documents are ordered by score *ascending*, so the first page should
@@ -428,10 +449,12 @@ TEST_F(ResultStateManagerThreadSafetyTest, MultipleResultStates) {
     // each thread should retrieve 1, 2, 3, ..., kNumThreads pages.
     int num_subsequent_pages_to_retrieve = thread_id;
     for (int i = 0; i < num_subsequent_pages_to_retrieve; ++i) {
-      ICING_ASSERT_OK_AND_ASSIGN(PageResultInfo page_result_info,
-                                 result_state_manager.GetNextPage(
-                                     next_page_token, *result_retriever,
-                                     clock_->GetSystemTimeMilliseconds()));
+      ICING_ASSERT_OK_AND_ASSIGN(
+          PageResultInfo page_result_info,
+          result_state_manager.GetNextPage(
+              next_page_token,
+              /*max_results=*/std::numeric_limits<int32_t>::max(),
+              *result_retriever, clock_->GetSystemTimeMilliseconds()));
       EXPECT_THAT(page_result_info.second.results, SizeIs(kNumPerPage));
       for (int j = 0; j < kNumPerPage; ++j) {
         EXPECT_THAT(page_result_info.second.results[j].score(),
diff --git a/icing/result/result-state-v2.cc b/icing/result/result-state-v2.cc
index 3aa9359..e7248bf 100644
--- a/icing/result/result-state-v2.cc
+++ b/icing/result/result-state-v2.cc
@@ -17,7 +17,8 @@
 #include <atomic>
 #include <cstdint>
 #include <memory>
-#include <string>
+#include <optional>
+#include <utility>
 #include <vector>
 
 #include "icing/proto/search.pb.h"
@@ -50,15 +51,12 @@ ResultStateV2::ResultStateV2(
     group_result_limits.push_back(result_grouping.max_results());
     for (const ResultSpecProto::ResultGrouping::Entry& entry :
          result_grouping.entry_groupings()) {
-      const std::string& name_space = entry.namespace_();
-      const std::string& schema = entry.schema();
-      auto entry_id_or = document_store.GetResultGroupingEntryId(
-          result_group_type_, name_space, schema);
-      if (!entry_id_or.ok()) {
+      std::optional<int32_t> entry_id = document_store.GetResultGroupingEntryId(
+          result_group_type_, entry.namespace_(), entry.schema());
+      if (!entry_id.has_value()) {
         continue;
       }
-      int32_t entry_id = entry_id_or.ValueOrDie();
-      entry_id_group_id_map_.insert({entry_id, group_id});
+      entry_id_group_id_map_.insert({*entry_id, group_id});
     }
   }
 }
diff --git a/icing/result/result-state-v2_test.cc b/icing/result/result-state-v2_test.cc
index 6b8b4bd..fb3dea4 100644
--- a/icing/result/result-state-v2_test.cc
+++ b/icing/result/result-state-v2_test.cc
@@ -25,9 +25,11 @@
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/absl_ports/mutex.h"
+#include "icing/document-builder.h"
 #include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/document_wrapper.pb.h"
 #include "icing/proto/schema.pb.h"
@@ -79,14 +81,18 @@ class ResultStateV2Test : public ::testing::Test {
     filesystem_.CreateDirectoryRecursively(doc_store_base_dir_.c_str());
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult result,
-        DocumentStore::Create(&filesystem_, doc_store_base_dir_, &clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_base_dir_, &clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(result.document_store);
 
     num_total_hits_ = 0;
@@ -102,7 +108,11 @@ class ResultStateV2Test : public ::testing::Test {
     document.set_namespace_("namespace");
     document.set_uri(std::to_string(document_id));
     document.set_schema("Document");
-    document_store_->Put(std::move(document));
+
+    DocumentWrapper document_wrapper;
+    *document_wrapper.mutable_document() = std::move(document);
+
+    document_store_->Put(document_wrapper);
     return ScoredDocumentHit(document_id, kSectionIdMaskNone, /*score=*/1);
   }
 
@@ -177,23 +187,29 @@ TEST_F(ResultStateV2Test, ShouldInitializeValuesAccordingToDefaultSpecs) {
 TEST_F(ResultStateV2Test,
        ShouldConstructNamespaceGroupIdMapAndGroupResultLimitsAccordingToSpecs) {
   // Create 3 docs under namespace1, namespace2, namespace3.
-  DocumentProto document1;
-  document1.set_namespace_("namespace1");
-  document1.set_uri("uri/1");
-  document1.set_schema("Document");
-  ICING_ASSERT_OK(document_store().Put(std::move(document1)));
-
-  DocumentProto document2;
-  document2.set_namespace_("namespace2");
-  document2.set_uri("uri/2");
-  document2.set_schema("Document");
-  ICING_ASSERT_OK(document_store().Put(std::move(document2)));
-
-  DocumentProto document3;
-  document3.set_namespace_("namespace3");
-  document3.set_uri("uri/3");
-  document3.set_schema("Document");
-  ICING_ASSERT_OK(document_store().Put(std::move(document3)));
+  DocumentWrapper document_wrapper1;
+  *document_wrapper1.mutable_document() = DocumentBuilder()
+                                              .SetNamespace("namespace1")
+                                              .SetUri("uri/1")
+                                              .SetSchema("Document")
+                                              .Build();
+  ICING_ASSERT_OK(document_store().Put(document_wrapper1));
+
+  DocumentWrapper document_wrapper2;
+  *document_wrapper2.mutable_document() = DocumentBuilder()
+                                              .SetNamespace("namespace2")
+                                              .SetUri("uri/2")
+                                              .SetSchema("Document")
+                                              .Build();
+  ICING_ASSERT_OK(document_store().Put(document_wrapper2));
+
+  DocumentWrapper document_wrapper3;
+  *document_wrapper3.mutable_document() = DocumentBuilder()
+                                              .SetNamespace("namespace3")
+                                              .SetUri("uri/3")
+                                              .SetSchema("Document")
+                                              .Build();
+  ICING_ASSERT_OK(document_store().Put(document_wrapper3));
 
   // Create a ResultSpec that limits "namespace1" to 3 results and limits
   // "namespace2"+"namespace3" to a total of 2 results. Also add
@@ -222,13 +238,13 @@ TEST_F(ResultStateV2Test,
   entry->set_namespace_("nonexistentNamespace1");
 
   // Get entry ids.
-  ICING_ASSERT_OK_AND_ASSIGN(
+  ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
       int32_t entry_id1, document_store().GetResultGroupingEntryId(
                              result_grouping_type, "namespace1", "Document"));
-  ICING_ASSERT_OK_AND_ASSIGN(
+  ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
       int32_t entry_id2, document_store().GetResultGroupingEntryId(
                              result_grouping_type, "namespace2", "Document"));
-  ICING_ASSERT_OK_AND_ASSIGN(
+  ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
       int32_t entry_id3, document_store().GetResultGroupingEntryId(
                              result_grouping_type, "namespace3", "Document"));
 
diff --git a/icing/schema/backup-schema-producer_test.cc b/icing/schema/backup-schema-producer_test.cc
index d0f609c..40f810f 100644
--- a/icing/schema/backup-schema-producer_test.cc
+++ b/icing/schema/backup-schema-producer_test.cc
@@ -952,14 +952,20 @@ INSTANTIATE_TEST_SUITE_P(
                      /*enable_repeated_field_joins=*/true,
                      /*enable_embedding_backup_generation=*/false,
                      /*enable_schema_database=*/true,
-                     /*release_backup_schema_file_if_overlay_present=*/true),
+                     /*release_backup_schema_file_if_overlay_present=*/true,
+                     /*enable_strict_page_byte_size=*/true,
+                     /*enable_smaller_decompression_buffer_size=*/true,
+                     /*enable_eigen_embedding_scoring=*/true),
         FeatureFlags(/*allow_circular_schema_definitions=*/true,
                      /*enable_scorable_properties=*/true,
                      /*enable_embedding_quantization=*/true,
                      /*enable_repeated_field_joins=*/true,
                      /*enable_embedding_backup_generation=*/true,
                      /*enable_schema_database=*/true,
-                     /*release_backup_schema_file_if_overlay_present=*/true)));
+                     /*release_backup_schema_file_if_overlay_present=*/true,
+                     /*enable_strict_page_byte_size=*/true,
+                     /*enable_smaller_decompression_buffer_size=*/true,
+                     /*enable_eigen_embedding_scoring=*/true)));
 
 }  // namespace
 
diff --git a/icing/schema/schema-store.cc b/icing/schema/schema-store.cc
index dda7746..2c7654b 100644
--- a/icing/schema/schema-store.cc
+++ b/icing/schema/schema-store.cc
@@ -141,7 +141,7 @@ std::string GetDatabaseFromSchemaType(const std::string& schema_type,
   size_t db_index = schema_type.find(database_delimeter);
   std::string database;
   if (db_index != std::string::npos) {
-    database = schema_type.substr(0, db_index);
+    database = schema_type.substr(0, db_index + 1);
   }
   return database;
 }
@@ -222,24 +222,32 @@ SchemaStore::Header::Read(const Filesystem* filesystem, std::string path) {
   int64_t file_size = filesystem->GetFileSize(sfd.get());
   if (file_size == sizeof(LegacyHeader)) {
     LegacyHeader legacy_header;
-    if (!filesystem->Read(sfd.get(), &legacy_header, sizeof(legacy_header))) {
+    if (filesystem->Read(sfd.get(), &legacy_header, sizeof(legacy_header)) !=
+        sizeof(legacy_header)) {
       return absl_ports::InternalError(
           absl_ports::StrCat("Couldn't read: ", path));
     }
     if (legacy_header.magic != Header::kMagic) {
+      ICING_LOG(ERROR)
+          << "Invalid legacy header magic for SchemaStore. Expected: "
+          << Header::kMagic << ", actual: " << legacy_header.magic;
       return absl_ports::InternalError(
-          absl_ports::StrCat("Invalid header kMagic for file: ", path));
+          "Invalid legacy header magic for SchemaStore");
     }
     serialized_header.checksum = legacy_header.checksum;
   } else if (file_size == sizeof(SerializedHeader)) {
-    if (!filesystem->Read(sfd.get(), &serialized_header,
-                          sizeof(serialized_header))) {
+    if (filesystem->Read(sfd.get(), &serialized_header,
+                         sizeof(serialized_header)) !=
+        sizeof(serialized_header)) {
       return absl_ports::InternalError(
           absl_ports::StrCat("Couldn't read: ", path));
     }
     if (serialized_header.magic != Header::kMagic) {
+      ICING_LOG(ERROR)
+          << "Invalid serialized header magic for SchemaStore. Expected: "
+          << Header::kMagic << ", actual: " << serialized_header.magic;
       return absl_ports::InternalError(
-          absl_ports::StrCat("Invalid header kMagic for file: ", path));
+          "Invalid serialized header magic for SchemaStore");
     }
   } else if (file_size != 0) {
     // file is neither the legacy header, the new header nor empty. Something is
@@ -558,9 +566,10 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   bool overlay_schema_file_exists =
       filesystem_->FileExists(overlay_schema_filename.c_str());
 
+  // The base schema file will be released at a later point (if necessary),
+  // after InitializeInternal is done.
   libtextclassifier3::Status base_schema_state = schema_file_.Read().status();
   if (!base_schema_state.ok() && !absl_ports::IsNotFound(base_schema_state)) {
-    ResetSchemaFileIfNeeded();
     return base_schema_state;
   }
 
@@ -568,7 +577,6 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   // 1. Everything is missing. This is an empty schema store.
   if (!base_schema_state.ok() && !overlay_schema_file_exists &&
       !header_exists) {
-    ResetSchemaFileIfNeeded();
     return libtextclassifier3::Status::OK;
   }
 
@@ -577,7 +585,6 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   if (base_schema_state.ok() && !overlay_schema_file_exists && header_exists &&
       !header_->overlay_created()) {
     // Nothing else to do. Just return safely.
-    ResetSchemaFileIfNeeded();
     return libtextclassifier3::Status::OK;
   }
 
@@ -587,7 +594,6 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
       header_->overlay_created()) {
     overlay_schema_file_ = std::make_unique<FileBackedProto<SchemaProto>>(
         *filesystem_, MakeOverlaySchemaFilename(base_dir_));
-    ResetSchemaFileIfNeeded();
     return libtextclassifier3::Status::OK;
   }
 
@@ -595,7 +601,6 @@ libtextclassifier3::Status SchemaStore::LoadSchema() {
   // Return an error.
   bool overlay_created = header_->overlay_created();
   bool base_schema_exists = base_schema_state.ok();
-  ResetSchemaFileIfNeeded();
   return absl_ports::InternalError(IcingStringUtil::StringPrintf(
       "Unable to properly load schema. Header {exists:%d, overlay_created:%d}, "
       "base schema exists: %d, overlay_schema_exists: %d",
@@ -625,6 +630,7 @@ libtextclassifier3::Status SchemaStore::InitializeInternal(
     initialize_stats->set_num_schema_types(type_config_map_.size());
   }
   has_schema_successfully_set_ = true;
+  ResetSchemaFileIfNeeded();
 
   return libtextclassifier3::Status::OK;
 }
@@ -694,7 +700,6 @@ libtextclassifier3::Status SchemaStore::RegenerateDerivedFiles(
 
   // Write the header
   ICING_RETURN_IF_ERROR(UpdateChecksum());
-  ResetSchemaFileIfNeeded();
   return libtextclassifier3::Status::OK;
 }
 
@@ -780,7 +785,8 @@ libtextclassifier3::StatusOr<Crc32> SchemaStore::GetChecksum() const {
   // schema (both of which will have a checksum of 0). For existing, but empty
   // schemas, we need to continue with the checksum calculation of the other
   // components.
-  if (schema_checksum == Crc32() && !has_schema_successfully_set_) {
+  if (schema_checksum == Crc32() &&
+      absl_ports::IsNotFound(schema_file_.Read().status())) {
     return schema_checksum;
   }
 
@@ -805,7 +811,8 @@ libtextclassifier3::StatusOr<Crc32> SchemaStore::UpdateChecksum() {
   // schema (both of which will have a checksum of 0). For existing, but empty
   // schemas, we need to continue with the checksum calculation of the other
   // components.
-  if (schema_checksum == Crc32() && !has_schema_successfully_set_) {
+  if (schema_checksum == Crc32() &&
+      absl_ports::IsNotFound(schema_file_.Read().status())) {
     return schema_checksum;
   }
   Crc32 total_checksum;
@@ -875,7 +882,8 @@ SchemaStore::SetSchema(SetSchemaRequestProto&& set_schema_request) {
   bool ignore_errors_and_delete_documents =
       set_schema_request.ignore_errors_and_delete_documents();
 
-  if (feature_flags_->enable_schema_database()) {
+  if (feature_flags_->enable_schema_database() &&
+      !set_schema_request.database().empty()) {
     // Step 1: (Only required if schema database is enabled)
     // Do some preliminary checks on the new schema before formal validation and
     // delta computation. This checks that:
@@ -951,6 +959,7 @@ SchemaStore::SetInitialSchemaForDatabase(
       GetFullSchemaProtoWithUpdatedDb(std::move(new_schema), database));
   ICING_RETURN_IF_ERROR(ApplySchemaChange(std::move(full_new_schema)));
   has_schema_successfully_set_ = true;
+  ResetSchemaFileIfNeeded();
 
   return result;
 }
@@ -1059,6 +1068,7 @@ SchemaStore::SetSchemaWithDatabaseOverride(
   if (result.success) {
     ICING_RETURN_IF_ERROR(ApplySchemaChange(std::move(full_new_schema)));
     has_schema_successfully_set_ = true;
+    ResetSchemaFileIfNeeded();
   }
 
   // Convert schema types to SchemaTypeIds after the new schema is applied.
@@ -1111,6 +1121,12 @@ libtextclassifier3::Status SchemaStore::ApplySchemaChange(
       SchemaStore::Create(filesystem_, temp_schema_store_dir.dir(), clock_,
                           feature_flags_, std::move(new_schema)));
 
+  // Call PersistToDisk() to write the new schema file to disk. This is needed
+  // to ensure that all subcomponents of the new schema store (header file,
+  // derived files, etc) are written to disk before we swap the files in the
+  // next step.
+  ICING_RETURN_IF_ERROR(new_schema_store->PersistToDisk());
+
   // Then we swap the new schema file + new derived files with the old files.
   if (!filesystem_->SwapFiles(base_dir_.c_str(),
                               temp_schema_store_dir.dir().c_str())) {
@@ -1121,12 +1137,13 @@ libtextclassifier3::Status SchemaStore::ApplySchemaChange(
   std::string old_base_dir = std::move(base_dir_);
   *this = std::move(*new_schema_store);
 
-  // After the std::move, the filepaths saved in this instance and in the
-  // schema_file_ instance will still be the one from temp_schema_store_dir
-  // even though they now point to files that are within old_base_dir.
-  // Manually set them to the correct paths.
+  // After the std::move, the filepaths saved in this instance, the header_ and
+  // in the schema_file_ instance will still be the one from
+  // temp_schema_store_dir even though they now point to files that are within
+  // old_base_dir. Manually set them to the correct paths.
   base_dir_ = std::move(old_base_dir);
   schema_file_.SetSwappedFilepath(MakeSchemaFilename(base_dir_));
+  header_->SetSwappedFilepath(MakeHeaderFilename(base_dir_));
   if (overlay_schema_file_ != nullptr) {
     overlay_schema_file_->SetSwappedFilepath(
         MakeOverlaySchemaFilename(base_dir_));
@@ -1417,7 +1434,8 @@ SchemaStore::ConstructBlobPropertyMap() const {
 
 libtextclassifier3::Status SchemaStore::ValidateSchemaDatabase(
     const SchemaProto& new_schema, const std::string& database) const {
-  if (!feature_flags_->enable_schema_database() || new_schema.types().empty()) {
+  if (!feature_flags_->enable_schema_database() || new_schema.types().empty() ||
+      database.empty()) {
     return libtextclassifier3::Status::OK;
   }
 
@@ -1456,9 +1474,10 @@ libtextclassifier3::StatusOr<SchemaProto>
 SchemaStore::GetFullSchemaProtoWithUpdatedDb(
     SchemaProto input_database_schema,
     const std::string& database_to_update) const {
-  if (!feature_flags_->enable_schema_database()) {
-    // If the schema database is not enabled, the input schema is already the
-    // full schema, so we don't need to do any merges.
+  if (!feature_flags_->enable_schema_database() || database_to_update.empty()) {
+    // The schema database is not enabled, or we're updating using the empty
+    // schema database. This means that the input schema is already the full
+    // schema, so we don't need to do any merges.
     return input_database_schema;
   }
 
diff --git a/icing/schema/schema-store.h b/icing/schema/schema-store.h
index b5d89ce..6995a97 100644
--- a/icing/schema/schema-store.h
+++ b/icing/schema/schema-store.h
@@ -157,6 +157,8 @@ class SchemaStore {
           min_overlay_version_compatibility;
     }
 
+    void SetSwappedFilepath(std::string path) { path_ = std::move(path); }
+
    private:
     explicit Header(SerializedHeader serialized_header, std::string path,
                     ScopedFd header_fd, const Filesystem* filesystem)
@@ -253,8 +255,6 @@ class SchemaStore {
 
   static constexpr std::string_view kSchemaTypeWildcard = "*";
 
-  static constexpr std::string_view kDefaultEmptySchemaDatabase = "";
-
   // Factory function to create a SchemaStore which does not take ownership
   // of any input components, and all pointers must refer to valid objects that
   // outlive the created SchemaStore instance. The base_dir must already exist.
@@ -329,18 +329,22 @@ class SchemaStore {
   // `SetSchema(SetSchemaRequestProto&& set_schema_request)` instead.
   //
   // TODO: b/337913932 - Remove this method once all callers (currently only
-  // used in tests) are migrated to the new SetSchema method.
+  // used in tests) are migrated to the new SetSchema method that takes a
+  // SetSchemaRequestProto.
   libtextclassifier3::StatusOr<SetSchemaResult> SetSchema(
       SchemaProto new_schema, bool ignore_errors_and_delete_documents);
 
   // Update our current schema if it's compatible. Does not accept incompatible
-  // schema or schema with types from multiple databases. Compatibility rules
-  // defined by SchemaUtil::ComputeCompatibilityDelta.
+  // schema or schema subsets with types from multiple databases. Compatibility
+  // rules defined by SchemaUtil::ComputeCompatibilityDelta.
   //
-  // Does not support setting the schema across multiple databases if
-  // `feature_flags_->enable_schema_database()` is true. This means that:
-  // - All types within the new schema must have their `database` field matching
-  //  `set_schema_request.database()`.
+  // This method accepts either a full schema (indicated by an empty database
+  // field) or a schema subset with types from a single database.
+  // - If `set_schema_request.database()` is non-empty, then all types in the
+  //   new schema must have their `database` field matching
+  //   `set_schema_request.database()`.
+  // - If `set_schema_request.database()` is empty, then the new schema will be
+  //   taken as the full schema, and will replace the entire existing schema.
   //
   // If ignore_errors_and_delete_documents is set to true, then incompatible
   // schema are allowed and we'll force set the schema, meaning
@@ -763,6 +767,7 @@ class SchemaStore {
   // Requires:
   //   - `new_schema` and `database` are valid according to
   //     `ValidateSchemaDatabase(new_schema, database)`
+  //   - `database` is not empty.
   //   - Types in `new_schema` and `old_schema` all belong to the provided
   //     database.
   //     - The old schema is guaranteed to contain types from exactly one
diff --git a/icing/schema/schema-store_test.cc b/icing/schema/schema-store_test.cc
index 4993408..f83fb32 100644
--- a/icing/schema/schema-store_test.cc
+++ b/icing/schema/schema-store_test.cc
@@ -620,65 +620,66 @@ TEST_F(SchemaStoreTest, SetNewSchemaInDifferentDatabaseOk) {
                           feature_flags_.get(),
                           /*initialize_stats=*/nullptr));
 
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
 
   // Set a schema in a different database
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the full schema. Databases that are updated last are appended to the
   // schema proto
-  SchemaProto expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
+  SchemaProto expected_full_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/email")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/message")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .Build();
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               IsOkAndHolds(EqualsProto(db2_schema)));
 }
 
@@ -732,6 +733,175 @@ TEST_F(SchemaStoreTest, SetEmptyDatabaseSchemaOk) {
   EXPECT_THAT(schema_store->GetSchema(""), IsOkAndHolds(EqualsProto(schema)));
 }
 
+TEST_F(SchemaStoreTest, SetSchemaWithEmptyDatabaseResetsEntireSchema) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
+                          feature_flags_.get()));
+
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("email"))
+          .AddType(SchemaTypeConfigBuilder().SetType("message"))
+          .Build();
+  SchemaStore::SetSchemaResult result;
+  result.success = true;
+  result.schema_types_new_by_name.insert("email");
+  result.schema_types_new_by_name.insert("message");
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+  EXPECT_THAT(schema_store->GetSchema(""), IsOkAndHolds(EqualsProto(schema)));
+
+  // Reset the schema using an empty database. This should ignore the
+  // database field in the schema type configs and reset the entire schema.
+  schema = SchemaBuilder()
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db1/email_v1")
+                            .SetDatabase("db1/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db1/message_v1")
+                            .SetDatabase("db1/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db2/email_v2")
+                            .SetDatabase("db2/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db2/message_v2")
+                            .SetDatabase("db2/"))
+               .Build();
+  result = SchemaStore::SetSchemaResult();
+  result.success = true;
+  result.schema_types_new_by_name.insert("db1/email_v1");
+  result.schema_types_new_by_name.insert("db1/message_v1");
+  result.schema_types_new_by_name.insert("db2/email_v2");
+  result.schema_types_new_by_name.insert("db2/message_v2");
+  result.schema_types_deleted_by_name.insert("email");
+  result.schema_types_deleted_by_name.insert("message");
+  result.schema_types_deleted_by_id.insert(0);
+  result.schema_types_deleted_by_id.insert(1);
+
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"",
+                  /*ignore_errors_and_delete_documents=*/true)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+
+  // The empty database should be replaced by db1/ and db2/.
+  EXPECT_THAT(schema_store->GetSchema(""),
+              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
+  EXPECT_THAT(
+      schema_store->GetSchema("db1/"),
+      IsOkAndHolds(EqualsProto(SchemaBuilder()
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db1/email_v1")
+                                                .SetDatabase("db1/"))
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db1/message_v1")
+                                                .SetDatabase("db1/"))
+                                   .Build())));
+  EXPECT_THAT(
+      schema_store->GetSchema("db2/"),
+      IsOkAndHolds(EqualsProto(SchemaBuilder()
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db2/email_v2")
+                                                .SetDatabase("db2/"))
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db2/message_v2")
+                                                .SetDatabase("db2/"))
+                                   .Build())));
+}
+
+TEST_F(SchemaStoreTest, SetSchemaWithUnpopulatedDatabaseResetsEntireSchema) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
+                          feature_flags_.get()));
+
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("email"))
+          .AddType(SchemaTypeConfigBuilder().SetType("message"))
+          .Build();
+  SchemaStore::SetSchemaResult result;
+  result.success = true;
+  result.schema_types_new_by_name.insert("email");
+  result.schema_types_new_by_name.insert("message");
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+  EXPECT_THAT(schema_store->GetSchema(""), IsOkAndHolds(EqualsProto(schema)));
+
+  schema = SchemaBuilder()
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db1/email_v1")
+                            .SetDatabase("db1/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db1/message_v1")
+                            .SetDatabase("db1/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db2/email_v2")
+                            .SetDatabase("db2/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db2/message_v2")
+                            .SetDatabase("db2/"))
+               .Build();
+  result = SchemaStore::SetSchemaResult();
+  result.success = true;
+  result.schema_types_new_by_name.insert("db1/email_v1");
+  result.schema_types_new_by_name.insert("db1/message_v1");
+  result.schema_types_new_by_name.insert("db2/email_v2");
+  result.schema_types_new_by_name.insert("db2/message_v2");
+  result.schema_types_deleted_by_name.insert("email");
+  result.schema_types_deleted_by_name.insert("message");
+  result.schema_types_deleted_by_id.insert(0);
+  result.schema_types_deleted_by_id.insert(1);
+
+  // Reset the schema without populating the database field in the
+  // SetSchemaRequestProto. This should ignore the database field in the schema
+  // type configs and reset the entire schema.
+  SetSchemaRequestProto set_schema_request;
+  *set_schema_request.mutable_schema() = schema;
+  set_schema_request.clear_database();
+  set_schema_request.set_ignore_errors_and_delete_documents(
+      /*ignore_errors_and_delete_documents=*/true);
+
+  EXPECT_THAT(schema_store->SetSchema(std::move(set_schema_request)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+
+  // The empty database should be replaced by db1/ and db2/.
+  EXPECT_THAT(schema_store->GetSchema(""),
+              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
+  EXPECT_THAT(
+      schema_store->GetSchema("db1/"),
+      IsOkAndHolds(EqualsProto(SchemaBuilder()
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db1/email_v1")
+                                                .SetDatabase("db1/"))
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db1/message_v1")
+                                                .SetDatabase("db1/"))
+                                   .Build())));
+  EXPECT_THAT(
+      schema_store->GetSchema("db2/"),
+      IsOkAndHolds(EqualsProto(SchemaBuilder()
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db2/email_v2")
+                                                .SetDatabase("db2/"))
+                                   .AddType(SchemaTypeConfigBuilder()
+                                                .SetType("db2/message_v2")
+                                                .SetDatabase("db2/"))
+                                   .Build())));
+}
+
 TEST_F(SchemaStoreTest, SetSameSchemaOk) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
@@ -767,49 +937,50 @@ TEST_F(SchemaStoreTest, SetSameDatabaseSchemaOk) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto expected_full_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/email")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/message")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .Build();
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
@@ -820,16 +991,16 @@ TEST_F(SchemaStoreTest, SetSameDatabaseSchemaOk) {
   result = SchemaStore::SetSchemaResult();
   result.success = true;
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               IsOkAndHolds(EqualsProto(db2_schema)));
 }
 
@@ -841,74 +1012,76 @@ TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesNoChange) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto db3_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
-  SchemaProto expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto db3_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/email")
+                                            .SetDatabase("db3/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/message")
+                                            .SetDatabase("db3/"))
+                               .Build();
+  SchemaProto expected_full_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/email")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/message")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db3/email")
+                                                      .SetDatabase("db3/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db3/message")
+                                                      .SetDatabase("db3/"))
+                                         .Build();
 
   // Set schema for db1
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db3_email");
-  result.schema_types_new_by_name.insert("db3_message");
+  result.schema_types_new_by_name.insert("db3/email");
+  result.schema_types_new_by_name.insert("db3/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db3_schema, /*database=*/"db3",
+                  db3_schema, /*database=*/"db3/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Verify schema.
@@ -918,20 +1091,20 @@ TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesNoChange) {
 
   // Reset db2 with the types reordered. This should not change the existing
   // schema in any way.
-  SchemaProto reordered_db2_schema =
-      SchemaBuilder()
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .Build();
+  SchemaProto reordered_db2_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
 
   libtextclassifier3::StatusOr<SchemaStore::SetSchemaResult> actual_result =
       schema_store->SetSchema(CreateSetSchemaRequestProto(
-          reordered_db2_schema, /*database=*/"db2",
+          reordered_db2_schema, /*database=*/"db2/",
           /*ignore_errors_and_delete_documents=*/false));
   EXPECT_THAT(actual_result, IsOkAndHolds(EqualsSetSchemaResult(result)));
   EXPECT_THAT(actual_result.ValueOrDie().old_schema_type_ids_changed,
@@ -940,16 +1113,16 @@ TEST_F(SchemaStoreTest, SetDatabaseReorderedTypesNoChange) {
   // Check the schema
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
 
   libtextclassifier3::StatusOr<SchemaProto> actual_db2_schema =
-      schema_store->GetSchema("db2");
+      schema_store->GetSchema("db2/");
   EXPECT_THAT(actual_db2_schema, IsOkAndHolds(EqualsProto(db2_schema)));
   EXPECT_THAT(actual_db2_schema.ValueOrDie(),
               Not(EqualsProto(reordered_db2_schema)));
 
-  EXPECT_THAT(schema_store->GetSchema("db3"),
+  EXPECT_THAT(schema_store->GetSchema("db3/"),
               IsOkAndHolds(EqualsProto(db3_schema)));
 }
 
@@ -961,74 +1134,76 @@ TEST_F(SchemaStoreTest, SetDatabaseAddedTypesPreservesSchemaTypeIds) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto db3_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
-  SchemaProto expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto db3_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/email")
+                                            .SetDatabase("db3/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/message")
+                                            .SetDatabase("db3/"))
+                               .Build();
+  SchemaProto expected_full_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/email")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/message")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db3/email")
+                                                      .SetDatabase("db3/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db3/message")
+                                                      .SetDatabase("db3/"))
+                                         .Build();
 
   // Set schema for db1
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db3_email");
-  result.schema_types_new_by_name.insert("db3_message");
+  result.schema_types_new_by_name.insert("db3/email");
+  result.schema_types_new_by_name.insert("db3/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db3_schema, /*database=*/"db3",
+                  db3_schema, /*database=*/"db3/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Verify schema.
@@ -1042,58 +1217,58 @@ TEST_F(SchemaStoreTest, SetDatabaseAddedTypesPreservesSchemaTypeIds) {
   // Whether or not the SchemaTypeIds for db2 change depends on the order in the
   // new db2 SchemaProto (in this case, existing type's order and ids do not
   // change)
-  db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_recipient")
-                       .SetDatabase("db2"))
-          .Build();
+  db2_schema = SchemaBuilder()
+                   .AddType(SchemaTypeConfigBuilder()
+                                .SetType("db2/email")
+                                .SetDatabase("db2/"))
+                   .AddType(SchemaTypeConfigBuilder()
+                                .SetType("db2/message")
+                                .SetDatabase("db2/"))
+                   .AddType(SchemaTypeConfigBuilder()
+                                .SetType("db2/recipient")
+                                .SetDatabase("db2/"))
+                   .Build();
   expected_full_schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()  // db1 types
-                       .SetType("db1_email")
-                       .SetDatabase("db1"))
+                       .SetType("db1/email")
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
+                       .SetType("db1/message")
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()  // db2 types
-                       .SetType("db2_email")
-                       .SetDatabase("db2"))
+                       .SetType("db2/email")
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
+                       .SetType("db2/message")
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()  // db3 types
-                       .SetType("db3_email")
-                       .SetDatabase("db3"))
+                       .SetType("db3/email")
+                       .SetDatabase("db3/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
+                       .SetType("db3/message")
+                       .SetDatabase("db3/"))
           .AddType(SchemaTypeConfigBuilder()  // Additional db2 type is appended
                                               // at the end
-                       .SetType("db2_recipient")
-                       .SetDatabase("db2"))
+                       .SetType("db2/recipient")
+                       .SetDatabase("db2/"))
           .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_recipient");
+  result.schema_types_new_by_name.insert("db2/recipient");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               IsOkAndHolds(EqualsProto(db2_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db3"),
+  EXPECT_THAT(schema_store->GetSchema("db3/"),
               IsOkAndHolds(EqualsProto(db3_schema)));
 }
 
@@ -1105,101 +1280,101 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto db3_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto db3_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/email")
+                                            .SetDatabase("db3/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/message")
+                                            .SetDatabase("db3/"))
+                               .Build();
 
   // Set schema for db1
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db3_email");
-  result.schema_types_new_by_name.insert("db3_message");
+  result.schema_types_new_by_name.insert("db3/email");
+  result.schema_types_new_by_name.insert("db3/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db3_schema, /*database=*/"db3",
+                  db3_schema, /*database=*/"db3/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema again for db2 and add a type. The added type should be appended
   // to the end of the SchemaProto.
-  db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_recipient")
-                       .SetDatabase("db2"))
-          .Build();
+  db2_schema = SchemaBuilder()
+                   .AddType(SchemaTypeConfigBuilder()
+                                .SetType("db2/email")
+                                .SetDatabase("db2/"))
+                   .AddType(SchemaTypeConfigBuilder()
+                                .SetType("db2/message")
+                                .SetDatabase("db2/"))
+                   .AddType(SchemaTypeConfigBuilder()
+                                .SetType("db2/recipient")
+                                .SetDatabase("db2/"))
+                   .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_recipient");
+  result.schema_types_new_by_name.insert("db2/recipient");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   SchemaProto expected_full_schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_email")  // SchemaTypeId 0
-                       .SetDatabase("db1"))
+                       .SetType("db1/email")  // SchemaTypeId 0
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")  // SchemaTypeId 1
-                       .SetDatabase("db1"))
+                       .SetType("db1/message")  // SchemaTypeId 1
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_email")  // SchemaTypeId 2
-                       .SetDatabase("db2"))
+                       .SetType("db2/email")  // SchemaTypeId 2
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")  // SchemaTypeId 3
-                       .SetDatabase("db2"))
+                       .SetType("db2/message")  // SchemaTypeId 3
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_email")  // SchemaTypeId 4
-                       .SetDatabase("db3"))
+                       .SetType("db3/email")  // SchemaTypeId 4
+                       .SetDatabase("db3/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")  // SchemaTypeId 5
-                       .SetDatabase("db3"))
+                       .SetType("db3/message")  // SchemaTypeId 5
+                       .SetDatabase("db3/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_recipient")  // SchemaTypeId 6
-                       .SetDatabase("db2"))
+                       .SetType("db2/recipient")  // SchemaTypeId 6
+                       .SetDatabase("db2/"))
           .Build();
   // Verify schema.
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
@@ -1210,53 +1385,53 @@ TEST_F(SchemaStoreTest, SetDatabaseDeletedTypesOk) {
   // db2 should have their type ids changed.
   db2_schema = SchemaBuilder()
                    .AddType(SchemaTypeConfigBuilder()
-                                .SetType("db2_message")
-                                .SetDatabase("db2"))
+                                .SetType("db2/message")
+                                .SetDatabase("db2/"))
                    .Build();
   expected_full_schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_email")  // SchemaTypeId 0
-                       .SetDatabase("db1"))
+                       .SetType("db1/email")  // SchemaTypeId 0
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")  // SchemaTypeId 1
-                       .SetDatabase("db1"))
+                       .SetType("db1/message")  // SchemaTypeId 1
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")  // SchemaTypeId 2
-                       .SetDatabase("db2"))
+                       .SetType("db2/message")  // SchemaTypeId 2
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_email")  // SchemaTypeId 3
-                       .SetDatabase("db3"))
+                       .SetType("db3/email")  // SchemaTypeId 3
+                       .SetDatabase("db3/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")  // SchemaTypeId 4
-                       .SetDatabase("db3"))
+                       .SetType("db3/message")  // SchemaTypeId 4
+                       .SetDatabase("db3/"))
           .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_deleted_by_name.insert("db2_email");
-  result.schema_types_deleted_by_name.insert("db2_recipient");
+  result.schema_types_deleted_by_name.insert("db2/email");
+  result.schema_types_deleted_by_name.insert("db2/recipient");
   result.schema_types_deleted_by_id.insert(2);   // db2_email
   result.schema_types_deleted_by_id.insert(6);   // db2_recipient
   result.old_schema_type_ids_changed.insert(3);  // db2_message
   result.old_schema_type_ids_changed.insert(4);  // db3_email
   result.old_schema_type_ids_changed.insert(5);  // db3_message
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/true)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               IsOkAndHolds(EqualsProto(db2_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db3"),
+  EXPECT_THAT(schema_store->GetSchema("db3/"),
               IsOkAndHolds(EqualsProto(db3_schema)));
 }
 
-TEST_F(SchemaStoreTest, SetEmptySchemaClearsDatabase) {
+TEST_F(SchemaStoreTest, SetEmptySchemaOk) {
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<SchemaStore> schema_store,
       SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
@@ -1264,79 +1439,127 @@ TEST_F(SchemaStoreTest, SetEmptySchemaClearsDatabase) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto db3_schema =
+  SchemaProto schema =
       SchemaBuilder()
           .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
+              SchemaTypeConfigBuilder().SetType("db/email").SetDatabase("db/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
+                       .SetType("db/message")
+                       .SetDatabase("db/"))
           .Build();
+  SchemaStore::SetSchemaResult result;
+  result.success = true;
+  result.schema_types_new_by_name.insert("db/email");
+  result.schema_types_new_by_name.insert("db/message");
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  schema, /*database=*/"db/",
+                  /*ignore_errors_and_delete_documents=*/false)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+
+  // Verify schema.
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(schema))));
+
+  // Reset to an empty schema.
+  result = SchemaStore::SetSchemaResult();
+  result.success = true;
+  result.schema_types_deleted_by_name.insert("db/email");
+  result.schema_types_deleted_by_name.insert("db/message");
+  result.schema_types_deleted_by_id.insert(0);  // email
+  result.schema_types_deleted_by_id.insert(1);  // message
+  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
+                  SchemaProto(), /*database=*/"db/",
+                  /*ignore_errors_and_delete_documents=*/true)),
+              IsOkAndHolds(EqualsSetSchemaResult(result)));
+
+  // Check the schema. It should be empty.
+  EXPECT_THAT(schema_store->GetSchema(),
+              IsOkAndHolds(Pointee(EqualsProto(SchemaProto()))));
+
+  EXPECT_THAT(schema_store->PersistToDisk(), IsOk());
+}
+
+TEST_F(SchemaStoreTest, SetEmptySchemaClearsDatabase) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir_, &fake_clock_,
+                          feature_flags_.get(),
+                          /*initialize_stats=*/nullptr));
+
+  // Set schema for the first time
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto db3_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/email")
+                                            .SetDatabase("db3/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db3/message")
+                                            .SetDatabase("db3/"))
+                               .Build();
 
   // Set schema for db1
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db2
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Set schema for db3
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db3_email");
-  result.schema_types_new_by_name.insert("db3_message");
+  result.schema_types_new_by_name.insert("db3/email");
+  result.schema_types_new_by_name.insert("db3/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db3_schema, /*database=*/"db3",
+                  db3_schema, /*database=*/"db3/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   // Verify schema.
   SchemaProto expected_full_schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_email")  // SchemaTypeId 0
-                       .SetDatabase("db1"))
+                       .SetType("db1/email")  // SchemaTypeId 0
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")  // SchemaTypeId 1
-                       .SetDatabase("db1"))
+                       .SetType("db1/message")  // SchemaTypeId 1
+                       .SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_email")  // SchemaTypeId 2
-                       .SetDatabase("db2"))
+                       .SetType("db2/email")  // SchemaTypeId 2
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")  // SchemaTypeId 3
-                       .SetDatabase("db2"))
+                       .SetType("db2/message")  // SchemaTypeId 3
+                       .SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_email")  // SchemaTypeId 4
-                       .SetDatabase("db3"))
+                       .SetType("db3/email")  // SchemaTypeId 4
+                       .SetDatabase("db3/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")  // SchemaTypeId 5
-                       .SetDatabase("db3"))
+                       .SetType("db3/message")  // SchemaTypeId 5
+                       .SetDatabase("db3/"))
           .Build();
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
@@ -1347,40 +1570,41 @@ TEST_F(SchemaStoreTest, SetEmptySchemaClearsDatabase) {
   db2_schema = SchemaProto();
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_deleted_by_name.insert("db2_email");
-  result.schema_types_deleted_by_name.insert("db2_message");
+  result.schema_types_deleted_by_name.insert("db2/email");
+  result.schema_types_deleted_by_name.insert("db2/message");
   result.schema_types_deleted_by_id.insert(2);   // db2_email
   result.schema_types_deleted_by_id.insert(3);   // db2_message
   result.old_schema_type_ids_changed.insert(4);  // db3_email
   result.old_schema_type_ids_changed.insert(5);  // db3_message
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/true)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema. Schemas for db1 and db3 should be unchanged.
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db3"),
+  EXPECT_THAT(schema_store->GetSchema("db3/"),
               IsOkAndHolds(EqualsProto(db3_schema)));
 
   // GetSchema for db2 should return NotFoundError
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
 
-  expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db3_email").SetDatabase("db3"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db3_message")
-                       .SetDatabase("db3"))
-          .Build();
+  expected_full_schema = SchemaBuilder()
+                             .AddType(SchemaTypeConfigBuilder()
+                                          .SetType("db1/email")
+                                          .SetDatabase("db1/"))
+                             .AddType(SchemaTypeConfigBuilder()
+                                          .SetType("db1/message")
+                                          .SetDatabase("db1/"))
+                             .AddType(SchemaTypeConfigBuilder()
+                                          .SetType("db3/email")
+                                          .SetDatabase("db3/"))
+                             .AddType(SchemaTypeConfigBuilder()
+                                          .SetType("db3/message")
+                                          .SetDatabase("db3/"))
+                             .Build();
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
 }
@@ -1423,49 +1647,50 @@ TEST_F(SchemaStoreTest, SetIncompatibleInDifferentDatabaseOk) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto expected_full_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/email")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/message")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .Build();
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
@@ -1475,28 +1700,29 @@ TEST_F(SchemaStoreTest, SetIncompatibleInDifferentDatabaseOk) {
   // Make db2 incompatible by changing a type name
   SchemaProto db2_schema_incompatible =
       SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_recipient")
-                       .SetDatabase("db2"))
+                       .SetType("db2/email")
+                       .SetDatabase("db2/"))
+          .AddType(SchemaTypeConfigBuilder()
+                       .SetType("db2/recipient")
+                       .SetDatabase("db2/"))
           .Build();
   result = SchemaStore::SetSchemaResult();
   result.success = false;
-  result.schema_types_deleted_by_name.insert("db2_message");
-  result.schema_types_new_by_name.insert("db2_recipient");
+  result.schema_types_deleted_by_name.insert("db2/message");
+  result.schema_types_new_by_name.insert("db2/recipient");
   result.schema_types_deleted_by_id.insert(3);  // db2_message
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema_incompatible, /*database=*/"db2",
+                  db2_schema_incompatible, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
 
   // Check the schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               IsOkAndHolds(EqualsProto(db2_schema)));
 }
 
@@ -1508,49 +1734,50 @@ TEST_F(SchemaStoreTest, SetInvalidInDifferentDatabaseFails) {
                           /*initialize_stats=*/nullptr));
 
   // Set schema for the first time
-  SchemaProto db1_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
-  SchemaProto db2_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  SchemaProto expected_full_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
+  SchemaProto db1_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/email")
+                                            .SetDatabase("db1/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db1/message")
+                                            .SetDatabase("db1/"))
+                               .Build();
+  SchemaProto db2_schema = SchemaBuilder()
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/email")
+                                            .SetDatabase("db2/"))
+                               .AddType(SchemaTypeConfigBuilder()
+                                            .SetType("db2/message")
+                                            .SetDatabase("db2/"))
+                               .Build();
+  SchemaProto expected_full_schema = SchemaBuilder()
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/email")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db1/message")
+                                                      .SetDatabase("db1/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/email")
+                                                      .SetDatabase("db2/"))
+                                         .AddType(SchemaTypeConfigBuilder()
+                                                      .SetType("db2/message")
+                                                      .SetDatabase("db2/"))
+                                         .Build();
   SchemaStore::SetSchemaResult result;
   result.success = true;
-  result.schema_types_new_by_name.insert("db1_email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/email");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   result = SchemaStore::SetSchemaResult();
   result.success = true;
-  result.schema_types_new_by_name.insert("db2_email");
-  result.schema_types_new_by_name.insert("db2_message");
+  result.schema_types_new_by_name.insert("db2/email");
+  result.schema_types_new_by_name.insert("db2/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   ICING_ASSERT_OK_AND_ASSIGN(const SchemaProto* actual_full_schema,
@@ -1566,23 +1793,23 @@ TEST_F(SchemaStoreTest, SetInvalidInDifferentDatabaseFails) {
           .Build();
   SchemaProto db2_schema_incompatible = SchemaBuilder()
                                             .AddType(SchemaTypeConfigBuilder()
-                                                         .SetType("db2_email")
-                                                         .SetDatabase("db2")
+                                                         .SetType("db2/email")
+                                                         .SetDatabase("db2/")
                                                          .AddProperty(prop)
                                                          .AddProperty(prop))
                                             .Build();
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
                   db2_schema_incompatible,
-                  /*database=*/"db2",
+                  /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::ALREADY_EXISTS));
 
   // Check the schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(expected_full_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
-  EXPECT_THAT(schema_store->GetSchema("db2"),
+  EXPECT_THAT(schema_store->GetSchema("db2/"),
               IsOkAndHolds(EqualsProto(db2_schema)));
 }
 
@@ -1593,21 +1820,22 @@ TEST_F(SchemaStoreTest, SetSchemaWithMultipleDbFails) {
                           feature_flags_.get(),
                           /*initialize_stats=*/nullptr));
 
-  SchemaProto combined_schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
+  SchemaProto combined_schema = SchemaBuilder()
+                                    .AddType(SchemaTypeConfigBuilder()
+                                                 .SetType("db2/email")
+                                                 .SetDatabase("db2/"))
+                                    .AddType(SchemaTypeConfigBuilder()
+                                                 .SetType("db2/message")
+                                                 .SetDatabase("db2/"))
+                                    .AddType(SchemaTypeConfigBuilder()
+                                                 .SetType("db1/email")
+                                                 .SetDatabase("db1/"))
+                                    .AddType(SchemaTypeConfigBuilder()
+                                                 .SetType("db1/message")
+                                                 .SetDatabase("db1/"))
+                                    .Build();
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  combined_schema, /*database=*/"db1",
+                  combined_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
@@ -1623,47 +1851,29 @@ TEST_F(SchemaStoreTest, SetSchemaWithMismatchedDbFails) {
       SchemaBuilder()
           // This type does not explicitly set its database, so it defaults to
           // the empty database.
-          .AddType(SchemaTypeConfigBuilder().SetType("db1_email"))
+          .AddType(SchemaTypeConfigBuilder().SetType("db1/email"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
+                       .SetType("db1/message")
+                       .SetDatabase("db1/"))
           .Build();
 
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  schema, /*database=*/"db1",
+                  schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 
-  schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .Build();
+  schema = SchemaBuilder()
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db1/email")
+                            .SetDatabase("db1/"))
+               .AddType(SchemaTypeConfigBuilder()
+                            .SetType("db1/message")
+                            .SetDatabase("db1/"))
+               .Build();
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
                   schema, /*database=*/"db_mismatch",
                   /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
-
-  schema =
-      SchemaBuilder()
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db1_email").SetDatabase("db1"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
-          .AddType(
-              SchemaTypeConfigBuilder().SetType("db2_email").SetDatabase("db2"))
-          .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
-          .Build();
-  EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  schema, /*database=*/"",
-                  /*ignore_errors_and_delete_documents=*/false)),
-              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
 }
 
 TEST_F(SchemaStoreTest, SetSchemaWithDuplicateTypeNameAcrossDifferentDbFails) {
@@ -1677,42 +1887,42 @@ TEST_F(SchemaStoreTest, SetSchemaWithDuplicateTypeNameAcrossDifferentDbFails) {
   SchemaProto db1_schema =
       SchemaBuilder()
           .AddType(
-              SchemaTypeConfigBuilder().SetType("email").SetDatabase("db1"))
+              SchemaTypeConfigBuilder().SetType("email").SetDatabase("db1/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db1_message")
-                       .SetDatabase("db1"))
+                       .SetType("db1/message")
+                       .SetDatabase("db1/"))
           .Build();
   SchemaStore::SetSchemaResult result;
   result.success = true;
   result.schema_types_new_by_name.insert("email");
-  result.schema_types_new_by_name.insert("db1_message");
+  result.schema_types_new_by_name.insert("db1/message");
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db1_schema, /*database=*/"db1",
+                  db1_schema, /*database=*/"db1/",
                   /*ignore_errors_and_delete_documents=*/false)),
               IsOkAndHolds(EqualsSetSchemaResult(result)));
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
 
   // Set schema in db2 with the same type name
   SchemaProto db2_schema =
       SchemaBuilder()
           .AddType(
-              SchemaTypeConfigBuilder().SetType("email").SetDatabase("db2"))
+              SchemaTypeConfigBuilder().SetType("email").SetDatabase("db2/"))
           .AddType(SchemaTypeConfigBuilder()
-                       .SetType("db2_message")
-                       .SetDatabase("db2"))
+                       .SetType("db2/message")
+                       .SetDatabase("db2/"))
           .Build();
   EXPECT_THAT(schema_store->SetSchema(CreateSetSchemaRequestProto(
-                  db2_schema, /*database=*/"db2",
+                  db2_schema, /*database=*/"db2/",
                   /*ignore_errors_and_delete_documents=*/false)),
               StatusIs(libtextclassifier3::StatusCode::ALREADY_EXISTS));
 
   // Check schema, this should not have changed
   EXPECT_THAT(schema_store->GetSchema(),
               IsOkAndHolds(Pointee(EqualsProto(db1_schema))));
-  EXPECT_THAT(schema_store->GetSchema("db1"),
+  EXPECT_THAT(schema_store->GetSchema("db1/"),
               IsOkAndHolds(EqualsProto(db1_schema)));
 }
 
@@ -4967,7 +5177,7 @@ TEST_P(SchemaStoreTestWithParam, MigrateSchemaWithDatabaseMigration) {
   SchemaTypeConfigProto db1_email_rfc =
       SchemaTypeConfigBuilder()
           .SetType("db1/email")
-          .SetDatabase("db1")
+          .SetDatabase("db1/")
           .AddProperty(
               PropertyConfigBuilder()
                   .SetName("db1Subject")
@@ -4977,7 +5187,7 @@ TEST_P(SchemaStoreTestWithParam, MigrateSchemaWithDatabaseMigration) {
   SchemaTypeConfigProto db1_email_no_rfc =
       SchemaTypeConfigBuilder()
           .SetType("db1/email")
-          .SetDatabase("db1")
+          .SetDatabase("db1/")
           .AddProperty(PropertyConfigBuilder()
                            .SetName("db1Subject")
                            .SetCardinality(CARDINALITY_OPTIONAL)
@@ -4986,7 +5196,7 @@ TEST_P(SchemaStoreTestWithParam, MigrateSchemaWithDatabaseMigration) {
   SchemaTypeConfigProto db2_email =
       SchemaTypeConfigBuilder()
           .SetType("db2/email")
-          .SetDatabase("db2")
+          .SetDatabase("db2/")
           .AddProperty(PropertyConfigBuilder()
                            .SetName("db2Subject")
                            .SetDataTypeString(TERM_MATCH_EXACT, TOKENIZER_PLAIN)
@@ -5019,41 +5229,41 @@ TEST_P(SchemaStoreTestWithParam, MigrateSchemaWithDatabaseMigration) {
       EXPECT_THAT(
           schema_store->GetSchema(),
           IsOkAndHolds(Pointee(EqualsProto(full_schema_with_database_no_rfc))));
-      EXPECT_THAT(schema_store->GetSchema("db1"),
+      EXPECT_THAT(schema_store->GetSchema("db1/"),
                   IsOkAndHolds(EqualsProto(db1_schema_no_rfc)));
-      EXPECT_THAT(schema_store->GetSchema("db2"),
+      EXPECT_THAT(schema_store->GetSchema("db2/"),
                   IsOkAndHolds(EqualsProto(db2_schema)));
     } else {
       EXPECT_THAT(
           schema_store->GetSchema(),
           IsOkAndHolds(Pointee(EqualsProto(full_schema_with_database_rfc))));
-      EXPECT_THAT(schema_store->GetSchema("db1"),
+      EXPECT_THAT(schema_store->GetSchema("db1/"),
                   IsOkAndHolds(EqualsProto(db1_schema_rfc)));
-      EXPECT_THAT(schema_store->GetSchema("db2"),
+      EXPECT_THAT(schema_store->GetSchema("db2/"),
                   IsOkAndHolds(EqualsProto(db2_schema)));
 
       DocumentProto db1_email_doc =
           DocumentBuilder()
               .SetKey("namespace", "uri1")
               .SetSchema("db1/email")
-              .AddStringProperty("db1Subject", "db1_subject")
+              .AddStringProperty("db1Subject", "db1/subject")
               .Build();
       DocumentProto db2_email_doc =
           DocumentBuilder()
               .SetKey("namespace", "uri3")
               .SetSchema("db2/email")
-              .AddStringProperty("db2Subject", "db2_subject")
+              .AddStringProperty("db2Subject", "db2/subject")
               .Build();
 
       // Verify that our in-memory structures are ok
       ICING_ASSERT_OK_AND_ASSIGN(SectionGroup section_group,
                                  schema_store->ExtractSections(db1_email_doc));
       EXPECT_THAT(section_group.string_sections[0].content,
-                  ElementsAre("db1_subject"));
+                  ElementsAre("db1/subject"));
       ICING_ASSERT_OK_AND_ASSIGN(section_group,
                                  schema_store->ExtractSections(db2_email_doc));
       EXPECT_THAT(section_group.string_sections[0].content,
-                  ElementsAre("db2_subject"));
+                  ElementsAre("db2/subject"));
 
       // Verify that our persisted data are ok
       EXPECT_THAT(schema_store->GetSchemaTypeId("db1/email"), IsOkAndHolds(0));
diff --git a/icing/schema/schema-util.cc b/icing/schema/schema-util.cc
index cfc2391..4d496cd 100644
--- a/icing/schema/schema-util.cc
+++ b/icing/schema/schema-util.cc
@@ -49,8 +49,30 @@ bool AreStringIndexingConfigsEqual(const StringIndexingConfig& old_config,
 
 bool AreDocumentIndexingConfigsEqual(const DocumentIndexingConfig& old_config,
                                      const DocumentIndexingConfig& new_config) {
-  return old_config.index_nested_properties() ==
-         new_config.index_nested_properties();
+  // TODO(b/265304217): This could mark the new schema as incompatible and
+  // generate some unnecessary index rebuilds if the two schemas have an
+  // equivalent set of indexed properties, but changed the way that it is
+  // declared.
+  if (old_config.index_nested_properties() !=
+      new_config.index_nested_properties()) {
+    return false;
+  }
+
+  if (old_config.indexable_nested_properties_list().size() !=
+      new_config.indexable_nested_properties_list().size()) {
+    return false;
+  }
+
+  std::unordered_set<std::string_view> old_indexable_nested_properies_set(
+      old_config.indexable_nested_properties_list().begin(),
+      old_config.indexable_nested_properties_list().end());
+  for (const auto& property : new_config.indexable_nested_properties_list()) {
+    if (old_indexable_nested_properies_set.find(property) ==
+        old_indexable_nested_properies_set.end()) {
+      return false;
+    }
+  }
+  return true;
 }
 
 bool AreIntegerIndexingConfigsEqual(const IntegerIndexingConfig& old_config,
@@ -145,53 +167,6 @@ bool IsPropertyCompatible(const PropertyConfigProto& old_property,
          IsCardinalityCompatible(old_property, new_property);
 }
 
-bool IsTermMatchTypeCompatible(const StringIndexingConfig& old_indexed,
-                               const StringIndexingConfig& new_indexed) {
-  return old_indexed.term_match_type() == new_indexed.term_match_type() &&
-         old_indexed.tokenizer_type() == new_indexed.tokenizer_type();
-}
-
-bool IsIntegerNumericMatchTypeCompatible(
-    const IntegerIndexingConfig& old_indexed,
-    const IntegerIndexingConfig& new_indexed) {
-  return old_indexed.numeric_match_type() == new_indexed.numeric_match_type();
-}
-
-bool IsEmbeddingIndexingCompatible(const EmbeddingIndexingConfig& old_indexed,
-                                   const EmbeddingIndexingConfig& new_indexed) {
-  return old_indexed.embedding_indexing_type() ==
-             new_indexed.embedding_indexing_type() &&
-         old_indexed.quantization_type() == new_indexed.quantization_type();
-}
-
-bool IsDocumentIndexingCompatible(const DocumentIndexingConfig& old_indexed,
-                                  const DocumentIndexingConfig& new_indexed) {
-  // TODO(b/265304217): This could mark the new schema as incompatible and
-  // generate some unnecessary index rebuilds if the two schemas have an
-  // equivalent set of indexed properties, but changed the way that it is
-  // declared.
-  if (old_indexed.index_nested_properties() !=
-      new_indexed.index_nested_properties()) {
-    return false;
-  }
-
-  if (old_indexed.indexable_nested_properties_list().size() !=
-      new_indexed.indexable_nested_properties_list().size()) {
-    return false;
-  }
-
-  std::unordered_set<std::string_view> old_indexable_nested_properies_set(
-      old_indexed.indexable_nested_properties_list().begin(),
-      old_indexed.indexable_nested_properties_list().end());
-  for (const auto& property : new_indexed.indexable_nested_properties_list()) {
-    if (old_indexable_nested_properies_set.find(property) ==
-        old_indexable_nested_properies_set.end()) {
-      return false;
-    }
-  }
-  return true;
-}
-
 void AddIncompatibleChangeToDelta(
     std::unordered_set<std::string>& incompatible_delta,
     const SchemaTypeConfigProto& old_type_config,
@@ -1269,16 +1244,16 @@ const SchemaUtil::SchemaDelta SchemaUtil::ComputeCompatibilityDelta(
       }
 
       // Any change in the indexed property requires a reindexing
-      if (!IsTermMatchTypeCompatible(
+      if (!AreStringIndexingConfigsEqual(
               old_property_config.string_indexing_config(),
               new_property_config->string_indexing_config()) ||
-          !IsIntegerNumericMatchTypeCompatible(
+          !AreIntegerIndexingConfigsEqual(
               old_property_config.integer_indexing_config(),
               new_property_config->integer_indexing_config()) ||
-          !IsDocumentIndexingCompatible(
+          !AreDocumentIndexingConfigsEqual(
               old_property_config.document_indexing_config(),
               new_property_config->document_indexing_config()) ||
-          !IsEmbeddingIndexingCompatible(
+          !AreEmbeddingIndexingConfigsEqual(
               old_property_config.embedding_indexing_config(),
               new_property_config->embedding_indexing_config())) {
         is_index_incompatible = true;
diff --git a/icing/schema/schema-util_test.cc b/icing/schema/schema-util_test.cc
index 6758984..a391e45 100644
--- a/icing/schema/schema-util_test.cc
+++ b/icing/schema/schema-util_test.cc
@@ -4436,7 +4436,10 @@ TEST_P(SchemaUtilTest,
       /*enable_repeated_field_joins=*/false,
       /*enable_embedding_backup_generation=*/true,
       /*enable_schema_database=*/true,
-      /*release_backup_schema_file_if_overlay_present=*/true);
+      /*release_backup_schema_file_if_overlay_present=*/true,
+      /*enable_strict_page_byte_size_limit=*/true,
+      /*enable_smaller_decompression_buffer_size=*/true,
+      /*enable_eigen_embedding_scoring=*/true);
   SchemaProto schema =
       SchemaBuilder()
           .AddType(SchemaTypeConfigBuilder().SetType("MyType").AddProperty(
@@ -4498,7 +4501,10 @@ TEST_P(SchemaUtilTest, ValidateJoinablePropertyCanHaveRepeatedCardinality) {
       /*enable_repeated_field_joins=*/true,
       /*enable_embedding_backup_generation=*/true,
       /*enable_schema_database=*/true,
-      /*release_backup_schema_file_if_overlay_present=*/true);
+      /*release_backup_schema_file_if_overlay_present=*/true,
+      /*enable_strict_page_byte_size_limit=*/true,
+      /*enable_smaller_decompression_buffer_size=*/true,
+      /*enable_eigen_embedding_scoring=*/true);
 
   SchemaProto schema =
       SchemaBuilder()
@@ -5818,23 +5824,28 @@ TEST_P(SchemaUtilTest, ValidateScorableType_DisabledForUnsupportedDataTypes) {
 
 INSTANTIATE_TEST_SUITE_P(
     SchemaUtilTest, SchemaUtilTest,
-    testing::Values(
-        FeatureFlags(
-            /*enable_circular_schema_definitions=*/false,
-            /*enable_scorable_properties=*/true,
-            /*enable_embedding_quantization=*/true,
-            /*enable_repeated_field_joins=*/true,
-            /*enable_embedding_backup_generation=*/true,
-            /*enable_schema_database=*/true,
-            /*release_backup_schema_file_if_overlay_present=*/true),
-        FeatureFlags(
-            /*enable_circular_schema_definitions=*/true,
-            /*enable_scorable_properties=*/true,
-            /*enable_embedding_quantization=*/true,
-            /*enable_repeated_field_joins=*/true,
-            /*enable_embedding_backup_generation=*/true,
-            /*enable_schema_database=*/true,
-            /*release_backup_schema_file_if_overlay_present=*/true)));
+    testing::Values(FeatureFlags(
+                        /*enable_circular_schema_definitions=*/false,
+                        /*enable_scorable_properties=*/true,
+                        /*enable_embedding_quantization=*/true,
+                        /*enable_repeated_field_joins=*/true,
+                        /*enable_embedding_backup_generation=*/true,
+                        /*enable_schema_database=*/true,
+                        /*release_backup_schema_file_if_overlay_present=*/true,
+                        /*enable_strict_page_byte_size_limit=*/true,
+                        /*enable_smaller_decompression_buffer_size=*/true,
+                        /*enable_eigen_embedding_scoring=*/true),
+                    FeatureFlags(
+                        /*enable_circular_schema_definitions=*/true,
+                        /*enable_scorable_properties=*/true,
+                        /*enable_embedding_quantization=*/true,
+                        /*enable_repeated_field_joins=*/true,
+                        /*enable_embedding_backup_generation=*/true,
+                        /*enable_schema_database=*/true,
+                        /*release_backup_schema_file_if_overlay_present=*/true,
+                        /*enable_strict_page_byte_size_limit=*/true,
+                        /*enable_smaller_decompression_buffer_size=*/true,
+                        /*enable_eigen_embedding_scoring=*/true)));
 
 struct IsIndexedPropertyTestParam {
   PropertyConfigProto property_config;
diff --git a/icing/scoring/advanced_scoring/advanced-scorer_fuzz_test.cc b/icing/scoring/advanced_scoring/advanced-scorer_fuzz_test.cc
index 765ccdb..c02f06b 100644
--- a/icing/scoring/advanced_scoring/advanced-scorer_fuzz_test.cc
+++ b/icing/scoring/advanced_scoring/advanced-scorer_fuzz_test.cc
@@ -22,6 +22,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/embed/embedding-query-results.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/schema/schema-store.h"
 #include "icing/scoring/advanced_scoring/advanced-scorer.h"
 #include "icing/store/document-store.h"
@@ -55,6 +56,9 @@ extern "C" int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) {
           /*force_recovery_and_revalidate_documents=*/false,
           /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
           PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+          PortableFileBackedProtoLog<
+              DocumentWrapper>::kDefaultCompressionThresholdBytes,
+          protobuf_ports::kDefaultMemLevel,
           /*initialize_stats=*/nullptr)
           .ValueOrDie()
           .document_store;
diff --git a/icing/scoring/advanced_scoring/advanced-scorer_test.cc b/icing/scoring/advanced_scoring/advanced-scorer_test.cc
index 386d0c2..a1eb58a 100644
--- a/icing/scoring/advanced_scoring/advanced-scorer_test.cc
+++ b/icing/scoring/advanced_scoring/advanced-scorer_test.cc
@@ -35,6 +35,7 @@
 #include "icing/index/embed/embedding-query-results.h"
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/join/join-children-fetcher-impl-deprecated.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
@@ -48,9 +49,11 @@
 #include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
 #include "icing/testing/common-matchers.h"
+#include "icing/testing/embedding-test-utils.h"
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -80,14 +83,18 @@ class AdvancedScorerTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     // Creates the schema
@@ -286,7 +293,8 @@ TEST_F(AdvancedScorerTest, InvalidAdvancedScoringSpec) {
 TEST_F(AdvancedScorerTest, SimpleExpression) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri"))));
   DocumentId document_id = put_result.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -307,7 +315,8 @@ TEST_F(AdvancedScorerTest, SimpleExpression) {
 TEST_F(AdvancedScorerTest, BasicPureArithmeticExpression) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri"))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -376,7 +385,8 @@ TEST_F(AdvancedScorerTest, BasicPureArithmeticExpression) {
 TEST_F(AdvancedScorerTest, BasicMathFunctionExpression) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri"))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -515,9 +525,9 @@ TEST_F(AdvancedScorerTest, BasicMathFunctionExpression) {
 TEST_F(AdvancedScorerTest, DocumentScoreCreationTimestampFunctionExpression) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument(
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
           "namespace", "uri", /*score=*/123,
-          /*creation_timestamp_ms=*/kDefaultCreationTimestampMs)));
+          /*creation_timestamp_ms=*/kDefaultCreationTimestampMs))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -558,7 +568,8 @@ TEST_F(AdvancedScorerTest, DocumentScoreCreationTimestampFunctionExpression) {
 TEST_F(AdvancedScorerTest, DocumentUsageFunctionExpression) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri"))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -615,7 +626,8 @@ TEST_F(AdvancedScorerTest, DocumentUsageFunctionExpression) {
 TEST_F(AdvancedScorerTest, DocumentUsageFunctionOutOfRange) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri"))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -667,8 +679,10 @@ TEST_F(AdvancedScorerTest, RelevanceScoreFunctionScoreExpression) {
           .SetCreationTimestampMs(kDefaultCreationTimestampMs)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<AdvancedScorer> scorer,
@@ -691,17 +705,20 @@ TEST_F(AdvancedScorerTest, ChildrenScoresFunctionScoreExpression) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store_->Put(CreateDocument("namespace", "uri1")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri1"))));
   DocumentId document_id_1 = put_result1.new_document_id;
   DocHitInfo docHitInfo1 = DocHitInfo(document_id_1);
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result2,
-      document_store_->Put(CreateDocument("namespace", "uri2")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri2"))));
   DocumentId document_id_2 = put_result2.new_document_id;
   DocHitInfo docHitInfo2 = DocHitInfo(document_id_2);
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result3,
-      document_store_->Put(CreateDocument("namespace", "uri3")));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri3"))));
   DocumentId document_id_3 = put_result3.new_document_id;
   DocHitInfo docHitInfo3 = DocHitInfo(document_id_3);
 
@@ -803,14 +820,20 @@ TEST_F(AdvancedScorerTest, PropertyWeightsFunctionScoreExpression) {
   DocumentProto test_document_3 =
       DocumentBuilder().SetKey("namespace", "uri3").SetSchema("person").Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(test_document_1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document_1)));
   DocumentId document_id_1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(test_document_2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document_2)));
   DocumentId document_id_2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store_->Put(test_document_3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document_3)));
   DocumentId document_id_3 = put_result3.new_document_id;
 
   ScoringSpecProto spec_proto = CreateAdvancedScoringSpec("");
@@ -900,11 +923,15 @@ TEST_F(AdvancedScorerTest,
   DocumentProto test_document_2 =
       DocumentBuilder().SetKey("namespace", "uri2").SetSchema("person").Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(test_document_1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document_1)));
   DocumentId document_id_1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(test_document_2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(test_document_2)));
   DocumentId document_id_2 = put_result2.new_document_id;
 
   ScoringSpecProto spec_proto = CreateAdvancedScoringSpec("");
@@ -1012,8 +1039,8 @@ TEST_F(AdvancedScorerTest, ComplexExpression) {
   const int64_t creation_timestamp_ms = 123;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri", /*score=*/123,
-                                          creation_timestamp_ms)));
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "namespace", "uri", /*score=*/123, creation_timestamp_ms))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -1133,7 +1160,8 @@ TEST_F(AdvancedScorerTest, EvaluationErrorShouldReturnDefaultScore) {
   // non-constant 0.
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri", /*score=*/0)));
+      document_store_->Put(document_util::CreateDocumentWrapper(
+          CreateDocument("namespace", "uri", /*score=*/0))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -1363,12 +1391,12 @@ TEST_F(AdvancedScorerTest, DocumentFunctionTypeError) {
 
 TEST_F(AdvancedScorerTest,
        MatchedSemanticScoresFunctionScoreExpressionTypeError) {
-  EmbeddingQueryResults embedding_query_results;
-  embedding_query_results
-      .result_infos[/*query_vector_index=*/0]
-                    [SearchSpecProto::EmbeddingQueryMetricType::COSINE]
-                    [/*document_id=*/0]
-      .AppendScore(/*semantic_score=*/0.1);
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/1);
+  GetOrCreateEmbeddingMatchInfosForDocument(
+      embedding_query_results, /*query_vector_index=*/0,
+      SearchSpecProto::EmbeddingQueryMetricType::COSINE, /*document_id=*/0)
+      .AppendScore(*embedding_query_results.global_scores,
+                   /*semantic_score=*/0.1);
 
   libtextclassifier3::StatusOr<std::unique_ptr<AdvancedScorer>> scorer_or =
       AdvancedScorer::Create(
@@ -1464,17 +1492,17 @@ TEST_F(AdvancedScorerTest,
 
 TEST_F(AdvancedScorerTest,
        MatchedSemanticScoresFunctionScoreExpressionNotQueried) {
-  EmbeddingQueryResults embedding_query_results;
-  embedding_query_results
-      .result_infos[/*query_vector_index=*/0]
-                    [SearchSpecProto::EmbeddingQueryMetricType::COSINE]
-                    [/*document_id=*/0]
-      .AppendScore(/*semantic_score=*/0.1);
-  embedding_query_results
-      .result_infos[/*query_vector_index=*/1]
-                    [SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT]
-                    [/*document_id=*/1]
-      .AppendScore(/*semantic_score=*/0.2);
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
+  GetOrCreateEmbeddingMatchInfosForDocument(
+      embedding_query_results, /*query_vector_index=*/0,
+      SearchSpecProto::EmbeddingQueryMetricType::COSINE, /*document_id=*/0)
+      .AppendScore(*embedding_query_results.global_scores,
+                   /*semantic_score=*/0.1);
+  GetOrCreateEmbeddingMatchInfosForDocument(
+      embedding_query_results, /*query_vector_index=*/1,
+      SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT, /*document_id=*/1)
+      .AppendScore(*embedding_query_results.global_scores,
+                   /*semantic_score=*/0.2);
 
   libtextclassifier3::StatusOr<std::unique_ptr<AdvancedScorer>> scorer_or =
       AdvancedScorer::Create(CreateAdvancedScoringSpec(
@@ -1564,9 +1592,10 @@ TEST_F(AdvancedScorerTest,
 }
 
 void AddEntryToEmbeddingQueryScoreMap(
+    std::vector<double>& global_scores,
     EmbeddingQueryResults::EmbeddingQueryMatchInfoMap& score_map,
     double semantic_score, DocumentId document_id) {
-  score_map[document_id].AppendScore(semantic_score);
+  score_map[document_id].AppendScore(global_scores, semantic_score);
 }
 
 TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
@@ -1574,7 +1603,7 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
   DocumentId document_id_1 = 1;
   DocHitInfo doc_hit_info_0(document_id_0);
   DocHitInfo doc_hit_info_1(document_id_1);
-  EmbeddingQueryResults embedding_query_results;
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
 
   // Let the first query assign the following semantic scores:
   // COSINE:
@@ -1586,41 +1615,57 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
   // EUCLIDEAN:
   //   Document 0: 0.7
   //   Document 1: 0.8
-  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* score_map =
-      &embedding_query_results
-           .result_infos[0][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  ICING_ASSERT_OK_AND_ASSIGN(
+      EmbeddingQueryResults::EmbeddingQueryMatchInfoMap * score_map,
+      embedding_query_results.GetOrCreateMatchInfoMap(
+          /*query_vector_index=*/0,
+          SearchSpecProto::EmbeddingQueryMetricType::COSINE));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.1, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.2, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.3, document_id_1);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.4, document_id_1);
-  score_map = &embedding_query_results.result_infos
-                   [0][SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT];
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  ICING_ASSERT_OK_AND_ASSIGN(
+      score_map, embedding_query_results.GetOrCreateMatchInfoMap(
+                     /*query_vector_index=*/0,
+                     SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.5, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.6, document_id_1);
-  score_map =
-      &embedding_query_results
-           .result_infos[0]
-                         [SearchSpecProto::EmbeddingQueryMetricType::EUCLIDEAN];
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  ICING_ASSERT_OK_AND_ASSIGN(
+      score_map, embedding_query_results.GetOrCreateMatchInfoMap(
+                     /*query_vector_index=*/0,
+                     SearchSpecProto::EmbeddingQueryMetricType::EUCLIDEAN));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.7, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.8, document_id_1);
 
   // Let the second query only assign DOT_PRODUCT scores:
   // DOT_PRODUCT:
   //   Document 0: 0.1
   //   Document 1: 0.2
-  score_map = &embedding_query_results.result_infos
-                   [1][SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT];
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  ICING_ASSERT_OK_AND_ASSIGN(
+      score_map, embedding_query_results.GetOrCreateMatchInfoMap(
+                     /*query_vector_index=*/1,
+                     SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.1, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/0.2, document_id_1);
 
   // Get semantic scores for default metric (DOT_PRODUCT) for the first query.
@@ -1708,6 +1753,75 @@ TEST_F(AdvancedScorerTest, MatchedSemanticScoresFunctionScoreExpression) {
                         "has not been queried"));
 }
 
+// This test should be very uncommon, but we should still make sure it works.
+TEST_F(
+    AdvancedScorerTest,
+    MatchedSemanticScoresFunctionScoreExpression_NonConstantQueryVectorIndex) {
+  // Create document 0 with document score 0.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "namespace", "uri0", /*score=*/0, kDefaultCreationTimestampMs))));
+  DocumentId document_id_0 = put_result.new_document_id;
+  DocHitInfo doc_hit_info_0(document_id_0);
+
+  // Create document 1 with document score 1.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "namespace", "uri1", /*score=*/1, kDefaultCreationTimestampMs))));
+  DocumentId document_id_1 = put_result.new_document_id;
+  DocHitInfo doc_hit_info_1(document_id_1);
+
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
+
+  // Create the first embedding query with scores:
+  // - Document 0: 0.1
+  // - Document 1: 0.2
+  // Create the second embedding query with scores:
+  // - Document 0: -0.1
+  // - Document 1: -0.2
+  ICING_ASSERT_OK_AND_ASSIGN(
+      EmbeddingQueryResults::EmbeddingQueryMatchInfoMap * score_map,
+      embedding_query_results.GetOrCreateMatchInfoMap(
+          /*query_vector_index=*/0,
+          SearchSpecProto::EmbeddingQueryMetricType::COSINE));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
+                                   /*semantic_score=*/0.1, document_id_0);
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
+                                   /*semantic_score=*/0.2, document_id_1);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      score_map, embedding_query_results.GetOrCreateMatchInfoMap(
+                     /*query_vector_index=*/1,
+                     SearchSpecProto::EmbeddingQueryMetricType::COSINE));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
+                                   /*semantic_score=*/-0.1, document_id_0);
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
+                                   /*semantic_score=*/-0.2, document_id_1);
+
+  // Create a weird scoring expression that has a non-constant query vector
+  // index. Specifically, document 0 should get the scores from the first query,
+  // but document 1 should get the scores from the second query.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<Scorer> scorer,
+      AdvancedScorer::Create(
+          CreateAdvancedScoringSpec(
+              "sum(this.matchedSemanticScores("
+              "getEmbeddingParameter(this.documentScore())))"),
+          kDefaultScore, /*default_semantic_metric_type=*/
+          SearchSpecProto::EmbeddingQueryMetricType::COSINE,
+          document_store_.get(), schema_store_.get(),
+          fake_clock_.GetSystemTimeMilliseconds(),
+          /*join_children_fetcher=*/nullptr, &embedding_query_results,
+          feature_flags_.get()));
+  EXPECT_THAT(scorer->GetScore(doc_hit_info_0), DoubleNear(0.1, kEps));
+  EXPECT_THAT(scorer->GetScore(doc_hit_info_1), DoubleNear(-0.2, kEps));
+}
+
 TEST_F(AdvancedScorerTest, ListRelatedFunctions) {
   DocumentId document_id_0 = 0;
   DocHitInfo doc_hit_info_0(document_id_0);
@@ -1717,23 +1831,31 @@ TEST_F(AdvancedScorerTest, ListRelatedFunctions) {
   //   {4, 5, 2, 1, 3}.
   // - this.matchedSemanticScores(getEmbeddingParameter(1)) returns an empty
   //   list.
-  EmbeddingQueryResults embedding_query_results;
-  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* score_map =
-      &embedding_query_results
-           .result_infos[0][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  EmbeddingQueryResults embedding_query_results(/*num_query_vectors=*/2);
+  ICING_ASSERT_OK_AND_ASSIGN(
+      EmbeddingQueryResults::EmbeddingQueryMatchInfoMap * score_map,
+      embedding_query_results.GetOrCreateMatchInfoMap(
+          /*query_vector_index=*/0,
+          SearchSpecProto::EmbeddingQueryMetricType::COSINE));
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/4, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/5, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/2, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/1, document_id_0);
-  AddEntryToEmbeddingQueryScoreMap(*score_map,
+  AddEntryToEmbeddingQueryScoreMap(*embedding_query_results.global_scores,
+                                   *score_map,
                                    /*semantic_score=*/3, document_id_0);
-  score_map =
-      &embedding_query_results
-           .result_infos[1][SearchSpecProto::EmbeddingQueryMetricType::COSINE];
+  ICING_ASSERT_OK_AND_ASSIGN(
+      score_map, embedding_query_results.GetOrCreateMatchInfoMap(
+                     /*query_vector_index=*/1,
+                     SearchSpecProto::EmbeddingQueryMetricType::COSINE));
 
   // maxOrDefault({4, 5, 2, 1, 3}, 100) = 5
   ICING_ASSERT_OK_AND_ASSIGN(
@@ -1810,8 +1932,8 @@ TEST_F(AdvancedScorerTest, AdditionalScores) {
   const int64_t creation_timestamp_ms = 123;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri", /*score=*/123,
-                                          creation_timestamp_ms)));
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "namespace", "uri", /*score=*/123, creation_timestamp_ms))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo docHitInfo = DocHitInfo(document_id);
 
@@ -1941,8 +2063,9 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_PropertyNameNotScorable) {
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -1977,8 +2100,9 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_PropertyNameNotExist) {
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2013,8 +2137,9 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_SomePropertiesNotScorable) {
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
       "this.documentScore() + "
@@ -2047,8 +2172,9 @@ TEST_F(AdvancedScorerTest,
                                .SetScore(100)
                                .SetCreationTimestampMs(123)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2080,8 +2206,9 @@ TEST_F(AdvancedScorerTest,
                                .SetScore(100)
                                .SetCreationTimestampMs(123)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   // getScorableProperty("aliasPerson", "frequencyScore") will return an empty
@@ -2116,8 +2243,9 @@ TEST_F(AdvancedScorerTest,
                                .SetScore(100)
                                .SetCreationTimestampMs(123)
                                .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   // getScorableProperty("aliasPerson", "frequencyScore") will return an empty
@@ -2188,12 +2316,16 @@ TEST_F(AdvancedScorerTest,
   double expected_score_doc1 = 100 + (1 + 2 + 3);
   double expected_score_doc2 = 100 + 0;
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store_->Put(document_from_db1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document_from_db1)));
   DocHitInfo docHitInfo1(put_result1.new_document_id);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store_->Put(document_from_db2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store_->Put(
+          document_util::CreateDocumentWrapper(document_from_db2)));
   DocHitInfo docHitInfo2(put_result2.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2230,8 +2362,9 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_WithDoubleList) {
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2265,8 +2398,9 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_WithInt64List) {
                                .AddInt64Property("contactTimes", 10, 20, 30)
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2301,8 +2435,9 @@ TEST_F(AdvancedScorerTest, GetScorableProperty_WithBoolean) {
                                .AddInt64Property("contactTimes", 10, 20, 30)
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2340,8 +2475,9 @@ TEST_F(AdvancedScorerTest,
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2381,8 +2517,9 @@ TEST_F(AdvancedScorerTest,
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2420,8 +2557,9 @@ TEST_F(AdvancedScorerTest,
                                .SetCreationTimestampMs(123)
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   // Expected score will fall back to the default score, because max() throws an
@@ -2456,8 +2594,9 @@ TEST_F(AdvancedScorerTest,
                                .SetScore(100)
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
@@ -2589,8 +2728,9 @@ TEST_F(AdvancedScorerTest, ScoreWithScorableProperty_WithNestedSchemas) {
           .SetCreationTimestampMs(0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
   ScoringSpecProto scoring_spec1 = CreateAdvancedScoringSpec(
       "this.documentScore() + "
@@ -2666,8 +2806,9 @@ TEST_F(AdvancedScorerTest, SchemaTypeAliasMap_AliasSchemaTypeNotMatched) {
           .AddDoubleProperty("frequencyScore", 1.0, 2.0, 3.0)
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store_->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store_->Put(document_util::CreateDocumentWrapper(document)));
   DocHitInfo docHitInfo(put_result.new_document_id);
 
   ScoringSpecProto scoring_spec = CreateAdvancedScoringSpec(
diff --git a/icing/scoring/advanced_scoring/double-list.h b/icing/scoring/advanced_scoring/double-list.h
new file mode 100644
index 0000000..6abc176
--- /dev/null
+++ b/icing/scoring/advanced_scoring/double-list.h
@@ -0,0 +1,99 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_SCORING_ADVANCED_SCORING_DOUBLE_LIST_H_
+#define ICING_SCORING_ADVANCED_SCORING_DOUBLE_LIST_H_
+
+#include <cstddef>
+#include <type_traits>
+#include <utility>
+#include <variant>
+#include <vector>
+
+// Represents the kDoubleList type, which can either own its data or provide a
+// non-owning view of existing data.
+class DoubleList {
+ public:
+  using value_type = double;
+
+  // Creates a list by taking ownership of an existing vector's data via move.
+  explicit DoubleList(std::vector<double>&& vec) : storage_(std::move(vec)) {}
+
+  // Creates a non-owning view of an external data buffer.
+  // The caller must ensure the lifetime of "data" exceeds the lifetime of this
+  // DoubleList.
+  explicit DoubleList(const double* data, size_t size)
+      : storage_(DataView(data, size)) {}
+
+  // Creates an empty list. Represents as an empty non-owning view by default.
+  explicit DoubleList() : storage_(DataView()) {}
+
+  // Disallow copy but allow move.
+  DoubleList(const DoubleList&) = delete;
+  DoubleList& operator=(const DoubleList&) = delete;
+  DoubleList(DoubleList&&) = default;
+  DoubleList& operator=(DoubleList&&) = default;
+
+  const double* data() const {
+    return std::visit(
+        [](const auto& arg) -> const double* { return arg.data(); }, storage_);
+  }
+
+  size_t size() const {
+    return std::visit([](const auto& arg) -> size_t { return arg.size(); },
+                      storage_);
+  }
+
+  const double* begin() const { return data(); }
+
+  const double* end() const { return data() + size(); }
+
+  bool empty() const { return size() == 0; }
+
+  // Releases the ownership of the internal vector, if owned.
+  // If not owned, returns a *new* vector containing a copy of the viewed data.
+  std::vector<double> ReleaseVector() && {
+    return std::visit(
+        [](auto&& arg) -> std::vector<double> {
+          using T = std::decay_t<decltype(arg)>;
+          if constexpr (std::is_same_v<T, std::vector<double>>) {
+            return std::forward<decltype(arg)>(arg);
+          } else {
+            return std::vector<double>(arg.data(), arg.data() + arg.size());
+          }
+        },
+        std::move(storage_));
+  }
+
+ private:
+  // Simple class to represent a non-owning view of data
+  class DataView {
+   public:
+    // Default constructor represents an empty non-owning view.
+    DataView() : DataView(nullptr, 0) {}
+    DataView(const double* data, size_t size) : data_(data), size_(size) {}
+
+    const double* data() const { return data_; }
+    size_t size() const { return size_; }
+
+   private:
+    const double* data_ = nullptr;
+    size_t size_ = 0;
+  };
+
+  // Storage can be either an owned vector or a non-owning view
+  std::variant<std::vector<double>, DataView> storage_;
+};
+
+#endif  // ICING_SCORING_ADVANCED_SCORING_DOUBLE_LIST_H_
diff --git a/icing/scoring/advanced_scoring/double-list_test.cc b/icing/scoring/advanced_scoring/double-list_test.cc
new file mode 100644
index 0000000..f29fe69
--- /dev/null
+++ b/icing/scoring/advanced_scoring/double-list_test.cc
@@ -0,0 +1,245 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/scoring/advanced_scoring/double-list.h"
+
+#include <cstddef>
+#include <iterator>
+#include <numeric>
+#include <utility>
+#include <vector>
+
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+
+namespace icing {
+namespace lib {
+
+namespace {
+
+using ::testing::ElementsAreArray;
+using ::testing::IsEmpty;
+
+std::vector<double> CreateSequenceVec(size_t size, double start = 0.0) {
+  std::vector<double> vec(size);
+  std::iota(vec.begin(), vec.end(), start);
+  return vec;
+}
+
+TEST(DoubleListTest, DefaultConstructorCreatesEmptyView) {
+  DoubleList list;
+  EXPECT_EQ(list.size(), 0);
+  EXPECT_TRUE(list.empty());
+  EXPECT_EQ(list.data(), nullptr);
+  EXPECT_EQ(list.begin(), list.end());
+}
+
+// Test constructor taking ownership of an empty vector
+TEST(DoubleListTest, EmptyVectorMoveConstructor) {
+  std::vector<double> source_vec;
+  const double* expected_data_ptr =
+      source_vec.data();  // Capture pointer before move
+  DoubleList list(std::move(source_vec));
+
+  EXPECT_EQ(list.size(), 0);
+  EXPECT_TRUE(list.empty());
+  EXPECT_EQ(list.data(), expected_data_ptr);
+  EXPECT_EQ(list.begin(), list.end());
+}
+
+// Test constructor creating an empty non-owning view, which is the same
+// behavior of the default constructor.
+TEST(DoubleListTest, EmptyDataViewConstructor) {
+  const double* external_data = nullptr;
+  DoubleList list(external_data, 0);
+  EXPECT_EQ(list.size(), 0);
+  EXPECT_TRUE(list.empty());
+  EXPECT_EQ(list.data(), nullptr);
+  EXPECT_EQ(list.begin(), list.end());
+}
+
+// Test constructor taking ownership via std::vector rvalue reference
+TEST(DoubleListTest, VectorMoveConstructor) {
+  std::vector<double> source_vec = {1.1, 2.2, 3.3};
+  const double* expected_data_ptr =
+      source_vec.data();  // Capture pointer before move
+  const size_t expected_size = source_vec.size();
+
+  DoubleList list(std::move(source_vec));
+
+  EXPECT_EQ(list.size(), expected_size);
+  ASSERT_FALSE(list.empty());
+  EXPECT_EQ(list.data(), expected_data_ptr);
+  EXPECT_THAT(list, ElementsAreArray({1.1, 2.2, 3.3}));
+}
+
+// Test constructor creating a non-owning view
+TEST(DoubleListTest, DataViewConstructor) {
+  const double external_data[] = {4.4, 5.5, 6.6};
+  const size_t external_size = std::size(external_data);
+
+  DoubleList list(external_data, external_size);
+
+  EXPECT_EQ(list.size(), external_size);
+  ASSERT_FALSE(list.empty());
+  EXPECT_EQ(list.data(),
+            external_data);  // Should point directly to external data
+  EXPECT_THAT(list, ElementsAreArray({4.4, 5.5, 6.6}));
+}
+
+// Test accessors on an owned list
+TEST(DoubleListTest, AccessorsOwned) {
+  const DoubleList list(CreateSequenceVec(3, 10.0));  // {10.0, 11.0, 12.0}
+
+  EXPECT_EQ(list.size(), 3);
+  ASSERT_FALSE(list.empty());
+  ASSERT_NE(list.data(), nullptr);
+  EXPECT_EQ(list.begin()[0], 10.0);
+  EXPECT_EQ(list.begin()[1], 11.0);
+  EXPECT_EQ(list.begin()[2], 12.0);
+  EXPECT_EQ(list.end(), list.begin() + 3);
+}
+
+// Test accessors on a non-owning list
+TEST(DoubleListTest, AccessorsView) {
+  const double external_data[] = {20.0, 21.0};
+  const DoubleList list(external_data, 2);
+
+  EXPECT_EQ(list.size(), 2);
+  ASSERT_FALSE(list.empty());
+  ASSERT_EQ(list.data(), external_data);
+  EXPECT_EQ(list.begin()[0], 20.0);
+  EXPECT_EQ(list.begin()[1], 21.0);
+  EXPECT_EQ(list.end(), list.begin() + 2);
+}
+
+// Test move constructor from an owned list
+TEST(DoubleListTest, MoveConstructionFromOwned) {
+  DoubleList list1(CreateSequenceVec(2, 1.0));  // {1.0, 2.0}
+  const double* original_data_ptr = list1.data();
+
+  DoubleList list2(std::move(list1));
+
+  // Check list2 has the data
+  EXPECT_EQ(list2.size(), 2);
+  ASSERT_FALSE(list2.empty());
+  EXPECT_EQ(list2.data(), original_data_ptr);
+  EXPECT_THAT(list2, ElementsAreArray({1.0, 2.0}));
+}
+
+// Test move constructor from a non-owning list
+TEST(DoubleListTest, MoveConstructionFromView) {
+  const double external_data[] = {3.0, 4.0};
+  DoubleList list1(external_data, 2);
+  const size_t original_size = list1.size();
+
+  DoubleList list2(std::move(list1));
+
+  // Check list2 has the view details
+  EXPECT_EQ(list2.size(), original_size);
+  ASSERT_FALSE(list2.empty());
+  EXPECT_EQ(list2.data(), external_data);
+  EXPECT_THAT(list2, ElementsAreArray({3.0, 4.0}));
+}
+
+// Test move assignment from an owned list to another
+TEST(DoubleListTest, MoveAssignmentFromOwned) {
+  DoubleList list1(CreateSequenceVec(3, 5.0));    // {5.0, 6.0, 7.0}
+  DoubleList list2(CreateSequenceVec(1, 100.0));  // {100.0}
+  const double* original_data_ptr_list1 = list1.data();
+
+  list2 = std::move(list1);
+
+  // Check list2 has the data from list1
+  EXPECT_EQ(list2.size(), 3);
+  ASSERT_FALSE(list2.empty());
+  EXPECT_EQ(list2.data(), original_data_ptr_list1);
+  EXPECT_THAT(list2, ElementsAreArray({5.0, 6.0, 7.0}));
+}
+
+// Test move assignment from a non-owning list to another
+TEST(DoubleListTest, MoveAssignmentFromView) {
+  const double external_data[] = {8.0, 9.0};
+  DoubleList list1(external_data, 2);
+  DoubleList list2(CreateSequenceVec(1, 200.0));  // {200.0}
+
+  list2 = std::move(list1);
+
+  // Check list2 has the view details from list1
+  EXPECT_EQ(list2.size(), 2);
+  ASSERT_FALSE(list2.empty());
+  EXPECT_EQ(list2.data(), external_data);
+  EXPECT_THAT(list2, ElementsAreArray({8.0, 9.0}));
+}
+
+// Test ReleaseVector when the list owns the data
+TEST(DoubleListTest, ReleaseVectorOwned) {
+  DoubleList list(CreateSequenceVec(3, 10.0));  // {10.0, 11.0, 12.0}
+  const double* original_data_ptr = list.data();
+
+  // ReleaseVector must be called on an rvalue
+  std::vector<double> released_vec = std::move(list).ReleaseVector();
+
+  // Check the released vector
+  EXPECT_EQ(released_vec.size(), 3);
+  EXPECT_THAT(released_vec, ElementsAreArray({10.0, 11.0, 12.0}));
+  EXPECT_EQ(released_vec.data(), original_data_ptr);
+}
+
+// Test ReleaseVector when the list has a non-owning view
+TEST(DoubleListTest, ReleaseVectorView) {
+  const double external_data[] = {13.0, 14.0};
+  DoubleList list(external_data, 2);
+  const double* original_view_ptr = list.data();
+
+  // ReleaseVector must be called on an rvalue
+  std::vector<double> released_vec = std::move(list).ReleaseVector();
+
+  // Check the released vector - it should be a COPY
+  EXPECT_EQ(released_vec.size(), 2);
+  EXPECT_THAT(released_vec, ElementsAreArray({13.0, 14.0}));
+
+  // IMPORTANT: Verify it's a copy, not pointing to the original external data
+  EXPECT_NE(released_vec.data(), original_view_ptr);
+}
+
+// Test ReleaseVector when the list is empty (default constructed - view)
+TEST(DoubleListTest, ReleaseVectorEmptyDefault) {
+  DoubleList list;  // Empty view by default
+  std::vector<double> released_vec = std::move(list).ReleaseVector();
+  EXPECT_TRUE(released_vec.empty());
+  EXPECT_THAT(released_vec, IsEmpty());
+}
+
+// Test ReleaseVector when the list is empty (constructed from empty view)
+TEST(DoubleListTest, ReleaseVectorEmptyView) {
+  DoubleList list(nullptr, 0);  // Empty view
+  std::vector<double> released_vec = std::move(list).ReleaseVector();
+  EXPECT_TRUE(released_vec.empty());
+  EXPECT_THAT(released_vec, IsEmpty());
+}
+
+// Test ReleaseVector when the list is empty (constructed from empty vector -
+// owned)
+TEST(DoubleListTest, ReleaseVectorEmptyOwned) {
+  DoubleList list(std::vector<double>{});  // Empty owned vector
+  std::vector<double> released_vec = std::move(list).ReleaseVector();
+  EXPECT_TRUE(released_vec.empty());
+  EXPECT_THAT(released_vec, IsEmpty());
+}
+
+}  // namespace
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/scoring/advanced_scoring/score-expression-util_test.cc b/icing/scoring/advanced_scoring/score-expression-util_test.cc
index 4e4355b..51b849a 100644
--- a/icing/scoring/advanced_scoring/score-expression-util_test.cc
+++ b/icing/scoring/advanced_scoring/score-expression-util_test.cc
@@ -29,6 +29,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/hit/doc-hit-info.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
@@ -42,6 +43,7 @@
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -72,14 +74,18 @@ class ScoreExpressionUtilTest : public testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     // Creates the schema
@@ -204,8 +210,8 @@ TEST_F(ScoreExpressionUtilTest,
 TEST_F(ScoreExpressionUtilTest, SimpleExpression) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri", /*score=*/10,
-                                          /*creation_timestamp_ms=*/100)));
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "namespace", "uri", /*score=*/10, /*creation_timestamp_ms=*/100))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo doc_hit_info = DocHitInfo(document_id);
 
@@ -228,8 +234,8 @@ TEST_F(ScoreExpressionUtilTest, SimpleExpression) {
 TEST_F(ScoreExpressionUtilTest, DocumentFunctionsWithoutOptionalDependencies) {
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      document_store_->Put(CreateDocument("namespace", "uri", /*score=*/10,
-                                          /*creation_timestamp_ms=*/100)));
+      document_store_->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "namespace", "uri", /*score=*/10, /*creation_timestamp_ms=*/100))));
   DocumentId document_id = put_result.new_document_id;
   DocHitInfo doc_hit_info = DocHitInfo(document_id);
 
diff --git a/icing/scoring/advanced_scoring/score-expression.cc b/icing/scoring/advanced_scoring/score-expression.cc
index 445e1f3..2dcd20d 100644
--- a/icing/scoring/advanced_scoring/score-expression.cc
+++ b/icing/scoring/advanced_scoring/score-expression.cc
@@ -41,6 +41,7 @@
 #include "icing/proto/internal/scorable_property_set.pb.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
+#include "icing/scoring/advanced_scoring/double-list.h"
 #include "icing/scoring/bm25f-calculator.h"
 #include "icing/scoring/scored-document-hit.h"
 #include "icing/scoring/section-weights.h"
@@ -312,89 +313,106 @@ MathFunctionScoreExpression::Create(
 libtextclassifier3::StatusOr<double>
 MathFunctionScoreExpression::EvaluateDouble(
     const DocHitInfo& hit_info, const DocHitInfoIterator* query_it) const {
-  std::vector<double> values;
+  DoubleList list_value;
+  std::vector<double> double_values;
   int ind = 0;
   if (args_.at(0)->type() == ScoreExpressionType::kDoubleList) {
-    ICING_ASSIGN_OR_RETURN(values,
+    ICING_ASSIGN_OR_RETURN(list_value,
                            args_.at(0)->EvaluateList(hit_info, query_it));
     ind = 1;
   }
+  double_values.reserve(args_.size() - ind);
   for (; ind < args_.size(); ++ind) {
     ICING_ASSIGN_OR_RETURN(double v,
                            args_.at(ind)->EvaluateDouble(hit_info, query_it));
-    values.push_back(v);
+    double_values.push_back(v);
+  }
+
+  // Double values in variable-argument functions can be treated as a single
+  // list.
+  if (kVariableArgumentsFunctions.count(function_type_) > 0 &&
+      !double_values.empty()) {
+    if (!list_value.empty()) {
+      return absl_ports::InternalError(
+          "Should never reach here, since static type checking should not "
+          "allow variable-argument functions to have both list arguments and "
+          "double arguments.");
+    }
+    list_value = DoubleList(std::move(double_values));
+    double_values.clear();
   }
 
   double res = 0;
   switch (function_type_) {
     case FunctionType::kLog:
-      if (values.size() == 1) {
-        res = log(values[0]);
+      if (double_values.size() == 1) {
+        res = log(double_values[0]);
       } else {
         // argument 0 is log base
         // argument 1 is the value
-        res = log(values[1]) / log(values[0]);
+        res = log(double_values[1]) / log(double_values[0]);
       }
       break;
     case FunctionType::kPow:
-      res = pow(values[0], values[1]);
+      res = pow(double_values[0], double_values[1]);
+      break;
+    case FunctionType::kSqrt:
+      res = sqrt(double_values[0]);
+      break;
+    case FunctionType::kAbs:
+      res = abs(double_values[0]);
+      break;
+    case FunctionType::kSin:
+      res = sin(double_values[0]);
+      break;
+    case FunctionType::kCos:
+      res = cos(double_values[0]);
+      break;
+    case FunctionType::kTan:
+      res = tan(double_values[0]);
       break;
+    // Variable-argument functions
     case FunctionType::kMax:
-      if (values.empty()) {
+      if (list_value.empty()) {
         return absl_ports::InvalidArgumentError(
             "Got an empty parameter set in max function");
       }
-      res = *std::max_element(values.begin(), values.end());
+      res = *std::max_element(list_value.begin(), list_value.end());
       break;
     case FunctionType::kMin:
-      if (values.empty()) {
+      if (list_value.empty()) {
         return absl_ports::InvalidArgumentError(
             "Got an empty parameter set in min function");
       }
-      res = *std::min_element(values.begin(), values.end());
+      res = *std::min_element(list_value.begin(), list_value.end());
       break;
     case FunctionType::kLen:
-      res = values.size();
+      res = list_value.size();
       break;
     case FunctionType::kSum:
-      res = std::reduce(values.begin(), values.end());
+      res = std::reduce(list_value.begin(), list_value.end());
       break;
     case FunctionType::kAvg:
-      if (values.empty()) {
+      if (list_value.empty()) {
         return absl_ports::InvalidArgumentError(
             "Got an empty parameter set in avg function.");
       }
-      res = std::reduce(values.begin(), values.end()) / values.size();
+      res =
+          std::reduce(list_value.begin(), list_value.end()) / list_value.size();
       break;
-    case FunctionType::kSqrt:
-      res = sqrt(values[0]);
-      break;
-    case FunctionType::kAbs:
-      res = abs(values[0]);
-      break;
-    case FunctionType::kSin:
-      res = sin(values[0]);
-      break;
-    case FunctionType::kCos:
-      res = cos(values[0]);
-      break;
-    case FunctionType::kTan:
-      res = tan(values[0]);
-      break;
-    // For the following two functions, the last value is the default value.
-    // If values.size() == 1, then it means the provided list is empty.
+    // For the following two functions, double_values[0] is the default value.
     case FunctionType::kMaxOrDefault:
-      if (values.size() == 1) {
-        res = values[0];
+      if (list_value.empty()) {
+        res = double_values[0];
       } else {
-        res = *std::max_element(values.begin(), values.end() - 1);
+        res = *std::max_element(list_value.begin(), list_value.end());
       }
       break;
     case FunctionType::kMinOrDefault:
-      if (values.size() == 1) {
-        res = values[0];
+      if (list_value.empty()) {
+        res = double_values[0];
       } else {
-        res = *std::min_element(values.begin(), values.end() - 1);
+        res = *std::min_element(list_value.begin(), list_value.end());
       }
       break;
   }
@@ -444,12 +462,12 @@ ListOperationFunctionScoreExpression::Create(
       new ListOperationFunctionScoreExpression(function_type, std::move(args)));
 }
 
-libtextclassifier3::StatusOr<std::vector<double>>
+libtextclassifier3::StatusOr<DoubleList>
 ListOperationFunctionScoreExpression::EvaluateList(
     const DocHitInfo& hit_info, const DocHitInfoIterator* query_it) const {
   switch (function_type_) {
     case FunctionType::kFilterByRange:
-      ICING_ASSIGN_OR_RETURN(std::vector<double> list_value,
+      ICING_ASSIGN_OR_RETURN(DoubleList list_value,
                              args_.at(0)->EvaluateList(hit_info, query_it));
       ICING_ASSIGN_OR_RETURN(double low,
                              args_.at(1)->EvaluateDouble(hit_info, query_it));
@@ -459,11 +477,13 @@ ListOperationFunctionScoreExpression::EvaluateList(
         return absl_ports::InvalidArgumentError(
             "The lower bound cannot be greater than the upper bound.");
       }
+      // TODO(b/408437387): Consider avoiding a copy if nothing is filtered out.
+      std::vector<double> new_list = std::move(list_value).ReleaseVector();
       auto new_end =
-          std::remove_if(list_value.begin(), list_value.end(),
+          std::remove_if(new_list.begin(), new_list.end(),
                          [low, high](double v) { return v < low || v > high; });
-      list_value.erase(new_end, list_value.end());
-      return list_value;
+      new_list.erase(new_end, new_list.end());
+      return DoubleList(std::move(new_list));
       break;
   }
   return absl_ports::InternalError("Should never reach here.");
@@ -629,7 +649,7 @@ ChildrenRankingSignalsFunctionScoreExpression::Create(
           document_store, *join_children_fetcher, current_time_ms));
 }
 
-libtextclassifier3::StatusOr<std::vector<double>>
+libtextclassifier3::StatusOr<DoubleList>
 ChildrenRankingSignalsFunctionScoreExpression::EvaluateList(
     const DocHitInfo& hit_info, const DocHitInfoIterator* query_it) const {
   ICING_ASSIGN_OR_RETURN(
@@ -640,7 +660,7 @@ ChildrenRankingSignalsFunctionScoreExpression::EvaluateList(
   for (const ScoredDocumentHit& child_hit : children_hits) {
     children_scores.push_back(child_hit.score());
   }
-  return std::move(children_scores);
+  return DoubleList(std::move(children_scores));
 }
 
 libtextclassifier3::StatusOr<
@@ -664,7 +684,7 @@ PropertyWeightsFunctionScoreExpression::Create(
           document_store, section_weights, current_time_ms));
 }
 
-libtextclassifier3::StatusOr<std::vector<double>>
+libtextclassifier3::StatusOr<DoubleList>
 PropertyWeightsFunctionScoreExpression::EvaluateList(
     const DocHitInfo& hit_info, const DocHitInfoIterator*) const {
   std::vector<double> weights;
@@ -678,7 +698,7 @@ PropertyWeightsFunctionScoreExpression::EvaluateList(
     weights.push_back(section_weights_.GetNormalizedSectionWeight(
         schema_type_id, section_id));
   }
-  return weights;
+  return DoubleList(std::move(weights));
 }
 
 libtextclassifier3::StatusOr<std::unique_ptr<ScoreExpression>>
@@ -767,13 +787,16 @@ MatchedSemanticScoresFunctionScoreExpression::Create(
         metric_type,
         embedding_util::GetEmbeddingQueryMetricTypeFromName(metric));
   }
+  const EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* match_info_map_ =
+      nullptr;
   if (embedding_index_arg->is_constant()) {
     ICING_ASSIGN_OR_RETURN(
         uint32_t embedding_index,
         embedding_index_arg->EvaluateDouble(DocHitInfo(),
                                             /*query_it=*/nullptr));
-    if (embedding_query_results->GetMatchInfoMap(embedding_index,
-                                                 metric_type) == nullptr) {
+    match_info_map_ =
+        embedding_query_results->GetMatchInfoMap(embedding_index, metric_type);
+    if (match_info_map_ == nullptr) {
       return absl_ports::InvalidArgumentError(absl_ports::StrCat(
           "The embedding query index ", std::to_string(embedding_index),
           " with metric type ",
@@ -783,22 +806,26 @@ MatchedSemanticScoresFunctionScoreExpression::Create(
   }
   return std::unique_ptr<MatchedSemanticScoresFunctionScoreExpression>(
       new MatchedSemanticScoresFunctionScoreExpression(
-          std::move(args), metric_type, *embedding_query_results));
+          std::move(args), metric_type, *embedding_query_results,
+          match_info_map_));
 }
 
-libtextclassifier3::StatusOr<std::vector<double>>
+libtextclassifier3::StatusOr<DoubleList>
 MatchedSemanticScoresFunctionScoreExpression::EvaluateList(
     const DocHitInfo& hit_info, const DocHitInfoIterator* query_it) const {
   ICING_ASSIGN_OR_RETURN(double raw_query_index,
                          args_[1]->EvaluateDouble(hit_info, query_it));
   uint32_t query_index = (uint32_t)raw_query_index;
-  const std::vector<double>* scores =
-      embedding_query_results_.GetMatchedScoresForDocument(
-          query_index, metric_type_, hit_info.document_id());
-  if (scores == nullptr) {
-    return std::vector<double>();
+  if (match_info_map_ != nullptr) {
+    auto info_it = match_info_map_->find(hit_info.document_id());
+    if (info_it == match_info_map_->end()) {
+      return DoubleList();
+    }
+    return embedding_query_results_.GetMatchedScoresFromEmbeddingMatchInfos(
+        info_it->second);
   }
-  return *scores;
+  return embedding_query_results_.GetMatchedScoresForDocument(
+      query_index, metric_type_, hit_info.document_id());
 }
 
 GetScorablePropertyFunctionScoreExpression::
@@ -885,13 +912,13 @@ GetScorablePropertyFunctionScoreExpression::Create(
           std::move(schema_type_ids), property_path));
 }
 
-libtextclassifier3::StatusOr<std::vector<double>>
+libtextclassifier3::StatusOr<DoubleList>
 GetScorablePropertyFunctionScoreExpression::EvaluateList(
     const DocHitInfo& hit_info, const DocHitInfoIterator* query_it) const {
   SchemaTypeId doc_schema_type_id = GetSchemaTypeId(
       hit_info.document_id(), document_store_, current_time_ms_);
   if (schema_type_ids_.find(doc_schema_type_id) == schema_type_ids_.end()) {
-    return std::vector<double>();
+    return DoubleList();
   }
 
   // By this point, the document to be evaluated is guaranteed to have a
@@ -920,17 +947,19 @@ GetScorablePropertyFunctionScoreExpression::EvaluateList(
 
   // Converts ScorablePropertyProto to a vector of doubles.
   if (scorable_property_proto->int64_values_size() > 0) {
-    return std::vector<double>(scorable_property_proto->int64_values().begin(),
-                               scorable_property_proto->int64_values().end());
+    return DoubleList(
+        std::vector<double>(scorable_property_proto->int64_values().begin(),
+                            scorable_property_proto->int64_values().end()));
   } else if (scorable_property_proto->double_values_size() > 0) {
-    return std::vector<double>(scorable_property_proto->double_values().begin(),
-                               scorable_property_proto->double_values().end());
+    return DoubleList(
+        std::vector<double>(scorable_property_proto->double_values().begin(),
+                            scorable_property_proto->double_values().end()));
   } else if (scorable_property_proto->boolean_values_size() > 0) {
-    return std::vector<double>(
-        scorable_property_proto->boolean_values().begin(),
-        scorable_property_proto->boolean_values().end());
+    return DoubleList(
+        std::vector<double>(scorable_property_proto->boolean_values().begin(),
+                            scorable_property_proto->boolean_values().end()));
   }
-  return std::vector<double>();
+  return DoubleList();
 }
 
 }  // namespace lib
diff --git a/icing/scoring/advanced_scoring/score-expression.h b/icing/scoring/advanced_scoring/score-expression.h
index 53c5807..5df15ec 100644
--- a/icing/scoring/advanced_scoring/score-expression.h
+++ b/icing/scoring/advanced_scoring/score-expression.h
@@ -31,12 +31,11 @@
 #include "icing/index/iterator/doc-hit-info-iterator.h"
 #include "icing/join/join-children-fetcher.h"
 #include "icing/schema/schema-store.h"
+#include "icing/scoring/advanced_scoring/double-list.h"
 #include "icing/scoring/bm25f-calculator.h"
 #include "icing/scoring/section-weights.h"
 #include "icing/store/document-filter-data.h"
-#include "icing/store/document-id.h"
 #include "icing/store/document-store.h"
-#include "icing/util/status-macros.h"
 
 namespace icing {
 namespace lib {
@@ -78,7 +77,7 @@ class ScoreExpression {
         "double. There must be inconsistencies in the static type checking.");
   }
 
-  virtual libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  virtual libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo& hit_info, const DocHitInfoIterator* query_it) const {
     if (type() == ScoreExpressionType::kDoubleList) {
       return absl_ports::UnimplementedError(
@@ -269,7 +268,7 @@ class ListOperationFunctionScoreExpression : public ScoreExpression {
       FunctionType function_type,
       std::vector<std::unique_ptr<ScoreExpression>> args);
 
-  libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo& hit_info,
       const DocHitInfoIterator* query_it) const override;
 
@@ -381,7 +380,7 @@ class ChildrenRankingSignalsFunctionScoreExpression : public ScoreExpression {
          const JoinChildrenFetcher* join_children_fetcher,
          int64_t current_time_ms);
 
-  libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo& hit_info,
       const DocHitInfoIterator* query_it) const override;
 
@@ -416,7 +415,7 @@ class PropertyWeightsFunctionScoreExpression : public ScoreExpression {
          const DocumentStore* document_store,
          const SectionWeights* section_weights, int64_t current_time_ms);
 
-  libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo& hit_info, const DocHitInfoIterator*) const override;
 
   ScoreExpressionType type() const override {
@@ -477,7 +476,7 @@ class MatchedSemanticScoresFunctionScoreExpression : public ScoreExpression {
          SearchSpecProto::EmbeddingQueryMetricType::Code default_metric_type,
          const EmbeddingQueryResults* embedding_query_results);
 
-  libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo& hit_info,
       const DocHitInfoIterator* query_it) const override;
 
@@ -489,14 +488,20 @@ class MatchedSemanticScoresFunctionScoreExpression : public ScoreExpression {
   explicit MatchedSemanticScoresFunctionScoreExpression(
       std::vector<std::unique_ptr<ScoreExpression>> args,
       SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
-      const EmbeddingQueryResults& embedding_query_results)
+      const EmbeddingQueryResults& embedding_query_results,
+      const EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* match_info_map)
       : args_(std::move(args)),
         metric_type_(metric_type),
-        embedding_query_results_(embedding_query_results) {}
+        embedding_query_results_(embedding_query_results),
+        match_info_map_(match_info_map) {}
 
   std::vector<std::unique_ptr<ScoreExpression>> args_;
   const SearchSpecProto::EmbeddingQueryMetricType::Code metric_type_;
   const EmbeddingQueryResults& embedding_query_results_;
+  // If the embedding vector's index evaluated from args is a constant, this is
+  // the corresponding EmbeddingQueryMatchInfoMap for the embedding query.
+  // Otherwise, this is nullptr.
+  const EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* match_info_map_;
 };
 
 class GetScorablePropertyFunctionScoreExpression : public ScoreExpression {
@@ -522,7 +527,7 @@ class GetScorablePropertyFunctionScoreExpression : public ScoreExpression {
     return ScoreExpressionType::kDoubleList;
   }
 
-  libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo& hit_info,
       const DocHitInfoIterator* query_it) const override;
 
diff --git a/icing/scoring/advanced_scoring/score-expression_test.cc b/icing/scoring/advanced_scoring/score-expression_test.cc
index cbfed9b..391248d 100644
--- a/icing/scoring/advanced_scoring/score-expression_test.cc
+++ b/icing/scoring/advanced_scoring/score-expression_test.cc
@@ -24,6 +24,7 @@
 #include "gtest/gtest.h"
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/scoring/advanced_scoring/double-list.h"
 #include "icing/testing/common-matchers.h"
 
 namespace icing {
@@ -62,9 +63,9 @@ class ListScoreExpression : public ScoreExpression {
     return res;
   }
 
-  libtextclassifier3::StatusOr<std::vector<double>> EvaluateList(
+  libtextclassifier3::StatusOr<DoubleList> EvaluateList(
       const DocHitInfo &, const DocHitInfoIterator *) const override {
-    return values;
+    return DoubleList(values.data(), values.size());
   }
 
   ScoreExpressionType type() const override {
diff --git a/icing/scoring/priority-queue-scored-document-hits-ranker.h b/icing/scoring/priority-queue-scored-document-hits-ranker.h
index 68cf921..135e0e3 100644
--- a/icing/scoring/priority-queue-scored-document-hits-ranker.h
+++ b/icing/scoring/priority-queue-scored-document-hits-ranker.h
@@ -15,6 +15,7 @@
 #ifndef ICING_SCORING_PRIORITY_QUEUE_SCORED_DOCUMENT_HITS_RANKER_H_
 #define ICING_SCORING_PRIORITY_QUEUE_SCORED_DOCUMENT_HITS_RANKER_H_
 
+#include <memory>
 #include <queue>
 #include <unordered_set>
 #include <vector>
@@ -37,22 +38,23 @@ class PriorityQueueScoredDocumentHitsRanker : public ScoredDocumentHitsRanker {
 
   ~PriorityQueueScoredDocumentHitsRanker() override = default;
 
+  void Pop() override;
+
   // Note: ranker may store ScoredDocumentHit or JoinedScoredDocumentHit, so we
   // have template for scored_data_pq_.
   // - JoinedScoredDocumentHit is a superset of ScoredDocumentHit, so we unify
-  //   the return type of PopNext to use the superset type
-  //   JoinedScoredDocumentHit in order to make it simple, and rankers storing
-  //   ScoredDocumentHit should convert it to JoinedScoredDocumentHit before
-  //   returning. It makes the implementation simpler, especially for
-  //   ResultRetriever, which now only needs to deal with one single return
-  //   format.
+  //   the return type of Top to use the superset type JoinedScoredDocumentHit
+  //   in order to make it simple, and rankers storing ScoredDocumentHit should
+  //   convert it to JoinedScoredDocumentHit before returning. It makes the
+  //   implementation simpler, especially for ResultRetriever, which now only
+  //   needs to deal with one single return format.
   // - JoinedScoredDocumentHit has ~2x size of ScoredDocumentHit. Since we cache
   //   ranker (which contains a priority queue of data) in ResultState, if we
   //   store the scored hits in JoinedScoredDocumentHit format directly, then it
   //   doubles the memory usage. Therefore, we still keep the flexibility to
-  //   store ScoredDocumentHit or any other types of data, but require PopNext
-  //   to convert it to JoinedScoredDocumentHit.
-  JoinedScoredDocumentHit PopNext() override;
+  //   store ScoredDocumentHit or any other types of data, but require Pop to
+  //   convert it to JoinedScoredDocumentHit and cache it in curr_.
+  const JoinedScoredDocumentHit& Top() const override { return *curr_; }
 
   // Returns DocumentIds of the top K documents according to the ranking policy.
   // - For ScoredDocumentHit, this returns the DocumentIds of the top K
@@ -70,7 +72,7 @@ class PriorityQueueScoredDocumentHitsRanker : public ScoredDocumentHitsRanker {
 
   int size() const override { return scored_data_pq_.size(); }
 
-  bool empty() const override { return scored_data_pq_.empty(); }
+  bool empty() const override { return curr_ == nullptr; }
 
  private:
   // Comparator for std::priority_queue. Since std::priority is a max heap
@@ -95,6 +97,11 @@ class PriorityQueueScoredDocumentHitsRanker : public ScoredDocumentHitsRanker {
     bool is_ascending_;
   };
 
+  // Helper function to refresh the current element (fetch the top element from
+  // the priority queue, convert it to JoinedScoredDocumentHit, and cache it in
+  // curr_).
+  void RefreshCurrent();
+
   Comparator comparator_;
 
   // Use priority queue to get top K hits in O(KlgN) time.
@@ -102,6 +109,8 @@ class PriorityQueueScoredDocumentHitsRanker : public ScoredDocumentHitsRanker {
       scored_data_pq_;
 
   Converter converter_;
+
+  std::unique_ptr<JoinedScoredDocumentHit> curr_;
 };
 
 template <typename ScoredDataType, typename Converter>
@@ -109,14 +118,14 @@ PriorityQueueScoredDocumentHitsRanker<ScoredDataType, Converter>::
     PriorityQueueScoredDocumentHitsRanker(
         std::vector<ScoredDataType>&& scored_data_vec, bool is_descending)
     : comparator_(/*is_ascending=*/!is_descending),
-      scored_data_pq_(comparator_, std::move(scored_data_vec)) {}
+      scored_data_pq_(comparator_, std::move(scored_data_vec)) {
+  RefreshCurrent();
+}
 
 template <typename ScoredDataType, typename Converter>
-JoinedScoredDocumentHit
-PriorityQueueScoredDocumentHitsRanker<ScoredDataType, Converter>::PopNext() {
-  ScoredDataType next_scored_data = scored_data_pq_.top();
+void PriorityQueueScoredDocumentHitsRanker<ScoredDataType, Converter>::Pop() {
   scored_data_pq_.pop();
-  return converter_(std::move(next_scored_data));
+  RefreshCurrent();
 }
 
 template <typename ScoredDataType, typename Converter>
@@ -192,7 +201,27 @@ void PriorityQueueScoredDocumentHitsRanker<
     new_pq.push(scored_data_pq_.top());
     scored_data_pq_.pop();
   }
+
+  // Assign back to the class members.
   scored_data_pq_ = std::move(new_pq);
+  RefreshCurrent();
+}
+
+template <typename ScoredDataType, typename Converter>
+void PriorityQueueScoredDocumentHitsRanker<ScoredDataType,
+                                           Converter>::RefreshCurrent() {
+  if (scored_data_pq_.empty()) {
+    curr_ = nullptr;
+  } else {
+    ScoredDataType scored_data = scored_data_pq_.top();
+
+    if (curr_ == nullptr) {
+      curr_ = std::make_unique<JoinedScoredDocumentHit>(
+          converter_(std::move(scored_data)));
+    } else {
+      *curr_ = converter_(std::move(scored_data));
+    }
+  }
 }
 
 }  // namespace lib
diff --git a/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc b/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc
index 19a9ebb..7ec1d68 100644
--- a/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc
+++ b/icing/scoring/priority-queue-scored-document-hits-ranker_test.cc
@@ -48,7 +48,8 @@ std::vector<JoinedScoredDocumentHit> PopAll(
     PriorityQueueScoredDocumentHitsRanker<ScoredDocumentHit>& ranker) {
   std::vector<JoinedScoredDocumentHit> hits;
   while (!ranker.empty()) {
-    hits.push_back(ranker.PopNext());
+    hits.push_back(ranker.Top());
+    ranker.Pop();
   }
   return hits;
 }
@@ -57,7 +58,8 @@ std::vector<JoinedScoredDocumentHit> PopAll(
     PriorityQueueScoredDocumentHitsRanker<JoinedScoredDocumentHit>& ranker) {
   std::vector<JoinedScoredDocumentHit> hits;
   while (!ranker.empty()) {
-    hits.push_back(ranker.PopNext());
+    hits.push_back(ranker.Top());
+    ranker.Pop();
   }
   return hits;
 }
@@ -76,15 +78,15 @@ TEST(PriorityQueueScoredDocumentHitsRankerTest, ShouldGetCorrectSizeAndEmpty) {
   EXPECT_THAT(ranker.size(), Eq(3));
   EXPECT_FALSE(ranker.empty());
 
-  ranker.PopNext();
+  ranker.Pop();
   EXPECT_THAT(ranker.size(), Eq(2));
   EXPECT_FALSE(ranker.empty());
 
-  ranker.PopNext();
+  ranker.Pop();
   EXPECT_THAT(ranker.size(), Eq(1));
   EXPECT_FALSE(ranker.empty());
 
-  ranker.PopNext();
+  ranker.Pop();
   EXPECT_THAT(ranker.size(), Eq(0));
   EXPECT_TRUE(ranker.empty());
 }
diff --git a/icing/scoring/score-and-rank_benchmark.cc b/icing/scoring/score-and-rank_benchmark.cc
index c8f6c00..006457f 100644
--- a/icing/scoring/score-and-rank_benchmark.cc
+++ b/icing/scoring/score-and-rank_benchmark.cc
@@ -32,6 +32,7 @@
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/iterator/doc-hit-info-iterator-test-util.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
@@ -46,6 +47,7 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
 
 // This is an overall benchmark for ScoringProcessor, Scorer, and Ranker. It
 // shows how performance varies when we score different numbers of document
@@ -85,6 +87,12 @@ SchemaProto CreateSchemaWithEmailType() {
   return schema;
 }
 
+DocumentWrapper CreateDocumentWrapper(DocumentProto document,
+                                      int32_t num_string_tokens) {
+  document.mutable_internal_fields()->set_length_in_tokens(num_string_tokens);
+  return document_util::CreateDocumentWrapper(std::move(document));
+}
+
 DocumentProto CreateEmailDocument(int id, int document_score,
                                   uint64_t creation_timestamp_ms) {
   return DocumentBuilder()
@@ -105,6 +113,9 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
       PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+      PortableFileBackedProtoLog<
+          DocumentWrapper>::kDefaultCompressionThresholdBytes,
+      protobuf_ports::kDefaultMemLevel,
       /*initialize_stats=*/nullptr);
 }
 
@@ -160,9 +171,10 @@ void BM_ScoreAndRankDocumentHitsByDocumentScore(benchmark::State& state) {
   for (int i = 0; i < num_of_documents; i++) {
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::PutResult put_result,
-        document_store->Put(CreateEmailDocument(
-            /*id=*/i, /*document_score=*/distribution(random_generator),
-            /*creation_timestamp_ms=*/1)));
+        document_store->Put(
+            document_util::CreateDocumentWrapper(CreateEmailDocument(
+                /*id=*/i, /*document_score=*/distribution(random_generator),
+                /*creation_timestamp_ms=*/1))));
     DocumentId document_id = put_result.new_document_id;
     doc_hit_infos.emplace_back(document_id);
   }
@@ -273,9 +285,10 @@ void BM_ScoreAndRankDocumentHitsByCreationTime(benchmark::State& state) {
   for (int i = 0; i < num_of_documents; i++) {
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::PutResult put_result,
-        document_store->Put(CreateEmailDocument(
-            /*id=*/i, /*document_score=*/1,
-            /*creation_timestamp_ms=*/distribution(random_generator))));
+        document_store->Put(
+            document_util::CreateDocumentWrapper(CreateEmailDocument(
+                /*id=*/i, /*document_score=*/1,
+                /*creation_timestamp_ms=*/distribution(random_generator)))));
     DocumentId document_id = put_result.new_document_id;
     doc_hit_infos.emplace_back(document_id);
   }
@@ -382,8 +395,9 @@ void BM_ScoreAndRankDocumentHitsNoScoring(benchmark::State& state) {
   for (int i = 0; i < num_of_documents; i++) {
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::PutResult put_result,
-        document_store->Put(CreateEmailDocument(/*id=*/i, /*document_score=*/1,
-                                                /*creation_timestamp_ms=*/1)));
+        document_store->Put(document_util::CreateDocumentWrapper(
+            CreateEmailDocument(/*id=*/i, /*document_score=*/1,
+                                /*creation_timestamp_ms=*/1))));
     DocumentId document_id = put_result.new_document_id;
     doc_hit_infos.emplace_back(document_id);
   }
@@ -497,10 +511,10 @@ void BM_ScoreAndRankDocumentHitsByRelevanceScoring(benchmark::State& state) {
   for (int i = 0; i < num_of_documents; i++) {
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::PutResult put_result,
-        document_store->Put(CreateEmailDocument(
-                                /*id=*/i, /*document_score=*/1,
+        document_store->Put(CreateDocumentWrapper(
+            CreateEmailDocument(/*id=*/i, /*document_score=*/1,
                                 /*creation_timestamp_ms=*/1),
-                            /*num_tokens=*/10));
+            /*num_string_tokens=*/10)));
     DocumentId document_id = put_result.new_document_id;
     DocHitInfoTermFrequencyPair doc_hit =
         DocHitInfo(document_id, section_id_mask);
diff --git a/icing/scoring/scored-document-hits-ranker.h b/icing/scoring/scored-document-hits-ranker.h
index 2a7956d..9135ecb 100644
--- a/icing/scoring/scored-document-hits-ranker.h
+++ b/icing/scoring/scored-document-hits-ranker.h
@@ -25,7 +25,7 @@ namespace lib {
 
 // TODO(sungyc): re-evaluate other similar implementations (e.g. std::sort +
 //               std::queue/std::vector). Also revisit the capacity shrinking
-//               issue for PopNext().
+//               issue for Pop().
 
 // ScoredDocumentHitsRanker is an interface class for ranking
 // ScoredDocumentHits.
@@ -33,19 +33,24 @@ class ScoredDocumentHitsRanker {
  public:
   virtual ~ScoredDocumentHitsRanker() = default;
 
-  // Pop the next top JoinedScoredDocumentHit and return. It is undefined to
-  // call PopNext on an empty ranker, so the caller should check if it is not
-  // empty before calling.
+  // Pops the current element and moves to the next one.
+  //
+  // REQUIRES: !empty().
+  virtual void Pop() = 0;
+
+  // Returns the top JoinedScoredDocumentHit.
   //
   // Note: ranker may store ScoredDocumentHit or JoinedScoredDocumentHit. We can
   // add template for this interface, but since JoinedScoredDocumentHit is a
-  // superset of ScoredDocumentHit, we unify the return type of PopNext to use
-  // the superset type JoinedScoredDocumentHit in order to make it simple, and
+  // superset of ScoredDocumentHit, we unify the return type of Top to use the
+  // superset type JoinedScoredDocumentHit in order to make it simple, and
   // rankers storing ScoredDocumentHit should convert it to
   // JoinedScoredDocumentHit before returning. It makes the implementation
   // simpler, especially for ResultRetriever, which now only needs to deal with
   // one single return format.
-  virtual JoinedScoredDocumentHit PopNext() = 0;
+  //
+  // REQUIRES: !empty().
+  virtual const JoinedScoredDocumentHit& Top() const = 0;
 
   // Truncates the remaining ScoredDocumentHits to the given size. The best
   // ScoredDocumentHits (according to the ranking policy) should be kept.
diff --git a/icing/scoring/scorer_test.cc b/icing/scoring/scorer_test.cc
index 98ca18e..e849971 100644
--- a/icing/scoring/scorer_test.cc
+++ b/icing/scoring/scorer_test.cc
@@ -29,6 +29,7 @@
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/index/embed/embedding-query-results.h"
 #include "icing/index/hit/doc-hit-info.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
@@ -43,6 +44,7 @@
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 
 namespace icing {
 namespace lib {
@@ -73,14 +75,18 @@ class ScorerTest : public ::testing::TestWithParam<ScorerTestingMode> {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock1_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock1_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     // Creates a simple email schema
@@ -193,8 +199,10 @@ TEST_P(ScorerTest, ShouldGetDefaultDocumentScore) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<Scorer> scorer,
@@ -221,8 +229,10 @@ TEST_P(ScorerTest, ShouldGetCorrectDocumentScore) {
           .SetCreationTimestampMs(fake_clock2().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<Scorer> scorer,
@@ -251,8 +261,10 @@ TEST_P(ScorerTest, QueryIteratorNullRelevanceScoreShouldReturnDefaultScore) {
           .SetCreationTimestampMs(fake_clock2().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<Scorer> scorer,
@@ -286,11 +298,15 @@ TEST_P(ScorerTest, ShouldGetCorrectCreationTimestampScore) {
           .SetCreationTimestampMs(fake_clock2().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store()->Put(test_document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store()->Put(test_document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document2)));
   DocumentId document_id2 = put_result2.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       std::unique_ptr<Scorer> scorer,
@@ -320,8 +336,10 @@ TEST_P(ScorerTest, ShouldGetCorrectUsageCountScoreForType1) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create 3 scorers for 3 different usage types.
@@ -377,8 +395,10 @@ TEST_P(ScorerTest, ShouldGetCorrectUsageCountScoreForType2) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create 3 scorers for 3 different usage types.
@@ -434,8 +454,10 @@ TEST_P(ScorerTest, ShouldGetCorrectUsageCountScoreForType3) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create 3 scorers for 3 different usage types.
@@ -491,8 +513,10 @@ TEST_P(ScorerTest, ShouldGetCorrectUsageTimestampScoreForType1) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create 3 scorers for 3 different usage types.
@@ -570,8 +594,10 @@ TEST_P(ScorerTest, ShouldGetCorrectUsageTimestampScoreForType2) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create 3 scorers for 3 different usage types.
@@ -649,8 +675,10 @@ TEST_P(ScorerTest, ShouldGetCorrectUsageTimestampScoreForType3) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   // Create 3 scorers for 3 different usage types.
@@ -764,8 +792,10 @@ TEST_P(ScorerTest, ShouldScaleUsageTimestampScoreForMaxTimestamp) {
           .SetCreationTimestampMs(fake_clock1().GetSystemTimeMilliseconds())
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             document_store()->Put(test_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      document_store()->Put(
+          document_util::CreateDocumentWrapper(test_document)));
   DocumentId document_id = put_result.new_document_id;
 
   ICING_ASSERT_OK_AND_ASSIGN(
diff --git a/icing/scoring/scoring-processor_test.cc b/icing/scoring/scoring-processor_test.cc
index f2dc84b..d94b054 100644
--- a/icing/scoring/scoring-processor_test.cc
+++ b/icing/scoring/scoring-processor_test.cc
@@ -33,6 +33,7 @@
 #include "icing/index/hit/doc-hit-info.h"
 #include "icing/index/iterator/doc-hit-info-iterator-test-util.h"
 #include "icing/index/iterator/doc-hit-info-iterator.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/scoring.pb.h"
@@ -49,6 +50,7 @@
 #include "icing/testing/fake-clock.h"
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
+#include "icing/util/document-util.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -82,14 +84,18 @@ class ScoringProcessorTest
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, doc_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/true,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, doc_store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/true,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     // Creates a simple email schema
@@ -158,6 +164,12 @@ DocumentProto CreateDocument(const std::string& name_space,
       .Build();
 }
 
+DocumentWrapper CreateDocumentWrapper(DocumentProto document,
+                                      int32_t num_string_tokens) {
+  document.mutable_internal_fields()->set_length_in_tokens(num_string_tokens);
+  return document_util::CreateDocumentWrapper(std::move(document));
+}
+
 libtextclassifier3::StatusOr<
     std::pair<std::vector<DocHitInfo>, std::vector<ScoredDocumentHit>>>
 CreateAndInsertsDocumentsWithScores(DocumentStore* document_store,
@@ -165,10 +177,11 @@ CreateAndInsertsDocumentsWithScores(DocumentStore* document_store,
   std::vector<DocHitInfo> doc_hit_infos;
   std::vector<ScoredDocumentHit> scored_document_hits;
   for (int i = 0; i < scores.size(); i++) {
-    ICING_ASSIGN_OR_RETURN(DocumentStore::PutResult put_result,
-                           document_store->Put(CreateDocument(
-                               "icing", "email/" + std::to_string(i),
-                               scores.at(i), kDefaultCreationTimestampMs)));
+    ICING_ASSIGN_OR_RETURN(
+        DocumentStore::PutResult put_result,
+        document_store->Put(document_util::CreateDocumentWrapper(
+            CreateDocument("icing", "email/" + std::to_string(i), scores.at(i),
+                           kDefaultCreationTimestampMs))));
     DocumentId document_id = put_result.new_document_id;
     doc_hit_infos.emplace_back(document_id);
     scored_document_hits.emplace_back(document_id, kSectionIdMaskNone,
@@ -268,8 +281,8 @@ TEST_P(ScoringProcessorTest, ShouldHandleNonPositiveNumToScore) {
   // Sets up documents
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result1,
-      document_store()->Put(CreateDocument("icing", "email/1", /*score=*/1,
-                                           kDefaultCreationTimestampMs)));
+      document_store()->Put(document_util::CreateDocumentWrapper(CreateDocument(
+          "icing", "email/1", /*score=*/1, kDefaultCreationTimestampMs))));
   DocumentId document_id1 = put_result1.new_document_id;
   DocHitInfo doc_hit_info1(document_id1);
 
@@ -379,17 +392,17 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/10)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/100));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/100)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result3,
-      document_store()->Put(document3, /*num_tokens=*/50));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document3, /*num_string_tokens=*/50)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocHitInfoTermFrequencyPair doc_hit_info1 = DocHitInfo(document_id1);
@@ -455,17 +468,17 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/10)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/10)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result3,
-      document_store()->Put(document3, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document3, /*num_string_tokens=*/10)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocHitInfoTermFrequencyPair doc_hit_info1 = DocHitInfo(document_id1);
@@ -530,17 +543,17 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/10)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/10)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result3,
-      document_store()->Put(document3, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document3, /*num_string_tokens=*/10)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   DocHitInfoTermFrequencyPair doc_hit_info1 = DocHitInfo(document_id1);
@@ -609,17 +622,17 @@ TEST_P(ScoringProcessorTest, ShouldScoreByRelevanceScore_MultipleQueryTerms) {
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/20));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/20)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/20));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/20)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result3,
-      document_store()->Put(document3, /*num_tokens=*/20));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document3, /*num_string_tokens=*/20)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // Index 5 terms with total frequencies:
@@ -830,9 +843,9 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/1", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/10));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/10)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   // Document 1 contains the term "foo" 0 times in the "subject" property
@@ -883,13 +896,13 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/2", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/1)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Document 1 contains the term "foo" 1 time in the "body" property
@@ -961,13 +974,13 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/2", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/1)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Document 1 contains the term "foo" 1 time in the "body" property
@@ -1039,9 +1052,9 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/2", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   // Document 1 contains the term "foo" 1 time in the "body" property
@@ -1135,13 +1148,13 @@ TEST_P(ScoringProcessorTest,
       CreateDocument("icing", "email/2", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      document_store()->Put(document1, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      document_store()->Put(document2, /*num_tokens=*/1));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             document_store()->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/1)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   // Document 1 contains the term "foo" 1 time in the "body" property
@@ -1215,14 +1228,17 @@ TEST_P(ScoringProcessorTest, ShouldScoreByCreationTimestamp) {
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/1571100003333);
   // Intentionally inserts documents in a different order
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store()->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store()->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store()->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store()->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store()->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store()->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
   DocHitInfo doc_hit_info1(document_id1);
   DocHitInfo doc_hit_info2(document_id2);
@@ -1270,14 +1286,17 @@ TEST_P(ScoringProcessorTest, ShouldScoreByUsageCount) {
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store()->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store()->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store()->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store()->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store()->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store()->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // Report usage for doc1 once and doc2 twice.
@@ -1337,14 +1356,17 @@ TEST_P(ScoringProcessorTest, ShouldScoreByUsageTimestamp) {
       CreateDocument("icing", "email/3", kDefaultScore,
                      /*creation_timestamp_ms=*/kDefaultCreationTimestampMs);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store()->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store()->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store()->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store()->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store()->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store()->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
 
   // Report usage for doc1 and doc2.
@@ -1442,13 +1464,16 @@ TEST_P(ScoringProcessorTest, ShouldWrapResultsWhenNoScoring) {
                                            kDefaultCreationTimestampMs);
 
   // Intentionally inserts documents in a different order
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store()->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store()->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             document_store()->Put(document3));
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store()->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      document_store()->Put(document_util::CreateDocumentWrapper(document3)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store()->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
   DocumentId document_id3 = put_result3.new_document_id;
   DocHitInfo doc_hit_info1(document_id1);
diff --git a/icing/store/blob-store.cc b/icing/store/blob-store.cc
index eb3b686..45143b6 100644
--- a/icing/store/blob-store.cc
+++ b/icing/store/blob-store.cc
@@ -141,7 +141,7 @@ BlobProto CreateBlobProtoFromFileDescriptor(int file_descriptor) {
 libtextclassifier3::StatusOr<BlobStore> BlobStore::Create(
     const Filesystem* filesystem, std::string base_dir, const Clock* clock,
     int64_t orphan_blob_time_to_live_ms, int32_t compression_level,
-    bool manage_blob_files) {
+    int32_t compression_mem_level, bool manage_blob_files) {
   ICING_RETURN_ERROR_IF_NULL(filesystem);
   ICING_RETURN_ERROR_IF_NULL(clock);
 
@@ -172,20 +172,21 @@ libtextclassifier3::StatusOr<BlobStore> BlobStore::Create(
       PortableFileBackedProtoLog<BlobInfoProto>::CreateResult log_create_result,
       PortableFileBackedProtoLog<BlobInfoProto>::Create(
           filesystem, blob_info_proto_file_name,
-          PortableFileBackedProtoLog<BlobInfoProto>::Options(
-              /*compress_in=*/true, constants::kMaxProtoSize,
-              compression_level)));
+          PortableFileBackedProtoLog<BlobInfoProto>::Options( 
+              /*compress_in=*/true, constants::kMaxProtoSize, compression_level,
+              /*compression_threshold_bytes=*/0, compression_mem_level,
+              /*enable_smaller_decompression_buffer_size_in=*/false)));
 
   std::unordered_map<std::string, int> blob_handle_to_offset;
   ICING_ASSIGN_OR_RETURN(
       blob_handle_to_offset,
       LoadBlobHandleToOffsetMapper(log_create_result.proto_log.get()));
 
-  return BlobStore(filesystem, std::move(base_dir), clock,
-                   orphan_blob_time_to_live_ms, compression_level,
-                   manage_blob_files, std::move(log_create_result.proto_log),
-                   std::move(blob_handle_to_offset),
-                   std::move(known_file_names));
+  return BlobStore(
+      filesystem, std::move(base_dir), clock, orphan_blob_time_to_live_ms,
+      compression_level, compression_mem_level, manage_blob_files,
+      std::move(log_create_result.proto_log), std::move(blob_handle_to_offset),
+      std::move(known_file_names));
 }
 
 BlobProto BlobStore::OpenWrite(
@@ -383,7 +384,7 @@ BlobProto BlobStore::CommitBlob(
     while (prev_total_read_size < file_size) {
       int32_t size_to_read =
           std::min<int32_t>(kReadBufferSize, file_size - prev_total_read_size);
-      if (!filesystem_.Read(sfd.get(), buffer, size_to_read)) {
+      if (filesystem_.Read(sfd.get(), buffer, size_to_read) != size_to_read) {
         return CreateBlobProtoFromError(absl_ports::InternalError(
             absl_ports::StrCat("Failed to read blob file for handle: ",
                                blob_handle.digest())));
@@ -496,13 +497,16 @@ libtextclassifier3::StatusOr<std::vector<std::string>> BlobStore::Optimize(
         "Unable to delete temp file to prepare to build new blob proto file.");
   }
 
-  ICING_ASSIGN_OR_RETURN(PortableFileBackedProtoLog<BlobInfoProto>::CreateResult
-                             temp_log_create_result,
-                         PortableFileBackedProtoLog<BlobInfoProto>::Create(
-                             &filesystem_, temp_blob_info_proto_file_name,
-                             PortableFileBackedProtoLog<BlobInfoProto>::Options(
-                                 /*compress_in=*/true, constants::kMaxProtoSize,
-                                 compression_level_)));
+  ICING_ASSIGN_OR_RETURN(
+      PortableFileBackedProtoLog<BlobInfoProto>::CreateResult
+          temp_log_create_result,
+      PortableFileBackedProtoLog<BlobInfoProto>::Create(
+          &filesystem_, temp_blob_info_proto_file_name,
+          PortableFileBackedProtoLog<BlobInfoProto>::Options(
+              /*compress_in=*/true, constants::kMaxProtoSize,
+              compression_level_, /*compression_threshold_bytes=*/0,
+              compression_mem_level_,
+              /*enable_smaller_decompression_buffer_size_in=*/false)));
   std::unique_ptr<PortableFileBackedProtoLog<BlobInfoProto>> new_blob_info_log =
       std::move(temp_log_create_result.proto_log);
 
@@ -565,7 +569,9 @@ libtextclassifier3::StatusOr<std::vector<std::string>> BlobStore::Optimize(
           &filesystem_, old_blob_info_proto_file_name,
           PortableFileBackedProtoLog<BlobInfoProto>::Options(
               /*compress_in=*/true, constants::kMaxProtoSize,
-              compression_level_)));
+              compression_level_, /*compression_threshold_bytes=*/0,
+              compression_mem_level_,
+              /*enable_smaller_decompression_buffer_size_in=*/false)));
   blob_info_log_ = std::move(log_create_result.proto_log);
   blob_handle_to_offset_ = std::move(new_blob_handle_to_offset);
   return blob_file_names_to_remove;
diff --git a/icing/store/blob-store.h b/icing/store/blob-store.h
index 77814a3..8d34a43 100644
--- a/icing/store/blob-store.h
+++ b/icing/store/blob-store.h
@@ -68,7 +68,7 @@ class BlobStore {
   static libtextclassifier3::StatusOr<BlobStore> Create(
       const Filesystem* filesystem, std::string base_dir, const Clock* clock,
       int64_t orphan_blob_time_to_live_ms, int32_t compression_level,
-      bool manage_blob_files);
+      int32_t compression_mem_level, bool manage_blob_files);
 
   // Gets or creates a file for write only purpose for the given blob handle.
   // To mark the blob is completed written, CommitBlob must be called. Once
@@ -178,7 +178,7 @@ class BlobStore {
   explicit BlobStore(
       const Filesystem* filesystem, std::string base_dir, const Clock* clock,
       int64_t orphan_blob_time_to_live_ms, int32_t compression_level,
-      bool manage_blob_files,
+      int32_t compression_mem_level, bool manage_blob_files,
       std::unique_ptr<PortableFileBackedProtoLog<BlobInfoProto>> blob_info_log,
       std::unordered_map<std::string, int32_t> blob_handle_to_offset,
       std::unordered_set<std::string> known_file_names)
@@ -187,6 +187,7 @@ class BlobStore {
         clock_(*clock),
         orphan_blob_time_to_live_ms_(orphan_blob_time_to_live_ms),
         compression_level_(compression_level),
+        compression_mem_level_(compression_mem_level),
         manage_blob_files_(manage_blob_files),
         blob_info_log_(std::move(blob_info_log)),
         blob_handle_to_offset_(std::move(blob_handle_to_offset)),
@@ -207,6 +208,7 @@ class BlobStore {
   const Clock& clock_;
   int64_t orphan_blob_time_to_live_ms_;
   int32_t compression_level_;
+  int32_t compression_mem_level_;
   bool manage_blob_files_;
 
   // The ground truth blob info log file, which is used to read/write/erase
diff --git a/icing/store/document-filter-data.h b/icing/store/document-filter-data.h
index 471ac60..789f45d 100644
--- a/icing/store/document-filter-data.h
+++ b/icing/store/document-filter-data.h
@@ -16,7 +16,6 @@
 #define ICING_STORE_DOCUMENT_FILTER_DATA_H_
 
 #include <cstdint>
-#include <type_traits>
 
 #include "icing/legacy/core/icing-packed-pod.h"
 #include "icing/store/namespace-id.h"
@@ -30,25 +29,23 @@ inline constexpr SchemaTypeId kInvalidSchemaTypeId = -1;
 class DocumentFilterData {
  public:
   explicit DocumentFilterData(NamespaceId namespace_id,
-                              uint64_t uri_fingerprint,
                               SchemaTypeId schema_type_id,
-                              int64_t expiration_timestamp_ms)
+                              int64_t expiration_timestamp_ms,
+                              int64_t raw_expiration_timestamp_ms)
       : expiration_timestamp_ms_(expiration_timestamp_ms),
-        uri_fingerprint_(uri_fingerprint),
+        raw_expiration_timestamp_ms_(raw_expiration_timestamp_ms),
         namespace_id_(namespace_id),
         schema_type_id_(schema_type_id) {}
 
   bool operator==(const DocumentFilterData& other) const {
     return namespace_id_ == other.namespace_id() &&
-           uri_fingerprint_ == other.uri_fingerprint() &&
            schema_type_id_ == other.schema_type_id() &&
-           expiration_timestamp_ms_ == other.expiration_timestamp_ms();
+           expiration_timestamp_ms_ == other.expiration_timestamp_ms() &&
+           raw_expiration_timestamp_ms_ == other.raw_expiration_timestamp_ms();
   }
 
   NamespaceId namespace_id() const { return namespace_id_; }
 
-  uint64_t uri_fingerprint() const { return uri_fingerprint_; }
-
   SchemaTypeId schema_type_id() const { return schema_type_id_; }
   void set_schema_type_id(SchemaTypeId schema_type_id) {
     schema_type_id_ = schema_type_id;
@@ -56,9 +53,31 @@ class DocumentFilterData {
 
   int64_t expiration_timestamp_ms() const { return expiration_timestamp_ms_; }
 
+  int64_t raw_expiration_timestamp_ms() const {
+    return raw_expiration_timestamp_ms_;
+  }
+
  private:
+  // The expiration timestamp of the document in milliseconds. This is the min
+  // value of:
+  // - The document's raw expiration timestamp (see
+  //   raw_expiration_timestamp_ms_).
+  // - The propagated expiration timestamps according to its dependencies
+  //   specified in join properties with delete propagation enabled.
+  //
+  // Icing will use this value to:
+  // - Determine if a document is alive or expired.
+  // - Propagte to its dependents' expiration timestamps. Note that in most
+  //   cases the propagation should use this value instead of the raw expiration
+  //   timestamp.
   int64_t expiration_timestamp_ms_;
-  uint64_t uri_fingerprint_;
+
+  // The raw expiration timestamp of the document in milliseconds, calculated by
+  // the document's creation timestamp and ttl. This value is cached and mostly
+  // should only be used to reset expiration_timestamp_ms_ when Icing needs to
+  // recompute the propagated expiration timestamps of all documents.
+  int64_t raw_expiration_timestamp_ms_;
+
   NamespaceId namespace_id_;
   SchemaTypeId schema_type_id_;
 } __attribute__((packed));
diff --git a/icing/store/document-log-creator.cc b/icing/store/document-log-creator.cc
index 683e6e1..0826441 100644
--- a/icing/store/document-log-creator.cc
+++ b/icing/store/document-log-creator.cc
@@ -14,6 +14,7 @@
 
 #include "icing/store/document-log-creator.h"
 
+#include <cstdint>
 #include <memory>
 #include <string>
 #include <utility>
@@ -23,6 +24,7 @@
 #include "icing/absl_ports/annotate.h"
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/absl_ports/str_cat.h"
+#include "icing/feature-flags.h"
 #include "icing/file/constants.h"
 #include "icing/file/file-backed-proto-log.h"
 #include "icing/file/filesystem.h"
@@ -68,7 +70,10 @@ std::string DocumentLogCreator::GetDocumentLogFilename() {
 libtextclassifier3::StatusOr<DocumentLogCreator::CreateResult>
 DocumentLogCreator::Create(const Filesystem* filesystem,
                            const std::string& base_dir,
-                           int32_t compression_level) {
+                           const FeatureFlags* feature_flags,
+                           int32_t compression_level,
+                           uint32_t compression_threshold_bytes,
+                           int32_t compression_mem_level) {
   bool v0_exists =
       filesystem->FileExists(MakeDocumentLogFilenameV0(base_dir).c_str());
   bool v1_exists =
@@ -77,8 +82,9 @@ DocumentLogCreator::Create(const Filesystem* filesystem,
   bool new_file = false;
   int preexisting_file_version = kCurrentVersion;
   if (v0_exists && !v1_exists) {
-    ICING_RETURN_IF_ERROR(
-        MigrateFromV0ToV1(filesystem, base_dir, compression_level));
+    ICING_RETURN_IF_ERROR(MigrateFromV0ToV1(
+        filesystem, base_dir, feature_flags, compression_level,
+        compression_threshold_bytes, compression_mem_level));
 
     // Need to regenerate derived files since documents may be written to a
     // different file offset in the log.
@@ -97,8 +103,9 @@ DocumentLogCreator::Create(const Filesystem* filesystem,
       PortableFileBackedProtoLog<DocumentWrapper>::Create(
           filesystem, MakeDocumentLogFilenameV1(base_dir),
           PortableFileBackedProtoLog<DocumentWrapper>::Options(
-              /*compress_in=*/true, constants::kMaxProtoSize,
-              compression_level)));
+              /*compress_in=*/true, constants::kMaxProtoSize, compression_level,
+              compression_threshold_bytes, compression_mem_level,
+              feature_flags->enable_smaller_decompression_buffer_size())));
 
   CreateResult create_result = {std::move(log_create_result),
                                 preexisting_file_version, new_file};
@@ -107,7 +114,8 @@ DocumentLogCreator::Create(const Filesystem* filesystem,
 
 libtextclassifier3::Status DocumentLogCreator::MigrateFromV0ToV1(
     const Filesystem* filesystem, const std::string& base_dir,
-    int32_t compression_level) {
+    const FeatureFlags* feature_flags, int32_t compression_level,
+    uint32_t compression_threshold_bytes, int32_t compression_mem_level) {
   ICING_VLOG(1) << "Migrating from v0 to v1 document log.";
 
   // Our v0 proto log was non-portable, create it so we can read protos out from
@@ -132,9 +140,9 @@ libtextclassifier3::Status DocumentLogCreator::MigrateFromV0ToV1(
           filesystem, MakeDocumentLogFilenameV1(base_dir),
           PortableFileBackedProtoLog<DocumentWrapper>::Options(
               /*compress_in=*/true,
-              /*max_proto_size_in=*/
-              constants::kMaxProtoSize,
-              /*compression_level_in=*/compression_level));
+              /*max_proto_size_in=*/constants::kMaxProtoSize, compression_level,
+              compression_threshold_bytes, compression_mem_level,
+              feature_flags->enable_smaller_decompression_buffer_size()));
   if (!v1_create_result_or.ok()) {
     return absl_ports::Annotate(
         v1_create_result_or.status(),
diff --git a/icing/store/document-log-creator.h b/icing/store/document-log-creator.h
index 0c2794a..917e6c3 100644
--- a/icing/store/document-log-creator.h
+++ b/icing/store/document-log-creator.h
@@ -15,10 +15,12 @@
 #ifndef ICING_STORE_DOCUMENT_LOG_CREATOR_H_
 #define ICING_STORE_DOCUMENT_LOG_CREATOR_H_
 
+#include <cstdint>
 #include <string>
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
+#include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/proto/document_wrapper.pb.h"
@@ -58,7 +60,8 @@ class DocumentLogCreator {
   //   INTERNAL on any I/O error.
   static libtextclassifier3::StatusOr<DocumentLogCreator::CreateResult> Create(
       const Filesystem* filesystem, const std::string& base_dir,
-      int32_t compression_level);
+      const FeatureFlags* feature_flags, int32_t compression_level,
+      uint32_t compression_threshold_bytes, int32_t compression_mem_level);
 
   // Returns the filename of the document log, without any directory prefixes.
   // Used mainly for testing purposes.
@@ -76,7 +79,8 @@ class DocumentLogCreator {
   //   INTERNAL on I/O error.
   static libtextclassifier3::Status MigrateFromV0ToV1(
       const Filesystem* filesystem, const std::string& base_dir,
-      int32_t compression_level);
+      const FeatureFlags* feature_flags, int32_t compression_level,
+      uint32_t compression_threshold_bytes, int32_t compression_mem_level);
 };
 
 }  // namespace lib
diff --git a/icing/store/document-store.cc b/icing/store/document-store.cc
index 87a3fa7..b24d391 100644
--- a/icing/store/document-store.cc
+++ b/icing/store/document-store.cc
@@ -15,7 +15,6 @@
 #include "icing/store/document-store.h"
 
 #include <cstdint>
-#include <limits>
 #include <memory>
 #include <optional>
 #include <string>
@@ -31,7 +30,6 @@
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/absl_ports/str_cat.h"
 #include "icing/feature-flags.h"
-#include "icing/file/file-backed-proto-log.h"
 #include "icing/file/file-backed-vector.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/memory-mapped-file-backed-proto-log.h"
@@ -68,10 +66,12 @@
 #include "icing/util/clock.h"
 #include "icing/util/crc32.h"
 #include "icing/util/data-loss.h"
+#include "icing/util/document-util.h"
 #include "icing/util/fingerprint-util.h"
 #include "icing/util/logging.h"
 #include "icing/util/scorable_property_set.h"
 #include "icing/util/status-macros.h"
+#include "icing/util/timestamp-util.h"
 #include "icing/util/tokenized-document.h"
 
 namespace icing {
@@ -110,12 +110,6 @@ constexpr int32_t kUriHashKeyMapperKVByteSize = 13 + 1 + sizeof(DocumentId);
 constexpr int32_t kNamespaceMapperMaxSize = 3 * 128 * 1024;  // 384 KiB
 constexpr int32_t kCorpusMapperMaxSize = 3 * 128 * 1024;     // 384 KiB
 
-DocumentWrapper CreateDocumentWrapper(DocumentProto&& document) {
-  DocumentWrapper document_wrapper;
-  *document_wrapper.mutable_document() = std::move(document);
-  return document_wrapper;
-}
-
 std::string MakeHeaderFilename(const std::string& base_dir) {
   return absl_ports::StrCat(base_dir, "/", kDocumentStoreHeaderFilename);
 }
@@ -156,27 +150,6 @@ std::string MakeCorpusMapperFilename(const std::string& base_dir) {
   return absl_ports::StrCat(base_dir, "/", kCorpusIdMapperFilename);
 }
 
-int64_t CalculateExpirationTimestampMs(int64_t creation_timestamp_ms,
-                                       int64_t ttl_ms) {
-  if (ttl_ms == 0) {
-    // Special case where a TTL of 0 indicates the document should never
-    // expire. int64_t max, interpreted as seconds since epoch, represents
-    // some point in the year 292,277,026,596. So we're probably ok to use
-    // this as "never reaching this point".
-    return std::numeric_limits<int64_t>::max();
-  }
-
-  int64_t expiration_timestamp_ms;
-  if (__builtin_add_overflow(creation_timestamp_ms, ttl_ms,
-                             &expiration_timestamp_ms)) {
-    // Overflow detected. Treat overflow as the same behavior of just int64_t
-    // max
-    return std::numeric_limits<int64_t>::max();
-  }
-
-  return expiration_timestamp_ms;
-}
-
 InitializeStatsProto::RecoveryCause GetRecoveryCause(
     const DocumentLogCreator::CreateResult& create_result,
     bool force_recovery_and_revalidate_documents) {
@@ -287,13 +260,12 @@ void RemoveAliveBlobHandles(
 
 }  // namespace
 
-DocumentStore::DocumentStore(const Filesystem* filesystem,
-                             const std::string_view base_dir,
-                             const Clock* clock,
-                             const SchemaStore* schema_store,
-                             const FeatureFlags* feature_flags,
-                             bool pre_mapping_fbv, bool use_persistent_hash_map,
-                             int32_t compression_level)
+DocumentStore::DocumentStore(
+    const Filesystem* filesystem, const std::string_view base_dir,
+    const Clock* clock, const SchemaStore* schema_store,
+    const FeatureFlags* feature_flags, bool pre_mapping_fbv,
+    bool use_persistent_hash_map, int32_t compression_level,
+    uint32_t compression_threshold_bytes, int32_t compression_mem_level)
     : filesystem_(filesystem),
       base_dir_(base_dir),
       clock_(*clock),
@@ -302,19 +274,14 @@ DocumentStore::DocumentStore(const Filesystem* filesystem,
       document_validator_(schema_store),
       pre_mapping_fbv_(pre_mapping_fbv),
       use_persistent_hash_map_(use_persistent_hash_map),
-      compression_level_(compression_level) {}
-
-libtextclassifier3::StatusOr<DocumentStore::PutResult> DocumentStore::Put(
-    const DocumentProto& document, int32_t num_tokens,
-    PutDocumentStatsProto* put_document_stats) {
-  return Put(DocumentProto(document), num_tokens, put_document_stats);
-}
+      compression_level_(compression_level),
+      compression_threshold_bytes_(compression_threshold_bytes),
+      compression_mem_level_(compression_mem_level) {}
 
 libtextclassifier3::StatusOr<DocumentStore::PutResult> DocumentStore::Put(
-    DocumentProto&& document, int32_t num_tokens,
+    const DocumentWrapper& document_wrapper,
     PutDocumentStatsProto* put_document_stats) {
-  document.mutable_internal_fields()->set_length_in_tokens(num_tokens);
-  return InternalPut(std::move(document), put_document_stats);
+  return InternalPut(document_wrapper, put_document_stats);
 }
 
 DocumentStore::~DocumentStore() {
@@ -332,6 +299,7 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> DocumentStore::Create(
     const FeatureFlags* feature_flags,
     bool force_recovery_and_revalidate_documents, bool pre_mapping_fbv,
     bool use_persistent_hash_map, int32_t compression_level,
+    uint32_t compression_threshold_bytes, int32_t compression_mem_level,
     InitializeStatsProto* initialize_stats) {
   ICING_RETURN_ERROR_IF_NULL(filesystem);
   ICING_RETURN_ERROR_IF_NULL(clock);
@@ -340,7 +308,8 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> DocumentStore::Create(
 
   auto document_store = std::unique_ptr<DocumentStore>(new DocumentStore(
       filesystem, base_dir, clock, schema_store, feature_flags, pre_mapping_fbv,
-      use_persistent_hash_map, compression_level));
+      use_persistent_hash_map, compression_level, compression_threshold_bytes,
+      compression_mem_level));
   ICING_ASSIGN_OR_RETURN(
       InitializeResult initialize_result,
       document_store->Initialize(force_recovery_and_revalidate_documents,
@@ -404,8 +373,9 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> DocumentStore::Create(
 libtextclassifier3::StatusOr<DocumentStore::InitializeResult>
 DocumentStore::Initialize(bool force_recovery_and_revalidate_documents,
                           InitializeStatsProto* initialize_stats) {
-  auto create_result_or =
-      DocumentLogCreator::Create(filesystem_, base_dir_, compression_level_);
+  auto create_result_or = DocumentLogCreator::Create(
+      filesystem_, base_dir_, &feature_flags_, compression_level_,
+      compression_threshold_bytes_, compression_mem_level_);
 
   // TODO(b/144458732): Implement a more robust version of TC_ASSIGN_OR_RETURN
   // that can support error logging.
@@ -499,15 +469,16 @@ libtextclassifier3::Status DocumentStore::InitializeExistingDerivedFiles() {
   }
 
   DocumentStore::Header header;
-  if (!filesystem_->Read(MakeHeaderFilename(base_dir_).c_str(), &header,
-                         sizeof(header))) {
+  if (filesystem_->Read(MakeHeaderFilename(base_dir_).c_str(), &header,
+                        sizeof(header)) != sizeof(header)) {
     return absl_ports::InternalError(
         absl_ports::StrCat("Couldn't read: ", MakeHeaderFilename(base_dir_)));
   }
 
-  if (header.magic != DocumentStore::Header::kMagic) {
-    return absl_ports::InternalError(absl_ports::StrCat(
-        "Invalid header kMagic for file: ", MakeHeaderFilename(base_dir_)));
+  if (header.magic != Header::kMagic) {
+    ICING_LOG(ERROR) << "Invalid header magic for DocumentStore. Expected: "
+                     << Header::kMagic << ", actual: " << header.magic;
+    return absl_ports::InternalError("Invalid header magic for DocumentStore");
   }
 
   // TODO(b/144458732): Implement a more robust version of TC_ASSIGN_OR_RETURN
@@ -713,15 +684,20 @@ libtextclassifier3::Status DocumentStore::RegenerateDerivedFiles(
             scorable_property_cache_index,
             document_wrapper.document().internal_fields().length_in_tokens())));
 
-    int64_t expiration_timestamp_ms = CalculateExpirationTimestampMs(
-        document_wrapper.document().creation_timestamp_ms(),
-        document_wrapper.document().ttl_ms());
+    int64_t raw_expiration_timestamp_ms =
+        timestamp_util::CalculateRawExpirationTimestampMs(
+            document_wrapper.document().creation_timestamp_ms(),
+            document_wrapper.document().ttl_ms());
 
+    // When regenerating derived files, set the expiration timestamp as the raw
+    // expiration timestamp. The dependency should be evaluated by the caller
+    // and updated to the propagated expiration timestamp later.
     ICING_RETURN_IF_ERROR(UpdateFilterCache(
         new_document_id,
-        DocumentFilterData(namespace_id,
-                           new_doc_nsid_uri_fingerprint.fingerprint(),
-                           schema_type_id, expiration_timestamp_ms)));
+        DocumentFilterData(
+            namespace_id, schema_type_id,
+            /*expiration_timestamp_ms=*/raw_expiration_timestamp_ms,
+            raw_expiration_timestamp_ms)));
     iterator_status = iterator.Advance();
   }
 
@@ -1141,36 +1117,31 @@ bool DocumentStore::HeaderExists() {
 }
 
 libtextclassifier3::StatusOr<DocumentStore::PutResult>
-DocumentStore::InternalPut(DocumentProto&& document,
+DocumentStore::InternalPut(const DocumentWrapper& document_wrapper,
                            PutDocumentStatsProto* put_document_stats) {
   std::unique_ptr<Timer> put_timer = clock_.GetNewTimer();
-  ICING_RETURN_IF_ERROR(document_validator_.Validate(document));
 
   if (put_document_stats != nullptr) {
-    put_document_stats->set_document_size(document.ByteSizeLong());
+    put_document_stats->set_document_size(
+        document_wrapper.document().ByteSizeLong());
   }
 
   // Copy fields needed before they are moved
-  std::string name_space = document.namespace_();
-  std::string uri = document.uri();
-  std::string schema = document.schema();
-  int document_score = document.score();
-  int32_t length_in_tokens = document.internal_fields().length_in_tokens();
-  int64_t creation_timestamp_ms = document.creation_timestamp_ms();
-
-  // Sets the creation timestamp if caller hasn't specified.
-  if (document.creation_timestamp_ms() == 0) {
-    creation_timestamp_ms = clock_.GetSystemTimeMilliseconds();
-    document.set_creation_timestamp_ms(creation_timestamp_ms);
-  }
-
-  int64_t expiration_timestamp_ms =
-      CalculateExpirationTimestampMs(creation_timestamp_ms, document.ttl_ms());
+  std::string name_space = document_wrapper.document().namespace_();
+  std::string uri = document_wrapper.document().uri();
+  std::string schema = document_wrapper.document().schema();
+  int document_score = document_wrapper.document().score();
+  int32_t length_in_tokens =
+      document_wrapper.document().internal_fields().length_in_tokens();
+  int64_t creation_timestamp_ms =
+      document_wrapper.document().creation_timestamp_ms();
+  int64_t raw_expiration_timestamp_ms =
+      timestamp_util::CalculateRawExpirationTimestampMs(
+          creation_timestamp_ms, document_wrapper.document().ttl_ms());
 
   // Update ground truth first
   // TODO(b/144458732): Implement a more robust version of TC_ASSIGN_OR_RETURN
   // that can support error logging.
-  DocumentWrapper document_wrapper = CreateDocumentWrapper(std::move(document));
   auto offset_or = document_log_->WriteProto(document_wrapper);
   if (!offset_or.ok()) {
     ICING_LOG(ERROR) << offset_or.status().error_message()
@@ -1233,11 +1204,15 @@ DocumentStore::InternalPut(DocumentProto&& document,
                            corpus_id, document_score, creation_timestamp_ms,
                            scorable_property_cache_index, length_in_tokens)));
 
+  // Here we set the expiration timestamp as the raw expiration timestamp,
+  // because we haven't propagated the expiration timestamps yet and it should
+  // be done in the next step by the caller.
   ICING_RETURN_IF_ERROR(UpdateFilterCache(
       new_document_id,
-      DocumentFilterData(namespace_id,
-                         new_doc_nsid_uri_fingerprint.fingerprint(),
-                         schema_type_id, expiration_timestamp_ms)));
+      DocumentFilterData(
+          namespace_id, schema_type_id,
+          /*expiration_timestamp_ms=*/raw_expiration_timestamp_ms,
+          raw_expiration_timestamp_ms)));
 
   if (old_document_id_or.ok()) {
     // The old document exists, copy over the usage scores and delete the old
@@ -1482,6 +1457,77 @@ DocumentStore::GetNonDeletedDocumentFilterData(DocumentId document_id) const {
   return std::move(filter_data_or).ValueOrDie();
 }
 
+bool DocumentStore::IsDocumentAlive(DocumentId document_id,
+                                    int64_t current_time_ms) const {
+  return GetAliveDocumentFilterData(document_id, current_time_ms).has_value();
+}
+
+bool DocumentStore::IsDocumentAlive(std::string_view name_space,
+                                    std::string_view uri,
+                                    int64_t current_time_ms) const {
+  auto document_id_or = GetDocumentId(name_space, uri);
+  if (!document_id_or.ok()) {
+    return false;
+  }
+  return IsDocumentAlive(document_id_or.ValueOrDie(), current_time_ms);
+}
+
+libtextclassifier3::StatusOr<
+    DocumentStore::UpdateDocumentExpirationTimestampResult>
+DocumentStore::UpdateDocumentExpirationTimestamp(
+    DocumentId document_id, int64_t expiration_timestamp_ms) {
+  if (document_id < 0 || document_id >= filter_cache_->num_elements()) {
+    return absl_ports::InvalidArgumentError(IcingStringUtil::StringPrintf(
+        "Document id '%d' invalid.", document_id));
+  }
+
+  std::optional<DocumentFilterData> filter_data =
+      GetNonDeletedDocumentFilterData(document_id);
+  if (!filter_data.has_value()) {
+    return absl_ports::NotFoundError(IcingStringUtil::StringPrintf(
+        "Document id '%d' is not alive", document_id));
+  }
+
+  // Currently we only support decreasing the expiration timestamp.
+  if (expiration_timestamp_ms < filter_data->expiration_timestamp_ms()) {
+    ICING_RETURN_IF_ERROR(filter_cache_->Set(
+        document_id, DocumentFilterData(
+                         filter_data->namespace_id(),
+                         filter_data->schema_type_id(), expiration_timestamp_ms,
+                         filter_data->raw_expiration_timestamp_ms())));
+    return UpdateDocumentExpirationTimestampResult{
+        .final_expiration_timestamp_ms = expiration_timestamp_ms,
+        .was_updated = true};
+  }
+  return UpdateDocumentExpirationTimestampResult{
+      .final_expiration_timestamp_ms = filter_data->expiration_timestamp_ms(),
+      .was_updated = false};
+}
+
+libtextclassifier3::Status
+DocumentStore::ResetAllAliveExpirationTimestampsToRaw(int64_t current_time_ms) {
+  for (DocumentId document_id = 0; document_id < filter_cache_->num_elements();
+       ++document_id) {
+    std::optional<DocumentFilterData> filter_data =
+        GetAliveDocumentFilterData(document_id, current_time_ms);
+    if (!filter_data.has_value()) {
+      continue;
+    }
+
+    if (filter_data->expiration_timestamp_ms() !=
+        filter_data->raw_expiration_timestamp_ms()) {
+      ICING_RETURN_IF_ERROR(filter_cache_->Set(
+          document_id,
+          DocumentFilterData(filter_data->namespace_id(),
+                             filter_data->schema_type_id(),
+                             /*expiration_timestamp_ms=*/
+                             filter_data->raw_expiration_timestamp_ms(),
+                             filter_data->raw_expiration_timestamp_ms())));
+    }
+  }
+  return libtextclassifier3::Status::OK;
+}
+
 bool DocumentStore::IsDeleted(DocumentId document_id) const {
   auto file_offset_or = document_id_mapper_->Get(document_id);
   if (!file_offset_or.ok()) {
@@ -1570,54 +1616,66 @@ libtextclassifier3::StatusOr<CorpusId> DocumentStore::GetCorpusId(
   return corpus_mapper_->Get(corpus_nsid_schema_fp.EncodeToCString());
 }
 
-libtextclassifier3::StatusOr<int32_t> DocumentStore::GetResultGroupingEntryId(
+std::optional<int32_t> DocumentStore::GetResultGroupingEntryId(
     ResultSpecProto::ResultGroupingType result_group_type,
-    const std::string_view name_space, const std::string_view schema) const {
-  auto namespace_id = GetNamespaceId(name_space);
-  auto schema_type_id = schema_store_->GetSchemaTypeId(schema);
-  switch (result_group_type) {
-    case ResultSpecProto::NONE:
-      return absl_ports::InvalidArgumentError(
-          "Cannot group by ResultSpecProto::NONE");
-    case ResultSpecProto::SCHEMA_TYPE:
-      if (schema_type_id.ok()) {
-        return schema_type_id.ValueOrDie();
-      }
-      break;
-    case ResultSpecProto::NAMESPACE:
-      if (namespace_id.ok()) {
-        return namespace_id.ValueOrDie();
-      }
-      break;
-    case ResultSpecProto::NAMESPACE_AND_SCHEMA_TYPE:
-      if (namespace_id.ok() && schema_type_id.ok()) {
-        // TODO(b/258715421): Temporary workaround to get a
-        //                    ResultGroupingEntryId given the Namespace string
-        //                    and Schema string.
-        return namespace_id.ValueOrDie() << 16 | schema_type_id.ValueOrDie();
-      }
-      break;
-  }
-  return absl_ports::NotFoundError("Cannot generate ResultGrouping Entry Id");
+    std::string_view name_space, std::string_view schema) const {
+  auto namespace_id_or = GetNamespaceId(name_space);
+  auto schema_type_id_or = schema_store_->GetSchemaTypeId(schema);
+
+  NamespaceId namespace_id =
+      namespace_id_or.ok() ? namespace_id_or.ValueOrDie() : kInvalidNamespaceId;
+  SchemaTypeId schema_type_id = schema_type_id_or.ok()
+                                    ? schema_type_id_or.ValueOrDie()
+                                    : kInvalidSchemaTypeId;
+  return GetResultGroupingEntryId(result_group_type, namespace_id,
+                                  schema_type_id);
 }
 
-libtextclassifier3::StatusOr<int32_t> DocumentStore::GetResultGroupingEntryId(
+std::optional<int32_t> DocumentStore::GetResultGroupingEntryId(
     ResultSpecProto::ResultGroupingType result_group_type,
-    const NamespaceId namespace_id, const SchemaTypeId schema_type_id) const {
+    NamespaceId namespace_id, SchemaTypeId schema_type_id) const {
+  static_assert(sizeof(NamespaceId) * 8 <= 16,
+                "Current ResultGroupingEntryId encoding only supports "
+                "namespace id up to 16 bits.");
+  static_assert(sizeof(SchemaTypeId) * 8 <= 16,
+                "Current ResultGroupingEntryId encoding only supports schema "
+                "type id up to 16 bits.");
+
+  // Note: this encoding method only works for a single
+  // ResultSpecProto::ResultGroupingType in a single search request. If multiple
+  // types can be used in the same search request, this encoding method needs to
+  // be updated since there will be encoded id collisions for NAMESPACE and
+  // SCHEMA_TYPE.
+
   switch (result_group_type) {
-    case ResultSpecProto::NONE:
-      return absl_ports::InvalidArgumentError(
-          "Cannot group by ResultSpecProto::NONE");
-    case ResultSpecProto::SCHEMA_TYPE:
+    case ResultSpecProto::ResultGroupingType::
+        ResultSpecProto_ResultGroupingType_NONE:
+      return std::nullopt;
+    case ResultSpecProto::ResultGroupingType::
+        ResultSpecProto_ResultGroupingType_SCHEMA_TYPE: {
+      if (schema_type_id == kInvalidSchemaTypeId) {
+        return std::nullopt;
+      }
       return schema_type_id;
-    case ResultSpecProto::NAMESPACE:
+    }
+    case ResultSpecProto::ResultGroupingType::
+        ResultSpecProto_ResultGroupingType_NAMESPACE: {
+      if (namespace_id == kInvalidNamespaceId) {
+        return std::nullopt;
+      }
       return namespace_id;
-    case ResultSpecProto::NAMESPACE_AND_SCHEMA_TYPE:
+    }
+    case ResultSpecProto::ResultGroupingType::
+        ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE: {
+      if (namespace_id == kInvalidNamespaceId ||
+          schema_type_id == kInvalidSchemaTypeId) {
+        return std::nullopt;
+      }
       // TODO(b/258715421): Temporary workaround to get a ResultGroupingEntryId
       //                    given the Namespace Id and SchemaType Id.
-      return namespace_id << 16 | schema_type_id;
+      return (static_cast<int32_t>(namespace_id) << 16) | schema_type_id;
+    }
   }
-  return absl_ports::NotFoundError("Cannot generate ResultGrouping Entry Id");
 }
 
 libtextclassifier3::StatusOr<DocumentAssociatedScoreData>
@@ -2014,7 +2072,7 @@ libtextclassifier3::Status DocumentStore::UpdateSchemaStore(
   return libtextclassifier3::Status::OK;
 }
 
-libtextclassifier3::Status DocumentStore::OptimizedUpdateSchemaStore(
+libtextclassifier3::StatusOr<int> DocumentStore::OptimizedUpdateSchemaStore(
     const SchemaStore* schema_store,
     const SchemaStore::SetSchemaResult& set_schema_result) {
   if (!set_schema_result.success) {
@@ -2027,6 +2085,7 @@ libtextclassifier3::Status DocumentStore::OptimizedUpdateSchemaStore(
   document_validator_.UpdateSchemaStore(schema_store);
 
   int size = document_id_mapper_->num_elements();
+  int deleted_document_count = 0;
   int64_t current_time_ms = clock_.GetSystemTimeMilliseconds();
   for (DocumentId document_id = 0; document_id < size; document_id++) {
     if (!GetAliveDocumentFilterData(document_id, current_time_ms)) {
@@ -2074,14 +2133,16 @@ libtextclassifier3::Status DocumentStore::OptimizedUpdateSchemaStore(
     if (delete_document) {
       // Document is no longer valid with the new SchemaStore. Mark as deleted
       auto delete_status = Delete(document_id, current_time_ms);
-      if (!delete_status.ok() && !absl_ports::IsNotFound(delete_status)) {
+      if (delete_status.ok()) {
+        ++deleted_document_count;
+      } else if (!absl_ports::IsNotFound(delete_status)) {
         // Real error, pass up
         return delete_status;
       }
     }
   }
 
-  return libtextclassifier3::Status::OK;
+  return deleted_document_count;
 }
 
 libtextclassifier3::Status DocumentStore::RegenerateScorablePropertyCache(
@@ -2144,6 +2205,7 @@ DocumentStore::OptimizeInto(
           filesystem_, new_directory, &clock_, schema_store_, &feature_flags_,
           /*force_recovery_and_revalidate_documents=*/false, pre_mapping_fbv_,
           use_persistent_hash_map_, compression_level_,
+          compression_threshold_bytes_, compression_mem_level_,
           /*initialize_stats=*/nullptr));
   std::unique_ptr<DocumentStore> new_doc_store =
       std::move(doc_store_create_result.document_store);
@@ -2192,6 +2254,9 @@ DocumentStore::OptimizeInto(
               "Failed to retrieve Document for DocumentId %d", document_id));
     }
 
+    // TODO(b/405467475): add a new Get method to return DocumentWrapper and
+    // change document_to_keep to DocumentWrapper.
+
     // Guaranteed to have a document now.
     DocumentProto document_to_keep = std::move(document_or).ValueOrDie();
     // Remove blobs that still have reference are removed from the
@@ -2201,8 +2266,10 @@ DocumentStore::OptimizeInto(
 
     libtextclassifier3::StatusOr<PutResult> put_result_or;
     if (document_to_keep.internal_fields().length_in_tokens() == 0) {
+      // Create a TokenizedDocument. length_in_tokens will be set there.
       auto tokenized_document_or = TokenizedDocument::Create(
-          schema_store_, lang_segmenter, document_to_keep);
+          schema_store_, lang_segmenter, current_time_ms,
+          std::move(document_to_keep));
       if (!tokenized_document_or.ok()) {
         return absl_ports::Annotate(
             tokenized_document_or.status(),
@@ -2211,12 +2278,12 @@ DocumentStore::OptimizeInto(
       }
       TokenizedDocument tokenized_document(
           std::move(tokenized_document_or).ValueOrDie());
-      put_result_or = new_doc_store->Put(
-          std::move(document_to_keep), tokenized_document.num_string_tokens());
+      put_result_or = new_doc_store->Put(tokenized_document.document_wrapper());
     } else {
       // TODO(b/144458732): Implement a more robust version of
       // TC_ASSIGN_OR_RETURN that can support error logging.
-      put_result_or = new_doc_store->InternalPut(std::move(document_to_keep));
+      put_result_or = new_doc_store->InternalPut(
+          document_util::CreateDocumentWrapper(std::move(document_to_keep)));
     }
     if (!put_result_or.ok()) {
       ICING_LOG(ERROR) << put_result_or.status().error_message()
@@ -2394,10 +2461,9 @@ libtextclassifier3::Status DocumentStore::ClearDerivedData(
 
   // Resets the filter cache entry
   ICING_RETURN_IF_ERROR(UpdateFilterCache(
-      document_id,
-      DocumentFilterData(kInvalidNamespaceId, /*uri_fingerprint=*/0,
-                         kInvalidSchemaTypeId,
-                         /*expiration_timestamp_ms=*/-1)));
+      document_id, DocumentFilterData(kInvalidNamespaceId, kInvalidSchemaTypeId,
+                                      /*expiration_timestamp_ms=*/-1,
+                                      /*raw_expiration_timestamp_ms=*/-1)));
 
   // Clears the usage scores.
   return usage_store_->DeleteUsageScores(document_id);
diff --git a/icing/store/document-store.h b/icing/store/document-store.h
index 79869a8..767baec 100644
--- a/icing/store/document-store.h
+++ b/icing/store/document-store.h
@@ -66,8 +66,8 @@ class DocumentStore {
  public:
   struct Header {
     // Previously used magic numbers, please avoid reusing those:
-    // [0x1b99c8b0, 0x3e005b5e]
-    static constexpr int32_t kMagic = 0x8a32cd1f;
+    // [0x1b99c8b0, 0x3e005b5e, 0x8a32cd1f, 0x2eea71de]
+    static constexpr int32_t kMagic = 0x142f84cd;
 
     // Holds the magic as a quick sanity check against file corruption.
     int32_t magic;
@@ -151,6 +151,7 @@ class DocumentStore {
       const FeatureFlags* feature_flags,
       bool force_recovery_and_revalidate_documents, bool pre_mapping_fbv,
       bool use_persistent_hash_map, int32_t compression_level,
+      uint32_t compression_threshold_bytes, int32_t compression_mem_level,
       InitializeStatsProto* initialize_stats);
 
   // Discards all derived data in the document store.
@@ -176,7 +177,7 @@ class DocumentStore {
   // of deleted or expired documents.
   int num_documents() const { return document_id_mapper_->num_elements(); }
 
-  // Puts the document into document store.
+  // Puts a single document into document store.
   //
   // If put_document_stats is present, the fields related to DocumentStore will
   // be populated.
@@ -199,10 +200,7 @@ class DocumentStore {
     }
   };
   libtextclassifier3::StatusOr<PutResult> Put(
-      const DocumentProto& document, int32_t num_tokens = 0,
-      PutDocumentStatsProto* put_document_stats = nullptr);
-  libtextclassifier3::StatusOr<PutResult> Put(
-      DocumentProto&& document, int32_t num_tokens = 0,
+      const DocumentWrapper& document_wrapper,
       PutDocumentStatsProto* put_document_stats = nullptr);
 
   // Finds and returns the document identified by the given key (namespace +
@@ -330,30 +328,31 @@ class DocumentStore {
   //
   // NOTE: ResultGroupingEntryIds that are generated by calls with different
   // ResultGroupingTypes should not be compared. Returned ResultGroupingEntryIds
-  // are only guarenteed to be unique within their own ResultGroupingType.
+  // are only guaranteed to be unique within their own ResultGroupingType.
   //
   // Returns:
-  //   A ResultGroupingEntryId on success
-  //   NOT_FOUND if the key doesn't exist
-  //   INTERNAL_ERROR on IO error
-  libtextclassifier3::StatusOr<int32_t> GetResultGroupingEntryId(
+  //   A valid ResultGroupingEntryId on success
+  //   std::nullopt there is no such result grouping entry id (e.g. result group
+  //     type is not supported, result group type is based on the given
+  //     namespace/schema but the namespace/schema doesn't exist).
+  std::optional<int32_t> GetResultGroupingEntryId(
       ResultSpecProto::ResultGroupingType result_group_type,
-      const std::string_view name_space, const std::string_view schema) const;
+      std::string_view name_space, std::string_view schema) const;
 
   // Returns the ResultGrouping Entry Id associated with the given NamespaceId
   // and SchemaTypeId
   //
   // NOTE: ResultGroupingEntryIds that are generated by calls with different
   // ResultGroupingTypes should not be compared. Returned ResultGroupingEntryIds
-  // are only guarenteed to be unique within their own ResultGroupingType.
+  // are only guaranteed to be unique within their own ResultGroupingType.
   //
   // Returns:
-  //   A ResultGroupingEntryId on success
-  //   NOT_FOUND if the key doesn't exist
-  //   INTERNAL_ERROR on IO error
-  libtextclassifier3::StatusOr<int32_t> GetResultGroupingEntryId(
+  //   A valid ResultGroupingEntryId on success
+  //   std::nullopt if there is no such result grouping entry id (result group
+  //     type is not supported).
+  std::optional<int32_t> GetResultGroupingEntryId(
       ResultSpecProto::ResultGroupingType result_group_type,
-      const NamespaceId namespace_id, const SchemaTypeId schema_type_id) const;
+      NamespaceId namespace_id, SchemaTypeId schema_type_id) const;
 
   // Returns the DocumentAssociatedScoreData of the document specified by the
   // DocumentId.
@@ -399,6 +398,57 @@ class DocumentStore {
   std::optional<DocumentFilterData> GetNonDeletedDocumentFilterData(
       DocumentId document_id) const;
 
+  // Checks if the document (given document_id) is alive or not.
+  bool IsDocumentAlive(DocumentId document_id, int64_t current_time_ms) const;
+
+  // Checks if the document (given namespace, uri) is alive or not.
+  bool IsDocumentAlive(std::string_view name_space, std::string_view uri,
+                       int64_t current_time_ms) const;
+
+  // Updates the expiration timestamp of the given document only if the document
+  // is not deleted (note: expired document's expiration timestamp can be
+  // updated decreasingly).
+  //
+  // Currently we only allow to decrease the expiration timestamp. This prevents
+  // us from making an expired document alive again.
+  //
+  // The input expiration timestamp is usually the propagated expiration
+  // timestamp computed from the document dependencies (expiration and delete
+  // propagation).
+  //
+  // Returns:
+  //   On success, the final value of the expiration timestamp and a boolean
+  //     flag that indicates if the expiration timestamp is updated. If the
+  //     input expiration timestamp is not smaller than the current expiration
+  //     timestamp stored in DocumentFilterData cache, then it is no-op and the
+  //     current expiration timestamp will be returned.
+  //   NOT_FOUND_ERROR if the document is deleted
+  //   INVALID_ARGUMENT_ERROR if document_id is invalid
+  //   Any FileBackedVector error
+  struct UpdateDocumentExpirationTimestampResult {
+    // The final value of the expiration timestamp.
+    int64_t final_expiration_timestamp_ms;
+
+    // Whether the expiration timestamp was updated or not.
+    bool was_updated;
+  };
+  libtextclassifier3::StatusOr<UpdateDocumentExpirationTimestampResult>
+  UpdateDocumentExpirationTimestamp(DocumentId document_id,
+                                    int64_t expiration_timestamp_ms);
+
+  // Resets the expiration timestamp as the raw expiration timestamp of all
+  // alive documents. See DocumentFilterData for more details.
+  //
+  // Note: this is usually called before recomputing propagated expiration
+  // timestamps when Icing detects the document dependency (expiration and
+  // delete propagation) should be re-evaluated.
+  //
+  // Returns:
+  //   OK on success
+  //   Any FileBackedVector error
+  libtextclassifier3::Status ResetAllAliveExpirationTimestampsToRaw(
+      int64_t current_time_ms);
+
   // Gets the SchemaTypeId of a document.
   //
   // Returns:
@@ -493,9 +543,9 @@ class DocumentStore {
   // what's changed between the old and new SchemaStore.
   //
   // Returns;
-  //   OK on success
+  //   number of documents deleted on success
   //   INTERNAL_ERROR on IO error
-  libtextclassifier3::Status OptimizedUpdateSchemaStore(
+  libtextclassifier3::StatusOr<int> OptimizedUpdateSchemaStore(
       const SchemaStore* schema_store,
       const SchemaStore::SetSchemaResult& set_schema_result);
 
@@ -600,7 +650,9 @@ class DocumentStore {
                          const SchemaStore* schema_store,
                          const FeatureFlags* feature_flags,
                          bool pre_mapping_fbv, bool use_persistent_hash_map,
-                         int32_t compression_level);
+                         int32_t compression_level,
+                         uint32_t compression_threshold_bytes,
+                         int32_t compression_mem_level);
 
   const Filesystem* const filesystem_;
   const std::string base_dir_;
@@ -624,6 +676,10 @@ class DocumentStore {
   bool use_persistent_hash_map_;
 
   const int32_t compression_level_;
+  const uint32_t compression_threshold_bytes_;
+
+  // Level of memory usage for compression.
+  const int32_t compression_mem_level_;
 
   // A log used to store all documents, it serves as a ground truth of doc
   // store. key_mapper_ and document_id_mapper_ can be regenerated from it.
@@ -671,7 +727,7 @@ class DocumentStore {
   std::unique_ptr<KeyMapper<NamespaceId>> namespace_mapper_;
 
   // Maps a corpus, i.e. a (namespace, schema type) pair, to a densely-assigned
-  // unique id. A coprus is assigned an
+  // unique id. A corpus is assigned an
   // id when the first document belonging to that corpus is added to the
   // DocumentStore. Corpus ids may be removed from the mapper during compaction.
   std::unique_ptr<
@@ -780,7 +836,7 @@ class DocumentStore {
   bool HeaderExists();
 
   libtextclassifier3::StatusOr<PutResult> InternalPut(
-      DocumentProto&& document,
+      const DocumentWrapper& document_wrapper,
       PutDocumentStatsProto* put_document_stats = nullptr);
 
   // Helper function to do batch deletes. Documents with the given
diff --git a/icing/store/document-store_benchmark.cc b/icing/store/document-store_benchmark.cc
index 3782da0..907c01b 100644
--- a/icing/store/document-store_benchmark.cc
+++ b/icing/store/document-store_benchmark.cc
@@ -14,26 +14,21 @@
 
 #include <unistd.h>
 
-#include <fstream>
-#include <iostream>
 #include <memory>
-#include <ostream>
 #include <random>
-#include <sstream>
-#include <stdexcept>
 #include <string>
 #include <string_view>
-#include <unordered_set>
-#include <vector>
+#include <utility>
 
+#include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "testing/base/public/benchmark.h"
-#include "gmock/gmock.h"
-#include "gtest/gtest.h"
 #include "icing/document-builder.h"
 #include "icing/feature-flags.h"
 #include "icing/file/filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
 #include "icing/proto/persist.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/proto/term.pb.h"
@@ -44,6 +39,8 @@
 #include "icing/testing/test-feature-flags.h"
 #include "icing/testing/tmp-directory.h"
 #include "icing/util/clock.h"
+#include "icing/util/document-util.h"
+#include "icing/util/logging.h"
 
 // Run on a Linux workstation:
 //    $ blaze build -c opt --dynamic_mode=off --copt=-gmlt
@@ -84,14 +81,15 @@ class DestructibleDirectory {
   std::string dir_;
 };
 
-DocumentProto CreateDocument(const std::string namespace_,
-                             const std::string uri) {
-  return DocumentBuilder()
-      .SetKey(namespace_, uri)
-      .SetSchema("email")
-      .AddStringProperty("subject", "subject foo")
-      .AddStringProperty("body", "body bar")
-      .Build();
+DocumentWrapper CreateDocument(const std::string namespace_,
+                               const std::string uri) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey(namespace_, uri)
+                               .SetSchema("email")
+                               .AddStringProperty("subject", "subject foo")
+                               .AddStringProperty("body", "body bar")
+                               .Build();
+  return document_util::CreateDocumentWrapper(std::move(document));
 }
 
 SchemaProto CreateSchema() {
@@ -138,6 +136,9 @@ libtextclassifier3::StatusOr<DocumentStore::CreateResult> CreateDocumentStore(
       /*force_recovery_and_revalidate_documents=*/false,
       /*pre_mapping_fbv=*/false, /*use_persistent_hash_map=*/true,
       PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+      PortableFileBackedProtoLog<
+          DocumentWrapper>::kDefaultCompressionThresholdBytes,
+      protobuf_ports::kDefaultMemLevel,
       /*initialize_stats=*/nullptr);
 }
 
@@ -204,7 +205,7 @@ void BM_Put(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  DocumentProto document = CreateDocument("namespace", "uri");
+  DocumentWrapper document = CreateDocument("namespace", "uri");
 
   for (auto s : state) {
     // It's ok that this is the same document over and over. We'll create a new
@@ -262,7 +263,7 @@ void BM_Delete(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  DocumentProto document = CreateDocument("namespace", "uri");
+  DocumentWrapper document = CreateDocument("namespace", "uri");
 
   for (auto s : state) {
     state.PauseTiming();
@@ -298,7 +299,7 @@ void BM_Create(benchmark::State& state) {
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
-    DocumentProto document = CreateDocument("namespace", "uri");
+    DocumentWrapper document = CreateDocument("namespace", "uri");
     ICING_ASSERT_OK(document_store->Put(document));
     ICING_ASSERT_OK(document_store->PersistToDisk(PersistType::FULL));
   }
@@ -336,7 +337,7 @@ void BM_UpdateChecksum(benchmark::State& state) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  DocumentProto document = CreateDocument("namespace", "uri");
+  DocumentWrapper document = CreateDocument("namespace", "uri");
   ICING_ASSERT_OK(document_store->Put(document));
   ICING_ASSERT_OK(document_store->PersistToDisk(PersistType::LITE));
 
diff --git a/icing/store/document-store_test.cc b/icing/store/document-store_test.cc
index eb50b9b..95a4614 100644
--- a/icing/store/document-store_test.cc
+++ b/icing/store/document-store_test.cc
@@ -24,7 +24,6 @@
 
 #include "icing/text_classifier/lib3/utils/base/status.h"
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
-#include "icing/text_classifier/lib3/utils/hash/farmhash.h"
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
 #include "icing/absl_ports/str_cat.h"
@@ -36,6 +35,7 @@
 #include "icing/file/mock-filesystem.h"
 #include "icing/file/portable-file-backed-proto-log.h"
 #include "icing/portable/equals-proto.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/debug.pb.h"
 #include "icing/proto/document.pb.h"
@@ -66,6 +66,7 @@
 #include "icing/util/clock.h"
 #include "icing/util/crc32.h"
 #include "icing/util/data-loss.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "icing/util/logging.h"
 #include "icing/util/scorable_property_set.h"
@@ -88,10 +89,20 @@ using ::testing::IsFalse;
 using ::testing::IsTrue;
 using ::testing::Ne;
 using ::testing::Not;
+using ::testing::Optional;
 using ::testing::Pointee;
 using ::testing::Return;
 using ::testing::UnorderedElementsAre;
 
+using ResultSpecProto::ResultGroupingType::
+    ResultSpecProto_ResultGroupingType_NAMESPACE;
+using ResultSpecProto::ResultGroupingType::
+    ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE;
+using ResultSpecProto::ResultGroupingType::
+    ResultSpecProto_ResultGroupingType_NONE;
+using ResultSpecProto::ResultGroupingType::
+    ResultSpecProto_ResultGroupingType_SCHEMA_TYPE;
+
 const NamespaceStorageInfoProto& GetNamespaceStorageInfo(
     const DocumentStorageInfoProto& storage_info,
     const std::string& name_space) {
@@ -284,6 +295,9 @@ class DocumentStoreTest
         /*force_recovery_and_revalidate_documents=*/false,
         GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
         PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+        PortableFileBackedProtoLog<
+            DocumentWrapper>::kDefaultCompressionThresholdBytes,
+        protobuf_ports::kDefaultMemLevel,
         /*initialize_stats=*/nullptr);
   }
 
@@ -312,6 +326,12 @@ class DocumentStoreTest
   const int64_t document2_expiration_timestamp_ = 3;  // creation + ttl
 };
 
+DocumentWrapper CreateDocumentWrapper(DocumentProto document,
+                                      int32_t num_string_tokens) {
+  document.mutable_internal_fields()->set_length_in_tokens(num_string_tokens);
+  return document_util::CreateDocumentWrapper(std::move(document));
+}
+
 TEST_P(DocumentStoreTest, CreationWithNullPointerShouldFail) {
   EXPECT_THAT(CreateDocumentStore(/*filesystem=*/nullptr, document_store_dir_,
                                   &fake_clock_, schema_store_.get()),
@@ -344,13 +364,15 @@ TEST_P(DocumentStoreTest, PutAndGetInSameNamespaceOk) {
       std::move(create_result.document_store);
 
   // Both documents have namespace of "icing"
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(test_document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document2_)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -381,13 +403,15 @@ TEST_P(DocumentStoreTest, PutAndGetAcrossNamespacesOk) {
                                    .SetCreationTimestampMs(0)
                                    .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(foo_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(foo_document)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(DocumentProto(bar_document)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(bar_document)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -412,13 +436,15 @@ TEST_P(DocumentStoreTest, PutSameKey) {
   DocumentProto document1 = DocumentProto(test_document1_);
   DocumentProto document2 = DocumentProto(test_document1_);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
   EXPECT_THAT(put_result2.old_document_id, Eq(document_id1));
   EXPECT_TRUE(put_result2.was_replacement());
@@ -432,8 +458,9 @@ TEST_P(DocumentStoreTest, PutSameKey) {
   // Makes sure that old doc ids are not getting reused.
   DocumentProto document3 = DocumentProto(test_document1_);
   document3.set_uri("another/uri/1");
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             doc_store->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      doc_store->Put(document_util::CreateDocumentWrapper(document3)));
   EXPECT_THAT(put_result3.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_THAT(put_result3.new_document_id, Ne(document_id1));
   EXPECT_FALSE(put_result3.was_replacement());
@@ -447,13 +474,15 @@ TEST_P(DocumentStoreTest, IsDocumentExistingWithoutStatus) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(test_document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document2_)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -489,7 +518,8 @@ TEST_P(DocumentStoreTest, GetDeletedDocumentNotFound) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(DocumentProto(test_document1_)));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(
       document_store->Get(test_document1_.namespace_(), test_document1_.uri()),
       IsOkAndHolds(EqualsProto(test_document1_)));
@@ -517,7 +547,8 @@ TEST_P(DocumentStoreTest, GetExpiredDocumentNotFound) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(document));
+  ICING_EXPECT_OK(
+      document_store->Put(document_util::CreateDocumentWrapper(document)));
   EXPECT_THAT(document_store->Get("namespace", "uri"),
               IsOkAndHolds(EqualsProto(document)));
 
@@ -545,8 +576,9 @@ TEST_P(DocumentStoreTest, GetInvalidDocumentId) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -630,7 +662,8 @@ TEST_P(DocumentStoreTest, DeleteAlreadyDeletedDocumentNotFound) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
 
   // First time is OK
   ICING_EXPECT_OK(document_store->Delete(
@@ -655,22 +688,26 @@ TEST_P(DocumentStoreTest, DeleteByNamespaceOk) {
   DocumentProto document1 = test_document1_;
   document1.set_namespace_("namespace.1");
   document1.set_uri("uri1");
-  ICING_ASSERT_OK(doc_store->Put(document1));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
 
   DocumentProto document2 = test_document1_;
   document2.set_namespace_("namespace.2");
   document2.set_uri("uri1");
-  ICING_ASSERT_OK(doc_store->Put(document2));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
 
   DocumentProto document3 = test_document1_;
   document3.set_namespace_("namespace.3");
   document3.set_uri("uri1");
-  ICING_ASSERT_OK(doc_store->Put(document3));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document3)));
 
   DocumentProto document4 = test_document1_;
   document4.set_namespace_("namespace.1");
   document4.set_uri("uri2");
-  ICING_ASSERT_OK(doc_store->Put(document4));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document4)));
 
   // DELETE namespace.1. document1 and document 4 should be deleted. document2
   // and document3 should still be retrievable.
@@ -721,7 +758,8 @@ TEST_P(DocumentStoreTest, DeleteByNamespaceNoExistingDocumentsNotFound) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   ICING_EXPECT_OK(document_store->Delete(
       test_document1_.namespace_(), test_document1_.uri(),
       fake_clock_.GetSystemTimeMilliseconds()));
@@ -760,10 +798,14 @@ TEST_P(DocumentStoreTest, DeleteByNamespaceRecoversOk) {
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK(doc_store->Put(document1));
-    ICING_ASSERT_OK(doc_store->Put(document2));
-    ICING_ASSERT_OK(doc_store->Put(document3));
-    ICING_ASSERT_OK(doc_store->Put(document4));
+    ICING_ASSERT_OK(
+        doc_store->Put(document_util::CreateDocumentWrapper(document1)));
+    ICING_ASSERT_OK(
+        doc_store->Put(document_util::CreateDocumentWrapper(document2)));
+    ICING_ASSERT_OK(
+        doc_store->Put(document_util::CreateDocumentWrapper(document3)));
+    ICING_ASSERT_OK(
+        doc_store->Put(document_util::CreateDocumentWrapper(document4)));
 
     // DELETE namespace.1. document1 and document 4 should be deleted. document2
     // and document3 should still be retrievable.
@@ -835,8 +877,10 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeOk) {
                                        .SetSchema("email")
                                        .SetCreationTimestampMs(1)
                                        .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result1,
-                             document_store->Put(email_document_1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult email_put_result1,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_document_1)));
   EXPECT_THAT(email_put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_put_result1.was_replacement());
   DocumentId email_1_document_id = email_put_result1.new_document_id;
@@ -846,8 +890,10 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeOk) {
                                        .SetSchema("email")
                                        .SetCreationTimestampMs(1)
                                        .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result2,
-                             document_store->Put(email_document_2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult email_put_result2,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_document_2)));
   EXPECT_THAT(email_put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_put_result2.was_replacement());
   DocumentId email_2_document_id = email_put_result2.new_document_id;
@@ -857,8 +903,10 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeOk) {
                                        .SetSchema("message")
                                        .SetCreationTimestampMs(1)
                                        .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult message_put_result,
-                             document_store->Put(message_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult message_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(message_document)));
   EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(message_put_result.was_replacement());
   DocumentId message_document_id = message_put_result.new_document_id;
@@ -868,8 +916,10 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeOk) {
                                       .SetSchema("person")
                                       .SetCreationTimestampMs(1)
                                       .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult person_put_result,
-                             document_store->Put(person_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult person_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(person_document)));
   EXPECT_THAT(person_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(person_put_result.was_replacement());
   DocumentId person_document_id = person_put_result.new_document_id;
@@ -937,7 +987,8 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeNoExistingDocumentsNotFound) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   ICING_EXPECT_OK(document_store->Delete(
       test_document1_.namespace_(), test_document1_.uri(),
       fake_clock_.GetSystemTimeMilliseconds()));
@@ -988,13 +1039,17 @@ TEST_P(DocumentStoreTest, DeleteBySchemaTypeRecoversOk) {
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result,
-                               document_store->Put(email_document));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult email_put_result,
+        document_store->Put(
+            document_util::CreateDocumentWrapper(email_document)));
     EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(email_put_result.was_replacement());
     email_document_id = email_put_result.new_document_id;
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult message_put_result,
-                               document_store->Put(message_document));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult message_put_result,
+        document_store->Put(
+            document_util::CreateDocumentWrapper(message_document)));
     EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(message_put_result.was_replacement());
     message_document_id = message_put_result.new_document_id;
@@ -1039,11 +1094,13 @@ TEST_P(DocumentStoreTest, PutDeleteThenPut) {
                           schema_store_.get()));
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
-  ICING_EXPECT_OK(doc_store->Put(test_document1_));
+  ICING_EXPECT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   ICING_EXPECT_OK(doc_store->Delete(test_document1_.namespace_(),
                                     test_document1_.uri(),
                                     fake_clock_.GetSystemTimeMilliseconds()));
-  ICING_EXPECT_OK(doc_store->Put(test_document1_));
+  ICING_EXPECT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
 }
 
 TEST_P(DocumentStoreTest, DeletedSchemaTypeFromSchemaStoreRecoversOk) {
@@ -1087,13 +1144,17 @@ TEST_P(DocumentStoreTest, DeletedSchemaTypeFromSchemaStoreRecoversOk) {
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result,
-                               document_store->Put(email_document));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult email_put_result,
+        document_store->Put(
+            document_util::CreateDocumentWrapper(email_document)));
     EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(email_put_result.was_replacement());
     email_document_id = email_put_result.new_document_id;
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult message_put_result,
-                               document_store->Put(message_document));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult message_put_result,
+        document_store->Put(
+            document_util::CreateDocumentWrapper(message_document)));
     EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(message_put_result.was_replacement());
     message_document_id = message_put_result.new_document_id;
@@ -1177,9 +1238,12 @@ TEST_P(DocumentStoreTest, OptimizeIntoSingleNamespace) {
   // Nothing should have expired yet.
   fake_clock_.SetSystemTimeMilliseconds(100);
 
-  ICING_ASSERT_OK(doc_store->Put(document1));
-  ICING_ASSERT_OK(doc_store->Put(document2));
-  ICING_ASSERT_OK(doc_store->Put(document3));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document1, /*num_string_tokens=*/0)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document2, /*num_string_tokens=*/0)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document3, /*num_string_tokens=*/0)));
 
   std::string original_document_log = absl_ports::StrCat(
       document_store_dir_, "/", DocumentLogCreator::GetDocumentLogFilename());
@@ -1326,11 +1390,16 @@ TEST_P(DocumentStoreTest, OptimizeIntoMultipleNamespaces) {
   // Nothing should have expired yet.
   fake_clock_.SetSystemTimeMilliseconds(100);
 
-  ICING_ASSERT_OK(doc_store->Put(document0));
-  ICING_ASSERT_OK(doc_store->Put(document1));
-  ICING_ASSERT_OK(doc_store->Put(document2));
-  ICING_ASSERT_OK(doc_store->Put(document3));
-  ICING_ASSERT_OK(doc_store->Put(document4));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document0, /*num_string_tokens=*/0)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document1, /*num_string_tokens=*/0)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document2, /*num_string_tokens=*/0)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document3, /*num_string_tokens=*/0)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document4, /*num_string_tokens=*/0)));
 
   std::string original_document_log = absl_ports::StrCat(
       document_store_dir_, "/", DocumentLogCreator::GetDocumentLogFilename());
@@ -1529,15 +1598,15 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromDataLoss) {
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result1,
-        doc_store->Put(DocumentProto(test_document1_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document1_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id1 = put_result1.new_document_id;
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result2,
-        doc_store->Put(DocumentProto(test_document2_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document2_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result2.was_replacement());
     document_id2 = put_result2.new_document_id;
@@ -1615,11 +1684,10 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromDataLoss) {
       DocumentFilterData doc_filter_data,
       doc_store->GetAliveDocumentFilterData(
           document_id2, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(
-      doc_filter_data,
-      Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(test_document2_.uri()),
-          /*schema_type_id=*/0, document2_expiration_timestamp_)));
+  EXPECT_THAT(doc_filter_data,
+              Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                    document2_expiration_timestamp_,
+                                    document2_expiration_timestamp_)));
 
   // Checks derived score cache
   EXPECT_THAT(
@@ -1655,15 +1723,15 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromCorruptDerivedFile) {
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result1,
-        doc_store->Put(DocumentProto(test_document1_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document1_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id1 = put_result1.new_document_id;
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result2,
-        doc_store->Put(DocumentProto(test_document2_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document2_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result2.was_replacement());
     document_id2 = put_result2.new_document_id;
@@ -1751,11 +1819,10 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromCorruptDerivedFile) {
       DocumentFilterData doc_filter_data,
       doc_store->GetAliveDocumentFilterData(
           document_id2, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(
-      doc_filter_data,
-      Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(test_document2_.uri()),
-          /*schema_type_id=*/0, document2_expiration_timestamp_)));
+  EXPECT_THAT(doc_filter_data,
+              Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                    document2_expiration_timestamp_,
+                                    document2_expiration_timestamp_)));
 
   // Checks derived score cache
   EXPECT_THAT(
@@ -1801,15 +1868,15 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromDiscardDerivedFiles) {
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result1,
-        doc_store->Put(DocumentProto(test_document1_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document1_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id1 = put_result1.new_document_id;
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result2,
-        doc_store->Put(DocumentProto(test_document2_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document2_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result2.was_replacement());
     document_id2 = put_result2.new_document_id;
@@ -1885,11 +1952,10 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromDiscardDerivedFiles) {
       DocumentFilterData doc_filter_data,
       doc_store->GetAliveDocumentFilterData(
           document_id2, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(
-      doc_filter_data,
-      Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(test_document2_.uri()),
-          /*schema_type_id=*/0, document2_expiration_timestamp_)));
+  EXPECT_THAT(doc_filter_data,
+              Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                    document2_expiration_timestamp_,
+                                    document2_expiration_timestamp_)));
 
   // Checks derived score cache.
   EXPECT_THAT(
@@ -1935,15 +2001,15 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromBadChecksum) {
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result1,
-        doc_store->Put(DocumentProto(test_document1_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document1_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id1 = put_result1.new_document_id;
-    ICING_ASSERT_OK_AND_ASSIGN(
-        DocumentStore::PutResult put_result2,
-        doc_store->Put(DocumentProto(test_document2_), /*num_tokens=*/4));
+    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                               doc_store->Put(CreateDocumentWrapper(
+                                   test_document2_, /*num_string_tokens=*/4)));
     EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result2.was_replacement());
     document_id2 = put_result2.new_document_id;
@@ -2010,11 +2076,10 @@ TEST_P(DocumentStoreTest, ShouldRecoverFromBadChecksum) {
       DocumentFilterData doc_filter_data,
       doc_store->GetAliveDocumentFilterData(
           document_id2, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(
-      doc_filter_data,
-      Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(test_document2_.uri()),
-          /*schema_type_id=*/0, document2_expiration_timestamp_)));
+  EXPECT_THAT(doc_filter_data,
+              Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                    document2_expiration_timestamp_,
+                                    document2_expiration_timestamp_)));
   // Checks derived score cache
   EXPECT_THAT(
       doc_store->GetDocumentAssociatedScoreData(document_id2),
@@ -2061,7 +2126,8 @@ TEST_P(DocumentStoreTest, GetStorageInfo) {
   // 1 block size. The number 100 is a bit arbitrary, gotten from manually
   // testing.
   for (int i = 0; i < 100; ++i) {
-    ICING_ASSERT_OK(doc_store->Put(document));
+    ICING_ASSERT_OK(
+        doc_store->Put(document_util::CreateDocumentWrapper(document)));
   }
   doc_store_storage_info = doc_store->GetStorageInfo();
   EXPECT_THAT(doc_store_storage_info.document_store_size(),
@@ -2093,8 +2159,9 @@ TEST_P(DocumentStoreTest, MaxDocumentId) {
   // Since the DocumentStore is empty, we get an invalid DocumentId
   EXPECT_THAT(doc_store->last_added_document_id(), Eq(kInvalidDocumentId));
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(DocumentProto(test_document1_)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
@@ -2105,8 +2172,9 @@ TEST_P(DocumentStoreTest, MaxDocumentId) {
                                     fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(doc_store->last_added_document_id(), Eq(document_id1));
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(DocumentProto(test_document2_)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document2_)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -2126,8 +2194,10 @@ TEST_P(DocumentStoreTest, GetNamespaceId) {
   DocumentProto document_namespace2 =
       DocumentBuilder().SetKey("namespace2", "2").SetSchema("email").Build();
 
-  ICING_ASSERT_OK(doc_store->Put(DocumentProto(document_namespace1)));
-  ICING_ASSERT_OK(doc_store->Put(DocumentProto(document_namespace2)));
+  ICING_ASSERT_OK(doc_store->Put(
+      document_util::CreateDocumentWrapper(document_namespace1)));
+  ICING_ASSERT_OK(doc_store->Put(
+      document_util::CreateDocumentWrapper(document_namespace2)));
 
   // NamespaceId of 0 since it was the first namespace seen by the DocumentStore
   EXPECT_THAT(doc_store->GetNamespaceId("namespace1"), IsOkAndHolds(Eq(0)));
@@ -2159,8 +2229,10 @@ TEST_P(DocumentStoreTest, GetDuplicateNamespaceId) {
   DocumentProto document2 =
       DocumentBuilder().SetKey("namespace", "2").SetSchema("email").Build();
 
-  ICING_ASSERT_OK(doc_store->Put(document1));
-  ICING_ASSERT_OK(doc_store->Put(document2));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
 
   // NamespaceId of 0 since it was the first namespace seen by the DocumentStore
   EXPECT_THAT(doc_store->GetNamespaceId("namespace"), IsOkAndHolds(Eq(0)));
@@ -2191,8 +2263,10 @@ TEST_P(DocumentStoreTest, GetCorpusDuplicateCorpusId) {
   DocumentProto document2 =
       DocumentBuilder().SetKey("namespace", "2").SetSchema("email").Build();
 
-  ICING_ASSERT_OK(doc_store->Put(document1));
-  ICING_ASSERT_OK(doc_store->Put(document2));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
 
   // CorpusId of 0 since it was the first namespace seen by the DocumentStore
   EXPECT_THAT(doc_store->GetCorpusId("namespace", "email"),
@@ -2212,8 +2286,10 @@ TEST_P(DocumentStoreTest, GetCorpusId) {
   DocumentProto document_corpus2 =
       DocumentBuilder().SetKey("namespace2", "2").SetSchema("email").Build();
 
-  ICING_ASSERT_OK(doc_store->Put(DocumentProto(document_corpus1)));
-  ICING_ASSERT_OK(doc_store->Put(DocumentProto(document_corpus2)));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document_corpus1)));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document_corpus2)));
 
   // CorpusId of 0 since it was the first corpus seen by the DocumentStore
   EXPECT_THAT(doc_store->GetCorpusId("namespace1", "email"),
@@ -2248,7 +2324,8 @@ TEST_P(DocumentStoreTest, NonexistentCorpusNotFound) {
 
   DocumentProto document_corpus =
       DocumentBuilder().SetKey("namespace1", "1").SetSchema("email").Build();
-  ICING_ASSERT_OK(doc_store->Put(DocumentProto(document_corpus)));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document_corpus)));
 
   EXPECT_THAT(doc_store->GetCorpusId("nonexistent_namespace", "email"),
               StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
@@ -2271,8 +2348,10 @@ TEST_P(DocumentStoreTest, GetCorpusAssociatedScoreDataSameCorpus) {
   DocumentProto document2 =
       DocumentBuilder().SetKey("namespace", "2").SetSchema("email").Build();
 
-  ICING_ASSERT_OK(doc_store->Put(document1, /*num_tokens=*/5));
-  ICING_ASSERT_OK(doc_store->Put(document2, /*num_tokens=*/7));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document1, /*num_string_tokens=*/5)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document2, /*num_string_tokens=*/7)));
 
   // CorpusId of 0 since it was the first namespace seen by the DocumentStore
   EXPECT_THAT(doc_store->GetCorpusAssociatedScoreData(/*corpus_id=*/0),
@@ -2296,10 +2375,10 @@ TEST_P(DocumentStoreTest, GetCorpusAssociatedScoreData) {
   DocumentProto document_corpus2 =
       DocumentBuilder().SetKey("namespace2", "2").SetSchema("email").Build();
 
-  ICING_ASSERT_OK(
-      doc_store->Put(DocumentProto(document_corpus1), /*num_tokens=*/5));
-  ICING_ASSERT_OK(
-      doc_store->Put(DocumentProto(document_corpus2), /*num_tokens=*/7));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document_corpus1, /*num_string_tokens=*/5)));
+  ICING_ASSERT_OK(doc_store->Put(
+      CreateDocumentWrapper(document_corpus2, /*num_string_tokens=*/7)));
 
   // CorpusId of 0 since it was the first corpus seen by the DocumentStore
   EXPECT_THAT(doc_store->GetCorpusAssociatedScoreData(/*corpus_id=*/0),
@@ -2358,15 +2437,15 @@ TEST_P(DocumentStoreTest, GetDocumentAssociatedScoreDataSameCorpus) {
               document2_creation_timestamp_)  // A random timestamp
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      doc_store->Put(DocumentProto(document1), /*num_tokens=*/5));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             doc_store->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/5)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      doc_store->Put(DocumentProto(document2), /*num_tokens=*/7));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             doc_store->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/7)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -2410,15 +2489,15 @@ TEST_P(DocumentStoreTest, GetDocumentAssociatedScoreDataDifferentCorpus) {
               document2_creation_timestamp_)  // A random timestamp
           .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result1,
-      doc_store->Put(DocumentProto(document1), /*num_tokens=*/5));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
+                             doc_store->Put(CreateDocumentWrapper(
+                                 document1, /*num_string_tokens=*/5)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result2,
-      doc_store->Put(DocumentProto(document2), /*num_tokens=*/7));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
+                             doc_store->Put(CreateDocumentWrapper(
+                                 document2, /*num_string_tokens=*/7)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -2469,8 +2548,9 @@ TEST_P(DocumentStoreTest, DeleteClearsFilterCache) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(DocumentProto(test_document1_)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2479,11 +2559,10 @@ TEST_P(DocumentStoreTest, DeleteClearsFilterCache) {
       DocumentFilterData doc_filter_data,
       doc_store->GetAliveDocumentFilterData(
           document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(
-      doc_filter_data,
-      Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(test_document1_.uri()),
-          /*schema_type_id=*/0, document1_expiration_timestamp_)));
+  EXPECT_THAT(doc_filter_data,
+              Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                    document1_expiration_timestamp_,
+                                    document1_expiration_timestamp_)));
 
   ICING_ASSERT_OK(doc_store->Delete("icing", "email/1",
                                     fake_clock_.GetSystemTimeMilliseconds()));
@@ -2500,9 +2579,9 @@ TEST_P(DocumentStoreTest, DeleteClearsScoreCache) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(
-      DocumentStore::PutResult put_result,
-      doc_store->Put(DocumentProto(test_document1_), /*num_tokens=*/4));
+  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
+                             doc_store->Put(CreateDocumentWrapper(
+                                 test_document1_, /*num_string_tokens=*/4)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2536,7 +2615,8 @@ TEST_P(DocumentStoreTest, DeleteClearsScorablePropertyCache) {
       std::move(create_result.document_store);
 
   ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(test_document1_, /*num_tokens=*/4));
+                             doc_store->Put(CreateDocumentWrapper(
+                                 test_document1_, /*num_string_tokens=*/4)));
   DocumentId document_id = put_result1.new_document_id;
   EXPECT_NE(doc_store->GetScorablePropertySet(
                 document_id, fake_clock_.GetSystemTimeMilliseconds()),
@@ -2557,8 +2637,9 @@ TEST_P(DocumentStoreTest, DeleteShouldPreventUsageScores) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(DocumentProto(test_document1_)));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2609,8 +2690,9 @@ TEST_P(DocumentStoreTest, ExpirationShouldPreventUsageScores) {
                                .SetTtlMs(100)
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2645,6 +2727,252 @@ TEST_P(DocumentStoreTest, ExpirationShouldPreventUsageScores) {
       document_id, fake_clock_.GetSystemTimeMilliseconds()));
 }
 
+TEST_P(DocumentStoreTest, IsDocumentAlive) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace", "uri")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(0)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  ASSERT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  ASSERT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // The expiration timestamp is 1000, so the document is alive at any time
+  // before that.
+  EXPECT_TRUE(doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/0));
+  EXPECT_TRUE(doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/100));
+  EXPECT_TRUE(doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/999));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1000));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1001));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/2000));
+
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/0));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/100));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/999));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1000));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1001));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/2000));
+}
+
+TEST_P(DocumentStoreTest, IsDocumentAlive_deletedDocument) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace", "uri")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(0)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  ASSERT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  ASSERT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // Delete the document.
+  ICING_ASSERT_OK(doc_store->Delete("namespace", "uri",
+                                    fake_clock_.GetSystemTimeMilliseconds()));
+
+  // Should be non-alive regardless of the current timestamp.
+  EXPECT_FALSE(doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/0));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/100));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1099));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1100));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1101));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/2000));
+
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/0));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/100));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1099));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1100));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1101));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/2000));
+}
+
+TEST_P(DocumentStoreTest, IsDocumentAlive_infiniteTtlDocument) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace", "uri")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(0)
+                               .SetTtlMs(0)  // infinite TTL
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  ASSERT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  ASSERT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  EXPECT_TRUE(doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/0));
+  EXPECT_TRUE(doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/100));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1099));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1100));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/1101));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive(document_id, /*current_time_ms=*/2000));
+  EXPECT_TRUE(doc_store->IsDocumentAlive(
+      document_id,
+      /*current_time_ms=*/std::numeric_limits<int64_t>::max() - 1));
+
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/0));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/100));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1099));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1100));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/1101));
+  EXPECT_TRUE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/2000));
+  EXPECT_TRUE(doc_store->IsDocumentAlive(
+      "namespace", "uri",
+      /*current_time_ms=*/std::numeric_limits<int64_t>::max() - 1));
+}
+
+TEST_P(DocumentStoreTest, IsDocumentAlive_invalidDocumentId) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ASSERT_THAT(doc_store->last_added_document_id(), Eq(kInvalidDocumentId));
+
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(/*document_id=*/-1, /*current_time_ms=*/0));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(/*document_id=*/0, /*current_time_ms=*/0));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(/*document_id=*/10000, /*current_time_ms=*/0));
+  EXPECT_FALSE(doc_store->IsDocumentAlive(/*document_id=*/100000,
+                                          /*current_time_ms=*/0));
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive(kInvalidDocumentId, /*current_time_ms=*/0));
+}
+
+TEST_P(DocumentStoreTest, IsDocumentAlive_invalidNamespaceUri) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ASSERT_THAT(doc_store->last_added_document_id(), Eq(kInvalidDocumentId));
+
+  EXPECT_FALSE(
+      doc_store->IsDocumentAlive("namespace", "uri", /*current_time_ms=*/0));
+}
+
+TEST_P(DocumentStoreTest,
+       GetAliveDocumentFilterDataShouldCheckExpirationTimestamp) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // The raw expiration timestamp is 1100. Now, set the expiration timestamp to
+  // 500.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/500));
+  EXPECT_THAT(update_result.final_expiration_timestamp_ms, Eq(500));
+  EXPECT_THAT(update_result.was_updated, IsTrue());
+
+  // Case 1: call GetAliveDocumentFilterData with a current ts before the
+  //         expiration timestamp.
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(document_id,
+                                            /*current_time_ms=*/300),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Case 2: call GetAliveDocumentFilterData with a current ts at the
+  //         expiration timestamp.
+  // This should fail even though the current ts is smaller than the raw
+  // expiration timestamp.
+  EXPECT_FALSE(doc_store->GetAliveDocumentFilterData(document_id,
+                                                     /*current_time_ms=*/500));
+
+  // Case 3: call GetAliveDocumentFilterData with a current ts after the
+  //         expiration timestamp.
+  // This should fail even though the current ts is smaller than the raw
+  // expiration timestamp.
+  EXPECT_FALSE(doc_store->GetAliveDocumentFilterData(document_id,
+                                                     /*current_time_ms=*/700));
+}
+
 TEST_P(DocumentStoreTest,
        ExpirationTimestampIsSumOfNonZeroTtlAndCreationTimestamp) {
   DocumentProto document = DocumentBuilder()
@@ -2661,8 +2989,9 @@ TEST_P(DocumentStoreTest,
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2670,11 +2999,10 @@ TEST_P(DocumentStoreTest,
       DocumentFilterData doc_filter_data,
       doc_store->GetAliveDocumentFilterData(
           document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(
-      doc_filter_data,
-      Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(document.uri()),
-          /*schema_type_id=*/0, /*expiration_timestamp_ms=*/1100)));
+  EXPECT_THAT(doc_filter_data, Eq(DocumentFilterData(
+                                   /*namespace_id=*/0, /*schema_type_id=*/0,
+                                   /*expiration_timestamp_ms=*/1100,
+                                   /*raw_expiration_timestamp_ms=*/1100)));
 }
 
 TEST_P(DocumentStoreTest, ExpirationTimestampIsInt64MaxIfTtlIsZero) {
@@ -2692,8 +3020,9 @@ TEST_P(DocumentStoreTest, ExpirationTimestampIsInt64MaxIfTtlIsZero) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2706,9 +3035,10 @@ TEST_P(DocumentStoreTest, ExpirationTimestampIsInt64MaxIfTtlIsZero) {
   EXPECT_THAT(
       doc_filter_data,
       Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(document.uri()),
-          /*schema_type_id=*/0,
-          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max())));
+          /*namespace_id=*/0, /*schema_type_id=*/0,
+          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max(),
+          /*raw_expiration_timestamp_ms=*/
+          std::numeric_limits<int64_t>::max())));
 }
 
 TEST_P(DocumentStoreTest, ExpirationTimestampIsInt64MaxOnOverflow) {
@@ -2727,8 +3057,9 @@ TEST_P(DocumentStoreTest, ExpirationTimestampIsInt64MaxOnOverflow) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -2741,23 +3072,255 @@ TEST_P(DocumentStoreTest, ExpirationTimestampIsInt64MaxOnOverflow) {
   EXPECT_THAT(
       doc_filter_data,
       Eq(DocumentFilterData(
-          /*namespace_id=*/0, tc3farmhash::Fingerprint64(document.uri()),
-          /*schema_type_id=*/0,
-          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max())));
+          /*namespace_id=*/0, /*schema_type_id=*/0,
+          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max(),
+          /*raw_expiration_timestamp_ms=*/
+          std::numeric_limits<int64_t>::max())));
 }
 
-TEST_P(DocumentStoreTest, CreationTimestampShouldBePopulated) {
-  // Creates a document without a given creation timestamp
-  DocumentProto document_without_creation_timestamp =
-      DocumentBuilder()
-          .SetKey("icing", "email/1")
-          .SetSchema("email")
-          .AddStringProperty("subject", "subject foo")
-          .AddStringProperty("body", "body bar")
-          .Build();
+TEST_P(DocumentStoreTest, UpdateDocumentExpirationTimestamp) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/1100,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Set the expiration timestamp to 700.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result1,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/700));
+  EXPECT_THAT(update_result1.final_expiration_timestamp_ms, Eq(700));
+  EXPECT_THAT(update_result1.was_updated, IsTrue());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/700,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Set the expiration timestamp to 500.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result2,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/500));
+  EXPECT_THAT(update_result2.final_expiration_timestamp_ms, Eq(500));
+  EXPECT_THAT(update_result2.was_updated, IsTrue());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+}
+
+TEST_P(DocumentStoreTest, UpdateDocumentExpirationTimestamp_invalidDocumentId) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  ASSERT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  ASSERT_FALSE(put_result.was_replacement());
+
+  EXPECT_THAT(doc_store->UpdateDocumentExpirationTimestamp(
+                  /*document_id=*/-1, /*expiration_timestamp_ms=*/700),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(doc_store->UpdateDocumentExpirationTimestamp(
+                  doc_store->last_added_document_id() + 1,
+                  /*expiration_timestamp_ms=*/700),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+  EXPECT_THAT(doc_store->UpdateDocumentExpirationTimestamp(
+                  kInvalidDocumentId, /*expiration_timestamp_ms=*/700),
+              StatusIs(libtextclassifier3::StatusCode::INVALID_ARGUMENT));
+}
+
+TEST_P(DocumentStoreTest,
+       UpdateDocumentExpirationTimestamp_shouldOnlyDecrease) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // The raw expiration timestamp and the expiration timestamp are 1100.
+  // Setting the expiration timestamp to 1500 should be no-op.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result1,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/1500));
+  EXPECT_THAT(update_result1.final_expiration_timestamp_ms, Eq(1100));
+  EXPECT_THAT(update_result1.was_updated, IsFalse());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/1100,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Set the expiration timestamp to 500. This should change the expiration
+  // timestamp to 500.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result2,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/500));
+  EXPECT_THAT(update_result2.final_expiration_timestamp_ms, Eq(500));
+  EXPECT_THAT(update_result2.was_updated, IsTrue());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Setting the expiration timestamp to 700 should be no-op.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result3,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/700));
+  EXPECT_THAT(update_result3.final_expiration_timestamp_ms, Eq(500));
+  EXPECT_THAT(update_result3.was_updated, IsFalse());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+}
+
+TEST_P(DocumentStoreTest,
+       UpdateDocumentExpirationTimestamp_canUpdateExpiredDocument) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // Set the expiration timestamp to 500.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result1,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/500));
+  ASSERT_THAT(update_result1.final_expiration_timestamp_ms, Eq(500));
+  ASSERT_THAT(update_result1.was_updated, IsTrue());
+  // Sanity check.
+  ASSERT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Adjust the current time to 500. The document is expired.
+  fake_clock_.SetSystemTimeMilliseconds(500);
+  ASSERT_THAT(doc_store->IsDocumentAlive(
+                  /*document_id=*/0,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsFalse());
+
+  // Updating an expired document is allowed, but since we only allow to
+  // decrease the expiration timestamp, it is a no-op.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result2,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/800));
+  EXPECT_THAT(update_result2.final_expiration_timestamp_ms, Eq(500));
+  EXPECT_THAT(update_result2.was_updated, IsFalse());
+  EXPECT_THAT(
+      doc_store->GetNonDeletedDocumentFilterData(document_id),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Updating an expired document is allowed, and it only takes effect if the
+  // new expiration timestamp is smaller than the current one, so the document
+  // remains expired.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result3,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/400));
+  EXPECT_THAT(update_result3.final_expiration_timestamp_ms, Eq(400));
+  EXPECT_THAT(update_result3.was_updated, IsTrue());
+  EXPECT_THAT(
+      doc_store->GetNonDeletedDocumentFilterData(document_id),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/400,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+}
+
+TEST_P(DocumentStoreTest,
+       UpdateDocumentExpirationTimestamp_shouldFailForDeletedDocument) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
 
-  int64_t fake_real_time = 100;
-  fake_clock_.SetSystemTimeMilliseconds(fake_real_time);
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::CreateResult create_result,
       CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
@@ -2767,17 +3330,240 @@ TEST_P(DocumentStoreTest, CreationTimestampShouldBePopulated) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult put_result,
-      doc_store->Put(document_without_creation_timestamp));
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentProto document_with_creation_timestamp,
-                             doc_store->Get(document_id));
+  // Delete the document.
+  ICING_ASSERT_OK(doc_store->Delete(
+      document_id,
+      /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()));
+
+  EXPECT_THAT(doc_store->UpdateDocumentExpirationTimestamp(
+                  document_id, /*expiration_timestamp_ms=*/500),
+              StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
+}
+
+TEST_P(DocumentStoreTest,
+       UpdateDocumentExpirationTimestamp_canUpdateToAnExpiredTimestamp) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("namespace1", "1")
+                               .SetSchema("email")
+                               .SetCreationTimestampMs(100)
+                               .SetTtlMs(1000)
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
+  EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result.was_replacement());
+  DocumentId document_id = put_result.new_document_id;
+
+  // Adjust the current time to 500. The document is still alive.
+  fake_clock_.SetSystemTimeMilliseconds(500);
+  ASSERT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/1100,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+
+  // Set the expiration timestamp to 400. It is allowed to set the expiration
+  // timestamp to a smaller value than the current timestamp, and the document
+  // will be treated as expired.
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::UpdateDocumentExpirationTimestampResult update_result,
+      doc_store->UpdateDocumentExpirationTimestamp(
+          document_id, /*expiration_timestamp_ms=*/400));
+  EXPECT_THAT(update_result.final_expiration_timestamp_ms, Eq(400));
+  EXPECT_THAT(update_result.was_updated, IsTrue());
+  EXPECT_THAT(doc_store->IsDocumentAlive(
+                  document_id,
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsFalse());
+}
+
+TEST_P(DocumentStoreTest, ResetAllAliveExpirationTimestampsToRaw) {
+  DocumentProto document1 = DocumentBuilder()
+                                .SetKey("namespace1", "1")
+                                .SetSchema("email")
+                                .SetCreationTimestampMs(100)
+                                .SetTtlMs(1000)
+                                .Build();
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("namespace1", "2")
+          .SetSchema("email")
+          .SetCreationTimestampMs(300)
+          .SetTtlMs(0)  // No TTL. The expiration timestamp will be INT64_MAX.
+          .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
+  EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result1.was_replacement());
+  DocumentId document_id1 = put_result1.new_document_id;
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
+  EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result2.was_replacement());
+  DocumentId document_id2 = put_result2.new_document_id;
+
+  // Update the expiration timestamp of document1 and document2.
+  ICING_ASSERT_OK(doc_store->UpdateDocumentExpirationTimestamp(
+      document_id1, /*expiration_timestamp_ms=*/500));
+  ICING_ASSERT_OK(doc_store->UpdateDocumentExpirationTimestamp(
+      document_id2, /*expiration_timestamp_ms=*/3000));
+  // Sanity check.
+  ASSERT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id1, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+  ASSERT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id2, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/3000,
+                                     /*raw_expiration_timestamp_ms=*/
+                                     std::numeric_limits<int64_t>::max()))));
+
+  // Reset.
+  EXPECT_THAT(doc_store->ResetAllAliveExpirationTimestampsToRaw(
+                  /*current_time_ms=*/fake_clock_.GetSystemTimeMilliseconds()),
+              IsOk());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id1, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/1100,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id2, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(
+          /*namespace_id=*/0, /*schema_type_id=*/0,
+          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max(),
+          /*raw_expiration_timestamp_ms=*/
+          std::numeric_limits<int64_t>::max()))));
+}
+
+TEST_P(DocumentStoreTest,
+       ResetAllAliveExpirationTimestampsToRaw_shouldSkipExpiredDocuments) {
+  DocumentProto document1 = DocumentBuilder()
+                                .SetKey("namespace1", "1")
+                                .SetSchema("email")
+                                .SetCreationTimestampMs(100)
+                                .SetTtlMs(1000)
+                                .Build();
+  DocumentProto document2 =
+      DocumentBuilder()
+          .SetKey("namespace1", "2")
+          .SetSchema("email")
+          .SetCreationTimestampMs(300)
+          .SetTtlMs(0)  // No TTL. The expiration timestamp will be INT64_MAX.
+          .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> doc_store =
+      std::move(create_result.document_store);
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
+  EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result1.was_replacement());
+  DocumentId document_id1 = put_result1.new_document_id;
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
+  EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
+  EXPECT_FALSE(put_result2.was_replacement());
+  DocumentId document_id2 = put_result2.new_document_id;
 
-  // Now the creation timestamp should be set by document store.
-  EXPECT_THAT(document_with_creation_timestamp.creation_timestamp_ms(),
-              Eq(fake_real_time));
+  // Update the expiration timestamp of document1 and document2.
+  ICING_ASSERT_OK(doc_store->UpdateDocumentExpirationTimestamp(
+      document_id1, /*expiration_timestamp_ms=*/500));
+  ICING_ASSERT_OK(doc_store->UpdateDocumentExpirationTimestamp(
+      document_id2, /*expiration_timestamp_ms=*/3000));
+  // Sanity check.
+  ASSERT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id1, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+  ASSERT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id2, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/3000,
+                                     /*raw_expiration_timestamp_ms=*/
+                                     std::numeric_limits<int64_t>::max()))));
+
+  // Reset with current timestamp 500. Document1 should be skipped since it is
+  // expired (at t = 500).
+  EXPECT_THAT(doc_store->ResetAllAliveExpirationTimestampsToRaw(
+                  /*current_time_ms=*/500),
+              IsOk());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id1, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id2, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(
+          /*namespace_id=*/0, /*schema_type_id=*/0,
+          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max(),
+          /*raw_expiration_timestamp_ms=*/
+          std::numeric_limits<int64_t>::max()))));
+
+  // Reset with current timestamp 700. Document1 should be skipped since it is
+  // expired (at t = 500).
+  EXPECT_THAT(doc_store->ResetAllAliveExpirationTimestampsToRaw(
+                  /*current_time_ms=*/700),
+              IsOk());
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id1, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(/*namespace_id=*/0, /*schema_type_id=*/0,
+                                     /*expiration_timestamp_ms=*/500,
+                                     /*raw_expiration_timestamp_ms=*/1100))));
+  EXPECT_THAT(
+      doc_store->GetAliveDocumentFilterData(
+          document_id2, fake_clock_.GetSystemTimeMilliseconds()),
+      Optional(Eq(DocumentFilterData(
+          /*namespace_id=*/0, /*schema_type_id=*/0,
+          /*expiration_timestamp_ms=*/std::numeric_limits<int64_t>::max(),
+          /*raw_expiration_timestamp_ms=*/
+          std::numeric_limits<int64_t>::max()))));
 }
 
 TEST_P(DocumentStoreTest, ShouldWriteAndReadScoresCorrectly) {
@@ -2801,13 +3587,15 @@ TEST_P(DocumentStoreTest, ShouldWriteAndReadScoresCorrectly) {
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -2835,7 +3623,8 @@ TEST_P(DocumentStoreTest, GetChecksumDoesntUpdateStoredChecksum) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   // GetChecksum should succeed without updating the checksum.
   ICING_EXPECT_OK(document_store->GetChecksum());
 
@@ -2854,7 +3643,8 @@ TEST_P(DocumentStoreTest, UpdateChecksumNextInitializationSucceeds) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, document_store->GetChecksum());
   EXPECT_THAT(document_store->UpdateChecksum(), IsOkAndHolds(checksum));
   EXPECT_THAT(document_store->GetChecksum(), IsOkAndHolds(checksum));
@@ -2880,7 +3670,8 @@ TEST_P(DocumentStoreTest, UpdateChecksumSameBetweenCalls) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   // GetChecksum should return the same value as UpdateChecksum
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, document_store->GetChecksum());
   EXPECT_THAT(document_store->UpdateChecksum(), IsOkAndHolds(checksum));
@@ -2898,12 +3689,14 @@ TEST_P(DocumentStoreTest, UpdateChecksumChangesOnNewDocument) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, document_store->GetChecksum());
   EXPECT_THAT(document_store->UpdateChecksum(), IsOkAndHolds(checksum));
   EXPECT_THAT(document_store->GetChecksum(), IsOkAndHolds(checksum));
 
-  ICING_EXPECT_OK(document_store->Put(test_document2_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document2_)));
   EXPECT_THAT(document_store->GetChecksum(), IsOkAndHolds(Not(Eq(checksum))));
   EXPECT_THAT(document_store->UpdateChecksum(),
               IsOkAndHolds(Not(Eq(checksum))));
@@ -2917,7 +3710,8 @@ TEST_P(DocumentStoreTest, UpdateChecksumDoesntChangeOnNewUsage) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_EXPECT_OK(document_store->Put(test_document1_));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
   ICING_ASSERT_OK_AND_ASSIGN(Crc32 checksum, document_store->GetChecksum());
   EXPECT_THAT(document_store->UpdateChecksum(), IsOkAndHolds(checksum));
   EXPECT_THAT(document_store->GetChecksum(), IsOkAndHolds(checksum));
@@ -2983,7 +3777,8 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
     // Insert and verify a "email "document
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::PutResult email_put_result,
-        document_store->Put(DocumentProto(email_document)));
+        document_store->Put(
+            document_util::CreateDocumentWrapper(email_document)));
     EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(email_put_result.was_replacement());
     email_document_id = email_put_result.new_document_id;
@@ -2993,8 +3788,6 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
         DocumentFilterData email_data,
         document_store->GetAliveDocumentFilterData(
             email_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-    EXPECT_THAT(email_data.uri_fingerprint(),
-                Eq(tc3farmhash::Fingerprint64(email_document.uri())));
     EXPECT_THAT(email_data.schema_type_id(), Eq(email_schema_type_id));
     email_namespace_id = email_data.namespace_id();
     email_expiration_timestamp = email_data.expiration_timestamp_ms();
@@ -3002,7 +3795,8 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
     // Insert and verify a "message" document
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::PutResult message_put_result,
-        document_store->Put(DocumentProto(message_document)));
+        document_store->Put(
+            document_util::CreateDocumentWrapper(message_document)));
     EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(message_put_result.was_replacement());
     message_document_id = message_put_result.new_document_id;
@@ -3012,8 +3806,6 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
         DocumentFilterData message_data,
         document_store->GetAliveDocumentFilterData(
             message_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-    EXPECT_THAT(message_data.uri_fingerprint(),
-                Eq(tc3farmhash::Fingerprint64(message_document.uri())));
     EXPECT_THAT(message_data.schema_type_id(), Eq(message_schema_type_id));
     message_namespace_id = message_data.namespace_id();
     message_expiration_timestamp = message_data.expiration_timestamp_ms();
@@ -3058,12 +3850,12 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
       document_store->GetAliveDocumentFilterData(
           email_document_id, fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(email_data.schema_type_id(), Eq(email_schema_type_id));
-  // Make sure that all the other fields are stll valid/the same
+  // Make sure that all the other fields are still valid/the same
   EXPECT_THAT(email_data.namespace_id(), Eq(email_namespace_id));
-  EXPECT_THAT(email_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(email_document.uri())));
   EXPECT_THAT(email_data.expiration_timestamp_ms(),
               Eq(email_expiration_timestamp));
+  EXPECT_THAT(email_data.raw_expiration_timestamp_ms(),
+              Eq(email_expiration_timestamp));
 
   // "message" document has an invalid SchemaTypeId
   EXPECT_THAT(document_store->Get(message_document_id),
@@ -3073,12 +3865,12 @@ TEST_P(DocumentStoreTest, RegenerateDerivedFilesSkipsUnknownSchemaTypeIds) {
       document_store->GetAliveDocumentFilterData(
           message_document_id, fake_clock_.GetSystemTimeMilliseconds()));
   EXPECT_THAT(message_data.schema_type_id(), Eq(-1));
-  // Make sure that all the other fields are stll valid/the same
+  // Make sure that all the other fields are still valid/the same
   EXPECT_THAT(message_data.namespace_id(), Eq(message_namespace_id));
-  EXPECT_THAT(message_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.expiration_timestamp_ms(),
               Eq(message_expiration_timestamp));
+  EXPECT_THAT(message_data.raw_expiration_timestamp_ms(),
+              Eq(message_expiration_timestamp));
 }
 
 TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
@@ -3127,7 +3919,8 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_put_result,
-      document_store->Put(DocumentProto(email_document)));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_document)));
   EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_put_result.was_replacement());
   DocumentId email_document_id = email_put_result.new_document_id;
@@ -3135,13 +3928,12 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
       DocumentFilterData email_data,
       document_store->GetAliveDocumentFilterData(
           email_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(email_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(email_document.uri())));
   EXPECT_THAT(email_data.schema_type_id(), Eq(old_email_schema_type_id));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult message_put_result,
-      document_store->Put(DocumentProto(message_document)));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(message_document)));
   EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(message_put_result.was_replacement());
   DocumentId message_document_id = message_put_result.new_document_id;
@@ -3149,8 +3941,6 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
       DocumentFilterData message_data,
       document_store->GetAliveDocumentFilterData(
           message_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(message_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.schema_type_id(), Eq(old_message_schema_type_id));
 
   // Add a new schema type. Since SchemaTypeId is assigned based on order,
@@ -3180,16 +3970,12 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreUpdatesSchemaTypeIds) {
       email_data,
       document_store->GetAliveDocumentFilterData(
           email_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(email_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(email_document.uri())));
   EXPECT_THAT(email_data.schema_type_id(), Eq(new_email_schema_type_id));
 
   ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
       message_data,
       document_store->GetAliveDocumentFilterData(
           message_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(message_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.schema_type_id(), Eq(new_message_schema_type_id));
 }
 
@@ -3241,7 +4027,8 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreDeletesInvalidDocuments) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_without_subject_put_result,
-      document_store->Put(DocumentProto(email_without_subject)));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_without_subject)));
   EXPECT_THAT(email_without_subject_put_result.old_document_id,
               Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_without_subject_put_result.was_replacement());
@@ -3252,7 +4039,8 @@ TEST_P(DocumentStoreTest, UpdateSchemaStoreDeletesInvalidDocuments) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_with_subject_put_result,
-      document_store->Put(DocumentProto(email_with_subject)));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_with_subject)));
   EXPECT_THAT(email_with_subject_put_result.old_document_id,
               Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_with_subject_put_result.was_replacement());
@@ -3323,16 +4111,20 @@ TEST_P(DocumentStoreTest,
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result,
-                             document_store->Put(email_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult email_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_document)));
   EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_put_result.was_replacement());
   DocumentId email_document_id = email_put_result.new_document_id;
   EXPECT_THAT(document_store->Get(email_document_id),
               IsOkAndHolds(EqualsProto(email_document)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult message_put_result,
-                             document_store->Put(message_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult message_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(message_document)));
   EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(message_put_result.was_replacement());
   DocumentId message_document_id = message_put_result.new_document_id;
@@ -3403,8 +4195,10 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreUpdatesSchemaTypeIds) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result,
-                             document_store->Put(email_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult email_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_document)));
   EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_put_result.was_replacement());
   DocumentId email_document_id = email_put_result.new_document_id;
@@ -3412,12 +4206,12 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreUpdatesSchemaTypeIds) {
       DocumentFilterData email_data,
       document_store->GetAliveDocumentFilterData(
           email_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(email_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(email_document.uri())));
   EXPECT_THAT(email_data.schema_type_id(), Eq(old_email_schema_type_id));
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult message_put_result,
-                             document_store->Put(message_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult message_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(message_document)));
   EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(message_put_result.was_replacement());
   DocumentId message_document_id = message_put_result.new_document_id;
@@ -3425,8 +4219,6 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreUpdatesSchemaTypeIds) {
       DocumentFilterData message_data,
       document_store->GetAliveDocumentFilterData(
           message_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(message_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.schema_type_id(), Eq(old_message_schema_type_id));
 
   // Add a new schema type. Since SchemaTypeId is assigned based on order,
@@ -3451,24 +4243,22 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreUpdatesSchemaTypeIds) {
   EXPECT_NE(old_email_schema_type_id, new_email_schema_type_id);
   EXPECT_NE(old_message_schema_type_id, new_message_schema_type_id);
 
-  ICING_EXPECT_OK(document_store->OptimizedUpdateSchemaStore(
-      schema_store.get(), set_schema_result));
+  ICING_ASSERT_OK_AND_ASSIGN(int deleted_document_count,
+                             document_store->OptimizedUpdateSchemaStore(
+                                 schema_store.get(), set_schema_result));
+  EXPECT_THAT(deleted_document_count, Eq(0));
 
   // Check that the FilterCache holds the new SchemaTypeIds
   ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
       email_data,
       document_store->GetAliveDocumentFilterData(
           email_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(email_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(email_document.uri())));
   EXPECT_THAT(email_data.schema_type_id(), Eq(new_email_schema_type_id));
 
   ICING_ASSERT_HAS_VALUE_AND_ASSIGN(
       message_data,
       document_store->GetAliveDocumentFilterData(
           message_document_id, fake_clock_.GetSystemTimeMilliseconds()));
-  EXPECT_THAT(message_data.uri_fingerprint(),
-              Eq(tc3farmhash::Fingerprint64(message_document.uri())));
   EXPECT_THAT(message_data.schema_type_id(), Eq(new_message_schema_type_id));
 }
 
@@ -3520,7 +4310,8 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreDeletesInvalidDocuments) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_without_subject_put_result,
-      document_store->Put(email_without_subject));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_without_subject)));
   EXPECT_THAT(email_without_subject_put_result.old_document_id,
               Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_without_subject_put_result.was_replacement());
@@ -3531,7 +4322,8 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreDeletesInvalidDocuments) {
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentStore::PutResult email_with_subject_put_result,
-      document_store->Put(email_with_subject));
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_with_subject)));
   EXPECT_THAT(email_with_subject_put_result.old_document_id,
               Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_with_subject_put_result.was_replacement());
@@ -3550,8 +4342,10 @@ TEST_P(DocumentStoreTest, OptimizedUpdateSchemaStoreDeletesInvalidDocuments) {
       schema_store->SetSchema(schema,
                               /*ignore_errors_and_delete_documents=*/true));
 
-  ICING_EXPECT_OK(document_store->OptimizedUpdateSchemaStore(
-      schema_store.get(), set_schema_result));
+  ICING_ASSERT_OK_AND_ASSIGN(int deleted_document_count,
+                             document_store->OptimizedUpdateSchemaStore(
+                                 schema_store.get(), set_schema_result));
+  EXPECT_THAT(deleted_document_count, Eq(1));
 
   // The email without a subject should be marked as deleted
   EXPECT_THAT(document_store->Get(email_without_subject_document_id),
@@ -3605,16 +4399,20 @@ TEST_P(DocumentStoreTest,
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult email_put_result,
-                             document_store->Put(email_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult email_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(email_document)));
   EXPECT_THAT(email_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(email_put_result.was_replacement());
   DocumentId email_document_id = email_put_result.new_document_id;
   EXPECT_THAT(document_store->Get(email_document_id),
               IsOkAndHolds(EqualsProto(email_document)));
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult message_put_result,
-                             document_store->Put(message_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult message_put_result,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(message_document)));
   EXPECT_THAT(message_put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(message_put_result.was_replacement());
   DocumentId message_document_id = message_put_result.new_document_id;
@@ -3631,8 +4429,10 @@ TEST_P(DocumentStoreTest,
       schema_store->SetSchema(new_schema,
                               /*ignore_errors_and_delete_documents=*/true));
 
-  ICING_EXPECT_OK(document_store->OptimizedUpdateSchemaStore(
-      schema_store.get(), set_schema_result));
+  ICING_ASSERT_OK_AND_ASSIGN(int deleted_document_count,
+                             document_store->OptimizedUpdateSchemaStore(
+                                 schema_store.get(), set_schema_result));
+  EXPECT_THAT(deleted_document_count, Eq(1));
 
   // The "email" type is unknown now, so the "email" document should be deleted
   EXPECT_THAT(document_store->Get(email_document_id),
@@ -3658,7 +4458,8 @@ TEST_P(DocumentStoreTest, GetOptimizeInfo) {
   EXPECT_THAT(optimize_info.optimizable_docs, Eq(0));
   EXPECT_THAT(optimize_info.estimated_optimizable_bytes, Eq(0));
 
-  ICING_EXPECT_OK(document_store->Put(DocumentProto(test_document1_)));
+  ICING_EXPECT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(test_document1_)));
 
   // Adding a document, still nothing is optimizable
   ICING_ASSERT_OK_AND_ASSIGN(optimize_info, document_store->GetOptimizeInfo());
@@ -3733,10 +4534,14 @@ TEST_P(DocumentStoreTest, GetAllNamespaces) {
                                  .SetTtlMs(100)
                                  .Build();
 
-  ICING_ASSERT_OK(document_store->Put(namespace1));
-  ICING_ASSERT_OK(document_store->Put(namespace2_uri1));
-  ICING_ASSERT_OK(document_store->Put(namespace2_uri2));
-  ICING_ASSERT_OK(document_store->Put(namespace3));
+  ICING_ASSERT_OK(
+      document_store->Put(document_util::CreateDocumentWrapper(namespace1)));
+  ICING_ASSERT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(namespace2_uri1)));
+  ICING_ASSERT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(namespace2_uri2)));
+  ICING_ASSERT_OK(
+      document_store->Put(document_util::CreateDocumentWrapper(namespace3)));
 
   auto get_result = document_store->Get("namespace1", "uri");
   get_result = document_store->Get("namespace2", "uri1");
@@ -3777,8 +4582,10 @@ TEST_P(DocumentStoreTest, ReportUsageWithDifferentTimestampsAndGetUsageScores) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id = put_result1.new_document_id;
@@ -3872,8 +4679,10 @@ TEST_P(DocumentStoreTest, ReportUsageWithDifferentTypesAndGetUsageScores) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id = put_result1.new_document_id;
@@ -3928,8 +4737,10 @@ TEST_P(DocumentStoreTest, UsageScoresShouldNotBeClearedOnChecksumMismatch) {
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                               document_store->Put(test_document1_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result1,
+        document_store->Put(
+            document_util::CreateDocumentWrapper(test_document1_)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id = put_result1.new_document_id;
@@ -3976,8 +4787,10 @@ TEST_P(DocumentStoreTest, UsageScoresShouldBeAvailableAfterDataLoss) {
     std::unique_ptr<DocumentStore> document_store =
         std::move(create_result.document_store);
 
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                               document_store->Put(test_document1_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result1,
+        document_store->Put(
+            document_util::CreateDocumentWrapper(test_document1_)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id = put_result1.new_document_id;
@@ -4032,8 +4845,10 @@ TEST_P(DocumentStoreTest, UsageScoresShouldBeCopiedOverToUpdatedDocument) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id = put_result1.new_document_id;
@@ -4053,8 +4868,10 @@ TEST_P(DocumentStoreTest, UsageScoresShouldBeCopiedOverToUpdatedDocument) {
   EXPECT_THAT(actual_scores, Eq(expected_scores));
 
   // Update the document.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result2.old_document_id, Eq(document_id));
   EXPECT_TRUE(put_result2.was_replacement());
   DocumentId updated_document_id = put_result2.new_document_id;
@@ -4077,13 +4894,17 @@ TEST_P(DocumentStoreTest, UsageScoresShouldPersistOnOptimize) {
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store->Put(test_document2_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document2_)));
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result2.was_replacement());
   DocumentId document_id2 = put_result2.new_document_id;
@@ -4136,8 +4957,10 @@ TEST_P(DocumentStoreTest, DeletedDocumentsShouldNotBeReplacements) {
       std::move(create_result.document_store);
 
   // Add the document.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id = put_result1.new_document_id;
@@ -4147,8 +4970,10 @@ TEST_P(DocumentStoreTest, DeletedDocumentsShouldNotBeReplacements) {
       document_id, fake_clock_.GetSystemTimeMilliseconds()));
 
   // Re-add the document.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
 
   // Because the document was deleted, it should not be a replacement.
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
@@ -4168,8 +4993,9 @@ TEST_P(DocumentStoreTest, ExpiredDocumentsShouldNotBeReplacements) {
   // Add the document.
   DocumentProto doc1 = test_document1_;
   doc1.set_ttl_ms(1);
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             document_store->Put(doc1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      document_store->Put(document_util::CreateDocumentWrapper(doc1)));
   EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result1.was_replacement());
   DocumentId document_id = put_result1.new_document_id;
@@ -4179,8 +5005,10 @@ TEST_P(DocumentStoreTest, ExpiredDocumentsShouldNotBeReplacements) {
       fake_clock_.GetSystemTimeMilliseconds() + 2);
 
   // Re-add the document.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             document_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      document_store->Put(
+          document_util::CreateDocumentWrapper(test_document1_)));
 
   // Because the document was expired, it should not be a replacement.
   EXPECT_THAT(put_result2.old_document_id, Eq(kInvalidDocumentId));
@@ -4201,8 +5029,9 @@ TEST_P(DocumentStoreTest, DetectPartialDataLoss) {
     EXPECT_THAT(create_result.data_loss, Eq(DataLoss::NONE));
     EXPECT_THAT(create_result.derived_files_regenerated, IsFalse());
 
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                               doc_store->Put(test_document1_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
     EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result.was_replacement());
     DocumentId document_id = put_result.new_document_id;
@@ -4257,8 +5086,9 @@ TEST_P(DocumentStoreTest, DetectCompleteDataLoss) {
     // initialization.
     corruptible_offset = filesystem_.GetFileSize(document_log_file.c_str());
 
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                               doc_store->Put(test_document1_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
     EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result.was_replacement());
     DocumentId document_id = put_result.new_document_id;
@@ -4350,7 +5180,9 @@ TEST_P(DocumentStoreTest, LoadScoreCacheAndInitializeSuccessfully) {
           /*force_recovery_and_revalidate_documents=*/false,
           GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
           PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
-          &initialize_stats));
+          PortableFileBackedProtoLog<
+              DocumentWrapper>::kDefaultCompressionThresholdBytes,
+          protobuf_ports::kDefaultMemLevel, &initialize_stats));
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
   // The document log is using the legacy v0 format so that a migration is
@@ -4375,24 +5207,28 @@ TEST_P(DocumentStoreTest, DocumentStoreStorageInfo) {
   DocumentProto document1 = test_document1_;
   document1.set_namespace_("namespace.1");
   document1.set_uri("uri1");
-  ICING_ASSERT_OK(doc_store->Put(document1));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
 
   DocumentProto document2 = test_document1_;
   document2.set_namespace_("namespace.1");
   document2.set_uri("uri2");
   document2.set_creation_timestamp_ms(fake_clock_.GetSystemTimeMilliseconds());
   document2.set_ttl_ms(100);
-  ICING_ASSERT_OK(doc_store->Put(document2));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
 
   DocumentProto document3 = test_document1_;
   document3.set_namespace_("namespace.1");
   document3.set_uri("uri3");
-  ICING_ASSERT_OK(doc_store->Put(document3));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document3)));
 
   DocumentProto document4 = test_document1_;
   document4.set_namespace_("namespace.2");
   document4.set_uri("uri1");
-  ICING_ASSERT_OK(doc_store->Put(document4));
+  ICING_ASSERT_OK(
+      doc_store->Put(document_util::CreateDocumentWrapper(document4)));
 
   // Report usage with type 1 on document1
   UsageReport usage_report_type1 = CreateUsageReport(
@@ -4524,8 +5360,9 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryUpdatesTypeIds) {
                 document1_creation_timestamp_)  // A random timestamp
             .SetTtlMs(document1_ttl_)
             .Build();
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                               doc_store->Put(doc));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(doc)));
     EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result.was_replacement());
     docid = put_result.new_document_id;
@@ -4534,8 +5371,6 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryUpdatesTypeIds) {
         doc_store->GetAliveDocumentFilterData(
             docid, fake_clock_.GetSystemTimeMilliseconds()));
 
-    ASSERT_THAT(filter_data.uri_fingerprint(),
-                Eq(tc3farmhash::Fingerprint64(doc.uri())));
     ASSERT_THAT(filter_data.schema_type_id(), Eq(0));
   }
 
@@ -4568,14 +5403,16 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryUpdatesTypeIds) {
     InitializeStatsProto initialize_stats;
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/true,
-                              GetParam().pre_mapping_fbv,
-                              GetParam().use_persistent_hash_map,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              &initialize_stats));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_, schema_store.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/true,
+            GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel, &initialize_stats));
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
@@ -4584,8 +5421,6 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryUpdatesTypeIds) {
         DocumentFilterData filter_data,
         doc_store->GetAliveDocumentFilterData(
             docid, fake_clock_.GetSystemTimeMilliseconds()));
-    EXPECT_THAT(filter_data.uri_fingerprint(),
-                Eq(tc3farmhash::Fingerprint64(std::string("email/1"))));
     EXPECT_THAT(filter_data.schema_type_id(), Eq(1));
     EXPECT_THAT(initialize_stats.document_store_recovery_cause(),
                 Eq(InitializeStatsProto::SCHEMA_CHANGES_OUT_OF_SYNC));
@@ -4643,8 +5478,9 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryDoesntUpdateTypeIds) {
                 document1_creation_timestamp_)  // A random timestamp
             .SetTtlMs(document1_ttl_)
             .Build();
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                               doc_store->Put(doc));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(doc)));
     EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result.was_replacement());
     docid = put_result.new_document_id;
@@ -4653,8 +5489,6 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryDoesntUpdateTypeIds) {
         doc_store->GetAliveDocumentFilterData(
             docid, fake_clock_.GetSystemTimeMilliseconds()));
 
-    EXPECT_THAT(filter_data.uri_fingerprint(),
-                Eq(tc3farmhash::Fingerprint64(doc.uri())));
     ASSERT_THAT(filter_data.schema_type_id(), Eq(0));
   }
 
@@ -4696,8 +5530,6 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryDoesntUpdateTypeIds) {
         DocumentFilterData filter_data,
         doc_store->GetAliveDocumentFilterData(
             docid, fake_clock_.GetSystemTimeMilliseconds()));
-    EXPECT_THAT(filter_data.uri_fingerprint(),
-                Eq(tc3farmhash::Fingerprint64(std::string("email/1"))));
     ASSERT_THAT(filter_data.schema_type_id(), Eq(0));
   }
 }
@@ -4730,7 +5562,7 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryDeletesInvalidDocument) {
                   schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
-  DocumentProto docWithBody =
+  DocumentProto doc_with_body =
       DocumentBuilder()
           .SetKey("icing", "email/1")
           .SetSchema("email")
@@ -4741,7 +5573,7 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryDeletesInvalidDocument) {
               document1_creation_timestamp_)  // A random timestamp
           .SetTtlMs(document1_ttl_)
           .Build();
-  DocumentProto docWithoutBody =
+  DocumentProto doc_without_body =
       DocumentBuilder()
           .SetKey("icing", "email/2")
           .SetSchema("email")
@@ -4763,26 +5595,28 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryDeletesInvalidDocument) {
         std::move(create_result.document_store);
 
     DocumentId docid = kInvalidDocumentId;
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_with_body_result,
-                               doc_store->Put(docWithBody));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_with_body_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(doc_with_body)));
     EXPECT_THAT(put_with_body_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_with_body_result.was_replacement());
     docid = put_with_body_result.new_document_id;
     ASSERT_NE(docid, kInvalidDocumentId);
     docid = kInvalidDocumentId;
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_without_body_result,
-                               doc_store->Put(docWithoutBody));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_without_body_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(doc_without_body)));
     EXPECT_THAT(put_without_body_result.old_document_id,
                 Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_without_body_result.was_replacement());
     docid = put_without_body_result.new_document_id;
     ASSERT_NE(docid, kInvalidDocumentId);
 
-    ASSERT_THAT(doc_store->Get(docWithBody.namespace_(), docWithBody.uri()),
-                IsOkAndHolds(EqualsProto(docWithBody)));
+    ASSERT_THAT(doc_store->Get(doc_with_body.namespace_(), doc_with_body.uri()),
+                IsOkAndHolds(EqualsProto(doc_with_body)));
     ASSERT_THAT(
-        doc_store->Get(docWithoutBody.namespace_(), docWithoutBody.uri()),
-        IsOkAndHolds(EqualsProto(docWithoutBody)));
+        doc_store->Get(doc_without_body.namespace_(), doc_without_body.uri()),
+        IsOkAndHolds(EqualsProto(doc_without_body)));
   }
 
   // Delete the 'body' property from the 'email' type, making all pre-existing
@@ -4805,22 +5639,25 @@ TEST_P(DocumentStoreTest, InitializeForceRecoveryDeletesInvalidDocument) {
     CorruptDocStoreHeaderChecksumFile();
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/true,
-                              GetParam().pre_mapping_fbv,
-                              GetParam().use_persistent_hash_map,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_, schema_store.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/true,
+            GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ASSERT_THAT(doc_store->Get(docWithBody.namespace_(), docWithBody.uri()),
+    ASSERT_THAT(doc_store->Get(doc_with_body.namespace_(), doc_with_body.uri()),
                 StatusIs(libtextclassifier3::StatusCode::NOT_FOUND));
     ASSERT_THAT(
-        doc_store->Get(docWithoutBody.namespace_(), docWithoutBody.uri()),
-        IsOkAndHolds(EqualsProto(docWithoutBody)));
+        doc_store->Get(doc_without_body.namespace_(), doc_without_body.uri()),
+        IsOkAndHolds(EqualsProto(doc_without_body)));
   }
 }
 
@@ -4852,7 +5689,7 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryKeepsInvalidDocument) {
                   schema, /*ignore_errors_and_delete_documents=*/false),
               IsOk());
 
-  DocumentProto docWithBody =
+  DocumentProto doc_with_body =
       DocumentBuilder()
           .SetKey("icing", "email/1")
           .SetSchema("email")
@@ -4863,7 +5700,7 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryKeepsInvalidDocument) {
               document1_creation_timestamp_)  // A random timestamp
           .SetTtlMs(document1_ttl_)
           .Build();
-  DocumentProto docWithoutBody =
+  DocumentProto doc_without_body =
       DocumentBuilder()
           .SetKey("icing", "email/2")
           .SetSchema("email")
@@ -4885,26 +5722,28 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryKeepsInvalidDocument) {
         std::move(create_result.document_store);
 
     DocumentId docid = kInvalidDocumentId;
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_with_body_result,
-                               doc_store->Put(docWithBody));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_with_body_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(doc_with_body)));
     EXPECT_THAT(put_with_body_result.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_with_body_result.was_replacement());
     docid = put_with_body_result.new_document_id;
     ASSERT_NE(docid, kInvalidDocumentId);
     docid = kInvalidDocumentId;
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_without_body_result,
-                               doc_store->Put(docWithoutBody));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_without_body_result,
+        doc_store->Put(document_util::CreateDocumentWrapper(doc_without_body)));
     EXPECT_THAT(put_without_body_result.old_document_id,
                 Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_without_body_result.was_replacement());
     docid = put_without_body_result.new_document_id;
     ASSERT_NE(docid, kInvalidDocumentId);
 
-    ASSERT_THAT(doc_store->Get(docWithBody.namespace_(), docWithBody.uri()),
-                IsOkAndHolds(EqualsProto(docWithBody)));
+    ASSERT_THAT(doc_store->Get(doc_with_body.namespace_(), doc_with_body.uri()),
+                IsOkAndHolds(EqualsProto(doc_with_body)));
     ASSERT_THAT(
-        doc_store->Get(docWithoutBody.namespace_(), docWithoutBody.uri()),
-        IsOkAndHolds(EqualsProto(docWithoutBody)));
+        doc_store->Get(doc_without_body.namespace_(), doc_without_body.uri()),
+        IsOkAndHolds(EqualsProto(doc_without_body)));
   }
 
   // Delete the 'body' property from the 'email' type, making all pre-existing
@@ -4933,11 +5772,11 @@ TEST_P(DocumentStoreTest, InitializeDontForceRecoveryKeepsInvalidDocument) {
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
 
-    ASSERT_THAT(doc_store->Get(docWithBody.namespace_(), docWithBody.uri()),
-                IsOkAndHolds(EqualsProto(docWithBody)));
+    ASSERT_THAT(doc_store->Get(doc_with_body.namespace_(), doc_with_body.uri()),
+                IsOkAndHolds(EqualsProto(doc_with_body)));
     ASSERT_THAT(
-        doc_store->Get(docWithoutBody.namespace_(), docWithoutBody.uri()),
-        IsOkAndHolds(EqualsProto(docWithoutBody)));
+        doc_store->Get(doc_without_body.namespace_(), doc_without_body.uri()),
+        IsOkAndHolds(EqualsProto(doc_without_body)));
   }
 }
 
@@ -5012,7 +5851,9 @@ TEST_P(DocumentStoreTest, MigrateToPortableFileBackedProtoLog) {
           /*force_recovery_and_revalidate_documents=*/false,
           GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
           PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
-          &initialize_stats));
+          PortableFileBackedProtoLog<
+              DocumentWrapper>::kDefaultCompressionThresholdBytes,
+          protobuf_ports::kDefaultMemLevel, &initialize_stats));
   std::unique_ptr<DocumentStore> document_store =
       std::move(create_result.document_store);
 
@@ -5116,7 +5957,8 @@ TEST_P(DocumentStoreTest, GetDebugInfo) {
                                 .AddStringProperty("body", "dd ee")
                                 .SetCreationTimestampMs(1)
                                 .Build();
-  ICING_ASSERT_OK(document_store->Put(document1, 5));
+  ICING_ASSERT_OK(document_store->Put(
+      CreateDocumentWrapper(document1, /*num_string_tokens=*/5)));
 
   DocumentProto document2 = DocumentBuilder()
                                 .SetKey("namespace2", "email/2")
@@ -5125,7 +5967,8 @@ TEST_P(DocumentStoreTest, GetDebugInfo) {
                                 .AddStringProperty("body", "cc")
                                 .SetCreationTimestampMs(1)
                                 .Build();
-  ICING_ASSERT_OK(document_store->Put(document2, 3));
+  ICING_ASSERT_OK(document_store->Put(
+      CreateDocumentWrapper(document2, /*num_string_tokens=*/3)));
 
   DocumentProto document3 = DocumentBuilder()
                                 .SetKey("namespace2", "email/3")
@@ -5134,7 +5977,8 @@ TEST_P(DocumentStoreTest, GetDebugInfo) {
                                 .AddStringProperty("body", "")
                                 .SetCreationTimestampMs(1)
                                 .Build();
-  ICING_ASSERT_OK(document_store->Put(document3, 1));
+  ICING_ASSERT_OK(document_store->Put(
+      CreateDocumentWrapper(document3, /*num_string_tokens=*/1)));
 
   DocumentProto document4 = DocumentBuilder()
                                 .SetKey("namespace1", "person/1")
@@ -5142,7 +5986,8 @@ TEST_P(DocumentStoreTest, GetDebugInfo) {
                                 .AddStringProperty("name", "test test")
                                 .SetCreationTimestampMs(1)
                                 .Build();
-  ICING_ASSERT_OK(document_store->Put(document4, 2));
+  ICING_ASSERT_OK(document_store->Put(
+      CreateDocumentWrapper(document4, /*num_string_tokens=*/2)));
 
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentDebugInfoProto out1,
@@ -5246,19 +6091,23 @@ TEST_P(DocumentStoreTest, SwitchKeyMapperTypeShouldRegenerateDerivedFiles) {
   {
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              GetParam().pre_mapping_fbv,
-                              GetParam().use_persistent_hash_map,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
 
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                               doc_store->Put(test_document1_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result1,
+        doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id1 = put_result1.new_document_id;
@@ -5295,7 +6144,9 @@ TEST_P(DocumentStoreTest, SwitchKeyMapperTypeShouldRegenerateDerivedFiles) {
             /*use_persistent_hash_map=*/switch_key_mapper_flag,
             PortableFileBackedProtoLog<
                 DocumentWrapper>::kDefaultCompressionLevel,
-            &initialize_stats));
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel, &initialize_stats));
     EXPECT_THAT(initialize_stats.document_store_recovery_cause(),
                 Eq(InitializeStatsProto::IO_ERROR));
 
@@ -5332,19 +6183,23 @@ TEST_P(DocumentStoreTest, SameKeyMapperTypeShouldNotRegenerateDerivedFiles) {
   {
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              GetParam().pre_mapping_fbv,
-                              GetParam().use_persistent_hash_map,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
 
     std::unique_ptr<DocumentStore> doc_store =
         std::move(create_result.document_store);
-    ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                               doc_store->Put(test_document1_));
+    ICING_ASSERT_OK_AND_ASSIGN(
+        DocumentStore::PutResult put_result1,
+        doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
     EXPECT_THAT(put_result1.old_document_id, Eq(kInvalidDocumentId));
     EXPECT_FALSE(put_result1.was_replacement());
     document_id1 = put_result1.new_document_id;
@@ -5371,14 +6226,16 @@ TEST_P(DocumentStoreTest, SameKeyMapperTypeShouldNotRegenerateDerivedFiles) {
     InitializeStatsProto initialize_stats;
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, document_store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              GetParam().pre_mapping_fbv,
-                              GetParam().use_persistent_hash_map,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              &initialize_stats));
+        DocumentStore::Create(
+            &filesystem_, document_store_dir_, &fake_clock_,
+            schema_store_.get(), feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel, &initialize_stats));
     EXPECT_THAT(initialize_stats.document_store_recovery_cause(),
                 Eq(InitializeStatsProto::NONE));
 
@@ -5415,6 +6272,9 @@ TEST_P(DocumentStoreTest, GetDocumentId_expiredDocument) {
           /*force_recovery_and_revalidate_documents=*/false,
           GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
           PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+          PortableFileBackedProtoLog<
+              DocumentWrapper>::kDefaultCompressionThresholdBytes,
+          protobuf_ports::kDefaultMemLevel,
           /*initialize_stats=*/nullptr));
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
@@ -5427,8 +6287,9 @@ TEST_P(DocumentStoreTest, GetDocumentId_expiredDocument) {
                                    .SetSchema("email")
                                    .SetCreationTimestampMs(0)
                                    .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(foo_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(foo_document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -5449,6 +6310,9 @@ TEST_P(DocumentStoreTest, GetDocumentId_deletedDocument) {
           /*force_recovery_and_revalidate_documents=*/false,
           GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
           PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+          PortableFileBackedProtoLog<
+              DocumentWrapper>::kDefaultCompressionThresholdBytes,
+          protobuf_ports::kDefaultMemLevel,
           /*initialize_stats=*/nullptr));
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
@@ -5458,8 +6322,9 @@ TEST_P(DocumentStoreTest, GetDocumentId_deletedDocument) {
                                    .SetSchema("email")
                                    .SetCreationTimestampMs(0)
                                    .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(foo_document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(foo_document)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -5482,12 +6347,16 @@ TEST_P(DocumentStoreTest, GetDocumentIdByNamespaceIdFingerprint) {
           /*force_recovery_and_revalidate_documents=*/false,
           GetParam().pre_mapping_fbv, GetParam().use_persistent_hash_map,
           PortableFileBackedProtoLog<DocumentWrapper>::kDefaultCompressionLevel,
+          PortableFileBackedProtoLog<
+              DocumentWrapper>::kDefaultCompressionThresholdBytes,
+          protobuf_ports::kDefaultMemLevel,
           /*initialize_stats=*/nullptr));
 
   std::unique_ptr<DocumentStore> doc_store =
       std::move(create_result.document_store);
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(test_document1_));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(test_document1_)));
   EXPECT_THAT(put_result.old_document_id, Eq(kInvalidDocumentId));
   EXPECT_FALSE(put_result.was_replacement());
   DocumentId document_id = put_result.new_document_id;
@@ -5540,8 +6409,9 @@ TEST_P(DocumentStoreTest, PutDocumentWithNoScorablePropertiesInSchema) {
                                .AddStringProperty("subject", "subject foo")
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentAssociatedScoreData score_data,
@@ -5566,8 +6436,9 @@ TEST_P(DocumentStoreTest, PutDocumentWithNoScorableProperties) {
                                .AddStringProperty("subject", "subject foo")
                                .Build();
 
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document)));
   DocumentId document_id = put_result.new_document_id;
   std::unique_ptr<ScorablePropertySet> scorable_property_set =
       doc_store->GetScorablePropertySet(
@@ -5642,11 +6513,13 @@ TEST_P(DocumentStoreTest, PutDocumentWithScorablePropertyThenRead) {
                                 .AddInt64Property("scoreInt64", 5)
                                 .SetCreationTimestampMs(0)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
 
   std::unique_ptr<ScorablePropertySet> scorable_property_set_doc1 =
@@ -5688,8 +6561,9 @@ TEST_P(DocumentStoreTest, PutDocumentWithScorablePropertyThenRead) {
                                 .Build();
   // Add document3 to the document store, it will result in document1 being
   // deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result3,
-                             doc_store->Put(document3));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result3,
+      doc_store->Put(document_util::CreateDocumentWrapper(document3)));
   DocumentId document_id3 = put_result3.new_document_id;
   std::unique_ptr<ScorablePropertySet> scorable_property_set_doc3 =
       doc_store->GetScorablePropertySet(
@@ -5717,8 +6591,9 @@ TEST_P(DocumentStoreTest, PutDocumentWithScorablePropertyThenRead) {
                                 .Build();
   // Add document4 to the document store, it will result in document3 being
   // deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result4,
-                             doc_store->Put(document4));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result4,
+      doc_store->Put(document_util::CreateDocumentWrapper(document4)));
   DocumentId document_id4 = put_result4.new_document_id;
   std::unique_ptr<ScorablePropertySet> scorable_property_set_doc4 =
       doc_store->GetScorablePropertySet(
@@ -5791,8 +6666,9 @@ TEST_P(DocumentStoreTest, ReadScorablePropertyAfterOptimization) {
                                 .AddDoubleProperty("scoreDouble", 1.5, 2.5)
                                 .SetCreationTimestampMs(0)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result1,
-                             doc_store->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result1,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result1.new_document_id;
 
   std::unique_ptr<ScorablePropertySet> scorable_property_set_doc1 =
@@ -5823,8 +6699,9 @@ TEST_P(DocumentStoreTest, ReadScorablePropertyAfterOptimization) {
 
   // Add document2 to the document store, it will result in document1 being
   // deleted.
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result2,
-                             doc_store->Put(document2));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result2,
+      doc_store->Put(document_util::CreateDocumentWrapper(document2)));
   DocumentId document_id2 = put_result2.new_document_id;
   std::unique_ptr<ScorablePropertySet> scorable_property_set_doc2 =
       doc_store->GetScorablePropertySet(
@@ -5903,8 +6780,9 @@ TEST_P(DocumentStoreTest,
                                 .SetCreationTimestampMs(1)
                                 .AddDoubleProperty("income", 10000, 20000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document0));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document0)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentAssociatedScoreData score_data,
@@ -5977,8 +6855,9 @@ TEST_P(DocumentStoreTest,
                                 .SetCreationTimestampMs(1)
                                 .AddDoubleProperty("income", 10000, 20000)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document0));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document0)));
   DocumentId document_id = put_result.new_document_id;
   ICING_ASSERT_OK_AND_ASSIGN(
       DocumentAssociatedScoreData score_data,
@@ -6062,10 +6941,13 @@ TEST_P(DocumentStoreTest,
                                 .SetCreationTimestampMs(1)
                                 .AddDoubleProperty("score", 10, 20)
                                 .Build();
-  ICING_ASSERT_OK_AND_ASSIGN(DocumentStore::PutResult put_result,
-                             doc_store->Put(document0));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::PutResult put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document0)));
   DocumentId document_id0 = put_result.new_document_id;
-  ICING_ASSERT_OK_AND_ASSIGN(put_result, doc_store->Put(document1));
+  ICING_ASSERT_OK_AND_ASSIGN(
+      put_result,
+      doc_store->Put(document_util::CreateDocumentWrapper(document1)));
   DocumentId document_id1 = put_result.new_document_id;
 
   // Update the schema by rearranging the schema types. Since SchemaTypeId is
@@ -6110,6 +6992,445 @@ TEST_P(DocumentStoreTest,
       Pointee(EqualsProto(BuildScorablePropertyProtoFromDouble({10, 20}))));
 }
 
+TEST_P(DocumentStoreTest, GetResultGroupingEntryId_getByFilterName) {
+  // Put 2 schema types into the schema store.
+  SchemaProto schema =
+      SchemaBuilder()
+          .AddType(SchemaTypeConfigBuilder().SetType("Email"))
+          .AddType(SchemaTypeConfigBuilder().SetType("Message"))
+          .Build();
+
+  std::string schema_store_dir = schema_store_dir_ + "_custom";
+  filesystem_.DeleteDirectoryRecursively(schema_store_dir.c_str());
+  filesystem_.CreateDirectoryRecursively(schema_store_dir.c_str());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
+                          feature_flags_.get()));
+
+  ICING_ASSERT_OK(schema_store->SetSchema(
+      std::move(schema), /*ignore_errors_and_delete_documents=*/false));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store.get()));
+  std::unique_ptr<DocumentStore> document_store =
+      std::move(create_result.document_store);
+
+  // Put 3 documents into the document store to create 3 different namespaces.
+  DocumentProto document0 = DocumentBuilder()
+                                .SetKey("namespace0", "uri/0")
+                                .SetSchema("Email")
+                                .Build();
+  DocumentProto document1 = DocumentBuilder()
+                                .SetKey("namespace1", "uri/1")
+                                .SetSchema("Message")
+                                .Build();
+  DocumentProto document2 = DocumentBuilder()
+                                .SetKey("namespace2", "uri/2")
+                                .SetSchema("Message")
+                                .Build();
+  ICING_ASSERT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(std::move(document0))));
+  ICING_ASSERT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(std::move(document1))));
+  ICING_ASSERT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(std::move(document2))));
+
+  ASSERT_THAT(document_store->GetNamespaceId("namespace0"), IsOkAndHolds(0));
+  ASSERT_THAT(document_store->GetNamespaceId("namespace1"), IsOkAndHolds(1));
+  ASSERT_THAT(document_store->GetNamespaceId("namespace2"), IsOkAndHolds(2));
+
+  ASSERT_THAT(schema_store->GetSchemaTypeId("Email"), IsOkAndHolds(0));
+  ASSERT_THAT(schema_store->GetSchemaTypeId("Message"), IsOkAndHolds(1));
+
+  // NONE should always return std::nullopt.
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NONE, "namespace0", "Email"),
+      IsFalse());
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NONE, "namespace1", "Email"),
+      IsFalse());
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NONE, "namespace2", "Email"),
+      IsFalse());
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NONE, "namespace0", "Message"),
+      IsFalse());
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NONE, "namespace1", "Message"),
+      IsFalse());
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NONE, "namespace2", "Message"),
+      IsFalse());
+
+  // SCHEMA_TYPE should return id based on the schema type and ignore the
+  // namespace.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace0",
+                  "Email"),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace1",
+                  "Email"),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace2",
+                  "Email"),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace0",
+                  "Message"),
+              Optional(Eq(1)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace1",
+                  "Message"),
+              Optional(Eq(1)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace2",
+                  "Message"),
+              Optional(Eq(1)));
+
+  // NAMESPACE should return id based on the namespace and ignore the schema
+  // type.
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace0", "Email"),
+      Optional(Eq(0)));
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace1", "Email"),
+      Optional(Eq(1)));
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace2", "Email"),
+      Optional(Eq(2)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace0",
+                  "Message"),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace1",
+                  "Message"),
+              Optional(Eq(1)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace2",
+                  "Message"),
+              Optional(Eq(2)));
+
+  // NAMESPACE_AND_SCHEMA_TYPE should return id based on both namespace and
+  // schema type.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace0", "Email"),
+              Optional(Eq(0x00000000)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace1", "Email"),
+              Optional(Eq(0x00010000)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace2", "Email"),
+              Optional(Eq(0x00020000)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace0", "Message"),
+              Optional(Eq(0x00000001)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace1", "Message"),
+              Optional(Eq(0x00010001)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace2", "Message"),
+              Optional(Eq(0x00020001)));
+}
+
+TEST_P(DocumentStoreTest, GetResultGroupingEntryId_getByNonExistingFilterName) {
+  // Put 1 schema type into the schema store.
+  SchemaProto schema = SchemaBuilder()
+                           .AddType(SchemaTypeConfigBuilder().SetType("Email"))
+                           .Build();
+
+  std::string schema_store_dir = schema_store_dir_ + "_custom";
+  filesystem_.DeleteDirectoryRecursively(schema_store_dir.c_str());
+  filesystem_.CreateDirectoryRecursively(schema_store_dir.c_str());
+  ICING_ASSERT_OK_AND_ASSIGN(
+      std::unique_ptr<SchemaStore> schema_store,
+      SchemaStore::Create(&filesystem_, schema_store_dir, &fake_clock_,
+                          feature_flags_.get()));
+
+  ICING_ASSERT_OK(schema_store->SetSchema(
+      std::move(schema), /*ignore_errors_and_delete_documents=*/false));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store.get()));
+  std::unique_ptr<DocumentStore> document_store =
+      std::move(create_result.document_store);
+
+  // Put 1 document into the document store to create 1 namespace.
+  DocumentProto document0 = DocumentBuilder()
+                                .SetKey("namespace0", "uri/0")
+                                .SetSchema("Email")
+                                .Build();
+  ICING_ASSERT_OK(document_store->Put(
+      document_util::CreateDocumentWrapper(std::move(document0))));
+
+  ASSERT_THAT(document_store->GetNamespaceId("namespace0"), IsOkAndHolds(0));
+  ASSERT_THAT(schema_store->GetSchemaTypeId("Email"), IsOkAndHolds(0));
+
+  // NONE should always return std::nullopt.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE,
+                  "nonExistingNamespace", "nonExistingSchemaType"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE,
+                  "nonExistingNamespace", "Email"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, "namespace0",
+                  "nonExistingSchemaType"),
+              IsFalse());
+
+  // SCHEMA_TYPE should return id based on the schema type and ignore the
+  // namespace. It is ok that the namespace does not exist.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE,
+                  "nonExistingNamespace", "nonExistingSchemaType"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE,
+                  "nonExistingNamespace", "Email"),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, "namespace0",
+                  "nonExistingSchemaType"),
+              IsFalse());
+
+  // NAMESPACE should return id based on the namespace and ignore the schema
+  // type. It is ok that the schema type does not exist.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  "nonExistingNamespace", "nonExistingSchemaType"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  "nonExistingNamespace", "Email"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE, "namespace0",
+                  "nonExistingSchemaType"),
+              Optional(Eq(0)));
+
+  // NAMESPACE_AND_SCHEMA_TYPE should return id based on both namespace and
+  // schema type. Both namespace and schema type must exist.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "nonExistingNamespace", "nonExistingSchemaType"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "nonExistingNamespace", "Email"),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  "namespace0", "nonExistingSchemaType"),
+              IsFalse());
+}
+
+TEST_P(DocumentStoreTest, GetResultGroupingEntryId_getByIds) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> document_store =
+      std::move(create_result.document_store);
+
+  // GetResultGroupingEntryId() by id only handles the encoding and won't check
+  // if the id exists (except kInvalidNamespaceId and kInvalidSchemaTypeId), so
+  // we don't need to set up schema types and namespaces here.
+
+  // NONE should always return std::nullopt.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, /*namespace_id=*/0,
+                  /*schema_type_id=*/0),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, /*namespace_id=*/0,
+                  /*schema_type_id=*/1),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, /*namespace_id=*/1,
+                  /*schema_type_id=*/0),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, /*namespace_id=*/1,
+                  /*schema_type_id=*/1),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE,
+                  /*namespace_id=*/std::numeric_limits<NamespaceId>::max(),
+                  /*schema_type_id=*/std::numeric_limits<SchemaTypeId>::max()),
+              IsFalse());
+
+  // SCHEMA_TYPE should return id based on the schema type id and ignore the
+  // namespace id.
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, /*namespace_id=*/0,
+          /*schema_type_id=*/0),
+      Optional(Eq(0)));
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, /*namespace_id=*/0,
+          /*schema_type_id=*/1),
+      Optional(Eq(1)));
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, /*namespace_id=*/1,
+          /*schema_type_id=*/0),
+      Optional(Eq(0)));
+  EXPECT_THAT(
+      document_store->GetResultGroupingEntryId(
+          ResultSpecProto_ResultGroupingType_SCHEMA_TYPE, /*namespace_id=*/1,
+          /*schema_type_id=*/1),
+      Optional(Eq(1)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE,
+                  /*namespace_id=*/std::numeric_limits<NamespaceId>::max(),
+                  /*schema_type_id=*/std::numeric_limits<SchemaTypeId>::max()),
+              Optional(Eq(std::numeric_limits<SchemaTypeId>::max())));
+
+  // NAMESPACE should return id based on the namespace id and ignore the schema
+  // type id.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  /*namespace_id=*/0, /*schema_type_id=*/0),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  /*namespace_id=*/0, /*schema_type_id=*/1),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  /*namespace_id=*/1, /*schema_type_id=*/0),
+              Optional(Eq(1)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  /*namespace_id=*/1, /*schema_type_id=*/1),
+              Optional(Eq(1)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  /*namespace_id=*/std::numeric_limits<NamespaceId>::max(),
+                  /*schema_type_id=*/std::numeric_limits<SchemaTypeId>::max()),
+              Optional(Eq(std::numeric_limits<NamespaceId>::max())));
+
+  // NAMESPACE_AND_SCHEMA_TYPE should return id based on both namespace and
+  // schema type ids.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  /*namespace_id=*/0, /*schema_type_id=*/0),
+              Optional(Eq(0x00000000)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  /*namespace_id=*/0, /*schema_type_id=*/1),
+              Optional(Eq(0x00000001)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  /*namespace_id=*/1, /*schema_type_id=*/0),
+              Optional(Eq(0x00010000)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  /*namespace_id=*/1, /*schema_type_id=*/1),
+              Optional(Eq(0x00010001)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  /*namespace_id=*/std::numeric_limits<NamespaceId>::max(),
+                  /*schema_type_id=*/std::numeric_limits<SchemaTypeId>::max()),
+              Optional(Eq(0x7fff7fff)));
+}
+
+TEST_P(DocumentStoreTest, GetResultGroupingEntryId_getByInvalidIds) {
+  ICING_ASSERT_OK_AND_ASSIGN(
+      DocumentStore::CreateResult create_result,
+      CreateDocumentStore(&filesystem_, document_store_dir_, &fake_clock_,
+                          schema_store_.get()));
+  std::unique_ptr<DocumentStore> document_store =
+      std::move(create_result.document_store);
+
+  // GetResultGroupingEntryId() by id only handles the encoding and won't check
+  // if the id exists (except kInvalidNamespaceId and kInvalidSchemaTypeId), so
+  // we don't need to set up schema types and namespaces here.
+
+  // NONE should always return std::nullopt.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, kInvalidNamespaceId,
+                  kInvalidSchemaTypeId),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, kInvalidNamespaceId,
+                  /*schema_type_id=*/0),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NONE, /*namespace_id=*/0,
+                  kInvalidSchemaTypeId),
+              IsFalse());
+
+  // SCHEMA_TYPE should return id based on the schema type id and ignore the
+  // namespace id. It is ok that the namespace id is invalid.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE,
+                  kInvalidNamespaceId, kInvalidSchemaTypeId),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE,
+                  kInvalidNamespaceId, /*schema_type_id=*/0),
+              Optional(Eq(0)));
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_SCHEMA_TYPE,
+                  /*namespace_id=*/0, kInvalidSchemaTypeId),
+              IsFalse());
+
+  // NAMESPACE should return id based on the namespace id and ignore the schema
+  // type id. It is ok that the schema type id is invalid.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  kInvalidNamespaceId, kInvalidSchemaTypeId),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  kInvalidNamespaceId, /*schema_type_id=*/0),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE,
+                  /*namespace_id=*/0, kInvalidSchemaTypeId),
+              Optional(Eq(0)));
+  // NAMESPACE_AND_SCHEMA_TYPE should return id based on both namespace and
+  // schema type ids. Both namespace and schema type ids must be valid.
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  kInvalidNamespaceId, kInvalidSchemaTypeId),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  kInvalidNamespaceId, /*schema_type_id=*/0),
+              IsFalse());
+  EXPECT_THAT(document_store->GetResultGroupingEntryId(
+                  ResultSpecProto_ResultGroupingType_NAMESPACE_AND_SCHEMA_TYPE,
+                  /*namespace_id=*/0, kInvalidSchemaTypeId),
+              IsFalse());
+}
+
 INSTANTIATE_TEST_SUITE_P(
     DocumentStoreTest, DocumentStoreTest,
     testing::Values(
diff --git a/icing/testing/embedding-test-utils.cc b/icing/testing/embedding-test-utils.cc
index 23f4197..aa61ad3 100644
--- a/icing/testing/embedding-test-utils.cc
+++ b/icing/testing/embedding-test-utils.cc
@@ -24,9 +24,11 @@
 #include "icing/absl_ports/canonical_errors.h"
 #include "icing/index/embed/embedding-hit.h"
 #include "icing/index/embed/embedding-index.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/index/embed/posting-list-embedding-hit-accessor.h"
 #include "icing/index/embed/quantizer.h"
 #include "icing/proto/document.pb.h"
+#include "icing/store/document-id.h"
 #include "icing/util/status-macros.h"
 
 namespace icing {
@@ -83,5 +85,16 @@ GetAndRestoreQuantizedEmbeddingVectorFromIndex(
   return result;
 }
 
+EmbeddingMatchInfos& GetOrCreateEmbeddingMatchInfosForDocument(
+    EmbeddingQueryResults& embedding_query_results, int query_vector_index,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
+    DocumentId doc_id) {
+  EmbeddingQueryResults::EmbeddingQueryMatchInfoMap* info_map =
+      embedding_query_results
+          .GetOrCreateMatchInfoMap(query_vector_index, metric_type)
+          .ValueOrDie();
+  return (*info_map)[doc_id];
+}
+
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/testing/embedding-test-utils.h b/icing/testing/embedding-test-utils.h
index 7f0b0c1..aa288e9 100644
--- a/icing/testing/embedding-test-utils.h
+++ b/icing/testing/embedding-test-utils.h
@@ -24,7 +24,9 @@
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/index/embed/embedding-hit.h"
 #include "icing/index/embed/embedding-index.h"
+#include "icing/index/embed/embedding-query-results.h"
 #include "icing/proto/document.pb.h"
+#include "icing/store/document-id.h"
 
 namespace icing {
 namespace lib {
@@ -59,6 +61,13 @@ GetAndRestoreQuantizedEmbeddingVectorFromIndex(
     const EmbeddingIndex* embedding_index, const EmbeddingHit& hit,
     uint32_t dimension);
 
+// Gets or creates the EmbeddingMatchInfos in embedding_query_results for the
+// given query_vector_index, metric_type, and document.
+EmbeddingMatchInfos& GetOrCreateEmbeddingMatchInfosForDocument(
+    EmbeddingQueryResults& embedding_query_results, int query_vector_index,
+    SearchSpecProto::EmbeddingQueryMetricType::Code metric_type,
+    DocumentId doc_id);
+
 }  // namespace lib
 }  // namespace icing
 
diff --git a/icing/testing/test-feature-flags.cc b/icing/testing/test-feature-flags.cc
index 3d167b4..f17e929 100644
--- a/icing/testing/test-feature-flags.cc
+++ b/icing/testing/test-feature-flags.cc
@@ -26,7 +26,10 @@ FeatureFlags GetTestFeatureFlags() {
                       /*enable_repeated_field_joins=*/true,
                       /*enable_embedding_backup_generation=*/true,
                       /*enable_schema_database=*/true,
-                      /*release_backup_schema_file_if_overlay_present=*/true);
+                      /*release_backup_schema_file_if_overlay_present=*/true,
+                      /*enable_strict_page_byte_size_limit=*/true,
+                      /*enable_smaller_decompression_buffer_size=*/true,
+                      /*enable_eigen_embedding_scoring=*/true);
 }
 
 }  // namespace lib
diff --git a/icing/tokenization/combined-tokenizer_test.cc b/icing/tokenization/combined-tokenizer_test.cc
index 520ea47..e553373 100644
--- a/icing/tokenization/combined-tokenizer_test.cc
+++ b/icing/tokenization/combined-tokenizer_test.cc
@@ -34,6 +34,7 @@
 #include "icing/index/numeric/numeric-index.h"
 #include "icing/jni/jni-cache.h"
 #include "icing/legacy/index/icing-filesystem.h"
+#include "icing/portable/gzip_stream.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/query/query-processor.h"
@@ -99,14 +100,18 @@ class CombinedTokenizerTest : public ::testing::Test {
 
     ICING_ASSERT_OK_AND_ASSIGN(
         DocumentStore::CreateResult create_result,
-        DocumentStore::Create(&filesystem_, store_dir_, &fake_clock_,
-                              schema_store_.get(), feature_flags_.get(),
-                              /*force_recovery_and_revalidate_documents=*/false,
-                              /*pre_mapping_fbv=*/false,
-                              /*use_persistent_hash_map=*/false,
-                              PortableFileBackedProtoLog<
-                                  DocumentWrapper>::kDefaultCompressionLevel,
-                              /*initialize_stats=*/nullptr));
+        DocumentStore::Create(
+            &filesystem_, store_dir_, &fake_clock_, schema_store_.get(),
+            feature_flags_.get(),
+            /*force_recovery_and_revalidate_documents=*/false,
+            /*pre_mapping_fbv=*/false,
+            /*use_persistent_hash_map=*/false,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionLevel,
+            PortableFileBackedProtoLog<
+                DocumentWrapper>::kDefaultCompressionThresholdBytes,
+            protobuf_ports::kDefaultMemLevel,
+            /*initialize_stats=*/nullptr));
     document_store_ = std::move(create_result.document_store);
 
     Index::Options options(index_dir_,
diff --git a/icing/util/document-util.cc b/icing/util/document-util.cc
new file mode 100644
index 0000000..d3834e6
--- /dev/null
+++ b/icing/util/document-util.cc
@@ -0,0 +1,36 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/util/document-util.h"
+
+#include <utility>
+
+#include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
+
+namespace icing {
+namespace lib {
+
+namespace document_util {
+
+DocumentWrapper CreateDocumentWrapper(DocumentProto document) {
+  DocumentWrapper document_wrapper;
+  *document_wrapper.mutable_document() = std::move(document);
+  return document_wrapper;
+}
+
+}  // namespace document_util
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/util/document-util.h b/icing/util/document-util.h
new file mode 100644
index 0000000..c9e117a
--- /dev/null
+++ b/icing/util/document-util.h
@@ -0,0 +1,34 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_UTIL_DOCUMENT_UTIL_H_
+#define ICING_UTIL_DOCUMENT_UTIL_H_
+
+#include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
+
+namespace icing {
+namespace lib {
+
+namespace document_util {
+
+// Creates a DocumentWrapper from a DocumentProto.
+DocumentWrapper CreateDocumentWrapper(DocumentProto document);
+
+}  // namespace document_util
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_UTIL_DOCUMENT_UTIL_H_
diff --git a/icing/util/document-util_test.cc b/icing/util/document-util_test.cc
new file mode 100644
index 0000000..c93ad6d
--- /dev/null
+++ b/icing/util/document-util_test.cc
@@ -0,0 +1,47 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/util/document-util.h"
+
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+#include "icing/document-builder.h"
+#include "icing/portable/equals-proto.h"
+#include "icing/proto/document_wrapper.pb.h"
+
+namespace icing {
+namespace lib {
+namespace document_util {
+
+namespace {
+
+using ::icing::lib::portable_equals_proto::EqualsProto;
+
+TEST(DocumentUtilTest, CreateDocumentWrapper) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("icing", "fake_type/1")
+                               .SetSchema("FakeType")
+                               .AddStringProperty("prop1", "foo", "bar", "baz")
+                               .Build();
+
+  DocumentWrapper document_wrapper = CreateDocumentWrapper(document);
+  EXPECT_THAT(document_wrapper.document(), EqualsProto(document));
+}
+
+}  // namespace
+
+}  // namespace document_util
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/util/document-validator.cc b/icing/util/document-validator.cc
index 916b34e..8c1ad85 100644
--- a/icing/util/document-validator.cc
+++ b/icing/util/document-validator.cc
@@ -80,7 +80,7 @@ libtextclassifier3::Status DocumentValidator::Validate(
   auto type_config_or = schema_store_->GetSchemaTypeConfig(document.schema());
   if (!type_config_or.ok()) {
     ICING_LOG(ERROR) << type_config_or.status().error_message()
-                     << "Error while validating document ("
+                     << " Error while validating document ("
                      << document.namespace_() << ", " << document.uri() << ")";
     return type_config_or.status();
   }
diff --git a/icing/util/embedding-util.h b/icing/util/embedding-util.h
index 5026051..1390d4e 100644
--- a/icing/util/embedding-util.h
+++ b/icing/util/embedding-util.h
@@ -15,6 +15,7 @@
 #ifndef ICING_UTIL_EMBEDDING_UTIL_H_
 #define ICING_UTIL_EMBEDDING_UTIL_H_
 
+#include <array>
 #include <string_view>
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
@@ -27,6 +28,15 @@ namespace lib {
 
 namespace embedding_util {
 
+// The list of embedding query metric types, with the order matching the
+// enum value.
+static const std::array<SearchSpecProto::EmbeddingQueryMetricType::Code, 3>
+    kEmbeddingQueryMetricTypes = {
+        SearchSpecProto::EmbeddingQueryMetricType::COSINE,       // value = 1
+        SearchSpecProto::EmbeddingQueryMetricType::DOT_PRODUCT,  // value = 2
+        SearchSpecProto::EmbeddingQueryMetricType::EUCLIDEAN     // value = 3
+};
+
 inline libtextclassifier3::StatusOr<
     SearchSpecProto::EmbeddingQueryMetricType::Code>
 GetEmbeddingQueryMetricTypeFromName(std::string_view metric_name) {
diff --git a/icing/util/logging.h b/icing/util/logging.h
index 415d055..7eaf776 100644
--- a/icing/util/logging.h
+++ b/icing/util/logging.h
@@ -77,6 +77,14 @@ inline LoggingStringStream& operator<<(LoggingStringStream& stream,
   return stream;
 }
 
+inline LoggingStringStream& operator<<(LoggingStringStream& stream,
+                                       char* message) {
+  if (stream.should_log_) {
+    stream.message.append(message);
+  }
+  return stream;
+}
+
 inline LoggingStringStream& operator<<(LoggingStringStream& stream,
                                        const char* message) {
   if (stream.should_log_) {
@@ -93,6 +101,14 @@ inline LoggingStringStream& operator<<(LoggingStringStream& stream,
   return stream;
 }
 
+inline LoggingStringStream& operator<<(LoggingStringStream& stream,
+                                       std::string& message) {
+  if (stream.should_log_) {
+    stream.message.append(message);
+  }
+  return stream;
+}
+
 inline LoggingStringStream& operator<<(LoggingStringStream& stream,
                                        std::string_view message) {
   if (stream.should_log_) {
diff --git a/icing/util/logging_test.cc b/icing/util/logging_test.cc
index eac018e..29e39b5 100644
--- a/icing/util/logging_test.cc
+++ b/icing/util/logging_test.cc
@@ -13,6 +13,8 @@
 // limitations under the License.
 
 #include "icing/util/logging.h"
+#include <cerrno>
+#include <cstring>
 
 #include "gmock/gmock.h"
 #include "gtest/gtest.h"
@@ -153,6 +155,18 @@ TEST(LoggingTest, LoggingStreamTest) {
   EXPECT_THAT(stream2.message, IsEmpty());
 }
 
+TEST(LoggingTest, LoggingStreamStrErrorTest) {
+  ASSERT_TRUE(SetLoggingLevel(LogSeverity::INFO));
+  char* error_message = strerror(ENOENT);
+  // This one should be logged.
+  LoggingStringStream stream1 = (ICING_LOG(INFO) << error_message);
+  EXPECT_THAT(stream1.message, EndsWith("No such file or directory"));
+
+  // This one should not be logged, thus empty.
+  LoggingStringStream stream2 = (ICING_LOG(DBG) << error_message);
+  EXPECT_THAT(stream2.message, IsEmpty());
+}
+
 }  // namespace
 }  // namespace lib
 }  // namespace icing
diff --git a/icing/util/timestamp-util.cc b/icing/util/timestamp-util.cc
new file mode 100644
index 0000000..6e50d2f
--- /dev/null
+++ b/icing/util/timestamp-util.cc
@@ -0,0 +1,49 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/util/timestamp-util.h"
+
+#include <cstdint>
+#include <limits>
+
+namespace icing {
+namespace lib {
+
+namespace timestamp_util {
+
+int64_t CalculateRawExpirationTimestampMs(int64_t creation_timestamp_ms,
+                                          int64_t ttl_ms) {
+  if (ttl_ms == 0) {
+    // Special case where a TTL of 0 indicates the document should never
+    // expire. int64_t max, interpreted as seconds since epoch, represents
+    // some point in the year 292,277,026,596. So we're probably ok to use
+    // this as "never reaching this point".
+    return std::numeric_limits<int64_t>::max();
+  }
+
+  int64_t expiration_timestamp_ms;
+  if (__builtin_add_overflow(creation_timestamp_ms, ttl_ms,
+                             &expiration_timestamp_ms)) {
+    // Overflow detected. Treat overflow as the same behavior of just int64_t
+    // max
+    return std::numeric_limits<int64_t>::max();
+  }
+
+  return expiration_timestamp_ms;
+}
+
+}  // namespace timestamp_util
+
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/util/timestamp-util.h b/icing/util/timestamp-util.h
new file mode 100644
index 0000000..6479b4f
--- /dev/null
+++ b/icing/util/timestamp-util.h
@@ -0,0 +1,42 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef ICING_UTIL_TIMESTAMP_UTIL_H_
+#define ICING_UTIL_TIMESTAMP_UTIL_H_
+
+#include <cstdint>
+
+namespace icing {
+namespace lib {
+
+namespace timestamp_util {
+
+// Calculates the (raw) expiration timestamp of a document given its creation
+// timestamp and time-to-live (TTL) in milliseconds.
+//
+// If the TTL is 0, the document should never expire and the function will
+// return INT64_MAX as the expiration timestamp.
+//
+// If an overflow occurs, the function will return INT64_MAX.
+//
+// REQUIRES: creation_timestamp_ms >= 0 && ttl_ms >= 0.
+int64_t CalculateRawExpirationTimestampMs(int64_t creation_timestamp_ms,
+                                          int64_t ttl_ms);
+
+}  // namespace timestamp_util
+
+}  // namespace lib
+}  // namespace icing
+
+#endif  // ICING_UTIL_TIMESTAMP_UTIL_H_
diff --git a/icing/util/timestamp-util_test.cc b/icing/util/timestamp-util_test.cc
new file mode 100644
index 0000000..fd488cd
--- /dev/null
+++ b/icing/util/timestamp-util_test.cc
@@ -0,0 +1,88 @@
+// Copyright (C) 2025 Google LLC
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include "icing/util/timestamp-util.h"
+
+#include <cstdint>
+#include <limits>
+
+#include "gmock/gmock.h"
+#include "gtest/gtest.h"
+
+namespace icing {
+namespace lib {
+namespace timestamp_util {
+
+namespace {
+
+using ::testing::Eq;
+
+TEST(TimestampUtilTest, CalculateRawExpirationTimestampMs) {
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/0,
+                                                /*ttl_ms=*/1000),
+              Eq(1000));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/1000,
+                                                /*ttl_ms=*/1000),
+              Eq(2000));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/2000,
+                                                /*ttl_ms=*/1000),
+              Eq(3000));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/5000,
+                                                /*ttl_ms=*/1000),
+              Eq(6000));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/5000,
+                                                /*ttl_ms=*/3000),
+              Eq(8000));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/5000,
+                                                /*ttl_ms=*/10000),
+              Eq(15000));
+}
+
+TEST(TimestampUtilTest,
+     CalculateRawExpirationTimestampMs_zeroTtlShouldReturnInt64Max) {
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/1000,
+                                                /*ttl_ms=*/0),
+              Eq(std::numeric_limits<int64_t>::max()));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/2000,
+                                                /*ttl_ms=*/0),
+              Eq(std::numeric_limits<int64_t>::max()));
+  EXPECT_THAT(CalculateRawExpirationTimestampMs(/*creation_timestamp_ms=*/5000,
+                                                /*ttl_ms=*/0),
+              Eq(std::numeric_limits<int64_t>::max()));
+}
+
+TEST(TimestampUtilTest,
+     CalculateRawExpirationTimestampMs_shouldPreventOverflow) {
+  EXPECT_THAT(
+      CalculateRawExpirationTimestampMs(
+          /*creation_timestamp_ms=*/std::numeric_limits<int64_t>::max() - 2,
+          /*ttl_ms=*/2),
+      Eq(std::numeric_limits<int64_t>::max()));
+  EXPECT_THAT(
+      CalculateRawExpirationTimestampMs(
+          /*creation_timestamp_ms=*/std::numeric_limits<int64_t>::max() - 2,
+          /*ttl_ms=*/100),
+      Eq(std::numeric_limits<int64_t>::max()));
+  EXPECT_THAT(
+      CalculateRawExpirationTimestampMs(
+          /*creation_timestamp_ms=*/std::numeric_limits<int64_t>::max() - 1,
+          /*ttl_ms=*/100000),
+      Eq(std::numeric_limits<int64_t>::max()));
+}
+
+}  // namespace
+
+}  // namespace timestamp_util
+}  // namespace lib
+}  // namespace icing
diff --git a/icing/util/tokenized-document.cc b/icing/util/tokenized-document.cc
index 576e0a2..5b9818a 100644
--- a/icing/util/tokenized-document.cc
+++ b/icing/util/tokenized-document.cc
@@ -14,6 +14,7 @@
 
 #include "icing/util/tokenized-document.h"
 
+#include <cstdint>
 #include <memory>
 #include <string_view>
 #include <utility>
@@ -21,6 +22,7 @@
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
 #include "icing/schema/joinable-property.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
@@ -28,6 +30,7 @@
 #include "icing/tokenization/token.h"
 #include "icing/tokenization/tokenizer-factory.h"
 #include "icing/tokenization/tokenizer.h"
+#include "icing/util/document-util.h"
 #include "icing/util/document-validator.h"
 #include "icing/util/status-macros.h"
 
@@ -68,21 +71,28 @@ libtextclassifier3::StatusOr<std::vector<TokenizedSection>> Tokenize(
 /* static */ libtextclassifier3::StatusOr<TokenizedDocument>
 TokenizedDocument::Create(const SchemaStore* schema_store,
                           const LanguageSegmenter* language_segmenter,
-                          DocumentProto document) {
+                          int64_t current_time_ms, DocumentProto document) {
+  // Set the creation timestamp if it is not set.
+  if (document.creation_timestamp_ms() == 0) {
+    document.set_creation_timestamp_ms(current_time_ms);
+  }
+
   // Since there are many std::string_view objects pointing to the document
-  // proto, we should make sure DocumentProto has a fixed address. The simplest
-  // way is to use a unique_ptr.
-  auto document_ptr = std::make_unique<DocumentProto>(std::move(document));
+  // proto, we should make sure DocumentProto in DocumentWrapper has a fixed
+  // address. The simplest way is to use a unique_ptr.
+  auto document_wrapper_ptr = std::make_unique<DocumentWrapper>(
+      document_util::CreateDocumentWrapper(std::move(document)));
 
   DocumentValidator validator(schema_store);
-  ICING_RETURN_IF_ERROR(validator.Validate(*document_ptr));
-
-  ICING_ASSIGN_OR_RETURN(SectionGroup section_group,
-                         schema_store->ExtractSections(*document_ptr));
+  ICING_RETURN_IF_ERROR(validator.Validate(document_wrapper_ptr->document()));
 
   ICING_ASSIGN_OR_RETURN(
-      JoinablePropertyGroup joinable_property_group,
-      schema_store->ExtractJoinableProperties(*document_ptr));
+      SectionGroup section_group,
+      schema_store->ExtractSections(document_wrapper_ptr->document()));
+
+  ICING_ASSIGN_OR_RETURN(JoinablePropertyGroup joinable_property_group,
+                         schema_store->ExtractJoinableProperties(
+                             document_wrapper_ptr->document()));
 
   // Tokenize string sections
   ICING_ASSIGN_OR_RETURN(
@@ -90,11 +100,19 @@ TokenizedDocument::Create(const SchemaStore* schema_store,
       Tokenize(schema_store, language_segmenter,
                section_group.string_sections));
 
-  return TokenizedDocument(std::move(document_ptr),
-                           std::move(tokenized_string_sections),
-                           std::move(section_group.integer_sections),
-                           std::move(section_group.vector_sections),
-                           std::move(joinable_property_group));
+  TokenizedDocument tokenized_document(
+      std::move(document_wrapper_ptr), std::move(tokenized_string_sections),
+      std::move(section_group.integer_sections),
+      std::move(section_group.vector_sections),
+      std::move(joinable_property_group));
+
+  // Set the num_string_tokens into the document proto.
+  int32_t num_string_tokens = tokenized_document.num_string_tokens();
+  tokenized_document.document_wrapper_->mutable_document()
+      ->mutable_internal_fields()
+      ->set_length_in_tokens(num_string_tokens);
+
+  return tokenized_document;
 }
 
 }  // namespace lib
diff --git a/icing/util/tokenized-document.h b/icing/util/tokenized-document.h
index ae92311..5a7f635 100644
--- a/icing/util/tokenized-document.h
+++ b/icing/util/tokenized-document.h
@@ -23,6 +23,7 @@
 
 #include "icing/text_classifier/lib3/utils/base/statusor.h"
 #include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
 #include "icing/schema/joinable-property.h"
 #include "icing/schema/schema-store.h"
 #include "icing/schema/section.h"
@@ -41,13 +42,29 @@ struct TokenizedSection {
         token_sequence(std::move(token_sequence_in)) {}
 };
 
+// A wrapper class to hold the input DocumentProto and the tokenized sections.
+// It finalizes the proto (to be added into DocumentStore) and tokens (to be
+// indexed), so after the creation, the proto and tokens are immutable and the
+// caller can simply use them to write.
+//
+// Note: the document dependency is not the responsibility of this class.
+// Additional steps (see DocumentDependencyProcessor) are needed to handle the
+// dependencies.
+//
+// Some essential fields are populated into the DocumentProto. For example:
+// - Creation timestamp: if it is not set by the client, it will be set to the
+//   current time.
+// - Length in tokens: the number of tokens in all string sections.
 class TokenizedDocument {
  public:
   static libtextclassifier3::StatusOr<TokenizedDocument> Create(
       const SchemaStore* schema_store,
-      const LanguageSegmenter* language_segmenter, DocumentProto document);
+      const LanguageSegmenter* language_segmenter, int64_t current_time_ms,
+      DocumentProto document);
 
-  const DocumentProto& document() const { return *document_; }
+  // Due to DocumentStore's internal implementation, we need to wrap
+  // DocumentProto into DocumentWrapper.
+  const DocumentWrapper& document_wrapper() const { return *document_wrapper_; }
 
   int32_t num_string_tokens() const {
     int32_t num_string_tokens = 0;
@@ -78,18 +95,18 @@ class TokenizedDocument {
  private:
   // Use TokenizedDocument::Create() to instantiate.
   explicit TokenizedDocument(
-      std::unique_ptr<DocumentProto> document,
+      std::unique_ptr<DocumentWrapper> document_wrapper,
       std::vector<TokenizedSection>&& tokenized_string_sections,
       std::vector<Section<int64_t>>&& integer_sections,
       std::vector<Section<PropertyProto::VectorProto>>&& vector_sections,
       JoinablePropertyGroup&& joinable_property_group)
-      : document_(std::move(document)),
+      : document_wrapper_(std::move(document_wrapper)),
         tokenized_string_sections_(std::move(tokenized_string_sections)),
         integer_sections_(std::move(integer_sections)),
         vector_sections_(std::move(vector_sections)),
         joinable_property_group_(std::move(joinable_property_group)) {}
 
-  std::unique_ptr<DocumentProto> document_;
+  std::unique_ptr<DocumentWrapper> document_wrapper_;
   std::vector<TokenizedSection> tokenized_string_sections_;
   std::vector<Section<int64_t>> integer_sections_;
   std::vector<Section<PropertyProto::VectorProto>> vector_sections_;
diff --git a/icing/util/tokenized-document_test.cc b/icing/util/tokenized-document_test.cc
index 513b8d0..84528e7 100644
--- a/icing/util/tokenized-document_test.cc
+++ b/icing/util/tokenized-document_test.cc
@@ -14,6 +14,7 @@
 
 #include "icing/util/tokenized-document.h"
 
+#include <cstdint>
 #include <memory>
 #include <string>
 #include <string_view>
@@ -27,6 +28,7 @@
 #include "icing/file/filesystem.h"
 #include "icing/portable/platform.h"
 #include "icing/proto/document.pb.h"
+#include "icing/proto/document_wrapper.pb.h"
 #include "icing/proto/schema.pb.h"
 #include "icing/schema-builder.h"
 #include "icing/schema/joinable-property.h"
@@ -39,6 +41,7 @@
 #include "icing/testing/tmp-directory.h"
 #include "icing/tokenization/language-segmenter-factory.h"
 #include "icing/tokenization/language-segmenter.h"
+#include "icing/util/document-util.h"
 #include "icing/util/icu-data-file-helper.h"
 #include "unicode/uloc.h"
 
@@ -239,7 +242,15 @@ class TokenizedDocumentTest : public ::testing::Test {
   std::unique_ptr<SchemaStore> schema_store_;
 };
 
+DocumentWrapper CreateDocumentWrapper(DocumentProto document,
+                                      int32_t num_string_tokens) {
+  document.mutable_internal_fields()->set_length_in_tokens(num_string_tokens);
+  return document_util::CreateDocumentWrapper(std::move(document));
+}
+
 TEST_F(TokenizedDocumentTest, CreateAll) {
+  int64_t current_time_ms = 123;
+
   PropertyProto::VectorProto vector1;
   vector1.set_model_signature("my_model1");
   vector1.add_values(1.0f);
@@ -252,6 +263,7 @@ TEST_F(TokenizedDocumentTest, CreateAll) {
 
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kUnindexedStringProperty),
@@ -273,9 +285,11 @@ TEST_F(TokenizedDocumentTest, CreateAll) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/9)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(9));
 
   // string sections
@@ -326,8 +340,11 @@ TEST_F(TokenizedDocumentTest, CreateAll) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateNoIndexableIntegerProperties) {
+  int64_t current_time_ms = 123;
+
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddInt64Property(std::string(kUnindexedIntegerProperty), 789)
@@ -336,9 +353,11 @@ TEST_F(TokenizedDocumentTest, CreateNoIndexableIntegerProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -355,8 +374,11 @@ TEST_F(TokenizedDocumentTest, CreateNoIndexableIntegerProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateMultipleIndexableIntegerProperties) {
+  int64_t current_time_ms = 123;
+
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddInt64Property(std::string(kUnindexedIntegerProperty), 789)
@@ -367,9 +389,11 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableIntegerProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -394,8 +418,11 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableIntegerProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateNoIndexableStringProperties) {
+  int64_t current_time_ms = 123;
+
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kUnindexedStringProperty),
@@ -405,9 +432,11 @@ TEST_F(TokenizedDocumentTest, CreateNoIndexableStringProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -424,8 +453,11 @@ TEST_F(TokenizedDocumentTest, CreateNoIndexableStringProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateMultipleIndexableStringProperties) {
+  int64_t current_time_ms = 123;
+
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kUnindexedStringProperty),
@@ -438,9 +470,11 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableStringProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/9)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(9));
 
   // string sections
@@ -467,12 +501,15 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableStringProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateNoIndexableVectorProperties) {
+  int64_t current_time_ms = 123;
+
   PropertyProto::VectorProto vector;
   vector.set_model_signature("my_model");
   vector.add_values(1.0f);
 
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddVectorProperty(std::string(kUnindexedVectorProperty), vector)
@@ -481,9 +518,11 @@ TEST_F(TokenizedDocumentTest, CreateNoIndexableVectorProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -500,6 +539,8 @@ TEST_F(TokenizedDocumentTest, CreateNoIndexableVectorProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateMultipleIndexableVectorProperties) {
+  int64_t current_time_ms = 123;
+
   PropertyProto::VectorProto vector1;
   vector1.set_model_signature("my_model1");
   vector1.add_values(1.0f);
@@ -512,6 +553,7 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableVectorProperties) {
 
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddVectorProperty(std::string(kUnindexedVectorProperty), vector1)
@@ -523,9 +565,11 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableVectorProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -550,8 +594,11 @@ TEST_F(TokenizedDocumentTest, CreateMultipleIndexableVectorProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateNoJoinQualifiedIdProperties) {
+  int64_t current_time_ms = 123;
+
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kUnindexedStringProperty),
@@ -561,9 +608,11 @@ TEST_F(TokenizedDocumentTest, CreateNoJoinQualifiedIdProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -580,8 +629,11 @@ TEST_F(TokenizedDocumentTest, CreateNoJoinQualifiedIdProperties) {
 }
 
 TEST_F(TokenizedDocumentTest, CreateMultipleJoinQualifiedIdProperties) {
+  int64_t current_time_ms = 123;
+
   DocumentProto document =
       DocumentBuilder()
+          .SetCreationTimestampMs(current_time_ms)
           .SetKey("icing", "fake_type/1")
           .SetSchema(std::string(kFakeType))
           .AddStringProperty(std::string(kUnindexedStringProperty),
@@ -593,9 +645,11 @@ TEST_F(TokenizedDocumentTest, CreateMultipleJoinQualifiedIdProperties) {
   ICING_ASSERT_OK_AND_ASSIGN(
       TokenizedDocument tokenized_document,
       TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
-                                document));
+                                current_time_ms, document));
 
-  EXPECT_THAT(tokenized_document.document(), EqualsProto(document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper(),
+      EqualsProto(CreateDocumentWrapper(document, /*num_string_tokens=*/0)));
   EXPECT_THAT(tokenized_document.num_string_tokens(), Eq(0));
 
   // string sections
@@ -619,6 +673,40 @@ TEST_F(TokenizedDocumentTest, CreateMultipleJoinQualifiedIdProperties) {
               ElementsAre("pkg$db/ns#uri2"));
 }
 
+TEST_F(TokenizedDocumentTest,
+       CreateShouldSetCreationTimestampToCurrentTimeIfUnset) {
+  DocumentProto document = DocumentBuilder()
+                               .SetKey("icing", "fake_type/1")
+                               .SetSchema(std::string(kFakeType))
+                               .Build();
+  ASSERT_THAT(document.creation_timestamp_ms(), Eq(0));
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_document,
+      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
+                                /*current_time_ms=*/123, document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper().document().creation_timestamp_ms(),
+      Eq(123));
+}
+
+TEST_F(TokenizedDocumentTest,
+       CreateShouldNotOverwriteExistingCreationTimestamp) {
+  DocumentProto document = DocumentBuilder()
+                               .SetCreationTimestampMs(123)
+                               .SetKey("icing", "fake_type/1")
+                               .SetSchema(std::string(kFakeType))
+                               .Build();
+
+  ICING_ASSERT_OK_AND_ASSIGN(
+      TokenizedDocument tokenized_document,
+      TokenizedDocument::Create(schema_store_.get(), lang_segmenter_.get(),
+                                /*current_time_ms=*/456, document));
+  EXPECT_THAT(
+      tokenized_document.document_wrapper().document().creation_timestamp_ms(),
+      Eq(123));
+}
+
 }  // namespace
 
 }  // namespace lib
diff --git a/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl
index 4017e8f..764ffdc 100644
--- a/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl
+++ b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIcingSearchEngine.aidl
@@ -25,12 +25,18 @@ interface IIcingSearchEngine {
 
   void close();
 
+  @nullable
+  /*ResetResultProto*/ byte[] clearAndDestroy();
+
   @nullable
   /*ResetResultProto*/ byte[] reset();
 
   @nullable
   /*SetSchemaResultProto*/ byte[] setSchema(in byte[] schemaProto, boolean ignoreErrorsAndDeleteDocuments);
 
+  @nullable
+  /*SetSchemaResultProto*/ byte[] setSchemaWithRequestProto(in byte[] setSchemaRequestProto);
+
   @nullable
   /*GetSchemaResultProto*/ byte[] getSchema();
 
@@ -49,6 +55,9 @@ interface IIcingSearchEngine {
   @nullable
   /*GetResultProto*/ byte[] get(String name_space, String uri, in byte[] getResultSpecProto);
 
+  @nullable
+  /*BatchGetResultProto*/ byte[] batchGet(in byte[] getResultSpecProto);
+
   @nullable
   /*ReportUsageResultProto*/ byte[] reportUsage(in byte[] usageReportProto);
 
@@ -61,6 +70,9 @@ interface IIcingSearchEngine {
   @nullable
   /*SearchResultProto*/ byte[] getNextPage(long nextPageToken);
 
+  @nullable
+  /*SearchResultProto*/ byte[] getNextPageWithRequestProto(in byte[] getNextPageRequestProto);
+
   void invalidateNextPageToken(long nextPageToken);
 
   @nullable
diff --git a/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl
index 2241e0a..4bfdb23 100644
--- a/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl
+++ b/isolated_storage_service/aidl/com/android/isolated_storage_service/IIsolatedStorageService.aidl
@@ -29,11 +29,33 @@ interface IIsolatedStorageService {
   oneway void quit();
 
   /**
-   * Returns an Icing connection for the given uid. Creates a new Icing connection if one does not
-   * already exist for the given uid.
+   * Trims the memory used by the pVM.
+   */
+  oneway void trimMemory();
+
+  /**
+   * Gets VM MemAvailable from /proc/meminfo in kB.
+   */
+  long getAvailableMemory();
+
+  /**
+   * Inform the VM that a user has unlocked the device
+   */
+  void onUserUnlocking();
+
+  /**
+   * Returns an Icing connection for the given userId. Creates a new Icing connection if one does
+   * not already exist for the given userId.
+   *
+   * @param userId The userId of the caller.
+   * @return An Icing connection for the given userId.
+   */
+  IIcingSearchEngine getOrCreateIcingConnection(int userId);
+
+  /**
+   * Removes an Icing connection for the given userId.
    *
-   * @param uid The uid of the caller.
-   * @return An Icing connection for the given uid.
+   * @param userId The userId of the caller.
    */
-  IIcingSearchEngine getOrCreateIcingConnection(int uid);
+  oneway void removeIcingConnection(int userId);
 }
diff --git a/isolated_storage_service/iss.lds b/isolated_storage_service/iss.lds
new file mode 100644
index 0000000..822df58
--- /dev/null
+++ b/isolated_storage_service/iss.lds
@@ -0,0 +1,9 @@
+{
+  global:
+    AVmPayload_main;
+
+    Java_*;
+    JNI_OnLoad;
+  local:
+    *;
+};
diff --git a/isolated_storage_service/payload/main.cc b/isolated_storage_service/payload/main.cc
index 93820e0..6ece959 100644
--- a/isolated_storage_service/payload/main.cc
+++ b/isolated_storage_service/payload/main.cc
@@ -1,16 +1,21 @@
+#include <android-base/properties.h>
 #include <android/binder_auto_utils.h>
 #include <android/binder_ibinder.h>
 #include <android/binder_status.h>
+#include <sys/system_properties.h>
+#include <vm_payload.h>
 
+#include <cinttypes>
 #include <cstdint>
+#include <cstdio>
 #include <cstdlib>
+#include <dlfcn.h>
+#include <fstream>
 #include <memory>
-#include <optional>
-#include <vector>
+#include <unistd.h>
 
 #include "aidl/com/android/isolated_storage_service/BnIcingSearchEngine.h"
 #include "aidl/com/android/isolated_storage_service/BnIsolatedStorageService.h"
-#include <vm_payload.h>
 #include "icing/icing-search-engine.h"
 #include "icing/proto/blob.pb.h"
 #include "icing/proto/document.pb.h"
@@ -25,10 +30,16 @@
 #include "icing/util/logging.h"
 #include "macros.h"
 
+constexpr std::string_view ENCRYPTED_STORE_SETUP_PROP = "microdroid_manager.encrypted_store.setup";
+constexpr std::string_view ENCRYPTED_STORE_STATUS_PROP = "microdroid_manager.encrypted_store.status";
+
+using android::base::WaitForProperty;
+
 namespace {
 
 using ::aidl::com::android::isolated_storage_service::BnIcingSearchEngine;
 using ::aidl::com::android::isolated_storage_service::BnIsolatedStorageService;
+using ::icing::lib::BatchGetResultProto;
 using ::icing::lib::BatchPutResultProto;
 using ::icing::lib::BlobProto;
 using ::icing::lib::DebugInfoResultProto;
@@ -39,6 +50,7 @@ using ::icing::lib::DeleteBySchemaTypeResultProto;
 using ::icing::lib::DeleteResultProto;
 using ::icing::lib::DocumentProto;
 using ::icing::lib::GetAllNamespacesResultProto;
+using ::icing::lib::GetNextPageRequestProto;
 using ::icing::lib::GetOptimizeInfoResultProto;
 using ::icing::lib::GetResultProto;
 using ::icing::lib::GetResultSpecProto;
@@ -59,6 +71,7 @@ using ::icing::lib::SchemaProto;
 using ::icing::lib::ScoringSpecProto;
 using ::icing::lib::SearchResultProto;
 using ::icing::lib::SearchSpecProto;
+using ::icing::lib::SetSchemaRequestProto;
 using ::icing::lib::SetSchemaResultProto;
 using ::icing::lib::StatusProto;
 using ::icing::lib::StorageInfoResultProto;
@@ -67,23 +80,64 @@ using ::icing::lib::SuggestionSpecProto;
 using ::icing::lib::TermMatchType;
 using ::icing::lib::UsageReport;
 using BlobHandleProto = ::icing::lib::PropertyProto::BlobHandleProto;
+using ::icing::lib::ERROR;
 using ::icing::lib::INFO;
 using ::ndk::ScopedAStatus;
 
+namespace {
+void vmShrinkRay() { sync(); }
+}  // namespace
+
+// TODO(b/413761935) move better or equivalent solution into AVF
+// TODO - is there a way to make dlopen automatically fill in weak symbols?
+// please tell smoreland@
+struct AVmPayloadLazy {
+    decltype(AVmPayload_getEncryptedStoragePath)* AVmPayload_getEncryptedStoragePath = nullptr;
+    decltype(AVmPayload_notifyPayloadReady)* AVmPayload_notifyPayloadReady = nullptr;
+    decltype(AVmPayload_runVsockRpcServer)* AVmPayload_runVsockRpcServer = nullptr;
+
+    void load() {
+      void* libvmpayload = dlopen("libvm_payload.so", RTLD_NOW | RTLD_GLOBAL);
+      if (libvmpayload == nullptr) {
+        ICING_LOG(ERROR) << "Failed to load libvm_payload.so: " << dlerror();
+        abort();
+      }
+#define LOAD_ONE(sym) do { \
+    sym = (decltype(sym)) dlsym(libvmpayload, #sym); \
+    if (sym == nullptr) { ICING_LOG(ERROR) << "Failed to load " #sym << dlerror(); } \
+    } while(false)
+
+      LOAD_ONE(AVmPayload_getEncryptedStoragePath);
+      LOAD_ONE(AVmPayload_notifyPayloadReady);
+      LOAD_ONE(AVmPayload_runVsockRpcServer);
+
+#undef LOAD_ONE
+    }
+} gVmPayloadLazy;
+
 // This class implements the AIDL interface for the Icing connection.
 class IcingConnectionImpl
     : public aidl::com::android::isolated_storage_service::BnIcingSearchEngine {
  public:
-  explicit IcingConnectionImpl(uint32_t uid) : uid_(uid) {}
+  explicit IcingConnectionImpl(uint32_t user_id) : user_id_(user_id) {}
 
   ScopedAStatus initialize(
       const std::vector<uint8_t>& icing_search_engine_options_proto,
       std::optional<std::vector<uint8_t>>* initialize_result_proto) {
-    IcingSearchEngineOptions options;
-    DESERIALIZE_OR_RETURN(icing_search_engine_options_proto, options);
-    options.set_base_dir(std::string(AVmPayload_getEncryptedStoragePath()) +
-                         "/" + std::to_string(uid_) + "/" + options.base_dir());
-    icing_ = std::make_unique<IcingSearchEngine>(options);
+    if (icing_ == nullptr) {
+      // Only create a new IcingSearchEngine instance if it is nullptr. This
+      // will avoid unnecessary object destruction and instantiation if this API
+      // is called more than one time.
+      IcingSearchEngineOptions options;
+      DESERIALIZE_OR_RETURN(icing_search_engine_options_proto, options);
+      options.set_base_dir(std::string(gVmPayloadLazy.AVmPayload_getEncryptedStoragePath()) +
+                           "/" + std::to_string(user_id_) + "/" +
+                           options.base_dir());
+      icing_ = std::make_unique<IcingSearchEngine>(options);
+    }
+
+    // IcingSearchEngine::Initialize will return success directly if it has
+    // already been initialized.
     InitializeResultProto initialize_result = icing_->Initialize();
     SERIALIZE_AND_RETURN_ASTATUS(initialize_result, initialize_result_proto);
   }
@@ -95,6 +149,16 @@ class IcingConnectionImpl
     return ScopedAStatus::ok();
   }
 
+  ScopedAStatus clearAndDestroy(
+      std::optional<std::vector<uint8_t>>* clear_and_destroy_result_proto) {
+    CHECK_ICING_INIT(icing_);
+    ICING_LOG(INFO)
+        << "IsolatedStorageService clear and destroy icing instance.";
+    ResetResultProto clear_and_destroy_result = icing_->ClearAndDestroy();
+    SERIALIZE_AND_RETURN_ASTATUS(clear_and_destroy_result,
+                                 clear_and_destroy_result_proto);
+  }
+
   ScopedAStatus reset(std::optional<std::vector<uint8_t>>* reset_result_proto) {
     CHECK_ICING_INIT(icing_);
     ResetResultProto reset_result = icing_->Reset();
@@ -115,6 +179,18 @@ class IcingConnectionImpl
     SERIALIZE_AND_RETURN_ASTATUS(set_schema_result, set_schema_result_proto);
   }
 
+  ScopedAStatus setSchemaWithRequestProto(
+      const std::vector<uint8_t>& set_schema_request_proto,
+      std::optional<std::vector<uint8_t>>* set_schema_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    SetSchemaRequestProto request;
+    DESERIALIZE_OR_RETURN(set_schema_request_proto, request)
+
+    SetSchemaResultProto set_schema_result = icing_->SetSchema(std::move(request));
+    SERIALIZE_AND_RETURN_ASTATUS(set_schema_result, set_schema_result_proto);
+  }
+
   ScopedAStatus getSchema(
       std::optional<std::vector<uint8_t>>* get_schema_result_proto) {
     CHECK_ICING_INIT(icing_);
@@ -153,8 +229,9 @@ class IcingConnectionImpl
     SERIALIZE_AND_RETURN_ASTATUS(put_result, put_result_proto);
   }
 
-  ScopedAStatus batchPut(const std::vector<uint8_t>& put_document_request_proto,
-                         std::optional<std::vector<uint8_t>>* batch_put_result_proto) {
+  ScopedAStatus batchPut(
+      const std::vector<uint8_t>& put_document_request_proto,
+      std::optional<std::vector<uint8_t>>* batch_put_result_proto) {
     CHECK_ICING_INIT(icing_);
 
     PutDocumentRequest request;
@@ -178,6 +255,19 @@ class IcingConnectionImpl
     SERIALIZE_AND_RETURN_ASTATUS(get_result, get_result_proto);
   }
 
+  ScopedAStatus batchGet(
+      const std::vector<uint8_t>& get_result_spec_proto,
+      std::optional<std::vector<uint8_t>>* batch_get_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetResultSpecProto get_result_spec;
+    DESERIALIZE_OR_RETURN(get_result_spec_proto, get_result_spec);
+
+    BatchGetResultProto batch_get_result =
+        icing_->BatchGet(std::move(get_result_spec));
+    SERIALIZE_AND_RETURN_ASTATUS(batch_get_result, batch_get_result_proto);
+  }
+
   ScopedAStatus reportUsage(
       const std::vector<uint8_t>& usage_report_proto,
       std::optional<std::vector<uint8_t>>* report_usage_result_proto) {
@@ -234,6 +324,18 @@ class IcingConnectionImpl
                                  get_next_page_result_proto);
   }
 
+  ScopedAStatus getNextPageWithRequestProto(
+      const std::vector<uint8_t>& get_next_page_request_proto,
+      std::optional<std::vector<uint8_t>>* get_next_page_result_proto) {
+    CHECK_ICING_INIT(icing_);
+
+    GetNextPageRequestProto request_proto;
+    DESERIALIZE_OR_RETURN(get_next_page_request_proto, request_proto);
+
+    SearchResultProto get_next_page_result = icing_->GetNextPage(std::move(request_proto));
+    SERIALIZE_AND_RETURN_ASTATUS(get_next_page_result, get_next_page_result_proto);
+  }
+
   ScopedAStatus invalidateNextPageToken(int64_t next_page_token) {
     CHECK_ICING_INIT(icing_);
 
@@ -396,7 +498,7 @@ class IcingConnectionImpl
 
  protected:
   std::unique_ptr<icing::lib::IcingSearchEngine> icing_ = nullptr;
-  uint32_t uid_;
+  uint32_t user_id_;
 };
 
 class IsolatedStorageServiceImpl : public BnIsolatedStorageService {
@@ -412,19 +514,105 @@ class IsolatedStorageServiceImpl : public BnIsolatedStorageService {
     exit(0);
   }
 
+  // Initially, when microdroid starts, the CE key associated with
+  // /mnt/encryptedstore is unavailable, and hence the filesystem
+  // cannot be decrypted. The onUserUnlocking call is used to notify
+  // microdroid that the CE directory is mounted, and hence the
+  // CE key can be retrieved by the VM.
+  //
+  // For more details, please see commit
+  // 7cc0c9b6f1102ac4e53ef63ae4731f0d1811826d in
+  // packages/modules/Virtualization
+  //
+  // This code has two steps:
+  //
+  // 1) Signal microdroid that the user has unlocked their device.
+  // 2) Wait until microdroid has completed the encrypted filesystem setup
+  //
+  ScopedAStatus onUserUnlocking() override {
+    ICING_LOG(INFO) << "onUserUnlocking";
+
+    // Signal microdroid that the CE directory is available by setting
+    // the property ENCRYPTED_STORE_SETUP_PROP
+
+    if (__system_property_set(std::string(ENCRYPTED_STORE_SETUP_PROP).c_str(), "true") != 0) {
+      std::string error = "failed to set property " + std::string(ENCRYPTED_STORE_SETUP_PROP);
+      ICING_LOG(ERROR) << error;
+      return ScopedAStatus::fromExceptionCodeWithMessage(EX_SERVICE_SPECIFIC, error.c_str());
+    }
+
+    // microdroid_manager uses getEncryptedStoreKEK API on
+    // IVirtualMachineService to get an IEncryptedStoreKEK object stored
+    // inside app's private directory on the Android host.
+    //
+    // Wait for that operation to complete by waiting on the
+    // ENCRYPTED_STORE_STATUS_PROP property.
+
+    if (!WaitForProperty(std::string(ENCRYPTED_STORE_STATUS_PROP), "ready")) {
+        return ScopedAStatus::fromExceptionCodeWithMessage(
+            EX_SERVICE_SPECIFIC, "encrypted store not available");
+    }
+
+    return ScopedAStatus::ok();
+  }
+
+  ScopedAStatus trimMemory() override {
+    ICING_LOG(INFO) << "Received trim memory request, trimming";
+    vmShrinkRay();
+    return ScopedAStatus::ok();
+  }
+
+  ScopedAStatus getAvailableMemory(int64_t* mem_available) override {
+    std::ifstream meminfo_file("/proc/meminfo");
+    if (!meminfo_file) {
+      return ScopedAStatus::fromExceptionCodeWithMessage(
+          EX_ILLEGAL_STATE, "Failed to open /proc/meminfo");
+    }
+    constexpr std::string_view kMemAvailableStr = "MemAvailable:";
+    std::string line;
+    while (std::getline(meminfo_file, line)) {
+      if (line.starts_with(kMemAvailableStr)) {
+        // It is possible that "kB" is in the end of the line, so let's use
+        // sscanf to parse int64_t.
+        int64_t temp_val = 0;
+        if (sscanf(line.c_str() + kMemAvailableStr.size(), "%" PRId64, &temp_val)
+            != 1) {
+          // Failed to parse int64_t. This should not happen, but let's handle
+          // it just in case.
+          return ScopedAStatus::fromExceptionCodeWithMessage(
+              EX_ILLEGAL_STATE, "Failed to parse MemAvailable");
+        }
+
+        *mem_available = temp_val;
+        return ScopedAStatus::ok();
+      }
+    }
+    return ScopedAStatus::fromExceptionCodeWithMessage(
+        EX_ILLEGAL_STATE, "Failed to find MemAvailable");
+  }
+
   ScopedAStatus getOrCreateIcingConnection(
-      int32_t uid,
+      int32_t user_id,
       std::shared_ptr<
           aidl::com::android::isolated_storage_service::IIcingSearchEngine>*
           icing_server) override {
-    auto connection = icing_connections_.find(uid);
+    auto connection = icing_connections_.find(user_id);
     if (connection != icing_connections_.end()) {
       *icing_server = connection->second;
       return ScopedAStatus::ok();
     }
-    icing_connections_[uid] =
-        ndk::SharedRefBase::make<IcingConnectionImpl>(uid);
-    *icing_server = icing_connections_[uid];
+    icing_connections_[user_id] =
+        ndk::SharedRefBase::make<IcingConnectionImpl>(user_id);
+    *icing_server = icing_connections_[user_id];
+    return ScopedAStatus::ok();
+  }
+
+  ScopedAStatus removeIcingConnection(int user_id) override {
+    ICING_LOG(INFO) << "Removing Icing connection for user " << user_id;
+    auto connection = icing_connections_.find(user_id);
+    if (connection != icing_connections_.end()) {
+      icing_connections_.erase(connection);
+    }
     return ScopedAStatus::ok();
   }
 
@@ -433,12 +621,18 @@ class IsolatedStorageServiceImpl : public BnIsolatedStorageService {
 }  // namespace
 
 extern "C" int AVmPayload_main() {
+  gVmPayloadLazy.load();
+
+  // TODO(b/401363381): Remove this once we have a better way to log to
+  // /dev/hvc2 in isolated storage.
+  // Force logging to /dev/hvc2 in isolated storage.
+  icing::lib::SetForceDebugLogging(true);
   ICING_LOG(INFO) << "IsolatedStorageService VM Payload starting";
   auto service = ndk::SharedRefBase::make<IsolatedStorageServiceImpl>();
   auto callback = []([[maybe_unused]] void* param) {
     ICING_LOG(INFO) << "IsolatedStorageService VM Payload ready";
-    AVmPayload_notifyPayloadReady();
+    gVmPayloadLazy.AVmPayload_notifyPayloadReady();
   };
-  AVmPayload_runVsockRpcServer(service->asBinder().get(), service->PORT,
+  gVmPayloadLazy.AVmPayload_runVsockRpcServer(service->asBinder().get(), service->PORT,
                                callback, /*param=*/nullptr);
 }
diff --git a/java/src/com/google/android/icing/IcingLibraryLoader.java b/java/src/com/google/android/icing/IcingLibraryLoader.java
index 1efc067..844ea79 100644
--- a/java/src/com/google/android/icing/IcingLibraryLoader.java
+++ b/java/src/com/google/android/icing/IcingLibraryLoader.java
@@ -6,7 +6,7 @@ package com.google.android.icing;
  */
 final class IcingLibraryLoader {
   public static void loadLibrary() {
-    System.loadLibrary("icing");
+    System.loadLibrary("icing_anywhere");
   }
 
   private IcingLibraryLoader() {}
diff --git a/java/src/com/google/android/icing/IcingSearchEngine.java b/java/src/com/google/android/icing/IcingSearchEngine.java
index fb6d1ef..a5de71f 100644
--- a/java/src/com/google/android/icing/IcingSearchEngine.java
+++ b/java/src/com/google/android/icing/IcingSearchEngine.java
@@ -25,6 +25,7 @@ import com.google.android.icing.proto.DeleteBySchemaTypeResultProto;
 import com.google.android.icing.proto.DeleteResultProto;
 import com.google.android.icing.proto.DocumentProto;
 import com.google.android.icing.proto.GetAllNamespacesResultProto;
+import com.google.android.icing.proto.GetNextPageRequestProto;
 import com.google.android.icing.proto.GetOptimizeInfoResultProto;
 import com.google.android.icing.proto.GetResultProto;
 import com.google.android.icing.proto.GetResultSpecProto;
@@ -181,6 +182,13 @@ public class IcingSearchEngine implements IcingSearchEngineInterface {
         icingSearchEngineImpl.getNextPage(nextPageToken));
   }
 
+  @Override
+  public @NonNull SearchResultProto getNextPage(
+      @NonNull GetNextPageRequestProto getNextPageRequest) {
+    return IcingSearchEngineUtils.byteArrayToSearchResultProto(
+        icingSearchEngineImpl.getNextPageWithRequestProto(getNextPageRequest.toByteArray()));
+  }
+
   @Override
   public void invalidateNextPageToken(long nextPageToken) {
     icingSearchEngineImpl.invalidateNextPageToken(nextPageToken);
@@ -282,6 +290,12 @@ public class IcingSearchEngine implements IcingSearchEngineInterface {
     return IcingSearchEngineUtils.byteArrayToResetResultProto(icingSearchEngineImpl.reset());
   }
 
+  @Override
+  public @NonNull ResetResultProto clearAndDestroy() {
+    return IcingSearchEngineUtils.byteArrayToResetResultProto(
+        icingSearchEngineImpl.clearAndDestroy());
+  }
+
   public static boolean shouldLog(LogSeverity.Code severity) {
     return shouldLog(severity, (short) 0);
   }
diff --git a/java/src/com/google/android/icing/IcingSearchEngineImpl.java b/java/src/com/google/android/icing/IcingSearchEngineImpl.java
index 05ae0a3..d28553e 100644
--- a/java/src/com/google/android/icing/IcingSearchEngineImpl.java
+++ b/java/src/com/google/android/icing/IcingSearchEngineImpl.java
@@ -174,6 +174,13 @@ public class IcingSearchEngineImpl implements Closeable {
     return nativeGetNextPage(this, nextPageToken, System.currentTimeMillis());
   }
 
+  @Nullable
+  public byte[] getNextPageWithRequestProto(@NonNull byte[] getNextPageRequestBytes) {
+    throwIfClosed();
+    return nativeGetNextPageWithRequestProto(
+        this, getNextPageRequestBytes, System.currentTimeMillis());
+  }
+
   public void invalidateNextPageToken(long nextPageToken) {
     throwIfClosed();
     nativeInvalidateNextPageToken(this, nextPageToken);
@@ -274,6 +281,12 @@ public class IcingSearchEngineImpl implements Closeable {
     return nativeReset(this);
   }
 
+  @Nullable
+  public byte[] clearAndDestroy() {
+    throwIfClosed();
+    return nativeClearAndDestroy(this);
+  }
+
   public static boolean shouldLog(short severity) {
     return shouldLog(severity, (short) 0);
   }
@@ -345,6 +358,11 @@ public class IcingSearchEngineImpl implements Closeable {
   private static native byte[] nativeGetNextPage(
       IcingSearchEngineImpl instance, long nextPageToken, long javaToNativeStartTimestampMs);
 
+  private static native byte[] nativeGetNextPageWithRequestProto(
+      IcingSearchEngineImpl instance,
+      byte[] getNextPageRequestBytes,
+      long javaToNativeStartTimestampMs);
+
   private static native void nativeInvalidateNextPageToken(
       IcingSearchEngineImpl instance, long nextPageToken);
 
@@ -382,6 +400,8 @@ public class IcingSearchEngineImpl implements Closeable {
 
   private static native byte[] nativeReset(IcingSearchEngineImpl instance);
 
+  private static native byte[] nativeClearAndDestroy(IcingSearchEngineImpl instance);
+
   private static native byte[] nativeSearchSuggestions(
       IcingSearchEngineImpl instance, byte[] suggestionSpecBytes);
 
diff --git a/java/src/com/google/android/icing/IcingSearchEngineInterface.java b/java/src/com/google/android/icing/IcingSearchEngineInterface.java
index dcf2b60..a583939 100644
--- a/java/src/com/google/android/icing/IcingSearchEngineInterface.java
+++ b/java/src/com/google/android/icing/IcingSearchEngineInterface.java
@@ -11,6 +11,7 @@ import com.google.android.icing.proto.DeleteBySchemaTypeResultProto;
 import com.google.android.icing.proto.DeleteResultProto;
 import com.google.android.icing.proto.DocumentProto;
 import com.google.android.icing.proto.GetAllNamespacesResultProto;
+import com.google.android.icing.proto.GetNextPageRequestProto;
 import com.google.android.icing.proto.GetOptimizeInfoResultProto;
 import com.google.android.icing.proto.GetResultProto;
 import com.google.android.icing.proto.GetResultSpecProto;
@@ -128,9 +129,21 @@ public interface IcingSearchEngineInterface extends Closeable {
   SearchResultProto search(
       SearchSpecProto searchSpec, ScoringSpecProto scoringSpec, ResultSpecProto resultSpec);
 
-  /** Gets the next page. */
+  /**
+   * Gets the next page.
+   *
+   * <p>Note: This method is deprecated. Please use {@link #getNextPage(GetNextPageRequestProto)}
+   * instead.
+   */
   SearchResultProto getNextPage(long nextPageToken);
 
+  /**
+   * Gets the next page.
+   *
+   * @param getNextPageRequest the request proto for getting the next page.
+   */
+  SearchResultProto getNextPage(GetNextPageRequestProto getNextPageRequest);
+
   /** Invalidates the next page token. */
   void invalidateNextPageToken(long nextPageToken);
 
@@ -193,6 +206,9 @@ public interface IcingSearchEngineInterface extends Closeable {
   /** Clears all data from the current icing instance, and reinitializes it. */
   ResetResultProto reset();
 
+  /** Clears all data from the current icing instance. */
+  ResetResultProto clearAndDestroy();
+
   /** Closes the current icing instance. */
   @Override
   void close();
diff --git a/java/tests/instrumentation/Android.bp b/java/tests/instrumentation/Android.bp
index 587566a..00c2575 100644
--- a/java/tests/instrumentation/Android.bp
+++ b/java/tests/instrumentation/Android.bp
@@ -33,7 +33,7 @@ android_test {
         "libicing-java",
         "icing-java-proto-lite",
     ],
-    jni_libs: ["libicing"],
+    jni_libs: ["libicing_anywhere"],
     test_suites: ["device-tests"],
     platform_apis: true,
     use_embedded_native_libs: true,
@@ -49,7 +49,7 @@ android_test {
         "androidx.test.runner",
         "truth",
     ],
-    jni_libs: ["libicing"],
+    jni_libs: ["libicing_anywhere"],
     plugins: ["androidx.appsearch_appsearch-compiler-plugin"],
     test_suites: ["device-tests"],
     platform_apis: true,
diff --git a/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java b/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java
index 8d7d8b1..c5f23f2 100644
--- a/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java
+++ b/java/tests/instrumentation/src/com/google/android/icing/IcingSearchEngineTest.java
@@ -16,6 +16,7 @@ package com.google.android.icing;
 
 import static com.google.common.truth.Truth.assertThat;
 import static com.google.common.truth.Truth.assertWithMessage;
+import static org.junit.Assert.assertThrows;
 
 import com.google.android.icing.IcingSearchEngine;
 import com.google.android.icing.proto.BatchGetResultProto;
@@ -29,6 +30,7 @@ import com.google.android.icing.proto.DeleteBySchemaTypeResultProto;
 import com.google.android.icing.proto.DeleteResultProto;
 import com.google.android.icing.proto.DocumentProto;
 import com.google.android.icing.proto.GetAllNamespacesResultProto;
+import com.google.android.icing.proto.GetNextPageRequestProto;
 import com.google.android.icing.proto.GetOptimizeInfoResultProto;
 import com.google.android.icing.proto.GetResultProto;
 import com.google.android.icing.proto.GetResultSpecProto;
@@ -213,9 +215,6 @@ public final class IcingSearchEngineTest {
     assertThat(getSchemaTypeResultProto.getSchemaTypeConfig()).isEqualTo(emailTypeConfig);
   }
 
-  // TODO: b/383379132 - Re-enable this test once the JNI API is pre-registered and dropped back
-  // into g3.
-  @Ignore
   @Test
   public void setAndGetSchemaWithDatabase_ok() throws Exception {
     IcingSearchEngineOptions options =
@@ -663,6 +662,83 @@ public final class IcingSearchEngineTest {
     assertThat(searchResultProto.getResultsCount()).isEqualTo(0);
   }
 
+  // TODO: b/417644758 - Re-enable this test once the JNI API is pre-registered and dropped back
+  // into g3.
+  @Ignore
+  @Test
+  public void getNextPageWithRequestProto() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    Map<String, DocumentProto> documents = new HashMap<>();
+    for (int i = 0; i < 10; i++) {
+      DocumentProto emailDocument =
+          createEmailDocument("namespace", "uri:" + i).toBuilder()
+              .addProperties(PropertyProto.newBuilder().setName("subject").addStringValues("foo"))
+              .build();
+      documents.put("uri:" + i, emailDocument);
+      assertWithMessage(icingSearchEngine.put(emailDocument).getStatus().getMessage())
+          .that(icingSearchEngine.put(emailDocument).getStatus().getCode())
+          .isEqualTo(StatusProto.Code.OK);
+    }
+
+    SearchSpecProto searchSpec =
+        SearchSpecProto.newBuilder()
+            .setQuery("foo")
+            .setTermMatchType(TermMatchType.Code.PREFIX)
+            .build();
+    ResultSpecProto resultSpecProto = ResultSpecProto.newBuilder().setNumPerPage(2).build();
+
+    SearchResultProto searchResultProto =
+        icingSearchEngine.search(
+            searchSpec, ScoringSpecProto.getDefaultInstance(), resultSpecProto);
+    assertStatusOk(searchResultProto.getStatus());
+    assertThat(searchResultProto.getResultsCount()).isEqualTo(2);
+    DocumentProto resultDocument1 = searchResultProto.getResults(0).getDocument();
+    DocumentProto resultDocument2 = searchResultProto.getResults(1).getDocument();
+    assertThat(resultDocument1).isEqualTo(documents.remove(resultDocument1.getUri()));
+    assertThat(resultDocument2).isEqualTo(documents.remove(resultDocument2.getUri()));
+
+    assertThat(searchResultProto.getQueryStats().hasNativeToJavaStartTimestampMs()).isTrue();
+    assertThat(searchResultProto.getQueryStats().hasNativeToJavaJniLatencyMs()).isTrue();
+    assertThat(searchResultProto.getQueryStats().hasJavaToNativeJniLatencyMs()).isTrue();
+    assertThat(searchResultProto.getQueryStats().getNativeToJavaStartTimestampMs())
+        .isGreaterThan(0);
+    assertThat(searchResultProto.getQueryStats().getNativeToJavaJniLatencyMs()).isAtLeast(0);
+    assertThat(searchResultProto.getQueryStats().getJavaToNativeJniLatencyMs()).isAtLeast(0);
+
+    GetNextPageRequestProto getNextPageRequestProto =
+        GetNextPageRequestProto.newBuilder()
+            .setNextPageToken(searchResultProto.getNextPageToken())
+            .setMaxResultsToRetrieveFromPage(1)
+            .build();
+    // fetch rest pages
+    for (int i = 1; i < 5; i++) {
+      searchResultProto = icingSearchEngine.getNextPage(getNextPageRequestProto);
+      DocumentProto resultDocument = searchResultProto.getResults(0).getDocument();
+      assertWithMessage(searchResultProto.getStatus().getMessage())
+          .that(searchResultProto.getStatus().getCode())
+          .isEqualTo(StatusProto.Code.OK);
+      assertThat(searchResultProto.getResultsCount()).isEqualTo(1);
+      assertThat(resultDocument).isEqualTo(documents.remove(resultDocument.getUri()));
+    }
+
+    // invalidate rest result
+    icingSearchEngine.invalidateNextPageToken(searchResultProto.getNextPageToken());
+
+    searchResultProto = icingSearchEngine.getNextPage(getNextPageRequestProto);
+    assertStatusOk(searchResultProto.getStatus());
+    assertThat(searchResultProto.getResultsCount()).isEqualTo(0);
+  }
+
   @Ignore // b/350530146
   @Test
   public void writeAndReadBlob_blobContentMatches() throws Exception {
@@ -1037,6 +1113,45 @@ public final class IcingSearchEngineTest {
     assertStatusOk(resetResultProto.getStatus());
   }
 
+  @Test
+  public void testClearAndDestroy() throws Exception {
+    assertStatusOk(icingSearchEngine.initialize().getStatus());
+
+    // Simple put and get
+    SchemaTypeConfigProto emailTypeConfig = createEmailTypeConfig();
+    SchemaProto schema = SchemaProto.newBuilder().addTypes(emailTypeConfig).build();
+    assertThat(
+            icingSearchEngine
+                .setSchema(schema, /* ignoreErrorsAndDeleteDocuments= */ false)
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.OK);
+
+    DocumentProto emailDocument = createEmailDocument("namespace", "uri");
+    PutResultProto putResultProto = icingSearchEngine.put(emailDocument);
+    assertStatusOk(putResultProto.getStatus());
+
+    GetResultProto getResultProto =
+        icingSearchEngine.get("namespace", "uri", GetResultSpecProto.getDefaultInstance());
+    assertStatusOk(getResultProto.getStatus());
+    assertThat(getResultProto.getDocument()).isEqualTo(emailDocument);
+
+    // Clear and destroy
+    ResetResultProto clearAndDestroyResult = icingSearchEngine.clearAndDestroy();
+    assertStatusOk(clearAndDestroyResult.getStatus());
+
+    // Try to put and get again, but it should fail since the instance is
+    // uninitialized after clearAndDestroy().
+    assertThat(icingSearchEngine.put(emailDocument).getStatus().getCode())
+        .isEqualTo(StatusProto.Code.FAILED_PRECONDITION);
+    assertThat(
+            icingSearchEngine
+                .get("namespace", "uri", GetResultSpecProto.getDefaultInstance())
+                .getStatus()
+                .getCode())
+        .isEqualTo(StatusProto.Code.FAILED_PRECONDITION);
+  }
+
   @Test
   public void testReportUsage() throws Exception {
     assertStatusOk(icingSearchEngine.initialize().getStatus());
@@ -1275,4 +1390,47 @@ public final class IcingSearchEngineTest {
   private static void assertStatusOk(StatusProto status) {
     assertWithMessage(status.getMessage()).that(status.getCode()).isEqualTo(StatusProto.Code.OK);
   }
+
+  @Test
+  @Ignore
+  // TODO: b/417644758 - Re-enable this test once the JNI API is pre-registered and dropped back
+  // into g3.
+  public void throwIfClosed() throws Exception {
+    icingSearchEngine.close();
+    assertThrows(IllegalStateException.class, () -> icingSearchEngine.initialize());
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.setSchema(SchemaProto.getDefaultInstance()));
+    assertThrows(IllegalStateException.class, () -> icingSearchEngine.getSchema());
+    assertThrows(IllegalStateException.class, () -> icingSearchEngine.getSchemaType("type"));
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.put(DocumentProto.getDefaultInstance()));
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.batchPut(PutDocumentRequest.getDefaultInstance()));
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.get("namespace", "uri", GetResultSpecProto.getDefaultInstance()));
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.batchGet(GetResultSpecProto.getDefaultInstance()));
+    assertThrows(IllegalStateException.class, () -> icingSearchEngine.optimize());
+    assertThrows(
+        IllegalStateException.class, () -> icingSearchEngine.persistToDisk(PersistType.Code.LITE));
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.reportUsage(UsageReport.getDefaultInstance()));
+    assertThrows(IllegalStateException.class, () -> icingSearchEngine.getStorageInfo());
+    assertThrows(
+        IllegalStateException.class,
+        () ->
+            icingSearchEngine.search(
+                SearchSpecProto.getDefaultInstance(),
+                ScoringSpecProto.getDefaultInstance(),
+                ResultSpecProto.getDefaultInstance()));
+    assertThrows(
+        IllegalStateException.class,
+        () -> icingSearchEngine.getNextPage(GetNextPageRequestProto.getDefaultInstance()));
+  }
 }
diff --git a/proto/icing/proto/initialize.proto b/proto/icing/proto/initialize.proto
index 5977aa9..e9c3cc2 100644
--- a/proto/icing/proto/initialize.proto
+++ b/proto/icing/proto/initialize.proto
@@ -137,7 +137,7 @@ message IcingSearchEngineMarkerProto {
   optional OperationType.Code operation_type = 1;
 }
 
-// Next tag: 35
+// Next tag: 41
 message IcingSearchEngineOptions {
   // Directory to persist files for Icing. Required.
   // If Icing was previously initialized with this directory, it will reload
@@ -193,6 +193,16 @@ message IcingSearchEngineOptions {
   // Optional.
   optional int32 compression_level = 7 [default = 3];
 
+  // Memory level for compression.
+  // 1 uses minimum memory but is slow and reduces compression ratio; 9 uses
+  // maximum memory for optimal speed and compression ratio.
+  // Icing historically used a memLevel of 8. Therefore, that value will be the
+  // default.
+  //
+  // Valid values: [1, 9]
+  // Optional.
+  optional int32 compression_mem_level = 37 [default = 8];
+
   // OPTIONAL: Whether to allow circular references between schema types for
   // the schema definition.
   //
@@ -290,6 +300,16 @@ message IcingSearchEngineOptions {
   // Optional.
   optional int32 blob_store_compression_level = 23 [default = 3];
 
+  // Memory level for compression in blob store.
+  // 1 uses minimum memory but is slow and reduces compression ratio; 9 uses
+  // maximum memory for optimal speed and compression ratio.
+  // Icing historically used a memLevel of 8. Therefore, that value will be the
+  // default.
+  //
+  // Valid values: [1, 9]
+  // Optional.
+  optional int32 blob_store_compression_mem_level = 38 [default = 8];
+
   // Whether to allow repeated fields to have a joinable value type.
   optional bool enable_repeated_field_joins = 24;
 
@@ -361,6 +381,28 @@ message IcingSearchEngineOptions {
   // the overlay exists.
   optional bool release_backup_schema_file_if_overlay_present = 34;
 
+  // Whether to enable strict byte size enforcement on a result page.
+  // - If set to true, then ResultRetrieverV2 will not include the next result
+  //   document if it would exceed the page byte size threshold (except for the
+  //   first document).
+  // - Otherwise, the page byte size enforcement works as a soft limit, i.e. it
+  //   will keep adding documents until exceeding the threshold.
+  optional bool enable_strict_page_byte_size_limit = 35;
+
+  // The threshold in bytes for compressing documents. If a document is larger
+  // than or equal to this threshold, it will be compressed based on
+  // compression_level. 0 means always compress.
+  optional uint32 compression_threshold_bytes = 36;
+
+  // Whether to enable using smaller input buffer size for decompression
+  // If set to false, the default buffer size of 64kb will be used.
+  optional bool enable_smaller_decompression_buffer_size = 39;
+
+  // Whether to enable the Eigen library for embedding scoring.
+  // If set to true **and** Eigen is compiled in (when ICING_DISABLE_EIGEN is
+  // not defined), Eigen will be used for embedding scoring.
+  optional bool enable_eigen_embedding_scoring = 40;
+
   reserved 2, 20;
 }
 
diff --git a/proto/icing/proto/logging.proto b/proto/icing/proto/logging.proto
index 2e620cd..a0dde29 100644
--- a/proto/icing/proto/logging.proto
+++ b/proto/icing/proto/logging.proto
@@ -24,7 +24,7 @@ option java_multiple_files = true;
 option objc_class_prefix = "ICNG";
 
 // Stats of the top-level function IcingSearchEngine::Initialize().
-// Next tag: 17
+// Next tag: 18
 message InitializeStatsProto {
   // Overall time used for the function call.
   optional int32 latency_ms = 1;
@@ -150,6 +150,64 @@ message InitializeStatsProto {
 
   // Number of documents that failed to be reindexed during index restoration.
   optional int32 num_failed_reindexed_documents = 16;
+
+  // A number indicating which stage of initialization failed.
+  message FailureStage {
+    enum Code {
+      NONE = 0;
+
+      OPTIONS_VALIDATION = 1;
+
+      BASE_DIRECTORY_CREATION = 2;
+
+      INIT_MARKER_FILE = 3;
+
+      READ_VERSION_FILE = 4;
+
+      MIGRATE_SCHEMA = 5;
+
+      DISCARD_DERIVED_FILES = 6;
+
+      WRITE_VERSION_FILE = 7;
+
+      SCHEMA_STORE_DIRECTORY_CREATION = 8;
+
+      SCHEMA_STORE_INSTANTIATION = 9;
+
+      LANGUAGE_SEGMENTER_CREATION = 10;
+
+      NORMALIZER_CREATION = 11;
+
+      // Discard any components, including delete the directory or call discard
+      // function of an index.
+      DISCARD_COMPONENTS = 12;
+
+      BLOB_STORE_INSTANTIATION = 13;
+
+      DOCUMENT_STORE_DIRECTORY_CREATION = 14;
+
+      DOCUMENT_STORE_INSTANTIATION = 15;
+
+      TERM_INDEX_DIRECTORY = 16;
+
+      TERM_INDEX_INSTANTIATION = 17;
+
+      INTEGER_INDEX_DIRECTORY = 18;
+
+      INTEGER_INDEX_INSTANTIATION = 19;
+
+      QUALIFIED_ID_JOIN_INDEX_DIRECTORY = 20;
+
+      QUALIFIED_ID_JOIN_INDEX_INSTANTIATION = 21;
+
+      EMBEDDING_INDEX_DIRECTORY = 22;
+
+      EMBEDDING_INDEX_INSTANTIATION = 23;
+
+      RESTORE_INDEX = 24;
+    }
+  }
+  optional FailureStage.Code failure_stage = 17;
 }
 
 // Stats of the top-level function IcingSearchEngine::Put().
@@ -206,7 +264,7 @@ message PutDocumentStatsProto {
 
 // Stats of the top-level function IcingSearchEngine::Search() and
 // IcingSearchEngine::GetNextPage().
-// Next tag: 28
+// Next tag: 30
 message QueryStatsProto {
   // TODO(b/305098009): deprecate. Use parent_search_stats instead.
   // The UTF-8 length of the query string
@@ -349,6 +407,28 @@ message QueryStatsProto {
   // Byte size of the unsorted tail of the lite index hit buffer.
   optional int64 lite_index_hit_buffer_unsorted_byte_size = 27;
 
+  message PageTokenType {
+    enum Code {
+      // Default. Usually used when it is the first page.
+      NONE = 0;
+
+      VALID = 1;
+
+      // The current page token is not found in ResultStateManager. This is
+      // usually caused by cache eviction.
+      NOT_FOUND = 2;
+
+      // The current page token is empty (kInvalidNextPageToken).
+      EMPTY = 3;
+    }
+  }
+  // The type of the input page token.
+  optional PageTokenType.Code page_token_type = 28;
+
+  // Number of result states being force-evicted from ResultStateManager due to
+  // budget limit. This doesn't include expired or invalidated states.
+  optional int32 num_result_states_evicted = 29;
+
   reserved 9;
 }
 
diff --git a/proto/icing/proto/optimize.proto b/proto/icing/proto/optimize.proto
index 0ba0a86..cc35db6 100644
--- a/proto/icing/proto/optimize.proto
+++ b/proto/icing/proto/optimize.proto
@@ -46,7 +46,7 @@ message OptimizeResultProto {
 }
 
 // Result of a call to IcingSearchEngine.GetOptimizeInfo
-// Next tag: 5
+// Next tag: 7
 message GetOptimizeInfoResultProto {
   // Status code can be one of:
   //   OK
@@ -66,6 +66,18 @@ message GetOptimizeInfoResultProto {
 
   // The amount of time since the last optimize ran.
   optional int64 time_since_last_optimize_ms = 4;
+
+  // True if there is no previous optimize info written to disk. This would
+  // indicate that Icing has never run optimize before.
+  optional bool no_previous_optimize_info = 5;
+
+  // The number of active result states in ResultStateManager.
+  //
+  // If this number is not 0, then the caller should avoid running optimize as
+  // much as possible to avoid result state manager reset and interrupted
+  // pagination, unless the last optimize run was a long time ago which exceeds
+  // the threshold.
+  optional int32 num_active_result_states = 6;
 }
 
 // Next tag: 14
diff --git a/proto/icing/proto/schema.proto b/proto/icing/proto/schema.proto
index 1f7eb4b..0f73fd2 100644
--- a/proto/icing/proto/schema.proto
+++ b/proto/icing/proto/schema.proto
@@ -455,7 +455,7 @@ message SetSchemaRequestProto {
 }
 
 // Result of a call to IcingSearchEngine.SetSchema
-// Next tag: 9
+// Next tag: 10
 message SetSchemaResultProto {
   // Status code can be one of:
   //   OK
@@ -502,6 +502,10 @@ message SetSchemaResultProto {
   // but changed to joinable in the new definition. In this case, this property
   // will be considered join incompatible when setting new schema.
   repeated string join_incompatible_changed_schema_types = 8;
+
+  // Number of documents that were deleted due to the new schema with
+  // ignore_errors_and_delete_documents enabled.
+  optional int32 deleted_document_count = 9;
 }
 
 // Result of a call to IcingSearchEngine.GetSchema
diff --git a/proto/icing/proto/search.proto b/proto/icing/proto/search.proto
index 40de819..871f306 100644
--- a/proto/icing/proto/search.proto
+++ b/proto/icing/proto/search.proto
@@ -382,7 +382,7 @@ message SnippetProto {
 }
 
 // Icing lib-supplied results from a search results.
-// Next tag: 6
+// Next tag: 7
 message SearchResultProto {
   // Status code can be one of:
   //   OK
@@ -442,6 +442,14 @@ message SearchResultProto {
 
   // Stats for query execution performance.
   optional QueryStatsProto query_stats = 5;
+
+  // This field is used only in the GetNextPage API.
+  //
+  // Whether GetNextPage returning an empty result is due to page token not
+  // found (mostly caused by cache eviction). If the client needs the entire set
+  // of result documents (as their ground truth), then they should restart the
+  // query via Search API when this field is true.
+  optional bool page_token_not_found = 6;
 }
 
 // Next tag: 3
@@ -638,3 +646,23 @@ message JoinSpecProto {
   }
   optional AggregationScoringStrategy.Code aggregation_scoring_strategy = 5;
 }
+
+// Next tag: 3
+message GetNextPageRequestProto {
+  // REQUIRED: The next page token to use for retrieving the next page of
+  // results.
+  //
+  // This is a token returned from a previous Search or GetNextPage
+  // call. The retrieved SearchResultProto will be empty if this token is
+  // invalid (value of 0, or previously invalidated by Icing)
+  optional int64 next_page_token = 1;
+
+  // The max number of results to return from the page.
+  //
+  // This is only an upper limit on the number of results to fetch from the
+  // page. Fewer results may be returned if there are not enough results
+  // remaining in the page, or if other limits (e.g. page size limit) are
+  // reached.
+  optional int32 max_results_to_retrieve_from_page = 2
+      [default = 2147483647];  // INT_MAX
+}
diff --git a/proto/icing/proto/status.proto b/proto/icing/proto/status.proto
index 06ec6c4..4b97e91 100644
--- a/proto/icing/proto/status.proto
+++ b/proto/icing/proto/status.proto
@@ -18,13 +18,12 @@ package icing.lib;
 
 option java_package = "com.google.android.icing.proto";
 option java_multiple_files = true;
-
 option objc_class_prefix = "ICNG";
 
 // Canonical status to indicate the results of API calls.
 // Next tag: 3
 message StatusProto {
-  // Next tag: 10
+  // Next tag: 11
   enum Code {
     // A default for all other use-cases. Should never be used in practice. This
     // may happen if there are backwards-compatibility issues.
@@ -71,6 +70,9 @@ message StatusProto {
     // same name within a type.
     ALREADY_EXISTS = 9;
 
+    // The system is unavailable to process the requested operation.
+    UNAVAILABLE = 10;
+
     // Any future status codes.
   }
   optional Code code = 1;
diff --git a/synced_AOSP_CL_number.txt b/synced_AOSP_CL_number.txt
index 305570d..a765dba 100644
--- a/synced_AOSP_CL_number.txt
+++ b/synced_AOSP_CL_number.txt
@@ -1 +1 @@
-set(synced_AOSP_CL_number=738860467)
+set(synced_AOSP_CL_number=765296558)
```

