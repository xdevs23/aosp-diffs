```diff
diff --git a/PREUPLOAD.cfg b/PREUPLOAD.cfg
index 011462597b..777d9fce2b 100644
--- a/PREUPLOAD.cfg
+++ b/PREUPLOAD.cfg
@@ -3,6 +3,9 @@ mainline_hook = ${REPO_ROOT}/frameworks/av/tools/mainline_hook_partial.sh ${REPO
 
 hidden_api_txt_checksorted_hook = ${REPO_ROOT}/tools/platform-compat/hiddenapi/checksorted_sha.sh ${PREUPLOAD_COMMIT} ${REPO_ROOT}
 
+# go/alint for details
+alint_hook = ${REPO_ROOT}/vendor/google/tools/alint
+
 [Builtin Hooks]
 bpfmt = true
 clang_format = true
diff --git a/apex/Android.bp b/apex/Android.bp
index 30b359dc30..cbe3e3c01e 100644
--- a/apex/Android.bp
+++ b/apex/Android.bp
@@ -86,6 +86,10 @@ apex {
     manifest: "manifest.json",
     defaults: ["com.android.media-defaults"],
     prebuilts: ["current_sdkinfo"],
+    licenses: [
+        "frameworks_av_license",
+        "opensourcerequest",
+    ],
 }
 
 linker_config {
@@ -185,6 +189,7 @@ apex_defaults {
         "com.android.media.swcodec-ld.config.txt",
         "mediaswcodec.policy",
         "code_coverage.policy",
+        "crash_dump.no_mmap_mprotect_prctl.policy",
         "crash_dump.policy",
         "mediaswcodec.xml",
     ],
@@ -250,6 +255,10 @@ apex {
     name: "com.android.media.swcodec",
     manifest: "manifest_codec.json",
     defaults: ["com.android.media.swcodec-defaults"],
+    licenses: [
+        "frameworks_av_license",
+        "opensourcerequest",
+    ],
 }
 
 apex_key {
diff --git a/camera/CameraMetadata.cpp b/camera/CameraMetadata.cpp
index 05d078be95..203f27650c 100644
--- a/camera/CameraMetadata.cpp
+++ b/camera/CameraMetadata.cpp
@@ -24,6 +24,8 @@
 #include <camera/CameraMetadata.h>
 #include <camera_metadata_hidden.h>
 
+#include <algorithm>
+
 namespace android {
 
 #define ALIGN_TO(val, alignment) \
diff --git a/camera/aidl/android/hardware/ICameraService.aidl b/camera/aidl/android/hardware/ICameraService.aidl
index 779c4a2abf..18f7c237ec 100644
--- a/camera/aidl/android/hardware/ICameraService.aidl
+++ b/camera/aidl/android/hardware/ICameraService.aidl
@@ -75,6 +75,7 @@ interface ICameraService
      */
     int getNumberOfCameras(int type, in AttributionSourceState clientAttribution, int devicePolicy);
 
+    // TODO(b/414347702): Revisit data structure.
     /**
      * If changed, reflect in
      * frameworks/base/core/java/android/hardware/camera2/CameraManager.java.
@@ -88,6 +89,7 @@ interface ICameraService
     const int ROTATION_OVERRIDE_NONE = 0;
     const int ROTATION_OVERRIDE_OVERRIDE_TO_PORTRAIT = 1;
     const int ROTATION_OVERRIDE_ROTATION_ONLY = 2;
+    const int ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE = 3;
 
     /**
      * Fetch basic camera information for a camera.
diff --git a/camera/camera2/OutputConfiguration.cpp b/camera/camera2/OutputConfiguration.cpp
index 2f1648385c..43c5570b60 100644
--- a/camera/camera2/OutputConfiguration.cpp
+++ b/camera/camera2/OutputConfiguration.cpp
@@ -376,6 +376,42 @@ status_t OutputConfiguration::readFromParcel(const android::Parcel* parcel) {
     return err;
 }
 
+
+void OutputConfiguration::inferSurfaceProperties() {
+    if (mSurfaces.empty()) {
+        return;
+    }
+
+#if WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
+    if (mSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_FORMAT, &mFormat) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_FORMAT query failed", __FUNCTION__);
+    }
+    if (mSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_DEFAULT_DATASPACE,
+            &mDataspace) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_DEFAULT_DATASPACE query failed", __FUNCTION__);
+    }
+    if (mSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_WIDTH, &mWidth) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_WIDTH query failed", __FUNCTION__);
+    }
+    if (mSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_HEIGHT, &mHeight) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_HEIGHT query failed", __FUNCTION__);
+    }
+#else
+    if (mSurfaces[0]->query(NATIVE_WINDOW_FORMAT, &mFormat) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_FORMAT query failed", __FUNCTION__);
+    }
+    if (mSurfaces[0]->query(NATIVE_WINDOW_DEFAULT_DATASPACE, &mDataspace) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_DEFAULT_DATASPACE query failed", __FUNCTION__);
+    }
+    if (mSurfaces[0]->query(NATIVE_WINDOW_WIDTH, &mWidth) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_WIDTH query failed", __FUNCTION__);
+    }
+    if (mSurfaces[0]->query(NATIVE_WINDOW_HEIGHT, &mHeight) != OK) {
+        ALOGE("%s: NATIVE_WINDOW_HEIGHT query failed", __FUNCTION__);
+    }
+#endif
+}
+
 OutputConfiguration::OutputConfiguration(ParcelableSurfaceType& surface, int rotation,
         const std::string& physicalId,
         int surfaceSetID, bool isShared) {
@@ -396,12 +432,13 @@ OutputConfiguration::OutputConfiguration(ParcelableSurfaceType& surface, int rot
     mFormat = HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED;
     mDataspace = 0;
     mUsage = 0;
+    inferSurfaceProperties();
 }
 
 OutputConfiguration::OutputConfiguration(
         const std::vector<ParcelableSurfaceType>& surfaces,
     int rotation, const std::string& physicalCameraId, int surfaceSetID,  int surfaceType,
-    int width, int height, bool isShared)
+    int width, int height, bool isShared, int format, int dataSpace)
   : mSurfaces(surfaces), mRotation(rotation), mSurfaceSetID(surfaceSetID),
     mSurfaceType(surfaceType), mWidth(width), mHeight(height), mIsDeferred(false),
     mIsShared(isShared), mPhysicalCameraId(physicalCameraId), mIsMultiResolution(false),
@@ -410,8 +447,8 @@ OutputConfiguration::OutputConfiguration(
     mStreamUseCase(ANDROID_SCALER_AVAILABLE_STREAM_USE_CASES_DEFAULT),
     mTimestampBase(TIMESTAMP_BASE_DEFAULT),
     mMirrorMode(MIRROR_MODE_AUTO), mMirrorModeForProducers(surfaces.size(), mMirrorMode),
-    mUseReadoutTimestamp(false), mFormat(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED),
-    mDataspace(0), mUsage(0) { }
+    mUseReadoutTimestamp(false), mFormat(format),
+    mDataspace(dataSpace), mUsage(0) { }
 
 status_t OutputConfiguration::writeToParcel(android::Parcel* parcel) const {
 
diff --git a/camera/camera_platform.aconfig b/camera/camera_platform.aconfig
index 2b425b1654..10dcde3860 100644
--- a/camera/camera_platform.aconfig
+++ b/camera/camera_platform.aconfig
@@ -102,16 +102,6 @@ flag {
     bug: "316375635"
 }
 
-flag {
-    namespace: "camera_platform"
-    name: "single_thread_executor_naming"
-    description: "Set the device executor thread name."
-    bug: "359709863"
-    metadata {
-        purpose: PURPOSE_BUGFIX
-    }
-}
-
 flag {
     namespace: "camera_platform"
     name: "analytics_24q3"
@@ -119,36 +109,6 @@ flag {
     bug: "332557570"
 }
 
-flag {
-    namespace: "camera_platform"
-    name: "multi_res_raw_reprocessing"
-    description: "Allow multi-resolution raw reprocessing without reprocessing capability"
-    bug: "336922859"
-    metadata {
-        purpose: PURPOSE_BUGFIX
-    }
-}
-
-flag {
-    namespace: "camera_platform"
-    name: "api1_release_binderlock_before_cameraservice_disconnect"
-    description: "Drop mSerializationLock in Camera1 client when calling into CameraService"
-    bug: "351778072"
-    metadata {
-        purpose: PURPOSE_BUGFIX
-    }
-}
-
-flag {
-    namespace: "camera_platform"
-    name: "bump_preview_frame_space_priority"
-    description: "Increase the PreviewFrameSpacer thread priority"
-    bug: "355665306"
-    metadata {
-        purpose: PURPOSE_BUGFIX
-    }
-}
-
 flag {
     namespace: "camera_platform"
     name: "dumpsys_request_stream_ids"
@@ -173,14 +133,6 @@ flag {
     bug: "341740105"
 }
 
-flag {
-    namespace: "camera_platform"
-    name: "data_delivery_permission_checks"
-    description: "Pass the full AttributionSource chain to PermissionChecker for data delivery"
-    bug: "190657833"
-    is_fixed_read_only: true
-}
-
 flag {
     namespace: "camera_platform"
     name: "depth_jpeg_extensions"
@@ -273,10 +225,16 @@ flag {
 
 flag {
     namespace: "camera_platform"
-    name: "metadata_resize_fix"
-    description: "metadata resize during update needs to consider existing entry"
-    bug: "379388099"
-    metadata {
-        purpose: PURPOSE_BUGFIX
-    }
+    name: "data_delivery_permission_checks"
+    description: "Pass the full AttributionSource chain to PermissionChecker for data delivery"
+    bug: "190657833"
+    is_fixed_read_only: true
+}
+
+flag {
+    namespace: "camera_platform"
+    name: "output_configuration_getter"
+    is_exported: true
+    description: "Unhide the size and format getters in OutputConfiguration class"
+    bug: "383609887"
 }
diff --git a/camera/cameraserver/main_cameraserver.cpp b/camera/cameraserver/main_cameraserver.cpp
index c49473267a..bcaa7f1e23 100644
--- a/camera/cameraserver/main_cameraserver.cpp
+++ b/camera/cameraserver/main_cameraserver.cpp
@@ -18,7 +18,6 @@
 //#define LOG_NDEBUG 0
 
 #include "CameraService.h"
-#include <android/binder_process.h>
 #include <hidl/HidlTransportSupport.h>
 
 using namespace android;
@@ -30,18 +29,12 @@ int main(int argc __unused, char** argv __unused)
     // Set 5 threads for HIDL calls. Now cameraserver will serve HIDL calls.
     hardware::configureRpcThreadpool(5, /*willjoin*/ false);
 
-    // Set 5 threads for VNDK AIDL calls. Now cameraserver will serve
-    // VNDK AIDL calls in addition to consuming them from the Camera HAL as well.
-    ABinderProcess_setThreadPoolMaxThreadCount(5);
-
     sp<ProcessState> proc(ProcessState::self());
     sp<IServiceManager> sm = defaultServiceManager();
     ALOGI("ServiceManager: %p", sm.get());
     CameraService::instantiate();
     ALOGI("ServiceManager: %p done instantiate", sm.get());
     ProcessState::self()->startThreadPool();
-    ABinderProcess_startThreadPool();
 
     IPCThreadState::self()->joinThreadPool();
-    ABinderProcess_joinThreadPool();
 }
diff --git a/camera/include/camera/camera2/OutputConfiguration.h b/camera/include/camera/camera2/OutputConfiguration.h
index 13bedb3ee1..f43001426f 100644
--- a/camera/include/camera/camera2/OutputConfiguration.h
+++ b/camera/include/camera/camera2/OutputConfiguration.h
@@ -18,6 +18,7 @@
 #define ANDROID_HARDWARE_CAMERA2_OUTPUTCONFIGURATION_H
 
 #include <string>
+#include "system/graphics-base-v1.0.h"
 
 #include <gui/Flags.h>  // remove with WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
 #if WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
@@ -113,7 +114,10 @@ public:
                         int rotation, const std::string& physicalCameraId,
                         int surfaceSetID = INVALID_SET_ID,
                         int surfaceType = SURFACE_TYPE_UNKNOWN, int width = 0,
-                        int height = 0, bool isShared = false);
+                        int height = 0, bool isShared = false,
+                        int format = HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED,
+                        int dataspace = 0);
+
     OutputConfiguration(int surfaceType, int width, int height, int format, int32_t colorSpace,
             int mirrorMode, bool useReadoutTimestamp,int timestampBase, int dataspace,
             int64_t usage, int64_t streamusecase, std::string physicalCamId);
@@ -247,6 +251,8 @@ public:
     }
 
 private:
+
+    void inferSurfaceProperties();
     std::vector<ParcelableSurfaceType>  mSurfaces;
     int                        mRotation;
     int                        mSurfaceSetID;
diff --git a/camera/ndk/impl/ACameraDevice.cpp b/camera/ndk/impl/ACameraDevice.cpp
index fc2117269b..9bc93ae344 100644
--- a/camera/ndk/impl/ACameraDevice.cpp
+++ b/camera/ndk/impl/ACameraDevice.cpp
@@ -243,7 +243,7 @@ camera_status_t CameraDevice::isSessionConfigurationSupported(
 
         ParcelableSurfaceType pSurface = flagtools::convertSurfaceTypeToParcelable(surface);
         OutputConfiguration outConfig(pSurface, output.mRotation, output.mPhysicalCameraId,
-                OutputConfiguration::INVALID_SET_ID, true);
+                OutputConfiguration::INVALID_SET_ID, output.mIsShared);
 
         for (auto& anw : output.mSharedWindows) {
             ret = getSurfacefromAnw(anw, surface);
@@ -331,7 +331,7 @@ camera_status_t CameraDevice::updateOutputConfigurationLocked(ACaptureSessionOut
 
     ParcelableSurfaceType pSurface = flagtools::convertSurfaceTypeToParcelable(surface);
     OutputConfiguration outConfig(pSurface, output->mRotation, output->mPhysicalCameraId,
-                                  OutputConfiguration::INVALID_SET_ID, true);
+                                  OutputConfiguration::INVALID_SET_ID, output->mIsShared);
 
     for (auto& anw : output->mSharedWindows) {
         ret = getSurfacefromAnw(anw, surface);
@@ -427,7 +427,7 @@ camera_status_t CameraDevice::prepareLocked(ANativeWindow *window) {
 
 camera_status_t
 CameraDevice::allocateCaptureRequest(
-        const ACaptureRequest* request, /*out*/sp<CaptureRequest>& outReq) {
+        const ACaptureRequest* request, /*out*/sp<CaptureRequest>& outReq, bool *isZsl) {
     camera_status_t ret;
     sp<CaptureRequest> req(new CaptureRequest());
     req->mPhysicalCameraSettings.push_back({getId(),
@@ -436,6 +436,13 @@ CameraDevice::allocateCaptureRequest(
         req->mPhysicalCameraSettings.push_back({entry.first,
                 entry.second->getInternalData()});
     }
+    if (isZsl != nullptr) {
+        auto meta = request->settings->getInternalData();
+        auto entry = meta.find(ANDROID_CONTROL_ENABLE_ZSL);
+        if (entry.count > 0 && (entry.data.u8[0] == ACAMERA_CONTROL_ENABLE_ZSL_TRUE)) {
+            *isZsl = true;
+        }
+    }
     req->mIsReprocess = false; // NDK does not support reprocessing yet
     req->mContext = request->context;
     req->mSurfaceConverted = true; // set to true, and fill in stream/surface idx to speed up IPC
@@ -575,7 +582,7 @@ CameraDevice::stopRepeatingLocked() {
         binder::Status remoteRet = mRemote->cancelRequest(repeatingSequenceId, &lastFrameNumber);
         if (remoteRet.serviceSpecificErrorCode() ==
                 hardware::ICameraService::ERROR_ILLEGAL_ARGUMENT) {
-            ALOGV("Repeating request is already stopped.");
+            ALOGD("Repeating request is already stopped.");
             return ACAMERA_OK;
         } else if (!remoteRet.isOk()) {
             ALOGE("Stop repeating request fails in remote: %s", remoteRet.toString8().c_str());
@@ -866,14 +873,32 @@ CameraDevice::setCameraDeviceErrorLocked(camera_status_t error) {
 }
 
 void
-CameraDevice::FrameNumberTracker::updateTracker(int64_t frameNumber, bool isError) {
-    ALOGV("updateTracker frame %" PRId64 " isError %d", frameNumber, isError);
+CameraDevice::FrameNumberTracker::updateTracker(int64_t frameNumber, bool isError,
+        bool isZsl) {
+    ALOGV("updateTracker frame %" PRId64 " isError %d isZsl %d", frameNumber, isError, isZsl);
     if (isError) {
         mFutureErrorSet.insert(frameNumber);
-    } else if (frameNumber <= mCompletedFrameNumber) {
+        update();
+        return;
+    }
+
+    if (isZsl && (frameNumber < mZslCompletedFrameNumber)) {
+        ALOGE("ZSL Frame number %" PRId64 " decreased! current fn %" PRId64,
+                frameNumber, mZslCompletedFrameNumber);
+        return;
+    }
+
+    if (!isZsl && (frameNumber < mCompletedFrameNumber)) {
         ALOGE("Frame number %" PRId64 " decreased! current fn %" PRId64,
                 frameNumber, mCompletedFrameNumber);
         return;
+    }
+
+    if (isZsl) {
+        mZslCompletedFrameNumber = frameNumber;
+        if (mZslCompletedFrameNumber == (mCompletedFrameNumber + 1)) {
+            mCompletedFrameNumber++;
+        }
     } else {
         if (frameNumber != mCompletedFrameNumber + 1) {
             ALOGE("Frame number out of order. Expect %" PRId64 " but get %" PRId64,
@@ -994,7 +1019,7 @@ CameraDevice::onCaptureErrorLocked(
         postSessionMsgAndCleanup(msg);
 
         // Update tracker
-        mFrameNumberTracker.updateTracker(frameNumber, /*isError*/true);
+        mFrameNumberTracker.updateTracker(frameNumber, /*isError*/true, false);
         checkAndFireSequenceCompleteLocked();
     }
     return;
@@ -1574,17 +1599,20 @@ CameraDevice::checkRepeatingSequenceCompleteLocked(
 void
 CameraDevice::checkAndFireSequenceCompleteLocked() {
     int64_t completedFrameNumber = mFrameNumberTracker.getCompletedFrameNumber();
+    int64_t completedZslFrameNumber = mFrameNumberTracker.getCompletedZslFrameNumber();
     auto it = mSequenceLastFrameNumberMap.begin();
     while (it != mSequenceLastFrameNumberMap.end()) {
         int sequenceId = it->first;
         int64_t lastFrameNumber = it->second.lastFrameNumber;
+        bool isZsl = it->second.isZsl;
 
         if (mRemote == nullptr) {
             ALOGW("Camera %s closed while checking sequence complete", getId());
             return;
         }
-        ALOGV("%s: seq %d's last frame number %" PRId64 ", completed %" PRId64,
-                __FUNCTION__, sequenceId, lastFrameNumber, completedFrameNumber);
+        ALOGV("%s: seq %d's isZsl: %d last frame number %" PRId64 " completed %" PRId64
+                " completedZslFrameNumber %" PRId64, __FUNCTION__, sequenceId, isZsl,
+                lastFrameNumber, completedFrameNumber, completedZslFrameNumber);
         if (!it->second.isSequenceCompleted) {
             // Check if there is callback for this sequence
             // This should not happen because we always register callback (with nullptr inside)
@@ -1592,7 +1620,12 @@ CameraDevice::checkAndFireSequenceCompleteLocked() {
                 ALOGW("No callback found for sequenceId %d", sequenceId);
             }
 
-            if (lastFrameNumber <= completedFrameNumber) {
+            if (isZsl) {
+                if(lastFrameNumber <= completedZslFrameNumber) {
+                    ALOGV("Mark ZSL sequenceId %d as sequence completed", sequenceId);
+                    it->second.isSequenceCompleted = true;
+                }
+            } else if (lastFrameNumber <= completedFrameNumber) {
                 ALOGV("Mark sequenceId %d as sequence completed", sequenceId);
                 it->second.isSequenceCompleted = true;
             }
@@ -1601,7 +1634,6 @@ CameraDevice::checkAndFireSequenceCompleteLocked() {
 
         if (it->second.isSequenceCompleted && it->second.isInflightCompleted) {
             sendCaptureSequenceCompletedLocked(sequenceId, lastFrameNumber);
-
             it = mSequenceLastFrameNumberMap.erase(it);
             ALOGV("%s: Remove holder for sequenceId %d", __FUNCTION__, sequenceId);
         } else {
@@ -1863,9 +1895,16 @@ CameraDevice::ServiceCallback::onResultReceived(
         return ret; // device has been disconnected
     }
 
+    bool isZsl = false;
+    auto itt = dev->mSequenceLastFrameNumberMap.find(sequenceId);
+    if (itt != dev->mSequenceLastFrameNumberMap.end()) {
+        isZsl = itt->second.isZsl;
+    }
+
     if (dev->isClosed()) {
         if (!isPartialResult) {
-            dev->mFrameNumberTracker.updateTracker(frameNumber, /*isError*/false);
+            dev->mFrameNumberTracker.updateTracker(frameNumber, /*isError*/false,
+                    isZsl);
         }
         // early return to avoid callback sent to closed devices
         return ret;
@@ -1934,7 +1973,8 @@ CameraDevice::ServiceCallback::onResultReceived(
     }
 
     if (!isPartialResult) {
-        dev->mFrameNumberTracker.updateTracker(frameNumber, /*isError*/false);
+        dev->mFrameNumberTracker.updateTracker(frameNumber, /*isError*/false,
+                isZsl);
         dev->checkAndFireSequenceCompleteLocked();
     }
 
diff --git a/camera/ndk/impl/ACameraDevice.h b/camera/ndk/impl/ACameraDevice.h
index 067923c649..9e920eb546 100644
--- a/camera/ndk/impl/ACameraDevice.h
+++ b/camera/ndk/impl/ACameraDevice.h
@@ -179,7 +179,8 @@ class CameraDevice final : public RefBase {
     camera_status_t prepareLocked(ANativeWindow *window);
 
     camera_status_t allocateCaptureRequest(
-            const ACaptureRequest* request, sp<CaptureRequest>& outReq);
+            const ACaptureRequest* request, sp<CaptureRequest>& outReq,
+            bool *isZsl = nullptr/*out*/);
 
     static ACaptureRequest* allocateACaptureRequest(sp<CaptureRequest>& req,
             const std::string& deviceId);
@@ -314,6 +315,8 @@ class CameraDevice final : public RefBase {
         // set to true, but not removed from the map yet if the capture results
         // haven't been delivered to the app yet.
         bool isInflightCompleted = false;
+        // Whether the inflight request is of type ZSL
+        bool isZsl = false;
         RequestLastFrameNumberHolder(int64_t lastFN) :
                 lastFrameNumber(lastFN) {}
     };
@@ -400,13 +403,15 @@ class CameraDevice final : public RefBase {
     class FrameNumberTracker {
       public:
         // TODO: Called in onResultReceived and onCaptureErrorLocked
-        void updateTracker(int64_t frameNumber, bool isError);
+        void updateTracker(int64_t frameNumber, bool isError, bool isZsl);
         inline int64_t getCompletedFrameNumber() { return mCompletedFrameNumber; }
+        inline int64_t getCompletedZslFrameNumber() { return mZslCompletedFrameNumber; }
       private:
         void update();
         void updateCompletedFrameNumber(int64_t frameNumber);
 
         int64_t mCompletedFrameNumber = NO_FRAMES_CAPTURED;
+        int64_t mZslCompletedFrameNumber = NO_FRAMES_CAPTURED;
         List<int64_t> mSkippedFrameNumbers;
         std::set<int64_t> mFutureErrorSet;
     };
diff --git a/camera/ndk/impl/ACameraDevice.inc b/camera/ndk/impl/ACameraDevice.inc
index 7e70d3989d..0f5922641a 100644
--- a/camera/ndk/impl/ACameraDevice.inc
+++ b/camera/ndk/impl/ACameraDevice.inc
@@ -63,9 +63,16 @@ camera_status_t CameraDevice::submitRequestsLocked(
     std::vector<hardware::camera2::CaptureRequest> requestList;
     Vector<sp<CaptureRequest> > requestsV;
     requestsV.setCapacity(numRequests);
+    // Check if we have a ZSL capture request.
+    // Capture sequences with ZSL enabled may return frame numbers that
+    // appear out of order relative to regular & repeating requests.
+    // The callbacks for such ZSL capture sequences may need to be kept
+    // for longer compared to regular/non-ZSL requests.
+    bool isZsl = false;
     for (int i = 0; i < numRequests; i++) {
         sp<CaptureRequest> req;
-        ret = allocateCaptureRequest(requests[i], req);
+        bool zslRequest = false;
+        ret = allocateCaptureRequest(requests[i], req, &zslRequest);
         if (ret != ACAMERA_OK) {
             ALOGE("Convert capture request to internal format failure! ret %d", ret);
             return ret;
@@ -76,6 +83,7 @@ camera_status_t CameraDevice::submitRequestsLocked(
         }
         requestList.push_back(*(req.get()));
         requestsV.push_back(req);
+        isZsl |= zslRequest;
     }
 
     if (isRepeating) {
@@ -107,7 +115,9 @@ camera_status_t CameraDevice::submitRequestsLocked(
         }
         mRepeatingSequenceId = sequenceId;
     } else {
-        mSequenceLastFrameNumberMap.insert(std::make_pair(sequenceId, lastFrameNumber));
+        RequestLastFrameNumberHolder holder(lastFrameNumber);
+        holder.isZsl = isZsl;
+        mSequenceLastFrameNumberMap.insert(std::make_pair(sequenceId, holder));
     }
 
     if (mIdle) {
diff --git a/camera/ndk/include/camera/NdkCameraMetadataTags.h b/camera/ndk/include/camera/NdkCameraMetadataTags.h
index 2234bedabd..12f5756a22 100644
--- a/camera/ndk/include/camera/NdkCameraMetadataTags.h
+++ b/camera/ndk/include/camera/NdkCameraMetadataTags.h
@@ -2425,7 +2425,7 @@ typedef enum acamera_metadata_tag {
      *
      * <p>If set to AUTO, the camera device detects which capture request key the application uses
      * to do zoom, ACAMERA_SCALER_CROP_REGION or ACAMERA_CONTROL_ZOOM_RATIO. If
-     * the application doesn't set android.scaler.zoomRatio or sets it to 1.0 in the capture
+     * the application doesn't set ACAMERA_CONTROL_ZOOM_RATIO or sets it to 1.0 in the capture
      * request, the effective zoom level is reflected in ACAMERA_SCALER_CROP_REGION in capture
      * results. If ACAMERA_CONTROL_ZOOM_RATIO is set to values other than 1.0, the effective
      * zoom level is reflected in ACAMERA_CONTROL_ZOOM_RATIO. AUTO is the default value
@@ -8655,9 +8655,15 @@ typedef enum acamera_metadata_enum_acamera_control_ae_mode {
      * (triggered by ACAMERA_CONTROL_AE_PRECAPTURE_TRIGGER) and
      * may be fired for captures for which the
      * ACAMERA_CONTROL_CAPTURE_INTENT field is set to
-     * STILL_CAPTURE</p>
+     * STILL_CAPTURE.</p>
+     * <p>It's important to wait for the precapture sequence
+     * to complete (i.e., ACAMERA_CONTROL_AE_STATE reaches
+     * FLASH_REQUIRED, CONVERGED, or LOCKED) before submitting a
+     * STILL_CAPTURE request. Otherwise, in low-light conditions,
+     * the image captures with flash fired won't have correct exposures.</p>
      *
      * @see ACAMERA_CONTROL_AE_PRECAPTURE_TRIGGER
+     * @see ACAMERA_CONTROL_AE_STATE
      * @see ACAMERA_CONTROL_CAPTURE_INTENT
      */
     ACAMERA_CONTROL_AE_MODE_ON_AUTO_FLASH                            = 2,
@@ -8670,9 +8676,15 @@ typedef enum acamera_metadata_enum_acamera_control_ae_mode {
      * (triggered by ACAMERA_CONTROL_AE_PRECAPTURE_TRIGGER) and
      * will always be fired for captures for which the
      * ACAMERA_CONTROL_CAPTURE_INTENT field is set to
-     * STILL_CAPTURE</p>
+     * STILL_CAPTURE.</p>
+     * <p>It's important to wait for the precapture sequence
+     * to complete (i.e., ACAMERA_CONTROL_AE_STATE reaches
+     * FLASH_REQUIRED, CONVERGED, or LOCKED) Dbefore submitting a
+     * STILL_CAPTURE request. Otherwise, in low-light conditions,
+     * the image captures with flash fired won't have correct exposures.</p>
      *
      * @see ACAMERA_CONTROL_AE_PRECAPTURE_TRIGGER
+     * @see ACAMERA_CONTROL_AE_STATE
      * @see ACAMERA_CONTROL_CAPTURE_INTENT
      */
     ACAMERA_CONTROL_AE_MODE_ON_ALWAYS_FLASH                          = 3,
diff --git a/camera/ndk/ndk_vendor/impl/ACameraDevice.cpp b/camera/ndk/ndk_vendor/impl/ACameraDevice.cpp
index b65aedf0e1..56f7820155 100644
--- a/camera/ndk/ndk_vendor/impl/ACameraDevice.cpp
+++ b/camera/ndk/ndk_vendor/impl/ACameraDevice.cpp
@@ -221,7 +221,6 @@ camera_status_t CameraDevice::isSessionConfigurationSupported(
     if (ret != ACAMERA_OK) {
         return ret;
     }
-
     SessionConfiguration sessionConfig;
     sessionConfig.inputWidth = 0;
     sessionConfig.inputHeight = 0;
diff --git a/cmds/screenrecord/Overlay.cpp b/cmds/screenrecord/Overlay.cpp
index f0bd402d2e..d4e6967415 100644
--- a/cmds/screenrecord/Overlay.cpp
+++ b/cmds/screenrecord/Overlay.cpp
@@ -14,10 +14,6 @@
  * limitations under the License.
  */
 
-#include <assert.h>
-#include <inttypes.h>
-#include <stdlib.h>
-
 #define LOG_TAG "ScreenRecord"
 //#define LOG_NDEBUG 0
 #include <utils/Log.h>
@@ -30,6 +26,10 @@
 #include <GLES2/gl2.h>
 #include <GLES2/gl2ext.h>
 
+#include <assert.h>
+#include <inttypes.h>
+#include <stdlib.h>
+
 #include "screenrecord.h"
 #include "Overlay.h"
 #include "TextRenderer.h"
@@ -214,27 +214,16 @@ void Overlay::processFrame_l() {
 
     mTextRenderer.setProportionalScale(35);
 
-    if (false) {  // DEBUG - full blue background
-        glClearColor(0.0f, 0.0f, 1.0f, 1.0f);
-        glClear(GL_DEPTH_BUFFER_BIT | GL_COLOR_BUFFER_BIT);
-    }
-
     int width = mEglWindow.getWidth();
     int height = mEglWindow.getHeight();
-    if (false) {  // DEBUG - draw inset
-        mExtTexProgram.blit(mExtTextureName, texMatrix,
-                100, 100, width-200, height-200);
-    } else {
-        mExtTexProgram.blit(mExtTextureName, texMatrix,
-                0, 0, width, height);
+    status_t ret = mExtTexProgram.blit(mExtTextureName, texMatrix, 0, 0, width, height);
+    if (ret != NO_ERROR) {
+        ALOGE("Overlay::processFrame: Failed to blit the frame texture, error %d", ret);
+        return;
     }
 
     glEnable(GL_BLEND);
     glBlendFunc(GL_ONE, GL_ONE_MINUS_SRC_ALPHA);
-    if (false) {  // DEBUG - show entire font bitmap
-        mTexProgram.blit(mTextRenderer.getTextureName(), Program::kIdentity,
-                100, 100, width-200, height-200);
-    }
 
     char textBuf[64];
     getTimeString_l(monotonicNsec, textBuf, sizeof(textBuf));
@@ -244,14 +233,6 @@ void Overlay::processFrame_l() {
 
     glDisable(GL_BLEND);
 
-    if (false) {  // DEBUG - add red rectangle in lower-left corner
-        glEnable(GL_SCISSOR_TEST);
-        glScissor(0, 0, 200, 200);
-        glClearColor(1.0f, 0.0f, 0.0f, 1.0f);
-        glClear(GL_COLOR_BUFFER_BIT);
-        glDisable(GL_SCISSOR_TEST);
-    }
-
     mEglWindow.presentationTime(monotonicNsec);
     mEglWindow.swapBuffers();
 }
diff --git a/cmds/screenrecord/screenrecord.cpp b/cmds/screenrecord/screenrecord.cpp
index e260165faf..d391e91924 100644
--- a/cmds/screenrecord/screenrecord.cpp
+++ b/cmds/screenrecord/screenrecord.cpp
@@ -811,11 +811,11 @@ struct RecordingData {
 
     ~RecordingData() {
         if (dpy != nullptr) SurfaceComposerClient::destroyVirtualDisplay(dpy);
-        if (overlay != nullptr) overlay->stop();
         if (encoder != nullptr) {
             encoder->stop();
             encoder->release();
         }
+        if (overlay != nullptr) overlay->stop();
     }
 };
 
@@ -897,8 +897,8 @@ static status_t recordScreen(const char* fileName) {
         return err;
     }
 
-    if (displayState.layerStack == ui::INVALID_LAYER_STACK) {
-        fprintf(stderr, "ERROR: INVALID_LAYER_STACK, please check your display state.\n");
+    if (displayState.layerStack == ui::UNASSIGNED_LAYER_STACK) {
+        fprintf(stderr, "ERROR: UNASSIGNED_LAYER_STACK, please check your display state.\n");
         return INVALID_OPERATION;
     }
 
diff --git a/include/media/MmapStreamInterface.h b/include/media/MmapStreamInterface.h
index 3d29335100..c115aa925a 100644
--- a/include/media/MmapStreamInterface.h
+++ b/include/media/MmapStreamInterface.h
@@ -61,6 +61,7 @@ class MmapStreamInterface : public virtual RefBase
      *                       Actual as output
      * \param[in] callback the MmapStreamCallback interface used by AudioFlinger to notify
      *                     condition changes affecting the stream operation
+     * \param[in] offloadInfo additional information for offload playback
      * \param[out] interface the MmapStreamInterface interface controlling the created stream
      * \param[out] same unique handle as the one used for the first client stream started.
      * \return OK if the stream was successfully created.
@@ -69,14 +70,15 @@ class MmapStreamInterface : public virtual RefBase
      *         INVALID_OPERATION if the stream cannot be opened because of platform limitations
      */
     static status_t openMmapStream(stream_direction_t direction,
-                                           const audio_attributes_t *attr,
-                                           audio_config_base_t *config,
-                                           const AudioClient& client,
-                                           DeviceIdVector *deviceIds,
-                                           audio_session_t *sessionId,
-                                           const sp<MmapStreamCallback>& callback,
-                                           sp<MmapStreamInterface>& interface,
-                                           audio_port_handle_t *handle);
+                                   const audio_attributes_t *attr,
+                                   audio_config_base_t *config,
+                                   const AudioClient& client,
+                                   DeviceIdVector *deviceIds,
+                                   audio_session_t *sessionId,
+                                   const sp<MmapStreamCallback>& callback,
+                                   const audio_offload_info_t* offloadInfo,
+                                   sp<MmapStreamInterface>& interface,
+                                   audio_port_handle_t *handle);
 
     /**
      * Retrieve information on the mmap buffer used for audio samples transfer.
diff --git a/include/private/media/AudioTrackShared.h b/include/private/media/AudioTrackShared.h
index a1e1702990..bd638136ea 100644
--- a/include/private/media/AudioTrackShared.h
+++ b/include/private/media/AudioTrackShared.h
@@ -17,9 +17,11 @@
 #ifndef ANDROID_AUDIO_TRACK_SHARED_H
 #define ANDROID_AUDIO_TRACK_SHARED_H
 
+#include <algorithm>
 #include <stdint.h>
 #include <sys/types.h>
 
+#include <audio_utils/atomic.h>
 #include <audio_utils/minifloat.h>
 #include <utils/threads.h>
 #include <utils/Log.h>
@@ -315,7 +317,12 @@ protected:
     const bool      mIsOut;             // true for AudioTrack, false for AudioRecord
     const bool      mClientInServer;    // true for OutputTrack, false for AudioTrack & AudioRecord
     bool            mIsShutdown;        // latch set to true when shared memory corruption detected
-    size_t          mUnreleased;        // unreleased frames remaining from most recent obtainBuffer
+
+    // mUnreleased is the number frames remaining from most recent obtainBuffer(s).
+    // Generally accessed by a single thread, but for Java offload,
+    // this variable may be accessed from multiple threads.  It is used to
+    // bounds check the releaseBuffer call after the obtainBuffer.
+    audio_utils::atomic<size_t, audio_utils::memory_order_relaxed>  mUnreleased;
 };
 
 // ----------------------------------------------------------------------------
@@ -426,6 +433,11 @@ public:
 
     virtual void stop() { }; // called by client in AudioTrack::stop()
 
+     void setMinMeasureMs(uint32_t measureMs) {
+         long measureNs = measureMs * 1'000'000L;
+         mMinMeasureNs = std::clamp(measureNs, kAbsoluteMinMeasureNs, kDefaultMinMeasureNs);
+     }
+
 private:
     // This is a copy of mCblk->mBufferSizeInFrames
     uint32_t   mBufferSizeInFrames;  // effective size of the buffer
@@ -437,6 +449,10 @@ private:
     // is initialized by the client constructor.
     ExtendedTimestampQueue::Observer mTimestampObserver;
     ExtendedTimestamp mTimestamp; // initialized by constructor
+    // Minimum timeout in nanoseconds for which we actually wait in obtainBuffer()
+    static constexpr long kDefaultMinMeasureNs = 10'000'000; // 10ms default
+    static constexpr long kAbsoluteMinMeasureNs = 1'000'000; // 1ms absolute min
+    long mMinMeasureNs = kDefaultMinMeasureNs;
 };
 
 // ----------------------------------------------------------------------------
diff --git a/media/TEST_MAPPING b/media/TEST_MAPPING
index 54b256fc46..1c43877682 100644
--- a/media/TEST_MAPPING
+++ b/media/TEST_MAPPING
@@ -52,6 +52,9 @@
                 }
             ]
         },
+        {
+            "name": "vts_treble_vintf_framework_test"
+        },
         {
             "name": "MctsMediaCodecTestCases",
             "options": [
diff --git a/media/aconfig/codec_fwk.aconfig b/media/aconfig/codec_fwk.aconfig
index 089ddf86ab..3714b4d1a2 100644
--- a/media/aconfig/codec_fwk.aconfig
+++ b/media/aconfig/codec_fwk.aconfig
@@ -13,6 +13,13 @@ flag {
   bug: "201479783"
 }
 
+flag {
+  name: "app_codec_usage_metrics"
+  namespace: "codec_fwk"
+  description: "Feature flag for application codec usage metrics"
+  bug: "406819941"
+}
+
 flag {
   name: "apv_support"
   is_exported: true
@@ -21,6 +28,15 @@ flag {
   bug: "375464302"
 }
 
+flag {
+  name: "audio_mix_presentation_support"
+  is_exported: true
+  is_fixed_read_only: true
+  namespace: "codec_fwk"
+  description: "Feature flag for MediaFormat KEY_AUDIO_PRESENTATION_ID"
+  bug: "418795315"
+}
+
 flag {
   name: "codec_availability"
   namespace: "codec_fwk"
@@ -163,6 +179,13 @@ flag {
   bug: "325549730"
 }
 
+flag {
+  name: "remove_arraymode_for_linear_output_buffers"
+  namespace: "codec_fwk"
+  description: "Feature flag for removing Array mode for linear output buffers"
+  bug: "418813731"
+}
+
 flag {
   name: "rendering_depth_removal"
   namespace: "codec_fwk"
@@ -231,3 +254,10 @@ flag {
   description: "Feature flag for using block model decoder in thumbnail generation"
   bug: "329521645"
 }
+
+flag {
+  name: "trace_codec_activity"
+  namespace: "codec_fwk"
+  description: "traces for logging codec activity"
+  bug: "380898418"
+}
diff --git a/media/aconfig/swcodec_flags.aconfig b/media/aconfig/swcodec_flags.aconfig
index cb8a9637a9..46a09b792d 100644
--- a/media/aconfig/swcodec_flags.aconfig
+++ b/media/aconfig/swcodec_flags.aconfig
@@ -23,6 +23,24 @@ flag {
   bug: "376770121"
 }
 
+flag {
+  name: "iamf_aac_flac"
+  is_exported: false
+  is_fixed_read_only: true
+  namespace: "codec_fwk"
+  description: "Feature flag for enabling AAC and FLAC in the IAMF Software C2 decoder"
+  bug: "396187214"
+}
+
+flag {
+  name: "iamf_software_decoder"
+  is_exported: false
+  is_fixed_read_only: true
+  namespace: "codec_fwk"
+  description: "Feature flag for IAMF Software C2 decoder"
+  bug: "388336285"
+}
+
 flag {
   name: "mpeg2_keep_threads_active"
   is_exported: true
diff --git a/media/audio/aconfig/aaudio.aconfig b/media/audio/aconfig/aaudio.aconfig
index 7896a75ca1..7c8c9cfc67 100644
--- a/media/audio/aconfig/aaudio.aconfig
+++ b/media/audio/aconfig/aaudio.aconfig
@@ -5,6 +5,13 @@
 package: "com.android.media.aaudio"
 container: "system"
 
+flag {
+    name: "new_data_callback"
+    namespace: "media_audio"
+    description: "New data callback in AAudio."
+    bug: "406332239"
+}
+
 flag {
     name: "offload_support"
     namespace: "media_audio"
@@ -18,10 +25,3 @@ flag {
     description: "Enable the AAudio sample rate converter."
     bug: "219533889"
 }
-
-flag {
-    name: "start_stop_client_from_command_thread"
-    namespace: "media_audio"
-    description: "Start or stop client from command thread."
-    bug: "341627085"
-}
diff --git a/media/audio/aconfig/audio.aconfig b/media/audio/aconfig/audio.aconfig
index 84646d7d65..34feb7cdbf 100644
--- a/media/audio/aconfig/audio.aconfig
+++ b/media/audio/aconfig/audio.aconfig
@@ -6,18 +6,18 @@ package: "com.android.media.audio"
 container: "system"
 
 flag {
-    name: "abs_volume_index_fix"
+    name: "alarm_min_volume_zero"
     namespace: "media_audio"
-    description:
-        "Fix double attenuation and index jumps in absolute volume mode"
-    bug: "340693050"
+    description: "Support configuring alarm min vol to zero"
+    bug: "296884402"
 }
 
 flag {
-    name: "alarm_min_volume_zero"
+    name: "abs_volume_prioritizes_abs_device"
     namespace: "media_audio"
-    description: "Support configuring alarm min vol to zero"
-    bug: "296884402"
+    description: "When receiving a volume command from an absolute volume device we "
+                 "prioritize selecting the available absolute device for volume change"
+    bug: "399307939"
 }
 
 flag {
@@ -51,6 +51,15 @@ flag {
     bug: "285588444"
 }
 
+flag {
+    name: "check_route_in_get_audio_mix_port"
+    namespace: "media_audio"
+    description: "Checks routing in the API getAudioMixPort to respect"
+                 "connectivity between mix ports and device ports as"
+                 "indicated by getAudioRoutes."
+    bug: "367117623"
+}
+
 flag {
     name: "defer_wear_permission_updates"
     namespace: "media_audio"
@@ -69,20 +78,21 @@ flag {
 }
 
 flag {
-    name: "dsa_over_bt_le_audio"
+    name: "equal_sco_lea_vc_index_range"
     namespace: "media_audio"
     description:
-        "Enable dynamic spatial audio over Bluetooth LE Audio."
-    bug: "307588546"
+        "Introduce the same index range for voice calls over SCO and "
+        "LE audio"
+    bug: "364364777"
 }
 
 flag {
-    name: "equal_sco_lea_vc_index_range"
+    name: "equal_sco_ha_vc_index_range"
     namespace: "media_audio"
     description:
         "Introduce the same index range for voice calls over SCO and "
-        "LE audio"
-    bug: "364364777"
+        "hearing aids"
+    bug: "416418971"
 }
 
 flag {
@@ -116,13 +126,6 @@ flag {
     bug: "376480814"
 }
 
-flag {
-    name: "music_fx_edge_to_edge"
-    namespace: "media_audio"
-    description: "Enable Edge-to-edge feature for MusicFx and handle insets"
-    bug: "336204940"
-}
-
 flag {
     name: "optimize_bt_device_switch"
     namespace: "media_audio"
@@ -130,14 +133,6 @@ flag {
     bug: "373867402"
 }
 
-flag {
-    name: "port_to_piid_simplification"
-    namespace: "media_audio"
-    description: "PAM only needs for each piid the last portId mapping"
-    bug: "335747248"
-
-}
-
 flag {
     name: "replace_stream_bt_sco"
     namespace: "media_audio"
@@ -162,15 +157,6 @@ flag {
     bug: "312456558"
 }
 
-flag {
-    name: "set_stream_volume_order"
-    namespace: "media_audio"
-    description:
-        "Fix race condition by adjusting the order when"
-        "setStreamVolume is calling into the BT stack"
-    bug: "329202581"
-}
-
 flag {
     name: "spatializer_offload"
     namespace: "media_audio"
@@ -193,12 +179,10 @@ flag {
 }
 
 flag {
-    name: "vgs_vss_sync_mute_order"
+    name: "update_preferred_devices_for_strategy"
     namespace: "media_audio"
-    description:
-        "When syncing the VGS to VSS we need to first adjust the"
-        "mute state before the index."
-    bug: "331849188"
+    description: "Use AudioDeviceInventory cache for getPreferredDevicesForStrategy"
+    bug: "417481226"
 }
 
 flag {
diff --git a/media/audio/aconfig/audio_framework.aconfig b/media/audio/aconfig/audio_framework.aconfig
index a4956b86b7..84ddf69830 100644
--- a/media/audio/aconfig/audio_framework.aconfig
+++ b/media/audio/aconfig/audio_framework.aconfig
@@ -8,19 +8,24 @@ package: "android.media.audio"
 container: "system"
 
 flag {
-    name: "auto_public_volume_api_hardening"
+    name: "assistant_volume_control"
     namespace: "media_audio"
-    description: "On AAOS, make volume and ringer SDK APIs in AudioManager no-ops."
-    bug: "302751899"
+    description: "Implement the logic for having STREAM_ASSISTANT lead the volume control"
+    bug: "416329698"
 }
 
 flag {
-    name: "automatic_bt_device_type"
+    name: "audio_focus_desktop"
     namespace: "media_audio"
-    description:
-        "Enable the automatic Bluetooth audio device type "
-        "categorization based on BluetoothDevice class metadata."
-    bug: "302323921"
+    description: "audio focus for desktop behaviors"
+    bug: "416963897"
+}
+
+flag {
+    name: "auto_public_volume_api_hardening"
+    namespace: "media_audio"
+    description: "On AAOS, make volume and ringer SDK APIs in AudioManager no-ops."
+    bug: "302751899"
 }
 
 flag {
@@ -49,6 +54,13 @@ flag {
     is_exported: true
 }
 
+flag {
+    name: "dap_injection_starve_management"
+    namespace: "media_audio"
+    description: "Dynamic AudioPolicy management of injection starvation"
+    bug: "416965224"
+}
+
 flag {
     name: "deprecate_stream_bt_sco"
     namespace: "media_audio"
@@ -57,6 +69,14 @@ flag {
     bug: "376756660"
 }
 
+flag {
+    name: "device_volume_apis"
+    namespace: "media_audio"
+    description: "Add APIs to set/adjust volume for a specific device."
+    is_exported: true
+    bug: "404313846"
+}
+
 flag {
     name: "enable_multichannel_group_device"
     namespace: "media_audio"
@@ -68,6 +88,13 @@ flag {
     bug: "344031109"
 }
 
+flag {
+    name: "enable_platform_pc_type"
+    namespace: "media_audio"
+    description: "Return PLATFORM_PC in getPlatformType when the device has FEATURE_PC to control behavior on PC."
+    bug: "414709012"
+}
+
 flag{
     name: "enable_ringtone_haptics_customization"
     namespace: "media_audio"
@@ -161,6 +188,13 @@ flag {
     bug: "337522902"
 }
 
+flag {
+    name: "leaudio_sw_offload"
+    namespace: "media_audio"
+    description: "Changes related to LEA SW offload"
+    bug: "372969373"
+}
+
 flag {
     name: "loudness_configurator_api"
     is_exported: true
diff --git a/media/audio/aconfig/audiopolicy_framework.aconfig b/media/audio/aconfig/audiopolicy_framework.aconfig
index 28b6c7f9dd..df3e7b0286 100644
--- a/media/audio/aconfig/audiopolicy_framework.aconfig
+++ b/media/audio/aconfig/audiopolicy_framework.aconfig
@@ -6,14 +6,6 @@
 package: "android.media.audiopolicy"
 container: "system"
 
-flag {
-    name: "audio_mix_ownership"
-    namespace: "media_audio"
-    description: "Improves ownership model of AudioMixes and the relationship between AudioPolicy and AudioMix."
-    bug: "309080867"
-    is_fixed_read_only: true
-}
-
 flag {
     name: "audio_mix_policy_ordering"
     namespace: "media_audio"
@@ -60,4 +52,12 @@ flag {
     description: "Enable device-aware permission handling for RECORD_AUDIO permission"
     bug: "291737188"
     is_fixed_read_only: true
-}
\ No newline at end of file
+}
+
+flag {
+    name: "volume_group_management_update"
+    namespace: "media_audio"
+    description: "Improves volume group management to remove usage of legacy audio attributes and "
+                 "stream types and control by identifier."
+    bug: "270049944"
+}
diff --git a/media/audio/aconfig/audioserver.aconfig b/media/audio/aconfig/audioserver.aconfig
index 3278a441d5..aba2798931 100644
--- a/media/audio/aconfig/audioserver.aconfig
+++ b/media/audio/aconfig/audioserver.aconfig
@@ -45,37 +45,19 @@ flag {
     bug: "366456949"
 }
 
-# shipped 24Q3
-flag {
-    name: "fdtostring_timeout_fix"
-    namespace: "media_audio"
-    description: "Improve fdtostring implementation to properly handle timing out."
-    bug: "306283018"
-}
-
 flag {
-    name: "fix_aaudio_stream_reopen_in_libaudiohal_aidl"
+    name: "enable_strict_port_routing_checks"
     namespace: "media_audio"
-    description:
-        "Support reopening of AAudio streams in the libaudiohal@aidl layer"
-    bug: "274456992"
-}
-
-flag {
-    name: "fix_call_audio_patch"
-    namespace: "media_audio"
-    description:
-        "optimize creation and release of audio patches for call routing"
-    bug: "292492229"
+    description: "Enables strict routing checks on associating ports"
+    bug: "367117623"
 }
 
+# shipped 24Q3
 flag {
-    name: "fix_concurrent_playback_behavior_with_bit_perfect_client"
+    name: "fdtostring_timeout_fix"
     namespace: "media_audio"
-    description:
-        "Treat playback use cases differently when bit-perfect client is active to improve the "
-        "user experience with bit-perfect playback."
-    bug: "339515899"
+    description: "Improve fdtostring implementation to properly handle timing out."
+    bug: "306283018"
 }
 
 flag {
@@ -97,6 +79,14 @@ flag {
     bug: "209491695"
 }
 
+flag {
+    name: "mmap_pcm_offload_support"
+    namespace: "media_audio"
+    description:
+        "Add pcm offload support on mmap path."
+    bug: "409798445"
+}
+
 flag {
     name: "portid_volume_management"
     namespace: "media_audio"
@@ -113,6 +103,13 @@ flag {
     bug: "350114693"
 }
 
+flag {
+    name: "remove_stream_suspend"
+    namespace: "media_audio"
+    description: "Remove the output stream suspend state and control mechanism"
+    bug: "409706525"
+}
+
 flag {
     name: "use_bt_sco_for_media"
     namespace: "media_audio"
diff --git a/media/audioaidlconversion/AidlConversionCppNdk.cpp b/media/audioaidlconversion/AidlConversionCppNdk.cpp
index af399040d2..64ecd17a8b 100644
--- a/media/audioaidlconversion/AidlConversionCppNdk.cpp
+++ b/media/audioaidlconversion/AidlConversionCppNdk.cpp
@@ -669,6 +669,8 @@ const detail::AudioFormatPairs& getAudioFormatPairs() {
             {AUDIO_FORMAT_VORBIS,
              make_AudioFormatDescription(::android::MEDIA_MIMETYPE_AUDIO_VORBIS)},
             {AUDIO_FORMAT_OPUS, make_AudioFormatDescription(::android::MEDIA_MIMETYPE_AUDIO_OPUS)},
+            {AUDIO_FORMAT_OPUS_HI_RES, make_AudioFormatDescription(
+                    std::string(::android::MEDIA_MIMETYPE_AUDIO_OPUS) + ".hi_res")},
             {AUDIO_FORMAT_AC3, make_AudioFormatDescription(::android::MEDIA_MIMETYPE_AUDIO_AC3)},
             {AUDIO_FORMAT_E_AC3, make_AudioFormatDescription(::android::MEDIA_MIMETYPE_AUDIO_EAC3)},
             {AUDIO_FORMAT_E_AC3_JOC,
diff --git a/media/audioserver/OWNERS b/media/audioserver/OWNERS
index f02cbc31bc..fe3205a8d4 100644
--- a/media/audioserver/OWNERS
+++ b/media/audioserver/OWNERS
@@ -1,5 +1,4 @@
 # Bug component: 48436
 atneya@google.com
 hunga@google.com
-philburk@google.com
 include platform/frameworks/av:/media/janitors/audio_OWNERS #{LAST_RESORT_SUGGESTION}
diff --git a/media/codec2/components/aac/Android.bp b/media/codec2/components/aac/Android.bp
index c547e85946..03b03a9465 100644
--- a/media/codec2/components/aac/Android.bp
+++ b/media/codec2/components/aac/Android.bp
@@ -29,7 +29,7 @@ cc_library {
         "DrcPresModeWrap.cpp",
     ],
 
-    static_libs: [
+    shared_libs: [
         "libFraunhoferAAC",
     ],
 }
@@ -43,7 +43,7 @@ cc_library {
 
     srcs: ["C2SoftAacEnc.cpp"],
 
-    static_libs: [
+    shared_libs: [
         "libFraunhoferAAC",
     ],
 }
diff --git a/media/codec2/components/aac/C2SoftAacEnc.cpp b/media/codec2/components/aac/C2SoftAacEnc.cpp
index 14a30a0376..84c7b427dd 100644
--- a/media/codec2/components/aac/C2SoftAacEnc.cpp
+++ b/media/codec2/components/aac/C2SoftAacEnc.cpp
@@ -33,6 +33,9 @@ namespace {
 
 constexpr char COMPONENT_NAME[] = "c2.android.aac.encoder";
 
+// Tolerance (5us) during comparison to desensitize for rounding errors
+constexpr int64_t kTimestampToleranceUs = 5;
+
 }  // namespace
 
 class C2SoftAacEnc::IntfImpl : public SimpleInterface<void>::BaseParams {
@@ -155,6 +158,9 @@ C2SoftAacEnc::C2SoftAacEnc(
       mNumBytesPerInputFrame(0u),
       mOutBufferSize(0u),
       mSentCodecSpecificData(false),
+      mIsFirstFrame(true),
+      mAnchorTimeStampUs(0),
+      mProcessedSamplesSinceAnchorReset(0u),
       mSignalledError(false),
       mOutIndex(0u),
       mRemainderLen(0u) {
@@ -186,7 +192,9 @@ status_t C2SoftAacEnc::initEncoder() {
 
 c2_status_t C2SoftAacEnc::onStop() {
     mSentCodecSpecificData = false;
-    mNextFrameTimestampUs.reset();
+    mIsFirstFrame = true;
+    mAnchorTimeStampUs = 0;
+    mProcessedSamplesSinceAnchorReset = 0u;
     mLastFrameEndTimestampUs.reset();
     mSignalledError = false;
     mRemainderLen = 0;
@@ -210,7 +218,9 @@ c2_status_t C2SoftAacEnc::onFlush_sm() {
         }
     }
     mSentCodecSpecificData = false;
-    mNextFrameTimestampUs.reset();
+    mIsFirstFrame = true;
+    mAnchorTimeStampUs = 0;
+    mProcessedSamplesSinceAnchorReset = 0u;
     mLastFrameEndTimestampUs.reset();
     mRemainderLen = 0;
     return C2_OK;
@@ -406,8 +416,15 @@ void C2SoftAacEnc::process(
         inputTimestampUs = *mLastFrameEndTimestampUs;
     }
     if (capacity > 0 || eos) {
-        if (!mNextFrameTimestampUs) {
-            mNextFrameTimestampUs = work->input.ordinal.timestamp;
+        // at the start of encoding or at a point where no audio frames were sent for encoding for
+        // brief period of time and restarted again with a new pts, reset the anchor timestamp. Use
+        // tolerance (5us) during comparison to desensitize for rounding errors
+        if (mIsFirstFrame ||
+            (inputTimestampUs - mLastFrameEndTimestampUs.value_or(inputTimestampUs)) >
+                    kTimestampToleranceUs) {
+            mProcessedSamplesSinceAnchorReset = 0;
+            mAnchorTimeStampUs = inputTimestampUs.peekll();
+            mIsFirstFrame = false;
         }
         mLastFrameEndTimestampUs = inputTimestampUs
                 + (capacity / sizeof(int16_t) * 1000000ll / channelCount / sampleRate);
@@ -505,7 +522,7 @@ void C2SoftAacEnc::process(
             inargs.numInSamples = 0;
         }
     }
-    int processedSampleCntInCurrBatch = 0;
+    int samplesPerFrame = mNumBytesPerInputFrame / (channelCount * sizeof(int16_t));
     while (encoderErr == AACENC_OK && (inargs.numInSamples >= channelCount || eos)) {
         if (!block) {
             C2MemoryUsage usage = { C2MemoryUsage::CPU_READ, C2MemoryUsage::CPU_WRITE };
@@ -539,14 +556,8 @@ void C2SoftAacEnc::process(
 
         if (encoderErr == AACENC_OK) {
             if (outargs.numOutBytes > 0) {
-                processedSampleCntInCurrBatch += mNumBytesPerInputFrame / sizeof(int16_t);
-                ALOGV("processedSampleCntInCurrBatch = %d, capacity = %zu, inSamples = %d, "
-                      "outSamples = %d",
-                      processedSampleCntInCurrBatch, capacity, inargs.numInSamples,
-                      outargs.numInSamples);
-                c2_cntr64_t currentFrameTimestampUs = *mNextFrameTimestampUs;
-                mNextFrameTimestampUs = inputTimestampUs + (processedSampleCntInCurrBatch *
-                                                            1000000ll / channelCount / sampleRate);
+                const int64_t duration = mProcessedSamplesSinceAnchorReset * 1000000ll / sampleRate;
+                mProcessedSamplesSinceAnchorReset += samplesPerFrame;
                 std::shared_ptr<C2Buffer> buffer =
                         createLinearBuffer(block, 0, outargs.numOutBytes);
 #if 0
@@ -556,7 +567,7 @@ void C2SoftAacEnc::process(
                 outAvailable = 0;
                 block.reset();
 
-                outputBuffers.push_back({buffer, currentFrameTimestampUs});
+                outputBuffers.push_back({buffer, mAnchorTimeStampUs + duration});
             }
 
             if (inBuffer[0] == mRemainder) {
@@ -574,8 +585,6 @@ void C2SoftAacEnc::process(
             inBufferSize[0] = 0;
             inargs.numInSamples = 0;
         }
-        ALOGV("encoderErr = %d, inargs.numInSamples = %d, mNextFrameTimestampUs = %lld", encoderErr,
-              inargs.numInSamples, mNextFrameTimestampUs->peekll());
     }
 
     if (inBufferSize[0] > 0) {
@@ -633,7 +642,9 @@ c2_status_t C2SoftAacEnc::drain(
 
     (void)pool;
     mSentCodecSpecificData = false;
-    mNextFrameTimestampUs.reset();
+    mIsFirstFrame = true;
+    mAnchorTimeStampUs = 0;
+    mProcessedSamplesSinceAnchorReset = 0u;
     mLastFrameEndTimestampUs.reset();
 
     // TODO: we don't have any pending work at this time to drain.
diff --git a/media/codec2/components/aac/C2SoftAacEnc.h b/media/codec2/components/aac/C2SoftAacEnc.h
index 328a5f6acb..6909d35753 100644
--- a/media/codec2/components/aac/C2SoftAacEnc.h
+++ b/media/codec2/components/aac/C2SoftAacEnc.h
@@ -61,7 +61,12 @@ private:
     UINT mOutBufferSize;
 
     bool mSentCodecSpecificData;
-    std::optional<c2_cntr64_t> mNextFrameTimestampUs;
+    bool mIsFirstFrame;
+    // Start offset for current output timestamp
+    int64_t mAnchorTimeStampUs;
+    // Tracks the number of processed samples to calculate an accurate current output timestamp.
+    uint64_t mProcessedSamplesSinceAnchorReset;
+
     std::optional<c2_cntr64_t> mLastFrameEndTimestampUs;
 
     bool mSignalledError;
diff --git a/media/codec2/components/apv/C2SoftApvDec.cpp b/media/codec2/components/apv/C2SoftApvDec.cpp
index 4c69b11a1a..dbddad276a 100644
--- a/media/codec2/components/apv/C2SoftApvDec.cpp
+++ b/media/codec2/components/apv/C2SoftApvDec.cpp
@@ -334,10 +334,11 @@ class C2SoftApvDec::IntfImpl : public SimpleInterface<void>::BaseParams {
                                   const C2P<C2StreamMaxPictureSizeTuning::output>& maxSize) {
         (void)mayBlock;
         ALOGV("%s", __FUNCTION__);
-        // assume compression ratio of 2, but enforce a floor
+        // assume 1.25x compression as a worst case. Enforce the floor.
         me.set().value =
-                c2_max((((maxSize.v.width + 63) / 64) * ((maxSize.v.height + 63) / 64) * 3072),
-                       kMinInputBufferSize);
+                /* 20 / 8 / 1.25 = 2: 20 is a bpp for 422 10 bit, 1.25 assumed min compression.*/
+                c2_max((ALIGN_VAL(maxSize.v.width, 16) * ALIGN_VAL(maxSize.v.height, 16) * 2),
+                     kMinInputBufferSize);
         return C2R::Ok();
     }
 
@@ -1294,7 +1295,11 @@ status_t C2SoftApvDec::outputBuffer(const std::shared_ptr<C2BlockPool>& pool,
     uint32_t format = HAL_PIXEL_FORMAT_YV12;
     std::shared_ptr<C2StreamColorAspectsInfo::output> codedColorAspects;
     if (mPixelFormatInfo->value != HAL_PIXEL_FORMAT_YCBCR_420_888) {
-        if (isHalPixelFormatSupported((AHardwareBuffer_Format)AHARDWAREBUFFER_FORMAT_YCbCr_P210)) {
+        if ((mPixelFormatInfo->value != HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) &&
+            isHalPixelFormatSupported((AHardwareBuffer_Format)mPixelFormatInfo->value)) {
+            format = mPixelFormatInfo->value;
+        } else if (isHalPixelFormatSupported(
+                        (AHardwareBuffer_Format)AHARDWAREBUFFER_FORMAT_YCbCr_P210)) {
             format = AHARDWAREBUFFER_FORMAT_YCbCr_P210;
         } else if (isHalPixelFormatSupported(
                         (AHardwareBuffer_Format)HAL_PIXEL_FORMAT_YCBCR_P010)) {
diff --git a/media/codec2/components/flac/Android.bp b/media/codec2/components/flac/Android.bp
index 38dfce4650..83ca2376d2 100644
--- a/media/codec2/components/flac/Android.bp
+++ b/media/codec2/components/flac/Android.bp
@@ -42,8 +42,11 @@ cc_library {
 
     srcs: ["C2SoftFlacEnc.cpp"],
 
-    static_libs: [
+    shared_libs: [
         "libFLAC",
+    ],
+
+    static_libs: [
         "libaudioutils",
     ],
 }
diff --git a/media/codec2/components/flac/C2SoftFlacEnc.cpp b/media/codec2/components/flac/C2SoftFlacEnc.cpp
index ad9d3e1844..6edc403788 100644
--- a/media/codec2/components/flac/C2SoftFlacEnc.cpp
+++ b/media/codec2/components/flac/C2SoftFlacEnc.cpp
@@ -100,7 +100,7 @@ public:
                 .withFields({
                     C2F(mInputMaxBufSize, value).any(),
                 })
-                .withSetter(MaxInputSizeSetter, mChannelCount, mPcmEncodingInfo)
+                .calculatedAs(MaxInputSizeSetter, mChannelCount, mPcmEncodingInfo)
                 .build());
     }
 
diff --git a/media/codec2/components/iamf/Android.bp b/media/codec2/components/iamf/Android.bp
index 8b6c8fae4b..6a3311a3f5 100644
--- a/media/codec2/components/iamf/Android.bp
+++ b/media/codec2/components/iamf/Android.bp
@@ -4,10 +4,22 @@ package {
 
 cc_library {
     name: "libcodec2_soft_iamfdec",
-
-    srcs: [],
-
+    defaults: [
+        "libcodec2_soft-defaults",
+        "libcodec2_soft_sanitize_all-defaults",
+    ],
+    srcs: [
+        "C2SoftIamfDec.cpp",
+        "LayoutTranslation.cpp",
+    ],
+    static_libs: [
+        "android.media.swcodec.flags-aconfig-cc",
+        "iamf_tools",
+    ],
     shared_libs: [
-        // iamf_tools library will need to go here.
+        "libFLAC",
+        "libFraunhoferAAC",
+        "liblog",
+        "libopus",
     ],
 }
diff --git a/media/codec2/components/iamf/C2SoftIamfDec.cpp b/media/codec2/components/iamf/C2SoftIamfDec.cpp
index cfd5369927..f2c853b10c 100644
--- a/media/codec2/components/iamf/C2SoftIamfDec.cpp
+++ b/media/codec2/components/iamf/C2SoftIamfDec.cpp
@@ -13,67 +13,662 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-
 #define LOG_TAG "C2SoftIamfDec"
+
+#include "C2SoftIamfDec.h"
+
+#include <cstddef>
+#include <cstdint>
+
+#include <C2PlatformSupport.h>
+#include <SimpleC2Interface.h>
+#include <android-base/properties.h>
+#include <android_media_swcodec_flags.h>
+#include <iamf_tools/iamf_decoder.h>
+#include <iamf_tools/iamf_tools_api_types.h>
 #include <log/log.h>
+#include <media/stagefright/foundation/MediaDefs.h>  // For MEDIA_MIMETYPE_AUDIO_IAMF
 
-namespace android {
+#include "LayoutTranslation.h"
 
+namespace android {
 namespace {
-
 constexpr char COMPONENT_NAME[] = "c2.android.iamf.decoder";
 
+uint32_t UNSET_OUTPUT_CHANNEL_MASK = 0;
+uint32_t UNSET_MAX_OUTPUT_CHANNELS = 0;
 }  // namespace
 
+using ::iamf_tools::api::IamfDecoder;
+using ::iamf_tools::api::IamfStatus;
+using ::std::shared_ptr;
+
 class C2SoftIamfDec::IntfImpl : public SimpleInterface<void>::BaseParams {
   public:
-    explicit IntfImpl(const std::shared_ptr<C2ReflectorHelper>& helper)
+    explicit IntfImpl(const shared_ptr<C2ReflectorHelper>& helper)
         : SimpleInterface<void>::BaseParams(helper, COMPONENT_NAME, C2Component::KIND_DECODER,
-                                            C2Component::DOMAIN_AUDIO,
-                                            // Replace with IAMF mimetype when available
-                                            "audio/iamf") {
-        // Configure (e.g. noPrivateBuffers(), etc.)
-        // Add parameters.
+                                            C2Component::DOMAIN_AUDIO, MEDIA_MIMETYPE_AUDIO_IAMF) {
+        noInputLatency();
+        noPrivateBuffers();
+        noInputReferences();
+        noOutputReferences();
+        noTimeStretch();
+        setDerivedInstance(this);
+
+        addParameter(DefineParam(mAttrib, C2_PARAMKEY_COMPONENT_ATTRIBUTES)
+                             .withConstValue(new C2ComponentAttributesSetting(
+                                     C2Component::ATTRIB_IS_TEMPORAL))
+                             .build());
+
+        // ===== Parameters for the input bitstream =====
+        // The profile will be updated by the decoder once the DescriptorObus have all been parsed.
+        // Level is unused by IAMF.
+        // The profiles requested are set in GetIamfDecoderSettings and used to initialize the
+        // decoder.
+        std::vector<unsigned int> profiles = {
+                C2Config::PROFILE_IAMF_SIMPLE_OPUS,
+                C2Config::PROFILE_IAMF_SIMPLE_PCM,
+                C2Config::PROFILE_IAMF_BASE_OPUS,
+                C2Config::PROFILE_IAMF_BASE_PCM,
+        };
+        if (android::media::swcodec::flags::iamf_aac_flac()) {
+            profiles.push_back(C2Config::PROFILE_IAMF_SIMPLE_FLAC);
+            profiles.push_back(C2Config::PROFILE_IAMF_BASE_FLAC);
+            profiles.push_back(C2Config::PROFILE_IAMF_SIMPLE_AAC);
+            profiles.push_back(C2Config::PROFILE_IAMF_BASE_AAC);
+        }
+        addParameter(
+                DefineParam(mProfileLevel, C2_PARAMKEY_PROFILE_LEVEL)
+                        .withDefault(new C2StreamProfileLevelInfo::input(
+                                0u, C2Config::PROFILE_IAMF_SIMPLE_PCM, C2Config::LEVEL_UNUSED))
+                        .withFields({C2F(mProfileLevel, profile).oneOf(profiles),
+                                     C2F(mProfileLevel, level).oneOf({C2Config::LEVEL_UNUSED})})
+                        .withSetter(ProfileLevelSetter)
+                        .build());
+
+        addParameter(DefineParam(mInputMaxBufSize, C2_PARAMKEY_INPUT_MAX_BUFFER_SIZE)
+                             // Starting with a safe max size based on max(opus,aac,flac) + space
+                             // for DescriptorObus. Opus: 960*6, Aac: 8196, Flac: 32768
+                             .withConstValue(new C2StreamMaxBufferSizeInfo::input(0u, 36000))
+                             .build());
+
+        // ===== Params for the output audio =====
+        // The max output channel count is a way of setting the requested output layout when
+        // CHANNEL_MASK cannot be used due to API level.  Default to 0 so we can see when it is set.
+        // IN/OUT details: Optionally set by the caller and read by the decoder.
+        addParameter(
+                DefineParam(mMaxOutputChannelCount, C2_PARAMKEY_MAX_CHANNEL_COUNT)
+                        .withDefault(new C2StreamMaxChannelCountInfo::output(
+                                0u, UNSET_MAX_OUTPUT_CHANNELS))
+                        .withFields({C2F(mMaxOutputChannelCount, value).inRange(2, 8)})
+                        .withSetter(
+                                Setter<decltype(*mMaxOutputChannelCount)>::StrictValueWithNoDeps)
+                        .build());
+
+        // The ChannelMask represents what the physical speaker layout of the decoded (output)
+        // audio. Only a fixed set of Layouts are supported by IAMF and the any given Layout might
+        // not be present in the given file.  The actual Layout of the output audio is updated once
+        // the DescriptorObus are processed.
+        //
+        // IN/OUT details: Set by the caller (if possible based on API level), then read by the
+        // decoder (instead of MAX_OUTPUT_CHANNELS).  In either case, it is set the decoder and read
+        // by the caller to see what output layout is actually produced.
+        addParameter(
+                DefineParam(mRenderedChannelMask, C2_PARAMKEY_CHANNEL_MASK)
+                        .withDefault(
+                                new C2StreamChannelMaskInfo::output(0u, UNSET_OUTPUT_CHANNEL_MASK))
+                        .withFields({C2F(mRenderedChannelMask, value).inRange(0, 4294967292)})
+                        .withSetter(Setter<decltype(*mRenderedChannelMask)>::StrictValueWithNoDeps)
+                        .build());
+
+        // Channel Count matches the ChannelMask above.
+        // IN/OUT details: Set by the decoder and read by the caller.
+        addParameter(DefineParam(mChannelCount, C2_PARAMKEY_CHANNEL_COUNT)
+                             .withDefault(new C2StreamChannelCountInfo::output(0u, 0))
+                             .withFields({C2F(mChannelCount, value).inRange(1, 24)})
+                             .withSetter(Setter<decltype(*mChannelCount)>::StrictValueWithNoDeps)
+                             .build());
+
+        // The sample rate will be determined by the content in the IAMF stream and updated once the
+        // DescriptorObus are processed.
+        // IN/OUT details: Set by the decoder, read by the caller.
+        addParameter(DefineParam(mSampleRate, C2_PARAMKEY_SAMPLE_RATE)
+                             .withDefault(new C2StreamSampleRateInfo::output(0u, 48000))
+                             // This decoder is currently PCM and Opus only.
+                             // IAMF spec allows PCM with sample rates {44.1k, 16k, 32k, 48k, 96k}.
+                             .withFields({C2F(mSampleRate, value)
+                                                  .oneOf({16000, 32000, 44100, 48000, 96000})})
+                             .withSetter((Setter<decltype(*mSampleRate)>::StrictValueWithNoDeps))
+                             .build());
+
+        // Only output audio in 16-bit ints are supported by this decoder.
+        addParameter(
+                DefineParam(mPcmEncodingInfo, C2_PARAMKEY_PCM_ENCODING)
+                        .withDefault(new C2StreamPcmEncodingInfo::output(0u, C2Config::PCM_16))
+                        .withFields({C2F(mPcmEncodingInfo, value).oneOf({C2Config::PCM_16})})
+                        .withSetter((Setter<decltype(*mPcmEncodingInfo)>::StrictValueWithNoDeps))
+                        .build());
     }
-}
+
+    uint32_t getOutputChannelMask() const { return mRenderedChannelMask->value; }
+    uint32_t getMaxOutputChannelCount() const { return mMaxOutputChannelCount->value; }
+    C2Config::pcm_encoding_t getOutputPcmEncoding() const { return mPcmEncodingInfo->value; }
+
+    static C2R ProfileLevelSetter(bool mayBlock, C2P<C2StreamProfileLevelInfo::input>& me) {
+        (void)mayBlock;
+        (void)me;  // TODO: validate
+        return C2R::Ok();
+    }
+
+  private:
+    // Params relating to the input IAMF bitstream.
+    shared_ptr<C2StreamProfileLevelInfo::input> mProfileLevel;
+    shared_ptr<C2StreamMaxBufferSizeInfo::input> mInputMaxBufSize;
+    // Params relating to the output audio.
+    shared_ptr<C2StreamChannelMaskInfo::output> mRenderedChannelMask;
+    std::shared_ptr<C2StreamChannelCountInfo::output> mChannelCount;
+    std::shared_ptr<C2StreamMaxChannelCountInfo::output> mMaxOutputChannelCount;
+    shared_ptr<C2StreamSampleRateInfo::output> mSampleRate;
+    shared_ptr<C2StreamPcmEncodingInfo::output> mPcmEncodingInfo;
+};
 
 C2SoftIamfDec::C2SoftIamfDec(const char* name, c2_node_id_t id,
-                             const std::shared_ptr<IntfImpl>& intfImpl)
+                             const shared_ptr<IntfImpl>& intfImpl)
     : SimpleC2Component(std::make_shared<SimpleInterface<IntfImpl>>(name, id, intfImpl)),
-      mIntf(intfImpl) {
-}
+      mIntf(intfImpl) {}
 
 C2SoftIamfDec::~C2SoftIamfDec() {
     onRelease();
 }
 
+iamf_tools::api::OutputLayout C2SoftIamfDec::getTargetOutputLayout() {
+    mCachedOutputChannelMask = mIntf->getOutputChannelMask();
+    mCachedMaxOutputChannelCount = mIntf->getMaxOutputChannelCount();
+    if (mCachedOutputChannelMask != UNSET_OUTPUT_CHANNEL_MASK) {
+        ALOGI("channel mask set, trying to use value %d", mCachedOutputChannelMask);
+        // If the channel mask has been set, we'll use that.
+        return c2_soft_iamf_internal::GetIamfLayout(mCachedOutputChannelMask);
+    }
+    // Fall back to using the max output channels.
+    ALOGI("channel mask not set, checking max channel count: %d", mCachedMaxOutputChannelCount);
+    if (mCachedMaxOutputChannelCount == UNSET_MAX_OUTPUT_CHANNELS) {
+        // Stereo default, if not set.
+        ALOGI("max output channels not set, defaulting to stereo.");
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0;
+    }
+    if (mCachedMaxOutputChannelCount <= 1) {
+        ALOGI("max output channels set to %d, using mono.", mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_0_1_0;
+    }
+    if (mCachedMaxOutputChannelCount <= 5) {  // 2 to 5 channels, use stereo.
+        ALOGI("max output channels set to %d, using stereo.", mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0;
+    }
+    if (mCachedMaxOutputChannelCount <= 7) {  // 6 or 7 channels, use 5.1.
+        ALOGI("max output channels set to %d, using 5.1.", mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemB_0_5_0;
+    }
+    if (mCachedMaxOutputChannelCount <= 9) {  // 8 or 9 channels, use 7.1.
+        ALOGI("max output channels set to %d, using 7.1.", mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemI_0_7_0;
+    }
+    if (mCachedMaxOutputChannelCount == 10) {  // 10 channels, use Sound System D, 5.1.4.
+        ALOGI("max output channels set to %d, using Sound System D, (5.1.4)",
+              mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemD_4_5_0;
+    }
+    if (mCachedMaxOutputChannelCount == 11) {  // Exactly 11 channels, use Sound System E.
+        ALOGI("max output channels set to %d, using Sound System E (4+5+1)",
+              mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemE_4_5_1;
+    }
+    if (mCachedMaxOutputChannelCount == 12) {  // Exactly 12 channels, use Sound System J, 7.1.4.
+        ALOGI("max output channels set to %d, using Sound System J (7.1.4)",
+              mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemJ_4_7_0;
+    }
+    if (mCachedMaxOutputChannelCount <= 15) {  // 13 to 15 channels, use Sound System G (4+9+0)
+        ALOGI("max output channels set to %d, using Sound System G (4+9+0)",
+              mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemG_4_9_0;
+    }
+    if (mCachedMaxOutputChannelCount < 24) {  // 16 to 23 channels, use 9.1.6
+        ALOGI("max output channels set to %d, using 9.1.6", mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_6_9_0;
+    }
+    if (mCachedMaxOutputChannelCount == 24) {  // 24 channels use Sound System H (22.2)
+        ALOGI("max output channels set to %d, using Sound System H (22.2)",
+              mCachedMaxOutputChannelCount);
+        return iamf_tools::api::OutputLayout::kItu2051_SoundSystemH_9_10_3;
+    }
+    // Any other value.
+    ALOGI("max output channels set to %d, defaulting to stereo.", mCachedMaxOutputChannelCount);
+    return iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0;
+}
+
+::iamf_tools::api::IamfDecoder::Settings C2SoftIamfDec::getIamfDecoderSettings() {
+    mOutputLayout = getTargetOutputLayout();
+    ALOGV("Creating decoder with IAMF OutputLayout %d.", mOutputLayout);
+    return {.requested_layout = mOutputLayout,
+            // Here we ask for default, IAMF ordering in favor of reordering for Android in this
+            // file.
+            .channel_ordering = ::iamf_tools::api::ChannelOrdering::kOrderingForAndroid,
+            .requested_profile_versions = {
+                    // Explicitly only request simple and base.
+                    ::iamf_tools::api::ProfileVersion::kIamfSimpleProfile,
+                    ::iamf_tools::api::ProfileVersion::kIamfBaseProfile,
+            }};
+}
+
+c2_status_t C2SoftIamfDec::initializeDecoder() {
+    ALOGV("Creating new decoder.");
+    mIamfDecoder = nullptr;
+    mOutputBufferSizeBytes = 0;
+    mDescriptorProcessingComplete = false;
+    mSignalledError = false;
+    mSignalledEos = false;
+
+    const auto settings = getIamfDecoderSettings();
+    const IamfStatus status = IamfDecoder::Create(settings, mIamfDecoder);
+    if (!status.ok()) {
+        // IamfDecoder::Create fails if it cannot create the ReadBitBuffer.
+        mSignalledError = true;
+        return C2_NO_MEMORY;
+    }
+    // Set to request only LE int16 samples as specified in the above params.
+    mIamfDecoder->ConfigureOutputSampleType(iamf_tools::api::OutputSampleType::kInt16LittleEndian);
+
+    ALOGV("Decoder created.");
+    return C2_OK;
+}
+
+c2_status_t C2SoftIamfDec::createNewDecoderWithDescriptorObus(const uint8_t* data,
+                                                              size_t dataSize) {
+    ALOGV("Creating new decoder from Descriptor OBUs.");
+    mIamfDecoder = nullptr;
+    mOutputBufferSizeBytes = 0;
+    mDescriptorProcessingComplete = false;
+    mSignalledError = false;
+    mSignalledEos = false;
+    const auto settings = getIamfDecoderSettings();
+    const IamfStatus status =
+            IamfDecoder::CreateFromDescriptors(settings, data, dataSize, mIamfDecoder);
+    if (!status.ok()) {
+        ALOGW("Failed to create decoder.");
+        // IamfDecoder::Create fails if it cannot create the ReadBitBuffer.
+        mSignalledError = true;
+        return C2_NO_MEMORY;
+    }
+    // Set to request only LE int16 samples as specified in the above params.
+    mIamfDecoder->ConfigureOutputSampleType(iamf_tools::api::OutputSampleType::kInt16LittleEndian);
+
+    ALOGV("Decoder created with Descriptor OBUs");
+    // We do NOT set mDescriptorProcessingComplete true here because we need to
+    // get all the frame size, sample rate, etc values in `process`.
+    return C2_OK;
+}
+
 c2_status_t C2SoftIamfDec::onInit() {
-    return C2_BAD_STATE;
+    ALOGV("onInit.");
+    return initializeDecoder();
 }
 
 c2_status_t C2SoftIamfDec::onStop() {
-    return C2_NO_INIT;
+    ALOGV("onStop.");
+    // onStop should preserve the mIntf state, but not the underlying decoder.
+    if (mIamfDecoder) {
+        // We're destroying the decoder, nothing we want to do with an error.
+        (void)mIamfDecoder->Close();
+        mIamfDecoder = nullptr;
+    }
+    mOutputBufferSizeBytes = 0;
+    mDescriptorProcessingComplete = false;
+    mSignalledError = false;
+    mSignalledEos = false;
+    return initializeDecoder();
 }
 
 void C2SoftIamfDec::onReset() {
-    return;
+    ALOGV("onReset.");
+    // Reset should re-initialize.
+    (void)onStop();
 }
 
 void C2SoftIamfDec::onRelease() {
-    return;
+    ALOGV("onRelease.");
+    // onRelease, the decoder is guaranteed not to be used again, so we release
+    // the decoder without worrying about resetting state.
+    if (mIamfDecoder) {
+        // We're destroying the decoder, nothing we want to do with an error.
+        (void)mIamfDecoder->Close();
+        mIamfDecoder = nullptr;
+    }
 }
 
 c2_status_t C2SoftIamfDec::onFlush_sm() {
-    return C2_NO_INIT;
+    ALOGV("onFlush_sm.");
+    IamfStatus status = mIamfDecoder->Reset();  // Throw away any pending work.
+    // The decoder may fail to reset if it was not created with DescriptorOBUs.
+    if (status.ok()) {
+        // We may be jumping back in time.
+        mSignalledEos = false;
+        return C2_OK;
+    }
+    ALOGE("Failed to reset. Error: %s", status.error_message.c_str());
+    // We failed to Reset.  We'll just get rid of the decoder.
+    mIamfDecoder = nullptr;
+    return C2_OK;
+}
+
+void C2SoftIamfDec::getAnyTemporalUnits(const std::unique_ptr<C2Work>& work,
+                                        const std::shared_ptr<C2BlockPool>& pool) {
+    while (mIamfDecoder->IsTemporalUnitAvailable()) {
+        // Get writing block into a Span for writing by the |mIamfDecoder|.
+        shared_ptr<C2LinearBlock> block;
+        c2_status_t fetch_block_status =
+                pool->fetchLinearBlock(mOutputBufferSizeBytes,
+                                       {C2MemoryUsage::CPU_READ, C2MemoryUsage::CPU_WRITE}, &block);
+        if (fetch_block_status != C2_OK) {
+            ALOGE("fetchLinearBlock for Output failed with status %d", fetch_block_status);
+            mSignalledError = true;
+            work->result = C2_NO_MEMORY;
+            return;
+        }
+        C2WriteView wView = block->map().get();
+        if (wView.error()) {
+            ALOGE("write view map failed %d", wView.error());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+        size_t bytesWritten = 0;
+        IamfStatus status = mIamfDecoder->GetOutputTemporalUnit(
+                wView.data(), mOutputBufferSizeBytes, bytesWritten);
+        if (!status.ok()) {
+            ALOGE("Failed to get temporal unit. Error message: %s", status.error_message.c_str());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+        ALOGV("out buffer attr. size %zu", bytesWritten);
+        work->worklets.front()->output.buffers.push_back(
+                createLinearBuffer(block, 0, bytesWritten));
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+    }
 }
 
 void C2SoftIamfDec::process(const std::unique_ptr<C2Work>& work,
-                            const std::shared_ptr<C2BlockPool>& pool) {
-    return;
+                            const shared_ptr<C2BlockPool>& pool) {
+    if (!mIamfDecoder) {
+        ALOGE("Decoder instance is null.");
+        return;
+    }
+    // N.B.: Android only supports single input buffer and single worklet.
+
+    // Initialize output work to assume OK and that we will process one worklet.
+    work->result = C2_OK;
+    work->workletsProcessed = 1u;
+    // For output buffers, `configUpdate` is for communicating responses, start clear.
+    work->worklets.front()->output.configUpdate.clear();
+    // Copy flags from work->input to first worklet's output.
+    work->worklets.front()->output.flags = work->input.flags;
+    // Clear output buffers
+    work->worklets.front()->output.buffers.clear();
+
+    if (mSignalledError || mSignalledEos) {
+        // We already had an error or EOS signalled previously, we should not have
+        // had `process` called again.
+        work->result = C2_BAD_VALUE;
+        return;
+    }
+
+    // If channel mask or max output channel count has changed, we reset the decoder if and only if
+    // the new values result in a different layout.
+    const bool outputMaskOrMaxCountChanged =
+            mCachedOutputChannelMask != mIntf->getOutputChannelMask() ||
+            mCachedMaxOutputChannelCount != mIntf->getMaxOutputChannelCount();
+    if (outputMaskOrMaxCountChanged) {
+        // Since resetting to a different layout is disruptive, only do it if we're sure it results
+        // in a different output IAMF Layout.
+        if (auto newLayout = getTargetOutputLayout(); newLayout != mOutputLayout) {
+            mOutputLayout = newLayout;
+            IamfStatus status = mIamfDecoder->ResetWithNewLayout(mOutputLayout);
+            if (!status.ok()) {
+                // Layout cannot be changed if decoder was not created with DescriptorOBUs.
+                ALOGE("Failed to reset with new layout. Error message: %s",
+                      status.error_message.c_str());
+                mSignalledError = true;
+                work->result = C2_CORRUPTED;
+                return;
+            }
+        }
+    }
+
+    // mDummyReadView provided by SimpleC2Component just returns C2_NO_INIT.
+    // It is here as a placeholder.
+    C2ReadView readView = mDummyReadView;
+    size_t inSize = 0u;  // Initially zero until set from readView.
+    if (!work->input.buffers.empty()) {
+        // Input buffers are not empty, so there is work to be done.
+        readView = work->input.buffers[0]->data().linearBlocks().front().map().get();
+        inSize = readView.capacity();
+        // readView could give a capacity of 0 when there are no new bytes to process,
+        // so it signals an error only when the readView has an error.
+        if (inSize != 0 && readView.error()) {
+            ALOGE("ReadView map failed %d", readView.error());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+    }
+    if (inSize == 0) {
+        // If inSize is still zero at this point, then there is no input to process.
+        work->worklets.front()->output.ordinal = work->input.ordinal;
+        work->workletsProcessed = 1u;
+        // No more data to send to decode if inSize is 0 and EOS signalled.
+        if (work->input.flags & C2FrameData::FLAG_END_OF_STREAM) {
+            mIamfDecoder->SignalEndOfDecoding();
+            mSignalledEos = true;
+            ALOGV("signalled EOS");
+        }
+        // For IAMF, we will still try to fetch a temporal unit at EOS.
+        getAnyTemporalUnits(work, pool);
+        return;
+    }
+
+    ALOGV("in buffer attr. size %zu timestamp %d frameindex %d", inSize,
+          (int)work->input.ordinal.timestamp.peeku(), (int)work->input.ordinal.frameIndex.peeku());
+
+    const bool isCodecConfig = work->input.flags & C2FrameData::FLAG_CODEC_CONFIG;
+    if (isCodecConfig) {
+        ALOGV("Got codec config.");
+        // If the CodecConfig flag is set, then we're assuming the buffer contains
+        // exactly and only the DescriptorObus.  We can re-create the IamfDecoder with the
+        // DescriptorObus (Codec Config) for more efficient decoding of all subsequent Temporal
+        // Units.
+        c2_status_t initializeStatus = createNewDecoderWithDescriptorObus(readView.data(), inSize);
+        if (initializeStatus != C2_OK) {
+            ALOGE("Failed to initialize decoder with descriptor OBUs. Error code: %d",
+                  initializeStatus);
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+    } else {
+        // If not a CodecConfig, we just try to Decode.
+        IamfStatus decodeStatus = mIamfDecoder->Decode(readView.data(), inSize);
+        if (!decodeStatus.ok()) {
+            ALOGE("Failed to decode. Error message: %s", decodeStatus.error_message.c_str());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+    }
+
+    // The first time that IsDescriptorProcessingComplete returns true, we update config.
+    if (!mDescriptorProcessingComplete && mIamfDecoder->IsDescriptorProcessingComplete()) {
+        // First time we are seeing descriptor processing as complete.
+        ALOGV("Decoder signaled descriptor processing complete.");
+        mDescriptorProcessingComplete = true;
+
+        // Here we should get the sample rate info and Layout and update.
+        uint32_t sampleRate;
+        IamfStatus sampleRateStatus = mIamfDecoder->GetSampleRate(sampleRate);
+        if (!sampleRateStatus.ok()) {
+            ALOGE("Failed to get sample rate. Error message: %s",
+                  sampleRateStatus.error_message.c_str());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+        ALOGV("successfully got sample rate: %d", sampleRate);
+        C2StreamSampleRateInfo::output sampleRateInfo(0u, sampleRate);
+
+        // The Layout used may be different than what was requested in IamfDecoder::Create
+        // because of the content of the stream.  Here we get the actual Layout that will be
+        // used and convert to a ChannelMask.
+        iamf_tools::api::OutputLayout actualLayout;
+        IamfStatus layoutStatus = mIamfDecoder->GetOutputLayout(actualLayout);
+        if (!layoutStatus.ok()) {
+            ALOGE("Failed to get output layout. Error message: %s",
+                  layoutStatus.error_message.c_str());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+        ALOGV("successfully got actual output layout: %d", actualLayout);
+        uint32_t actualChannelMask = c2_soft_iamf_internal::GetAndroidChannelMask(actualLayout);
+        C2StreamChannelMaskInfo::output channelMaskInfo(0u, actualChannelMask);
+
+        // Get the number of output channels.
+        int numOutputChannels;
+        IamfStatus numOutputChannelsStatus =
+                mIamfDecoder->GetNumberOfOutputChannels(numOutputChannels);
+        if (!numOutputChannelsStatus.ok()) {
+            ALOGE("Failed to get number of output channels. Error message: %s",
+                  numOutputChannelsStatus.error_message.c_str());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+        ALOGV("successfully got number of output channels: %d", numOutputChannels);
+        C2StreamChannelCountInfo::output channelCountInfo(0u, numOutputChannels);
+
+        // We collect the failures but do not use them.
+        std::vector<std::unique_ptr<C2SettingResult>> failures;
+        // Update the config in the params.
+        const c2_status_t configStatus = mIntf->config(
+                {&sampleRateInfo, &channelMaskInfo, &channelCountInfo}, C2_MAY_BLOCK, &failures);
+        if (configStatus == C2_OK) {
+            // Include the config update in the work for the caller to see.
+            work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(sampleRateInfo));
+            work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(channelMaskInfo));
+            work->worklets.front()->output.configUpdate.push_back(C2Param::Copy(channelCountInfo));
+            ALOGV("successfully updated config.");
+        } else {
+            ALOGE("Config Update failed");
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+
+        // We want to calculate the max size we need for the write buffer for output and for
+        // that, we need the frame size.
+        uint32_t frameSize;
+        IamfStatus frameSizeStatus = mIamfDecoder->GetFrameSize(frameSize);
+        if (!frameSizeStatus.ok()) {
+            ALOGE("Failed to get frame size. Error message: %s",
+                  frameSizeStatus.error_message.c_str());
+            mSignalledError = true;
+            work->result = C2_CORRUPTED;
+            return;
+        }
+        ALOGV("successfully got frame size: %d", frameSize);
+
+        mOutputBufferSizeBytes = (size_t)frameSize * sizeof(int16_t) * (size_t)numOutputChannels;
+        ALOGV("calculated frame size bytes: %zu", mOutputBufferSizeBytes);
+    }  // Done updating config.
+
+    // In any case, check for finished temporal units to return.
+    getAnyTemporalUnits(work, pool);
 }
 
-c2_status_t C2SoftIamfDec::drain(uint32_t drainMode, const std::shared_ptr<C2BlockPool>& pool) {
-    return C2_NO_INIT;
+c2_status_t C2SoftIamfDec::drain(uint32_t drainMode, const shared_ptr<C2BlockPool>& pool) {
+    // Practically speaking, drain is unused.
+    (void)pool;
+    // SimpleC2Component
+    if (drainMode == NO_DRAIN) {
+        ALOGW("drain with NO_DRAIN: no-op");
+        return C2_OK;
+    }
+    if (drainMode == DRAIN_CHAIN) {
+        ALOGW("DRAIN_CHAIN not supported");
+        return C2_OMITTED;
+    }
+
+    return C2_OK;
 }
 
+class C2SoftIamfDecFactory : public C2ComponentFactory {
+  public:
+    C2SoftIamfDecFactory()
+        : mHelper(std::static_pointer_cast<C2ReflectorHelper>(
+                  GetCodec2PlatformComponentStore()->getParamReflector())) {}
+
+    virtual c2_status_t createComponent(c2_node_id_t id, shared_ptr<C2Component>* const component,
+                                        std::function<void(C2Component*)> deleter) override {
+        *component = shared_ptr<C2Component>(
+                new C2SoftIamfDec(COMPONENT_NAME, id,
+                                  std::make_shared<C2SoftIamfDec::IntfImpl>(mHelper)),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual c2_status_t createInterface(
+            c2_node_id_t id, shared_ptr<C2ComponentInterface>* const interface,
+            std::function<void(C2ComponentInterface*)> deleter) override {
+        *interface = shared_ptr<C2ComponentInterface>(
+                new SimpleInterface<C2SoftIamfDec::IntfImpl>(
+                        COMPONENT_NAME, id, std::make_shared<C2SoftIamfDec::IntfImpl>(mHelper)),
+                deleter);
+        return C2_OK;
+    }
+
+    virtual ~C2SoftIamfDecFactory() override = default;
+
+  private:
+    shared_ptr<C2ReflectorHelper> mHelper;
+};
+
 }  // namespace android
+
+static bool SufficientSdkVersion() {
+    static int sCurrentSdk = 0;
+    static std::string sCurrentCodeName;
+    static std::once_flag sCheckOnce;
+    std::call_once(sCheckOnce, [&]() {
+        sCurrentSdk = android_get_device_api_level();
+        sCurrentCodeName = android::base::GetProperty("ro.build.version.codename", "<none>");
+    });
+    return sCurrentSdk >= 36 || sCurrentCodeName == "Baklava";
+}
+
+__attribute__((cfi_canonical_jump_table)) extern "C" ::C2ComponentFactory* CreateCodec2Factory() {
+    ALOGV("in %s", __func__);
+    if (!android::media::swcodec::flags::iamf_software_decoder()) {
+        ALOGV("IAMF SW decoder is disabled by flag.");
+        return nullptr;
+    }
+
+    bool enabled = SufficientSdkVersion();
+    if (!enabled) {
+        return nullptr;
+    }
+    return new ::android::C2SoftIamfDecFactory();
+}
+
+__attribute__((cfi_canonical_jump_table)) extern "C" void DestroyCodec2Factory(
+        ::C2ComponentFactory* factory) {
+    ALOGV("in %s", __func__);
+    delete factory;
+}
diff --git a/media/codec2/components/iamf/C2SoftIamfDec.h b/media/codec2/components/iamf/C2SoftIamfDec.h
index 547b3bae20..58deb102f0 100644
--- a/media/codec2/components/iamf/C2SoftIamfDec.h
+++ b/media/codec2/components/iamf/C2SoftIamfDec.h
@@ -17,15 +17,20 @@
 #ifndef ANDROID_C2_SOFT_IAMF_DEC_H_
 #define ANDROID_C2_SOFT_IAMF_DEC_H_
 
+#include <cstddef>
+#include <cstdint>
+
 #include <SimpleC2Component.h>
+#include <iamf_tools/iamf_decoder.h>
+#include <iamf_tools/iamf_tools_api_types.h>
 
 namespace android {
 
 class C2SoftIamfDec : public SimpleC2Component {
+  public:
     // Forward declaration of the C2 interface implementation.
     class IntfImpl;
 
-  public:
     C2SoftIamfDec(const char* name, c2_node_id_t id, const std::shared_ptr<IntfImpl>& intfImpl);
     virtual ~C2SoftIamfDec();
 
@@ -40,8 +45,35 @@ class C2SoftIamfDec : public SimpleC2Component {
     c2_status_t drain(uint32_t drainMode, const std::shared_ptr<C2BlockPool>& pool) override;
 
   private:
+    // Returns the layout requested by the caller via channel count or mask.
+    ::iamf_tools::api::OutputLayout getTargetOutputLayout();
+    ::iamf_tools::api::IamfDecoder::Settings getIamfDecoderSettings();
+    // Initializes a decoder without the IAMF config (Descriptor OBUs).  They will be parsed from
+    // subsequent calls to Decode.
+    c2_status_t initializeDecoder();
+    // Creates a decoder when the Descriptor OBUs are provided as one block and signaled with the
+    // codec config flag.
+    c2_status_t createNewDecoderWithDescriptorObus(const uint8_t* data, size_t data_size);
+    // Fetches any decoded audio from the decoder, writing into work output.
+    void getAnyTemporalUnits(const std::unique_ptr<C2Work>& work,
+                             const std::shared_ptr<C2BlockPool>& pool);
+    void reorderForAndroidIfNeeded(uint8_t* buffer, size_t number_bytes);
+
     std::shared_ptr<IntfImpl> mIntf;
-}
+    std::unique_ptr<::iamf_tools::api::IamfDecoder> mIamfDecoder;
+
+    uint32_t mCachedOutputChannelMask = 0;
+    uint32_t mCachedMaxOutputChannelCount = 0;
+    ::iamf_tools::api::OutputLayout mOutputLayout =
+            ::iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0;
+    // N.B.: Calculation of this number assumes int16_t samples.
+    size_t mOutputBufferSizeBytes = 0;
+    bool mDescriptorProcessingComplete = false;
+    bool mSignalledError = false;
+    bool mSignalledEos = false;
+
+    C2_DO_NOT_COPY(C2SoftIamfDec);
+};
 
 }  // namespace android
 
diff --git a/media/codec2/components/iamf/LayoutTranslation.cpp b/media/codec2/components/iamf/LayoutTranslation.cpp
new file mode 100644
index 0000000000..c71ab2edbb
--- /dev/null
+++ b/media/codec2/components/iamf/LayoutTranslation.cpp
@@ -0,0 +1,220 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "LayoutTranslation.h"
+
+#include <iamf_tools/iamf_tools_api_types.h>
+#include <log/log.h>
+
+namespace android {
+namespace c2_soft_iamf_internal {
+
+namespace {
+// All values of CHANNEL_OUT_* are copied from android.media.AudioFormat.java
+// but only including the values needed.
+constexpr uint32_t CHANNEL_OUT_FRONT_LEFT = 0x4;
+constexpr uint32_t CHANNEL_OUT_FRONT_RIGHT = 0x8;
+constexpr uint32_t CHANNEL_OUT_FRONT_CENTER = 0x10;
+constexpr uint32_t CHANNEL_OUT_LOW_FREQUENCY = 0x20;
+constexpr uint32_t CHANNEL_OUT_BACK_LEFT = 0x40;
+constexpr uint32_t CHANNEL_OUT_BACK_RIGHT = 0x80;
+constexpr uint32_t CHANNEL_OUT_FRONT_LEFT_OF_CENTER = 0x100;
+constexpr uint32_t CHANNEL_OUT_FRONT_RIGHT_OF_CENTER = 0x200;
+constexpr uint32_t CHANNEL_OUT_BACK_CENTER = 0x400;
+constexpr uint32_t CHANNEL_OUT_SIDE_LEFT = 0x800;
+constexpr uint32_t CHANNEL_OUT_SIDE_RIGHT = 0x1000;
+constexpr uint32_t CHANNEL_OUT_TOP_CENTER = 0x2000;
+constexpr uint32_t CHANNEL_OUT_TOP_FRONT_LEFT = 0x4000;
+constexpr uint32_t CHANNEL_OUT_TOP_FRONT_CENTER = 0x8000;
+constexpr uint32_t CHANNEL_OUT_TOP_FRONT_RIGHT = 0x10000;
+constexpr uint32_t CHANNEL_OUT_TOP_BACK_LEFT = 0x20000;
+constexpr uint32_t CHANNEL_OUT_TOP_BACK_CENTER = 0x40000;
+constexpr uint32_t CHANNEL_OUT_TOP_BACK_RIGHT = 0x80000;
+// These two only used for Android's (non-IAMF/non-ITU) 5.1.2 and 7.1.2.
+constexpr uint32_t CHANNEL_OUT_TOP_SIDE_LEFT = 0x100000;
+constexpr uint32_t CHANNEL_OUT_TOP_SIDE_RIGHT = 0x200000;
+// Bottom channels used by ITU Sound Systems E (4+5+1) and H (9+10+3).
+constexpr uint32_t CHANNEL_OUT_BOTTOM_FRONT_LEFT = 0x400000;
+constexpr uint32_t CHANNEL_OUT_BOTTOM_FRONT_CENTER = 0x800000;
+constexpr uint32_t CHANNEL_OUT_BOTTOM_FRONT_RIGHT = 0x1000000;
+// Used by ITU Sound System F (3+7+0) and H (9+10+3).
+constexpr uint32_t CHANNEL_OUT_LOW_FREQUENCY_2 = 0x2000000;
+// Used by layouts with 9 speakers in the middle plane (9.1.4, 9.1.6, ITU H).
+constexpr uint32_t CHANNEL_OUT_FRONT_WIDE_LEFT = 0x4000000;
+constexpr uint32_t CHANNEL_OUT_FRONT_WIDE_RIGHT = 0x8000000;
+
+// All of these CHANNEL_OUT_ combinations are Android-defined combinations of ChannelMasks that
+// match IAMF OutputLayouts and are copied from AudioFormat.java.
+constexpr uint32_t CHANNEL_OUT_MONO = CHANNEL_OUT_FRONT_LEFT;
+constexpr uint32_t CHANNEL_OUT_STEREO = (CHANNEL_OUT_FRONT_LEFT | CHANNEL_OUT_FRONT_RIGHT);
+constexpr uint32_t CHANNEL_OUT_5POINT1 =
+        (CHANNEL_OUT_FRONT_LEFT | CHANNEL_OUT_FRONT_RIGHT | CHANNEL_OUT_FRONT_CENTER |
+         CHANNEL_OUT_LOW_FREQUENCY | CHANNEL_OUT_BACK_LEFT | CHANNEL_OUT_BACK_RIGHT);
+constexpr uint32_t CHANNEL_OUT_5POINT1POINT4 =
+        (CHANNEL_OUT_5POINT1 | CHANNEL_OUT_TOP_FRONT_LEFT | CHANNEL_OUT_TOP_FRONT_RIGHT |
+         CHANNEL_OUT_TOP_BACK_LEFT | CHANNEL_OUT_TOP_BACK_RIGHT);
+constexpr uint32_t CHANNEL_OUT_7POINT1_SURROUND =
+        (CHANNEL_OUT_FRONT_LEFT | CHANNEL_OUT_FRONT_CENTER | CHANNEL_OUT_FRONT_RIGHT |
+         CHANNEL_OUT_SIDE_LEFT | CHANNEL_OUT_SIDE_RIGHT | CHANNEL_OUT_BACK_LEFT |
+         CHANNEL_OUT_BACK_RIGHT | CHANNEL_OUT_LOW_FREQUENCY);
+constexpr uint32_t CHANNEL_OUT_7POINT1POINT4 =
+        (CHANNEL_OUT_7POINT1_SURROUND | CHANNEL_OUT_TOP_FRONT_LEFT | CHANNEL_OUT_TOP_FRONT_RIGHT |
+         CHANNEL_OUT_TOP_BACK_LEFT | CHANNEL_OUT_TOP_BACK_RIGHT);
+constexpr uint32_t CHANNEL_OUT_9POINT1POINT4 =
+        (CHANNEL_OUT_7POINT1POINT4 | CHANNEL_OUT_FRONT_WIDE_LEFT | CHANNEL_OUT_FRONT_WIDE_RIGHT);
+constexpr uint32_t CHANNEL_OUT_9POINT1POINT6 =
+        (CHANNEL_OUT_9POINT1POINT4 | CHANNEL_OUT_TOP_SIDE_LEFT | CHANNEL_OUT_TOP_SIDE_RIGHT);
+constexpr uint32_t CHANNEL_OUT_22POINT2 =
+        (CHANNEL_OUT_7POINT1POINT4 | CHANNEL_OUT_FRONT_LEFT_OF_CENTER |
+         CHANNEL_OUT_FRONT_RIGHT_OF_CENTER | CHANNEL_OUT_BACK_CENTER | CHANNEL_OUT_TOP_CENTER |
+         CHANNEL_OUT_TOP_FRONT_CENTER | CHANNEL_OUT_TOP_BACK_CENTER | CHANNEL_OUT_TOP_SIDE_LEFT |
+         CHANNEL_OUT_TOP_SIDE_RIGHT | CHANNEL_OUT_BOTTOM_FRONT_LEFT |
+         CHANNEL_OUT_BOTTOM_FRONT_RIGHT | CHANNEL_OUT_BOTTOM_FRONT_CENTER |
+         CHANNEL_OUT_LOW_FREQUENCY_2);
+
+// These 5.1.2 and 7.1.2, are copied from AudioFormat.java, but do not match the ITU standard/IAMF
+// spec because they use top side L/R rather than top front L/R, but we will match it to the
+// ITU/IAMF 5.1.2 and 7.1.2.
+constexpr uint32_t CHANNEL_OUT_5POINT1POINT2 =
+        (CHANNEL_OUT_5POINT1 | CHANNEL_OUT_TOP_SIDE_LEFT | CHANNEL_OUT_TOP_SIDE_RIGHT);
+constexpr uint32_t CHANNEL_OUT_7POINT1POINT2 =
+        (CHANNEL_OUT_7POINT1_SURROUND | CHANNEL_OUT_TOP_SIDE_LEFT | CHANNEL_OUT_TOP_SIDE_RIGHT);
+
+// The above CHANNEL_OUT_9POINT1POINT4 and CHANNEL_OUT_9POINT1POINT6 use _WIDE_LEFT and _WIDE_RIGHT
+// but the ITU spec for Sound System G says "left [/right] screen edge" and the ITU spec for Sound
+// System H, which is the basis for the IAMF 9.1.6 uses LEFT/RIGHT_OF_CENTER so we'll allow
+// permissive matching.
+constexpr uint32_t IAMF_9POINT1POINT4 =
+        (CHANNEL_OUT_7POINT1POINT4 | CHANNEL_OUT_FRONT_LEFT_OF_CENTER |
+         CHANNEL_OUT_FRONT_RIGHT_OF_CENTER);
+constexpr uint32_t IAMF_9POINT1POINT6 =
+        (IAMF_9POINT1POINT4 | CHANNEL_OUT_TOP_SIDE_LEFT | CHANNEL_OUT_TOP_SIDE_RIGHT);
+
+// Sound Systems E, F, and H are defined in ITU B.S. 2051-3 but are not defined by Android.
+// We can make them from combinations of speakers available in Android.
+constexpr uint32_t ITU_2051_SOUND_SYSTEM_E_4_5_1 =
+        (CHANNEL_OUT_5POINT1POINT4 | CHANNEL_OUT_BOTTOM_FRONT_CENTER);
+constexpr uint32_t ITU_2051_SOUND_SYSTEM_F_3_7_0 =
+        (CHANNEL_OUT_7POINT1_SURROUND | CHANNEL_OUT_TOP_FRONT_LEFT | CHANNEL_OUT_TOP_FRONT_RIGHT |
+         CHANNEL_OUT_TOP_BACK_CENTER | CHANNEL_OUT_LOW_FREQUENCY_2);
+
+// The Android defined 5.1.2 (ITU Sound System C) and 7.1.2 use top *side* left/right which does not
+// match their ITU/IAMF equivalents. We will define the ITU/IAMF versions here.
+constexpr uint32_t ITU_2051_SOUND_SYSTEM_C_2_5_0 =
+        (CHANNEL_OUT_5POINT1 | CHANNEL_OUT_TOP_FRONT_LEFT | CHANNEL_OUT_TOP_FRONT_RIGHT);
+constexpr uint32_t IAMF_7POINT1POINT2 =
+        (CHANNEL_OUT_7POINT1_SURROUND | CHANNEL_OUT_TOP_FRONT_LEFT | CHANNEL_OUT_TOP_FRONT_RIGHT);
+
+// This is just an IAMF layout that does not have an Android-defined version.
+constexpr uint32_t IAMF_3POINT1POINT2 =
+        (CHANNEL_OUT_FRONT_LEFT | CHANNEL_OUT_FRONT_RIGHT | CHANNEL_OUT_FRONT_CENTER |
+         CHANNEL_OUT_LOW_FREQUENCY | CHANNEL_OUT_TOP_FRONT_LEFT | CHANNEL_OUT_TOP_FRONT_RIGHT);
+}  // namespace
+
+iamf_tools::api::OutputLayout GetIamfLayout(uint32_t channelMask) {
+    switch (channelMask) {
+        case CHANNEL_OUT_STEREO:
+            // ITU-R B.S. 2051-3 sound system A (0+2+0), commonly known as Stereo.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0;
+        case CHANNEL_OUT_5POINT1:
+            // ITU-R B.S. 2051-3 sound system B (0+5+0), commonly known as 5.1.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemB_0_5_0;
+        case CHANNEL_OUT_5POINT1POINT2:
+        case ITU_2051_SOUND_SYSTEM_C_2_5_0:
+            // Here we match both the ITU/IAMF 5.1.2 as well as Android's 5.1.2.
+            // ITU-R B.S. 2051-3 sound system C (2+5+0), commonly known as 5.1.2.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemC_2_5_0;
+        case CHANNEL_OUT_5POINT1POINT4:
+            // ITU-R B.S. 2051-3 sound system D (4+5+0), commonly known as 5.1.4.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemD_4_5_0;
+        case ITU_2051_SOUND_SYSTEM_E_4_5_1:
+            // ITU-R B.S. 2051-3 sound system E (4+5+1).
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemE_4_5_1;
+        case ITU_2051_SOUND_SYSTEM_F_3_7_0:
+            // ITU-R B.S. 2051-3 sound system F (3+7+0).
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemF_3_7_0;
+        case CHANNEL_OUT_9POINT1POINT4:
+        case IAMF_9POINT1POINT4:
+            // ITU-R B.S. 2051-3 sound system G (4+9+0).
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemG_4_9_0;
+        case CHANNEL_OUT_22POINT2:
+            // ITU-R B.S. 2051-3 sound system H (9+10+3), commonly known as 22.2.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemH_9_10_3;
+        case CHANNEL_OUT_7POINT1_SURROUND:
+            // ITU-R B.S. 2051-3 sound system I (0+7+0), commonly known as 7.1.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemI_0_7_0;
+        case CHANNEL_OUT_7POINT1POINT4:
+            // ITU-R B.S. 2051-3 sound system J (4+7+0), commonly known as 7.1.4.
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemJ_4_7_0;
+        case CHANNEL_OUT_7POINT1POINT2:
+        case IAMF_7POINT1POINT2:
+            // IAMF extension 7.1.2.
+            return iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_2_7_0;
+        case IAMF_3POINT1POINT2:
+            // IAMF extension 3.1.2.
+            return iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_2_3_0;
+        case CHANNEL_OUT_MONO:
+            // Mono.
+            return iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_0_1_0;
+        case CHANNEL_OUT_9POINT1POINT6:
+        case IAMF_9POINT1POINT6:
+            // IAMF Extension 9.1.6.
+            return iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_6_9_0;
+        default:
+            ALOGW("No matching IAMF Layout found for given ChannelMask: %d.  Defaulting to Stereo.",
+                  channelMask);
+            return iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0;
+    }
+}
+
+uint32_t GetAndroidChannelMask(iamf_tools::api::OutputLayout iamf_layout) {
+    switch (iamf_layout) {
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemA_0_2_0:
+            return CHANNEL_OUT_STEREO;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemB_0_5_0:
+            return CHANNEL_OUT_5POINT1;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemC_2_5_0:
+            return ITU_2051_SOUND_SYSTEM_C_2_5_0;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemD_4_5_0:
+            return CHANNEL_OUT_5POINT1POINT4;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemE_4_5_1:
+            return ITU_2051_SOUND_SYSTEM_E_4_5_1;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemF_3_7_0:
+            return ITU_2051_SOUND_SYSTEM_F_3_7_0;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemG_4_9_0:
+            return CHANNEL_OUT_9POINT1POINT4;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemH_9_10_3:
+            return CHANNEL_OUT_22POINT2;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemI_0_7_0:
+            return CHANNEL_OUT_7POINT1_SURROUND;
+        case iamf_tools::api::OutputLayout::kItu2051_SoundSystemJ_4_7_0:
+            return CHANNEL_OUT_7POINT1POINT4;
+        case iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_2_7_0:
+            return IAMF_7POINT1POINT2;
+        case iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_2_3_0:
+            return IAMF_3POINT1POINT2;
+        case iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_0_1_0:
+            return CHANNEL_OUT_MONO;
+        case iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_6_9_0:
+            return CHANNEL_OUT_9POINT1POINT6;
+        default:
+            ALOGW("Invalid iamf_tools::api::OutputLayout received.  Returning stereo.");
+            return CHANNEL_OUT_STEREO;
+    }
+}
+
+}  // namespace c2_soft_iamf_internal
+}  // namespace android
\ No newline at end of file
diff --git a/media/codec2/components/iamf/LayoutTranslation.h b/media/codec2/components/iamf/LayoutTranslation.h
new file mode 100644
index 0000000000..12f503c4f3
--- /dev/null
+++ b/media/codec2/components/iamf/LayoutTranslation.h
@@ -0,0 +1,37 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef ANDROID_C2_IAMF_LAYOUT_TRANSLATION_H_
+
+#include <iamf_tools/iamf_tools_api_types.h>
+
+namespace android {
+namespace c2_soft_iamf_internal {
+
+// Translate the requested output ChannelMask into one of the IAMF Layouts.
+// ChannelMasks not matching an IAMF Layout are rejected, but
+// CHANNEL_OUT_5POINT1POINT2 and CHANNEL_OUT_7POINT1POINT2 are matched to their
+// near equivalents. IAMF Layouts, from spec 1.0.1:
+// https://aomediacodec.github.io/iamf/#loudspeaker_layout
+iamf_tools::api::OutputLayout GetIamfLayout(uint32_t channelMask);
+
+// Translate an IAMF OutputLayout back into an Android ChannelMask.
+uint32_t GetAndroidChannelMask(iamf_tools::api::OutputLayout iamf_layout);
+
+}  // namespace c2_soft_iamf_internal
+}  // namespace android
+
+#endif  // ANDROID_C2_IAMF_LAYOUT_TRANSLATION_H_
diff --git a/media/codec2/components/iamf/TEST_MAPPING b/media/codec2/components/iamf/TEST_MAPPING
new file mode 100644
index 0000000000..19dec7e69c
--- /dev/null
+++ b/media/codec2/components/iamf/TEST_MAPPING
@@ -0,0 +1,7 @@
+{
+  "presubmit": [
+    {
+      "name": "libcodec2_soft_iamfdec_LayoutTranslationTest"
+    }
+  ]
+}
diff --git a/media/codec2/components/iamf/tests/Android.bp b/media/codec2/components/iamf/tests/Android.bp
new file mode 100644
index 0000000000..70ed371249
--- /dev/null
+++ b/media/codec2/components/iamf/tests/Android.bp
@@ -0,0 +1,29 @@
+package {
+    default_applicable_licenses: ["frameworks_av_license"],
+}
+
+cc_test {
+    name: "libcodec2_soft_iamfdec_LayoutTranslationTest",
+    team: "trendy_team_media_codec_framework",
+    gtest: true,
+    srcs: [
+        "LayoutTranslationTest.cpp",
+    ],
+    static_libs: [
+        "iamf_tools",
+        "libcodec2_soft_iamfdec",
+    ],
+    shared_libs: [
+        "liblog",
+    ],
+    include_dirs: [
+        "frameworks/av/media/codec2/components/iamf/",
+    ],
+    cflags: [
+        "-Wall",
+        "-Werror",
+    ],
+    test_suites: [
+        "general-tests",
+    ],
+}
diff --git a/media/codec2/components/iamf/tests/LayoutTranslationTest.cpp b/media/codec2/components/iamf/tests/LayoutTranslationTest.cpp
new file mode 100644
index 0000000000..9c906a7d77
--- /dev/null
+++ b/media/codec2/components/iamf/tests/LayoutTranslationTest.cpp
@@ -0,0 +1,119 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "LayoutTranslation.h"
+
+#include <gtest/gtest.h>
+#include <log/log.h>
+
+#include <iamf_tools/iamf_tools_api_types.h>
+
+namespace android {
+namespace c2_soft_iamf_internal {
+
+// Helper to count the number of bits set in a channel mask.
+size_t GetNumberChannels(uint32_t android_channel_mask) {
+    size_t number_channels = 0;
+    while (android_channel_mask > 0) {
+        number_channels += android_channel_mask & 1;
+        android_channel_mask >>= 1;
+    }
+    return number_channels;
+}
+using ::iamf_tools::api::OutputLayout;
+
+using ::testing::TestWithParam;
+using LayoutAndChannelCount = std::pair<OutputLayout, size_t>;
+using LayoutRoundtripTest = TestWithParam<LayoutAndChannelCount>;
+
+// Test converting from IAMF Layout to ChannelMask and back and count bits in the channel mask.
+TEST_P(LayoutRoundtripTest, ConvertsToChannelMaskAndBack) {
+    const auto& [iamf_layout, expected_number_channels] = GetParam();
+
+    uint32_t channel_mask = GetAndroidChannelMask(iamf_layout);
+
+    EXPECT_EQ(GetNumberChannels(channel_mask), expected_number_channels);
+    EXPECT_EQ(GetIamfLayout(channel_mask), iamf_layout);
+}
+
+INSTANTIATE_TEST_SUITE_P(
+        LayoutRoundtripTest_Instantiation, LayoutRoundtripTest,
+        ::testing::Values(LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemA_0_2_0, 2),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemB_0_5_0, 6),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemC_2_5_0, 8),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemD_4_5_0, 10),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemE_4_5_1, 11),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemF_3_7_0, 12),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemG_4_9_0, 14),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemH_9_10_3, 24),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemI_0_7_0, 8),
+                          LayoutAndChannelCount(OutputLayout::kItu2051_SoundSystemJ_4_7_0, 12),
+                          LayoutAndChannelCount(OutputLayout::kIAMF_SoundSystemExtension_2_7_0, 10),
+                          LayoutAndChannelCount(OutputLayout::kIAMF_SoundSystemExtension_2_3_0, 6),
+                          LayoutAndChannelCount(OutputLayout::kIAMF_SoundSystemExtension_0_1_0, 1),
+                          LayoutAndChannelCount(OutputLayout::kIAMF_SoundSystemExtension_6_9_0,
+                                                16)));
+
+// Test that both ChannelMask versions of 5.1.2 give the same IAMF Layout.
+TEST(LayoutTranslationTest, EquivalenceOf5point1point2) {
+    constexpr uint32_t android_5p1p2 = 0b1100000000000011111100;
+    constexpr uint32_t iamf_5p1p2 = 0b0000010100000011111100;
+
+    EXPECT_EQ(GetIamfLayout(android_5p1p2),
+              iamf_tools::api::OutputLayout::kItu2051_SoundSystemC_2_5_0);
+    EXPECT_EQ(GetIamfLayout(iamf_5p1p2),
+              iamf_tools::api::OutputLayout::kItu2051_SoundSystemC_2_5_0);
+}
+
+// Test that both ChannelMask versions of 7.1.2 give the same IAMF Layout.
+TEST(LayoutTranslationTest, EquivalenceOf7point1point2) {
+    constexpr uint32_t android_7p1p2 = 0b1100000001100011111100;
+    constexpr uint32_t iamf_7p1p2 = 0b0000010101100011111100;
+
+    EXPECT_EQ(GetIamfLayout(android_7p1p2),
+              iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_2_7_0);
+    EXPECT_EQ(GetIamfLayout(iamf_7p1p2),
+              iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_2_7_0);
+}
+
+TEST(LayoutTranslationTest, EquivalenceOf9point1point4) {
+    constexpr uint32_t android_9p1p4 = 0b1100000010110101100011111100;
+    constexpr uint32_t iamf_9p1p4 = 0b10110101101111111100;
+
+    EXPECT_EQ(GetIamfLayout(android_9p1p4),
+              iamf_tools::api::OutputLayout::kItu2051_SoundSystemG_4_9_0);
+    EXPECT_EQ(GetIamfLayout(iamf_9p1p4),
+              iamf_tools::api::OutputLayout::kItu2051_SoundSystemG_4_9_0);
+}
+
+TEST(LayoutTranslationTest, EquivalenceOf9point1point6) {
+    constexpr uint32_t android_9p1p6 = 0b1100001110110101100011111100;
+    constexpr uint32_t iamf_9p1p6 = 0b0000001110110101101111111100;
+
+    EXPECT_EQ(GetIamfLayout(android_9p1p6),
+              iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_6_9_0);
+    EXPECT_EQ(GetIamfLayout(iamf_9p1p6),
+              iamf_tools::api::OutputLayout::kIAMF_SoundSystemExtension_6_9_0);
+}
+
+TEST(LayoutTranslationTest, NonMatchingChannelMaskBecomesStereo) {
+    constexpr uint32_t arbitrary_value = 0b101010101010101010;
+
+    EXPECT_EQ(GetIamfLayout(arbitrary_value), OutputLayout::kItu2051_SoundSystemA_0_2_0);
+}
+
+}  // namespace c2_soft_iamf_internal
+}  // namespace android
diff --git a/media/codec2/core/include/C2Config.h b/media/codec2/core/include/C2Config.h
index 6dfe90982a..34b71d0bf1 100644
--- a/media/codec2/core/include/C2Config.h
+++ b/media/codec2/core/include/C2Config.h
@@ -29,8 +29,8 @@
  * Enumerated boolean.
  */
 C2ENUM(c2_bool_t, uint32_t,
-    C2_FALSE, ///< true
-    C2_TRUE,  ///< false
+    C2_FALSE, ///< false
+    C2_TRUE,  ///< true
 )
 
 typedef C2SimpleValueStruct<c2_bool_t> C2BoolValue;
@@ -249,7 +249,8 @@ enum C2ParamIndexKind : C2Param::type_index_t {
     kParamIndexDrcEffectType, // drc, enum
     kParamIndexDrcOutputLoudness, // drc, float (dBFS)
     kParamIndexDrcAlbumMode, // drc, enum
-    kParamIndexAudioFrameSize, // int
+    kParamIndexAudioFrameSize, // u32
+    kParamIndexAudioPresentationId,  // i64
 
     /* ============================== platform-defined parameters ============================== */
 
@@ -448,7 +449,7 @@ enum : uint32_t {
     _C2_PL_MPEGH_BASE = 0xB000,     // MPEG-H 3D Audio
     _C2_PL_APV_BASE = 0xC000,     // APV
     _C2_PL_AC4_BASE  = 0xD000,
-
+    _C2_PL_IAMF_START = 0xE000,
     C2_PROFILE_LEVEL_VENDOR_START = 0x70000000,
 };
 
@@ -634,6 +635,20 @@ enum C2Config::profile_t : uint32_t {
     PROFILE_AC4_1_1,                            ///< AC-4 Profile 01.01
     PROFILE_AC4_2_1,                            ///< AC-4 Profile 02.01
     PROFILE_AC4_2_2,                            ///< AC-4 Profile 02.02
+
+    // IAMF Profiles
+    PROFILE_IAMF_SIMPLE_AAC = _C2_PL_IAMF_START, ///< IAMF Simple Profile with AAC
+    PROFILE_IAMF_SIMPLE_FLAC,                    ///< IAMF Simple Profile with FLAC
+    PROFILE_IAMF_SIMPLE_OPUS,                    ///< IAMF Simple Profile with Opus
+    PROFILE_IAMF_SIMPLE_PCM,                     ///< IAMF Simple Profile with PCM
+    PROFILE_IAMF_BASE_AAC,                       ///< IAMF Base Profile with AAC
+    PROFILE_IAMF_BASE_FLAC,                      ///< IAMF Base Profile with FLAC
+    PROFILE_IAMF_BASE_OPUS,                      ///< IAMF Base Profile with Opus
+    PROFILE_IAMF_BASE_PCM,                       ///< IAMF Base Profile with PCM
+    PROFILE_IAMF_BASE_ENHANCED_AAC,              ///< IAMF Base Enhanced with AAC
+    PROFILE_IAMF_BASE_ENHANCED_FLAC,             ///< IAMF Base Enhanced with FLAC
+    PROFILE_IAMF_BASE_ENHANCED_OPUS,             ///< IAMF Base Enhanced with Opus
+    PROFILE_IAMF_BASE_ENHANCED_PCM,              ///< IAMF Base Enhanced with PCM
 };
 
 enum C2Config::level_t : uint32_t {
@@ -2474,6 +2489,14 @@ typedef C2StreamParam<C2Info, C2SimpleArrayStruct<C2AccessUnitInfosStruct>,
 constexpr char C2_PARAMKEY_INPUT_ACCESS_UNIT_INFOS[] = "input.access-unit-infos";
 constexpr char C2_PARAMKEY_OUTPUT_ACCESS_UNIT_INFOS[] = "output.access-unit-infos";
 
+/**
+ * Audio Presentation ID. Used to configure a decoder with an audio presentation
+ * or mix presentation to be decoded.
+ */
+typedef C2GlobalParam<C2Tuning, C2Int64Value, kParamIndexAudioPresentationId>
+        C2AudioPresentationIdTuning;
+const char C2_PARAMKEY_AUDIO_PRESENTATION_ID[] = "algo.audio-presentation-id";
+
 /* --------------------------------------- AAC components --------------------------------------- */
 
 /**
diff --git a/media/codec2/core/include/media/stagefright/codec2/1.0/InputSurface.h b/media/codec2/core/include/media/stagefright/codec2/1.0/InputSurface.h
deleted file mode 100644
index 0a82a6813b..0000000000
--- a/media/codec2/core/include/media/stagefright/codec2/1.0/InputSurface.h
+++ /dev/null
@@ -1,70 +0,0 @@
-/*
- * Copyright 2018, The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef ANDROID_HARDWARE_MEDIA_C2_V1_0_INPUT_SURFACE_H
-#define ANDROID_HARDWARE_MEDIA_C2_V1_0_INPUT_SURFACE_H
-
-#include <memory>
-
-#include <C2Component.h>
-#include <media/stagefright/codec2/1.0/InputSurfaceConnection.h>
-
-namespace android {
-
-class GraphicBufferSource;
-
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_0 {
-namespace implementation {
-
-using ::android::sp;
-
-typedef ::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer
-        HGraphicBufferProducer;
-typedef ::android::IGraphicBufferProducer BGraphicBufferProducer;
-
-// TODO: ::android::TWGraphicBufferProducer<IInputSurface>
-typedef ::android::TWGraphicBufferProducer<HGraphicBufferProducer> InputSurfaceBase;
-
-class InputSurface : public InputSurfaceBase {
-public:
-    virtual ~InputSurface() = default;
-
-    // Methods from IInputSurface
-    sp<InputSurfaceConnection> connectToComponent(
-            const std::shared_ptr<::C2Component> &comp);
-    // TODO: intf()
-
-    static sp<InputSurface> Create();
-
-private:
-    InputSurface(
-            const sp<BGraphicBufferProducer> &base,
-            const sp<::android::GraphicBufferSource> &source);
-
-    sp<::android::GraphicBufferSource> mSource;
-};
-
-}  // namespace implementation
-}  // namespace V1_0
-}  // namespace c2
-}  // namespace media
-}  // namespace hardware
-}  // namespace android
-
-#endif  // ANDROID_HARDWARE_MEDIA_C2_V1_0_INPUT_SURFACE_H
diff --git a/media/codec2/core/include/media/stagefright/codec2/1.0/InputSurfaceConnection.h b/media/codec2/core/include/media/stagefright/codec2/1.0/InputSurfaceConnection.h
deleted file mode 100644
index 5eae3af4cd..0000000000
--- a/media/codec2/core/include/media/stagefright/codec2/1.0/InputSurfaceConnection.h
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Copyright 2018, The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef ANDROID_HARDWARE_MEDIA_C2_V1_0_INPUT_SURFACE_CONNECTION_H
-#define ANDROID_HARDWARE_MEDIA_C2_V1_0_INPUT_SURFACE_CONNECTION_H
-
-#include <memory>
-
-#include <C2Component.h>
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
-#include <media/stagefright/codec2/1.0/InputSurfaceConnection.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_0 {
-namespace implementation {
-
-// TODO: inherit from IInputSurfaceConnection
-class InputSurfaceConnection : public RefBase {
-public:
-    virtual ~InputSurfaceConnection();
-
-    // From IInputSurfaceConnection
-    void disconnect();
-
-private:
-    friend class InputSurface;
-
-    // For InputSurface
-    InputSurfaceConnection(
-            const sp<GraphicBufferSource> &source, const std::shared_ptr<C2Component> &comp);
-    bool init();
-
-    InputSurfaceConnection() = delete;
-
-    class Impl;
-
-    sp<GraphicBufferSource> mSource;
-    sp<Impl> mImpl;
-
-    DISALLOW_EVIL_CONSTRUCTORS(InputSurfaceConnection);
-};
-
-}  // namespace implementation
-}  // namespace V1_0
-}  // namespace c2
-}  // namespace media
-}  // namespace hardware
-}  // namespace android
-
-#endif  // ANDROID_HARDWARE_MEDIA_C2_V1_0_INPUT_SURFACE_CONNECTION_H
diff --git a/media/codec2/fuzzer/Android.bp b/media/codec2/fuzzer/Android.bp
index 6604315e0f..cdffdd2eae 100644
--- a/media/codec2/fuzzer/Android.bp
+++ b/media/codec2/fuzzer/Android.bp
@@ -27,7 +27,7 @@ package {
 
 cc_defaults {
     name: "C2Fuzzer-defaults",
-
+    team: "trendy_team_media_codec_framework",
     defaults: ["libcodec2-static-defaults"],
 
     srcs: [
@@ -193,7 +193,7 @@ cc_fuzz {
 
 cc_fuzz {
     name: "C2FuzzerAPVDec",
-    defaults: ["C2Fuzzer-defaults"],
+    defaults: ["C2Fuzzer-defaults-shipped"],
 
     cflags: [
         "-DC2COMPONENTNAME=\"c2.android.apv.decoder\"",
@@ -308,6 +308,23 @@ cc_fuzz {
     ],
 }
 
+cc_fuzz {
+    name: "C2FuzzerIamfDec",
+    defaults: ["C2Fuzzer-defaults-shipped"],
+
+    cflags: [
+        "-DC2COMPONENTNAME=\"c2.android.iamf.decoder\"",
+    ],
+
+    static_libs: [
+        "iamf_tools",
+        "libcodec2_soft_iamfdec",
+        "libFLAC",
+        "libFraunhoferAAC",
+        "libopus",
+    ],
+}
+
 cc_fuzz {
     name: "C2FuzzerMp3Dec",
     defaults: ["C2Fuzzer-defaults-shipped"],
diff --git a/media/codec2/hal/aidl/Android.bp b/media/codec2/hal/aidl/Android.bp
index c85df82538..e294a316c8 100644
--- a/media/codec2/hal/aidl/Android.bp
+++ b/media/codec2/hal/aidl/Android.bp
@@ -77,6 +77,7 @@ cc_library {
         "ComponentStore.cpp",
         "Configurable.cpp",
         "InputBufferManager.cpp",
+        "InputSink.cpp",
         "ParamTypes.cpp",
     ],
 
@@ -135,6 +136,10 @@ cc_library {
         "libstagefright_bufferpool@2.0.1",
         "libui",
     ],
+
+    cflags: [
+        "-DNO_C2_INPUT_SURFACE",
+    ],
 }
 
 // DO NOT DEPEND ON THIS DIRECTLY
@@ -160,8 +165,10 @@ cc_library {
         "ComponentStore.cpp",
         "Configurable.cpp",
         "InputBufferManager.cpp",
+        "InputSink.cpp",
         "ParamTypes.cpp",
         "inputsurface/FrameDropper.cpp",
+        "inputsurface/FrameQueueThread.cpp",
         "inputsurface/InputSurface.cpp",
         "inputsurface/InputSurfaceConnection.cpp",
         "inputsurface/InputSurfaceSource.cpp",
@@ -186,6 +193,7 @@ cc_library {
         "liblog",
         "libnativewindow",
         "libmediandk",
+        "libsfplugin_ccodec_utils",
         "libstagefright_aidl_bufferpool2",
         "libstagefright_bufferpool@2.0.1",
         "libstagefright_foundation",
diff --git a/media/codec2/hal/aidl/Component.cpp b/media/codec2/hal/aidl/Component.cpp
index a2c45cbe5a..b25590f682 100644
--- a/media/codec2/hal/aidl/Component.cpp
+++ b/media/codec2/hal/aidl/Component.cpp
@@ -21,6 +21,7 @@
 #include <codec2/aidl/Component.h>
 #include <codec2/aidl/ComponentStore.h>
 #include <codec2/aidl/InputBufferManager.h>
+#include <codec2/aidl/InputSink.h>
 
 #ifndef __ANDROID_APEX__
 #include <FilterWrapper.h>
@@ -202,6 +203,7 @@ Component::Component(
         mListener{listener},
         mStore{store},
         mBufferPoolSender{clientPoolManager},
+        mReleased(false),
         mDeathContext(nullptr) {
     // Retrieve supported parameters from store
     // TODO: We could cache this per component/interface type
@@ -456,6 +458,7 @@ ScopedAStatus Component::reset() {
 }
 
 ScopedAStatus Component::release() {
+    mReleased = true;
     c2_status_t status = mComponent->release();
     {
         std::lock_guard<std::mutex> lock(mBlockPoolsMutex);
@@ -487,7 +490,8 @@ ScopedAStatus Component::configureVideoTunnel(
 ScopedAStatus Component::connectToInputSurface(
         const std::shared_ptr<IInputSurface>& inputSurface,
         std::shared_ptr<IInputSurfaceConnection> *connection) {
-    // TODO
+    // Obsolete.
+    // IInputSurface::connect instead of this interface.
     (void)inputSurface;
     (void)connection;
     return ScopedAStatus::fromServiceSpecificError(Status::OMITTED);
@@ -495,9 +499,8 @@ ScopedAStatus Component::connectToInputSurface(
 
 ScopedAStatus Component::asInputSink(
         std::shared_ptr<IInputSink> *sink) {
-    // TODO
-    (void)sink;
-    return ScopedAStatus::fromServiceSpecificError(Status::OMITTED);
+    *sink = SharedRefBase::make<InputSink>(this->ref<Component>());
+    return ScopedAStatus::ok();
 }
 
 void Component::initListener(const std::shared_ptr<Component>& self) {
@@ -553,6 +556,10 @@ void Component::OnBinderUnlinked(void *cookie) {
 }
 
 Component::~Component() {
+    if (!mReleased) {
+        this->reset();
+        this->release();
+    }
     InputBufferManager::unregisterFrameData(mListener);
     mStore->reportComponentDeath(this);
     if (mDeathRecipient.get()) {
diff --git a/media/codec2/hal/aidl/ComponentStore.cpp b/media/codec2/hal/aidl/ComponentStore.cpp
index de9332b971..4daa6c8d4f 100644
--- a/media/codec2/hal/aidl/ComponentStore.cpp
+++ b/media/codec2/hal/aidl/ComponentStore.cpp
@@ -23,6 +23,9 @@
 #include <codec2/aidl/ComponentInterface.h>
 #include <codec2/aidl/ComponentStore.h>
 #include <codec2/aidl/ParamTypes.h>
+#ifndef NO_C2_INPUT_SURFACE
+#include <codec2/aidl/inputsurface/InputSurface.h>
+#endif
 
 #include <android-base/file.h>
 #include <utils/Errors.h>
@@ -345,9 +348,13 @@ ScopedAStatus ComponentStore::listComponents(
 
 ScopedAStatus ComponentStore::createInputSurface(
         std::shared_ptr<IInputSurface> *inputSurface) {
-    // TODO
+#ifdef NO_C2_INPUT_SURFACE
     (void)inputSurface;
     return ScopedAStatus::fromServiceSpecificError(Status::OMITTED);
+#else
+    *inputSurface = SharedRefBase::make<InputSurface>();
+    return ScopedAStatus::ok();
+#endif
 }
 
 void ComponentStore::onInterfaceLoaded(const std::shared_ptr<C2ComponentInterface> &intf) {
diff --git a/media/codec2/hal/aidl/InputSink.cpp b/media/codec2/hal/aidl/InputSink.cpp
new file mode 100644
index 0000000000..c09bf04131
--- /dev/null
+++ b/media/codec2/hal/aidl/InputSink.cpp
@@ -0,0 +1,45 @@
+/*
+ * Copyright 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Codec2-InputSink"
+#include <android-base/logging.h>
+
+#include <C2.h>
+
+#include <codec2/aidl/Component.h>
+#include <codec2/aidl/InputSink.h>
+
+
+namespace aidl::android::hardware::media::c2::utils {
+
+InputSink::InputSink(const std::shared_ptr<Component>& component)
+    : mComponent(component) {}
+
+InputSink::~InputSink() {
+}
+
+::ndk::ScopedAStatus InputSink::queue(
+        const ::aidl::android::hardware::media::c2::WorkBundle& in_workBundle) {
+    auto comp = mComponent.lock();
+    if (!comp) {
+        ALOGE("Component not alive for queueing works");
+        return ::ndk::ScopedAStatus::fromServiceSpecificError(C2_CORRUPTED);
+    }
+    return comp->queue(in_workBundle);
+}
+
+} // namespace aidl::android::hardware::media::c2::utils
diff --git a/media/codec2/hal/aidl/include/codec2/aidl/Component.h b/media/codec2/hal/aidl/include/codec2/aidl/Component.h
index 712a3e9b2c..0ebfd752f0 100644
--- a/media/codec2/hal/aidl/include/codec2/aidl/Component.h
+++ b/media/codec2/hal/aidl/include/codec2/aidl/Component.h
@@ -100,6 +100,7 @@ protected:
     // destroyBlockPool(), reset() or release(), or by destroying the component.
     std::map<uint64_t, std::shared_ptr<C2BlockPool>> mBlockPools;
     bool mBlockFenceSupport;
+    bool mReleased;
 
     void initListener(const std::shared_ptr<Component>& self);
 
diff --git a/media/codec2/hal/aidl/include/codec2/aidl/InputSink.h b/media/codec2/hal/aidl/include/codec2/aidl/InputSink.h
new file mode 100644
index 0000000000..6a4c299e4a
--- /dev/null
+++ b/media/codec2/hal/aidl/include/codec2/aidl/InputSink.h
@@ -0,0 +1,40 @@
+/*
+ * Copyright 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+#include <aidl/android/hardware/media/c2/BnInputSink.h>
+
+#include <memory>
+
+namespace aidl::android::hardware::media::c2::utils {
+struct Component;
+
+struct InputSink : public BnInputSink {
+    InputSink(const std::shared_ptr<Component>& component);
+
+    // Methods from IInputSink follow.
+    ::ndk::ScopedAStatus queue(
+            const ::aidl::android::hardware::media::c2::WorkBundle& in_workBundle) override;
+
+protected:
+    virtual ~InputSink() override;
+
+private:
+    std::weak_ptr<Component> mComponent;
+};
+
+}  // namespace aidl::android::hardware::media::c2::utils
diff --git a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/FrameQueueThread.h b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/FrameQueueThread.h
new file mode 100644
index 0000000000..d8af97b7b4
--- /dev/null
+++ b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/FrameQueueThread.h
@@ -0,0 +1,86 @@
+/*
+ *
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+#include <condition_variable>
+#include <deque>
+#include <thread>
+
+#include <aidl/android/hardware/media/c2/BnInputSink.h>
+#include <utils/Timers.h>
+
+#include <C2Config.h>
+#include <C2Work.h>
+
+namespace aidl::android::hardware::media::c2::implementation {
+
+/**
+ * This class runs a thread which receives encoder frames and queues them
+ * to an encoder component. Frames queued in a specific short duration can be
+ * batched for queueing to an encoder component.
+ */
+class FrameQueueThread {
+public:
+    FrameQueueThread(const std::shared_ptr<IInputSink> &sink);
+
+    ~FrameQueueThread();
+
+    /**
+     * Queue a frame for an encoder.
+     */
+    void queue(std::unique_ptr<C2Work> &&work, int fenceFd);
+
+    /**
+     * Set/update a dataspace for upcoming frames.
+     */
+    void setDataspace(android_dataspace dataspace);
+
+    /**
+     * Set/update thread priority for the frame queueing thread.
+     */
+    void setPriority(int priority);
+
+private:
+    bool mDone = false;
+    std::thread mThread;
+    std::weak_ptr<IInputSink> mSink;
+
+    std::mutex mLock;
+    std::condition_variable mCv;
+    struct Item {
+        Item(std::unique_ptr<C2Work> &&w, int fd) : work(std::move(w)), fenceFd(fd) {}
+
+        void updateConfig(std::deque<std::unique_ptr<C2Param>> &newConfig) {
+            configUpdate = std::move(newConfig);
+        }
+
+        std::unique_ptr<C2Work> work;
+        int fenceFd;
+        std::deque<std::unique_ptr<C2Param>> configUpdate;
+    };
+    std::deque<Item> mItems;
+    std::deque<std::unique_ptr<C2Param>> mConfigUpdate;
+    nsecs_t mLastQueuedTimestampNs = 0;
+
+private:
+    void run();
+
+    void queueItems(std::deque<Item> &items);
+};
+
+}  // namespace aidl::android::hardware::media::c2::implementation
diff --git a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurface.h b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurface.h
index 8e15778874..2667b99875 100644
--- a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurface.h
+++ b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurface.h
@@ -95,7 +95,7 @@ struct InputSurface : public BnInputSurface {
     //
     // Config for current work status w.r.t input buffers
     struct WorkStatusConfig {
-        int32_t mLastDoneIndex = -1;      // Last work done input buffer index
+        uint64_t mLastDoneIndex = UINT64_MAX;      // Last work done buffer frame index
         uint32_t mLastDoneCount = 0;      // # of work done count
         uint64_t mEmptyCount = 0;         // # of input buffers being emptied
     };
@@ -105,7 +105,7 @@ protected:
     class Interface;
     class ConfigurableIntf;
 
-    c2_status_t mInit;
+    std::once_flag mInit;
     std::shared_ptr<Interface> mIntf;
     std::shared_ptr<CachedConfigurable> mConfigurable;
 
@@ -121,6 +121,9 @@ private:
 
     std::mutex mLock;
 
+    struct SourceEventCallback;
+    std::shared_ptr<SourceEventCallback> mSourceEventCallback;
+
     friend class ConfigurableIntf;
 
     bool updateConfig(
@@ -133,6 +136,7 @@ private:
     bool updateStreamConfig(StreamConfig &config, int64_t *inputDelayUs);
     void updateWorkStatusConfig(WorkStatusConfig &config);
 
+    void init();
     void release();
 };
 
diff --git a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceConnection.h b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceConnection.h
index 7a57f1898f..fc40d93a45 100644
--- a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceConnection.h
+++ b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceConnection.h
@@ -23,12 +23,17 @@
 
 #include <C2.h>
 
+#include <list>
+#include <map>
 #include <memory>
 
 namespace aidl::android::hardware::media::c2::implementation {
 class InputSurfaceSource;
+class FrameQueueThread;
 }
 
+class C2Allocator;
+
 namespace aidl::android::hardware::media::c2::utils {
 
 struct InputSurfaceConnection : public BnInputSurfaceConnection {
@@ -57,12 +62,55 @@ struct InputSurfaceConnection : public BnInputSurfaceConnection {
     void dispatchDataSpaceChanged(
             int32_t dataSpace, int32_t aspects, int32_t pixelFormat);
 
+    void release();
+
+    // InputSurface config
+    void setAdjustTimestampGapUs(int32_t gapUs);
+
+    void onInputBufferDone(c2_cntr64_t index);
+
+    void onInputBufferEmptied();
+
 protected:
     virtual ~InputSurfaceConnection() override;
 
 private:
-    std::weak_ptr<IInputSink> mSink;
-    ::android::sp<c2::implementation::InputSurfaceSource> mSource;
+    c2_status_t mInit;
+    std::atomic<bool> mReleased;
+
+    std::shared_ptr<IInputSink> mSink;
+    ::android::wp<c2::implementation::InputSurfaceSource> mSource;
+    std::shared_ptr<c2::implementation::FrameQueueThread> mQueueThread;
+
+    std::atomic_uint64_t mFrameIndex;
+
+    // WORKAROUND: timestamp adjustment
+
+    // if >0: this is the max timestamp gap, if <0: this is -1 times the fixed timestamp gap
+    // if 0: no timestamp adjustment is made
+    // note that C2OMXNode can be recycled between encoding sessions.
+    int32_t mAdjustTimestampGapUs;
+    bool mFirstInputFrame; // true for first input
+    c2_cntr64_t mPrevInputTimestamp; // input timestamp for previous frame
+    c2_cntr64_t mPrevCodecTimestamp; // adjusted (codec) timestamp for previous frame
+
+    // Tracks the status of buffers
+    struct BuffersTracker {
+        BuffersTracker() = default;
+
+        // For synchronization of data accesses and/or modifications.
+        std::mutex mMutex;
+        // Keeps track of buffers that are used by the component. Maps timestamp -> ID
+        std::map<uint64_t, uint32_t> mIdsInUse;
+        // Keeps track of the buffer IDs that are available after being released from the component.
+        std::list<uint32_t> mAvailableIds;
+    };
+    BuffersTracker mBuffersTracker;
+
+    c2_status_t submitBufferInternal(
+            int32_t bufferId, const AImage *buffer, int64_t timestamp, int fenceFd, bool eos);
+
+    void notifyInputBufferEmptied(int32_t bufferId);
 };
 
 }  // namespace aidl::android::hardware::media::c2::utils
diff --git a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceSource.h b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceSource.h
index 25a55e7d00..a145c61d97 100644
--- a/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceSource.h
+++ b/media/codec2/hal/aidl/include/codec2/aidl/inputsurface/InputSurfaceSource.h
@@ -68,6 +68,13 @@ struct FrameDropper;
  */
 class InputSurfaceSource : public ::android::RefBase {
 // TODO: remove RefBase dependency and AHanderReflector.
+
+private:
+    void initLocked();
+
+    void initWithParams(int32_t width, int32_t height, int32_t format,
+                       int32_t maxImages, uint64_t usage);
+
 public:
     // creates an InputSurfaceSource.
     // init() have to be called prior to use the class.
@@ -75,20 +82,26 @@ public:
 
     virtual ~InputSurfaceSource();
 
-    // Initialize with the default parameter. (persistent surface or init params
-    // are not decided yet.)
-    void init();
-
-    // Initialize with the specified parameters. (non-persistent surface)
-    void initWithParams(int32_t width, int32_t height, int32_t format,
-                       int32_t maxImages, uint64_t usage);
-
     // We can't throw an exception if the constructor fails, so we just set
     // this and require that the caller test the value.
     c2_status_t initCheck() const {
         return mInitCheck;
     }
 
+    class EventCallback {
+    public:
+        EventCallback() = default;
+
+        virtual ~EventCallback() = default;
+
+        virtual void onDataspaceChanged(int32_t dataspace, int32_t pixelFormat) = 0;
+
+        virtual void onComponentReleased() = 0;
+    };
+
+    // Sets callback for the specified events.
+    void setEventCallback(std::shared_ptr<EventCallback> callback);
+
     /**
      * Returns the handle of ANativeWindow of the AImageReader.
      */
@@ -215,6 +228,9 @@ private:
     AImageReader_ImageListener mImageListener;
     AImageReader_BufferRemovedListener mBufferRemovedListener;
 
+    // EventCallback
+    std::shared_ptr<EventCallback> mEventCallback;
+
     // Lock, covers all member variables.
     mutable std::mutex mMutex;
 
@@ -367,6 +383,7 @@ private:
     // buffers queued by the producer.
     AImageReader *mImageReader;
     ANativeWindow *mImageWindow;
+    uint64_t mCurrentUsage;
 
     // AImageReader creation parameters
     // maxImages cannot be changed after AImageReader is created.
diff --git a/media/codec2/hal/aidl/inputsurface/FrameQueueThread.cpp b/media/codec2/hal/aidl/inputsurface/FrameQueueThread.cpp
new file mode 100644
index 0000000000..05a62070bd
--- /dev/null
+++ b/media/codec2/hal/aidl/inputsurface/FrameQueueThread.cpp
@@ -0,0 +1,141 @@
+/*
+ *
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Codec2-InputSurfaceQueue"
+
+#include <sys/types.h>
+
+#include <chrono>
+
+#include <android-base/logging.h>
+#include <codec2/aidl/BufferTypes.h>
+#include <codec2/aidl/inputsurface/FrameQueueThread.h>
+#include <media/stagefright/foundation/ColorUtils.h>
+#include <ui/Fence.h>
+#include <utils/AndroidThreads.h>
+
+#include <Codec2Mapper.h>
+
+namespace aidl::android::hardware::media::c2::implementation {
+
+FrameQueueThread::FrameQueueThread(const std::shared_ptr<IInputSink> &sink)
+        : mSink{sink} {
+    mThread = std::thread(&FrameQueueThread::run, this);
+}
+
+FrameQueueThread::~FrameQueueThread() {
+    {
+        std::unique_lock<std::mutex> l(mLock);
+        mDone = true;
+        mCv.notify_all();
+    }
+    if (mThread.joinable()) {
+        mThread.join();
+    }
+}
+
+void FrameQueueThread::queue(std::unique_ptr<C2Work> &&work, int fenceFd) {
+    {
+        std::unique_lock<std::mutex> l(mLock);
+        mItems.emplace_back(std::move(work), fenceFd);
+        if (!mConfigUpdate.empty()) {
+            mItems.back().updateConfig(mConfigUpdate);
+        }
+    }
+    mCv.notify_all();
+}
+
+void FrameQueueThread::setDataspace(android_dataspace dataspace) {
+    std::unique_lock<std::mutex> l(mLock);
+    ::android::ColorUtils::convertDataSpaceToV0(dataspace);
+    mConfigUpdate.emplace_back(new C2StreamDataSpaceInfo::input(0u, dataspace));
+    int32_t standard;
+    int32_t transfer;
+    int32_t range;
+    ::android::ColorUtils::getColorConfigFromDataSpace(dataspace, &range, &standard, &transfer);
+    std::unique_ptr<C2StreamColorAspectsInfo::input> colorAspects =
+        std::make_unique<C2StreamColorAspectsInfo::input>(0u);
+    if (::android::C2Mapper::map(standard, &colorAspects->primaries, &colorAspects->matrix)
+            && ::android::C2Mapper::map(transfer, &colorAspects->transfer)
+            && ::android::C2Mapper::map(range, &colorAspects->range)) {
+        mConfigUpdate.push_back(std::move(colorAspects));
+    }
+}
+
+void FrameQueueThread::setPriority(int priority) {
+    androidSetThreadPriority(gettid(), priority);
+}
+
+void FrameQueueThread::run() {
+    constexpr nsecs_t kIntervalNs = nsecs_t(10) * 1000 * 1000;  // 10ms
+    constexpr nsecs_t kWaitNs = kIntervalNs * 2;
+
+    std::unique_lock<std::mutex> lock(mLock);
+    while (!mDone) {
+        nsecs_t nowNs = systemTime();
+        nsecs_t diffNs = nowNs - mLastQueuedTimestampNs;
+        if (mItems.empty() || (mLastQueuedTimestampNs != 0 && diffNs < kIntervalNs)) {
+            nsecs_t waitNs = kIntervalNs;
+            if (mLastQueuedTimestampNs != 0) {
+                waitNs = diffNs < kIntervalNs ? kIntervalNs - diffNs : 1;
+            }
+            mCv.wait_for(lock, std::chrono::nanoseconds(waitNs));
+            continue;
+        }
+        std::deque<Item> items = std::move(mItems);
+        lock.unlock();
+        queueItems(items);
+        lock.lock();
+        mLastQueuedTimestampNs = nowNs;
+        mCv.wait_for(lock, std::chrono::nanoseconds(kWaitNs));
+    }
+}
+
+void FrameQueueThread::queueItems(std::deque<Item> &items) {
+    std::shared_ptr<IInputSink> sink = mSink.lock();
+    if (!sink) {
+        ALOGE("queueItems: sink is not valid");
+        return;
+    }
+
+    std::list<std::unique_ptr<C2Work>> c2Items;
+    std::vector<int> fenceFds;
+    while (!items.empty()) {
+        c2Items.push_back(std::move(items.front().work));
+        fenceFds.push_back(items.front().fenceFd);
+        for (const std::unique_ptr<C2Param> &param: items.front().configUpdate) {
+            c2Items.back()->input.configUpdate.emplace_back(C2Param::Copy(*param));
+        }
+        items.pop_front();
+    }
+    // TODO: Pass fence if an encoder supports receiving fences
+    // along with a block.
+    for (int fenceFd : fenceFds) {
+        ::android::sp<::android::Fence> fence(new ::android::Fence(fenceFd));
+        fence->waitForever(LOG_TAG);
+    }
+
+    WorkBundle workBundle;
+    if (!utils::ToAidl(&workBundle, c2Items, nullptr)) {
+        ALOGE("queueItems: conversion from C2Work to workBundle failed");
+        return;
+    }
+    sink->queue(workBundle);
+}
+
+}  // namespace aidl::android::hardware::media::c2::implementation
diff --git a/media/codec2/hal/aidl/inputsurface/InputSurface.cpp b/media/codec2/hal/aidl/inputsurface/InputSurface.cpp
index ce694ee913..d2011f4e42 100644
--- a/media/codec2/hal/aidl/inputsurface/InputSurface.cpp
+++ b/media/codec2/hal/aidl/inputsurface/InputSurface.cpp
@@ -31,6 +31,8 @@
 
 namespace aidl::android::hardware::media::c2::utils {
 
+using implementation::InputSurfaceSource;
+
 using ImageConfig = InputSurface::ImageConfig;
 using StreamConfig = InputSurface::StreamConfig;
 using WorkStatusConfig = InputSurface::WorkStatusConfig;
@@ -169,8 +171,8 @@ public:
                 .build());
 
         addParameter(
-                DefineParam(mInputDone, C2_PARAMKEY_LAYER_INDEX)
-                .withDefault(new C2StreamLayerIndexInfo::output(0u, UINT32_MAX))
+                DefineParam(mInputDone, C2_PARAMKEY_OUTPUT_COUNTER)
+                .withDefault(new C2PortConfigCounterTuning::output(UINT64_MAX))
                 .withFields({C2F(mInputDone, value).any()})
                 .withSetter(BasicSetter<decltype(mInputDone)::element_type>)
                 .build());
@@ -178,13 +180,13 @@ public:
                 DefineParam(mInputDoneCount, C2_PARAMKEY_LAYER_INDEX)
                 .withDefault(new C2StreamLayerCountInfo::input(0u, 0))
                 .withFields({C2F(mInputDoneCount, value).any()})
-                .withSetter(InputDoneCountSetter)
+                .withSetter(BasicSetter<decltype(mInputDoneCount)::element_type>)
                 .build());
         addParameter(
                 DefineParam(mEmptyCount, C2_PARAMKEY_LAYER_COUNT)
                 .withDefault(new C2StreamLayerCountInfo::output(0u, 0))
                 .withFields({C2F(mEmptyCount, value).any()})
-                .withSetter(EmptyCountSetter)
+                .withSetter(BasicSetter<decltype(mEmptyCount)::element_type>)
                 .build());
     }
 
@@ -222,11 +224,7 @@ public:
     }
 
     void getWorkStatusConfig(WorkStatusConfig* _Nonnull config) {
-        if (mInputDone->value == UINT32_MAX) {
-            config->mLastDoneIndex = -1;
-        } else {
-            config->mLastDoneIndex = mInputDone->value;
-        }
+        config->mLastDoneIndex = mInputDone->value;
         config->mLastDoneCount = mInputDoneCount->value;
         config->mEmptyCount = mEmptyCount->value;
     }
@@ -251,20 +249,6 @@ private:
         return C2R::Ok();
     }
 
-    static C2R InputDoneCountSetter(bool mayBlock,
-            C2InterfaceHelper::C2P<C2StreamLayerCountInfo::input> &me) {
-        (void)mayBlock;
-        me.set().value = me.v.value + 1;
-        return C2R::Ok();
-    }
-
-    static C2R EmptyCountSetter(bool mayBlock,
-            C2InterfaceHelper::C2P<C2StreamLayerCountInfo::output> &me) {
-        (void)mayBlock;
-        me.set().value = me.v.value + 1;
-        return C2R::Ok();
-    }
-
 private:
     // buffer configuraration
     std::shared_ptr<C2StreamBlockSizeInfo::output> mBlockSize;
@@ -289,7 +273,7 @@ private:
 
     // current work status configuration
     // TODO: remove this and move this to onWorkDone()
-    std::shared_ptr<C2StreamLayerIndexInfo::output> mInputDone;
+    std::shared_ptr<C2PortConfigCounterTuning::output> mInputDone;
     std::shared_ptr<C2StreamLayerCountInfo::input> mInputDoneCount;
     std::shared_ptr<C2StreamLayerCountInfo::output> mEmptyCount;
 };
@@ -369,20 +353,46 @@ private:
     mutable std::mutex mConfigLock;
 };
 
+struct InputSurface::SourceEventCallback : public InputSurfaceSource::EventCallback {
+    explicit SourceEventCallback(std::shared_ptr<InputSurface> surface) : mSurface{surface} {}
+
+    virtual ~SourceEventCallback() override {}
+
+    void onDataspaceChanged(int32_t dataspace, int32_t pixelFormat) override {
+        // TODO, tricky since this might be called with a lock being held.
+        (void) dataspace;
+        (void) pixelFormat;
+    }
+
+    void onComponentReleased() override {
+        // TODO
+    }
+
+    std::weak_ptr<InputSurface> mSurface;
+};
+
 InputSurface::InputSurface() {
     mIntf = std::make_shared<Interface>(
             std::make_shared<C2ReflectorHelper>());
-
-    // mConfigurable is initialized lazily.
-    // mInit indicates the initialization status of mConfigurable.
-    mInit = C2_NO_INIT;
+    mSource = new InputSurfaceSource();
+    // mConfigurable, mSourceEventcallback are initialized lazily.
 }
 
 InputSurface::~InputSurface() {
     release();
 }
 
+void InputSurface::init() {
+    std::call_once(mInit, [this]() {
+        mConfigurable = SharedRefBase::make<CachedConfigurable>(
+                std::make_unique<ConfigurableIntf>(mIntf, this->ref<InputSurface>()));
+        mSourceEventCallback = std::make_shared<SourceEventCallback>(this->ref<InputSurface>());
+        mSource->setEventCallback(mSourceEventCallback);
+    });
+}
+
 ::ndk::ScopedAStatus InputSurface::getSurface(::aidl::android::view::Surface* surface) {
+    init();
     std::lock_guard<std::mutex> l(mLock);
     ANativeWindow *window = mSource->getNativeWindow();
     if (window) {
@@ -394,11 +404,7 @@ InputSurface::~InputSurface() {
 
 ::ndk::ScopedAStatus InputSurface::getConfigurable(
         std::shared_ptr<IConfigurable>* configurable) {
-    if (mInit == C2_NO_INIT) {
-        mConfigurable = SharedRefBase::make<CachedConfigurable>(
-                std::make_unique<ConfigurableIntf>(mIntf, this->ref<InputSurface>()));
-        mInit = C2_OK;
-    }
+    init();
     if (mConfigurable) {
         *configurable = mConfigurable;
         return ::ndk::ScopedAStatus::ok();
@@ -409,8 +415,29 @@ InputSurface::~InputSurface() {
 ::ndk::ScopedAStatus InputSurface::connect(
         const std::shared_ptr<IInputSink>& sink,
         std::shared_ptr<IInputSurfaceConnection>* connection) {
+    std::unique_lock<std::mutex> l(mLock);
     mConnection = SharedRefBase::make<InputSurfaceConnection>(sink, mSource);
     *connection = mConnection;
+    c2_status_t c2Res = mSource->configure(
+            mConnection,
+            mImageConfig.mDataspace,
+            mImageConfig.mNumBuffers,
+            mImageConfig.mWidth,
+            mImageConfig.mHeight,
+            mImageConfig.mUsage);
+    if (c2Res != C2_OK) {
+        ALOGE("InputSurface connect: configuring source failed(%d)", c2Res);
+        return ::ndk::ScopedAStatus::fromServiceSpecificError(c2Res);
+    }
+    int numSlots = mImageConfig.mNumBuffers;
+    for (size_t i = 0; i < numSlots; ++i) {
+        mSource->onInputBufferAdded(i);
+    }
+    c2Res = mSource->start();
+    if (c2Res != C2_OK) {
+        ALOGE("InputSurface connect: starting source failed(%d)", c2Res);
+        return ::ndk::ScopedAStatus::fromServiceSpecificError(c2Res);
+    }
     return ::ndk::ScopedAStatus::ok();
 }
 
@@ -459,12 +486,12 @@ bool InputSurface::updateStreamConfig(
     if (config.mAdjustedFpsMode != C2TimestampGapAdjustmentStruct::NONE && (
             config.mAdjustedFpsMode != mStreamConfig.mAdjustedFpsMode ||
             config.mAdjustedGapUs != mStreamConfig.mAdjustedGapUs)) {
-        // TODO: configure GapUs to connection
-        // The original codes do not update config, figure out why.
         mStreamConfig.mAdjustedFpsMode = config.mAdjustedFpsMode;
         mStreamConfig.mAdjustedGapUs = config.mAdjustedGapUs;
         fixedModeUpdate = (config.mAdjustedFpsMode == C2TimestampGapAdjustmentStruct::FIXED_GAP);
-        // TODO: update Gap to Connection.
+        if (mConnection) {
+            mConnection->setAdjustTimestampGapUs(mStreamConfig.mAdjustedGapUs);
+        }
     }
     // TRICKY: we do not unset max fps to 0 unless using fixed fps
     if ((config.mMaxFps > 0 || (fixedModeUpdate && config.mMaxFps == -1))
@@ -542,7 +569,7 @@ bool InputSurface::updateStreamConfig(
         mStreamConfig.mStopped = config.mStopped;
     }
     if (status.str().empty()) {
-        ALOGD("StreamConfig not changed");
+        ALOGV("StreamConfig not changed");
     } else {
         ALOGD("StreamConfig%s", status.str().c_str());
     }
@@ -550,8 +577,22 @@ bool InputSurface::updateStreamConfig(
 }
 
 void InputSurface::updateWorkStatusConfig(WorkStatusConfig &config) {
-    (void)config;
-    // TODO
+    std::unique_lock<std::mutex> l(mLock);
+    if (!mConnection) {
+        ALOGE("work status is updated though there is no connection.");
+        return;
+    }
+    if (mWorkStatusConfig.mLastDoneIndex != config.mLastDoneIndex) {
+        mWorkStatusConfig.mLastDoneIndex = config.mLastDoneIndex;
+        mConnection->onInputBufferDone(mWorkStatusConfig.mLastDoneIndex);
+    }
+    if (mWorkStatusConfig.mLastDoneCount != config.mLastDoneCount) {
+        mWorkStatusConfig.mLastDoneCount = config.mLastDoneCount;
+    }
+    if (mWorkStatusConfig.mEmptyCount != config.mEmptyCount) {
+        mWorkStatusConfig.mEmptyCount = config.mEmptyCount;
+        mConnection->onInputBufferEmptied();
+    }
 }
 
 bool InputSurface::updateConfig(
diff --git a/media/codec2/hal/aidl/inputsurface/InputSurfaceConnection.cpp b/media/codec2/hal/aidl/inputsurface/InputSurfaceConnection.cpp
index 6a95472ebe..b9cae6ceda 100644
--- a/media/codec2/hal/aidl/inputsurface/InputSurfaceConnection.cpp
+++ b/media/codec2/hal/aidl/inputsurface/InputSurfaceConnection.cpp
@@ -15,55 +15,236 @@
  */
 
 //#define LOG_NDEBUG 0
-#define LOG_TAG "Codec2-InputSurface"
+#define LOG_TAG "Codec2-InputSurfaceConnection"
+
+#include <android_media_codec.h>
 #include <android-base/logging.h>
+#include <android-base/unique_fd.h>
 
+#include <codec2/aidl/inputsurface/FrameQueueThread.h>
 #include <codec2/aidl/inputsurface/InputSurfaceConnection.h>
 #include <codec2/aidl/inputsurface/InputSurfaceSource.h>
 
+#include <C2AllocatorGralloc.h>
+#include <C2BlockInternal.h>
+
 namespace aidl::android::hardware::media::c2::utils {
 
 InputSurfaceConnection::InputSurfaceConnection(
         const std::shared_ptr<IInputSink>& sink,
         ::android::sp<c2::implementation::InputSurfaceSource> const &source)
-        : mSink{sink}, mSource{source} {
+    : mSink{sink}, mSource{source},
+      mQueueThread{std::make_shared<implementation::FrameQueueThread>(sink)}, mFrameIndex(0),
+      mAdjustTimestampGapUs(0), mFirstInputFrame(true) {
+    if (!mSink) {
+        mInit = C2_NO_INIT;
+        return;
+    }
+    mInit = C2_OK;
 }
 
 InputSurfaceConnection::~InputSurfaceConnection() {
 }
 
 c2_status_t InputSurfaceConnection::status() const {
-    // TODO;
-    return C2_OK;
+    return mInit;
 }
 
 ::ndk::ScopedAStatus InputSurfaceConnection::disconnect() {
+    auto source = mSource.promote();
+    if (!source) {
+        return ::ndk::ScopedAStatus::fromServiceSpecificError(C2_CORRUPTED);
+    }
+    (void)source->stop();
+    (void)source->release();
+
     return ::ndk::ScopedAStatus::ok();
 }
 
 ::ndk::ScopedAStatus InputSurfaceConnection::signalEndOfStream() {
+    auto source = mSource.promote();
+    if (!source) {
+        return ::ndk::ScopedAStatus::fromServiceSpecificError(C2_CORRUPTED);
+    }
+
+    c2_status_t status = source->signalEndOfInputStream();
+    if (status != C2_OK) {
+        return ::ndk::ScopedAStatus::fromServiceSpecificError(status);
+    }
     return ::ndk::ScopedAStatus::ok();
 }
 
 c2_status_t InputSurfaceConnection::submitBuffer(
         int32_t bufferId, const AImage *buffer, int64_t timestamp, int fenceFd) {
-    (void)bufferId;
-    (void)buffer;
-    (void)timestamp;
-    (void)fenceFd;
-    return C2_OK;
+    return submitBufferInternal(bufferId, buffer, timestamp, fenceFd, false);
 }
 
 c2_status_t InputSurfaceConnection::submitEos(int32_t bufferId) {
-    (void)bufferId;
-    return C2_OK;
+    return submitBufferInternal(bufferId, nullptr, 0, -1, true);
 }
 
 void InputSurfaceConnection::dispatchDataSpaceChanged(
             int32_t dataSpace, int32_t aspects, int32_t pixelFormat) {
-    (void)dataSpace;
     (void)aspects;
     (void)pixelFormat;
+    android_dataspace d = (android_dataspace)dataSpace;
+    mQueueThread->setDataspace(d);
+}
+
+void InputSurfaceConnection::setAdjustTimestampGapUs(int32_t gapUs) {
+    mAdjustTimestampGapUs = gapUs;
+}
+
+
+void InputSurfaceConnection::onInputBufferDone(c2_cntr64_t index) {
+    if (::android::media::codec::provider_->input_surface_throttle()) {
+        std::unique_lock<std::mutex> l(mBuffersTracker.mMutex);
+        auto it = mBuffersTracker.mIdsInUse.find(index.peeku());
+        if (it == mBuffersTracker.mIdsInUse.end()) {
+            ALOGV("Untracked input index %llu (maybe already removed)", index.peekull());
+            return;
+        }
+        int32_t bufferId = it->second;
+        (void)mBuffersTracker.mIdsInUse.erase(it);
+        mBuffersTracker.mAvailableIds.push_back(bufferId);
+    } else {
+        {
+            auto source = mSource.promote();
+            if (!source) {
+                return;
+            }
+        }
+        int32_t bufferId = 0;
+        {
+            std::unique_lock<std::mutex> l(mBuffersTracker.mMutex);
+            auto it = mBuffersTracker.mIdsInUse.find(index.peeku());
+            if (it == mBuffersTracker.mIdsInUse.end()) {
+                ALOGV("Untracked input index %llu (maybe already removed)", index.peekull());
+                return;
+            }
+            bufferId = it->second;
+            (void)mBuffersTracker.mIdsInUse.erase(it);
+        }
+        notifyInputBufferEmptied(bufferId);
+    }
+}
+
+void InputSurfaceConnection::onInputBufferEmptied() {
+    if (!::android::media::codec::provider_->input_surface_throttle()) {
+        ALOGE("onInputBufferEmptied should not be called "
+              "when input_surface_throttle is false");
+        return;
+    }
+    {
+        auto source = mSource.promote();
+        if (!source) {
+            return;
+        }
+    }
+    int32_t bufferId = 0;
+    {
+        std::unique_lock<std::mutex> l(mBuffersTracker.mMutex);
+        if (mBuffersTracker.mAvailableIds.empty()) {
+            ALOGV("The codec is ready to take more input buffers "
+                    "but no input buffers are ready yet.");
+            return;
+        }
+        bufferId = mBuffersTracker.mAvailableIds.front();
+        mBuffersTracker.mAvailableIds.pop_front();
+    }
+    notifyInputBufferEmptied(bufferId);
+}
+
+c2_status_t InputSurfaceConnection::submitBufferInternal(
+        int32_t bufferId, const AImage *buffer, int64_t timestamp, int fenceFd, bool eos) {
+    // close fenceFd on returning an error.
+    ::android::base::unique_fd ufd(fenceFd);
+    std::shared_ptr<IInputSink> sink = mSink;
+    if (!sink) {
+        ALOGE("inputsurface does not have valid sink");
+        return C2_BAD_STATE;
+    }
+
+    uint32_t c2Flags = (eos == true) ? C2FrameData::FLAG_END_OF_STREAM : 0;
+    AHardwareBuffer *hwBuffer = nullptr;
+
+    if (buffer) {
+        if (AImage_getHardwareBuffer(buffer, &hwBuffer) != AMEDIA_OK) {
+            ALOGE("cannot get AHardwareBuffer form AImage");
+            return C2_CORRUPTED;
+        }
+    } else if (!eos) {
+        ALOGE("buffer should be submitted, but was nullptr");
+        return C2_BAD_VALUE;
+    }
+
+    std::shared_ptr<C2GraphicBlock> block;
+    if (hwBuffer) {
+        block = _C2BlockFactory::CreateGraphicBlock(hwBuffer);
+    }
+
+    std::unique_ptr<C2Work> work(new C2Work);
+    work->input.flags = (C2FrameData::flags_t)c2Flags;
+    work->input.ordinal.timestamp = timestamp;
+    {
+        work->input.ordinal.customOrdinal = timestamp; // save input timestamp
+        if (mFirstInputFrame) {
+            // grab timestamps on first frame
+            mPrevInputTimestamp = timestamp;
+            mPrevCodecTimestamp = timestamp;
+            mFirstInputFrame = false;
+        } else if (mAdjustTimestampGapUs > 0) {
+            work->input.ordinal.timestamp =
+                mPrevCodecTimestamp
+                        + c2_min((timestamp - mPrevInputTimestamp).peek(), mAdjustTimestampGapUs);
+        } else if (mAdjustTimestampGapUs < 0) {
+            work->input.ordinal.timestamp = mPrevCodecTimestamp - mAdjustTimestampGapUs;
+        }
+        mPrevInputTimestamp = work->input.ordinal.customOrdinal;
+        mPrevCodecTimestamp = work->input.ordinal.timestamp;
+        ALOGV("adjusting %lld to %lld (gap=%lld)",
+              work->input.ordinal.customOrdinal.peekll(),
+              work->input.ordinal.timestamp.peekll(),
+              (long long)mAdjustTimestampGapUs);
+    }
+
+    work->input.ordinal.frameIndex = mFrameIndex++;
+    work->input.buffers.clear();
+    if (block) {
+        std::shared_ptr<C2Buffer> c2Buffer(
+                C2Buffer::CreateGraphicBuffer(block->share(
+                        C2Rect(block->width(), block->height()), ::C2Fence())));
+        work->input.buffers.push_back(c2Buffer);
+        std::shared_ptr<C2StreamHdrStaticInfo::input> staticInfo;
+        std::shared_ptr<C2StreamHdrDynamicMetadataInfo::input> dynamicInfo;
+        ::android::GetHdrMetadataFromGralloc4Handle(
+                block->handle(),
+                &staticInfo,
+                &dynamicInfo);
+        if (staticInfo && *staticInfo) {
+            c2Buffer->setInfo(staticInfo);
+        }
+        if (dynamicInfo && *dynamicInfo) {
+            c2Buffer->setInfo(dynamicInfo);
+        }
+    }
+    work->worklets.clear();
+    work->worklets.emplace_back(new C2Worklet);
+    {
+        std::unique_lock<std::mutex> l(mBuffersTracker.mMutex);
+        mBuffersTracker.mIdsInUse.emplace(work->input.ordinal.frameIndex.peeku(), bufferId);
+    }
+    mQueueThread->queue(std::move(work), ufd.release());
+
+    return C2_OK;
+}
+
+void InputSurfaceConnection::notifyInputBufferEmptied(int32_t bufferId) {
+    auto source = mSource.promote();
+    if (!source) {
+        return;
+    }
+    source->onInputBufferEmptied(bufferId, -1);
 }
 
 }  // namespace aidl::android::hardware::media::c2::utils
diff --git a/media/codec2/hal/aidl/inputsurface/InputSurfaceSource.cpp b/media/codec2/hal/aidl/inputsurface/InputSurfaceSource.cpp
index 953790ecf8..549aba5785 100644
--- a/media/codec2/hal/aidl/inputsurface/InputSurfaceSource.cpp
+++ b/media/codec2/hal/aidl/inputsurface/InputSurfaceSource.cpp
@@ -374,6 +374,7 @@ InputSurfaceSource::InputSurfaceSource() :
     mLastFrameTimestampUs(-1),
     mImageReader(nullptr),
     mImageWindow(nullptr),
+    mCurrentUsage(0ULL),
     mStopTimeUs(-1),
     mLastActionTimeUs(-1LL),
     mSkipFramesBeforeNs(-1LL),
@@ -406,15 +407,16 @@ InputSurfaceSource::InputSurfaceSource() :
 void InputSurfaceSource::initWithParams(
         int32_t width, int32_t height, int32_t format,
         int32_t maxImages, uint64_t usage) {
+    std::lock_guard<std::mutex> autoLock(mMutex);
     mImageReaderConfig.width = width;
     mImageReaderConfig.height = height;
     mImageReaderConfig.format = format;
     mImageReaderConfig.maxImages = maxImages;
     mImageReaderConfig.usage = (AHARDWAREBUFFER_USAGE_VIDEO_ENCODE | usage);
-    init();
+    initLocked();
 }
 
-void InputSurfaceSource::init() {
+void InputSurfaceSource::initLocked() {
     if (mInitCheck != C2_NO_INIT) {
         return;
     }
@@ -422,8 +424,8 @@ void InputSurfaceSource::init() {
             mImageReaderConfig.width,
             mImageReaderConfig.height,
             mImageReaderConfig.format,
-            mImageReaderConfig.maxImages,
-            mImageReaderConfig.usage, &mImageReader);
+            mImageReaderConfig.usage,
+            mImageReaderConfig.maxImages, &mImageReader);
     if (err != AMEDIA_OK) {
         if (err == AMEDIA_ERROR_INVALID_PARAMETER) {
             mInitCheck = C2_BAD_VALUE;
@@ -433,6 +435,7 @@ void InputSurfaceSource::init() {
         ALOGE("Error constructing AImageReader: %d", err);
         return;
     }
+    mCurrentUsage = mImageReaderConfig.usage;
     createImageListeners();
     (void)AImageReader_setImageListener(mImageReader, &mImageListener);
     (void)AImageReader_setBufferRemovedListener(mImageReader, &mBufferRemovedListener);
@@ -445,6 +448,10 @@ void InputSurfaceSource::init() {
     }
 }
 
+void InputSurfaceSource::setEventCallback(std::shared_ptr<EventCallback> callback) {
+    mEventCallback = callback;
+}
+
 InputSurfaceSource::~InputSurfaceSource() {
     ALOGV("~InputSurfaceSource");
     {
@@ -486,6 +493,8 @@ void InputSurfaceSource::createImageListeners() {
 }
 
 ANativeWindow *InputSurfaceSource::getNativeWindow() {
+    std::lock_guard<std::mutex> autoLock(mMutex);
+    initLocked();
     return mImageWindow;
 }
 
@@ -582,6 +591,9 @@ c2_status_t InputSurfaceSource::release(){
     if (looper != NULL) {
         looper->stop();
     }
+    if (mEventCallback) {
+        mEventCallback->onComponentReleased();
+    }
     return C2_OK;
 }
 
@@ -676,6 +688,10 @@ void InputSurfaceSource::onDataspaceChanged_l(
     if (ColorUtils::convertDataSpaceToV0(dataspace)) {
         mComponent->dispatchDataSpaceChanged(
                 mLastDataspace, mDefaultColorAspectsPacked, pixelFormat);
+        if (mEventCallback) {
+            // This will allow the client to query the changed dataspace.
+            mEventCallback->onDataspaceChanged(dataspace, pixelFormat);
+        }
     }
 }
 
@@ -1250,6 +1266,8 @@ c2_status_t InputSurfaceSource::configure(
         uint32_t frameWidth,
         uint32_t frameHeight,
         uint64_t consumerUsage) {
+    initWithParams(frameWidth, frameHeight,
+            HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, bufferCount, consumerUsage);
     if (mInitCheck != C2_OK) {
         ALOGE("configure() was called without initialization");
         return C2_CORRUPTED;
@@ -1277,7 +1295,7 @@ c2_status_t InputSurfaceSource::configure(
         }
 
         consumerUsage |= AHARDWAREBUFFER_USAGE_VIDEO_ENCODE;
-        if (consumerUsage != mImageReaderConfig.usage) {
+        if (consumerUsage != mCurrentUsage) {
             if (__builtin_available(android 36, *)) {
                 media_status_t err = AImageReader_setUsage(mImageReader, consumerUsage);
                 if (err != AMEDIA_OK) {
@@ -1287,8 +1305,9 @@ c2_status_t InputSurfaceSource::configure(
                     return C2_BAD_VALUE;
                 }
             }
-            mImageReaderConfig.usage = consumerUsage;
+            mCurrentUsage = consumerUsage;
         }
+        mImageReaderConfig.usage = consumerUsage;
 
         // Set impl. defined format as default. Depending on the usage flags
         // the device-specific implementation will derive the exact format.
diff --git a/media/codec2/hal/client/ApexCodecsLazy.cpp b/media/codec2/hal/client/ApexCodecsLazy.cpp
index 784798567e..597e824370 100644
--- a/media/codec2/hal/client/ApexCodecsLazy.cpp
+++ b/media/codec2/hal/client/ApexCodecsLazy.cpp
@@ -134,6 +134,7 @@ private:
         BIND_SYMBOL(ApexCodec_Buffer_getGraphicBuffer);
         BIND_SYMBOL(ApexCodec_Buffer_getLinearBuffer);
         BIND_SYMBOL(ApexCodec_Buffer_getType);
+        BIND_SYMBOL(ApexCodec_Buffer_setBufferInfo);
         BIND_SYMBOL(ApexCodec_Buffer_setConfigUpdates);
         BIND_SYMBOL(ApexCodec_Buffer_setGraphicBuffer);
         BIND_SYMBOL(ApexCodec_Buffer_setLinearBuffer);
@@ -168,6 +169,7 @@ private:
             }
         }
         mInit = true;
+        ALOGI("ApexCodecs loaded");
         return true;
     }
 
diff --git a/media/codec2/hal/client/GraphicsTracker.cpp b/media/codec2/hal/client/GraphicsTracker.cpp
index 6f4e834fcf..cedff96e94 100644
--- a/media/codec2/hal/client/GraphicsTracker.cpp
+++ b/media/codec2/hal/client/GraphicsTracker.cpp
@@ -98,21 +98,44 @@ public:
             return C2_CORRUPTED;
         }
 
-        native_window_set_usage(mSurface.get(), usage);
-        native_window_set_buffers_format(mSurface.get(), format);
-        native_window_set_buffers_dimensions(mSurface.get(), width, height);
-
-        ::android::status_t res;
-        std::vector<Surface::BatchBuffer> buffers(1);
-        res = mSurface->dequeueBuffers(&buffers);
-        if (res != ::android::OK) {
-            ALOGE("dequeueBuffers failed from PlaceHolderSurface %d", res);
-            return C2_CORRUPTED;
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_PLATFORM_API_IMPROVEMENTS)
+        {
+            native_window_set_usage(mSurface.get(), usage);
+            native_window_set_buffers_format(mSurface.get(), format);
+            native_window_set_buffers_dimensions(mSurface.get(), width, height);
+
+            sp<GraphicBuffer> gb;
+            ::android::status_t res = mSurface->dequeueBuffer(&gb, fence);
+            if (res != ::android::OK) {
+                ALOGE("dequeueBuffer failed from PlaceHolderSurface %d", res);
+                return C2_CORRUPTED;
+            }
+            (void)mSurface->detachBuffer(gb);
+            *pBuf = AHardwareBuffer_from_GraphicBuffer(gb.get());
+            AHardwareBuffer_acquire(*pBuf);
+        }
+#else
+        // NOTE: This should be obsolete from 25Q2.
+        {
+            sp<IGraphicBufferProducer> producer = mSurface->getIGraphicBufferProducer();
+            int slot;
+            ::android::status_t res = producer->dequeueBuffer(
+                    &slot, fence, width, height, format, usage, nullptr, nullptr);
+            if (res < 0) {
+                ALOGE("Producer::dequeueBuffer failed from PlaceHolderSurface %d", res);
+                return C2_CORRUPTED;
+            }
+            sp<GraphicBuffer> gb;
+            res = producer->requestBuffer(slot, &gb);
+            if (res != ::android::OK) {
+                ALOGE("Producer::requestBuffer failed from PlaceHolderSurface %d", res);
+                return C2_CORRUPTED;
+            }
+            (void)producer->detachBuffer(slot);
+            *pBuf = AHardwareBuffer_from_GraphicBuffer(gb.get());
+            AHardwareBuffer_acquire(*pBuf);
         }
-        sp<GraphicBuffer> gb = GraphicBuffer::from(buffers[0].buffer);
-        *pBuf = AHardwareBuffer_from_GraphicBuffer(gb.get());
-        AHardwareBuffer_acquire(*pBuf);
-        *fence = new Fence(buffers[0].fenceFd);
+#endif
         return C2_OK;
     }
 
diff --git a/media/codec2/hal/client/client.cpp b/media/codec2/hal/client/client.cpp
index e2af0d9c83..f2b19faa15 100644
--- a/media/codec2/hal/client/client.cpp
+++ b/media/codec2/hal/client/client.cpp
@@ -26,9 +26,10 @@
 #include <codec2/common/HalSelection.h>
 #include <codec2/hidl/client.h>
 
-#include <C2Debug.h>
 #include <C2BufferPriv.h>
+#include <C2Component.h>
 #include <C2Config.h> // for C2StreamUsageTuning
+#include <C2Debug.h>
 #include <C2PlatformSupport.h>
 
 #include <android/hardware/media/bufferpool/2.0/IClientManager.h>
@@ -2212,6 +2213,21 @@ c2_status_t Codec2Client::createComponent_hidl(
 c2_status_t Codec2Client::createInterface(
         const C2String& name,
         std::shared_ptr<Codec2Client::Interface>* const interface) {
+    if (mApexBase) {
+        if (__builtin_available(android 36, *)) {
+            ApexCodec_Component *comp = nullptr;
+            c2_status_t status =
+                (c2_status_t)ApexCodec_Component_create(mApexBase, name.c_str(), &comp);
+            if (status != C2_OK) {
+                return status;
+            }
+            // interface owns |comp| and will release it in the destructor.
+            interface->reset(new Codec2Client::Interface(comp, name));
+            return C2_OK;
+        } else {
+            return C2_OMITTED;
+        }
+    }
     if (mAidlBase) {
         std::shared_ptr<c2_aidl::IComponentInterface> aidlInterface;
         ::ndk::ScopedAStatus transStatus = mAidlBase->createInterface(
@@ -2261,30 +2277,26 @@ c2_status_t Codec2Client::createInterface(
 
 c2_status_t Codec2Client::createInputSurface(
         std::shared_ptr<InputSurface>* const inputSurface) {
-    if (mAidlBase) {
-        // FIXME
+    if (mApexBase) {
+        // Not supported for APEX.
         return C2_OMITTED;
     }
-
-    c2_status_t status;
-    Return<void> transStatus = mHidlBase1_0->createInputSurface(
-            [&status, inputSurface](
-                    c2_hidl::Status s,
-                    const sp<c2_hidl::IInputSurface>& i) {
-                status = static_cast<c2_status_t>(s);
-                if (status != C2_OK) {
-                    return;
-                }
-                *inputSurface = std::make_shared<InputSurface>(i);
-            });
-    if (!transStatus.isOk()) {
-        LOG(ERROR) << "createInputSurface -- transaction failed.";
-        return C2_TRANSACTION_FAILED;
-    } else if (status != C2_OK) {
-        LOG(DEBUG) << "createInputSurface -- call failed: "
-                   << status << ".";
+    if (!mAidlBase) {
+        // Only AIDL supports InputSurface.
+        return C2_OMITTED;
     }
-    return status;
+    if (!IsCodec2AidlInputSurfaceSelected()) {
+        return C2_OMITTED;
+    }
+    std::shared_ptr<c2_aidl::IInputSurface> interface;
+    ndk::ScopedAStatus status = mAidlBase->createInputSurface(&interface);
+    c2_status_t c2Status = GetC2Status(status, "createInputSurface");
+    if (c2Status != C2_OK) {
+        LOG(ERROR) << "createInputSurface() failed: " << c2Status;
+        return c2Status;
+    }
+    *inputSurface = std::make_shared<InputSurface>(interface);
+    return C2_OK;
 }
 
 std::vector<C2Component::Traits> const& Codec2Client::listComponents() const {
@@ -2296,6 +2308,28 @@ std::vector<C2Component::Traits> Codec2Client::_listComponents(
     std::vector<C2Component::Traits> traits;
     std::string const& serviceName = getServiceName();
 
+    if (mApexBase) {
+        if (__builtin_available(android 36, *)) {
+            for (size_t i = 0; ; ++i) {
+                ApexCodec_ComponentTraits *apexTraits = ApexCodec_Traits_get(mApexBase, i);
+                if (!apexTraits) {
+                    break;
+                }
+                traits.emplace_back();
+                C2Component::Traits& trait = traits.back();
+                trait.name      = apexTraits->name;
+                trait.mediaType = apexTraits->mediaType;
+                trait.domain    = (C2Component::domain_t)apexTraits->domain;
+                trait.kind      = (C2Component::kind_t)apexTraits->kind;
+                trait.owner     = serviceName;
+            }
+            *success = true;
+        } else {
+            *success = false;
+            LOG(WARNING) << "ApexCodecs not supported on Android version older than 36";
+        }
+        return traits;
+    }
     if (mAidlBase) {
         std::vector<c2_aidl::IComponentStore::ComponentTraits> aidlTraits;
         ::ndk::ScopedAStatus transStatus = mAidlBase->listComponents(&aidlTraits);
@@ -2781,6 +2815,12 @@ std::shared_ptr<Codec2Client::InputSurface> Codec2Client::CreateInputSurface(
     return nullptr;
 }
 
+std::shared_ptr<Codec2Client::InputSurface> Codec2Client::CreateInputSurfaceFromInterface(
+        const ::ndk::SpAIBinder &interface) {
+    return std::make_shared<Codec2Client::InputSurface>(
+            c2_aidl::IInputSurface::fromBinder(interface));
+}
+
 bool Codec2Client::IsAidlSelected() {
     return c2_aidl::utils::IsSelected();
 }
@@ -2811,6 +2851,27 @@ Codec2Client::Interface::Interface(const std::shared_ptr<AidlBase>& base)
         mAidlBase{base} {
 }
 
+Codec2Client::Interface::Interface(
+        ApexCodec_Component *base, const C2String &name)
+      : Configurable{[base]() -> ApexCodec_Configurable * {
+            if (__builtin_available(android 36, *)) {
+                return ApexCodec_Component_getConfigurable(base);
+            } else {
+                return nullptr;
+            }
+        }(), name},
+        mApexBase{base} {
+}
+
+Codec2Client::Interface::~Interface() {
+    if (mApexBase) {
+        if (__builtin_available(android 36, *)) {
+            ApexCodec_Component_destroy(mApexBase);
+        }
+        mApexBase = nullptr;
+    }
+}
+
 // Codec2Client::Component
 
 class Codec2Client::Component::AidlDeathManager {
@@ -3611,92 +3672,6 @@ void Codec2Client::Component::holdIgbaBlocks(
     }
 }
 
-c2_status_t Codec2Client::Component::connectToInputSurface(
-        const std::shared_ptr<InputSurface>& inputSurface,
-        std::shared_ptr<InputSurfaceConnection>* connection) {
-    if (mApexBase) {
-        // FIXME
-        return C2_OMITTED;
-    }
-    if (mAidlBase) {
-        // FIXME
-        return C2_OMITTED;
-    }
-    c2_status_t status;
-    Return<void> transStatus = mHidlBase1_0->connectToInputSurface(
-            inputSurface->mBase,
-            [&status, connection](
-                    c2_hidl::Status s, const sp<c2_hidl::IInputSurfaceConnection>& c) {
-                status = static_cast<c2_status_t>(s);
-                if (status != C2_OK) {
-                    LOG(DEBUG) << "connectToInputSurface -- call failed: "
-                               << status << ".";
-                    return;
-                }
-                *connection = std::make_shared<InputSurfaceConnection>(c);
-            });
-    if (!transStatus.isOk()) {
-        LOG(ERROR) << "connectToInputSurface -- transaction failed";
-        return C2_TRANSACTION_FAILED;
-    }
-    return status;
-}
-
-c2_status_t Codec2Client::Component::connectToOmxInputSurface(
-        const sp<HGraphicBufferProducer1>& producer,
-        const sp<HGraphicBufferSource>& source,
-        std::shared_ptr<InputSurfaceConnection>* connection) {
-    if (mApexBase) {
-        LOG(WARNING) << "Connecting to OMX input surface is not supported for AIDL C2 HAL";
-        return C2_OMITTED;
-    }
-    if (mAidlBase) {
-        LOG(WARNING) << "Connecting to OMX input surface is not supported for AIDL C2 HAL";
-        return C2_OMITTED;
-    }
-    c2_status_t status;
-    Return<void> transStatus = mHidlBase1_0->connectToOmxInputSurface(
-            producer, source,
-            [&status, connection](
-                    c2_hidl::Status s, const sp<c2_hidl::IInputSurfaceConnection>& c) {
-                status = static_cast<c2_status_t>(s);
-                if (status != C2_OK) {
-                    LOG(DEBUG) << "connectToOmxInputSurface -- call failed: "
-                               << status << ".";
-                    return;
-                }
-                *connection = std::make_shared<InputSurfaceConnection>(c);
-            });
-    if (!transStatus.isOk()) {
-        LOG(ERROR) << "connectToOmxInputSurface -- transaction failed.";
-        return C2_TRANSACTION_FAILED;
-    }
-    return status;
-}
-
-c2_status_t Codec2Client::Component::disconnectFromInputSurface() {
-    if (mApexBase) {
-        // FIXME
-        return C2_OMITTED;
-    }
-    if (mAidlBase) {
-        // FIXME
-        return C2_OMITTED;
-    }
-    Return<c2_hidl::Status> transStatus = mHidlBase1_0->disconnectFromInputSurface();
-    if (!transStatus.isOk()) {
-        LOG(ERROR) << "disconnectToInputSurface -- transaction failed.";
-        return C2_TRANSACTION_FAILED;
-    }
-    c2_status_t status =
-            static_cast<c2_status_t>(static_cast<c2_hidl::Status>(transStatus));
-    if (status != C2_OK) {
-        LOG(DEBUG) << "disconnectFromInputSurface -- call failed: "
-                   << status << ".";
-    }
-    return status;
-}
-
 Codec2Client::Component::AidlDeathManager *Codec2Client::Component::GetAidlDeathManager() {
     // This object never gets destructed
     static AidlDeathManager *sManager = new AidlDeathManager();
@@ -3760,54 +3735,90 @@ c2_status_t Codec2Client::Component::setDeathListener(
 }
 
 // Codec2Client::InputSurface
-Codec2Client::InputSurface::InputSurface(const sp<c2_hidl::IInputSurface>& base)
+Codec2Client::InputSurface::InputSurface(const std::shared_ptr<c2_aidl::IInputSurface>& base)
       : Configurable{
-            [base]() -> sp<c2_hidl::IConfigurable> {
-                Return<sp<c2_hidl::IConfigurable>> transResult =
-                        base->getConfigurable();
-                return transResult.isOk() ?
-                        static_cast<sp<c2_hidl::IConfigurable>>(transResult) :
-                        nullptr;
+            [base]() -> std::shared_ptr<c2_aidl::IConfigurable> {
+                std::shared_ptr<c2_aidl::IConfigurable> aidlConfigurable;
+                ::ndk::ScopedAStatus transStatus =
+                    base->getConfigurable(&aidlConfigurable);
+                return transStatus.isOk() ? aidlConfigurable : nullptr;
             }()
         },
-        mBase{base},
-        mGraphicBufferProducer{new
-            H2BGraphicBufferProducer2([base]() -> sp<HGraphicBufferProducer2> {
-                Return<sp<HGraphicBufferProducer2>> transResult =
-                        base->getGraphicBufferProducer();
-                return transResult.isOk() ?
-                        static_cast<sp<HGraphicBufferProducer2>>(transResult) :
-                        nullptr;
-            }())} {
+        mBase{base}, mNativeWindow{nullptr} {
+}
+
+ANativeWindow *Codec2Client::InputSurface::getNativeWindow() {
+    std::call_once(mWindowInitOnce, [this]() {
+        ::aidl::android::view::Surface surface;
+        ::ndk::ScopedAStatus transStatus = mBase->getSurface(&surface);
+        c2_status_t c2Status = GetC2Status(transStatus, "InputSurface::getNativeWindow");
+        if (c2Status != C2_OK) {
+            LOG(ERROR) << "InputSurface::getNativeWindow -- cannot get window: " << c2Status;
+            return;
+        }
+        mNativeWindow = surface.release();
+    });
+    return mNativeWindow;
 }
 
-sp<IGraphicBufferProducer>
-        Codec2Client::InputSurface::getGraphicBufferProducer() const {
-    return mGraphicBufferProducer;
+::ndk::SpAIBinder Codec2Client::InputSurface::getHalInterface() const {
+    return mBase ? mBase->asBinder() : nullptr;
 }
 
-sp<c2_hidl::IInputSurface> Codec2Client::InputSurface::getHalInterface() const {
-    return mBase;
+c2_status_t Codec2Client::InputSurface::connect(
+        const std::shared_ptr<Codec2Client::Component> &comp,
+        std::shared_ptr<Connection> *connection) {
+    if (!comp) {
+        LOG(ERROR) << "InputSurface:connect, component invalid";
+        return C2_BAD_VALUE;
+    }
+    std::shared_ptr<Codec2Client::Component::AidlBase> aidlBase = comp->mAidlBase;
+    if (!aidlBase) {
+        LOG(ERROR) << "InputSurface:connect, component invalid";
+        return C2_BAD_VALUE;
+    }
+    std::shared_ptr<c2_aidl::IInputSink> sink;
+    ::ndk::ScopedAStatus transResult = aidlBase->asInputSink(&sink);
+    if (GetC2Status(transResult, "InputSurface:Component:asInputSink") != C2_OK) {
+        LOG(ERROR) << "InputSurface:connect sink conversion failed";
+        return C2_CORRUPTED;
+    }
+    if (!mBase) {
+        LOG(ERROR) << "InputSurface:connect failed, no valid base";
+        return C2_CORRUPTED;
+    }
+    std::shared_ptr<ConnectionBase> base;
+    transResult = mBase->connect(sink, &base);
+    c2_status_t c2Status = GetC2Status(transResult, "InputSurface:connect");
+    if (c2Status != C2_OK) {
+        LOG(ERROR) << "IInputSurface:connect failed: " << c2Status;
+        return c2Status;
+    }
+    *connection = std::make_shared<Connection>(base);
+    return C2_OK;
 }
 
 // Codec2Client::InputSurfaceConnection
 Codec2Client::InputSurfaceConnection::InputSurfaceConnection(
-        const sp<c2_hidl::IInputSurfaceConnection>& base)
-      : Configurable{
-            [base]() -> sp<c2_hidl::IConfigurable> {
-                Return<sp<c2_hidl::IConfigurable>> transResult =
-                        base->getConfigurable();
-                return transResult.isOk() ?
-                        static_cast<sp<c2_hidl::IConfigurable>>(transResult) :
-                        nullptr;
-            }()
-        },
-        mBase{base} {
+        const std::shared_ptr<c2_aidl::IInputSurfaceConnection>& base) : mBase{base} {
 }
 
 c2_status_t Codec2Client::InputSurfaceConnection::disconnect() {
-    Return<c2_hidl::Status> transResult = mBase->disconnect();
-    return static_cast<c2_status_t>(static_cast<c2_hidl::Status>(transResult));
+    if (!mBase) {
+        LOG(ERROR) << "InputSurfaceConnection:disconnect failed, no valid base";
+        return C2_CORRUPTED;
+    }
+    ::ndk::ScopedAStatus transResult = mBase->disconnect();
+    return GetC2Status(transResult, "InputSurfaceConnection::disconnect");
+}
+
+c2_status_t Codec2Client::InputSurfaceConnection::signalEos() {
+    if (!mBase) {
+        LOG(ERROR) << "InputSurfaceConnection:signalEos failed, no valid base";
+        return C2_CORRUPTED;
+    }
+    ::ndk::ScopedAStatus transResult = mBase->signalEndOfStream();
+    return GetC2Status(transResult, "InputSurfaceConnection::signalEndOfStream");
 }
 
 }  // namespace android
diff --git a/media/codec2/hal/client/include/codec2/hidl/client.h b/media/codec2/hal/client/include/codec2/hidl/client.h
index 35c87e0a54..bb3775cd92 100644
--- a/media/codec2/hal/client/include/codec2/hidl/client.h
+++ b/media/codec2/hal/client/include/codec2/hidl/client.h
@@ -23,6 +23,7 @@
 #include <C2Param.h>
 #include <C2.h>
 
+#include <android/native_window_aidl.h>
 #include <gui/FrameTimestamps.h>
 #include <gui/IGraphicBufferProducer.h>
 #include <hidl/HidlSupport.h>
@@ -69,9 +70,6 @@ struct IConfigurable;
 struct IComponent;
 struct IComponentInterface;
 struct IComponentStore;
-struct IInputSink;
-struct IInputSurface;
-struct IInputSurfaceConnection;
 }  // namespace android::hardware::media::c2::V1_0
 
 namespace android::hardware::media::c2::V1_1 {
@@ -89,6 +87,9 @@ class IComponent;
 class IComponentInterface;
 class IComponentStore;
 class IConfigurable;
+class IInputSink;
+class IInputSurface;
+class IInputSurfaceConnection;
 }  // namespace aidl::android::hardware::media::c2
 
 namespace android::hardware::media::bufferpool::V2_0 {
@@ -190,6 +191,7 @@ struct Codec2Client : public Codec2ConfigurableClient {
     typedef HidlBase1_0 HidlBase;
 
     typedef ::aidl::android::hardware::media::c2::IComponentStore AidlBase;
+    typedef ::aidl::android::hardware::media::c2::IInputSurface IInputSurface;
 
     struct Listener;
 
@@ -276,6 +278,10 @@ struct Codec2Client : public Codec2ConfigurableClient {
     static std::shared_ptr<InputSurface> CreateInputSurface(
             char const* serviceName = nullptr);
 
+    // Create an input surface from an existing interface.
+    static std::shared_ptr<InputSurface> CreateInputSurfaceFromInterface(
+            const ::ndk::SpAIBinder &interface);
+
     // Whether AIDL is selected.
     static bool IsAidlSelected();
 
@@ -358,10 +364,13 @@ struct Codec2Client::Interface : public Codec2Client::Configurable {
 
     Interface(const sp<HidlBase>& base);
     Interface(const std::shared_ptr<AidlBase>& base);
+    Interface(ApexCodec_Component* base, const C2String& name);
+    ~Interface();
 
 protected:
     sp<HidlBase> mHidlBase;
     std::shared_ptr<AidlBase> mAidlBase;
+    ApexCodec_Component *mApexBase{nullptr};
 };
 
 struct Codec2Client::Listener {
@@ -520,18 +529,6 @@ struct Codec2Client::Component : public Codec2Client::Configurable {
     void holdIgbaBlocks(
             const std::list<std::unique_ptr<C2Work>>& workList);
 
-    // Connect to a given InputSurface.
-    c2_status_t connectToInputSurface(
-            const std::shared_ptr<InputSurface>& inputSurface,
-            std::shared_ptr<InputSurfaceConnection>* connection);
-
-    c2_status_t connectToOmxInputSurface(
-            const sp<HGraphicBufferProducer1>& producer,
-            const sp<HGraphicBufferSource>& source,
-            std::shared_ptr<InputSurfaceConnection>* connection);
-
-    c2_status_t disconnectFromInputSurface();
-
     c2_status_t initApexHandler(
             const std::shared_ptr<Listener> &listener,
             const std::shared_ptr<Component> &comp);
@@ -592,44 +589,78 @@ protected:
     void handleOnWorkDone(const std::list<std::unique_ptr<C2Work>> &workItems);
 };
 
+
+// Creation of InputSurface
+// Codec2Client               --> Codec2Client::InputSurface.
+// Codec2Client::InputSurface --> Codec2Client::InputSurfaceConnection
+//
+// Codec2Client::InputSurface could have at most only one
+// Codec2Client::InputSurfaceConnection at any given time.
+//
+// A Codec2Client::InputSurfaceConnection is valid during a video encoder
+// session. After a encoder session, the end of stream can be notified by
+// Codec2Client::InputSurfaceConnection::signalEos() to the encoder.
+//
+// Codec2Client::InputSurfaceConnection::disconnect() will disconnect from the
+// encoder and notify that it is no longer valid to Codec2Client::InputSurface.
+// On disconnect() Codec2Client::InputSurface will perform clean-up, then
+// Codec2Client::InputSurface is ready to re-start with a new encoder and a new
+// Codec2Client::InputSurfaceConnection.
+
+// The class holds ::aidl::android::hardware::media::c2::IInputSurface for the
+// client framework.
 struct Codec2Client::InputSurface : public Codec2Client::Configurable {
 public:
-    typedef ::android::hardware::media::c2::V1_0::IInputSurface Base;
 
-    typedef ::android::hardware::media::c2::V1_0::IInputSurfaceConnection ConnectionBase;
+    typedef ::aidl::android::hardware::media::c2::IInputSurface Base;
 
-    typedef Codec2Client::InputSurfaceConnection Connection;
+    typedef ::aidl::android::hardware::media::c2::IInputSurfaceConnection ConnectionBase;
 
-    typedef ::android::IGraphicBufferProducer IGraphicBufferProducer;
+    typedef Codec2Client::InputSurfaceConnection Connection;
 
-    sp<IGraphicBufferProducer> getGraphicBufferProducer() const;
+    // Return the window which is owned by the underlying interface.
+    ANativeWindow *getNativeWindow();
 
     // Return the underlying IInputSurface.
-    sp<Base> getHalInterface() const;
+    ::ndk::SpAIBinder getHalInterface() const;
+
+    // connect to a video encoder component.
+    c2_status_t connect(
+            const std::shared_ptr<Codec2Client::Component> &comp,
+            std::shared_ptr<Connection> *connection);
 
     // base cannot be null.
-    InputSurface(const sp<Base>& base);
+    InputSurface(const std::shared_ptr<Base>& base);
 
 protected:
-    sp<Base> mBase;
-
-    sp<IGraphicBufferProducer> mGraphicBufferProducer;
+    std::shared_ptr<Base> mBase;
 
+    std::once_flag mWindowInitOnce;
+    ANativeWindow *mNativeWindow; // lazily initialized,
+                                  // for later construction params binding.
     friend struct Codec2Client;
     friend struct Component;
 };
 
-struct Codec2Client::InputSurfaceConnection : public Codec2Client::Configurable {
+// The class holds ::aidl::android::hardware::media::c2::IInputSurfaceConnection
+// for the client framework.
+struct Codec2Client::InputSurfaceConnection {
 
-    typedef ::android::hardware::media::c2::V1_0::IInputSurfaceConnection Base;
+    typedef ::aidl::android::hardware::media::c2::IInputSurfaceConnection Base;
 
+    // disconnect from a video encoder from the class.
+    // This will eventually notify Codec2Client::InputSurface that
+    // life cycle of the class is ended.
     c2_status_t disconnect();
 
+    // signal Eos to the connected video encoder.
+    c2_status_t signalEos();
+
     // base cannot be null.
-    InputSurfaceConnection(const sp<Base>& base);
+    InputSurfaceConnection(const std::shared_ptr<Base>& base);
 
 protected:
-    sp<Base> mBase;
+    std::shared_ptr<Base> mBase;
 
     friend struct Codec2Client::InputSurface;
 };
diff --git a/media/codec2/hal/hidl/1.0/utils/Android.bp b/media/codec2/hal/hidl/1.0/utils/Android.bp
index 9646a0b9c3..ba269ba97d 100644
--- a/media/codec2/hal/hidl/1.0/utils/Android.bp
+++ b/media/codec2/hal/hidl/1.0/utils/Android.bp
@@ -71,8 +71,6 @@ cc_library {
         "ComponentStore.cpp",
         "Configurable.cpp",
         "InputBufferManager.cpp",
-        "InputSurface.cpp",
-        "InputSurfaceConnection.cpp",
         "types.cpp",
     ],
 
@@ -99,7 +97,6 @@ cc_library {
         "libhidlbase",
         "liblog",
         "libstagefright_bufferpool@2.0.1",
-        "libstagefright_bufferqueue_helper_novndk",
         "libui",
         "libutils",
     ],
@@ -107,11 +104,9 @@ cc_library {
     target: {
         vendor: {
             exclude_shared_libs: [
-                "libstagefright_bufferqueue_helper_novndk",
                 "libcodec2_hidl_plugin_stub",
             ],
             shared_libs: [
-                "libstagefright_bufferqueue_helper",
                 "libcodec2_hidl_plugin",
             ],
         },
diff --git a/media/codec2/hal/hidl/1.0/utils/Component.cpp b/media/codec2/hal/hidl/1.0/utils/Component.cpp
index 162a80e2f4..f5afd0e1ea 100644
--- a/media/codec2/hal/hidl/1.0/utils/Component.cpp
+++ b/media/codec2/hal/hidl/1.0/utils/Component.cpp
@@ -385,17 +385,8 @@ Return<Status> Component::setOutputSurface(
 Return<void> Component::connectToInputSurface(
         const sp<IInputSurface>& inputSurface,
         connectToInputSurface_cb _hidl_cb) {
-    Status status;
-    sp<IInputSurfaceConnection> connection;
-    auto transStatus = inputSurface->connect(
-            asInputSink(),
-            [&status, &connection](
-                    Status s, const sp<IInputSurfaceConnection>& c) {
-                status = s;
-                connection = c;
-            }
-        );
-    _hidl_cb(status, connection);
+    (void)inputSurface;
+    _hidl_cb(Status::OMITTED, nullptr);
     return Void();
 }
 
diff --git a/media/codec2/hal/hidl/1.0/utils/ComponentStore.cpp b/media/codec2/hal/hidl/1.0/utils/ComponentStore.cpp
index 108ba06129..664088a896 100644
--- a/media/codec2/hal/hidl/1.0/utils/ComponentStore.cpp
+++ b/media/codec2/hal/hidl/1.0/utils/ComponentStore.cpp
@@ -19,11 +19,9 @@
 #include <android-base/logging.h>
 
 #include <codec2/hidl/1.0/ComponentStore.h>
-#include <codec2/hidl/1.0/InputSurface.h>
 #include <codec2/hidl/1.0/types.h>
 
 #include <android-base/file.h>
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
 #include <utils/Errors.h>
 
 #include <C2PlatformSupport.h>
@@ -51,7 +49,6 @@ namespace V1_0 {
 namespace utils {
 
 using namespace ::android;
-using ::android::GraphicBufferSource;
 using namespace ::android::hardware::media::bufferpool::V2_0::implementation;
 
 namespace /* unnamed */ {
@@ -324,19 +321,7 @@ Return<void> ComponentStore::listComponents(listComponents_cb _hidl_cb) {
 }
 
 Return<void> ComponentStore::createInputSurface(createInputSurface_cb _hidl_cb) {
-    sp<GraphicBufferSource> source = new GraphicBufferSource();
-    if (source->initCheck() != OK) {
-        _hidl_cb(Status::CORRUPTED, nullptr);
-        return Void();
-    }
-    using namespace std::placeholders;
-    sp<InputSurface> inputSurface = new InputSurface(
-            mParameterCache,
-            std::make_shared<C2ReflectorHelper>(),
-            source->getHGraphicBufferProducer(),
-            source);
-    _hidl_cb(inputSurface ? Status::OK : Status::NO_MEMORY,
-             inputSurface);
+    _hidl_cb(Status::OMITTED, nullptr);
     return Void();
 }
 
diff --git a/media/codec2/hal/hidl/1.0/utils/InputSurface.cpp b/media/codec2/hal/hidl/1.0/utils/InputSurface.cpp
deleted file mode 100644
index c3c32e9c0a..0000000000
--- a/media/codec2/hal/hidl/1.0/utils/InputSurface.cpp
+++ /dev/null
@@ -1,177 +0,0 @@
-/*
- * Copyright 2018 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-//#define LOG_NDEBUG 0
-#define LOG_TAG "Codec2-InputSurface"
-#include <android-base/logging.h>
-
-#include <codec2/hidl/1.0/InputSurface.h>
-#include <codec2/hidl/1.0/InputSurfaceConnection.h>
-
-#include <C2Component.h>
-#include <C2Config.h>
-
-#include <memory>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_0 {
-namespace utils {
-
-using namespace ::android;
-
-// Derived class of C2InterfaceHelper
-class InputSurface::Interface : public C2InterfaceHelper {
-public:
-    explicit Interface(
-            const std::shared_ptr<C2ReflectorHelper> &helper)
-        : C2InterfaceHelper(helper) {
-
-        setDerivedInstance(this);
-
-        addParameter(
-                DefineParam(mEos, C2_PARAMKEY_INPUT_SURFACE_EOS)
-                .withDefault(new C2InputSurfaceEosTuning(false))
-                .withFields({C2F(mEos, value).oneOf({true, false})})
-                .withSetter(EosSetter)
-                .build());
-    }
-
-    static C2R EosSetter(bool mayBlock, C2P<C2InputSurfaceEosTuning> &me) {
-        (void)mayBlock;
-        return me.F(me.v.value).validatePossible(me.v.value);
-    }
-
-    bool eos() const { return mEos->value; }
-
-private:
-    std::shared_ptr<C2InputSurfaceEosTuning> mEos;
-};
-
-// Derived class of ConfigurableC2Intf
-class InputSurface::ConfigurableIntf : public ConfigurableC2Intf {
-public:
-    ConfigurableIntf(
-            const std::shared_ptr<InputSurface::Interface> &intf,
-            const sp<GraphicBufferSource> &source)
-        : ConfigurableC2Intf("input-surface", 0),
-          mIntf(intf),
-          mSource(source) {
-    }
-
-    virtual ~ConfigurableIntf() override = default;
-
-    virtual c2_status_t query(
-            const std::vector<C2Param::Index> &indices,
-            c2_blocking_t mayBlock,
-            std::vector<std::unique_ptr<C2Param>>* const params
-            ) const override {
-        return mIntf->query({}, indices, mayBlock, params);
-    }
-
-    virtual c2_status_t config(
-            const std::vector<C2Param*> &params,
-            c2_blocking_t mayBlock,
-            std::vector<std::unique_ptr<C2SettingResult>>* const failures
-            ) override {
-        c2_status_t err = mIntf->config(params, mayBlock, failures);
-        if (mIntf->eos()) {
-            sp<GraphicBufferSource> source = mSource.promote();
-            if (source == nullptr || source->signalEndOfInputStream() != OK) {
-                // TODO: put something in |failures|
-                err = C2_BAD_VALUE;
-            }
-            // TODO: reset eos?
-        }
-        return err;
-    }
-
-    virtual c2_status_t querySupportedParams(
-            std::vector<std::shared_ptr<C2ParamDescriptor>>* const params
-            ) const override {
-        return mIntf->querySupportedParams(params);
-    }
-
-    virtual c2_status_t querySupportedValues(
-            std::vector<C2FieldSupportedValuesQuery>& fields,
-            c2_blocking_t mayBlock) const override {
-        return mIntf->querySupportedValues(fields, mayBlock);
-    }
-
-private:
-    const std::shared_ptr<InputSurface::Interface> mIntf;
-    wp<GraphicBufferSource> mSource;
-};
-
-Return<sp<InputSurface::HGraphicBufferProducer>> InputSurface::getGraphicBufferProducer() {
-    return mProducer;
-}
-
-Return<sp<IConfigurable>> InputSurface::getConfigurable() {
-    return mConfigurable;
-}
-
-Return<void> InputSurface::connect(
-        const sp<IInputSink>& sink,
-        connect_cb _hidl_cb) {
-    Status status;
-    sp<InputSurfaceConnection> connection;
-    if (!sink) {
-        _hidl_cb(Status::BAD_VALUE, nullptr);
-        return Void();
-    }
-    std::shared_ptr<C2Component> comp = Component::findLocalComponent(sink);
-    if (comp) {
-        connection = new InputSurfaceConnection(mSource, comp, mParameterCache);
-    } else {
-        connection = new InputSurfaceConnection(mSource, sink, mParameterCache);
-    }
-    if (!connection->init()) {
-        connection = nullptr;
-        status = Status::BAD_VALUE;
-    } else {
-        status = Status::OK;
-    }
-    _hidl_cb(status, connection);
-    return Void();
-}
-
-// Constructor is exclusive to ComponentStore.
-InputSurface::InputSurface(
-        const std::shared_ptr<ParameterCache>& cache,
-        const std::shared_ptr<C2ReflectorHelper>& reflector,
-        const sp<HGraphicBufferProducer>& producer,
-        const sp<GraphicBufferSource>& source)
-      : mParameterCache{cache},
-        mProducer{producer},
-        mSource{source},
-        mIntf{std::make_shared<Interface>(reflector)},
-        mConfigurable{new CachedConfigurable(
-                std::make_unique<ConfigurableIntf>(
-                    mIntf, source))} {
-
-    mConfigurable->init(mParameterCache);
-}
-
-}  // namespace utils
-}  // namespace V1_0
-}  // namespace c2
-}  // namespace media
-}  // namespace hardware
-}  // namespace android
-
diff --git a/media/codec2/hal/hidl/1.0/utils/InputSurfaceConnection.cpp b/media/codec2/hal/hidl/1.0/utils/InputSurfaceConnection.cpp
deleted file mode 100644
index d3fdd6b2a6..0000000000
--- a/media/codec2/hal/hidl/1.0/utils/InputSurfaceConnection.cpp
+++ /dev/null
@@ -1,531 +0,0 @@
-/*
- * Copyright 2018 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-//#define LOG_NDEBUG 0
-#define LOG_TAG "Codec2-InputSurfaceConnection"
-#include <android-base/logging.h>
-
-#include <codec2/hidl/1.0/InputSurfaceConnection.h>
-#include <codec2/hidl/1.0/InputSurfaceConnection.h>
-
-#include <memory>
-#include <list>
-#include <mutex>
-#include <atomic>
-
-#include <hidl/HidlSupport.h>
-#include <media/stagefright/bqhelper/ComponentWrapper.h>
-#include <system/graphics.h>
-#include <ui/GraphicBuffer.h>
-#include <utils/Errors.h>
-
-#include <C2.h>
-#include <C2AllocatorGralloc.h>
-#include <C2BlockInternal.h>
-#include <C2Buffer.h>
-#include <C2Component.h>
-#include <C2Config.h>
-#include <C2Debug.h>
-#include <C2PlatformSupport.h>
-#include <C2Work.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_0 {
-namespace utils {
-
-constexpr int32_t kBufferCount = 16;
-
-using namespace ::android;
-using ::android::hardware::hidl_string;
-using ::android::hardware::hidl_vec;
-using ::android::hardware::Return;
-
-namespace /* unnamed */ {
-
-class Buffer2D : public C2Buffer {
-public:
-    explicit Buffer2D(C2ConstGraphicBlock block) : C2Buffer({ block }) {
-    }
-};
-
-} // unnamed namespace
-
-// Derived class of ComponentWrapper for use with
-// GraphicBufferSource::configure().
-//
-struct InputSurfaceConnection::Impl : public ComponentWrapper {
-
-    Impl(const sp<GraphicBufferSource>& source,
-         const std::shared_ptr<C2Component>& localComp)
-          : mSource{source}, mLocalComp{localComp}, mSink{}, mFrameIndex{0} {
-        std::shared_ptr<C2ComponentInterface> intf = localComp->intf();
-        mSinkName = intf ? intf->getName() : "";
-    }
-
-    Impl(const sp<GraphicBufferSource>& source,
-         const sp<IInputSink>& sink)
-          : mSource{source}, mLocalComp{}, mSink{sink}, mFrameIndex{0} {
-        Return<sp<IConfigurable>> transResult = sink->getConfigurable();
-        if (!transResult.isOk()) {
-            LOG(ERROR) << "Remote sink is dead.";
-            return;
-        }
-        mSinkConfigurable =
-                static_cast<sp<IConfigurable>>(transResult);
-        if (!mSinkConfigurable) {
-            LOG(ERROR) << "Remote sink is not configurable.";
-            mSinkName = "";
-            return;
-        }
-
-        hidl_string name;
-        Return<void> transStatus = mSinkConfigurable->getName(
-                [&name](const hidl_string& n) {
-                    name = n;
-                });
-        if (!transStatus.isOk()) {
-            LOG(ERROR) << "Remote sink's configurable is dead.";
-            mSinkName = "";
-            return;
-        }
-        mSinkName = name.c_str();
-    }
-
-    virtual ~Impl() {
-        mSource->stop();
-        mSource->release();
-    }
-
-    bool init() {
-        if (mSource == nullptr) {
-            return false;
-        }
-        status_t err = mSource->initCheck();
-        if (err != OK) {
-            LOG(WARNING) << "Impl::init -- GraphicBufferSource init failed: "
-                         << "status = " << err << ".";
-            return false;
-        }
-
-        // TODO: read settings properly from the interface
-        C2StreamPictureSizeInfo::input inputSize;
-        C2StreamUsageTuning::input usage;
-        c2_status_t c2Status = queryFromSink({ &inputSize, &usage },
-                                         {},
-                                         C2_MAY_BLOCK,
-                                         nullptr);
-        if (c2Status != C2_OK) {
-            LOG(WARNING) << "Impl::init -- cannot query information from "
-                            "the component interface: "
-                         << "status = " << asString(c2Status) << ".";
-            return false;
-        }
-
-        // TODO: proper color aspect & dataspace
-        android_dataspace dataSpace = HAL_DATASPACE_BT709;
-
-        // TODO: use the usage read from intf
-        // uint32_t grallocUsage =
-        //         C2AndroidMemoryUsage(C2MemoryUsage(usage.value)).
-        //         asGrallocUsage();
-
-        uint64_t grallocUsage =
-                mSinkName.compare(0, 11, "c2.android.") == 0 ?
-                GRALLOC_USAGE_SW_READ_OFTEN :
-                GRALLOC_USAGE_HW_VIDEO_ENCODER;
-
-        err = mSource->configure(
-                this, dataSpace, kBufferCount,
-                inputSize.width, inputSize.height,
-                grallocUsage);
-        if (err != OK) {
-            LOG(WARNING) << "Impl::init -- GBS configure failed: "
-                         << "status = " << err << ".";
-            return false;
-        }
-        for (int32_t i = 0; i < kBufferCount; ++i) {
-            if (mSource->onInputBufferAdded(i) != OK) {
-                LOG(WARNING) << "Impl::init: failed to populate GBS slots.";
-                return false;
-            }
-        }
-        if (mSource->start() != OK) {
-            LOG(WARNING) << "Impl::init -- GBS failed to start.";
-            return false;
-        }
-        mAllocatorMutex.lock();
-        c2_status_t c2err = GetCodec2PlatformAllocatorStore()->fetchAllocator(
-                C2AllocatorStore::PLATFORM_START + 1,  // GRALLOC
-                &mAllocator);
-        mAllocatorMutex.unlock();
-        if (c2err != OK) {
-            LOG(WARNING) << "Impl::init -- failed to fetch gralloc allocator: "
-                         << "status = " << asString(c2err) << ".";
-            return false;
-        }
-        return true;
-    }
-
-    // From ComponentWrapper
-    virtual status_t submitBuffer(
-            int32_t bufferId,
-            const sp<GraphicBuffer>& buffer,
-            int64_t timestamp,
-            int fenceFd) override {
-        LOG(VERBOSE) << "Impl::submitBuffer -- bufferId = " << bufferId << ".";
-        // TODO: Use fd to construct fence
-        (void)fenceFd;
-
-        std::shared_ptr<C2GraphicAllocation> alloc;
-        C2Handle* handle = WrapNativeCodec2GrallocHandle(
-                buffer->handle,
-                buffer->width, buffer->height,
-                buffer->format, buffer->usage, buffer->stride);
-        mAllocatorMutex.lock();
-        c2_status_t err = mAllocator->priorGraphicAllocation(handle, &alloc);
-        mAllocatorMutex.unlock();
-        if (err != OK) {
-            native_handle_close(handle);
-            native_handle_delete(handle);
-            return UNKNOWN_ERROR;
-        }
-        std::shared_ptr<C2GraphicBlock> block =
-                _C2BlockFactory::CreateGraphicBlock(alloc);
-
-        std::unique_ptr<C2Work> work(new C2Work);
-        work->input.flags = (C2FrameData::flags_t)0;
-        work->input.ordinal.timestamp = timestamp;
-        work->input.ordinal.frameIndex = mFrameIndex.fetch_add(
-                1, std::memory_order_relaxed);
-        work->input.buffers.clear();
-        std::shared_ptr<C2Buffer> c2Buffer(
-                // TODO: fence
-                new Buffer2D(block->share(
-                        C2Rect(block->width(), block->height()), ::C2Fence())),
-                [bufferId, source = mSource](C2Buffer* ptr) {
-                    delete ptr;
-                    if (source != nullptr) {
-                        // TODO: fence
-                        (void)source->onInputBufferEmptied(bufferId, -1);
-                    }
-                });
-        work->input.buffers.push_back(c2Buffer);
-        work->worklets.clear();
-        work->worklets.emplace_back(new C2Worklet);
-        std::list<std::unique_ptr<C2Work>> items;
-        items.push_back(std::move(work));
-
-        err = queueToSink(&items);
-        return (err == C2_OK) ? OK : UNKNOWN_ERROR;
-    }
-
-    virtual status_t submitEos(int32_t bufferId) override {
-        LOG(VERBOSE) << "Impl::submitEos -- bufferId = " << bufferId << ".";
-        (void)bufferId;
-
-        std::unique_ptr<C2Work> work(new C2Work);
-        work->input.flags = (C2FrameData::flags_t)0;
-        work->input.ordinal.frameIndex = mFrameIndex.fetch_add(
-                1, std::memory_order_relaxed);
-        work->input.buffers.clear();
-        work->worklets.clear();
-        work->worklets.emplace_back(new C2Worklet);
-        std::list<std::unique_ptr<C2Work>> items;
-        items.push_back(std::move(work));
-
-        c2_status_t err = queueToSink(&items);
-        return (err == C2_OK) ? OK : UNKNOWN_ERROR;
-    }
-
-    virtual void dispatchDataSpaceChanged(
-            int32_t dataSpace, int32_t aspects, int32_t pixelFormat) override {
-        // TODO
-        (void)dataSpace;
-        (void)aspects;
-        (void)pixelFormat;
-    }
-
-    // Configurable interface for InputSurfaceConnection::Impl.
-    //
-    // This class is declared as an inner class so that it will have access to
-    // all Impl's members.
-    struct ConfigurableIntf : public ConfigurableC2Intf {
-        sp<Impl> mConnection;
-        ConfigurableIntf(const sp<Impl>& connection)
-              : ConfigurableC2Intf{"input-surface-connection", 0},
-                mConnection{connection} {}
-        virtual c2_status_t config(
-                const std::vector<C2Param*> &params,
-                c2_blocking_t mayBlock,
-                std::vector<std::unique_ptr<C2SettingResult>> *const failures
-                ) override;
-        virtual c2_status_t query(
-                const std::vector<C2Param::Index> &indices,
-                c2_blocking_t mayBlock,
-                std::vector<std::unique_ptr<C2Param>> *const params) const override;
-        virtual c2_status_t querySupportedParams(
-                std::vector<std::shared_ptr<C2ParamDescriptor>> *const params
-                ) const override;
-        virtual c2_status_t querySupportedValues(
-                std::vector<C2FieldSupportedValuesQuery> &fields,
-                c2_blocking_t mayBlock) const override;
-    };
-
-private:
-    c2_status_t queryFromSink(
-            const std::vector<C2Param*> &stackParams,
-            const std::vector<C2Param::Index> &heapParamIndices,
-            c2_blocking_t mayBlock,
-            std::vector<std::unique_ptr<C2Param>>* const heapParams) {
-        if (mLocalComp) {
-            std::shared_ptr<C2ComponentInterface> intf = mLocalComp->intf();
-            if (intf) {
-                return intf->query_vb(stackParams,
-                                      heapParamIndices,
-                                      mayBlock,
-                                      heapParams);
-            } else {
-                LOG(ERROR) << "queryFromSink -- "
-                           << "component does not have an interface.";
-                return C2_BAD_STATE;
-            }
-        }
-
-        CHECK(mSink) << "-- queryFromSink "
-                     << "-- connection has no sink.";
-        CHECK(mSinkConfigurable) << "-- queryFromSink "
-                                 << "-- sink has no configurable.";
-
-        hidl_vec<ParamIndex> indices(
-                stackParams.size() + heapParamIndices.size());
-        size_t numIndices = 0;
-        for (C2Param* const& stackParam : stackParams) {
-            if (!stackParam) {
-                LOG(DEBUG) << "queryFromSink -- null stack param encountered.";
-                continue;
-            }
-            indices[numIndices++] = static_cast<ParamIndex>(stackParam->index());
-        }
-        size_t numStackIndices = numIndices;
-        for (const C2Param::Index& index : heapParamIndices) {
-            indices[numIndices++] =
-                    static_cast<ParamIndex>(static_cast<uint32_t>(index));
-        }
-        indices.resize(numIndices);
-        if (heapParams) {
-            heapParams->reserve(heapParams->size() + numIndices);
-        }
-        c2_status_t status;
-        Return<void> transStatus = mSinkConfigurable->query(
-                indices,
-                mayBlock == C2_MAY_BLOCK,
-                [&status, &numStackIndices, &stackParams, heapParams](
-                        Status s, const Params& p) {
-                    status = static_cast<c2_status_t>(s);
-                    if (status != C2_OK && status != C2_BAD_INDEX) {
-                        LOG(DEBUG) << "queryFromSink -- call failed: "
-                                   << "status = " << asString(status) << ".";
-                        return;
-                    }
-                    std::vector<C2Param*> paramPointers;
-                    if (!parseParamsBlob(&paramPointers, p)) {
-                        LOG(DEBUG) << "queryFromSink -- error while "
-                                   << "parsing params.";
-                        status = C2_CORRUPTED;
-                        return;
-                    }
-                    size_t i = 0;
-                    for (auto it = paramPointers.begin();
-                            it != paramPointers.end(); ) {
-                        C2Param* paramPointer = *it;
-                        if (numStackIndices > 0) {
-                            --numStackIndices;
-                            if (!paramPointer) {
-                                LOG(DEBUG) << "queryFromSink -- "
-                                              "null stack param.";
-                                ++it;
-                                continue;
-                            }
-                            for (; i < stackParams.size() &&
-                                    !stackParams[i]; ) {
-                                ++i;
-                            }
-                            CHECK(i < stackParams.size());
-                            if (stackParams[i]->index() !=
-                                    paramPointer->index()) {
-                                LOG(DEBUG) << "queryFromSink -- "
-                                              "param skipped (index = "
-                                           << stackParams[i]->index() << ").";
-                                stackParams[i++]->invalidate();
-                                continue;
-                            }
-                            if (!stackParams[i++]->updateFrom(*paramPointer)) {
-                                LOG(DEBUG) << "queryFromSink -- "
-                                              "param update failed (index = "
-                                           << paramPointer->index() << ").";
-                            }
-                        } else {
-                            if (!paramPointer) {
-                                LOG(DEBUG) << "queryFromSink -- "
-                                              "null heap param.";
-                                ++it;
-                                continue;
-                            }
-                            if (!heapParams) {
-                                LOG(WARNING) << "queryFromSink -- "
-                                                "too many stack params.";
-                                break;
-                            }
-                            heapParams->emplace_back(C2Param::Copy(*paramPointer));
-                        }
-                        ++it;
-                    }
-                });
-        if (!transStatus.isOk()) {
-            LOG(ERROR) << "queryFromSink -- transaction failed.";
-            return C2_CORRUPTED;
-        }
-        return status;
-    }
-
-    c2_status_t queueToSink(std::list<std::unique_ptr<C2Work>>* const items) {
-        if (mLocalComp) {
-            return mLocalComp->queue_nb(items);
-        }
-
-        CHECK(mSink) << "-- queueToSink "
-                     << "-- connection has no sink.";
-
-        WorkBundle workBundle;
-        if (!objcpy(&workBundle, *items, nullptr)) {
-            LOG(ERROR) << "queueToSink -- bad input.";
-            return C2_CORRUPTED;
-        }
-        Return<Status> transStatus = mSink->queue(workBundle);
-        if (!transStatus.isOk()) {
-            LOG(ERROR) << "queueToSink -- transaction failed.";
-            return C2_CORRUPTED;
-        }
-        c2_status_t status =
-                static_cast<c2_status_t>(static_cast<Status>(transStatus));
-        if (status != C2_OK) {
-            LOG(DEBUG) << "queueToSink -- call failed: "
-                         << asString(status);
-        }
-        return status;
-    }
-
-    sp<GraphicBufferSource> mSource;
-    std::shared_ptr<C2Component> mLocalComp;
-    sp<IInputSink> mSink;
-    sp<IConfigurable> mSinkConfigurable;
-    std::string mSinkName;
-
-    // Needed for ComponentWrapper implementation
-    std::mutex mAllocatorMutex;
-    std::shared_ptr<C2Allocator> mAllocator;
-    std::atomic_uint64_t mFrameIndex;
-
-};
-
-InputSurfaceConnection::InputSurfaceConnection(
-        const sp<GraphicBufferSource>& source,
-        const std::shared_ptr<C2Component>& comp,
-        const std::shared_ptr<ParameterCache>& cache)
-      : mImpl{new Impl(source, comp)},
-        mConfigurable{new CachedConfigurable(
-            std::make_unique<Impl::ConfigurableIntf>(mImpl))} {
-    mConfigurable->init(cache);
-}
-
-InputSurfaceConnection::InputSurfaceConnection(
-        const sp<GraphicBufferSource>& source,
-        const sp<IInputSink>& sink,
-        const std::shared_ptr<ParameterCache>& cache)
-      : mImpl{new Impl(source, sink)},
-        mConfigurable{new CachedConfigurable(
-            std::make_unique<Impl::ConfigurableIntf>(mImpl))} {
-    mConfigurable->init(cache);
-}
-
-Return<Status> InputSurfaceConnection::disconnect() {
-    std::lock_guard<std::mutex> lock(mImplMutex);
-    mImpl = nullptr;
-    return Status::OK;
-}
-
-InputSurfaceConnection::~InputSurfaceConnection() {
-    mImpl = nullptr;
-}
-
-bool InputSurfaceConnection::init() {
-    std::lock_guard<std::mutex> lock(mImplMutex);
-    return mImpl->init();
-}
-
-Return<sp<IConfigurable>> InputSurfaceConnection::getConfigurable() {
-    return mConfigurable;
-}
-
-// Configurable interface for InputSurfaceConnection::Impl
-c2_status_t InputSurfaceConnection::Impl::ConfigurableIntf::config(
-        const std::vector<C2Param*> &params,
-        c2_blocking_t mayBlock,
-        std::vector<std::unique_ptr<C2SettingResult>> *const failures) {
-    // TODO: implement
-    (void)params;
-    (void)mayBlock;
-    (void)failures;
-    return C2_OK;
-}
-
-c2_status_t InputSurfaceConnection::Impl::ConfigurableIntf::query(
-        const std::vector<C2Param::Index> &indices,
-        c2_blocking_t mayBlock,
-        std::vector<std::unique_ptr<C2Param>> *const params) const {
-    // TODO: implement
-    (void)indices;
-    (void)mayBlock;
-    (void)params;
-    return C2_OK;
-}
-
-c2_status_t InputSurfaceConnection::Impl::ConfigurableIntf::querySupportedParams(
-        std::vector<std::shared_ptr<C2ParamDescriptor>> *const params) const {
-    // TODO: implement
-    (void)params;
-    return C2_OK;
-}
-
-c2_status_t InputSurfaceConnection::Impl::ConfigurableIntf::querySupportedValues(
-        std::vector<C2FieldSupportedValuesQuery> &fields,
-        c2_blocking_t mayBlock) const {
-    // TODO: implement
-    (void)fields;
-    (void)mayBlock;
-    return C2_OK;
-}
-
-}  // namespace utils
-}  // namespace V1_0
-}  // namespace c2
-}  // namespace media
-}  // namespace hardware
-}  // namespace android
-
diff --git a/media/codec2/hal/hidl/1.0/utils/include/codec2/hidl/1.0/InputSurface.h b/media/codec2/hal/hidl/1.0/utils/include/codec2/hidl/1.0/InputSurface.h
deleted file mode 100644
index 062dcd9d72..0000000000
--- a/media/codec2/hal/hidl/1.0/utils/include/codec2/hidl/1.0/InputSurface.h
+++ /dev/null
@@ -1,87 +0,0 @@
-/*
- * Copyright 2018 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef CODEC2_HIDL_V1_0_UTILS_INPUTSURFACE_H
-#define CODEC2_HIDL_V1_0_UTILS_INPUTSURFACE_H
-
-#include <codec2/hidl/1.0/ComponentStore.h>
-
-#include <android/hardware/graphics/bufferqueue/2.0/IGraphicBufferProducer.h>
-#include <android/hardware/media/c2/1.0/IInputSink.h>
-#include <android/hardware/media/c2/1.0/IInputSurface.h>
-#include <hidl/Status.h>
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
-
-#include <util/C2InterfaceHelper.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_0 {
-namespace utils {
-
-using ::android::hardware::hidl_handle;
-using ::android::hardware::hidl_string;
-using ::android::hardware::hidl_vec;
-using ::android::hardware::Return;
-using ::android::hardware::Void;
-using ::android::sp;
-
-struct InputSurface : public IInputSurface {
-
-    typedef ::android::hardware::graphics::bufferqueue::V2_0::
-            IGraphicBufferProducer HGraphicBufferProducer;
-
-    typedef ::android::
-            GraphicBufferSource GraphicBufferSource;
-
-    virtual Return<sp<HGraphicBufferProducer>> getGraphicBufferProducer() override;
-
-    virtual Return<sp<IConfigurable>> getConfigurable() override;
-
-    virtual Return<void> connect(
-            const sp<IInputSink>& sink,
-            connect_cb _hidl_cb) override;
-
-    InputSurface(
-            const std::shared_ptr<ParameterCache>& cache,
-            const std::shared_ptr<C2ReflectorHelper>& reflector,
-            const sp<HGraphicBufferProducer>& base,
-            const sp<GraphicBufferSource>& source);
-
-protected:
-
-    class Interface;
-    class ConfigurableIntf;
-
-    std::shared_ptr<ParameterCache> mParameterCache;
-    sp<HGraphicBufferProducer> mProducer;
-    sp<GraphicBufferSource> mSource;
-    std::shared_ptr<Interface> mIntf;
-    sp<CachedConfigurable> mConfigurable;
-
-    virtual ~InputSurface() override = default;
-};
-
-}  // namespace utils
-}  // namespace V1_0
-}  // namespace c2
-}  // namespace media
-}  // namespace hardware
-}  // namespace android
-
-#endif  // CODEC2_HIDL_V1_0_UTILS_INPUTSURFACE_H
diff --git a/media/codec2/hal/hidl/1.0/utils/include/codec2/hidl/1.0/InputSurfaceConnection.h b/media/codec2/hal/hidl/1.0/utils/include/codec2/hidl/1.0/InputSurfaceConnection.h
deleted file mode 100644
index 475ce8beb9..0000000000
--- a/media/codec2/hal/hidl/1.0/utils/include/codec2/hidl/1.0/InputSurfaceConnection.h
+++ /dev/null
@@ -1,96 +0,0 @@
-/*
- * Copyright 2018 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef CODEC2_HIDL_V1_0_UTILS_INPUTSURFACECONNECTION_H
-#define CODEC2_HIDL_V1_0_UTILS_INPUTSURFACECONNECTION_H
-
-#include <codec2/hidl/1.0/Component.h>
-#include <codec2/hidl/1.0/Configurable.h>
-
-#include <android/hardware/media/c2/1.0/IComponent.h>
-#include <android/hardware/media/c2/1.0/IConfigurable.h>
-#include <android/hardware/media/c2/1.0/IInputSurfaceConnection.h>
-
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
-
-#include <hidl/HidlSupport.h>
-#include <hidl/Status.h>
-
-#include <C2Component.h>
-
-#include <memory>
-#include <mutex>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_0 {
-namespace utils {
-
-using ::android::hardware::Return;
-using ::android::hardware::Void;
-using ::android::sp;
-using ::android::GraphicBufferSource;
-
-// An InputSurfaceConnection connects an InputSurface to a sink, which may be an
-// IInputSink or a local C2Component. This can be specified by choosing the
-// corresponding constructor. The reason for distinguishing these two cases is
-// that when an InputSurfaceConnection lives in the same process as the
-// component that processes the buffers, data parceling is not needed.
-struct InputSurfaceConnection : public IInputSurfaceConnection {
-
-    virtual Return<Status> disconnect() override;
-
-    virtual Return<sp<IConfigurable>> getConfigurable() override;
-
-protected:
-
-    InputSurfaceConnection(
-            const sp<GraphicBufferSource>& source,
-            const std::shared_ptr<C2Component>& comp,
-            const std::shared_ptr<ParameterCache>& cache);
-
-    InputSurfaceConnection(
-            const sp<GraphicBufferSource>& source,
-            const sp<IInputSink>& sink,
-            const std::shared_ptr<ParameterCache>& cache);
-
-    bool init();
-
-    friend struct InputSurface;
-
-    InputSurfaceConnection() = delete;
-    InputSurfaceConnection(const InputSurfaceConnection&) = delete;
-    void operator=(const InputSurfaceConnection&) = delete;
-
-    struct Impl;
-
-    std::mutex mImplMutex;
-    sp<Impl> mImpl;
-    sp<CachedConfigurable> mConfigurable;
-
-    virtual ~InputSurfaceConnection() override;
-};
-
-}  // namespace utils
-}  // namespace V1_0
-}  // namespace c2
-}  // namespace media
-}  // namespace hardware
-}  // namespace android
-
-#endif  // CODEC2_HIDL_V1_0_UTILS_INPUTSURFACECONNECTION_H
diff --git a/media/codec2/hal/hidl/1.0/vts/functional/video/VtsHalMediaC2V1_0TargetVideoDecTest.cpp b/media/codec2/hal/hidl/1.0/vts/functional/video/VtsHalMediaC2V1_0TargetVideoDecTest.cpp
index 239a484241..d15536a71e 100644
--- a/media/codec2/hal/hidl/1.0/vts/functional/video/VtsHalMediaC2V1_0TargetVideoDecTest.cpp
+++ b/media/codec2/hal/hidl/1.0/vts/functional/video/VtsHalMediaC2V1_0TargetVideoDecTest.cpp
@@ -32,10 +32,8 @@
 #include <codec2/common/HalSelection.h>
 #include <codec2/hidl/client.h>
 #include <com_android_graphics_libgui_flags.h>
-#include <gui/BufferQueue.h>
-#include <gui/IConsumerListener.h>
-#include <gui/IProducerListener.h>
 #include <system/window.h>
+#include <gui/BufferItemConsumer.h>
 #include <gui/GLConsumer.h>
 #include <gui/Surface.h>
 #include <gui/SurfaceComposerClient.h>
@@ -573,30 +571,10 @@ TEST_P(Codec2VideoDecHidlTest, configureTunnel) {
     using namespace android;
     sp<NativeHandle> nativeHandle = NativeHandle::create(sidebandStream, true);
 
-    sp<IGraphicBufferProducer> producer;
-    sp<IGraphicBufferConsumer> consumer;
-    BufferQueue::createBufferQueue(&producer, &consumer);
-
-    class DummyConsumerListener : public IConsumerListener {
-      public:
-        DummyConsumerListener() : IConsumerListener() {}
-        void onFrameAvailable(const BufferItem&) override {}
-        void onBuffersReleased() override {}
-        void onSidebandStreamChanged() override {}
-    };
-    consumer->consumerConnect(new DummyConsumerListener(), false);
-
-    class DummyProducerListener : public BnProducerListener {
-      public:
-        DummyProducerListener() : BnProducerListener() {}
-        virtual void onBufferReleased() override {}
-        virtual bool needsReleaseNotify() override { return false; }
-        virtual void onBuffersDiscarded(const std::vector<int32_t>&) override {}
-    };
-    IGraphicBufferProducer::QueueBufferOutput qbo{};
-    producer->connect(new DummyProducerListener(), NATIVE_WINDOW_API_MEDIA, false, &qbo);
-
-    ASSERT_EQ(producer->setSidebandStream(nativeHandle), NO_ERROR);
+    auto [consumer, surface] = BufferItemConsumer::create(GRALLOC_USAGE_SW_READ_OFTEN);
+
+    surface->connect(NATIVE_WINDOW_API_MEDIA, new StubSurfaceListener(), false);
+    surface->setSidebandStream(nativeHandle);
 }
 
 // Config output pixel format
diff --git a/media/codec2/hal/hidl/1.1/utils/Android.bp b/media/codec2/hal/hidl/1.1/utils/Android.bp
index d8b5db5374..c5d16731bd 100644
--- a/media/codec2/hal/hidl/1.1/utils/Android.bp
+++ b/media/codec2/hal/hidl/1.1/utils/Android.bp
@@ -73,8 +73,6 @@ cc_library {
         "ComponentStore.cpp",
         "Configurable.cpp",
         "InputBufferManager.cpp",
-        "InputSurface.cpp",
-        "InputSurfaceConnection.cpp",
         "types.cpp",
     ],
 
@@ -103,7 +101,6 @@ cc_library {
         "libhidlbase",
         "liblog",
         "libstagefright_bufferpool@2.0.1",
-        "libstagefright_bufferqueue_helper_novndk",
         "libui",
         "libutils",
     ],
@@ -111,11 +108,9 @@ cc_library {
     target: {
         vendor: {
             exclude_shared_libs: [
-                "libstagefright_bufferqueue_helper_novndk",
                 "libcodec2_hidl_plugin_stub",
             ],
             shared_libs: [
-                "libstagefright_bufferqueue_helper",
                 "libcodec2_hidl_plugin",
             ],
         },
diff --git a/media/codec2/hal/hidl/1.1/utils/Component.cpp b/media/codec2/hal/hidl/1.1/utils/Component.cpp
index 1c2a49a33e..7c88df42e6 100644
--- a/media/codec2/hal/hidl/1.1/utils/Component.cpp
+++ b/media/codec2/hal/hidl/1.1/utils/Component.cpp
@@ -391,17 +391,8 @@ Return<Status> Component::setOutputSurface(
 Return<void> Component::connectToInputSurface(
         const sp<IInputSurface>& inputSurface,
         connectToInputSurface_cb _hidl_cb) {
-    Status status;
-    sp<IInputSurfaceConnection> connection;
-    auto transStatus = inputSurface->connect(
-            asInputSink(),
-            [&status, &connection](
-                    Status s, const sp<IInputSurfaceConnection>& c) {
-                status = s;
-                connection = c;
-            }
-        );
-    _hidl_cb(status, connection);
+    (void)inputSurface;
+    _hidl_cb(Status::OMITTED, nullptr);
     return Void();
 }
 
diff --git a/media/codec2/hal/hidl/1.1/utils/ComponentStore.cpp b/media/codec2/hal/hidl/1.1/utils/ComponentStore.cpp
index 84f5d260bd..15f4d68b89 100644
--- a/media/codec2/hal/hidl/1.1/utils/ComponentStore.cpp
+++ b/media/codec2/hal/hidl/1.1/utils/ComponentStore.cpp
@@ -19,11 +19,9 @@
 #include <android-base/logging.h>
 
 #include <codec2/hidl/1.1/ComponentStore.h>
-#include <codec2/hidl/1.1/InputSurface.h>
 #include <codec2/hidl/1.1/types.h>
 
 #include <android-base/file.h>
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
 #include <utils/Errors.h>
 
 #include <C2PlatformSupport.h>
@@ -51,7 +49,6 @@ namespace V1_1 {
 namespace utils {
 
 using namespace ::android;
-using ::android::GraphicBufferSource;
 using namespace ::android::hardware::media::bufferpool::V2_0::implementation;
 
 namespace /* unnamed */ {
@@ -324,19 +321,7 @@ Return<void> ComponentStore::listComponents(listComponents_cb _hidl_cb) {
 }
 
 Return<void> ComponentStore::createInputSurface(createInputSurface_cb _hidl_cb) {
-    sp<GraphicBufferSource> source = new GraphicBufferSource();
-    if (source->initCheck() != OK) {
-        _hidl_cb(Status::CORRUPTED, nullptr);
-        return Void();
-    }
-    using namespace std::placeholders;
-    sp<InputSurface> inputSurface = new InputSurface(
-            mParameterCache,
-            std::make_shared<C2ReflectorHelper>(),
-            source->getHGraphicBufferProducer(),
-            source);
-    _hidl_cb(inputSurface ? Status::OK : Status::NO_MEMORY,
-             inputSurface);
+    _hidl_cb(Status::OMITTED, nullptr);
     return Void();
 }
 
diff --git a/media/codec2/hal/hidl/1.1/utils/InputSurfaceConnection.cpp b/media/codec2/hal/hidl/1.1/utils/InputSurfaceConnection.cpp
deleted file mode 100644
index 32154a7035..0000000000
--- a/media/codec2/hal/hidl/1.1/utils/InputSurfaceConnection.cpp
+++ /dev/null
@@ -1,17 +0,0 @@
-/*
- * Copyright 2019 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#include <codec2/hidl/1.1/InputSurfaceConnection.h>
diff --git a/media/codec2/hal/hidl/1.1/utils/include/codec2/hidl/1.1/InputSurface.h b/media/codec2/hal/hidl/1.1/utils/include/codec2/hidl/1.1/InputSurface.h
deleted file mode 100644
index 59223b71f5..0000000000
--- a/media/codec2/hal/hidl/1.1/utils/include/codec2/hidl/1.1/InputSurface.h
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright 2019 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef CODEC2_HIDL_V1_1_UTILS_INPUT_SURFACE_H
-#define CODEC2_HIDL_V1_1_UTILS_INPUT_SURFACE_H
-
-#include <codec2/hidl/1.0/InputSurface.h>
-#include <codec2/hidl/1.1/types.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_1 {
-namespace utils {
-
-using ::android::hardware::media::c2::V1_0::utils::InputSurface;
-
-} // namespace utils
-} // namespace V1_1
-} // namespace c2
-} // namespace media
-} // namespace hardware
-} // namespace android
-
-#endif // CODEC2_HIDL_V1_1_UTILS_INPUT_SURFACE_H
diff --git a/media/codec2/hal/hidl/1.1/utils/include/codec2/hidl/1.1/InputSurfaceConnection.h b/media/codec2/hal/hidl/1.1/utils/include/codec2/hidl/1.1/InputSurfaceConnection.h
deleted file mode 100644
index 7f695ef33e..0000000000
--- a/media/codec2/hal/hidl/1.1/utils/include/codec2/hidl/1.1/InputSurfaceConnection.h
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright 2019 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef CODEC2_HIDL_V1_1_UTILS_INPUT_SURFACE_CONNECTION_H
-#define CODEC2_HIDL_V1_1_UTILS_INPUT_SURFACE_CONNECTION_H
-
-#include <codec2/hidl/1.0/InputSurfaceConnection.h>
-#include <codec2/hidl/1.1/types.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_1 {
-namespace utils {
-
-using ::android::hardware::media::c2::V1_0::utils::InputSurfaceConnection;
-
-} // namespace utils
-} // namespace V1_1
-} // namespace c2
-} // namespace media
-} // namespace hardware
-} // namespace android
-
-#endif // CODEC2_HIDL_V1_1_UTILS_INPUT_SURFACE_CONNECTION_H
diff --git a/media/codec2/hal/hidl/1.2/utils/Android.bp b/media/codec2/hal/hidl/1.2/utils/Android.bp
index a3399460d2..2cd58f7acd 100644
--- a/media/codec2/hal/hidl/1.2/utils/Android.bp
+++ b/media/codec2/hal/hidl/1.2/utils/Android.bp
@@ -78,8 +78,6 @@ cc_library {
         "ComponentStore.cpp",
         "Configurable.cpp",
         "InputBufferManager.cpp",
-        "InputSurface.cpp",
-        "InputSurfaceConnection.cpp",
         "types.cpp",
     ],
 
@@ -110,7 +108,6 @@ cc_library {
         "libhidlbase",
         "liblog",
         "libstagefright_bufferpool@2.0.1",
-        "libstagefright_bufferqueue_helper_novndk",
         "libui",
         "libutils",
     ],
@@ -118,11 +115,9 @@ cc_library {
     target: {
         vendor: {
             exclude_shared_libs: [
-                "libstagefright_bufferqueue_helper_novndk",
                 "libcodec2_hidl_plugin_stub",
             ],
             shared_libs: [
-                "libstagefright_bufferqueue_helper",
                 "libcodec2_hidl_plugin",
             ],
         },
diff --git a/media/codec2/hal/hidl/1.2/utils/Component.cpp b/media/codec2/hal/hidl/1.2/utils/Component.cpp
index a15febed85..376a26f631 100644
--- a/media/codec2/hal/hidl/1.2/utils/Component.cpp
+++ b/media/codec2/hal/hidl/1.2/utils/Component.cpp
@@ -387,17 +387,8 @@ Return<Status> Component::setOutputSurface(
 Return<void> Component::connectToInputSurface(
         const sp<IInputSurface>& inputSurface,
         connectToInputSurface_cb _hidl_cb) {
-    Status status;
-    sp<IInputSurfaceConnection> connection;
-    auto transStatus = inputSurface->connect(
-            asInputSink(),
-            [&status, &connection](
-                    Status s, const sp<IInputSurfaceConnection>& c) {
-                status = s;
-                connection = c;
-            }
-        );
-    _hidl_cb(status, connection);
+    (void)inputSurface;
+    _hidl_cb(Status::OMITTED, nullptr);
     return Void();
 }
 
diff --git a/media/codec2/hal/hidl/1.2/utils/ComponentStore.cpp b/media/codec2/hal/hidl/1.2/utils/ComponentStore.cpp
index 5585be8c6a..aa49819185 100644
--- a/media/codec2/hal/hidl/1.2/utils/ComponentStore.cpp
+++ b/media/codec2/hal/hidl/1.2/utils/ComponentStore.cpp
@@ -19,11 +19,9 @@
 #include <android-base/logging.h>
 
 #include <codec2/hidl/1.2/ComponentStore.h>
-#include <codec2/hidl/1.2/InputSurface.h>
 #include <codec2/hidl/1.2/types.h>
 
 #include <android-base/file.h>
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
 #include <utils/Errors.h>
 
 #include <C2PlatformSupport.h>
@@ -51,7 +49,6 @@ namespace V1_2 {
 namespace utils {
 
 using namespace ::android;
-using ::android::GraphicBufferSource;
 using namespace ::android::hardware::media::bufferpool::V2_0::implementation;
 
 namespace /* unnamed */ {
@@ -323,19 +320,7 @@ Return<void> ComponentStore::listComponents(listComponents_cb _hidl_cb) {
 }
 
 Return<void> ComponentStore::createInputSurface(createInputSurface_cb _hidl_cb) {
-    sp<GraphicBufferSource> source = new GraphicBufferSource();
-    if (source->initCheck() != OK) {
-        _hidl_cb(Status::CORRUPTED, nullptr);
-        return Void();
-    }
-    using namespace std::placeholders;
-    sp<InputSurface> inputSurface = new InputSurface(
-            mParameterCache,
-            std::make_shared<C2ReflectorHelper>(),
-            source->getHGraphicBufferProducer(),
-            source);
-    _hidl_cb(inputSurface ? Status::OK : Status::NO_MEMORY,
-             inputSurface);
+    _hidl_cb(Status::OMITTED, nullptr);
     return Void();
 }
 
diff --git a/media/codec2/hal/hidl/1.2/utils/InputSurface.cpp b/media/codec2/hal/hidl/1.2/utils/InputSurface.cpp
deleted file mode 100644
index 7c4d28b76d..0000000000
--- a/media/codec2/hal/hidl/1.2/utils/InputSurface.cpp
+++ /dev/null
@@ -1,17 +0,0 @@
-/*
- * Copyright 2021 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#include <codec2/hidl/1.2/InputSurface.h>
diff --git a/media/codec2/hal/hidl/1.2/utils/include/codec2/hidl/1.2/InputSurface.h b/media/codec2/hal/hidl/1.2/utils/include/codec2/hidl/1.2/InputSurface.h
deleted file mode 100644
index 3fae86b4fd..0000000000
--- a/media/codec2/hal/hidl/1.2/utils/include/codec2/hidl/1.2/InputSurface.h
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright 2021 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef CODEC2_HIDL_V1_2_UTILS_INPUT_SURFACE_H
-#define CODEC2_HIDL_V1_2_UTILS_INPUT_SURFACE_H
-
-#include <codec2/hidl/1.0/InputSurface.h>
-#include <codec2/hidl/1.2/types.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_2 {
-namespace utils {
-
-using ::android::hardware::media::c2::V1_0::utils::InputSurface;
-
-} // namespace utils
-} // namespace V1_2
-} // namespace c2
-} // namespace media
-} // namespace hardware
-} // namespace android
-
-#endif // CODEC2_HIDL_V1_2_UTILS_INPUT_SURFACE_H
diff --git a/media/codec2/hal/hidl/1.2/utils/include/codec2/hidl/1.2/InputSurfaceConnection.h b/media/codec2/hal/hidl/1.2/utils/include/codec2/hidl/1.2/InputSurfaceConnection.h
deleted file mode 100644
index 13a8a61845..0000000000
--- a/media/codec2/hal/hidl/1.2/utils/include/codec2/hidl/1.2/InputSurfaceConnection.h
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright 2021 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef CODEC2_HIDL_V1_2_UTILS_INPUT_SURFACE_CONNECTION_H
-#define CODEC2_HIDL_V1_2_UTILS_INPUT_SURFACE_CONNECTION_H
-
-#include <codec2/hidl/1.0/InputSurfaceConnection.h>
-#include <codec2/hidl/1.2/types.h>
-
-namespace android {
-namespace hardware {
-namespace media {
-namespace c2 {
-namespace V1_2 {
-namespace utils {
-
-using ::android::hardware::media::c2::V1_0::utils::InputSurfaceConnection;
-
-} // namespace utils
-} // namespace V1_2
-} // namespace c2
-} // namespace media
-} // namespace hardware
-} // namespace android
-
-#endif // CODEC2_HIDL_V1_2_UTILS_INPUT_SURFACE_CONNECTION_H
diff --git a/media/codec2/sfplugin/Android.bp b/media/codec2/sfplugin/Android.bp
index 489857df53..69d4638409 100644
--- a/media/codec2/sfplugin/Android.bp
+++ b/media/codec2/sfplugin/Android.bp
@@ -84,7 +84,6 @@ cc_library_shared {
         "libstagefright_codecbase",
         "libstagefright_graphicbuffersource_aidl",
         "libstagefright_foundation",
-        "libstagefright_omx",
         "libstagefright_surface_utils",
         "libstagefright_xmlparser",
         "libui",
diff --git a/media/codec2/sfplugin/CCodec.cpp b/media/codec2/sfplugin/CCodec.cpp
index 99f0f53b9a..40d06143fd 100644
--- a/media/codec2/sfplugin/CCodec.cpp
+++ b/media/codec2/sfplugin/CCodec.cpp
@@ -52,8 +52,6 @@
 #include <media/stagefright/aidlpersistentsurface/C2NodeDef.h>
 #include <media/stagefright/aidlpersistentsurface/wrapper/Conversion.h>
 #include <media/stagefright/aidlpersistentsurface/wrapper/WAidlGraphicBufferSource.h>
-#include <media/stagefright/omx/1.0/WGraphicBufferSource.h>
-#include <media/stagefright/omx/OmxGraphicBufferSource.h>
 #include <media/stagefright/CCodec.h>
 #include <media/stagefright/BufferProducerWrapper.h>
 #include <media/stagefright/CCodecResources.h>
@@ -167,8 +165,14 @@ private:
 class C2InputSurfaceWrapper : public InputSurfaceWrapper {
 public:
     explicit C2InputSurfaceWrapper(
-            const std::shared_ptr<Codec2Client::InputSurface> &surface) :
-        mSurface(surface) {
+            const std::shared_ptr<Codec2Client::InputSurface> &surface,
+            uint32_t width,
+            uint32_t height,
+            uint64_t usage)
+        : mSurface(surface), mWidth(width), mHeight(height), mInputDoneCount(0) {
+        // Configurations are not passed until connect().
+        mDataSpace = HAL_DATASPACE_BT709;
+        mConfig.mUsage = usage;
     }
 
     ~C2InputSurfaceWrapper() override = default;
@@ -177,39 +181,228 @@ public:
         if (mConnection != nullptr) {
             return ALREADY_EXISTS;
         }
-        return toStatusT(comp->connectToInputSurface(mSurface, &mConnection));
+        std::vector<std::unique_ptr<C2SettingResult>> failures;
+
+        C2StreamBlockSizeInfo::output blockSize{0u, mWidth, mHeight};
+        C2StreamBlockCountInfo::output blockCount{0u, getInputBufferCount(comp)};
+        C2StreamUsageTuning::output usage{0u, mConfig.mUsage};
+        C2StreamDataSpaceInfo::output dataspace{0u, mDataSpace};
+        c2_status_t err = mSurface->config(
+                {&blockSize, &blockCount, &usage, &dataspace}, C2_MAY_BLOCK, &failures);
+        if (err != C2_OK && err != C2_BAD_INDEX) {
+            ALOGE("InputSurface configuration failure on connect(): %d", err);
+            return UNKNOWN_ERROR;
+        }
+        return mSurface->connect(comp, &mConnection);
     }
 
     void disconnect() override {
-        if (mConnection != nullptr) {
+        if (mConnection) {
             mConnection->disconnect();
-            mConnection = nullptr;
+            mConnection.reset();
         }
+        mInputDoneCount = 0;
+        mInputEmptyCount = 0;
     }
 
     status_t start() override {
-        // InputSurface does not distinguish started state
+        // InputSurface starts when connect().
+        // no-op here.
         return OK;
     }
 
     status_t signalEndOfInputStream() override {
-        C2InputSurfaceEosTuning eos(true);
+        if (mConnection) {
+            if (mConnection->signalEos() != C2_OK) {
+                return UNKNOWN_ERROR;
+            }
+        }
+        return OK;
+    }
+
+    status_t configure(Config &config) {
+        std::vector<C2Param*> params;
         std::vector<std::unique_ptr<C2SettingResult>> failures;
-        c2_status_t err = mSurface->config({&eos}, C2_MAY_BLOCK, &failures);
+
+        std::shared_ptr<C2PortMinFrameRateTuning::output> minFps;
+        std::shared_ptr<C2PortMaxFrameRateTuning::output> maxFps;
+        std::shared_ptr<C2PortCaptureFrameRateTuning::output> captureFps;
+        std::shared_ptr<C2StreamFrameRateInfo::output> codedFps;
+        std::shared_ptr<C2ComponentTimeOffsetTuning> timeOffset;
+        std::shared_ptr<C2PortSuspendTimestampTuning::output> suspended;
+        std::shared_ptr<C2PortResumeTimestampTuning::output> resumed;
+        std::shared_ptr<C2PortStartTimestampTuning::output> started;
+        std::shared_ptr<C2PortStopTimestampTuning::output> stopped;
+        std::shared_ptr<C2PortTimestampGapTuning::output> gap;
+
+        if (config.mMinFps > 0 && config.mMinFps != mConfig.mMinFps) {
+            minFps = std::make_shared<C2PortMinFrameRateTuning::output>(config.mMinFps);
+            params.push_back(minFps.get());
+            mConfig.mMinFps = config.mMinFps;
+        }
+        bool fixedFpsMode = false;
+        if (config.mMinAdjustedFps > 0 || config.mFixedAdjustedFps > 0) {
+            if (config.mMinAdjustedFps > 0) {
+                float minGap = c2_min(INT32_MAX + 0., 1e6 / config.mMinAdjustedFps + 0.5);
+                uint64_t gapUs = int32_t(minGap);
+                gap = std::make_shared<C2PortTimestampGapTuning::output>(
+                        C2TimestampGapAdjustmentStruct::MIN_GAP, gapUs);
+                params.push_back(gap.get());
+                mConfig.mMinAdjustedFps = config.mMinAdjustedFps;
+            } else {
+                bool fixedFpsMode = true;
+                float fixedGap = c2_max(0. - INT32_MAX, -1e6 / config.mFixedAdjustedFps - 0.5);
+                uint64_t gapUs = int32_t(fixedGap);
+                gap = std::make_shared<C2PortTimestampGapTuning::output>(
+                        C2TimestampGapAdjustmentStruct::FIXED_GAP, gapUs);
+                params.push_back(gap.get());
+                mConfig.mFixedAdjustedFps = config.mFixedAdjustedFps;
+            }
+        }
+        if ((config.mMaxFps > 0 || (fixedFpsMode && config.mMaxFps == -1))
+                && config.mMaxFps != mConfig.mMaxFps) {
+            maxFps = std::make_shared<C2PortMaxFrameRateTuning::output>(config.mMaxFps);
+            params.push_back(maxFps.get());
+            mConfig.mMaxFps = config.mMaxFps;
+        }
+        if (config.mTimeOffsetUs != mConfig.mTimeOffsetUs) {
+            timeOffset = std::make_shared<C2ComponentTimeOffsetTuning>(config.mTimeOffsetUs);
+            params.push_back(timeOffset.get());
+            mConfig.mTimeOffsetUs = config.mTimeOffsetUs;
+        }
+        if (config.mCaptureFps != mConfig.mCaptureFps || config.mCodedFps != mConfig.mCodedFps) {
+            captureFps = std::make_shared<C2PortCaptureFrameRateTuning::output>(
+                    config.mCaptureFps);
+            codedFps = std::make_shared<C2StreamFrameRateInfo::output>(0u, config.mCodedFps);
+            params.push_back(captureFps.get());
+            params.push_back(codedFps.get());
+            mConfig.mCaptureFps = config.mCaptureFps;
+            mConfig.mCodedFps = config.mCodedFps;
+        }
+
+        if (config.mStartAtUs != mConfig.mStartAtUs
+                || (config.mStopped != mConfig.mStopped && !config.mStopped)) {
+            started = std::make_shared<C2PortStartTimestampTuning::output>(config.mStartAtUs);
+            stopped = std::make_shared<C2PortStopTimestampTuning::output>();
+            params.push_back(started.get());
+            params.push_back(stopped.get());
+            mConfig.mStartAtUs = config.mStartAtUs;
+            mConfig.mStopped = config.mStopped;
+        }
+        if (config.mSuspended != mConfig.mSuspended) {
+            if (config.mSuspended) {
+                suspended = std::make_shared<C2PortSuspendTimestampTuning::output>(
+                        mConfig.mSuspendAtUs);
+                resumed = std::make_shared<C2PortResumeTimestampTuning::output>();
+            } else {
+                suspended = std::make_shared<C2PortSuspendTimestampTuning::output>();
+                resumed = std::make_shared<C2PortResumeTimestampTuning::output>(
+                        config.mSuspendAtUs);
+            }
+            params.push_back(suspended.get());
+            params.push_back(resumed.get());
+            mConfig.mSuspended = config.mSuspended;
+            mConfig.mSuspendAtUs = config.mSuspendAtUs;
+        }
+        if (config.mStopped != mConfig.mStopped && config.mStopped) {
+            started = std::make_shared<C2PortStartTimestampTuning::output>();
+            stopped = std::make_shared<C2PortStopTimestampTuning::output>(config.mStopAtUs);
+            params.push_back(started.get());
+            params.push_back(stopped.get());
+            mConfig.mStopAtUs = config.mStopAtUs;
+            mConfig.mStopped = config.mStopped;
+        }
+        c2_status_t err = mSurface->config(params, C2_MAY_BLOCK, &failures);
         if (err != C2_OK) {
+            ALOGE("C2InputSurfaceWrapper::config err(%d)", err);
             return UNKNOWN_ERROR;
         }
         return OK;
     }
 
-    status_t configure(Config &config __unused) {
+    // TODO: optimize binder calls of onInputBufferDone()
+    // current: HAL --> client --> HAL
+    void onInputBufferDone(c2_cntr64_t index) override {
+        mInputDoneCount++;
+        C2PortConfigCounterTuning::output inputDone{index.peekull()};
+        C2StreamLayerCountInfo::input inputDoneCount{0u, mInputDoneCount};
+        std::vector<std::unique_ptr<C2SettingResult>> failures;
+
+        c2_status_t err = mSurface->config(
+                {&inputDone, &inputDoneCount}, C2_MAY_BLOCK, &failures);
+
+        if (err != C2_OK) {
+            ALOGE("C2InputSurfaceWrapper::onInputBufferDone err(%d) - %llu",
+                    err, index.peekull());
+        }
+    }
+
+    // TODO: optimize binder calls of onInputBufferEmptied()
+    // current: HAL --> client --> HAL
+    void onInputBufferEmptied() override {
+        mInputEmptyCount++;
+        C2StreamLayerCountInfo::output inputEmptyCount{0u, mInputEmptyCount};
+        std::vector<std::unique_ptr<C2SettingResult>> failures;
+
+        c2_status_t err = mSurface->config({&inputEmptyCount}, C2_MAY_BLOCK, &failures);
+
+        if (err != C2_OK) {
+            ALOGE("C2InputSurfaceWrapper::onInputBufferEmptried err(%d)", err);
+        }
+    }
+
+    android_dataspace getDataspace() override {
         // TODO
-        return OK;
+        return static_cast<android_dataspace>(0);
+    }
+
+    uint32_t getPixelFormat() override {
+        // TODO
+        return 0;
     }
 
 private:
+    int getInputBufferCount(
+            const std::shared_ptr<Codec2Client::Component> &comp) {
+        const static int kDefaultInputBufferCount = 16;
+        const static int kDefaultInputBufferMargin = 4;
+
+        // WORKAROUND: having more slots improve performance while consuming
+        // more memory. This is a temporary workaround to reduce memory for
+        // larger-than-4K scenario.
+        //
+        // NOTE: this optimization may not work on Persistent InputSurface since
+        // AImageReader cannot re-configure buffer count after creation.
+        if (mWidth * mHeight > 4096 * 2340) {
+            C2PortActualDelayTuning::input inputDelay(0);
+            C2ActualPipelineDelayTuning pipelineDelay(0);
+            c2_status_t c2Err = C2_NOT_FOUND;
+            if (comp) {
+                c2Err = comp->query(
+                        {&inputDelay, &pipelineDelay}, {}, C2_DONT_BLOCK, nullptr);
+                if (c2Err == C2_OK || c2Err == C2_BAD_INDEX) {
+                    int bufferCount = kDefaultInputBufferMargin;
+                    if (inputDelay) {
+                        bufferCount += inputDelay.value;
+                    }
+                    if (pipelineDelay) {
+                        bufferCount += pipelineDelay.value;
+                    }
+                    ALOGD("InputSurface InputBuffer Count adjusted to %d", bufferCount);
+                    return bufferCount;
+                }
+            }
+        }
+        return kDefaultInputBufferCount;
+    }
+
     std::shared_ptr<Codec2Client::InputSurface> mSurface;
     std::shared_ptr<Codec2Client::InputSurfaceConnection> mConnection;
+    uint32_t mWidth;
+    uint32_t mHeight;
+    uint32_t mInputDoneCount;
+    uint32_t mInputEmptyCount;
+    Config mConfig;
 };
 
 class HGraphicBufferSourceWrapper : public InputSurfaceWrapper {
@@ -1978,13 +2171,7 @@ void CCodec::createInputSurface() {
         sp<IInputSurface> hidlInputSurface = IInputSurface::castFrom(hidlTarget);
         sp<HGraphicBufferSource> gbs = HGraphicBufferSource::castFrom(hidlTarget);
 
-        if (hidlInputSurface) {
-            std::shared_ptr<Codec2Client::InputSurface> inputSurface =
-                    std::make_shared<Codec2Client::InputSurface>(hidlInputSurface);
-            err = setupInputSurface(std::make_shared<C2InputSurfaceWrapper>(
-                    inputSurface));
-            bufferProducer = inputSurface->getGraphicBufferProducer();
-        } else if (gbs) {
+        if (gbs) {
             int32_t width = 0;
             (void)outputFormat->findInt32("width", &width);
             int32_t height = 0;
@@ -2116,15 +2303,7 @@ void CCodec::setInputSurface(const sp<PersistentSurface> &surface) {
         sp<hidl::base::V1_0::IBase> hidlTarget = surface->getHidlTarget();
         sp<IInputSurface> inputSurface = IInputSurface::castFrom(hidlTarget);
         sp<HGraphicBufferSource> gbs = HGraphicBufferSource::castFrom(hidlTarget);
-        if (inputSurface) {
-            status_t err = setupInputSurface(std::make_shared<C2InputSurfaceWrapper>(
-                    std::make_shared<Codec2Client::InputSurface>(inputSurface)));
-            if (err != OK) {
-                ALOGE("Failed to set up input surface: %d", err);
-                mCallback->onInputSurfaceDeclined(err);
-                return;
-            }
-        } else if (gbs) {
+        if (gbs) {
             int32_t width = 0;
             (void)outputFormat->findInt32("width", &width);
             int32_t height = 0;
@@ -3137,46 +3316,23 @@ void CCodec::initiateReleaseIfStuck() {
 // static
 PersistentSurface *CCodec::CreateInputSurface() {
     using namespace android;
-    using ::android::hardware::media::omx::V1_0::implementation::TWGraphicBufferSource;
-    // Attempt to create a Codec2's input surface.
-    std::shared_ptr<Codec2Client::InputSurface> inputSurface =
-            Codec2Client::CreateInputSurface();
-    if (!inputSurface) {
-        if (property_get_int32("debug.stagefright.c2inputsurface", 0) == -1) {
-            if (Codec2Client::IsAidlSelected()) {
-                sp<IGraphicBufferProducer> gbp;
-                sp<AidlGraphicBufferSource> gbs = new AidlGraphicBufferSource();
-                status_t err = gbs->initCheck();
-                if (err != OK) {
-                    ALOGE("Failed to create persistent input surface: error %d", err);
-                    return nullptr;
-                }
-                ALOGD("aidl based PersistentSurface created");
-                std::shared_ptr<WAidlGraphicBufferSource> wrapper =
-                        ::ndk::SharedRefBase::make<WAidlGraphicBufferSource>(gbs);
-
-                return new PersistentSurface(
-                      gbs->getIGraphicBufferProducer(), wrapper->asBinder());
-            } else {
-                sp<IGraphicBufferProducer> gbp;
-                sp<OmxGraphicBufferSource> gbs = new OmxGraphicBufferSource();
-                status_t err = gbs->initCheck();
-                if (err != OK) {
-                    ALOGE("Failed to create persistent input surface: error %d", err);
-                    return nullptr;
-                }
-                ALOGD("hidl based PersistentSurface created");
-                return new PersistentSurface(
-                        gbs->getIGraphicBufferProducer(), new TWGraphicBufferSource(gbs));
-            }
-        } else {
+    if (property_get_int32("debug.stagefright.c2inputsurface", 0) == -1) {
+        sp<IGraphicBufferProducer> gbp;
+        sp<AidlGraphicBufferSource> gbs = new AidlGraphicBufferSource();
+        status_t err = gbs->initCheck();
+        if (err != OK) {
+            ALOGE("Failed to create persistent input surface: error %d", err);
             return nullptr;
         }
+        ALOGD("aidl based PersistentSurface created");
+        std::shared_ptr<WAidlGraphicBufferSource> wrapper =
+                ::ndk::SharedRefBase::make<WAidlGraphicBufferSource>(gbs);
+
+        return new PersistentSurface(
+              gbs->getIGraphicBufferProducer(), wrapper->asBinder());
+    } else {
+        return nullptr;
     }
-    return new PersistentSurface(
-            inputSurface->getGraphicBufferProducer(),
-            static_cast<sp<android::hidl::base::V1_0::IBase>>(
-            inputSurface->getHalInterface()));
 }
 
 class IntfCache {
diff --git a/media/codec2/sfplugin/CCodecBufferChannel.cpp b/media/codec2/sfplugin/CCodecBufferChannel.cpp
index 66a9adfdb2..54a5b0d07c 100644
--- a/media/codec2/sfplugin/CCodecBufferChannel.cpp
+++ b/media/codec2/sfplugin/CCodecBufferChannel.cpp
@@ -2088,11 +2088,14 @@ status_t CCodecBufferChannel::start(
         }
 
         if (oStreamFormat.value == C2BufferData::LINEAR) {
-            if (buffersBoundToCodec) {
-                // WORKAROUND: if we're using early CSD workaround we convert to
-                //             array mode, to appease apps assuming the output
-                //             buffers to be of the same size.
-                output->buffers = output->buffers->toArrayMode(numOutputSlots);
+            if (android::media::codec::provider_->remove_arraymode_for_linear_output_buffers() ==
+                    false) {
+                if (buffersBoundToCodec) {
+                    // WORKAROUND: if we're using early CSD workaround we convert to
+                    //             array mode, to appease apps assuming the output
+                    //             buffers to be of the same size.
+                    output->buffers = output->buffers->toArrayMode(numOutputSlots);
+                }
             }
 
             int32_t channelCount;
diff --git a/media/codec2/sfplugin/CCodecConfig.cpp b/media/codec2/sfplugin/CCodecConfig.cpp
index 119658a595..baaf1120c5 100644
--- a/media/codec2/sfplugin/CCodecConfig.cpp
+++ b/media/codec2/sfplugin/CCodecConfig.cpp
@@ -957,7 +957,7 @@ void CCodecConfig::initializeStandardParams() {
         .limitTo(D::AUDIO & (D::CONFIG | D::PARAM | D::READ)));
 
     add(ConfigMapper(KEY_CHANNEL_MASK, C2_PARAMKEY_CHANNEL_MASK, "value")
-        .limitTo(D::AUDIO & D::DECODER & D::READ));
+        .limitTo(D::AUDIO & D::DECODER & (D::CONFIG | D::PARAM | D::READ)));
 
     add(ConfigMapper(KEY_CHANNEL_MASK, C2_PARAMKEY_CHANNEL_MASK, "value")
         .limitTo(D::AUDIO & D::ENCODER & D::CONFIG));
@@ -1053,6 +1053,9 @@ void CCodecConfig::initializeStandardParams() {
                     .limitTo(D::VIDEO & D::RAW & D::DECODER));
     }
 
+    add(ConfigMapper(KEY_AUDIO_PRESENTATION_ID, C2_PARAMKEY_AUDIO_PRESENTATION_ID, "value")
+                .limitTo(D::AUDIO & D::DECODER & (D::CONFIG | D::PARAM | D::READ)));
+
     /* still to do
        not yet used by MediaCodec, but defined as MediaFormat
     KEY_AUDIO_SESSION_ID // we use "audio-hw-sync"
diff --git a/media/codec2/sfplugin/Codec2InfoBuilder.cpp b/media/codec2/sfplugin/Codec2InfoBuilder.cpp
index 0f5cdd6590..25c2f6ffac 100644
--- a/media/codec2/sfplugin/Codec2InfoBuilder.cpp
+++ b/media/codec2/sfplugin/Codec2InfoBuilder.cpp
@@ -52,7 +52,6 @@
 #include <media/omx/1.0/WOmxNode.h>
 #include <media/stagefright/foundation/ALookup.h>
 #include <media/stagefright/foundation/MediaDefs.h>
-#include <media/stagefright/omx/OMXUtils.h>
 #include <media/stagefright/xmlparser/MediaCodecsXmlParser.h>
 #include <media/stagefright/Codec2InfoBuilder.h>
 #include <media/stagefright/MediaCodecConstants.h>
diff --git a/media/codec2/sfplugin/Omx2IGraphicBufferSource.cpp b/media/codec2/sfplugin/Omx2IGraphicBufferSource.cpp
deleted file mode 100644
index 764fa001ec..0000000000
--- a/media/codec2/sfplugin/Omx2IGraphicBufferSource.cpp
+++ /dev/null
@@ -1,185 +0,0 @@
-/*
- * Copyright 2019 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifdef __LP64__
-#define OMX_ANDROID_COMPILE_AS_32BIT_ON_64BIT_PLATFORMS
-#endif
-
-//#define LOG_NDEBUG 0
-#define LOG_TAG "Omx2IGraphicBufferSource"
-#include <android-base/logging.h>
-
-#include "Omx2IGraphicBufferSource.h"
-
-#include <android/BnOMXBufferSource.h>
-#include <media/OMXBuffer.h>
-#include <media/stagefright/omx/OMXUtils.h>
-
-#include <OMX_Component.h>
-#include <OMX_Index.h>
-#include <OMX_IndexExt.h>
-
-namespace android {
-
-namespace /* unnamed */ {
-
-// OmxGraphicBufferSource -> IOMXBufferSource
-
-struct OmxGbs2IOmxBs : public BnOMXBufferSource {
-    sp<OmxGraphicBufferSource> mBase;
-    OmxGbs2IOmxBs(sp<OmxGraphicBufferSource> const& base) : mBase{base} {}
-    BnStatus onOmxExecuting() override {
-        return mBase->onOmxExecuting();
-    }
-    BnStatus onOmxIdle() override {
-        return mBase->onOmxIdle();
-    }
-    BnStatus onOmxLoaded() override {
-        return mBase->onOmxLoaded();
-    }
-    BnStatus onInputBufferAdded(int32_t bufferId) override {
-        return mBase->onInputBufferAdded(bufferId);
-    }
-    BnStatus onInputBufferEmptied(
-            int32_t bufferId,
-            OMXFenceParcelable const& fenceParcel) override {
-        return mBase->onInputBufferEmptied(bufferId, fenceParcel.get());
-    }
-};
-
-struct OmxNodeWrapper : public IOmxNodeWrapper {
-    sp<IOMXNode> mBase;
-    OmxNodeWrapper(sp<IOMXNode> const& base) : mBase{base} {}
-    status_t emptyBuffer(
-            int32_t bufferId, uint32_t flags,
-            const sp<GraphicBuffer> &buffer,
-            int64_t timestamp, int fenceFd) override {
-        return mBase->emptyBuffer(bufferId, buffer, flags, timestamp, fenceFd);
-    }
-    void dispatchDataSpaceChanged(
-            int32_t dataSpace, int32_t aspects, int32_t pixelFormat) override {
-        omx_message msg{};
-        msg.type = omx_message::EVENT;
-        msg.fenceFd = -1;
-        msg.u.event_data.event = OMX_EventDataSpaceChanged;
-        msg.u.event_data.data1 = dataSpace;
-        msg.u.event_data.data2 = aspects;
-        msg.u.event_data.data3 = pixelFormat;
-        mBase->dispatchMessage(msg);
-    }
-};
-
-} // unnamed namespace
-
-// Omx2IGraphicBufferSource
-Omx2IGraphicBufferSource::Omx2IGraphicBufferSource(
-        sp<OmxGraphicBufferSource> const& base)
-      : mBase{base},
-        mOMXBufferSource{new OmxGbs2IOmxBs(base)} {
-}
-
-BnStatus Omx2IGraphicBufferSource::setSuspend(
-        bool suspend, int64_t timeUs) {
-    return BnStatus::fromStatusT(mBase->setSuspend(suspend, timeUs));
-}
-
-BnStatus Omx2IGraphicBufferSource::setRepeatPreviousFrameDelayUs(
-        int64_t repeatAfterUs) {
-    return BnStatus::fromStatusT(mBase->setRepeatPreviousFrameDelayUs(repeatAfterUs));
-}
-
-BnStatus Omx2IGraphicBufferSource::setMaxFps(float maxFps) {
-    return BnStatus::fromStatusT(mBase->setMaxFps(maxFps));
-}
-
-BnStatus Omx2IGraphicBufferSource::setTimeLapseConfig(
-        double fps, double captureFps) {
-    return BnStatus::fromStatusT(mBase->setTimeLapseConfig(fps, captureFps));
-}
-
-BnStatus Omx2IGraphicBufferSource::setStartTimeUs(
-        int64_t startTimeUs) {
-    return BnStatus::fromStatusT(mBase->setStartTimeUs(startTimeUs));
-}
-
-BnStatus Omx2IGraphicBufferSource::setStopTimeUs(
-        int64_t stopTimeUs) {
-    return BnStatus::fromStatusT(mBase->setStopTimeUs(stopTimeUs));
-}
-
-BnStatus Omx2IGraphicBufferSource::getStopTimeOffsetUs(
-        int64_t *stopTimeOffsetUs) {
-    return BnStatus::fromStatusT(mBase->getStopTimeOffsetUs(stopTimeOffsetUs));
-}
-
-BnStatus Omx2IGraphicBufferSource::setColorAspects(
-        int32_t aspects) {
-    return BnStatus::fromStatusT(mBase->setColorAspects(aspects));
-}
-
-BnStatus Omx2IGraphicBufferSource::setTimeOffsetUs(
-        int64_t timeOffsetsUs) {
-    return BnStatus::fromStatusT(mBase->setTimeOffsetUs(timeOffsetsUs));
-}
-
-BnStatus Omx2IGraphicBufferSource::signalEndOfInputStream() {
-    return BnStatus::fromStatusT(mBase->signalEndOfInputStream());
-}
-
-BnStatus Omx2IGraphicBufferSource::configure(
-        const sp<IOMXNode>& omxNode, int32_t dataSpace) {
-    if (omxNode == NULL) {
-        return BnStatus::fromServiceSpecificError(BAD_VALUE);
-    }
-
-    // Do setInputSurface() first, the node will try to enable metadata
-    // mode on input, and does necessary error checking. If this fails,
-    // we can't use this input surface on the node.
-    status_t err = omxNode->setInputSurface(mOMXBufferSource);
-    if (err != NO_ERROR) {
-        ALOGE("Unable to set input surface: %d", err);
-        return BnStatus::fromServiceSpecificError(err);
-    }
-
-    uint32_t consumerUsage;
-    if (omxNode->getParameter(
-            (OMX_INDEXTYPE)OMX_IndexParamConsumerUsageBits,
-            &consumerUsage, sizeof(consumerUsage)) != OK) {
-        consumerUsage = 0;
-    }
-
-    OMX_PARAM_PORTDEFINITIONTYPE def;
-    InitOMXParams(&def);
-    def.nPortIndex = 0; // kPortIndexInput
-
-    err = omxNode->getParameter(
-            OMX_IndexParamPortDefinition, &def, sizeof(def));
-    if (err != NO_ERROR) {
-        ALOGE("Failed to get port definition: %d", err);
-        return BnStatus::fromServiceSpecificError(UNKNOWN_ERROR);
-    }
-
-    return BnStatus::fromStatusT(mBase->configure(
-            new OmxNodeWrapper(omxNode),
-            dataSpace,
-            def.nBufferCountActual,
-            def.format.video.nFrameWidth,
-            def.format.video.nFrameHeight,
-            consumerUsage));
-}
-
-} // namespace android
-
diff --git a/media/codec2/sfplugin/Omx2IGraphicBufferSource.h b/media/codec2/sfplugin/Omx2IGraphicBufferSource.h
deleted file mode 100644
index 20fd1ecb4b..0000000000
--- a/media/codec2/sfplugin/Omx2IGraphicBufferSource.h
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Copyright 2019 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-#ifndef OMX_2_IGRAPHICBUFFERSOURCE_H_
-#define OMX_2_IGRAPHICBUFFERSOURCE_H_
-
-#include <android/BnGraphicBufferSource.h>
-#include <media/stagefright/omx/OmxGraphicBufferSource.h>
-
-namespace android {
-
-using BnStatus = ::android::binder::Status;
-
-struct Omx2IGraphicBufferSource : public BnGraphicBufferSource {
-    sp<OmxGraphicBufferSource> mBase;
-    sp<IOMXBufferSource> mOMXBufferSource;
-    Omx2IGraphicBufferSource(sp<OmxGraphicBufferSource> const& base);
-    BnStatus configure(const sp<IOMXNode>& omxNode, int32_t dataSpace) override;
-    BnStatus setSuspend(bool suspend, int64_t timeUs) override;
-    BnStatus setRepeatPreviousFrameDelayUs(int64_t repeatAfterUs) override;
-    BnStatus setMaxFps(float maxFps) override;
-    BnStatus setTimeLapseConfig(double fps, double captureFps) override;
-    BnStatus setStartTimeUs(int64_t startTimeUs) override;
-    BnStatus setStopTimeUs(int64_t stopTimeUs) override;
-    BnStatus getStopTimeOffsetUs(int64_t *stopTimeOffsetUs) override;
-    BnStatus setColorAspects(int32_t aspects) override;
-    BnStatus setTimeOffsetUs(int64_t timeOffsetsUs) override;
-    BnStatus signalEndOfInputStream() override;
-};
-
-} // namespace android
-
-#endif // OMX_2_IGRAPHICBUFFERSOURCE_H_
-
diff --git a/media/codec2/tests/aidl/GraphicsTracker_test.cpp b/media/codec2/tests/aidl/GraphicsTracker_test.cpp
index ec3e3d147e..530f1a126b 100644
--- a/media/codec2/tests/aidl/GraphicsTracker_test.cpp
+++ b/media/codec2/tests/aidl/GraphicsTracker_test.cpp
@@ -18,14 +18,16 @@
 #include <unistd.h>
 
 #include <android/hardware_buffer.h>
-#include <codec2/aidl/GraphicsTracker.h>
 #include <binder/IPCThreadState.h>
 #include <binder/IServiceManager.h>
 #include <binder/ProcessState.h>
+#include <codec2/aidl/GraphicsTracker.h>
 #include <gtest/gtest.h>
+#include <gui/BufferItemConsumer.h>
 #include <gui/BufferQueue.h>
-#include <gui/IProducerListener.h>
 #include <gui/IConsumerListener.h>
+#include <gui/IGraphicBufferProducer.h>
+#include <gui/IProducerListener.h>
 #include <gui/Surface.h>
 #include <private/android/AHardwareBufferHelpers.h>
 
@@ -39,15 +41,16 @@
 
 using ::aidl::android::hardware::media::c2::implementation::GraphicsTracker;
 using ::android::BufferItem;
+using ::android::BufferItemConsumer;
 using ::android::BufferQueue;
 using ::android::Fence;
 using ::android::GraphicBuffer;
+using ::android::IConsumerListener;
 using ::android::IGraphicBufferProducer;
-using ::android::IGraphicBufferConsumer;
 using ::android::IProducerListener;
-using ::android::IConsumerListener;
 using ::android::OK;
 using ::android::sp;
+using ::android::Surface;
 using ::android::wp;
 
 namespace {
@@ -76,29 +79,24 @@ struct BqStatistics {
     }
 };
 
-struct DummyConsumerListener : public android::IConsumerListener {
+struct DummyConsumerListener : public BufferItemConsumer::FrameAvailableListener {
     void onFrameAvailable(const BufferItem& /* item */) override {}
-    void onBuffersReleased() override {}
-    void onSidebandStreamChanged() override {}
 };
 
-struct TestConsumerListener : public android::IConsumerListener {
-    TestConsumerListener(const sp<IGraphicBufferConsumer>& consumer)
-        : IConsumerListener(), mConsumer(consumer) {}
+struct TestConsumerListener : public BufferItemConsumer::FrameAvailableListener {
+    TestConsumerListener(const sp<BufferItemConsumer>& consumer) : mConsumer(consumer) {}
     void onFrameAvailable(const BufferItem&) override {
         constexpr static int kRenderDelayUs = 1000000/30; // 30fps
         BufferItem buffer;
         // consume buffer
-        sp<IGraphicBufferConsumer> consumer = mConsumer.promote();
+        sp<BufferItemConsumer> consumer = mConsumer.promote();
         if (consumer != nullptr && consumer->acquireBuffer(&buffer, 0) == android::NO_ERROR) {
             ::usleep(kRenderDelayUs);
-            consumer->releaseBuffer(buffer.mSlot, buffer.mFrameNumber, buffer.mFence);
+            consumer->releaseBuffer(buffer.mGraphicBuffer, buffer.mFence);
         }
     }
-    void onBuffersReleased() override {}
-    void onSidebandStreamChanged() override {}
 
-    wp<IGraphicBufferConsumer> mConsumer;
+    wp<BufferItemConsumer> mConsumer;
 };
 
 struct TestProducerListener : public android::BnProducerListener {
@@ -256,37 +254,36 @@ public:
     }
 
 protected:
-    bool init(int maxDequeueCount) {
-        mTracker = GraphicsTracker::CreateGraphicsTracker(maxDequeueCount);
-        if (!mTracker) {
-            return false;
-        }
-        BufferQueue::createBufferQueue(&mProducer, &mConsumer);
-        if (!mProducer || !mConsumer) {
-            return false;
-        }
-        return true;
-    }
-    bool configure(sp<IProducerListener> producerListener,
-                   sp<IConsumerListener> consumerListener,
-                   int maxAcquiredCount = 1, bool controlledByApp = true) {
-        if (mConsumer->consumerConnect(
-                consumerListener, controlledByApp) != ::android::NO_ERROR) {
-            return false;
-        }
-        if (mConsumer->setMaxAcquiredBufferCount(maxAcquiredCount) != ::android::NO_ERROR) {
-            return false;
-        }
-        IGraphicBufferProducer::QueueBufferOutput qbo{};
-        if (mProducer->connect(producerListener,
-                          NATIVE_WINDOW_API_MEDIA, true, &qbo) != ::android::NO_ERROR) {
-            return false;
-        }
-        if (mProducer->setDequeueTimeout(0) != ::android::NO_ERROR) {
-            return false;
-        }
-        return true;
-    }
+  bool init(int maxDequeueCount, bool controlledByApp = true) {
+      mTracker = GraphicsTracker::CreateGraphicsTracker(maxDequeueCount);
+      if (!mTracker) {
+          return false;
+      }
+      sp<Surface> surface;
+      std::tie(mConsumer, surface) = BufferItemConsumer::create(
+              kTestUsageFlag, BufferItemConsumer::DEFAULT_MAX_BUFFERS, controlledByApp);
+      mProducer = surface->getIGraphicBufferProducer();
+
+      return true;
+  }
+  bool configure(sp<IProducerListener> producerListener,
+                 sp<BufferItemConsumer::FrameAvailableListener> consumerListener,
+                 int maxAcquiredCount = 1) {
+      mConsumerListener = consumerListener;
+      mConsumer->setFrameAvailableListener(mConsumerListener);
+      if (mConsumer->setMaxAcquiredBufferCount(maxAcquiredCount) != ::android::NO_ERROR) {
+          return false;
+      }
+      IGraphicBufferProducer::QueueBufferOutput qbo{};
+      if (mProducer->connect(producerListener, NATIVE_WINDOW_API_MEDIA, true, &qbo) !=
+          ::android::NO_ERROR) {
+          return false;
+      }
+      if (mProducer->setDequeueTimeout(0) != ::android::NO_ERROR) {
+          return false;
+      }
+      return true;
+  }
 
     virtual void TearDown() override {
         mBqStat->log();
@@ -306,7 +303,8 @@ protected:
 protected:
     std::shared_ptr<BqStatistics> mBqStat = std::make_shared<BqStatistics>();
     sp<IGraphicBufferProducer> mProducer;
-    sp<IGraphicBufferConsumer> mConsumer;
+    sp<BufferItemConsumer> mConsumer;
+    sp<BufferItemConsumer::FrameAvailableListener> mConsumerListener;
     std::shared_ptr<GraphicsTracker> mTracker;
 };
 
@@ -437,7 +435,8 @@ TEST_F(GraphicsTrackerTest, DropAndReleaseTest) {
     // Consume one buffer and release
     BufferItem item;
     ASSERT_EQ(OK, mConsumer->acquireBuffer(&item, 0));
-    ASSERT_EQ(OK, mConsumer->releaseBuffer(item.mSlot, item.mFrameNumber, item.mFence));
+    ASSERT_EQ(OK, mConsumer->releaseBuffer(item.mGraphicBuffer, item.mFence));
+
     // Nothing to consume
     ASSERT_NE(OK, mConsumer->acquireBuffer(&item, 0));
 
@@ -451,9 +450,9 @@ TEST_F(GraphicsTrackerTest, RenderTest) {
     const int maxDequeueCount = 10;
     const int maxNumAlloc = 20;
 
-    ASSERT_TRUE(init(maxDequeueCount));
+    ASSERT_TRUE(init(maxDequeueCount, /*controlledByApp=*/false));
     ASSERT_TRUE(configure(new TestProducerListener(mTracker, mBqStat, generation),
-                          new TestConsumerListener(mConsumer), 1, false));
+                          new TestConsumerListener(mConsumer), 1));
 
     ASSERT_EQ(OK, mProducer->setGenerationNumber(generation));
 
@@ -512,9 +511,9 @@ TEST_F(GraphicsTrackerTest, StopAndWaitTest) {
     uint32_t generation = 1;
     const int maxDequeueCount = 2;
 
-    ASSERT_TRUE(init(maxDequeueCount));
+    ASSERT_TRUE(init(maxDequeueCount, /*controlledByApp=*/false));
     ASSERT_TRUE(configure(new TestProducerListener(mTracker, mBqStat, generation),
-                          new TestConsumerListener(mConsumer), 1, false));
+                          new TestConsumerListener(mConsumer), 1));
 
     ASSERT_EQ(OK, mProducer->setGenerationNumber(generation));
 
@@ -556,9 +555,9 @@ TEST_F(GraphicsTrackerTest, SurfaceChangeTest) {
     const int firstPassAlloc = 12;
     const int firstPassRender = 8;
 
-    ASSERT_TRUE(init(maxDequeueCount));
+    ASSERT_TRUE(init(maxDequeueCount, /*controlledByApp=*/false));
     ASSERT_TRUE(configure(new TestProducerListener(mTracker, mBqStat, generation),
-                          new TestConsumerListener(mConsumer), 1, false));
+                          new TestConsumerListener(mConsumer), 1));
 
     ASSERT_EQ(OK, mProducer->setGenerationNumber(generation));
 
@@ -607,16 +606,19 @@ TEST_F(GraphicsTrackerTest, SurfaceChangeTest) {
 
     // switching surface
     sp<IGraphicBufferProducer> oldProducer = mProducer;
-    sp<IGraphicBufferConsumer> oldConsumer = mConsumer;
+    sp<BufferItemConsumer> oldConsumer = mConsumer;
+    sp<BufferItemConsumer::FrameAvailableListener> oldConsumerListener = mConsumerListener;
     mProducer.clear();
     mConsumer.clear();
-    BufferQueue::createBufferQueue(&mProducer, &mConsumer);
-    ASSERT_TRUE((bool)mProducer && (bool)mConsumer);
+    sp<Surface> surface;
+    std::tie(mConsumer, surface) = BufferItemConsumer::create(
+            kTestUsageFlag, BufferItemConsumer::DEFAULT_MAX_BUFFERS, /*controlledByApp=*/false);
+    mProducer = surface->getIGraphicBufferProducer();
 
     generation += 1;
 
     ASSERT_TRUE(configure(new TestProducerListener(mTracker, mBqStat, generation),
-                          new TestConsumerListener(mConsumer), 1, false));
+                          new TestConsumerListener(mConsumer), 1));
     ASSERT_EQ(OK, mProducer->setGenerationNumber(generation));
     ASSERT_EQ(C2_OK, mTracker->configureGraphics(mProducer, generation));
     ASSERT_EQ(C2_OK, mTracker->configureMaxDequeueCount(maxDequeueCount));
@@ -690,9 +692,9 @@ TEST_F(GraphicsTrackerTest, maxDequeueIncreaseTest) {
 
     int numAlloc = 0;
 
-    ASSERT_TRUE(init(maxDequeueCount));
+    ASSERT_TRUE(init(maxDequeueCount, /*controlledByApp=*/false));
     ASSERT_TRUE(configure(new TestProducerListener(mTracker, mBqStat, generation),
-                          new TestConsumerListener(mConsumer), 1, false));
+                          new TestConsumerListener(mConsumer), 1));
 
     ASSERT_EQ(OK, mProducer->setGenerationNumber(generation));
     ASSERT_EQ(C2_OK, mTracker->configureGraphics(mProducer, generation));
@@ -757,9 +759,9 @@ TEST_F(GraphicsTrackerTest, maxDequeueDecreaseTest) {
 
     int numAlloc = 0;
 
-    ASSERT_TRUE(init(maxDequeueCount));
+    ASSERT_TRUE(init(maxDequeueCount, /*controlledByApp=*/false));
     ASSERT_TRUE(configure(new TestProducerListener(mTracker, mBqStat, generation),
-                          new TestConsumerListener(mConsumer), 1, false));
+                          new TestConsumerListener(mConsumer), 1));
 
     ASSERT_EQ(OK, mProducer->setGenerationNumber(generation));
     ASSERT_EQ(C2_OK, mTracker->configureGraphics(mProducer, generation));
diff --git a/media/codec2/vndk/C2Store.cpp b/media/codec2/vndk/C2Store.cpp
index 7ca86c161f..a494b70cc5 100644
--- a/media/codec2/vndk/C2Store.cpp
+++ b/media/codec2/vndk/C2Store.cpp
@@ -1196,6 +1196,7 @@ C2PlatformComponentStore::C2PlatformComponentStore()
     emplace("libcodec2_soft_h263enc.so");
     emplace("libcodec2_soft_hevcdec.so");
     emplace("libcodec2_soft_hevcenc.so");
+    emplace("libcodec2_soft_iamfdec.so");
     emplace("libcodec2_soft_mp3dec.so");
     emplace("libcodec2_soft_mpeg2dec.so");
     emplace("libcodec2_soft_mpeg4dec.so");
diff --git a/media/janitors/better_together_OWNERS b/media/janitors/better_together_OWNERS
index 70723cb49e..403b66820c 100644
--- a/media/janitors/better_together_OWNERS
+++ b/media/janitors/better_together_OWNERS
@@ -3,3 +3,4 @@
 aquilescanta@google.com
 asapperstein@google.com
 halliwell@google.com
+shenqiuz@google.com
diff --git a/media/libaaudio/OWNERS b/media/libaaudio/OWNERS
index 3285bf38dc..c3817bb90f 100644
--- a/media/libaaudio/OWNERS
+++ b/media/libaaudio/OWNERS
@@ -1,4 +1,5 @@
 # Bug component: 48436
 jiabin@google.com
-philburk@google.com
+hunga@google.com
+elaurent@google.com
 include platform/frameworks/av:/media/janitors/audio_OWNERS #{LAST_RESORT_SUGGESTION}
diff --git a/media/libaaudio/TEST_MAPPING b/media/libaaudio/TEST_MAPPING
index 5d3fb0a013..da72a37eeb 100644
--- a/media/libaaudio/TEST_MAPPING
+++ b/media/libaaudio/TEST_MAPPING
@@ -14,6 +14,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     }
diff --git a/media/libaaudio/examples/utils/AAudioSimplePlayer.h b/media/libaaudio/examples/utils/AAudioSimplePlayer.h
index 5b8ab59c96..a413c4b707 100644
--- a/media/libaaudio/examples/utils/AAudioSimplePlayer.h
+++ b/media/libaaudio/examples/utils/AAudioSimplePlayer.h
@@ -120,7 +120,8 @@ public:
                          AAudioStream_dataCallback dataCallback = nullptr,
                          AAudioStream_errorCallback errorCallback = nullptr,
                          void *userContext = nullptr,
-                         AAudioStream_presentationEndCallback presentationEndCallback = nullptr) {
+                         AAudioStream_presentationEndCallback presentationEndCallback = nullptr,
+                         AAudioStream_partialDataCallback partialDataCallback = nullptr) {
         aaudio_result_t result = AAUDIO_OK;
 
         // Use an AAudioStreamBuilder to contain requested parameters.
@@ -142,6 +143,9 @@ public:
             AAudioStreamBuilder_setPresentationEndCallback(
                     builder, presentationEndCallback, userContext);
         }
+        if (partialDataCallback != nullptr) {
+            AAudioStreamBuilder_setPartialDataCallback(builder, partialDataCallback, userContext);
+        }
         //AAudioStreamBuilder_setFramesPerDataCallback(builder, CALLBACK_SIZE_FRAMES);
         //AAudioStreamBuilder_setBufferCapacityInFrames(builder, 48 * 8);
 
@@ -150,9 +154,14 @@ public:
 
         if (result == AAUDIO_OK) {
             int32_t sizeInBursts = parameters.getNumberOfBursts();
-            int32_t framesPerBurst = AAudioStream_getFramesPerBurst(mStream);
-            int32_t bufferSizeFrames = sizeInBursts * framesPerBurst;
-            AAudioStream_setBufferSizeInFrames(mStream, bufferSizeFrames);
+            if (sizeInBursts < 0) {
+                printf("Requested size in bursts is negative, %d", sizeInBursts);
+            } else if (sizeInBursts > 0) {
+                int32_t framesPerBurst = AAudioStream_getFramesPerBurst(mStream);
+                int32_t bufferSizeFrames = sizeInBursts * framesPerBurst;
+                AAudioStream_setBufferSizeInFrames(mStream, bufferSizeFrames);
+            }
+            // When the requested size in bursts is 0, use the default value set by the framework.
         }
 
         AAudioStreamBuilder_delete(builder);
@@ -195,7 +204,7 @@ public:
         return result;
     }
 
-    aaudio_result_t close() {
+    virtual aaudio_result_t close() {
         if (mStream != nullptr) {
             AAudioStream_close(mStream);
             mStream = nullptr;
diff --git a/media/libaaudio/include/aaudio/AAudio.h b/media/libaaudio/include/aaudio/AAudio.h
index ddafd5772f..3e5e9ff51c 100644
--- a/media/libaaudio/include/aaudio/AAudio.h
+++ b/media/libaaudio/include/aaudio/AAudio.h
@@ -123,36 +123,50 @@ enum {
 
     /**
      * This format is used for audio compressed in MP3 format.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_MP3,
 
     /**
      * This format is used for audio compressed in AAC LC format.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_AAC_LC,
 
     /**
      * This format is used for audio compressed in AAC HE V1 format.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_AAC_HE_V1,
 
     /**
      * This format is used for audio compressed in AAC HE V2 format.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_AAC_HE_V2,
 
     /**
      * This format is used for audio compressed in AAC ELD format.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_AAC_ELD,
 
     /**
      * This format is used for audio compressed in AAC XHE format.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_AAC_XHE,
 
     /**
      * This format is used for audio compressed in OPUS.
+     *
+     * Available since API level 36.
      */
     AAUDIO_FORMAT_OPUS
 };
@@ -384,6 +398,8 @@ enum {
      * pipe will be suspended automatically and the CPU will be allowed to sleep for
      * power saving. When all queued data are played, the apps will be able to get callback
      * to feed more data.
+     *
+     * Available since API level 36.
      */
     AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED
 };
@@ -1604,6 +1620,9 @@ typedef aaudio_data_callback_result_t (*AAudioStream_dataCallback)(
  *
  * Note that the AAudio callbacks will never be called simultaneously from multiple threads.
  *
+ * If both this method and {@link #AAudioStreamBuilder_setPartialDataCallback} are called,
+ * the data callback from the last called method will be used.
+ *
  * Available since API level 26.
  *
  * @param builder reference provided by AAudio_createStreamBuilder()
@@ -1615,6 +1634,104 @@ AAUDIO_API void AAudioStreamBuilder_setDataCallback(AAudioStreamBuilder* _Nonnul
         AAudioStream_dataCallback _Nullable callback, void* _Nullable userData)
         __INTRODUCED_IN(26);
 
+/**
+ * Prototype for the data function that is passed to AAudioStreamBuilder_setPartialDataCallback().
+ *
+ * The main difference between this callback prototype and AAudioStream_dataCallback is the return
+ * value. In this method, it returns an integer value to indicate the actual frames of data is
+ * processed. In AAudioStream_dataCallback, it can only return AAUDIO_CALLBACK_RESULT_CONTINUE
+ * indicating all data is processed or AAUDIO_CALLBACK_RESULT_CONTINUE indicating no data is
+ * processed.
+ *
+ * For an output stream, this function should render and write at most numFrames of data
+ * in the streams current data format to the audioData buffer.
+ *
+ * For an input stream, this function should read and process at most numFrames of data
+ * from the audioData buffer. The data in the audioData buffer must not be modified
+ * directly. Instead, it should be copied to another buffer before doing any modification.
+ * In many cases, writing to the audioData buffer of an input stream will result in a
+ * native exception.
+ *
+ * The audio data is passed through the buffer. So do NOT call AAudioStream_read() or
+ * AAudioStream_write() on the stream that is making the callback.
+ *
+ * Note that numFrames can vary unless AAudioStreamBuilder_setFramesPerDataCallback()
+ * is called.
+ *
+ * Also note that this callback function should be considered a "real-time" function.
+ * The callback should copy the data to/from the buffer and not do anything that could cause
+ * unbounded delay because that can cause the audio to glitch or pop.
+ *
+ * These are things the function should NOT do:
+ * <ul>
+ * <li>allocate memory using, for example, malloc() or new</li>
+ * <li>any file operations such as opening, closing, reading or writing</li>
+ * <li>any network operations such as streaming</li>
+ * <li>use any mutexes or other synchronization primitives</li>
+ * <li>sleep</li>
+ * <li>stop or close the stream</li>
+ * <li>AAudioStream_read()</li>
+ * <li>AAudioStream_write()</li>
+ * </ul>
+ *
+ * The following are OK to call from the data callback:
+ * <ul>
+ * <li>AAudioStream_get*()</li>
+ * <li>AAudio_convertResultToText()</li>
+ * </ul>
+ *
+ * We recommend use of non-blocking techniques to copy data furnished by the callback method,
+ * for example the non-blocking fifo: system/media/audio_utils/include/audio_utils/fifo.h
+ *
+ * @param stream reference provided by AAudioStreamBuilder_openStream().
+ * @param userData the same address that was passed to AAudioStreamBuilder_setPartialCallback().
+ * @param audioData a pointer to the audio data.
+ * @param numFrames the number of frames to be processed, which can vary.
+ * @return the actual processed number of frames. Negative value will stop the stream.
+ *         if the returned value is greater than numFrames, the stream will stop.
+ */
+typedef int32_t (*AAudioStream_partialDataCallback)(
+        AAudioStream* _Nonnull stream,
+        void* _Nullable userData,
+        void* _Nonnull audioData,
+        int32_t numFrames);
+
+/**
+ * Request that AAudio call this functions when the stream is running.
+ *
+ * Note that when using this callback, it must be the sole way of transferring audio data;
+ * you cannot call AAudioStream_write() or AAudioStream_read() on the same stream that has
+ * an active data callback.
+ *
+ * The callback function will start being called after AAudioStream_requestStart()
+ * is called.
+ * It will stop being called after AAudioStream_requestPause() or
+ * AAudioStream_requestStop() is called.
+ *
+ * This callback function will be called on a real-time thread owned by AAudio.
+ * The low latency streams may have callback threads with higher priority than normal streams.
+ * See {@link #AAudioStream_partialDataCallback} for more information.
+ *
+ * Note that the AAudio callbacks will never be called simultaneously from multiple threads.
+ *
+ * If both this method and {@link #AAudioStreamBuilder_setDataCallback} are called,
+ * the data callback from the last called method will be used.
+ *
+ * Available since API level 37.
+ *
+ * @param builder reference provided by AAudio_createStreamBuilder().
+ * @param callback pointer to a function that will process audio data.
+ * @param userData pointer to an application data structure that will be passed
+ *          to the callback functions.
+ * @return AAUDIO_OK if data callback is set successfully or
+ *         AAUDIO_ERROR_UNIMPLEMENTED if {@link #AAudioStream_partialDataCallback}
+ *         is not supported.
+ */
+AAUDIO_API aaudio_result_t AAudioStreamBuilder_setPartialDataCallback(
+        AAudioStreamBuilder* _Nonnull builder,
+        AAudioStream_partialDataCallback _Nullable callback,
+        void* _Nullable userData) __INTRODUCED_IN(37);
+
 /**
  * Set the requested data callback buffer size in frames.
  * See {@link #AAudioStream_dataCallback}.
@@ -2461,6 +2578,8 @@ AAUDIO_API aaudio_channel_mask_t AAudioStream_getChannelMask(AAudioStream* _Nonn
  * The unit is frames, where a frame includes samples for all audio channels, e.g. 100 frames
  * for a stereo stream corresponds to 200 interleaved PCM samples.
  *
+ * Available since API level 36.
+ *
  * @param stream reference provided by AAudioStreamBuilder_openStream()
  * @param delayInFrames number of frames to be ignored at the beginning of the stream. A value
  *                      of 0 indicates no delay is to be applied.
@@ -2480,6 +2599,8 @@ AAUDIO_API aaudio_result_t AAudioStream_setOffloadDelayPadding(
 /**
  * Return the decoder delay of an offloaded stream in frames.
  *
+ * Available since API level 36.
+ *
  * @param stream reference provided by AAudioStreamBuilder_openStream()
  * @return the offload delay in frames that previously set with
  *         {@link #AAudioStream_setOffloadDelayPadding},
@@ -2493,6 +2614,8 @@ AAUDIO_API int32_t AAudioStream_getOffloadDelay(AAudioStream* _Nonnull stream) _
 /**
  * Return the decoder padding of an offloaded stream in frames.
  *
+ * Available since API level 36.
+ *
  * @param stream reference provided by AAudioStreamBuilder_openStream()
  * @return the offload padding in frames that previously set with
  *         {@link #AAudioStream_setOffloadDelayPadding},
@@ -2511,6 +2634,8 @@ AAUDIO_API int32_t AAudioStream_getOffloadPadding(AAudioStream* _Nonnull stream)
  * all written data will be played.
  * Use this method in the same thread as any data writing operation.
  *
+ * Available since API level 36.
+ *
  * @param stream reference provided by AAudioStreamBuilder_openStream()
  * @return {@link #AAUDIO_OK} on success,
  *         or {@link #AAUDIO_ERROR_UNIMPLEMENTED} if the stream is not an output stream whose
@@ -2520,6 +2645,70 @@ AAUDIO_API int32_t AAudioStream_getOffloadPadding(AAudioStream* _Nonnull stream)
 AAUDIO_API aaudio_result_t AAudioStream_setOffloadEndOfStream(AAudioStream* _Nonnull stream)
         __INTRODUCED_IN(36);
 
+/**
+ * The values are defined to be used for the accuracy requirement when calling
+ * {@link AAudioStream_flushFromFrame}.
+ */
+typedef enum AAudio_FlushFromAccuracy : int32_t {
+    /**
+     * There is not requirement for frame accuracy when flushing, it is up to the framework
+     * to select a right position to flush from.
+     */
+    AAUDIO_FLUSH_FROM_ACCURACY_UNDEFINED = 0,
+
+    /**
+     * The stream must be flushed from the requested position. If it is not possible to flush
+     * from the requested position, the stream must not be flushed.
+     */
+    AAUDIO_FLUSH_FROM_FRAME_ACCURATE = 1
+} AAudio_FlushFromAccuracy;
+
+/**
+ * Flush all data from given position. If this operation returns successfully, the following
+ * data will be written from the returned position.
+ *
+ * This method will only work when the performance mode is
+ * {@link AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED}.
+ *
+ * The requested position must not be negative or greater than the written frames. The current
+ * written position can be known by querying {@link AAudioStream_getFramesWritten}.
+ *
+ * When clients request to flush from a certain position, the audio system will return the actual
+ * flushed position based on the requested position, playback latency, etc. The written position
+ * will be updated as the actual flush position. All data behind actual flush position will be
+ * flushed. The client can provide data from actual flush position at next write operation or data
+ * callback request. When the stream is flushed, the stream end will be reset. The client must not
+ * write any data before this function returns. Otherwise, the data will be corrupted. When the
+ * method returns successfully and the stream is active, the client must write data immediately
+ * if little audio data remains. Otherwise, the stream will underrun.
+ *
+ * If apps prefer data callback, it is suggested to use {@link AAudioStream_partialDataCallback}.
+ * In that case, after the stream is flushed successfully by calling this method, the app can just
+ * fill partial data from the data callback instead of as much (partial) data as possible. That
+ * can help avoid underrun after successfully calling this method.
+ *
+ * @param stream reference provided by AAudioStreamBuilder_openStream().
+ * @param accuracy the accuracy requirement when flushing. The value must be one of the valid
+ *                 AAudio_FlushFromAccuracy value.
+ * @param[in|out] position the start point in frames to flush the stream. If flushing from frame
+ *                         is supported for the stream, the position will be updated as the actual
+ *                         flush from position when successfully flush or the suggested position
+ *                         to flush from if it cannot flush from the requested position. If there
+ *                         is not enough data to safely flush, position will remain the same.
+ * @return AAUDIO_OK if the stream is successfully flushed.
+ *         AAUDIO_ERROR_UNIMPLEMENTED if it is not supported by the device.
+ *         AAUDIO_ERROR_ILLEGAL_ARGUMENT if the stream is not an output offload stream or the
+ *         accuracy is not one of valid AAudio_FlushFromAccuracy values.
+ *         AAUDIO_ERROR_OUT_OF_RANGE if the provided position is negative or is greater than the
+ *         frames written or the stream cannot flush from the requested position and
+ *         AAUDIO_FLUSH_FROM_FRAME_ACCURATE is requested.
+ *         AAUDIO_ERROR_DISCONNECTED if aaudio service is dead or the stream is disconnected.
+ */
+AAUDIO_API aaudio_result_t AAudioStream_flushFromFrame(
+        AAudioStream* _Nonnull stream,
+        AAudio_FlushFromAccuracy accuracy,
+        int64_t* _Nonnull inOutPosition) __INTRODUCED_IN(37);
+
 /************************************************************************************
  * Helper functions for AAudio MMAP.
  * AAudio MMAP data path uses a memory region that is shared between the hardware and
diff --git a/media/libaaudio/src/Android.bp b/media/libaaudio/src/Android.bp
index 5aa4964e0c..7c569afe5f 100644
--- a/media/libaaudio/src/Android.bp
+++ b/media/libaaudio/src/Android.bp
@@ -100,6 +100,7 @@ cc_library {
     ],
 
     shared_libs: [
+        "com.android.media.aaudio-aconfig-cc",
         "framework-permission-aidl-cpp",
         "libaaudio_internal",
         "libaudioclient",
diff --git a/media/libaaudio/src/binding/AAudioBinderAdapter.cpp b/media/libaaudio/src/binding/AAudioBinderAdapter.cpp
index ee7480b63d..bcf33535cc 100644
--- a/media/libaaudio/src/binding/AAudioBinderAdapter.cpp
+++ b/media/libaaudio/src/binding/AAudioBinderAdapter.cpp
@@ -166,4 +166,17 @@ aaudio_result_t AAudioBinderAdapter::exitStandby(const AAudioHandleInfo& streamH
     return result;
 }
 
+aaudio_result_t AAudioBinderAdapter::updateTimestamp(
+        const aaudio::AAudioHandleInfo &streamHandleInfo) {
+    if (streamHandleInfo.getServiceLifetimeId() != mServiceLifetimeId) {
+        return AAUDIO_ERROR_DISCONNECTED;
+    }
+    aaudio_result_t result;
+    Status status = mDelegate->updateTimestamp(streamHandleInfo.getHandle(), &result);
+    if (!status.isOk()) {
+        result = AAudioConvert_androidToAAudioResult(statusTFromBinderStatus(status));
+    }
+    return result;
+}
+
 }  // namespace aaudio
diff --git a/media/libaaudio/src/binding/AAudioBinderAdapter.h b/media/libaaudio/src/binding/AAudioBinderAdapter.h
index 301150fda7..fe682459fc 100644
--- a/media/libaaudio/src/binding/AAudioBinderAdapter.h
+++ b/media/libaaudio/src/binding/AAudioBinderAdapter.h
@@ -60,6 +60,8 @@ public:
     aaudio_result_t exitStandby(const AAudioHandleInfo& streamHandleInfo,
                                 AudioEndpointParcelable &parcelable) override;
 
+    aaudio_result_t updateTimestamp(const AAudioHandleInfo& streamHandleInfo) override;
+
 private:
     IAAudioService* const mDelegate;
     // A unique id to recognize the service that the adapter connected to.
diff --git a/media/libaaudio/src/binding/AAudioBinderClient.cpp b/media/libaaudio/src/binding/AAudioBinderClient.cpp
index 439d5af59a..3c2319b285 100644
--- a/media/libaaudio/src/binding/AAudioBinderClient.cpp
+++ b/media/libaaudio/src/binding/AAudioBinderClient.cpp
@@ -206,3 +206,10 @@ aaudio_result_t AAudioBinderClient::exitStandby(const AAudioHandleInfo& streamHa
 
     return service->exitStandby(streamHandleInfo, endpointOut);
 }
+
+aaudio_result_t AAudioBinderClient::updateTimestamp(const AAudioHandleInfo& streamHandleInfo) {
+    std::shared_ptr<AAudioServiceInterface> service = getAAudioService();
+    if (service.get() == nullptr) return AAUDIO_ERROR_NO_SERVICE;
+
+    return service->updateTimestamp(streamHandleInfo);
+}
diff --git a/media/libaaudio/src/binding/AAudioBinderClient.h b/media/libaaudio/src/binding/AAudioBinderClient.h
index 66d3295e38..865eb4a168 100644
--- a/media/libaaudio/src/binding/AAudioBinderClient.h
+++ b/media/libaaudio/src/binding/AAudioBinderClient.h
@@ -116,6 +116,8 @@ public:
     aaudio_result_t exitStandby(const AAudioHandleInfo& streamHandleInfo,
                                 AudioEndpointParcelable &endpointOut) override;
 
+    aaudio_result_t updateTimestamp(const AAudioHandleInfo& streamHandleInfo) override;
+
     void onStreamChange(aaudio_handle_t /*handle*/, int32_t /*opcode*/, int32_t /*value*/) {
         // TODO This is just a stub so we can have a client Binder to pass to the service.
         // TODO Implemented in a later CL.
diff --git a/media/libaaudio/src/binding/AAudioServiceInterface.h b/media/libaaudio/src/binding/AAudioServiceInterface.h
index 79f498bfb6..2630b59c75 100644
--- a/media/libaaudio/src/binding/AAudioServiceInterface.h
+++ b/media/libaaudio/src/binding/AAudioServiceInterface.h
@@ -108,6 +108,15 @@ public:
      */
     virtual aaudio_result_t exitStandby(const AAudioHandleInfo& streamHandleInfo,
                                         AudioEndpointParcelable &parcelable) = 0;
+
+    /**
+     * AAudio service will send timestamp periodically. Client call this method to trigger
+     * a timestamp update immediately.
+     *
+     * @param streamHandleInfo the stream handle
+     * @return
+     */
+    virtual aaudio_result_t updateTimestamp(const AAudioHandleInfo& streamHandleInfo) = 0;
 };
 
 } /* namespace aaudio */
diff --git a/media/libaaudio/src/binding/AAudioStreamConfiguration.cpp b/media/libaaudio/src/binding/AAudioStreamConfiguration.cpp
index 4e962194f9..afe2e5b162 100644
--- a/media/libaaudio/src/binding/AAudioStreamConfiguration.cpp
+++ b/media/libaaudio/src/binding/AAudioStreamConfiguration.cpp
@@ -83,6 +83,9 @@ AAudioStreamConfiguration::AAudioStreamConfiguration(const StreamParameters& par
         ALOGE("hardwareAudioFormat (%s) aidl2legacy conversion failed",
               parcelable.hardwareAudioFormat.toString().c_str());
     }
+
+    static_assert(sizeof(aaudio_performance_mode_t) == sizeof(parcelable.performanceMode));
+    setPerformanceMode(parcelable.performanceMode);
 }
 
 AAudioStreamConfiguration&
@@ -150,5 +153,7 @@ StreamParameters AAudioStreamConfiguration::parcelable() const {
         result.hardwareAudioFormat.type =
                 android::media::audio::common::AudioFormatType::SYS_RESERVED_INVALID;
     }
+    static_assert(sizeof(aaudio_performance_mode_t) == sizeof(result.performanceMode));
+    result.performanceMode = getPerformanceMode();
     return result;
 }
diff --git a/media/libaaudio/src/binding/aidl/aaudio/IAAudioService.aidl b/media/libaaudio/src/binding/aidl/aaudio/IAAudioService.aidl
index 485c2e288c..768ebe792b 100644
--- a/media/libaaudio/src/binding/aidl/aaudio/IAAudioService.aidl
+++ b/media/libaaudio/src/binding/aidl/aaudio/IAAudioService.aidl
@@ -80,4 +80,6 @@ interface IAAudioService {
                               int clientThreadId);
 
     int exitStandby(int streamHandle, out Endpoint endpoint);
+
+    int updateTimestamp(int streamHandle);
 }
diff --git a/media/libaaudio/src/binding/aidl/aaudio/StreamParameters.aidl b/media/libaaudio/src/binding/aidl/aaudio/StreamParameters.aidl
index 88ad449027..8f673dfb4d 100644
--- a/media/libaaudio/src/binding/aidl/aaudio/StreamParameters.aidl
+++ b/media/libaaudio/src/binding/aidl/aaudio/StreamParameters.aidl
@@ -38,4 +38,5 @@ parcelable StreamParameters {
     int                                       hardwareSamplesPerFrame;//= AAUDIO_UNSPECIFIED;
     int                                       hardwareSampleRate;  //   = AAUDIO_UNSPECIFIED;
     AudioFormatDescription                    hardwareAudioFormat;  //  = AUDIO_FORMAT_DEFAULT;
+    int /* aaudio_performance_mode_t */       performanceMode; //       = AAUDIO_UNSPECIFIED;
 }
diff --git a/media/libaaudio/src/client/AudioEndpoint.cpp b/media/libaaudio/src/client/AudioEndpoint.cpp
index cd7679ca98..d16f7e0838 100644
--- a/media/libaaudio/src/client/AudioEndpoint.cpp
+++ b/media/libaaudio/src/client/AudioEndpoint.cpp
@@ -28,7 +28,8 @@
 using namespace android;
 using namespace aaudio;
 
-#define RIDICULOUSLY_LARGE_BUFFER_CAPACITY   (256 * 1024)
+// TODO(411490458): put all aaudio constants at same place
+#define RIDICULOUSLY_LARGE_BUFFER_CAPACITY   (256 * 1024 * 1024)
 #define RIDICULOUSLY_LARGE_FRAME_SIZE        4096
 
 // TODO Consider moving to a method in RingBufferDescriptor
diff --git a/media/libaaudio/src/client/AudioStreamInternal.cpp b/media/libaaudio/src/client/AudioStreamInternal.cpp
index 33f152c6e3..56009989b6 100644
--- a/media/libaaudio/src/client/AudioStreamInternal.cpp
+++ b/media/libaaudio/src/client/AudioStreamInternal.cpp
@@ -31,6 +31,7 @@
 #include <media/AudioSystem.h>
 #include <media/MediaMetricsItem.h>
 #include <utils/Trace.h>
+#include <mediautils/SchedulingPolicyService.h>
 
 #include "AudioEndpointParcelable.h"
 #include "binding/AAudioBinderClient.h"
@@ -66,6 +67,9 @@ using namespace aaudio;
 // Minimum number of bursts to use when sample rate conversion is used.
 #define MIN_SAMPLE_RATE_CONVERSION_NUM_BURSTS    3
 
+// Matches kRealTimeAudioPriorityService in frameworks/av/services/oboeservice/AAudioService.h
+#define REAL_TIME_AUDIO_PRIORITY_SERVICE 3
+
 AudioStreamInternal::AudioStreamInternal(AAudioServiceInterface  &serviceInterface, bool inService)
         : AudioStream()
         , mClockModel()
@@ -98,14 +102,22 @@ aaudio_result_t AudioStreamInternal::open(const AudioStreamBuilder &builder) {
     if (result < 0) {
         return result;
     }
+    if (getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED) {
+        // For offload, force the sharing mode as exclusive
+        ALOGI("%s force to use exclusive mode when trying to open mmap offload stream", __func__);
+        setSharingMode(AAUDIO_SHARING_MODE_EXCLUSIVE);
+        setSharingModeMatchRequired(true);
+    }
 
     const audio_format_t requestedFormat = getFormat();
     // We have to do volume scaling. So we prefer FLOAT format.
     if (requestedFormat == AUDIO_FORMAT_DEFAULT) {
         setFormat(AUDIO_FORMAT_PCM_FLOAT);
     }
-    // Request FLOAT for the shared mixer or the device.
-    request.getConfiguration().setFormat(AUDIO_FORMAT_PCM_FLOAT);
+    // Request FLOAT for the shared mixer or the device if it is not offload.
+    request.getConfiguration().setFormat(
+            getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED
+                    ? getFormat() : AUDIO_FORMAT_PCM_FLOAT);
 
     // TODO b/182392769: use attribution source util
     AttributionSourceState attributionSource;
@@ -136,6 +148,8 @@ aaudio_result_t AudioStreamInternal::open(const AudioStreamBuilder &builder) {
 
     request.getConfiguration().setBufferCapacity(builder.getBufferCapacity());
 
+    request.getConfiguration().setPerformanceMode(getPerformanceMode());
+
     mServiceStreamHandleInfo = mServiceInterface.openStream(request, configurationOutput);
     if (getServiceHandle() < 0
             && (request.getConfiguration().getSamplesPerFrame() == 1
@@ -329,8 +343,13 @@ aaudio_result_t AudioStreamInternal::configureDataInformation(int32_t callbackFr
         mTimeOffsetNanos = offsetMicros * AAUDIO_NANOS_PER_MICROSECOND;
     }
 
-    // Default buffer size to match Q
-    setBufferSize(mBufferCapacityInFrames / 2);
+    // Default buffer size to match Android Q
+    int32_t bufSize = mBufferCapacityInFrames / 2;
+    if (getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED) {
+        // If it is an offload stream, try to set the buffer size as big as possible.
+        bufSize = std::max(bufSize, mBufferCapacityInFrames - getFramesPerBurst());
+    }
+    setBufferSize(bufSize);
     return AAUDIO_OK;
 }
 
@@ -389,9 +408,10 @@ aaudio_result_t AudioStreamInternal::exitStandby_l() {
     // Cache the buffer size which may be from client.
     const int32_t previousBufferSize = mBufferSizeInFrames;
     // Copy all available data from current data queue.
-    uint8_t buffer[getDeviceBufferCapacity() * getBytesPerFrame()];
-    android::fifo_frames_t fullFramesAvailable = mAudioEndpoint->read(buffer,
-            getDeviceBufferCapacity());
+    android::fifo_frames_t fullFramesAvailable = mAudioEndpoint->getFullFramesAvailable();
+    std::unique_ptr<uint8_t[]> buffer =
+            std::make_unique<uint8_t[]>(fullFramesAvailable * getBytesPerFrame());
+    fullFramesAvailable = mAudioEndpoint->read(buffer.get(), fullFramesAvailable);
     // Before releasing the data queue, update the frames read and written.
     getFramesRead();
     getFramesWritten();
@@ -430,7 +450,7 @@ aaudio_result_t AudioStreamInternal::exitStandby_l() {
     }
     // Write data from previous data buffer to new endpoint.
     if (const android::fifo_frames_t framesWritten =
-                mAudioEndpoint->write(buffer, fullFramesAvailable);
+                mAudioEndpoint->write(buffer.get(), fullFramesAvailable);
             framesWritten != fullFramesAvailable) {
         ALOGW("Some data lost after exiting standby, frames written: %d, "
               "frames to write: %d", framesWritten, fullFramesAvailable);
@@ -499,11 +519,7 @@ aaudio_result_t AudioStreamInternal::requestStart_l()
     // Start data callback thread.
     if (result == AAUDIO_OK && isDataCallbackSet()) {
         // Launch the callback loop thread.
-        int64_t periodNanos = mCallbackFrames
-                              * AAUDIO_NANOS_PER_SECOND
-                              / getSampleRate();
-        mCallbackEnabled.store(true);
-        result = createThread_l(periodNanos, aaudio_callback_thread_proc, this);
+        result = startCallback_l();
     }
     if (result != AAUDIO_OK) {
         setState(originalState);
@@ -533,6 +549,7 @@ aaudio_result_t AudioStreamInternal::stopCallback_l()
 {
     if (isDataCallbackSet() && (isActive() || isDisconnected())) {
         mCallbackEnabled.store(false);
+        wakeupCallbackThread();
         aaudio_result_t result = joinThread_l(nullptr); // may temporarily unlock mStreamLock
         if (result == AAUDIO_ERROR_INVALID_HANDLE) {
             ALOGD("%s() INVALID_HANDLE, stream was probably stolen", __func__);
@@ -546,6 +563,12 @@ aaudio_result_t AudioStreamInternal::stopCallback_l()
     }
 }
 
+aaudio_result_t AudioStreamInternal::startCallback_l() {
+    int64_t periodNanos = mCallbackFrames * AAUDIO_NANOS_PER_SECOND / getSampleRate();
+    mCallbackEnabled.store(true);
+    return createThread_l(periodNanos, aaudio_callback_thread_proc, this);
+}
+
 aaudio_result_t AudioStreamInternal::requestStop_l() {
     aaudio_result_t result = stopCallback_l();
     if (result != AAUDIO_OK) {
@@ -594,6 +617,16 @@ aaudio_result_t AudioStreamInternal::registerThread() {
         ALOGW("%s() mServiceStreamHandle invalid", __func__);
         return AAUDIO_ERROR_INVALID_STATE;
     }
+    if (mInService) {
+        // Threads in the service can request for their own priority directly.
+        int err = android::requestPriority(getpid(), gettid(), REAL_TIME_AUDIO_PRIORITY_SERVICE,
+                                           true /* isForApp */);
+        if (err != 0) {
+            ALOGE("%s(%d) requestPriority failed, errno = %d", __func__, gettid(), err);
+            return AAUDIO_ERROR_INTERNAL;
+        }
+        return AAUDIO_OK;
+    }
     return mServiceInterface.registerAudioThread(mServiceStreamHandleInfo,
                                                  gettid(),
                                                  getPeriodNanoseconds());
@@ -604,6 +637,9 @@ aaudio_result_t AudioStreamInternal::unregisterThread() {
         ALOGW("%s() mServiceStreamHandle invalid", __func__);
         return AAUDIO_ERROR_INVALID_STATE;
     }
+    if (mInService) {
+        return AAUDIO_OK;
+    }
     return mServiceInterface.unregisterAudioThread(mServiceStreamHandleInfo, gettid());
 }
 
@@ -954,8 +990,8 @@ aaudio_result_t AudioStreamInternal::setBufferSize(int32_t requestedFrames) {
 
     mBufferSizeInFrames = bufferSizeInFrames;
     mDeviceBufferSizeInFrames = deviceBufferSizeInFrames;
-    ALOGV("%s(%d) returns %d", __func__, requestedFrames, adjustedFrames);
-    return (aaudio_result_t) adjustedFrames;
+    ALOGV("%s(%d) returns %d", __func__, requestedFrames, mBufferSizeInFrames);
+    return (aaudio_result_t) mBufferSizeInFrames;
 }
 
 int32_t AudioStreamInternal::getBufferSize() const {
diff --git a/media/libaaudio/src/client/AudioStreamInternal.h b/media/libaaudio/src/client/AudioStreamInternal.h
index 20d55f9e5e..0b7bb07135 100644
--- a/media/libaaudio/src/client/AudioStreamInternal.h
+++ b/media/libaaudio/src/client/AudioStreamInternal.h
@@ -35,8 +35,8 @@ namespace aaudio {
     // These are intended to be outside the range of what is normally encountered.
     // TODO MAXes should probably be much bigger.
     constexpr int32_t MIN_FRAMES_PER_BURST = 16; // arbitrary
-    constexpr int32_t MAX_FRAMES_PER_BURST = 16 * 1024;  // arbitrary
-    constexpr int32_t MAX_BUFFER_CAPACITY_IN_FRAMES = 32 * 1024;  // arbitrary
+    constexpr int32_t MAX_FRAMES_PER_BURST = 16 * 1024 * 1024;  // arbitrary
+    constexpr int32_t MAX_BUFFER_CAPACITY_IN_FRAMES = 32 * 1024 * 1024;  // arbitrary
 
 // A stream that talks to the AAudioService or directly to a HAL.
 class AudioStreamInternal : public AudioStream {
@@ -129,6 +129,8 @@ protected:
 
     virtual void onFlushFromServer() {}
 
+    virtual void wakeupCallbackThread() {}
+
     aaudio_result_t onEventFromServer(AAudioServiceMessage *message);
 
     aaudio_result_t onTimestampService(AAudioServiceMessage *message);
@@ -153,6 +155,8 @@ protected:
      */
     bool isClockModelInControl() const;
 
+    aaudio_result_t startCallback_l() REQUIRES(mStreamLock);
+
     IsochronousClockModel    mClockModel;      // timing model for chasing the HAL
 
     std::unique_ptr<AudioEndpoint> mAudioEndpoint;   // source for reads or sink for writes
diff --git a/media/libaaudio/src/client/AudioStreamInternalCapture.cpp b/media/libaaudio/src/client/AudioStreamInternalCapture.cpp
index 68c9156d71..c1e88cadb2 100644
--- a/media/libaaudio/src/client/AudioStreamInternalCapture.cpp
+++ b/media/libaaudio/src/client/AudioStreamInternalCapture.cpp
@@ -282,18 +282,20 @@ int64_t AudioStreamInternalCapture::getFramesRead() {
 // Read data from the stream and pass it to the callback for processing.
 void *AudioStreamInternalCapture::callbackLoop() {
     aaudio_result_t result = AAUDIO_OK;
-    aaudio_data_callback_result_t callbackResult = AAUDIO_CALLBACK_RESULT_CONTINUE;
+    int32_t callbackResult = 0;
     if (!isDataCallbackSet()) return nullptr;
 
+    uint8_t* buf = mCallbackBuffer.get();
+    int32_t framesToRead = mCallbackFrames;
     // result might be a frame count
     while (mCallbackEnabled.load() && isActive() && (result >= 0)) {
 
         // Read audio data from stream.
-        int64_t timeoutNanos = calculateReasonableTimeout(mCallbackFrames);
+        int64_t timeoutNanos = calculateReasonableTimeout(framesToRead);
 
         // This is a BLOCKING READ!
-        result = read(mCallbackBuffer.get(), mCallbackFrames, timeoutNanos);
-        if ((result != mCallbackFrames)) {
+        result = read(buf, framesToRead, timeoutNanos);
+        if ((result != framesToRead)) {
             ALOGE("callbackLoop: read() returned %d", result);
             if (result >= 0) {
                 // Only read some of the frames requested. The stream can be disconnected
@@ -305,14 +307,23 @@ void *AudioStreamInternalCapture::callbackLoop() {
             break;
         }
 
-        // Call application using the AAudio callback interface.
         callbackResult = maybeCallDataCallback(mCallbackBuffer.get(), mCallbackFrames);
 
-        if (callbackResult == AAUDIO_CALLBACK_RESULT_STOP) {
+        if (callbackResult < 0) {
             ALOGD("%s(): callback returned AAUDIO_CALLBACK_RESULT_STOP", __func__);
             result = systemStopInternal();
             break;
         }
+
+        buf = mCallbackBuffer.get();
+        framesToRead = callbackResult;
+
+        // Client side may only consumes part of the data, copy the left data to the beginning of
+        // callback buffer.
+        const uint8_t* unprocessedBuf = buf + callbackResult * getBytesPerFrame();
+        int32_t bytesLeft = (mCallbackFrames - callbackResult) * getBytesPerFrame();
+        memcpy(buf, unprocessedBuf, bytesLeft);
+        buf += bytesLeft;
     }
 
     ALOGD("callbackLoop() exiting, result = %d, isActive() = %d",
diff --git a/media/libaaudio/src/client/AudioStreamInternalPlay.cpp b/media/libaaudio/src/client/AudioStreamInternalPlay.cpp
index a7ac12e9e6..b01bac3ebe 100644
--- a/media/libaaudio/src/client/AudioStreamInternalPlay.cpp
+++ b/media/libaaudio/src/client/AudioStreamInternalPlay.cpp
@@ -20,8 +20,11 @@
 #define ATRACE_TAG ATRACE_TAG_AUDIO
 
 #include <algorithm>
+#include <chrono>
+#include <thread>
 
 #include <media/MediaMetricsItem.h>
+#include <mediautils/Runnable.h>
 #include <utils/Trace.h>
 
 #include "client/AudioStreamInternalPlay.h"
@@ -70,6 +73,15 @@ aaudio_result_t AudioStreamInternalPlay::open(const AudioStreamBuilder &builder)
         int32_t numFrames = kRampMSec * getSampleRate() / AAUDIO_MILLIS_PER_SECOND;
         mFlowGraph.setRampLengthInFrames(numFrames);
     }
+    if (getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED &&
+        !isDataCallbackSet() && mPresentationEndCallbackProc != nullptr) {
+        // Client is not using data callback but has presentation end callback for offload playback,
+        // initialize an executor for presentation end callback.
+        mStreamEndExecutor.emplace();
+    }
+    mOffloadSafeMarginInFrames = std::max(
+            getDeviceSampleRate() * kOffloadSafeMarginMs / AAUDIO_MILLIS_PER_SECOND,
+            getDeviceFramesPerBurst());
     return result;
 }
 
@@ -88,6 +100,11 @@ aaudio_result_t AudioStreamInternalPlay::requestPause_l()
     mClockModel.stop(AudioClock::getNanoseconds());
     setState(AAUDIO_STREAM_STATE_PAUSING);
     mAtomicInternalTimestamp.clear();
+
+    // When pause is called, the service will notify the HAL so that no more data will be consumed.
+    // In that case, it is no longer needed to wait for stream end.
+    dropPresentationEndCallback();
+
     return mServiceInterface.pauseStream(mServiceStreamHandleInfo);
 }
 
@@ -98,6 +115,11 @@ aaudio_result_t AudioStreamInternalPlay::requestFlush_l() {
     }
 
     setState(AAUDIO_STREAM_STATE_FLUSHING);
+
+    // When flush is called, the service will notify the HAL so that no more data will be consumed.
+    // In that case, it is no longer needed to wait for stream end.
+    dropPresentationEndCallback();
+
     return mServiceInterface.flushStream(mServiceStreamHandleInfo);
 }
 
@@ -124,20 +146,20 @@ void AudioStreamInternalPlay::prepareBuffersForStop() {
     int64_t validFramesInBuffer =
             mAudioEndpoint->getDataWriteCounter() - mAudioEndpoint->getDataReadCounter();
     if (validFramesInBuffer >= 0) {
-        int64_t emptyFramesInBuffer = ((int64_t) getBufferCapacity()) - validFramesInBuffer;
+        int64_t emptyFramesInBuffer = ((int64_t) getDeviceBufferCapacity()) - validFramesInBuffer;
 
         // Prevent stale data from being played if the DSP is still running.
         // Erase some of the FIFO memory in front of the DSP read cursor.
         // Subtract one burst so we do not accidentally erase data that the DSP might be using.
         int64_t framesToErase = std::max((int64_t) 0,
-                                         emptyFramesInBuffer - getFramesPerBurst());
+                                         emptyFramesInBuffer - getDeviceFramesPerBurst());
         mAudioEndpoint->eraseEmptyDataMemory(framesToErase);
 
         // Sleep until we are confident the DSP has consumed all of the valid data.
         // Sleep for one extra burst as a safety margin because the IsochronousClockModel
         // is not perfectly accurate.
         // The ClockModel uses the server frame position so do not use getFramesWritten().
-        int64_t positionInEmptyMemory = mAudioEndpoint->getDataWriteCounter() + getFramesPerBurst();
+        int64_t positionInEmptyMemory = mAudioEndpoint->getDataWriteCounter() + getDeviceFramesPerBurst();
         int64_t timeAllConsumed = mClockModel.convertPositionToTime(positionInEmptyMemory);
         int64_t durationAllConsumed = timeAllConsumed - AudioClock::getNanoseconds();
         // Prevent sleeping for too long.
@@ -232,7 +254,7 @@ aaudio_result_t AudioStreamInternalPlay::processDataNow(void *buffer, int32_t nu
         // This will avoid initial underruns caused by a slow cold start.
         // We add a one burst margin in case the DSP advances before we can write the data.
         // This can help prevent the beginning of the stream from being skipped.
-        advanceClientToMatchServerPosition(getFramesPerBurst());
+        advanceClientToMatchServerPosition(getDeviceFramesPerBurst());
         mNeedCatchUp.acknowledge();
     }
 
@@ -403,18 +425,181 @@ int64_t AudioStreamInternalPlay::getFramesWritten() {
     return mLastFramesWritten;
 }
 
+aaudio_result_t AudioStreamInternalPlay::setOffloadEndOfStream() {
+    if (getPerformanceMode() != AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED ||
+        getSharingMode() != AAUDIO_SHARING_MODE_EXCLUSIVE) {
+        // Offload end of stream callback is only available for offload playback.
+        // Offload playback must be exclusive mode.
+        return AAUDIO_ERROR_UNIMPLEMENTED;
+    }
+    std::lock_guard<std::mutex> lock(mStreamLock);
+    if (getState() != AAUDIO_STREAM_STATE_STARTED || mClockModel.isStarting()) {
+        // If the stream is not running or there is not timestamp from the service side,
+        // it is not possible to set offload end of stream.
+        return AAUDIO_ERROR_INVALID_STATE;
+    }
+    {
+        std::lock_guard<std::mutex> offloadEosLock(mStreamEndMutex);
+        mOffloadEosPending = true;
+    }
+    if (!isDataCallbackSet()) {
+        const int64_t streamEndNanos = mClockModel.convertDeltaPositionToTime(
+                std::max(0, mAudioEndpoint->getFullFramesAvailable() - getDeviceFramesPerBurst()));
+        auto streamPtr = getPtr();
+        mStreamEndExecutor->enqueue(android::mediautils::Runnable{
+            [streamPtr, streamEndNanos]() {
+                std::unique_lock<std::mutex> ul(streamPtr->mStreamEndMutex);
+                streamPtr->mStreamEndCV.wait_for(
+                        ul, std::chrono::nanoseconds(streamEndNanos),
+                        [streamPtr]() { return !streamPtr->mOffloadEosPending; });
+                if (streamPtr->mOffloadEosPending) {
+                    streamPtr->maybeCallPresentationEndCallback();
+                    streamPtr->mOffloadEosPending = false;
+                }
+            }});
+    }
+    return AAUDIO_OK;
+}
+
+bool AudioStreamInternalPlay::shouldStopStream() {
+    if (getPerformanceMode() != AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED) {
+        return true;
+    }
+    std::lock_guard<std::mutex> offloadEosLock(mStreamEndMutex);
+    return !mOffloadEosPending;
+}
+
+void AudioStreamInternalPlay::maybeCallPresentationEndCallback() {
+    if (mPresentationEndCallbackProc != nullptr) {
+        pid_t expected = CALLBACK_THREAD_NONE;
+        if (mPresentationEndCallbackThread.compare_exchange_strong(expected, gettid())) {
+            (*mPresentationEndCallbackProc)(
+                    (AAudioStream *) this, mPresentationEndCallbackUserData);
+            mPresentationEndCallbackThread.store(CALLBACK_THREAD_NONE);
+        } else {
+            ALOGW("%s() presentation end callback already running!", __func__);
+        }
+    }
+}
+
+void AudioStreamInternalPlay::dropPresentationEndCallback() {
+    {
+        std::lock_guard<std::mutex> offloadEosLock(mStreamEndMutex);
+        mOffloadEosPending = false;
+    }
+    mStreamEndCV.notify_one();
+}
+
+aaudio_result_t AudioStreamInternalPlay::requestStop_l() {
+    // When stop is called, the service will notify the HAL so that no more data will be consumed.
+    // In that case, it is no longer needed to wait for stream end.
+    dropPresentationEndCallback();
+    return AudioStreamInternal::requestStop_l();
+}
+
+void AudioStreamInternalPlay::wakeupCallbackThread() {
+    std::lock_guard<std::mutex> _l(mCallbackMutex);
+    mSuspendCallback = false;
+    mCallbackCV.notify_one();
+}
+
+aaudio_result_t AudioStreamInternalPlay::flushFromFrame_l(
+        AAudio_FlushFromAccuracy accuracy, int64_t* position) {
+    if (getServiceHandle() == AAUDIO_HANDLE_INVALID) {
+        ALOGD("%s() mServiceStreamHandle invalid", __func__);
+        return AAUDIO_ERROR_DISCONNECTED;
+    }
+    if (isDisconnected()) {
+        ALOGD("%s() but DISCONNECTED", __func__);
+        return AAUDIO_ERROR_DISCONNECTED;
+    }
+
+    aaudio_result_t result = AAUDIO_OK;
+    {
+        std::lock_guard _endpointLock(mEndpointMutex);
+        int64_t framesWritten = getFramesWritten();
+        if (framesWritten < *position) {
+            ALOGE("%s(), the requested position is not yet written", __func__);
+            result = AAUDIO_ERROR_OUT_OF_RANGE;
+        }
+
+        // The position is updated from the server, it may not be very accurate if the stream has
+        // been active for a while. In that case, updates the latest timestamp and then get the
+        // actual rewind position again.
+        if (aaudio_result_t res = mServiceInterface.updateTimestamp(mServiceStreamHandleInfo);
+                res != AAUDIO_OK) {
+            ALOGE("%s() failed to update timestamp, error=%d", __func__, res);
+            return res;
+        }
+        processCommands();
+        const int64_t safePosition = getFramesRead() + mOffloadSafeMarginInFrames;
+        if (safePosition > framesWritten) {
+            ALOGE("%s() do not have enough data, safePosition=%jd, frameWritten=%jd",
+                  __func__, safePosition, framesWritten);
+            return AAUDIO_ERROR_OUT_OF_RANGE;
+        }
+        int64_t actualPosition = std::max(safePosition, *position);
+        if (accuracy == AAUDIO_FLUSH_FROM_FRAME_ACCURATE && actualPosition != *position) {
+            result = AAUDIO_ERROR_OUT_OF_RANGE;
+        }
+        if (result != AAUDIO_OK) {
+            *position = actualPosition;
+            return result;
+        }
+
+        // Rewind successfully, update the written position as the rewound position.
+        mLastFramesWritten = actualPosition;
+        mAudioEndpoint->setDataWriteCounter(actualPosition - mFramesOffsetFromService);
+    }
+    {
+        std::lock_guard _streamEndLock(mStreamEndMutex);
+        mOffloadEosPending = false;
+    }
+    wakeupCallbackThread();
+    return result;
+}
+
 // Render audio in the application callback and then write the data to the stream.
 void *AudioStreamInternalPlay::callbackLoop() {
     ALOGD("%s() entering >>>>>>>>>>>>>>>", __func__);
     aaudio_result_t result = AAUDIO_OK;
-    aaudio_data_callback_result_t callbackResult = AAUDIO_CALLBACK_RESULT_CONTINUE;
+    int32_t callbackResult = 0;
     if (!isDataCallbackSet()) return nullptr;
     int64_t timeoutNanos = calculateReasonableTimeout(mCallbackFrames);
 
     // result might be a frame count
     while (mCallbackEnabled.load() && isActive() && (result >= 0)) {
-        // Call application using the AAudio callback interface.
-        callbackResult = maybeCallDataCallback(mCallbackBuffer.get(), mCallbackFrames);
+        processCommands();
+        {
+            std::unique_lock<std::mutex> ul(mStreamEndMutex);
+            if (mOffloadEosPending) {
+                const int64_t streamEndNanos = mClockModel.convertDeltaPositionToTime(std::max(0,
+                        mAudioEndpoint->getFullFramesAvailable() - getDeviceFramesPerBurst()));
+                mStreamEndCV.wait_for(
+                        ul, std::chrono::nanoseconds(streamEndNanos),
+                        [this]() { return !mOffloadEosPending; });
+                if (mOffloadEosPending) {
+                    maybeCallPresentationEndCallback();
+                    mOffloadEosPending = false;
+                }
+            }
+        }
+        {
+            std::lock_guard _endpointLock(mEndpointMutex);
+            // Call application using the AAudio callback interface.
+            callbackResult = maybeCallDataCallback(mCallbackBuffer.get(), mCallbackFrames);
+        }
+
+        if (callbackResult < 0) {
+            if (!shouldStopStream()) {
+                ALOGD("%s(): callback request to stop but should not as it may be pending for"
+                      "stream end", __func__);
+                continue;
+            }
+            ALOGD("%s(): callback request to stop", __func__);
+            result = systemStopInternal();
+            break;
+        }
 
         // Write audio data to stream. This is a BLOCKING WRITE!
         // Write data regardless of the callbackResult because we assume the data
@@ -423,8 +608,8 @@ void *AudioStreamInternalPlay::callbackLoop() {
         // When it gets to the end of the sound it can partially fill
         // the last buffer with the end of the sound, then zero pad the buffer, then return STOP.
         // If the callback has no valid data then it should zero-fill the entire buffer.
-        result = write(mCallbackBuffer.get(), mCallbackFrames, timeoutNanos);
-        if ((result != mCallbackFrames)) {
+        result = write(mCallbackBuffer.get(), callbackResult, timeoutNanos);
+        if ((result != callbackResult)) {
             if (result >= 0) {
                 // Only wrote some of the frames requested. The stream can be disconnected
                 // or timed out.
@@ -435,10 +620,20 @@ void *AudioStreamInternalPlay::callbackLoop() {
             break;
         }
 
-        if (callbackResult == AAUDIO_CALLBACK_RESULT_STOP) {
-            ALOGD("%s(): callback returned AAUDIO_CALLBACK_RESULT_STOP", __func__);
-            result = systemStopInternal();
-            break;
+        if (getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED &&
+            isClockModelInControl()) {
+            // If it is an offload playback and the buffer is pretty full, sleep to drain data
+            // to save battery.
+            int32_t fullFrames = mAudioEndpoint->getFullFramesAvailable();
+            if (fullFrames > getDeviceBufferSize() - mOffloadSafeMarginInFrames) {
+                int64_t drainNanos = mClockModel.convertDeltaPositionToTime(
+                        std::max(fullFrames - mOffloadSafeMarginInFrames, 0));
+                std::unique_lock<std::mutex> ul(mStreamEndMutex);
+                mSuspendCallback = true;
+                mCallbackCV.wait_for(
+                        ul, std::chrono::nanoseconds(drainNanos),
+                        [this]() { return !mSuspendCallback; });
+            }
         }
     }
 
diff --git a/media/libaaudio/src/client/AudioStreamInternalPlay.h b/media/libaaudio/src/client/AudioStreamInternalPlay.h
index 4e14f18c00..2b6a60b965 100644
--- a/media/libaaudio/src/client/AudioStreamInternalPlay.h
+++ b/media/libaaudio/src/client/AudioStreamInternalPlay.h
@@ -17,8 +17,13 @@
 #ifndef ANDROID_AAUDIO_AUDIO_STREAM_INTERNAL_PLAY_H
 #define ANDROID_AAUDIO_AUDIO_STREAM_INTERNAL_PLAY_H
 
+#include <condition_variable>
+#include <mutex>
 #include <stdint.h>
+#include <thread>
+
 #include <aaudio/AAudio.h>
+#include <mediautils/SingleThreadExecutor.h>
 
 #include "binding/AAudioServiceInterface.h"
 #include "client/AudioStreamInternal.h"
@@ -62,6 +67,16 @@ public:
         return AAUDIO_DIRECTION_OUTPUT;
     }
 
+    aaudio_result_t setOffloadEndOfStream() EXCLUDES(mStreamLock) final;
+
+    void setPresentationEndCallbackProc(AAudioStream_presentationEndCallback proc) final {
+        mPresentationEndCallbackProc = proc;
+    }
+
+    void setPresentationEndCallbackUserData(void *userData) final {
+        mPresentationEndCallbackUserData = userData;
+    }
+
 protected:
 
     void prepareBuffersForStart() override;
@@ -85,6 +100,12 @@ protected:
                              int32_t numFrames,
                              int64_t currentTimeNanos,
                              int64_t *wakeTimePtr) override;
+
+    aaudio_result_t requestStop_l() REQUIRES(mStreamLock) final;
+
+    void wakeupCallbackThread() final;
+    aaudio_result_t flushFromFrame_l(AAudio_FlushFromAccuracy accuracy, int64_t* position)
+            REQUIRES(mStreamLock) final;
 private:
     /*
      * Asynchronous write with data conversion.
@@ -95,6 +116,27 @@ private:
     aaudio_result_t writeNowWithConversion(const void *buffer,
                                            int32_t numFrames);
 
+    bool shouldStopStream();
+    void maybeCallPresentationEndCallback();
+    void dropPresentationEndCallback();
+
+    android::sp<AudioStreamInternalPlay> getPtr() { return this; }
+
+    bool mOffloadEosPending GUARDED_BY(mStreamEndMutex){false};
+    std::mutex mStreamEndMutex;
+    std::condition_variable mStreamEndCV;
+    std::optional<android::mediautils::SingleThreadExecutor> mStreamEndExecutor;
+    AAudioStream_presentationEndCallback mPresentationEndCallbackProc = nullptr;
+    void                                *mPresentationEndCallbackUserData = nullptr;
+    std::atomic<pid_t>                   mPresentationEndCallbackThread{CALLBACK_THREAD_NONE};
+
+    static constexpr int32_t kOffloadSafeMarginMs = 100;
+    int32_t mOffloadSafeMarginInFrames = 0;
+    std::mutex mCallbackMutex;
+    std::condition_variable mCallbackCV;
+    bool mSuspendCallback GUARDED_BY(mCallbackMutex){false};
+
+    std::mutex mEndpointMutex;
 };
 
 } /* namespace aaudio */
diff --git a/media/libaaudio/src/core/AAudioAudio.cpp b/media/libaaudio/src/core/AAudioAudio.cpp
index ecffcbd49f..d0567cf71a 100644
--- a/media/libaaudio/src/core/AAudioAudio.cpp
+++ b/media/libaaudio/src/core/AAudioAudio.cpp
@@ -25,6 +25,8 @@
 
 #include <aaudio/AAudio.h>
 #include <aaudio/AAudioTesting.h>
+#include <com_android_media_aaudio.h>
+#include <com_android_media_audioserver.h>
 #include <system/aaudio/AAudio.h>
 #include <system/audio.h>
 #include "AudioClock.h"
@@ -250,6 +252,20 @@ AAUDIO_API void AAudioStreamBuilder_setDataCallback(AAudioStreamBuilder* builder
     streamBuilder->setDataCallbackUserData(userData);
 }
 
+AAUDIO_API aaudio_result_t AAudioStreamBuilder_setPartialDataCallback(
+        AAudioStreamBuilder* builder,
+        AAudioStream_partialDataCallback callback,
+        void *userData)
+{
+    if (!com::android::media::aaudio::new_data_callback()) {
+        return AAUDIO_ERROR_UNIMPLEMENTED;
+    }
+    AudioStreamBuilder *streamBuilder = convertAAudioBuilderToStreamBuilder(builder);
+    streamBuilder->setPartialDataCallbackProc(callback)
+                 ->setDataCallbackUserData(userData);
+    return AAUDIO_OK;
+}
+
 AAUDIO_API void AAudioStreamBuilder_setErrorCallback(AAudioStreamBuilder* builder,
                                                  AAudioStream_errorCallback callback,
                                                  void *userData)
@@ -295,11 +311,18 @@ AAUDIO_API aaudio_result_t  AAudioStreamBuilder_openStream(AAudioStreamBuilder*
     if (result == AAUDIO_OK) {
         *streamPtr = (AAudioStream*) audioStream;
         id = audioStream->getId();
+        ALOGI("%s() got %s, devIds = [%s], perf = %s, burst = %d",
+              __func__,
+              (audioStream->isMMap() ? "MMAP" : "Legacy"),
+              android::toString(audioStream->getDeviceIds()).c_str(),
+              AudioGlobal_convertPerformanceModeToShortText(audioStream->getPerformanceMode()),
+              audioStream->getFramesPerBurst()
+              );
     } else {
         *streamPtr = nullptr;
     }
     ALOGI("%s() returns %d = %s for s#%u ----------------",
-        __func__, result, AAudio_convertResultToText(result), id);
+          __func__, result, AAudio_convertResultToText(result), id);
     return result;
 }
 
@@ -754,3 +777,12 @@ AAUDIO_API aaudio_result_t AAudioStream_setOffloadEndOfStream(AAudioStream* stre
     AudioStream *audioStream = convertAAudioStreamToAudioStream(stream);
     return audioStream->setOffloadEndOfStream();
 }
+
+AAUDIO_API aaudio_result_t AAudioStream_flushFromFrame(
+        AAudioStream* stream, AAudio_FlushFromAccuracy accuracy, int64_t* inOutPosition) {
+    if (!com::android::media::audioserver::mmap_pcm_offload_support()) {
+        return AAUDIO_ERROR_UNIMPLEMENTED;
+    }
+    AudioStream *audioStream = convertAAudioStreamToAudioStream(stream);
+    return audioStream->flushFromFrame(accuracy, inOutPosition);
+}
diff --git a/media/libaaudio/src/core/AAudioStreamParameters.cpp b/media/libaaudio/src/core/AAudioStreamParameters.cpp
index 3090fb24c4..2282f69351 100644
--- a/media/libaaudio/src/core/AAudioStreamParameters.cpp
+++ b/media/libaaudio/src/core/AAudioStreamParameters.cpp
@@ -49,6 +49,7 @@ void AAudioStreamParameters::copyFrom(const AAudioStreamParameters &other) {
     mHardwareSamplesPerFrame = other.mHardwareSamplesPerFrame;
     mHardwareSampleRate   = other.mHardwareSampleRate;
     mHardwareAudioFormat  = other.mHardwareAudioFormat;
+    mPerformanceMode      = other.mPerformanceMode;
 }
 
 static aaudio_result_t isFormatValid(audio_format_t format) {
@@ -218,6 +219,27 @@ aaudio_result_t AAudioStreamParameters::validate() const {
         return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
     }
 
+    switch (mPerformanceMode) {
+        case AAUDIO_PERFORMANCE_MODE_NONE:
+        case AAUDIO_PERFORMANCE_MODE_POWER_SAVING:
+        case AAUDIO_PERFORMANCE_MODE_LOW_LATENCY:
+            break;
+        case AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED:
+            if (mDirection != AAUDIO_DIRECTION_OUTPUT ||
+                mAudioFormat == AUDIO_FORMAT_DEFAULT ||
+                mSampleRate == 0 ||
+                mChannelMask == AAUDIO_UNSPECIFIED) {
+                ALOGD("%s invalid configuration when performance mode is power saving offloaded, "
+                      "direction=%d, format=%#x, sampleRate=%d, channelMask=%#x",
+                      __func__, mDirection, mAudioFormat, mSampleRate, mChannelMask);
+                return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
+            }
+            break;
+        default:
+            ALOGD("%s unknown performance mode = %d", __func__, mPerformanceMode);
+            return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
+    }
+
     return validateChannelMask();
 }
 
@@ -337,4 +359,5 @@ void AAudioStreamParameters::dump() const {
     ALOGD("mHardwareSamplesPerFrame = %6d", mHardwareSamplesPerFrame);
     ALOGD("mHardwareSampleRate   = %6d", mHardwareSampleRate);
     ALOGD("mHardwareAudioFormat  = %6d", (int)mHardwareAudioFormat);
+    ALOGD("mPerformanceMode      = %6d", (int)mPerformanceMode);
 }
diff --git a/media/libaaudio/src/core/AAudioStreamParameters.h b/media/libaaudio/src/core/AAudioStreamParameters.h
index 94c5e8980d..3de4706399 100644
--- a/media/libaaudio/src/core/AAudioStreamParameters.h
+++ b/media/libaaudio/src/core/AAudioStreamParameters.h
@@ -213,6 +213,14 @@ public:
         return getSamplesPerFrame() * audio_bytes_per_sample(getFormat());
     }
 
+    aaudio_performance_mode_t getPerformanceMode() const {
+        return mPerformanceMode;
+    }
+
+    void setPerformanceMode(aaudio_performance_mode_t performanceMode) {
+        mPerformanceMode = performanceMode;
+    }
+
     /**
      * Copy variables defined in other AAudioStreamParameters instance to this one.
      * @param other
@@ -252,6 +260,7 @@ private:
                                                           = AAUDIO_UNSPECIFIED;
     int                             mHardwareSampleRate   = AAUDIO_UNSPECIFIED;
     audio_format_t                  mHardwareAudioFormat  = AUDIO_FORMAT_DEFAULT;
+    aaudio_performance_mode_t       mPerformanceMode      = AAUDIO_PERFORMANCE_MODE_NONE;
 };
 
 } /* namespace aaudio */
diff --git a/media/libaaudio/src/core/AudioGlobal.cpp b/media/libaaudio/src/core/AudioGlobal.cpp
index 3268488109..a058301d75 100644
--- a/media/libaaudio/src/core/AudioGlobal.cpp
+++ b/media/libaaudio/src/core/AudioGlobal.cpp
@@ -37,12 +37,12 @@ using android::media::audio::common::AudioMMapPolicyType;
 static aaudio_policy_t g_MMapPolicy = AAUDIO_UNSPECIFIED;
 
 aaudio_policy_t AudioGlobal_getMMapPolicy() {
-  return g_MMapPolicy;
+    return g_MMapPolicy;
 }
 
 aaudio_result_t AudioGlobal_setMMapPolicy(aaudio_policy_t policy) {
     aaudio_result_t result = AAUDIO_OK;
-    switch(policy) {
+    switch (policy) {
         case AAUDIO_UNSPECIFIED:
         case AAUDIO_POLICY_NEVER:
         case AAUDIO_POLICY_AUTO:
@@ -63,13 +63,13 @@ const char* AudioGlobal_convertResultToText(aaudio_result_t returnCode) {
         AAUDIO_CASE_ENUM(AAUDIO_OK);
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_DISCONNECTED);
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_ILLEGAL_ARGUMENT);
-        // reserved
+            // reserved
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_INTERNAL);
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_INVALID_STATE);
-        // reserved
-        // reserved
+            // reserved
+            // reserved
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_INVALID_HANDLE);
-         // reserved
+            // reserved
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_UNIMPLEMENTED);
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_UNAVAILABLE);
         AAUDIO_CASE_ENUM(AAUDIO_ERROR_NO_FREE_HANDLES);
@@ -86,7 +86,7 @@ const char* AudioGlobal_convertResultToText(aaudio_result_t returnCode) {
 }
 
 const char* AudioGlobal_convertFormatToText(aaudio_format_t format) {
-      switch (format) {
+    switch (format) {
         AAUDIO_CASE_ENUM(AAUDIO_FORMAT_UNSPECIFIED);
         AAUDIO_CASE_ENUM(AAUDIO_FORMAT_INVALID);
         AAUDIO_CASE_ENUM(AAUDIO_FORMAT_PCM_I16);
@@ -99,7 +99,7 @@ const char* AudioGlobal_convertFormatToText(aaudio_format_t format) {
 }
 
 const char* AudioGlobal_convertDirectionToText(aaudio_direction_t direction) {
-      switch (direction) {
+    switch (direction) {
         AAUDIO_CASE_ENUM(AAUDIO_DIRECTION_INPUT);
         AAUDIO_CASE_ENUM(AAUDIO_DIRECTION_OUTPUT);
     }
@@ -107,7 +107,7 @@ const char* AudioGlobal_convertDirectionToText(aaudio_direction_t direction) {
 }
 
 const char* AudioGlobal_convertPerformanceModeToText(aaudio_performance_mode_t mode) {
-      switch (mode) {
+    switch (mode) {
         AAUDIO_CASE_ENUM(AAUDIO_PERFORMANCE_MODE_POWER_SAVING);
         AAUDIO_CASE_ENUM(AAUDIO_PERFORMANCE_MODE_NONE);
         AAUDIO_CASE_ENUM(AAUDIO_PERFORMANCE_MODE_LOW_LATENCY);
@@ -115,8 +115,28 @@ const char* AudioGlobal_convertPerformanceModeToText(aaudio_performance_mode_t m
     return "Unrecognized";
 }
 
+const char* AudioGlobal_convertPerformanceModeToShortText(aaudio_performance_mode_t mode) {
+    switch (mode) {
+        case AAUDIO_PERFORMANCE_MODE_NONE:
+            return "NO";
+            break;
+        case AAUDIO_PERFORMANCE_MODE_POWER_SAVING:
+            return "PS";
+            break;
+        case AAUDIO_PERFORMANCE_MODE_LOW_LATENCY:
+            return "LL";
+            break;
+        case AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED:
+            return "OF";
+            break;
+        default:
+            return "??";
+            break;
+    }
+}
+
 const char* AudioGlobal_convertSharingModeToText(aaudio_sharing_mode_t mode) {
-      switch (mode) {
+    switch (mode) {
         AAUDIO_CASE_ENUM(AAUDIO_SHARING_MODE_SHARED);
         AAUDIO_CASE_ENUM(AAUDIO_SHARING_MODE_EXCLUSIVE);
     }
@@ -124,7 +144,7 @@ const char* AudioGlobal_convertSharingModeToText(aaudio_sharing_mode_t mode) {
 }
 
 const char* AudioGlobal_convertStreamStateToText(aaudio_stream_state_t state) {
-      switch (state) {
+    switch (state) {
         AAUDIO_CASE_ENUM(AAUDIO_STREAM_STATE_UNINITIALIZED);
         AAUDIO_CASE_ENUM(AAUDIO_STREAM_STATE_UNKNOWN);
         AAUDIO_CASE_ENUM(AAUDIO_STREAM_STATE_OPEN);
diff --git a/media/libaaudio/src/core/AudioGlobal.h b/media/libaaudio/src/core/AudioGlobal.h
index c4ef87dece..51ff697b01 100644
--- a/media/libaaudio/src/core/AudioGlobal.h
+++ b/media/libaaudio/src/core/AudioGlobal.h
@@ -38,6 +38,7 @@ aaudio_result_t AudioGlobal_setMMapPolicy(aaudio_policy_t policy);
 const char* AudioGlobal_convertFormatToText(aaudio_format_t format);
 const char* AudioGlobal_convertDirectionToText(aaudio_direction_t direction);
 const char* AudioGlobal_convertPerformanceModeToText(aaudio_performance_mode_t mode);
+const char* AudioGlobal_convertPerformanceModeToShortText(aaudio_performance_mode_t mode);
 const char* AudioGlobal_convertResultToText(aaudio_result_t returnCode);
 const char* AudioGlobal_convertSharingModeToText(aaudio_sharing_mode_t mode);
 const char* AudioGlobal_convertStreamStateToText(aaudio_stream_state_t state);
diff --git a/media/libaaudio/src/core/AudioStream.cpp b/media/libaaudio/src/core/AudioStream.cpp
index 2f65faf6f5..123b70519a 100644
--- a/media/libaaudio/src/core/AudioStream.cpp
+++ b/media/libaaudio/src/core/AudioStream.cpp
@@ -19,6 +19,7 @@
 #include <utils/Log.h>
 
 #include <atomic>
+#include <functional>
 #include <stdint.h>
 
 #include <linux/futex.h>
@@ -27,6 +28,7 @@
 
 #include <aaudio/AAudio.h>
 #include <android-base/strings.h>
+#include <com_android_media_audioserver.h>
 
 #include "AudioStreamBuilder.h"
 #include "AudioStream.h"
@@ -114,6 +116,12 @@ aaudio_result_t AudioStream::open(const AudioStreamBuilder& builder)
     // callbacks
     mFramesPerDataCallback = builder.getFramesPerDataCallback();
     mDataCallbackProc = builder.getDataCallbackProc();
+    mPartialDataCallbackProc = builder.getPartialDataCallbackProc();
+    if (mPartialDataCallbackProc != nullptr) {
+        mDataCallbackWrapper = &AudioStream::partialDataCallbackInternal;
+    } else if (mDataCallbackProc != nullptr) {
+        mDataCallbackWrapper = &AudioStream::dataCallbackInternal;
+    }
     mErrorCallbackProc = builder.getErrorCallbackProc();
     mDataCallbackUserData = builder.getDataCallbackUserData();
     mErrorCallbackUserData = builder.getErrorCallbackUserData();
@@ -583,23 +591,16 @@ aaudio_result_t AudioStream::joinThread_l(void** returnArg) {
     return (result != AAUDIO_OK) ? result : mThreadRegistrationResult;
 }
 
-aaudio_data_callback_result_t AudioStream::maybeCallDataCallback(void *audioData,
-                                                                 int32_t numFrames) {
-    aaudio_data_callback_result_t result = AAUDIO_CALLBACK_RESULT_STOP;
-    AAudioStream_dataCallback dataCallback = getDataCallbackProc();
-    if (dataCallback != nullptr) {
-        // Store thread ID of caller to detect stop() and close() calls from callback.
-        pid_t expected = CALLBACK_THREAD_NONE;
-        if (mDataCallbackThread.compare_exchange_strong(expected, gettid())) {
-            result = (*dataCallback)(
-                    (AAudioStream *) this,
-                    getDataCallbackUserData(),
-                    audioData,
-                    numFrames);
-            mDataCallbackThread.store(CALLBACK_THREAD_NONE);
-        } else {
-            ALOGW("%s() data callback already running!", __func__);
-        }
+int32_t AudioStream::maybeCallDataCallback(void *audioData, int32_t numFrames) {
+    int32_t result = -1;
+    auto dataCallback = getDataCallbackWrapper();
+    // Store thread ID of caller to detect stop() and close() calls from callback.
+    pid_t expected = CALLBACK_THREAD_NONE;
+    if (mDataCallbackThread.compare_exchange_strong(expected, gettid())) {
+        result = std::invoke(dataCallback, this, audioData, numFrames);
+        mDataCallbackThread.store(CALLBACK_THREAD_NONE);
+    } else {
+        ALOGW("%s() data callback already running!", __func__);
     }
     return result;
 }
@@ -669,6 +670,50 @@ std::string AudioStream::getTagsAsString() const {
     return android::base::Join(mTags, AUDIO_ATTRIBUTES_TAGS_SEPARATOR);
 }
 
+aaudio_result_t AudioStream::flushFromFrame(AAudio_FlushFromAccuracy accuracy, int64_t* position) {
+    ALOGD("%s(%d, %jd)", __func__, accuracy, *position);
+    if (!com_android_media_audioserver_mmap_pcm_offload_support()) {
+        return AAUDIO_ERROR_UNIMPLEMENTED;
+    }
+    if (getDirection() != AAUDIO_DIRECTION_OUTPUT ||
+        getPerformanceMode() != AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED ||
+        (accuracy != AAUDIO_FLUSH_FROM_ACCURACY_UNDEFINED &&
+                accuracy != AAUDIO_FLUSH_FROM_FRAME_ACCURATE)) {
+        return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
+    }
+    if (*position < 0) {
+        return AAUDIO_ERROR_OUT_OF_RANGE;
+    }
+    const int64_t requestedPosition = *position;
+    std::lock_guard lock(mStreamLock);
+    const aaudio_result_t result = flushFromFrame_l(accuracy, position);
+    ALOGD("%s(%d, %jd), actual position = %jd, result = %d",
+          __func__, accuracy, requestedPosition, *position, result);
+    return result;
+}
+
+int AudioStream::dataCallbackInternal(void *audioData, int32_t numFrames) {
+    const aaudio_data_callback_result_t result = std::invoke(mDataCallbackProc,
+            (AAudioStream*) this,
+            getDataCallbackUserData(),
+            audioData,
+            numFrames);
+    // Return negative values to indicate STOP
+    return result == AAUDIO_CALLBACK_RESULT_CONTINUE ? numFrames : -1;
+}
+
+int AudioStream::partialDataCallbackInternal(void *audioData, int32_t numFrames) {
+    const int framesProcessed = std::invoke(
+            mPartialDataCallbackProc, (AAudioStream*) this, getDataCallbackUserData(),
+            audioData, numFrames);
+    if (framesProcessed > numFrames) {
+        ALOGE("%s client returned wrong frames processed=%d, provided=%d",
+              __func__, framesProcessed, numFrames);
+        return -1;
+    }
+    return framesProcessed;
+}
+
 void AudioStream::MyPlayerBase::registerWithAudioManager(const android::sp<AudioStream>& parent) {
     std::lock_guard<std::mutex> lock(mParentLock);
     mParent = parent;
diff --git a/media/libaaudio/src/core/AudioStream.h b/media/libaaudio/src/core/AudioStream.h
index 38ed5bec91..67de5a93eb 100644
--- a/media/libaaudio/src/core/AudioStream.h
+++ b/media/libaaudio/src/core/AudioStream.h
@@ -96,6 +96,12 @@ protected:
 
     virtual aaudio_result_t requestStop_l() REQUIRES(mStreamLock) = 0;
 
+    virtual aaudio_result_t flushFromFrame_l(AAudio_FlushFromAccuracy accuracy [[maybe_unused]],
+                                             int64_t* position [[maybe_unused]])
+                                             REQUIRES(mStreamLock) {
+        return AAUDIO_ERROR_UNIMPLEMENTED;
+    }
+
 public:
     virtual aaudio_result_t getTimestamp(clockid_t clockId,
                                        int64_t *framePosition,
@@ -282,6 +288,10 @@ public:
         return mSharingModeMatchRequired;
     }
 
+    void setSharingModeMatchRequired(bool sharingModeMatchRequired) {
+        mSharingModeMatchRequired = sharingModeMatchRequired;
+    }
+
     virtual aaudio_direction_t getDirection() const = 0;
 
     aaudio_usage_t getUsage() const {
@@ -354,15 +364,16 @@ public:
 
     virtual int64_t getFramesRead() = 0;
 
-    AAudioStream_dataCallback getDataCallbackProc() const {
-        return mDataCallbackProc;
+    typedef int (AudioStream::*DataCallbackWrapper)(void* audioData, int32_t numFrames);
+    DataCallbackWrapper getDataCallbackWrapper() const {
+        return mDataCallbackWrapper;
     }
 
     AAudioStream_errorCallback getErrorCallbackProc() const {
         return mErrorCallbackProc;
     }
 
-    aaudio_data_callback_result_t maybeCallDataCallback(void *audioData, int32_t numFrames);
+    int32_t maybeCallDataCallback(void *audioData, int32_t numFrames);
 
     void maybeCallErrorCallback(aaudio_result_t result);
 
@@ -414,7 +425,7 @@ public:
      * @return true if data callback has been specified
      */
     bool isDataCallbackSet() const {
-        return mDataCallbackProc != nullptr;
+        return mDataCallbackWrapper != nullptr;
     }
 
     /**
@@ -516,6 +527,9 @@ public:
 
     aaudio_result_t safeReleaseCloseInternal() EXCLUDES(mStreamLock);
 
+    aaudio_result_t flushFromFrame(AAudio_FlushFromAccuracy accuracy, int64_t* position)
+            EXCLUDES(mStreamLock);
+
 protected:
 
     // PlayerBase allows the system to control the stream volume.
@@ -786,6 +800,9 @@ private:
         close_l();
     }
 
+    int dataCallbackInternal(void* audioData, int32_t numFrames);
+    int partialDataCallbackInternal(void* audioData, int32_t numFrames);
+
     std::atomic<aaudio_stream_state_t>          mState{AAUDIO_STREAM_STATE_UNINITIALIZED};
 
     std::atomic_bool            mDisconnected{false};
@@ -832,6 +849,8 @@ private:
     void                       *mDataCallbackUserData = nullptr;
     int32_t                     mFramesPerDataCallback = AAUDIO_UNSPECIFIED; // frames
     std::atomic<pid_t>          mDataCallbackThread{CALLBACK_THREAD_NONE};
+    AAudioStream_partialDataCallback mPartialDataCallbackProc = nullptr;
+    DataCallbackWrapper         mDataCallbackWrapper = nullptr;
 
     AAudioStream_errorCallback  mErrorCallbackProc = nullptr;
     void                       *mErrorCallbackUserData = nullptr;
diff --git a/media/libaaudio/src/core/AudioStreamBuilder.cpp b/media/libaaudio/src/core/AudioStreamBuilder.cpp
index a88052de0b..4bda70d86d 100644
--- a/media/libaaudio/src/core/AudioStreamBuilder.cpp
+++ b/media/libaaudio/src/core/AudioStreamBuilder.cpp
@@ -170,9 +170,11 @@ aaudio_result_t AudioStreamBuilder::build(AudioStream** streamPtr) {
     bool allowLegacy = mmapPolicy != AAUDIO_POLICY_ALWAYS;
 
     // TODO Support other performance settings in MMAP mode.
-    // Disable MMAP if low latency not requested.
-    if (getPerformanceMode() != AAUDIO_PERFORMANCE_MODE_LOW_LATENCY) {
-        ALOGD("%s() MMAP not used because AAUDIO_PERFORMANCE_MODE_LOW_LATENCY not requested.",
+    // Disable MMAP if low latency or power saving offloaded is not requested.
+    if (getPerformanceMode() != AAUDIO_PERFORMANCE_MODE_LOW_LATENCY &&
+        getPerformanceMode() != AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED) {
+        ALOGD("%s() MMAP not used because AAUDIO_PERFORMANCE_MODE_LOW_LATENCY or "
+              "AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED not requested.",
               __func__);
         allowMMap = false;
     }
@@ -263,25 +265,6 @@ aaudio_result_t AudioStreamBuilder::validate() const {
         return result;
     }
 
-    switch (mPerformanceMode) {
-        case AAUDIO_PERFORMANCE_MODE_NONE:
-        case AAUDIO_PERFORMANCE_MODE_POWER_SAVING:
-        case AAUDIO_PERFORMANCE_MODE_LOW_LATENCY:
-            break;
-        case AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED:
-            if (getDirection() != AAUDIO_DIRECTION_OUTPUT ||
-                getFormat() == AUDIO_FORMAT_DEFAULT ||
-                getSampleRate() == 0 ||
-                getChannelMask() == AAUDIO_UNSPECIFIED) {
-                return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
-            }
-            break;
-        default:
-            ALOGE("illegal performanceMode = %d", mPerformanceMode);
-            return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
-            // break;
-    }
-
     // Prevent ridiculous values from causing problems.
     if (mFramesPerDataCallback != AAUDIO_UNSPECIFIED
         && (mFramesPerDataCallback < FRAMES_PER_DATA_CALLBACK_MIN
@@ -336,7 +319,7 @@ static const char *AAudio_convertDirectionToText(aaudio_direction_t direction) {
 
 void AudioStreamBuilder::logParameters() const {
     // This is very helpful for debugging in the future. Please leave it in.
-    ALOGI("rate   = %6d, channels  = %d, channelMask = %#x, format   = %d, sharing = %s, dir = %s",
+    ALOGI("rate   = %6d, channels  = %d, channelMask = %#x, format   = %#x, sharing = %s, dir = %s",
           getSampleRate(), getSamplesPerFrame(), getChannelMask(), getFormat(),
           AAudio_convertSharingModeToShortText(getSharingMode()),
           AAudio_convertDirectionToText(getDirection()));
@@ -344,7 +327,9 @@ void AudioStreamBuilder::logParameters() const {
           android::toString(getDeviceIds()).c_str(),
           getSessionId(),
           getPerformanceMode(),
-          ((getDataCallbackProc() != nullptr) ? "ON" : "OFF"),
+          ((getPartialDataCallbackProc() != nullptr) ? "ON_P"
+                                                     : (getDataCallbackProc() != nullptr) ? "ON"
+                                                                                          : "OFF"),
           mFramesPerDataCallback);
     ALOGI("usage  = %6d, contentType = %d, inputPreset = %d, allowedCapturePolicy = %d",
           getUsage(), getContentType(), getInputPreset(), getAllowedCapturePolicy());
diff --git a/media/libaaudio/src/core/AudioStreamBuilder.h b/media/libaaudio/src/core/AudioStreamBuilder.h
index 4f66f5b0ae..11a811a431 100644
--- a/media/libaaudio/src/core/AudioStreamBuilder.h
+++ b/media/libaaudio/src/core/AudioStreamBuilder.h
@@ -45,24 +45,30 @@ public:
         return this;
     }
 
-    int32_t getPerformanceMode() const {
-        return mPerformanceMode;
+    AAudioStream_dataCallback getDataCallbackProc() const {
+        return mDataCallbackProc;
     }
 
-    AudioStreamBuilder* setPerformanceMode(aaudio_performance_mode_t performanceMode) {
-        mPerformanceMode = performanceMode;
+    AudioStreamBuilder* setDataCallbackProc(AAudioStream_dataCallback proc) {
+        mDataCallbackProc = proc;
+        mPartialDataCallbackProc = nullptr;
         return this;
     }
 
-    AAudioStream_dataCallback getDataCallbackProc() const {
-        return mDataCallbackProc;
+    AAudioStream_partialDataCallback getPartialDataCallbackProc() const {
+        return mPartialDataCallbackProc;
     }
 
-    AudioStreamBuilder* setDataCallbackProc(AAudioStream_dataCallback proc) {
-        mDataCallbackProc = proc;
+    AudioStreamBuilder* setPartialDataCallbackProc(AAudioStream_partialDataCallback proc) {
+        mPartialDataCallbackProc = proc;
+        mDataCallbackProc = nullptr;
         return this;
     }
 
+    bool isDataCallbackSet() const {
+        return mDataCallbackProc != nullptr || mPartialDataCallbackProc != nullptr;
+    }
+
     void *getDataCallbackUserData() const {
         return mDataCallbackUserData;
     }
@@ -142,12 +148,13 @@ private:
     static AudioStream *startUsingStream(android::sp<AudioStream> &spAudioStream);
 
     bool                       mSharingModeMatchRequired = false; // must match sharing mode requested
-    aaudio_performance_mode_t  mPerformanceMode = AAUDIO_PERFORMANCE_MODE_NONE;
 
     AAudioStream_dataCallback  mDataCallbackProc = nullptr;  // external callback functions
     void                      *mDataCallbackUserData = nullptr;
     int32_t                    mFramesPerDataCallback = AAUDIO_UNSPECIFIED; // frames
 
+    AAudioStream_partialDataCallback mPartialDataCallbackProc = nullptr;
+
     AAudioStream_errorCallback mErrorCallbackProc = nullptr;
     void                      *mErrorCallbackUserData = nullptr;
 
diff --git a/media/libaaudio/src/flowgraph/RampLinear.cpp b/media/libaaudio/src/flowgraph/RampLinear.cpp
index 32ad2604d3..3bd2c0fd27 100644
--- a/media/libaaudio/src/flowgraph/RampLinear.cpp
+++ b/media/libaaudio/src/flowgraph/RampLinear.cpp
@@ -19,6 +19,7 @@
 #include <utils/Log.h>
 
 #include <algorithm>
+#include <cmath>
 #include <unistd.h>
 #include "FlowGraphNode.h"
 #include "RampLinear.h"
diff --git a/media/libaaudio/src/legacy/AudioStreamLegacy.cpp b/media/libaaudio/src/legacy/AudioStreamLegacy.cpp
index cdd004c5b4..5ad7de6d19 100644
--- a/media/libaaudio/src/legacy/AudioStreamLegacy.cpp
+++ b/media/libaaudio/src/legacy/AudioStreamLegacy.cpp
@@ -38,22 +38,22 @@ AudioStreamLegacy::AudioStreamLegacy()
 }
 
 
-aaudio_data_callback_result_t AudioStreamLegacy::callDataCallbackFrames(uint8_t *buffer,
-                                                                        int32_t numFrames) {
+int32_t AudioStreamLegacy::callDataCallbackFrames(uint8_t *buffer, int32_t numFrames) {
     void *finalAudioData = buffer;
     if (getDirection() == AAUDIO_DIRECTION_INPUT) {
-        // Increment before because we already got the data from the device.
-        incrementFramesRead(numFrames);
         finalAudioData = (void *) maybeConvertDeviceData(buffer, numFrames);
     }
 
     // Call using the AAudio callback interface.
-    aaudio_data_callback_result_t callbackResult = maybeCallDataCallback(finalAudioData, numFrames);
+    int32_t callbackResult = maybeCallDataCallback(finalAudioData, numFrames);
 
-    if (callbackResult == AAUDIO_CALLBACK_RESULT_CONTINUE
-            && getDirection() == AAUDIO_DIRECTION_OUTPUT) {
-        // Increment after because we are going to write the data to the device.
-        incrementFramesWritten(numFrames);
+    if (callbackResult >= 0) {
+        if (getDirection() == AAUDIO_DIRECTION_OUTPUT) {
+            // Increment after because we are going to write the data to the device.
+            incrementFramesWritten(callbackResult);
+        } else {
+            incrementFramesRead(callbackResult);
+        }
     }
     return callbackResult;
 }
@@ -61,7 +61,7 @@ aaudio_data_callback_result_t AudioStreamLegacy::callDataCallbackFrames(uint8_t
 // Implement FixedBlockProcessor
 int32_t AudioStreamLegacy::onProcessFixedBlock(uint8_t *buffer, int32_t numBytes) {
     int32_t numFrames = numBytes / mBlockAdapterBytesPerFrame;
-    return (int32_t) callDataCallbackFrames(buffer, numFrames);
+    return callDataCallbackFrames(buffer, numFrames) * mBlockAdapterBytesPerFrame;
 }
 
 
@@ -78,7 +78,7 @@ size_t AudioStreamLegacy::onMoreData(const android::AudioTrack::Buffer& buffer)
     // TODO add to API in AudioRecord and AudioTrack
     // TODO(b/216175830) cleanup size re-computation
     const size_t SIZE_STOP_CALLBACKS = SIZE_MAX;
-    aaudio_data_callback_result_t callbackResult;
+    aaudio_data_callback_result_t callbackResult = AAUDIO_CALLBACK_RESULT_CONTINUE;
     (void) checkForDisconnectRequest(true);
 
     // Note that this code assumes an AudioTrack::Buffer is the same as
@@ -109,20 +109,20 @@ size_t AudioStreamLegacy::onMoreData(const android::AudioTrack::Buffer& buffer)
                     buffer.data(), byteCount);
         } else {
             // Call using the AAudio callback interface.
-            callbackResult = callDataCallbackFrames(buffer.data(),
-                                                    buffer.getFrameCount());
-            written = callbackResult == AAUDIO_CALLBACK_RESULT_CONTINUE ?
-                    buffer.getFrameCount() * getBytesPerDeviceFrame() : 0;
-        }
-
-        if (callbackResult != AAUDIO_CALLBACK_RESULT_CONTINUE) {
-            if (callbackResult == AAUDIO_CALLBACK_RESULT_STOP) {
-                ALOGD("%s() callback returned AAUDIO_CALLBACK_RESULT_STOP", __func__);
+            const int32_t framesProcessed = callDataCallbackFrames(
+                    buffer.data(), buffer.getFrameCount());
+            if (framesProcessed < 0) {
+                written = 0;
+                callbackResult = AAUDIO_CALLBACK_RESULT_STOP;
             } else {
-                ALOGW("%s() callback returned invalid result = %d",
-                      __func__, callbackResult);
+                written = framesProcessed * getBytesPerDeviceFrame();
+                callbackResult = AAUDIO_CALLBACK_RESULT_CONTINUE;
             }
-            if (callbackResult != AAUDIO_CALLBACK_RESULT_STOP || shouldStopStream()) {
+        }
+
+        if (callbackResult == AAUDIO_CALLBACK_RESULT_STOP) {
+            ALOGD("%s() callback requested to stop", __func__);
+            if (shouldStopStream()) {
                 // If the callback result is STOP, stop the stream if it should be stopped.
                 // Currently, the framework will not call stop if the client is doing offload
                 // playback and waiting for stream end. The client will already be STOPPING
@@ -149,7 +149,7 @@ size_t AudioStreamLegacy::onMoreData(const android::AudioRecord::Buffer& buffer)
     // That is an undocumented behavior.
     // TODO add to API in AudioRecord and AudioTrack
     const size_t SIZE_STOP_CALLBACKS = SIZE_MAX;
-    aaudio_data_callback_result_t callbackResult;
+    aaudio_data_callback_result_t callbackResult = AAUDIO_CALLBACK_RESULT_CONTINUE;
     (void) checkForDisconnectRequest(true);
 
     // Note that this code assumes an AudioTrack::Buffer is the same as
@@ -180,18 +180,18 @@ size_t AudioStreamLegacy::onMoreData(const android::AudioRecord::Buffer& buffer)
                     buffer.data(), byteCount);
         } else {
             // Call using the AAudio callback interface.
-            callbackResult = callDataCallbackFrames(buffer.data(),
-                                                    buffer.getFrameCount());
-            written = callbackResult == AAUDIO_CALLBACK_RESULT_CONTINUE ?
-                    buffer.getFrameCount() * getBytesPerDeviceFrame() : 0;
-        }
-        if (callbackResult != AAUDIO_CALLBACK_RESULT_CONTINUE) {
-            if (callbackResult == AAUDIO_CALLBACK_RESULT_STOP) {
-                ALOGD("%s() callback returned AAUDIO_CALLBACK_RESULT_STOP", __func__);
+            const int framesProcessed = callDataCallbackFrames(
+                    buffer.data(), buffer.getFrameCount());
+            if (framesProcessed < 0) {
+                written = 0;
+                callbackResult = AAUDIO_CALLBACK_RESULT_STOP;
             } else {
-                ALOGW("%s() callback returned invalid result = %d",
-                      __func__, callbackResult);
+                written = framesProcessed * getBytesPerDeviceFrame();
+                callbackResult = AAUDIO_CALLBACK_RESULT_CONTINUE;
             }
+        }
+        if (callbackResult == AAUDIO_CALLBACK_RESULT_STOP) {
+            ALOGD("%s() callback requested to stop", __func__);
             // Always stop the recording case if callback result is not CONTINUE.
             systemStopInternal();
             // Disable the callback just in case the system keeps trying to call us.
diff --git a/media/libaaudio/src/legacy/AudioStreamRecord.cpp b/media/libaaudio/src/legacy/AudioStreamRecord.cpp
index 1591f7daba..71c513782e 100644
--- a/media/libaaudio/src/legacy/AudioStreamRecord.cpp
+++ b/media/libaaudio/src/legacy/AudioStreamRecord.cpp
@@ -105,7 +105,7 @@ aaudio_result_t AudioStreamRecord::open(const AudioStreamBuilder& builder)
     // Setup the callback if there is one.
     sp<AudioRecord::IAudioRecordCallback> callback;
     AudioRecord::transfer_type streamTransferType = AudioRecord::transfer_type::TRANSFER_SYNC;
-    if (builder.getDataCallbackProc() != nullptr) {
+    if (builder.isDataCallbackSet()) {
         streamTransferType = AudioRecord::transfer_type::TRANSFER_CALLBACK;
         callback = sp<AudioRecord::IAudioRecordCallback>::fromExisting(this);
     }
@@ -233,7 +233,7 @@ aaudio_result_t AudioStreamRecord::open(const AudioStreamBuilder& builder)
     if (getDeviceFormat() == AUDIO_FORMAT_PCM_16_BIT
         && getFormat() == AUDIO_FORMAT_PCM_FLOAT) {
 
-        if (builder.getDataCallbackProc() != nullptr) {
+        if (builder.isDataCallbackSet()) {
             // If we have a callback then we need to convert the data into an internal float
             // array and then pass that entire array to the app.
             mFormatConversionBufferSizeInFrames =
diff --git a/media/libaaudio/src/legacy/AudioStreamTrack.cpp b/media/libaaudio/src/legacy/AudioStreamTrack.cpp
index 0cb2328b81..38c0f8e4f4 100644
--- a/media/libaaudio/src/legacy/AudioStreamTrack.cpp
+++ b/media/libaaudio/src/legacy/AudioStreamTrack.cpp
@@ -120,7 +120,7 @@ aaudio_result_t AudioStreamTrack::open(const AudioStreamBuilder& builder)
     wp<AudioTrack::IAudioTrackCallback> callback;
     // Note that TRANSFER_SYNC does not allow FAST track
     AudioTrack::transfer_type streamTransferType = AudioTrack::transfer_type::TRANSFER_SYNC;
-    if (builder.getDataCallbackProc() != nullptr) {
+    if (builder.isDataCallbackSet()) {
         streamTransferType = AudioTrack::transfer_type::TRANSFER_CALLBACK;
         callback = wp<AudioTrack::IAudioTrackCallback>::fromExisting(this);
 
diff --git a/media/libaaudio/src/libaaudio.map.txt b/media/libaaudio/src/libaaudio.map.txt
index 0de054611e..416f26ffe5 100644
--- a/media/libaaudio/src/libaaudio.map.txt
+++ b/media/libaaudio/src/libaaudio.map.txt
@@ -29,6 +29,7 @@ LIBAAUDIO {
     AAudioStreamBuilder_setSpatializationBehavior; # introduced=32
     AAudioStreamBuilder_setIsContentSpatialized;   # introduced=32
     AAudioStreamBuilder_setPresentationEndCallback; #introduced=36
+    AAudioStreamBuilder_setPartialDataCallback; # introduced=37
     AAudioStreamBuilder_openStream;
     AAudioStreamBuilder_delete;
     AAudioStream_close;
@@ -78,6 +79,7 @@ LIBAAUDIO {
     AAudioStream_getOffloadDelay; #introduced=36
     AAudioStream_getOffloadPadding; #introduced=36
     AAudioStream_setOffloadEndOfStream; #introduced=36
+    AAudioStream_flushFromFrame; #introduced=37
 
     AAudioStreamBuilder_addTag; # systemapi
     AAudioStreamBuilder_clearTags; # systemapi
diff --git a/media/libaaudio/src/utility/FixedBlockAdapter.h b/media/libaaudio/src/utility/FixedBlockAdapter.h
index 516e67f948..7b3ab8c1c3 100644
--- a/media/libaaudio/src/utility/FixedBlockAdapter.h
+++ b/media/libaaudio/src/utility/FixedBlockAdapter.h
@@ -21,6 +21,8 @@
 #include <stdio.h>
 #include <utility>
 
+#include "aaudio/AAudio.h"
+
 /**
  * Interface for a class that needs fixed-size blocks.
  */
@@ -30,9 +32,9 @@ public:
     virtual int32_t onProcessFixedBlock(uint8_t *buffer, int32_t numBytes) = 0;
 };
 
-// The first value is the processing result code which 0 is OK.
+// The first value is used to indicate if callback should be stopped or continued.
 // The second value is the actual processed size in bytes.
-using AdapterProcessResult = std::pair<int32_t, int32_t>;
+using AdapterProcessResult = std::pair<aaudio_data_callback_result_t, int32_t>;
 
 /**
  * Base class for a variable-to-fixed-size block adapter.
@@ -72,6 +74,7 @@ protected:
     std::unique_ptr<uint8_t[]> mStorage;         // Store data here while assembling buffers.
     int32_t               mSize = 0;             // Size in bytes of the fixed size buffer.
     int32_t               mPosition = 0;         // Offset of the last byte read or written.
+    int32_t               mAvailable = 0;        // Total available data in storage
 };
 
 #endif /* AAUDIO_FIXED_BLOCK_ADAPTER_H */
diff --git a/media/libaaudio/src/utility/FixedBlockReader.cpp b/media/libaaudio/src/utility/FixedBlockReader.cpp
index 2d3174d457..76a69dd131 100644
--- a/media/libaaudio/src/utility/FixedBlockReader.cpp
+++ b/media/libaaudio/src/utility/FixedBlockReader.cpp
@@ -25,17 +25,22 @@
 FixedBlockReader::FixedBlockReader(FixedBlockProcessor &fixedBlockProcessor)
     : FixedBlockAdapter(fixedBlockProcessor) {
     mPosition = mSize;
+    mAvailable = 0;
 }
 
 int32_t FixedBlockReader::open(int32_t bytesPerFixedBlock) {
     int32_t result = FixedBlockAdapter::open(bytesPerFixedBlock);
     mPosition = mSize; // Indicate no data in storage.
+    mAvailable = 0;
     return result;
 }
 
 int32_t FixedBlockReader::readFromStorage(uint8_t *buffer, int32_t numBytes) {
+    if (mAvailable <= mPosition) {
+        return 0;
+    }
     int32_t bytesToRead = numBytes;
-    int32_t dataAvailable = mSize - mPosition;
+    int32_t dataAvailable = mAvailable - mPosition;
     if (bytesToRead > dataAvailable) {
         bytesToRead = dataAvailable;
     }
@@ -45,31 +50,49 @@ int32_t FixedBlockReader::readFromStorage(uint8_t *buffer, int32_t numBytes) {
 }
 
 AdapterProcessResult FixedBlockReader::processVariableBlock(uint8_t *buffer, int32_t numBytes) {
-    int32_t result = 0;
+    aaudio_data_callback_result_t result = AAUDIO_CALLBACK_RESULT_CONTINUE;
     int32_t bytesLeft = numBytes;
-    int32_t bytesProcessed = 0;
-    while(bytesLeft > 0 && result == 0) {
-        if (mPosition < mSize) {
+    int32_t totalBytesProcessed = 0;
+    while (bytesLeft > 0) {
+        if (mPosition < mAvailable) {
             // Use up bytes currently in storage.
             int32_t bytesRead = readFromStorage(buffer, bytesLeft);
             buffer += bytesRead;
             bytesLeft -= bytesRead;
-            bytesProcessed += bytesRead;
+            totalBytesProcessed += bytesRead;
         } else if (bytesLeft >= mSize) {
             // Read through if enough for a complete block.
-            result = mFixedBlockProcessor.onProcessFixedBlock(buffer, mSize);
-            if (result != 0) {
+            int32_t bytesProcessed = mFixedBlockProcessor.onProcessFixedBlock(buffer, mSize);
+            if (bytesProcessed < 0) {
+                result = AAUDIO_CALLBACK_RESULT_STOP;
+                break;
+            }
+            buffer += bytesProcessed;
+            bytesLeft -= bytesProcessed;
+            totalBytesProcessed += bytesProcessed;
+            if (bytesProcessed != mSize) {
+                // The client my not be able to process all data. Let's return earlier
+                // and come back later.
                 break;
             }
-            buffer += mSize;
-            bytesLeft -= mSize;
-            bytesProcessed += mSize;
         } else {
             // Just need a partial block so we have to use storage.
-            result = mFixedBlockProcessor.onProcessFixedBlock(mStorage.get(), mSize);
-            mPosition = 0;
+            mAvailable = mFixedBlockProcessor.onProcessFixedBlock(
+                    mStorage.get(), mSize);
+            if (mAvailable < 0) {
+                result = AAUDIO_CALLBACK_RESULT_STOP;
+                mAvailable = 0;
+                break;
+            } else {
+                mPosition = 0;
+                if (mAvailable != mSize) {
+                    // The client my not be able to process all data. Let's return earlier
+                    // and come back later.
+                    break;
+                }
+            }
         }
     }
-    return {result, bytesProcessed};
+    return {result, totalBytesProcessed};
 }
 
diff --git a/media/libaaudio/src/utility/FixedBlockWriter.cpp b/media/libaaudio/src/utility/FixedBlockWriter.cpp
index ff6ef8a740..1efe9fdfb1 100644
--- a/media/libaaudio/src/utility/FixedBlockWriter.cpp
+++ b/media/libaaudio/src/utility/FixedBlockWriter.cpp
@@ -36,39 +36,47 @@ int32_t FixedBlockWriter::writeToStorage(const uint8_t *buffer, int32_t numBytes
 }
 
 AdapterProcessResult FixedBlockWriter::processVariableBlock(uint8_t *buffer, int32_t numBytes) {
-    int32_t result = 0;
     int32_t bytesLeft = numBytes;
-    int32_t bytesProcessed = 0;
+    int32_t bytesTotalProcessed = 0;
 
     // If we already have data in storage then add to it.
     if (mPosition > 0) {
         int32_t bytesWritten = writeToStorage(buffer, bytesLeft);
         buffer += bytesWritten;
         bytesLeft -= bytesWritten;
-        bytesProcessed += bytesWritten;
+        bytesTotalProcessed += bytesWritten;
         // If storage full then flush it out
         if (mPosition == mSize) {
-            result = mFixedBlockProcessor.onProcessFixedBlock(mStorage.get(), mSize);
+            int bytes = mFixedBlockProcessor.onProcessFixedBlock(mStorage.get(), mSize);
             mPosition = 0;
+            if (bytes < 0) {
+                return {AAUDIO_CALLBACK_RESULT_STOP, bytesTotalProcessed};
+            } else if (bytes != mSize) {
+                // Client only consumes part of the data, it may be busy.
+                // Move the unprocessed data to the beginning of the storage, return earlier here.
+                mPosition = mSize - bytes;
+                memmove(mStorage.get(), mStorage.get() + bytes, mPosition);
+                return {AAUDIO_CALLBACK_RESULT_CONTINUE, bytesTotalProcessed};
+            }
         }
     }
 
     // Write through if enough for a complete block.
-    while(bytesLeft > mSize && result == 0) {
-        result = mFixedBlockProcessor.onProcessFixedBlock(buffer, mSize);
-        if (result != 0) {
-            break;
+    while (bytesLeft > mSize) {
+        int32_t bytesProcessed = mFixedBlockProcessor.onProcessFixedBlock(buffer, mSize);
+        if (bytesProcessed < 0) {
+            return {AAUDIO_CALLBACK_RESULT_STOP, bytesTotalProcessed};
         }
-        buffer += mSize;
-        bytesLeft -= mSize;
-        bytesProcessed += mSize;
+        buffer += bytesProcessed;
+        bytesLeft -= bytesProcessed;
+        bytesTotalProcessed += bytesProcessed;
     }
 
     // Save any remaining partial block for next time.
     if (bytesLeft > 0) {
-        writeToStorage(buffer, bytesLeft);
-        bytesProcessed += bytesLeft;
+        int32_t bytesWritten = writeToStorage(buffer, bytesLeft);
+        bytesTotalProcessed += bytesWritten;
     }
 
-    return {result, bytesProcessed};
+    return {AAUDIO_CALLBACK_RESULT_CONTINUE, bytesTotalProcessed};
 }
diff --git a/media/libaaudio/tests/Android.bp b/media/libaaudio/tests/Android.bp
index 1ff75be3cc..1e099dc4be 100644
--- a/media/libaaudio/tests/Android.bp
+++ b/media/libaaudio/tests/Android.bp
@@ -292,3 +292,11 @@ cc_binary {
     header_libs: ["libaaudio_example_utils"],
     shared_libs: ["libaaudio"],
 }
+
+cc_binary {
+    name: "test_flush_from_frame",
+    defaults: ["libaaudio_tests_defaults"],
+    srcs: ["test_flush_from_frame.cpp"],
+    header_libs: ["libaaudio_example_utils"],
+    shared_libs: ["libaaudio"],
+}
diff --git a/media/libaaudio/tests/test_flush_from_frame.cpp b/media/libaaudio/tests/test_flush_from_frame.cpp
new file mode 100644
index 0000000000..70727cd5f5
--- /dev/null
+++ b/media/libaaudio/tests/test_flush_from_frame.cpp
@@ -0,0 +1,291 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <chrono>
+#include <memory>
+#include <mutex>
+#include <stdio.h>
+#include <stdlib.h>
+#include <thread>
+#include <vector>
+
+#include <aaudio/AAudio.h>
+
+#include "AAudioArgsParser.h"
+#include "AAudioSimplePlayer.h"
+#include "SineGenerator.h"
+
+/**
+ * This tests AAudioStream_flushFromPosition. This test will do playback in offload mode
+ * and try to flush from frame every 2 seconds. It will switch the sine generator between
+ * 440Hz and 880Hz when flush from frame.
+ */
+
+constexpr static int DEFAULT_TIME_TO_RUN_IN_SECOND = 10;
+constexpr static int PLAYBACK_LENGTH_SECONDS = 2;
+constexpr static int MORE_DATA_IN_SECONDS = 3;
+
+int32_t MyPartialDataCallback(
+        AAudioStream* stream, void* userData, void* audioData, int32_t numFrames);
+
+void MyErrorCallback(AAudioStream* /*stream*/, void* /*userData*/, aaudio_result_t error);
+
+class MyPlayer : public AAudioSimplePlayer {
+public:
+    MyPlayer(AAudioArgsParser& argParser, bool useDataCallback)
+            : mArgParser(argParser), mUseDataCallback(useDataCallback) {}
+
+    aaudio_result_t open() {
+        aaudio_result_t result = AAudioSimplePlayer::open(
+                mArgParser,
+                nullptr /*dataCallback*/,
+                &MyErrorCallback,
+                this,
+                nullptr /*presentationEndCallback*/,
+                mUseDataCallback ? &MyPartialDataCallback : nullptr);
+        if (result != AAUDIO_OK) {
+            return result;
+        }
+        mChannelCount = getChannelCount();
+        mSampleRate = getSampleRate();
+        mSines.resize(2);
+        for (int i = 0; i < mChannelCount; ++i) {
+            SineGenerator sine;
+            sine.setup(440.0, mSampleRate);
+            mSines[0].push_back(sine);
+            SineGenerator sine1;
+            sine1.setup(880.0, mSampleRate);
+            mSines[1].push_back(sine1);
+        }
+        return result;
+    }
+
+    int32_t renderAudio(AAudioStream* stream, void* audioData, int32_t numFrames) {
+        int index = 0;
+        {
+            std::lock_guard _l(mFlushMutex);
+            if (mPendingFlush) {
+                return 0;
+            }
+            index = mSineGeneratorIndex;
+        }
+        // Just handle PCM_16 and PCM_FLOAT for testing
+        if (!fillData(stream, audioData, numFrames, index)) {
+            printf("Failed to render data, stop the stream\n");
+            return -1;
+        }
+        return numFrames;
+    }
+
+    void writeData() {
+        for (int i = 0; i < MORE_DATA_IN_SECONDS; ++i) {
+            writeOneSecondData();
+        }
+    }
+
+    aaudio_result_t flushFromFrame(AAudio_FlushFromAccuracy accuracy, int64_t* position) {
+        if (position == nullptr) {
+            return AAUDIO_ERROR_ILLEGAL_ARGUMENT;
+        }
+        aaudio_result_t result = AAUDIO_OK;
+        {
+            std::lock_guard _l(mFlushMutex);
+            mPendingFlush = true;
+            mSineGeneratorIndex ^= 1;
+        }
+        {
+            std::lock_guard _l(mStreamMutex);
+            auto framesWritten = AAudioStream_getFramesWritten(getStream());
+            int64_t requestedPosition = *position;
+            result = AAudioStream_flushFromFrame(getStream(), accuracy, position);
+            printf("%s(%d, %jd) result=%d actual position=%jd, frames written before "
+                   "flushFromFrame=%jd frames written after flushFromFrame=%jd\n",
+                   __func__, accuracy, requestedPosition, result, *position, framesWritten,
+                   AAudioStream_getFramesWritten(getStream()));
+        }
+        {
+            std::lock_guard _l(mFlushMutex);
+            mPendingFlush = false;
+        }
+        return result;
+    }
+
+    aaudio_result_t close() override {
+        std::lock_guard _l(mStreamMutex);
+        return AAudioSimplePlayer::close();
+    }
+
+private:
+    void writeOneSecondData() {
+        int index = 0;
+        {
+            std::lock_guard _l(mFlushMutex);
+            if (mPendingFlush) {
+                return;
+            }
+            index = mSineGeneratorIndex;
+        }
+        // Lock to prevent the stream is released
+        std::lock_guard _l(mStreamMutex);
+        AAudioStream* stream = getStream();
+        if (stream == nullptr) {
+            return;
+        }
+        int bytesPerFrame = mChannelCount;
+        std::shared_ptr<uint8_t[]> data;
+        switch (AAudioStream_getFormat(stream)) {
+            case AAUDIO_FORMAT_PCM_I16: {
+                bytesPerFrame *= 2;
+            } break;
+            case AAUDIO_FORMAT_PCM_FLOAT: {
+                bytesPerFrame *= 4;
+            } break;
+            default:
+                printf("Unsupported format %d\n", AAudioStream_getFormat(stream));
+                return;
+        }
+        data = std::make_shared<uint8_t[]>(bytesPerFrame * mSampleRate);
+        fillData(stream, static_cast<void*>(data.get()), mSampleRate, index);
+        int bytesWritten = 0;
+        int framesLeft = mSampleRate;
+        while (framesLeft > 0) {
+            auto framesWritten = AAudioStream_write(
+                    stream, static_cast<void *>(&data[bytesWritten]),
+                    framesLeft, 0 /*timeoutNanoseconds*/);
+            if (framesWritten < 0) {
+                printf("Failed to write data %d\n", framesWritten);
+                return;
+            }
+            printf("Write data succeed, frames=%d\n", framesWritten);
+            framesLeft -= framesWritten;
+            bytesWritten += framesWritten * bytesPerFrame;
+        }
+    }
+
+    bool fillData(AAudioStream* stream, void* data, int numFrames, int sineGeneratorIndex) {
+        switch (AAudioStream_getFormat(stream)) {
+            case AAUDIO_FORMAT_PCM_I16: {
+                int16_t *audioBuffer = static_cast<int16_t *>(data);
+                for (int i = 0; i < mChannelCount; ++i) {
+                    mSines[sineGeneratorIndex][i].render(&audioBuffer[i], mChannelCount, numFrames);
+                }
+            } break;
+            case AAUDIO_FORMAT_PCM_FLOAT: {
+                float *audioBuffer = static_cast<float *>(data);
+                for (int i = 0; i < mChannelCount; ++i) {
+                    mSines[sineGeneratorIndex][i].render(&audioBuffer[i], mChannelCount, numFrames);
+                }
+            } break;
+            default:
+                return false;
+        }
+        return true;
+    }
+
+    const AAudioArgsParser mArgParser;
+    const bool mUseDataCallback;
+
+    int mSampleRate;
+    int mChannelCount;
+    std::vector<std::vector<SineGenerator>> mSines;
+    int mSineGeneratorIndex = 0;
+
+    std::mutex mStreamMutex;
+
+    std::mutex mFlushMutex;
+    bool mPendingFlush = false;
+};
+
+int32_t MyPartialDataCallback(
+        AAudioStream* stream, void* userData, void* audioData, int32_t numFrames) {
+    MyPlayer* player = static_cast<MyPlayer*>(userData);
+    return player->renderAudio(stream, audioData, numFrames);
+}
+
+void MyErrorCallback(AAudioStream* /*stream*/, void* /*userData*/, aaudio_result_t error) {
+    printf("Error callback, error=%d\n", error);
+}
+
+static void usage() {
+    printf("This test will playback in offload mode and try to flush from frame "
+           "every 2 seconds\n");
+    AAudioArgsParser::usage();
+    printf("      -T{seconds} time to run the test\n");
+    printf("      -B use blocking write instead of data callback\n");
+}
+
+int main(int argc, char **argv) {
+    AAudioArgsParser argParser;
+    int timeToRun = DEFAULT_TIME_TO_RUN_IN_SECOND;
+    bool useDataCallback = true;
+    for (int i = 1; i < argc; ++i) {
+        const char *arg = argv[i];
+        if (argParser.parseArg(arg)) {
+            if (arg[0] == '-') {
+                char option = arg[1];
+                switch (option) {
+                    case 'T':
+                        timeToRun = atoi(&arg[2]);
+                        break;
+                    case 'B':
+                        useDataCallback = false;
+                        break;
+                    default:
+                        usage();
+                        exit(EXIT_FAILURE);
+                }
+            } else {
+                usage();
+                exit(EXIT_FAILURE);
+            }
+        }
+    }
+
+    // Force to use offload mode
+    argParser.setPerformanceMode(AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED);
+    argParser.setNumberOfBursts(0);
+
+    MyPlayer player(argParser, useDataCallback);
+    if (auto result = player.open(); result != AAUDIO_OK) {
+        printf("Failed to open stream, error=%d\n", result);
+        exit(EXIT_FAILURE);
+    }
+
+    if (auto result = player.start(); result != AAUDIO_OK) {
+        printf("Failed to start stream, error=%d", result);
+        exit(EXIT_FAILURE);
+    }
+
+    auto timeStart = std::chrono::system_clock::now();
+    int64_t position = 0;
+
+    while (std::chrono::duration_cast<std::chrono::seconds>(
+            std::chrono::system_clock::now() - timeStart).count() < timeToRun) {
+        if (useDataCallback) {
+            std::this_thread::sleep_for(std::chrono::seconds(PLAYBACK_LENGTH_SECONDS));
+            player.flushFromFrame(AAUDIO_FLUSH_FROM_ACCURACY_UNDEFINED, &position);
+        } else {
+            auto timeToWakeUp = std::chrono::system_clock::now() +
+                    std::chrono::seconds(PLAYBACK_LENGTH_SECONDS);
+            player.writeData();
+            std::this_thread::sleep_until(timeToWakeUp);
+            player.flushFromFrame(AAUDIO_FLUSH_FROM_ACCURACY_UNDEFINED, &position);
+        }
+    }
+
+    player.close();
+    return EXIT_SUCCESS;
+}
diff --git a/media/libaaudio/tests/test_pcm_offload.cpp b/media/libaaudio/tests/test_pcm_offload.cpp
index c01c77ab8e..f2e2a7aa08 100644
--- a/media/libaaudio/tests/test_pcm_offload.cpp
+++ b/media/libaaudio/tests/test_pcm_offload.cpp
@@ -17,8 +17,10 @@
 // PCM offload
 
 #include <memory>
+#include <mutex>
 #include <stdio.h>
 #include <stdlib.h>
+#include <thread>
 #include <vector>
 
 #include <aaudio/AAudio.h>
@@ -85,18 +87,33 @@ public:
     }
 
     void presentationEnd(AAudioStream* stream) {
+        if (stream != getStream()) {
+            printf("%s with a stream that is different from our stream\n", __func__);
+            return;
+        }
         printf("Presentation end\n");
         if (!mUseDataCallback) {
-            writeAllStreamData(stream);
+            std::thread(&OffloadPlayer::writeAllStreamData, this).detach();
         }
     }
 
     void writeData() {
-        writeAllStreamData(getStream());
+        writeAllStreamData();
+    }
+
+    aaudio_result_t close() override {
+        std::lock_guard _l(mMutex);
+        return AAudioSimplePlayer::close();
     }
 
 private:
-    void writeAllStreamData(AAudioStream* stream) {
+    void writeAllStreamData() {
+        // Lock to prevent the stream is released
+        std::lock_guard _l(mMutex);
+        AAudioStream* stream = getStream();
+        if (stream == nullptr) {
+            return;
+        }
         int bytesPerFrame = mChannelCount;
         std::shared_ptr<uint8_t[]> data;
         switch (AAudioStream_getFormat(stream)) {
@@ -160,6 +177,7 @@ private:
     int mChannelCount;
     std::vector<SineGenerator> mSines;
     int mFramesWritten = 0;
+    std::mutex mMutex;
 };
 
 aaudio_data_callback_result_t MyDatacallback(AAudioStream* stream,
@@ -229,6 +247,10 @@ int main(int argc, char **argv) {
 
     // Force to use offload mode
     argParser.setPerformanceMode(AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED);
+    // By default, AAudioSimplePlayer uses 2 as the number of bursts. For offload case,
+    // 2 bursts is too small if the burst size is only couple seconds. In that case, use
+    // the value set by the framework.
+    argParser.setNumberOfBursts(0);
 
     OffloadPlayer player(argParser, delay, padding, streamFrames, useDataCallback);
     if (auto result = player.open(); result != AAUDIO_OK) {
@@ -249,5 +271,7 @@ int main(int argc, char **argv) {
 
     sleep(timeToRun);
 
+    player.close();
+
     return EXIT_SUCCESS;
 }
diff --git a/media/libaudioclient/AidlConversion.cpp b/media/libaudioclient/AidlConversion.cpp
index 2377fc8131..1d104504ce 100644
--- a/media/libaudioclient/AidlConversion.cpp
+++ b/media/libaudioclient/AidlConversion.cpp
@@ -710,6 +710,10 @@ legacy2aidl_audio_port_v7_AudioPortFw(const audio_port_v7& legacy) {
     // These get filled by the call to 'legacy2aidl_AudioPortExt' below.
     aidl.sys.profiles.resize(legacy.num_audio_profiles);
     aidl.sys.gains.resize(legacy.num_gains);
+    for (int i = 0; i < legacy.num_gains; i++) {
+        aidl.sys.gains[i].isInput = isInput;
+        aidl.sys.gains[i].index = i;
+    }
     aidl.sys.activeConfig = VALUE_OR_RETURN(
             legacy2aidl_audio_port_config_AudioPortConfigFw(legacy.active_config, legacy.id));
     aidl.sys.activeConfig.hal.portId = aidl.hal.id;
diff --git a/media/libaudioclient/Android.bp b/media/libaudioclient/Android.bp
index 8b4e01209d..f502f1fa90 100644
--- a/media/libaudioclient/Android.bp
+++ b/media/libaudioclient/Android.bp
@@ -465,6 +465,7 @@ aidl_interface {
         "aidl/android/media/IAudioPolicyService.aidl",
         "aidl/android/media/IAudioPolicyServiceClient.aidl",
         "aidl/android/media/RecordClientInfo.aidl",
+        "aidl/android/media/StartOutputResponse.aidl",
     ],
     defaults: [
         "latest_android_media_audio_common_types_import_interface",
diff --git a/media/libaudioclient/AudioSystem.cpp b/media/libaudioclient/AudioSystem.cpp
index 3ef9225520..bd70757547 100644
--- a/media/libaudioclient/AudioSystem.cpp
+++ b/media/libaudioclient/AudioSystem.cpp
@@ -197,7 +197,6 @@ public:
         }
         if (mValid) return mService;
         if (waitMs.count() < 0) waitMs = mWaitMs;
-        auto timepointLimit = std::chrono::steady_clock::now() + waitMs;
         ul.unlock();
 
         // mediautils::getService() installs a persistent new service notification.
@@ -208,7 +207,6 @@ public:
         ul.lock();
         // return the IAudioFlinger interface which is adapted
         // from the media::IAudioFlingerService.
-        mCv.wait_until(ul, timepointLimit, isServiceValid_l);
         return mService;
     }
 
@@ -293,7 +291,6 @@ private:
             mService = service;
             client = mClient;
             mValid = true;
-            mCv.notify_all();
         }
         // TODO(b/375280520) consider registerClient() within mMutex lock.
         const int64_t token = IPCThreadState::self()->clearCallingIdentity();
@@ -308,12 +305,7 @@ private:
         return sp<AudioFlingerClientAdapter>::make(af);
     }
 
-    static bool isServiceValid_l() REQUIRES(mMutex) {
-        return mValid;
-    }
-
     static inline constinit std::mutex mMutex;
-    static inline constinit std::condition_variable mCv;
     static inline constinit sp<AudioSystem::AudioFlingerClient> mClient GUARDED_BY(mMutex);
     static inline constinit sp<IAudioFlinger> mService GUARDED_BY(mMutex);
     static inline constinit std::chrono::milliseconds mWaitMs
@@ -1032,7 +1024,6 @@ public:
             client = mClient;
             mService = aps;
             mValid = true;
-            mCv.notify_all();
         }
         // TODO(b/375280520) consider registerClient() within mMutex lock.
         const int64_t token = IPCThreadState::self()->clearCallingIdentity();
@@ -1093,7 +1084,6 @@ public:
         }
         if (mValid) return mService;
         if (waitMs.count() < 0) waitMs = mWaitMs;
-        auto timepointLimit = std::chrono::steady_clock::now() + waitMs;
         ul.unlock();
 
         auto service = mediautils::getService<
@@ -1104,7 +1094,6 @@ public:
         // (whereupon mService contained the actual local service pointer to use).
         // we should always return mService.
         ul.lock();
-        mCv.wait_until(ul, timepointLimit, isServiceValid_l);
         return mService;
     }
 
@@ -1153,12 +1142,7 @@ public:
     }
 private:
 
-    static bool isServiceValid_l() REQUIRES(mMutex) {
-        return mValid;
-    }
-
     static inline constinit std::mutex mMutex;
-    static inline constinit std::condition_variable mCv;
     static inline constinit sp<AudioSystem::AudioPolicyServiceClient> mClient GUARDED_BY(mMutex);
     static inline constinit sp<IAudioPolicyService> mService GUARDED_BY(mMutex);
     static inline constinit bool mValid GUARDED_BY(mMutex) = false;
@@ -1321,9 +1305,7 @@ status_t AudioSystem::getOutputForAttr(audio_attributes_t* attr,
                                        audio_port_handle_t* portId,
                                        std::vector<audio_io_handle_t>* secondaryOutputs,
                                        bool *isSpatialized,
-                                       bool *isBitPerfect,
-                                       float *volume,
-                                       bool *muted) {
+                                       bool *isBitPerfect) {
     if (attr == nullptr) {
         ALOGE("%s NULL audio attributes", __func__);
         return BAD_VALUE;
@@ -1389,18 +1371,23 @@ status_t AudioSystem::getOutputForAttr(audio_attributes_t* attr,
     *isBitPerfect = responseAidl.isBitPerfect;
     *attr = VALUE_OR_RETURN_STATUS(
             aidl2legacy_AudioAttributes_audio_attributes_t(responseAidl.attr));
-    *volume = responseAidl.volume;
-    *muted = responseAidl.muted;
 
     return OK;
 }
 
-status_t AudioSystem::startOutput(audio_port_handle_t portId) {
+status_t AudioSystem::startOutput(
+        audio_port_handle_t portId, float* volume, bool* muted) {
     const sp<IAudioPolicyService> aps = get_audio_policy_service();
     if (aps == nullptr) return AudioPolicyServiceTraits::getError();
 
     int32_t portIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_audio_port_handle_t_int32_t(portId));
-    return statusTFromBinderStatus(aps->startOutput(portIdAidl));
+    media::StartOutputResponse responseAidl;
+    status_t status = statusTFromBinderStatus(aps->startOutput(portIdAidl, &responseAidl));
+    if (status != NO_ERROR) return status;
+
+    *volume = responseAidl.volume;
+    *muted = responseAidl.muted;
+    return OK;
 }
 
 status_t AudioSystem::stopOutput(audio_port_handle_t portId) {
@@ -1642,6 +1629,78 @@ status_t AudioSystem::getMinVolumeIndexForAttributes(const audio_attributes_t& a
     return OK;
 }
 
+status_t AudioSystem::setVolumeIndexForGroup(volume_group_t groupId,
+                                                int index, bool muted,
+                                                audio_devices_t device) {
+    const sp<IAudioPolicyService> aps = get_audio_policy_service();
+    if (aps == 0) return PERMISSION_DENIED;
+
+    int32_t groupIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_volume_group_t_int32_t(groupId));
+    int32_t indexAidl = VALUE_OR_RETURN_STATUS(convertIntegral<int32_t>(index));
+    AudioDeviceDescription deviceAidl = VALUE_OR_RETURN_STATUS(
+            legacy2aidl_audio_devices_t_AudioDeviceDescription(device));
+    return statusTFromBinderStatus(
+            aps->setVolumeIndexForGroup(groupIdAidl, deviceAidl, indexAidl, muted));
+}
+
+status_t AudioSystem::getVolumeIndexForGroup(volume_group_t groupId,
+                                                int& index,
+                                                audio_devices_t device) {
+    const sp<IAudioPolicyService> aps = get_audio_policy_service();
+    if (aps == 0) return PERMISSION_DENIED;
+
+    int32_t groupIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_volume_group_t_int32_t(groupId));
+    AudioDeviceDescription deviceAidl = VALUE_OR_RETURN_STATUS(
+            legacy2aidl_audio_devices_t_AudioDeviceDescription(device));
+    int32_t indexAidl;
+    RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+            aps->getVolumeIndexForGroup(groupIdAidl, deviceAidl, &indexAidl)));
+    index = VALUE_OR_RETURN_STATUS(convertIntegral<int>(indexAidl));
+    return OK;
+}
+
+status_t AudioSystem::getMaxVolumeIndexForGroup(volume_group_t groupId, int& index) {
+    const sp<IAudioPolicyService> aps = get_audio_policy_service();
+    if (aps == 0) return PERMISSION_DENIED;
+
+    int32_t groupIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_volume_group_t_int32_t(groupId));
+    int32_t indexAidl;
+    RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+            aps->getMaxVolumeIndexForGroup(groupIdAidl, &indexAidl)));
+    index = VALUE_OR_RETURN_STATUS(convertIntegral<int>(indexAidl));
+    return OK;
+}
+
+status_t AudioSystem::setMaxVolumeIndexForGroup(volume_group_t groupId, int index) {
+    const sp<IAudioPolicyService> aps = get_audio_policy_service();
+    if (aps == 0) return PERMISSION_DENIED;
+
+    int32_t groupIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_volume_group_t_int32_t(groupId));
+    int32_t indexAidl = VALUE_OR_RETURN_STATUS(convertIntegral<int32_t>(index));
+    return statusTFromBinderStatus(aps->setMaxVolumeIndexForGroup(groupIdAidl, indexAidl));
+}
+
+status_t AudioSystem::getMinVolumeIndexForGroup(volume_group_t groupId, int& index) {
+    const sp<IAudioPolicyService> aps = get_audio_policy_service();
+    if (aps == 0) return PERMISSION_DENIED;
+
+    int32_t groupIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_volume_group_t_int32_t(groupId));
+    int32_t indexAidl;
+    RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+            aps->getMinVolumeIndexForGroup(groupIdAidl, &indexAidl)));
+    index = VALUE_OR_RETURN_STATUS(convertIntegral<int>(indexAidl));
+    return OK;
+}
+
+status_t AudioSystem::setMinVolumeIndexForGroup(volume_group_t groupId, int index) {
+    const sp<IAudioPolicyService> aps = get_audio_policy_service();
+    if (aps == 0) return PERMISSION_DENIED;
+
+    int32_t groupIdAidl = VALUE_OR_RETURN_STATUS(legacy2aidl_volume_group_t_int32_t(groupId));
+    int32_t indexAidl = VALUE_OR_RETURN_STATUS(convertIntegral<int32_t>(index));
+    return statusTFromBinderStatus(aps->setMinVolumeIndexForGroup(groupIdAidl, indexAidl));
+}
+
 product_strategy_t AudioSystem::getStrategyForStream(audio_stream_type_t stream) {
     const sp<IAudioPolicyService> aps = get_audio_policy_service();
     if (aps == nullptr) return PRODUCT_STRATEGY_NONE;
diff --git a/media/libaudioclient/AudioTrack.cpp b/media/libaudioclient/AudioTrack.cpp
index 0506645a18..5cac65c88b 100644
--- a/media/libaudioclient/AudioTrack.cpp
+++ b/media/libaudioclient/AudioTrack.cpp
@@ -1534,7 +1534,7 @@ status_t AudioTrack::getPosition(uint32_t *position)
     // for compressed/synced data; however, we use proxy position for pure linear pcm data
     // as we do not know the capability of the HAL for pcm position support and standby.
     // There may be some latency differences between the HAL position and the proxy position.
-    if (isOffloadedOrDirect_l() && !isPurePcmData_l()) {
+    if (isOffloaded_l() || (isDirect_l() && !isPurePcmData_l())) {
         if (isOffloaded_l() && ((mState == STATE_PAUSED) || (mState == STATE_PAUSED_STOPPING))) {
             ALOGV("%s(%d): called in paused state, return cached position %u",
                 __func__, mPortId, mPausedPosition);
@@ -2616,6 +2616,10 @@ nsecs_t AudioTrack::processAudioBuffer()
         if (err != NO_ERROR) {
             if (err == TIMED_OUT || err == WOULD_BLOCK || err == -EINTR ||
                     (isOffloaded && (err == DEAD_OBJECT))) {
+                if (writtenFrames > 0) {
+                    AutoMutex lock(mLock);
+                    mFramesWritten += writtenFrames;
+                }
                 // FIXME bug 25195759
                 return 1000000;
             }
diff --git a/media/libaudioclient/AudioTrackShared.cpp b/media/libaudioclient/AudioTrackShared.cpp
index 359f3c1ff2..e614228ac8 100644
--- a/media/libaudioclient/AudioTrackShared.cpp
+++ b/media/libaudioclient/AudioTrackShared.cpp
@@ -117,8 +117,6 @@ ClientProxy::ClientProxy(audio_track_cblk_t* cblk, void *buffers, size_t frameCo
 const struct timespec ClientProxy::kForever = {INT_MAX /*tv_sec*/, 0 /*tv_nsec*/};
 const struct timespec ClientProxy::kNonBlocking = {0 /*tv_sec*/, 0 /*tv_nsec*/};
 
-#define MEASURE_NS 10000000 // attempt to provide accurate timeouts if requested >= MEASURE_NS
-
 // To facilitate quicker recovery from server failure, this value limits the timeout per each futex
 // wait.  However it does not protect infinite timeouts.  If defined to be zero, there is no limit.
 // FIXME May not be compatible with audio tunneling requirements where timeout should be in the
@@ -172,7 +170,7 @@ status_t ClientProxy::obtainBuffer(Buffer* buffer, const struct timespec *reques
         timeout = TIMEOUT_INFINITE;
     } else {
         timeout = TIMEOUT_FINITE;
-        if (requested->tv_sec > 0 || requested->tv_nsec >= MEASURE_NS) {
+        if (requested->tv_sec > 0 || requested->tv_nsec >= mMinMeasureNs) {
             measure = true;
         }
     }
@@ -267,7 +265,11 @@ status_t ClientProxy::obtainBuffer(Buffer* buffer, const struct timespec *reques
             buffer->mRaw = part1 > 0 ?
                     &((char *) mBuffers)[(mIsOut ? rear : front) * mFrameSize] : NULL;
             buffer->mNonContig = avail - part1;
-            mUnreleased = part1;
+            // If two obtainBuffers requests are concurrent (for Java Offload),
+            // take the maximum of the two mUnreleased (consistency check variable)
+            // to avoid triggering an assertion on releaseBuffer.
+            // TODO(b/419572928) improve this logic.
+            mUnreleased.max(part1);
             status = NO_ERROR;
             break;
         }
@@ -397,7 +399,7 @@ void ClientProxy::releaseBuffer(Buffer* buffer)
     LOG_ALWAYS_FATAL_IF(!(stepCount <= mUnreleased && mUnreleased <= mFrameCount),
             "%s: mUnreleased out of range, "
             "!(stepCount:%zu <= mUnreleased:%zu <= mFrameCount:%zu), BufferSizeInFrames:%u",
-            __func__, stepCount, mUnreleased, mFrameCount, getBufferSizeInFrames());
+            __func__, stepCount, mUnreleased.load(), mFrameCount, getBufferSizeInFrames());
     mUnreleased -= stepCount;
     audio_track_cblk_t* cblk = mCblk;
     // Both of these barriers are required
@@ -918,7 +920,7 @@ void ServerProxy::releaseBuffer(Buffer* buffer)
     LOG_ALWAYS_FATAL_IF(!(stepCount <= mUnreleased && mUnreleased <= mFrameCount),
             "%s: mUnreleased out of range, "
             "!(stepCount:%zu <= mUnreleased:%zu <= mFrameCount:%zu)",
-            __func__, stepCount, mUnreleased, mFrameCount);
+            __func__, stepCount, mUnreleased.load(), mFrameCount);
     mUnreleased -= stepCount;
     audio_track_cblk_t* cblk = mCblk;
     if (mIsOut) {
@@ -1231,7 +1233,7 @@ void StaticAudioTrackServerProxy::releaseBuffer(Buffer* buffer)
     LOG_ALWAYS_FATAL_IF(!(stepCount <= mUnreleased),
             "%s: stepCount out of range, "
             "!(stepCount:%zu <= mUnreleased:%zu)",
-            __func__, stepCount, mUnreleased);
+            __func__, stepCount, mUnreleased.load());
     if (stepCount == 0) {
         // prevent accidental re-use of buffer
         buffer->mRaw = NULL;
diff --git a/media/libaudioclient/IAudioFlinger.cpp b/media/libaudioclient/IAudioFlinger.cpp
index 152360770f..29bdecd060 100644
--- a/media/libaudioclient/IAudioFlinger.cpp
+++ b/media/libaudioclient/IAudioFlinger.cpp
@@ -887,7 +887,8 @@ status_t AudioFlingerClientAdapter::getAudioPolicyConfig(media::AudioPolicyConfi
 }
 
 status_t AudioFlingerClientAdapter::getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                                    struct audio_port_v7 *mixPort) const {
+                                                    struct audio_port_v7 *mixPort,
+                                                    int32_t mixPortHalId) const {
     if (devicePort == nullptr || mixPort == nullptr) {
         return BAD_VALUE;
     }
@@ -897,7 +898,7 @@ status_t AudioFlingerClientAdapter::getAudioMixPort(const struct audio_port_v7 *
             legacy2aidl_audio_port_v7_AudioPortFw(*mixPort));
     media::AudioPortFw aidlRet;
     RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
-            mDelegate->getAudioMixPort(devicePortAidl, mixPortAidl, &aidlRet)));
+            mDelegate->getAudioMixPort(devicePortAidl, mixPortAidl, mixPortHalId, &aidlRet)));
     *mixPort = VALUE_OR_RETURN_STATUS(aidl2legacy_AudioPortFw_audio_port_v7(aidlRet));
     return OK;
 }
@@ -1456,12 +1457,14 @@ Status AudioFlingerServerAdapter::getAudioPolicyConfig(media::AudioPolicyConfig*
 
 Status AudioFlingerServerAdapter::getAudioMixPort(const media::AudioPortFw &devicePort,
                                                   const media::AudioPortFw &mixPort,
+                                                  int32_t mixPortHalId,
                                                   media::AudioPortFw *_aidl_return) {
     audio_port_v7 devicePortLegacy = VALUE_OR_RETURN_BINDER(
             aidl2legacy_AudioPortFw_audio_port_v7(devicePort));
     audio_port_v7 mixPortLegacy = VALUE_OR_RETURN_BINDER(
             aidl2legacy_AudioPortFw_audio_port_v7(mixPort));
-    RETURN_BINDER_IF_ERROR(mDelegate->getAudioMixPort(&devicePortLegacy, &mixPortLegacy));
+    RETURN_BINDER_IF_ERROR(
+            mDelegate->getAudioMixPort(&devicePortLegacy, &mixPortLegacy, mixPortHalId));
     *_aidl_return = VALUE_OR_RETURN_BINDER(legacy2aidl_audio_port_v7_AudioPortFw(mixPortLegacy));
     return Status::ok();
 }
diff --git a/media/libaudioclient/PolicyAidlConversion.cpp b/media/libaudioclient/PolicyAidlConversion.cpp
index 163a359a8a..3fdac4891b 100644
--- a/media/libaudioclient/PolicyAidlConversion.cpp
+++ b/media/libaudioclient/PolicyAidlConversion.cpp
@@ -118,8 +118,10 @@ aidl2legacy_AudioMixRouteFlag_uint32_t_mask(int32_t aidl) {
 
 ConversionResult<int32_t>
 legacy2aidl_uint32_t_AudioMixRouteFlag_mask(uint32_t legacy) {
+    // MIX_ROUTE_FLAG_DISALLOWS_PREFERRED_DEVICE is for internal user, and thus
+    // it is not converted.
     return convertBitmask<int32_t, uint32_t, media::AudioMixRouteFlag, uint32_t>(
-            legacy,
+            legacy & MIX_ROUTE_FLAG_LOOP_BACK_AND_RENDER,
             legacy2aidl_uint32_t_AudioMixRouteFlag,
             indexToEnum_bitmask<uint32_t>,
             enumToMask_index<int32_t, media::AudioMixRouteFlag>);
diff --git a/media/libaudioclient/TEST_MAPPING b/media/libaudioclient/TEST_MAPPING
index 29b876c0d7..2b2e7b6d78 100644
--- a/media/libaudioclient/TEST_MAPPING
+++ b/media/libaudioclient/TEST_MAPPING
@@ -38,6 +38,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     }
diff --git a/media/libaudioclient/ToneGenerator.cpp b/media/libaudioclient/ToneGenerator.cpp
index d325d0ab6f..43db1e915c 100644
--- a/media/libaudioclient/ToneGenerator.cpp
+++ b/media/libaudioclient/ToneGenerator.cpp
@@ -1323,13 +1323,18 @@ bool ToneGenerator::initAudioTrack() {
     }
     attr = AudioSystem::streamTypeToAttributes(streamType);
     attr.flags = static_cast<audio_flags_mask_t>(attr.flags | AUDIO_FLAG_LOW_LATENCY);
-
+    size_t frameCount = 0;
+    if (AudioSystem::getOutputSamplingRate(&mSamplingRate, streamType) == NO_ERROR) {
+        frameCount = (mSamplingRate * kCadenceMs) / 1000;
+    } else {
+        mSamplingRate = 0;
+    }
     status_t status = mpAudioTrack->set(
             AUDIO_STREAM_DEFAULT,
-            0,    // sampleRate
+            mSamplingRate,
             AUDIO_FORMAT_PCM_16_BIT,
             AUDIO_CHANNEL_OUT_MONO,
-            0,    // frameCount
+            frameCount,
             AUDIO_OUTPUT_FLAG_NONE,
             wp<AudioTrack::IAudioTrackCallback>::fromExisting(this),
             0,    // notificationFrames
@@ -1349,9 +1354,15 @@ bool ToneGenerator::initAudioTrack() {
         return false;
     }
 
-    mSamplingRate = mpAudioTrack->getSampleRate();
-    // Generate tone by chunks of 20 ms to keep cadencing precision
-    mProcessSize = (mSamplingRate * 20) / 1000;
+    if (mSamplingRate == 0) {
+        mSamplingRate = mpAudioTrack->getSampleRate();
+    } else {
+        LOG_ALWAYS_FATAL_IF(mSamplingRate != mpAudioTrack->getSampleRate(),
+            "ToneGenerator track sample rate %d does not match requested rate %d",
+            mpAudioTrack->getSampleRate(), mSamplingRate);
+    }
+    // Generate tone by chunks of kCadenceMs ms to keep cadencing precision
+    mProcessSize = (mSamplingRate * kCadenceMs) / 1000;
 
     mpAudioTrack->setVolume(mVolume);
     mState = TONE_INIT;
diff --git a/media/libaudioclient/aidl/android/media/GetOutputForAttrResponse.aidl b/media/libaudioclient/aidl/android/media/GetOutputForAttrResponse.aidl
index 5d066bb7cb..5eb9e56a1f 100644
--- a/media/libaudioclient/aidl/android/media/GetOutputForAttrResponse.aidl
+++ b/media/libaudioclient/aidl/android/media/GetOutputForAttrResponse.aidl
@@ -39,8 +39,4 @@ parcelable GetOutputForAttrResponse {
     boolean isBitPerfect;
     /** The corrected audio attributes. **/
     AudioAttributes attr;
-    /** initial port volume for the new audio track */
-    float volume;
-    /** initial port muted state for the new audio track */
-    boolean muted;
 }
diff --git a/media/libaudioclient/aidl/android/media/IAudioFlingerService.aidl b/media/libaudioclient/aidl/android/media/IAudioFlingerService.aidl
index 474ab11a3e..68f9438c33 100644
--- a/media/libaudioclient/aidl/android/media/IAudioFlingerService.aidl
+++ b/media/libaudioclient/aidl/android/media/IAudioFlingerService.aidl
@@ -298,8 +298,12 @@ interface IAudioFlingerService {
 
     /**
      * Get the attributes of the mix port when connecting to the given device port.
+     * If `mixPortHalId` is not `AUDIO_PORT_HANDLE_NONE`, it will be used to determine
+     * the mix port. Otherwise, `mixPort.ext.mix.handle` will be used.
      */
-    AudioPortFw getAudioMixPort(in AudioPortFw devicePort, in AudioPortFw mixPort);
+    AudioPortFw getAudioMixPort(in AudioPortFw devicePort,
+                                in AudioPortFw mixPort,
+                                int mixPortHalId);
 
     /**
      * Set internal mute for a list of tracks.
diff --git a/media/libaudioclient/aidl/android/media/IAudioPolicyService.aidl b/media/libaudioclient/aidl/android/media/IAudioPolicyService.aidl
index 590679183f..0a2e97eb57 100644
--- a/media/libaudioclient/aidl/android/media/IAudioPolicyService.aidl
+++ b/media/libaudioclient/aidl/android/media/IAudioPolicyService.aidl
@@ -42,6 +42,7 @@ import android.media.IAudioPolicyServiceClient;
 import android.media.ICaptureStateListener;
 import android.media.INativeSpatializerCallback;
 import android.media.SoundTriggerSession;
+import android.media.StartOutputResponse;
 import android.media.audio.common.AudioAttributes;
 import android.media.audio.common.AudioConfig;
 import android.media.audio.common.AudioConfigBase;
@@ -97,7 +98,7 @@ interface IAudioPolicyService {
                                               int /* Bitmask, indexed by AudioOutputFlags */ flags,
                                               in int[] /* audio_port_handle_t */ selectedDeviceIds);
 
-    void startOutput(int /* audio_port_handle_t */ portId);
+    StartOutputResponse startOutput(int /* audio_port_handle_t */ portId);
 
     void stopOutput(int /* audio_port_handle_t */ portId);
 
@@ -145,6 +146,19 @@ interface IAudioPolicyService {
 
     int getMinVolumeIndexForAttributes(in AudioAttributes attr);
 
+    void setVolumeIndexForGroup(int groupId, in AudioDeviceDescription device, int index,
+                                   boolean muted);
+
+    int getVolumeIndexForGroup(int groupId, in AudioDeviceDescription device);
+
+    int getMaxVolumeIndexForGroup(int groupId);
+
+    int getMinVolumeIndexForGroup(int groupId);
+
+    void setMaxVolumeIndexForGroup(int groupId, int maxIndex);
+
+    void setMinVolumeIndexForGroup(int groupId, int minIndex);
+
     int /* product_strategy_t */ getStrategyForStream(AudioStreamType stream);
 
     AudioDevice[] getDevicesForAttributes(in AudioAttributes attr, boolean forVolume);
diff --git a/media/libaudioclient/aidl/android/media/OpenInputRequest.aidl b/media/libaudioclient/aidl/android/media/OpenInputRequest.aidl
index 75ff8e926c..1f0b4d9940 100644
--- a/media/libaudioclient/aidl/android/media/OpenInputRequest.aidl
+++ b/media/libaudioclient/aidl/android/media/OpenInputRequest.aidl
@@ -33,4 +33,5 @@ parcelable OpenInputRequest {
     AudioSource source;
     /** Bitmask, indexed by AudioInputFlag. */
     int flags;
+    int mixPortHalId;
 }
diff --git a/media/libaudioclient/aidl/android/media/OpenOutputRequest.aidl b/media/libaudioclient/aidl/android/media/OpenOutputRequest.aidl
index 73610a8d21..b1e9d21b4c 100644
--- a/media/libaudioclient/aidl/android/media/OpenOutputRequest.aidl
+++ b/media/libaudioclient/aidl/android/media/OpenOutputRequest.aidl
@@ -34,4 +34,5 @@ parcelable OpenOutputRequest {
     /** Bitmask, indexed by AudioOutputFlag. */
     int flags;
     AudioAttributes attributes;
+    int mixPortHalId;
 }
diff --git a/media/codec2/hal/hidl/1.1/utils/InputSurface.cpp b/media/libaudioclient/aidl/android/media/StartOutputResponse.aidl
similarity index 68%
rename from media/codec2/hal/hidl/1.1/utils/InputSurface.cpp
rename to media/libaudioclient/aidl/android/media/StartOutputResponse.aidl
index ce40494ce8..0bad44c5d0 100644
--- a/media/codec2/hal/hidl/1.1/utils/InputSurface.cpp
+++ b/media/libaudioclient/aidl/android/media/StartOutputResponse.aidl
@@ -1,5 +1,5 @@
 /*
- * Copyright 2019 The Android Open Source Project
+ * Copyright (C) 2025 The Android Open Source Project
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
@@ -14,4 +14,14 @@
  * limitations under the License.
  */
 
-#include <codec2/hidl/1.1/InputSurface.h>
+package android.media;
+
+/**
+ * {@hide}
+ */
+parcelable StartOutputResponse {
+    /** port volume for the audio track */
+    float volume;
+    /** port muted state for the audio track */
+    boolean muted;
+}
diff --git a/media/libaudioclient/include/media/AudioSystem.h b/media/libaudioclient/include/media/AudioSystem.h
index 16c3a7fded..9c05f86a4a 100644
--- a/media/libaudioclient/include/media/AudioSystem.h
+++ b/media/libaudioclient/include/media/AudioSystem.h
@@ -348,10 +348,9 @@ public:
                                      audio_port_handle_t *portId,
                                      std::vector<audio_io_handle_t> *secondaryOutputs,
                                      bool *isSpatialized,
-                                     bool *isBitPerfect,
-                                     float *volume,
-                                     bool *muted);
-    static status_t startOutput(audio_port_handle_t portId);
+                                     bool *isBitPerfect);
+    static status_t startOutput(
+            audio_port_handle_t portId, float* volume, bool* muted);
     static status_t stopOutput(audio_port_handle_t portId);
     static void releaseOutput(audio_port_handle_t portId);
 
@@ -416,6 +415,64 @@ public:
 
     static status_t getMinVolumeIndexForAttributes(const audio_attributes_t &attr, int &index);
 
+    /**
+     * Set the volume index for a given volume group and device.
+     *
+     * @param groupId the volume group id
+     * @param index the volume index to set
+     * @param muted state of the volume group
+     * @param device the device to set the volume index for
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    static status_t setVolumeIndexForGroup(volume_group_t groupId, int index,
+            bool muted, audio_devices_t device);
+
+    /**
+     * Get the volume index for a given volume group and device.
+     *
+     * @param groupId the volume group id
+     * @param index the volume index to get
+     * @param device the device to get the volume index for
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    static status_t getVolumeIndexForGroup(volume_group_t groupId, int &index,
+            audio_devices_t device);
+    /**
+     * Get the maximum volume index for a given volume group
+     *
+     * @param groupId the volume group id
+     * @param index the max volume index to get
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    static status_t getMaxVolumeIndexForGroup(volume_group_t groupId, int &index);
+
+    /**
+     * Set the maximum volume index for a given volume group
+     *
+     * @param groupId the volume group id
+     * @param index the max volume index to set
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    static status_t setMaxVolumeIndexForGroup(volume_group_t groupId, int index);
+
+    /**
+     * Get the minimum volume index for a given volume group.
+     *
+     * @param groupId
+     * @param index the min volume index to get
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    static status_t getMinVolumeIndexForGroup(volume_group_t groupId, int &index);
+
+    /**
+     * Set the minimum volume index for a given volume group.
+     *
+     * @param groupId
+     * @param index the min volume index to set
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    static status_t setMinVolumeIndexForGroup(volume_group_t groupId, int index);
+
     static product_strategy_t getStrategyForStream(audio_stream_type_t stream);
     static status_t getDevicesForAttributes(const audio_attributes_t &aa,
                                             AudioDeviceTypeAddrVector *devices,
diff --git a/media/libaudioclient/include/media/IAudioFlinger.h b/media/libaudioclient/include/media/IAudioFlinger.h
index 6b501a7c05..74a09369dc 100644
--- a/media/libaudioclient/include/media/IAudioFlinger.h
+++ b/media/libaudioclient/include/media/IAudioFlinger.h
@@ -397,7 +397,8 @@ public:
     virtual status_t getAudioPolicyConfig(media::AudioPolicyConfig* output) = 0;
 
     virtual status_t getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                     struct audio_port_v7 *mixPort) const = 0;
+                                     struct audio_port_v7 *mixPort,
+                                     int32_t mixPortHalId) const = 0;
 
     virtual status_t setTracksInternalMute(
             const std::vector<media::TrackInternalMuteInfo>& tracksInternalMute) = 0;
@@ -519,7 +520,8 @@ public:
     status_t invalidateTracks(const std::vector<audio_port_handle_t>& portIds) override;
     status_t getAudioPolicyConfig(media::AudioPolicyConfig* output) override;
     status_t getAudioMixPort(const struct audio_port_v7 *devicePort,
-                             struct audio_port_v7 *mixPort) const override;
+                             struct audio_port_v7 *mixPort,
+                             int32_t mixPortHalId) const override;
     status_t setTracksInternalMute(
             const std::vector<media::TrackInternalMuteInfo>& tracksInternalMute) override;
     status_t resetReferencesForTest() override;
@@ -761,6 +763,7 @@ public:
     Status getAudioPolicyConfig(media::AudioPolicyConfig* _aidl_return) override;
     Status getAudioMixPort(const media::AudioPortFw& devicePort,
                            const media::AudioPortFw& mixPort,
+                           int32_t mixPortHalId,
                            media::AudioPortFw* _aidl_return) override;
     Status setTracksInternalMute(
             const std::vector<media::TrackInternalMuteInfo>& tracksInternalMute) override;
diff --git a/media/libaudioclient/include/media/ToneGenerator.h b/media/libaudioclient/include/media/ToneGenerator.h
index 3e515fc33f..048b82ed3c 100644
--- a/media/libaudioclient/include/media/ToneGenerator.h
+++ b/media/libaudioclient/include/media/ToneGenerator.h
@@ -258,6 +258,7 @@ private:
     static const unsigned int TONEGEN_MAX_SEGMENTS = 12;  // Maximun number of segments in a tone descriptor
     static const unsigned int TONEGEN_INF = 0xFFFFFFFF;  // Represents infinite time duration
     static const CONSTEXPR float TONEGEN_GAIN = 0.9;  // Default gain passed to  WaveGenerator().
+    static const int kCadenceMs = 20;   // Unit time for generating tones
 
     // ToneDescriptor class contains all parameters needed to generate a tone:
     //    - The array waveFreq[]:
diff --git a/media/libaudioclient/tests/Android.bp b/media/libaudioclient/tests/Android.bp
index 049402852a..7e63ba0eb5 100644
--- a/media/libaudioclient/tests/Android.bp
+++ b/media/libaudioclient/tests/Android.bp
@@ -16,6 +16,7 @@ cc_defaults {
         "-Werror",
     ],
     shared_libs: [
+        "android.media.audiopolicy-aconfig-cc",
         "libbinder",
         "libcutils",
         "liblog",
diff --git a/media/libaudioclient/tests/audio_aidl_legacy_conversion_tests.cpp b/media/libaudioclient/tests/audio_aidl_legacy_conversion_tests.cpp
index 61dfd40d4d..2967657ecd 100644
--- a/media/libaudioclient/tests/audio_aidl_legacy_conversion_tests.cpp
+++ b/media/libaudioclient/tests/audio_aidl_legacy_conversion_tests.cpp
@@ -633,6 +633,10 @@ TEST_P(AudioPortFwRoundTripTest, Aidl2Legacy2Aidl) {
     initial.sys.type = AudioPortType::DEVICE;
     initial.sys.profiles.resize(initial.hal.profiles.size());
     initial.sys.gains.resize(initial.hal.gains.size());
+    for (int i = 0; i < initial.hal.gains.size(); i++) {
+        initial.sys.gains[i].isInput = isInput;
+        initial.sys.gains[i].index = i;
+    }
     initial.sys.activeConfig =
             createAudioPortConfigFw(make_ACL_Stereo(), make_AFD_Pcm16Bit(), device);
     initial.sys.activeConfig.hal.flags = initial.hal.flags;
diff --git a/media/libaudioclient/tests/audiosystem_tests.cpp b/media/libaudioclient/tests/audiosystem_tests.cpp
index bc3bb8dda9..2eea212196 100644
--- a/media/libaudioclient/tests/audiosystem_tests.cpp
+++ b/media/libaudioclient/tests/audiosystem_tests.cpp
@@ -25,9 +25,13 @@
 #include <media/AidlConversionCppNdk.h>
 #include <media/IAudioFlinger.h>
 
+#include <android_media_audiopolicy.h>
+
 #include "audio_test_utils.h"
 #include "test_execution_tracer.h"
 
+namespace audio_flags = android::media::audiopolicy;
+
 using android::media::audio::common::AudioDeviceAddress;
 using android::media::audio::common::AudioDeviceDescription;
 using android::media::audio::common::AudioDeviceType;
@@ -47,6 +51,10 @@ void anyPatchContainsInputDevice(audio_port_handle_t deviceId, bool& res) {
     }
 }
 
+bool isNonPublicOrBluetoothScoStream(int streamType) {
+    return streamType >= AUDIO_STREAM_PUBLIC_CNT || streamType == AUDIO_STREAM_BLUETOOTH_SCO;
+}
+
 class AudioSystemTest : public ::testing::Test {
   public:
     void SetUp() override {
@@ -458,6 +466,60 @@ TEST_F(AudioSystemTest, VolumeIndexForAttributes) {
     }
 }
 
+TEST_F(AudioSystemTest, IndexForVolumeGroup) {
+    if (!audio_flags::volume_group_management_update()) {
+        GTEST_SKIP() << "RequiresFlagsEnabled volume_group_management_update";
+    }
+    std::optional<audio_port_v7> speakerPort = audio_port_v7{};
+    if (getPortByAttributes(AUDIO_PORT_ROLE_SINK, AUDIO_PORT_TYPE_DEVICE, AUDIO_DEVICE_OUT_SPEAKER,
+                            "", *speakerPort) != OK) {
+        GTEST_SKIP() << "Requires out speaker device";
+    }
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, AudioSystem::listAudioVolumeGroups(groups));
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (isNonPublicOrBluetoothScoStream(streamType)) continue;
+
+        int index;
+        EXPECT_EQ(OK, AudioSystem::getVolumeIndexForGroup(vg, index, AUDIO_DEVICE_OUT_SPEAKER))
+            << "Could not get volume index for group " << group.getName();
+
+        int indexTest;
+        EXPECT_EQ(OK, AudioSystem::getStreamVolumeIndex(streamType, &indexTest,
+                                                        AUDIO_DEVICE_OUT_SPEAKER))
+            << "Could not get volume index for stream " << toString(streamType);
+        EXPECT_EQ(index, indexTest) << "Volume index for group " << group.getName()
+        << " and stream " << toString(streamType) << " do not match";
+    }
+}
+
+TEST_F(AudioSystemTest, MinMaxIndexForVolumeGroup) {
+    if (!audio_flags::volume_group_management_update()) {
+        GTEST_SKIP() << "RequiresFlagsEnabled volume_group_management_update";
+    }
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, AudioSystem::listAudioVolumeGroups(groups));
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (isNonPublicOrBluetoothScoStream(streamType)) continue;
+        int minIndex;
+        int maxIndex;
+        EXPECT_EQ(OK, AudioSystem::getMinVolumeIndexForGroup(vg, minIndex))
+            << "Could not get min volume for group " << group.getName();
+        EXPECT_EQ(OK, AudioSystem::getMaxVolumeIndexForGroup(vg, maxIndex))
+            << "Could not get max volume for group " << group.getName();
+
+        EXPECT_TRUE(minIndex < maxIndex)
+            << "Group " << group.getName() << " min["
+            << minIndex << "] is not less than max [" << maxIndex << "]";
+    }
+}
+
 TEST_F(AudioSystemTest, DevicesRoleForCapturePreset) {
     std::vector<struct audio_port_v7> ports;
     status_t status = listAudioPorts(ports);
diff --git a/media/libaudiofoundation/AudioPort.cpp b/media/libaudiofoundation/AudioPort.cpp
index 6dbf284da0..ae5d71dbb3 100644
--- a/media/libaudiofoundation/AudioPort.cpp
+++ b/media/libaudiofoundation/AudioPort.cpp
@@ -180,6 +180,7 @@ void AudioPort::dump(std::string *dst, int spaces, const char* extraInfo, bool v
     if (!mName.empty() || extraInfo != nullptr) {
         dst->append("\n");
     }
+    dst->append(base::StringPrintf("%*sPort Hal ID: %d\n", spaces, "", mHalId));
     if (verbose) {
         std::string profilesStr;
         mProfiles.dump(&profilesStr, spaces);
@@ -231,6 +232,7 @@ bool AudioPort::equals(const sp<AudioPort> &other) const
 }
 
 status_t AudioPort::writeToParcelable(media::AudioPortFw* parcelable) const {
+    parcelable->hal.id = mHalId;
     parcelable->hal.name = mName;
     parcelable->sys.type = VALUE_OR_RETURN_STATUS(
             legacy2aidl_audio_port_type_t_AudioPortType(mType));
@@ -279,6 +281,7 @@ status_t AudioPort::readFromParcelable(const media::AudioPortFw& parcelable) {
         maxActiveCount = mixExt.maxActiveStreamCount;
         recommendedMuteDurationMs = mixExt.recommendedMuteDurationMs;
     }
+    mHalId = parcelable.hal.id;
     return OK;
 }
 
diff --git a/media/libaudiofoundation/TEST_MAPPING b/media/libaudiofoundation/TEST_MAPPING
index f7e5b12900..e999a14f9c 100644
--- a/media/libaudiofoundation/TEST_MAPPING
+++ b/media/libaudiofoundation/TEST_MAPPING
@@ -17,6 +17,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     }
diff --git a/media/libaudiofoundation/include/media/AudioPort.h b/media/libaudiofoundation/include/media/AudioPort.h
index 5786f7ffac..baac879c55 100644
--- a/media/libaudiofoundation/include/media/AudioPort.h
+++ b/media/libaudiofoundation/include/media/AudioPort.h
@@ -114,6 +114,9 @@ public:
                         ((mFlags.input & AUDIO_INPUT_FLAG_MMAP_NOIRQ) != 0)));
     }
 
+    void setHalIdForTest(int32_t halId) { mHalId = halId; }
+    int32_t getHalId() const { return mHalId; }
+
     void dump(std::string *dst, int spaces,
               const char* extraInfo = nullptr, bool verbose = true) const;
 
@@ -150,6 +153,8 @@ protected:
     // by the platform, e.g. short audio descriptor in EDID for HDMI.
     std::vector<media::audio::common::ExtraAudioDescriptor> mExtraAudioDescriptors;
     union audio_io_flags mFlags = { .output = AUDIO_OUTPUT_FLAG_NONE };
+
+    int32_t mHalId = 0;
 private:
     template <typename T, std::enable_if_t<std::is_same<T, struct audio_port>::value
                                         || std::is_same<T, struct audio_port_v7>::value, int> = 0>
diff --git a/media/libaudiohal/TEST_MAPPING b/media/libaudiohal/TEST_MAPPING
index 90f481bb6d..1acfb52809 100644
--- a/media/libaudiohal/TEST_MAPPING
+++ b/media/libaudiohal/TEST_MAPPING
@@ -14,6 +14,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     },
diff --git a/media/libaudiohal/impl/ConversionHelperAidl.cpp b/media/libaudiohal/impl/ConversionHelperAidl.cpp
index 7a3281177d..84e0e281ea 100644
--- a/media/libaudiohal/impl/ConversionHelperAidl.cpp
+++ b/media/libaudiohal/impl/ConversionHelperAidl.cpp
@@ -29,88 +29,56 @@ using aidl::android::media::audio::IHalAdapterVendorExtension;
 
 namespace android {
 
-status_t parseAndGetVendorParameters(
-        std::shared_ptr<IHalAdapterVendorExtension> vendorExt,
-        const VendorParametersRecipient& recipient,
-        const AudioParameter& parameterKeys,
-        String8* values) {
-    using ParameterScope = IHalAdapterVendorExtension::ParameterScope;
+status_t reparseVendorParameters(const std::string& vendorParameters, String8* values) {
+    // Re-parse the vendor-provided string to ensure that it is correct.
+    AudioParameter reparse(String8(vendorParameters.c_str()));
+    if (reparse.size() != 0) {
+        if (values->length() > 0) {
+            values->append(";");
+        }
+        values->append(reparse.toString().c_str());
+    }
+    return OK;
+}
+
+status_t fillVendorParameterIds(std::shared_ptr<IHalAdapterVendorExtension> vendorExt,
+                                IHalAdapterVendorExtension::ParameterScope scope,
+                                const AudioParameter& parameterKeys,
+                                std::vector<std::string>& vendorParametersIds) {
     if (parameterKeys.size() == 0) return OK;
     const String8 rawKeys = parameterKeys.keysToString();
-
-    std::vector<std::string> parameterIds;
+    assert(vendorParametersIds.size() == 0);
     RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(vendorExt->parseVendorParameterIds(
-                            ParameterScope(recipient.index()),
-                            std::string(rawKeys.c_str()), &parameterIds)));
-    if (parameterIds.empty()) return OK;
+            scope, std::string(rawKeys.c_str()), &vendorParametersIds)));
+    return OK;
+}
 
-    std::vector<VendorParameter> parameters;
-    if (recipient.index() == static_cast<int>(ParameterScope::MODULE)) {
-        auto module = std::get<static_cast<int>(ParameterScope::MODULE)>(recipient);
-        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(module->getVendorParameters(
-                                parameterIds, &parameters)));
-    } else if (recipient.index() == static_cast<int>(ParameterScope::STREAM)) {
-        auto stream = std::get<static_cast<int>(ParameterScope::STREAM)>(recipient);
-        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(stream->getVendorParameters(
-                                parameterIds, &parameters)));
-    } else {
-        LOG_ALWAYS_FATAL("%s: unexpected recipient variant index: %zu",
-                __func__, recipient.index());
-    }
-    if (!parameters.empty()) {
-        std::string vendorParameters;
-        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(vendorExt->processVendorParameters(
-                                ParameterScope(recipient.index()),
-                                parameters, &vendorParameters)));
-        // Re-parse the vendor-provided string to ensure that it is correct.
-        AudioParameter reparse(String8(vendorParameters.c_str()));
-        if (reparse.size() != 0) {
-            if (values->length() > 0) {
-                values->append(";");
-            }
-            values->append(reparse.toString().c_str());
-        }
+status_t fillKeyValuePairsFromVendorParameters(
+        std::shared_ptr<IHalAdapterVendorExtension> vendorExt,
+        IHalAdapterVendorExtension::ParameterScope scope,
+        const std::vector<VendorParameter>& vendorParameters, String8* values) {
+    if (vendorParameters.empty()) {
+        return OK;
     }
+    std::string keyValuePairs;
+    RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+            vendorExt->processVendorParameters(scope, vendorParameters, &keyValuePairs)));
+    RETURN_STATUS_IF_ERROR(reparseVendorParameters(keyValuePairs, values));
     return OK;
 }
 
-status_t parseAndSetVendorParameters(
-        std::shared_ptr<IHalAdapterVendorExtension> vendorExt,
-        const VendorParametersRecipient& recipient,
-        const AudioParameter& parameters) {
-    using ParameterScope = IHalAdapterVendorExtension::ParameterScope;
+status_t fillVendorParameters(std::shared_ptr<IHalAdapterVendorExtension> vendorExt,
+                              IHalAdapterVendorExtension::ParameterScope scope,
+                              const AudioParameter& parameters,
+                              std::vector<VendorParameter>& syncParameters,
+                              std::vector<VendorParameter>& asyncParameters) {
     if (parameters.size() == 0) return OK;
-    const String8 rawKeysAndValues = parameters.toString();
 
-    std::vector<VendorParameter> syncParameters, asyncParameters;
+    assert(syncParameters.empty() && asyncParameters.empty());
+
+    const String8 rawKeysAndValues = parameters.toString();
     RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(vendorExt->parseVendorParameters(
-                            ParameterScope(recipient.index()),
-                            std::string(rawKeysAndValues.c_str()),
-                            &syncParameters, &asyncParameters)));
-    if (recipient.index() == static_cast<int>(ParameterScope::MODULE)) {
-        auto module = std::get<static_cast<int>(ParameterScope::MODULE)>(recipient);
-        if (!syncParameters.empty()) {
-            RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(module->setVendorParameters(
-                                    syncParameters, false /*async*/)));
-        }
-        if (!asyncParameters.empty()) {
-            RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(module->setVendorParameters(
-                                    asyncParameters, true /*async*/)));
-        }
-    } else if (recipient.index() == static_cast<int>(ParameterScope::STREAM)) {
-        auto stream = std::get<static_cast<int>(ParameterScope::STREAM)>(recipient);
-        if (!syncParameters.empty()) {
-            RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(stream->setVendorParameters(
-                                    syncParameters, false /*async*/)));
-        }
-        if (!asyncParameters.empty()) {
-            RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(stream->setVendorParameters(
-                                    asyncParameters, true /*async*/)));
-        }
-    } else {
-        LOG_ALWAYS_FATAL("%s: unexpected recipient variant index: %zu",
-                __func__, recipient.index());
-    }
+            scope, std::string(rawKeysAndValues.c_str()), &syncParameters, &asyncParameters)));
     return OK;
 }
 
diff --git a/media/libaudiohal/impl/ConversionHelperAidl.h b/media/libaudiohal/impl/ConversionHelperAidl.h
index fe00fb2f94..abb735e683 100644
--- a/media/libaudiohal/impl/ConversionHelperAidl.h
+++ b/media/libaudiohal/impl/ConversionHelperAidl.h
@@ -106,14 +106,21 @@ error::Result<bool> filterOutAndProcessParameter(
 using VendorParametersRecipient = std::variant<
         std::shared_ptr<::aidl::android::hardware::audio::core::IModule>,
         std::shared_ptr<::aidl::android::hardware::audio::core::IStreamCommon>>;
-status_t parseAndGetVendorParameters(
+status_t fillVendorParameterIds(
         std::shared_ptr<::aidl::android::media::audio::IHalAdapterVendorExtension> vendorExt,
-        const VendorParametersRecipient& recipient,
-        const AudioParameter& parameterKeys,
+        ::aidl::android::media::audio::IHalAdapterVendorExtension::ParameterScope scope,
+        const AudioParameter& parameterKeys, std::vector<std::string>& vendorParametersIds);
+status_t fillKeyValuePairsFromVendorParameters(
+        std::shared_ptr<::aidl::android::media::audio::IHalAdapterVendorExtension> vendorExt,
+        ::aidl::android::media::audio::IHalAdapterVendorExtension::ParameterScope scope,
+        const std::vector<::aidl::android::hardware::audio::core::VendorParameter>&
+                vendorParameters,
         String8* values);
-status_t parseAndSetVendorParameters(
+status_t fillVendorParameters(
         std::shared_ptr<::aidl::android::media::audio::IHalAdapterVendorExtension> vendorExt,
-        const VendorParametersRecipient& recipient,
-        const AudioParameter& parameters);
+        ::aidl::android::media::audio::IHalAdapterVendorExtension::ParameterScope scope,
+        const AudioParameter& parameters,
+        std::vector<::aidl::android::hardware::audio::core::VendorParameter>& syncParameters,
+        std::vector<::aidl::android::hardware::audio::core::VendorParameter>& asyncParameters);
 
 }  // namespace android
diff --git a/media/libaudiohal/impl/DeviceHalAidl.cpp b/media/libaudiohal/impl/DeviceHalAidl.cpp
index 36a40cddd0..db279c14e3 100644
--- a/media/libaudiohal/impl/DeviceHalAidl.cpp
+++ b/media/libaudiohal/impl/DeviceHalAidl.cpp
@@ -23,6 +23,7 @@
 #include <aidl/android/hardware/audio/core/BnStreamOutEventCallback.h>
 #include <aidl/android/hardware/audio/core/StreamDescriptor.h>
 #include <android/binder_ibinder_platform.h>
+#include <com_android_media_audio.h>
 #include <error/expected_utils.h>
 #include <media/AidlConversionCppNdk.h>
 #include <media/AidlConversionNdk.h>
@@ -178,18 +179,21 @@ status_t DeviceHalAidl::initCheck() {
     AUGMENT_LOG(D);
     TIME_CHECK();
     RETURN_IF_MODULE_NOT_INIT(NO_INIT);
-    std::lock_guard l(mLock);
     int32_t aidlVersion = 0;
-    RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(mModule->getInterfaceVersion(&aidlVersion)));
+    {
+        std::lock_guard l(mLock);
+        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(mModule->getInterfaceVersion(&aidlVersion)));
+    }
     if (aidlVersion > kAidlVersion3) {
         mHasClipTransitionSupport = true;
     } else {
         AudioParameter parameterKeys;
         parameterKeys.addKey(String8(AudioParameter::keyClipTransitionSupport));
         String8 values;
-        auto status = parseAndGetVendorParameters(mVendorExt, mModule, parameterKeys, &values);
+        auto status = parseAndGetVendorParameters(parameterKeys, &values);
         mHasClipTransitionSupport = status == OK && !values.empty();
     }
+    std::lock_guard l(mLock);
     return mMapper.initialize();
 }
 
@@ -314,8 +318,7 @@ status_t DeviceHalAidl::setParameters(const String8& kvPairs) {
     if (status_t status = filterAndUpdateTelephonyParameters(parameters); status != OK) {
         AUGMENT_LOG(W, "filterAndUpdateTelephonyParameters failed: %d", status);
     }
-    std::lock_guard l(mLock);
-    return parseAndSetVendorParameters(mVendorExt, mModule, parameters);
+    return parseAndSetVendorParameters(parameters);
 }
 
 status_t DeviceHalAidl::getParameters(const String8& keys, String8 *values) {
@@ -335,8 +338,7 @@ status_t DeviceHalAidl::getParameters(const String8& keys, String8 *values) {
         AUGMENT_LOG(W, "filterAndRetrieveBtLeParameters failed: %d", status);
     }
     *values = result.toString();
-    std::lock_guard l(mLock);
-    return parseAndGetVendorParameters(mVendorExt, mModule, parameterKeys, values);
+    return parseAndGetVendorParameters(parameterKeys, values);
 }
 
 status_t DeviceHalAidl::getInputBufferSize(struct audio_config* config, size_t* size) {
@@ -361,7 +363,7 @@ status_t DeviceHalAidl::getInputBufferSize(struct audio_config* config, size_t*
     {
         std::lock_guard l(mLock);
         RETURN_STATUS_IF_ERROR(mMapper.prepareToOpenStream(
-                        0 /*handle*/, aidlDevice, aidlFlags, aidlSource,
+                        0 /*handle*/, 0 /*mixPortHalId*/, aidlDevice, aidlFlags, aidlSource,
                         &cleanups, &aidlConfig, &mixPortConfig, &aidlPatch));
     }
     *config = VALUE_OR_RETURN_STATUS(
@@ -373,6 +375,42 @@ status_t DeviceHalAidl::getInputBufferSize(struct audio_config* config, size_t*
     return OK;
 }
 
+status_t DeviceHalAidl::parseAndGetVendorParameters(const AudioParameter& parameterKeys,
+                                                    String8* values) {
+    std::vector<std::string> vendorParameterIds;
+    RETURN_STATUS_IF_ERROR(
+            fillVendorParameterIds(mVendorExt, IHalAdapterVendorExtension::ParameterScope::MODULE,
+                                   parameterKeys, vendorParameterIds));
+    if (vendorParameterIds.empty()) {
+        return OK;
+    }
+    std::vector<VendorParameter> vendorParameters;
+    {
+        std::lock_guard l(mLock);
+        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+                mModule->getVendorParameters(vendorParameterIds, &vendorParameters)));
+    }
+    RETURN_STATUS_IF_ERROR(fillKeyValuePairsFromVendorParameters(
+            mVendorExt, IHalAdapterVendorExtension::ParameterScope::MODULE, vendorParameters,
+            values));
+    return OK;
+}
+
+status_t DeviceHalAidl::parseAndSetVendorParameters(const AudioParameter& parameters) {
+    std::vector<VendorParameter> syncParameters, asyncParameters;
+    RETURN_STATUS_IF_ERROR(fillVendorParameters(mVendorExt,
+                                                IHalAdapterVendorExtension::ParameterScope::MODULE,
+                                                parameters, syncParameters, asyncParameters));
+    std::lock_guard l(mLock);
+    if (!syncParameters.empty())
+        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+                mModule->setVendorParameters(syncParameters, false /*async*/)));
+    if (!asyncParameters.empty())
+        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(
+                mModule->setVendorParameters(asyncParameters, true /*async*/)));
+    return OK;
+}
+
 namespace {
 
 class StreamCallbackBase {
@@ -494,8 +532,10 @@ status_t DeviceHalAidl::openOutputStream(
         audio_output_flags_t flags, struct audio_config* config,
         const char* address,
         sp<StreamOutHalInterface>* outStream,
-        const std::vector<playback_track_metadata_v7_t>& sourceMetadata) {
-    AUGMENT_LOG(D, "handle: %d devices %0x flags %0x", handle, devices, flags);
+        const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+        int32_t mixPortHalId) {
+    AUGMENT_LOG(D, "handle: %d devices %0x flags %0x mixPortHalId %d",
+                handle, devices, flags, mixPortHalId);
 
     TIME_CHECK();
     RETURN_IF_MODULE_NOT_INIT(NO_INIT);
@@ -521,8 +561,8 @@ status_t DeviceHalAidl::openOutputStream(
     Hal2AidlMapper::Cleanups cleanups(mMapperAccessor);
     {
         std::lock_guard l(mLock);
-        RETURN_STATUS_IF_ERROR(mMapper.prepareToOpenStream(aidlHandle, aidlDevice, aidlFlags,
-                        AudioSource::SYS_RESERVED_INVALID /*only needed for input*/,
+        RETURN_STATUS_IF_ERROR(mMapper.prepareToOpenStream(aidlHandle, mixPortHalId, aidlDevice,
+                        aidlFlags, AudioSource::SYS_RESERVED_INVALID /*only needed for input*/,
                         &cleanups, &aidlConfig, &mixPortConfig, &aidlPatch));
     }
     *config = VALUE_OR_RETURN_STATUS(
@@ -594,8 +634,10 @@ status_t DeviceHalAidl::openInputStream(
         struct audio_config* config, audio_input_flags_t flags,
         const char* address, audio_source_t source,
         audio_devices_t outputDevice, const char* outputDeviceAddress,
-        sp<StreamInHalInterface>* inStream) {
-    AUGMENT_LOG(D, "handle: %d devices %0x flags %0x", handle, devices, flags);
+        sp<StreamInHalInterface>* inStream,
+        int32_t mixPortHalId) {
+    AUGMENT_LOG(D, "handle: %d devices %0x flags %0x mixPortHalId %d",
+                handle, devices, flags, mixPortHalId);
     TIME_CHECK();
     RETURN_IF_MODULE_NOT_INIT(NO_INIT);
     if (inStream == nullptr || config == nullptr) {
@@ -620,7 +662,7 @@ status_t DeviceHalAidl::openInputStream(
     {
         std::lock_guard l(mLock);
         RETURN_STATUS_IF_ERROR(mMapper.prepareToOpenStream(
-                        aidlHandle, aidlDevice, aidlFlags, aidlSource,
+                        aidlHandle, mixPortHalId, aidlDevice, aidlFlags, aidlSource,
                         &cleanups, &aidlConfig, &mixPortConfig, &aidlPatch));
     }
     *config = VALUE_OR_RETURN_STATUS(
@@ -820,7 +862,8 @@ status_t DeviceHalAidl::getAudioPort(struct audio_port_v7 *port) {
 }
 
 status_t DeviceHalAidl::getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                        struct audio_port_v7 *mixPort) {
+                                        struct audio_port_v7 *mixPort,
+                                        int32_t mixPortHalId) {
     AUGMENT_LOG(D);
     TIME_CHECK();
     RETURN_IF_MODULE_NOT_INIT(NO_INIT);
@@ -830,6 +873,43 @@ status_t DeviceHalAidl::getAudioMixPort(const struct audio_port_v7 *devicePort,
         AUGMENT_LOG(E, "invalid device or mix port");
         return BAD_VALUE;
     }
+
+    if (com::android::media::audio::check_route_in_get_audio_mix_port()) {
+        std::lock_guard l(mLock);
+
+        const bool isInput = VALUE_OR_RETURN_STATUS(
+                ::aidl::android::portDirection(devicePort->role, devicePort->type)) ==
+                ::aidl::android::AudioPortDirection::INPUT;
+
+        AudioPort aidlDevicePort;
+        auto aidlPort = VALUE_OR_RETURN_STATUS(
+                ::aidl::android::legacy2aidl_audio_port_v7_AudioPort(*devicePort, isInput));
+        const auto& matchDevice = aidlPort.ext.get<AudioPortExt::device>().device;
+        RETURN_STATUS_IF_ERROR(mMapper.getAudioPortCached(matchDevice, &aidlDevicePort));
+
+        AudioPort aidlMixPort;
+        if (mixPortHalId != AUDIO_PORT_HANDLE_NONE) {
+            RETURN_STATUS_IF_ERROR(mMapper.updateAudioPort(mixPortHalId, &aidlMixPort));
+        } else {
+            const int32_t aidlHandle = VALUE_OR_RETURN_STATUS(
+                  ::aidl::android::legacy2aidl_audio_io_handle_t_int32_t(mixPort->ext.mix.handle));
+            if (aidlHandle == AUDIO_IO_HANDLE_NONE) {
+                AUGMENT_LOG(E, "mix port has neither handle nor port ID");
+                return BAD_VALUE;
+            }
+            RETURN_STATUS_IF_ERROR(mMapper.getAudioMixPort(aidlHandle, &aidlMixPort));
+        }
+
+        if (!mMapper.isRoutable(aidlDevicePort.id, aidlMixPort.id)) {
+            return INVALID_OPERATION;
+        }
+
+        *mixPort = VALUE_OR_RETURN_STATUS(::aidl::android::aidl2legacy_AudioPort_audio_port_v7(
+                aidlMixPort, isInput));
+
+        return OK;
+    }
+
     const int32_t aidlHandle = VALUE_OR_RETURN_STATUS(
             ::aidl::android::legacy2aidl_audio_io_handle_t_int32_t(mixPort->ext.mix.handle));
     AudioPort port;
diff --git a/media/libaudiohal/impl/DeviceHalAidl.h b/media/libaudiohal/impl/DeviceHalAidl.h
index 173d16f25c..50b9c09f19 100644
--- a/media/libaudiohal/impl/DeviceHalAidl.h
+++ b/media/libaudiohal/impl/DeviceHalAidl.h
@@ -121,7 +121,8 @@ class DeviceHalAidl : public DeviceHalInterface, public ConversionHelperAidl,
                               audio_output_flags_t flags, struct audio_config* config,
                               const char* address, sp<StreamOutHalInterface>* outStream,
                               const std::vector<playback_track_metadata_v7_t>&
-                                                               sourceMetadata = {}) override;
+                                                               sourceMetadata = {},
+                              int32_t mixPortHalId = 0) override;
 
     // Creates and opens the audio hardware input stream. The stream is closed
     // by releasing all references to the returned object.
@@ -129,7 +130,8 @@ class DeviceHalAidl : public DeviceHalInterface, public ConversionHelperAidl,
                              struct audio_config* config, audio_input_flags_t flags,
                              const char* address, audio_source_t source,
                              audio_devices_t outputDevice, const char* outputDeviceAddress,
-                             sp<StreamInHalInterface>* inStream) override;
+                             sp<StreamInHalInterface>* inStream,
+                             int32_t mixPortHalId = 0) override;
 
     // Returns whether createAudioPatch and releaseAudioPatch operations are supported.
     status_t supportsAudioPatches(bool* supportsPatches) override;
@@ -182,7 +184,8 @@ class DeviceHalAidl : public DeviceHalInterface, public ConversionHelperAidl,
     status_t setSimulateDeviceConnections(bool enabled) override;
 
     status_t getAudioMixPort(const struct audio_port_v7* devicePort,
-                             struct audio_port_v7* mixPort) override;
+                             struct audio_port_v7* mixPort,
+                             int32_t mixPortHalId) override;
 
     status_t dump(int fd, const Vector<String16>& args) override;
 
@@ -216,6 +219,8 @@ class DeviceHalAidl : public DeviceHalInterface, public ConversionHelperAidl,
     status_t filterAndUpdateBtScoParameters(AudioParameter &parameters);
     status_t filterAndUpdateScreenParameters(AudioParameter &parameters);
     status_t filterAndUpdateTelephonyParameters(AudioParameter &parameters);
+    status_t parseAndGetVendorParameters(const AudioParameter& parameterKeys, String8* values);
+    status_t parseAndSetVendorParameters(const AudioParameter& parameters);
 
     // CallbackBroker implementation
     void clearCallbacks(void* cookie) override;
diff --git a/media/libaudiohal/impl/DeviceHalHidl.cpp b/media/libaudiohal/impl/DeviceHalHidl.cpp
index 263ef968ba..01102d3dc8 100644
--- a/media/libaudiohal/impl/DeviceHalHidl.cpp
+++ b/media/libaudiohal/impl/DeviceHalHidl.cpp
@@ -260,7 +260,8 @@ status_t DeviceHalHidl::openOutputStream(
         struct audio_config *config,
         const char *address,
         sp<StreamOutHalInterface> *outStream,
-        const std::vector<playback_track_metadata_v7_t>& sourceMetadata) {
+        const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+        int32_t /* mixPortHalId */) {
     TIME_CHECK();
     if (mDevice == 0) return NO_INIT;
     DeviceAddress hidlDevice;
@@ -332,7 +333,8 @@ status_t DeviceHalHidl::openInputStream(
         audio_source_t source,
         audio_devices_t outputDevice,
         const char *outputDeviceAddress,
-        sp<StreamInHalInterface> *inStream) {
+        sp<StreamInHalInterface> *inStream,
+        int32_t /*mixPortHalId*/) {
     TIME_CHECK();
     if (mDevice == 0) return NO_INIT;
     DeviceAddress hidlDevice;
@@ -763,7 +765,13 @@ status_t getParametersFromStream(
 } // namespace
 
 status_t DeviceHalHidl::getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                        struct audio_port_v7 *mixPort) {
+                                        struct audio_port_v7 *mixPort,
+                                        int32_t mixPortHalId __unused) {
+    if (mixPort->ext.mix.handle == AUDIO_IO_HANDLE_NONE) {
+        ALOGW("%s: ext.mix.handle is not specified", __func__);
+        return BAD_VALUE;
+    }
+
     // For HIDL HAL, querying mix port information is not supported. If the HAL supports
     // `getAudioPort` API to query the device port attributes, use the structured audio profiles
     // that have the same attributes reported by the `getParameters` API. Otherwise, only use
diff --git a/media/libaudiohal/impl/DeviceHalHidl.h b/media/libaudiohal/impl/DeviceHalHidl.h
index 5f3e08c975..900134e4e0 100644
--- a/media/libaudiohal/impl/DeviceHalHidl.h
+++ b/media/libaudiohal/impl/DeviceHalHidl.h
@@ -75,7 +75,8 @@ class DeviceHalHidl : public DeviceHalInterface, public CoreConversionHelperHidl
                               audio_output_flags_t flags, struct audio_config* config,
                               const char* address, sp<StreamOutHalInterface>* outStream,
                               const std::vector<playback_track_metadata_v7_t>&
-                                                                sourceMetadata = {}) override;
+                                                                sourceMetadata = {},
+                              int32_t mixPortHalId = 0) override;
 
     // Creates and opens the audio hardware input stream. The stream is closed
     // by releasing all references to the returned object.
@@ -83,7 +84,8 @@ class DeviceHalHidl : public DeviceHalInterface, public CoreConversionHelperHidl
                              struct audio_config* config, audio_input_flags_t flags,
                              const char* address, audio_source_t source,
                              audio_devices_t outputDevice, const char* outputDeviceAddress,
-                             sp<StreamInHalInterface>* inStream) override;
+                             sp<StreamInHalInterface>* inStream,
+                             int32_t mixPortHalId = 0) override;
 
     // Returns whether createAudioPatch and releaseAudioPatch operations are supported.
     status_t supportsAudioPatches(bool* supportsPatches) override;
@@ -149,7 +151,8 @@ class DeviceHalHidl : public DeviceHalInterface, public CoreConversionHelperHidl
     status_t prepareToDisconnectExternalDevice(const struct audio_port_v7* port) override;
 
     status_t getAudioMixPort(const struct audio_port_v7* devicePort,
-                             struct audio_port_v7* mixPort) override;
+                             struct audio_port_v7* mixPort,
+                             int32_t mixPortHalId) override;
 
   private:
     friend class DevicesFactoryHalHidl;
diff --git a/media/libaudiohal/impl/EffectProxy.cpp b/media/libaudiohal/impl/EffectProxy.cpp
index ac3975e04b..2fad0cb8ca 100644
--- a/media/libaudiohal/impl/EffectProxy.cpp
+++ b/media/libaudiohal/impl/EffectProxy.cpp
@@ -325,31 +325,23 @@ bool EffectProxy::isTunnel() const {
            Flags::HardwareAccelerator::TUNNEL;
 }
 
-binder_status_t EffectProxy::dump(int fd, const char** args, uint32_t numArgs) {
-    const std::string dumpString = toString();
+binder_status_t EffectProxy::dump(int fd, const char**, uint32_t) {
+    const std::string dumpString = toString(8 /* spaces */);
     write(fd, dumpString.c_str(), dumpString.size());
-
-    return runWithAllSubEffects([&](std::shared_ptr<IEffect>& effect) {
-               return ndk::ScopedAStatus::fromStatus(effect->dump(fd, args, numArgs));
-           })
-            .getStatus();
+    return STATUS_OK;
 }
 
-std::string EffectProxy::toString(size_t level) const {
-    std::string prefixSpace(level, ' ');
-    std::string ss = prefixSpace + "EffectProxy:\n";
-    prefixSpace += " ";
-    base::StringAppendF(&ss, "%sDescriptorCommon: %s\n", prefixSpace.c_str(),
-                        mDescriptorCommon.toString().c_str());
-    base::StringAppendF(&ss, "%sDescriptorCapability: %s\n", prefixSpace.c_str(),
-                        mSharedCapability.toString().c_str());
-    base::StringAppendF(&ss, "%sActiveSubIdx: %zu\n", prefixSpace.c_str(), mActiveSubIdx);
-    base::StringAppendF(&ss, "%sAllSubEffects:\n", prefixSpace.c_str());
+std::string EffectProxy::toString(size_t spaces) const {
+    std::string prefixSpace(spaces, ' ');
+    std::string ss = prefixSpace + "EffectProxy (sub-effects):\n";
     for (size_t i = 0; i < mSubEffects.size(); i++) {
-        base::StringAppendF(&ss, "%s[%zu] - Handle: %p, %s\n", prefixSpace.c_str(), i,
-                            mSubEffects[i].handle.get(),
-                            mSubEffects[i].descriptor.toString().c_str());
+        base::StringAppendF(
+                &ss, "%s[%s] - Handle: %p, implementation UUID: %s\n", prefixSpace.c_str(),
+                (i == mActiveSubIdx) ? "ACTIVE" : "INACTIVE", mSubEffects[i].handle.get(),
+                android::audio::utils::toString(mSubEffects[i].descriptor.common.id.uuid).c_str());
     }
+    base::StringAppendF(&ss, "%sDescriptorCapability: %s\n", prefixSpace.c_str(),
+                        mSharedCapability.toString().c_str());
     return ss;
 }
 
diff --git a/media/libaudiohal/impl/Hal2AidlMapper.cpp b/media/libaudiohal/impl/Hal2AidlMapper.cpp
index 5642b6ec4b..1c76cf888d 100644
--- a/media/libaudiohal/impl/Hal2AidlMapper.cpp
+++ b/media/libaudiohal/impl/Hal2AidlMapper.cpp
@@ -240,6 +240,44 @@ status_t Hal2AidlMapper::createOrUpdatePatch(
     return OK;
 }
 
+status_t Hal2AidlMapper::createOrUpdatePortConfig(
+        const AudioPort& audioPort,
+        const AudioConfig& config, const std::optional<AudioIoFlags>& flags,
+        AudioSource source, int32_t ioHandle, AudioPortConfig* result, bool* created) {
+    AudioPortConfig requestedPortConfig;
+    requestedPortConfig.portId = audioPort.id;
+    setPortConfigFromConfig(&requestedPortConfig, config);
+    requestedPortConfig.flags = audioPort.flags;
+    requestedPortConfig.ext = AudioPortMixExt{ .handle = ioHandle };
+    if (flags.has_value() && flags.value().getTag() == AudioIoFlags::Tag::input
+        && source != AudioSource::SYS_RESERVED_INVALID) {
+        requestedPortConfig.ext.get<AudioPortExt::Tag::mix>().usecase =
+                AudioPortMixExtUseCase::make<AudioPortMixExtUseCase::Tag::source>(source);
+    }
+    return createOrUpdatePortConfig(requestedPortConfig, result, created);
+}
+
+status_t Hal2AidlMapper::createOrUpdatePortConfig(
+        const AudioPortConfig& currentPortConfig, const AudioConfig& config, AudioSource source,
+        AudioPortConfig* result, bool *created) {
+    AudioPortConfig requestedPortConfig = currentPortConfig;
+    setPortConfigFromConfig(&requestedPortConfig, config);
+
+    AudioPortMixExt& mixExt = requestedPortConfig.ext.get<AudioPortExt::Tag::mix>();
+    if (mixExt.usecase.getTag() == AudioPortMixExtUseCase::Tag::source &&
+        source != AudioSource::SYS_RESERVED_INVALID) {
+        mixExt.usecase.get<AudioPortMixExtUseCase::Tag::source>() = source;
+    }
+
+    if (requestedPortConfig != currentPortConfig) {
+        return createOrUpdatePortConfig(requestedPortConfig, result, created);
+    } else {
+        *result = currentPortConfig;
+        *created = false;
+    }
+    return OK;
+}
+
 status_t Hal2AidlMapper::createOrUpdatePortConfig(
         const AudioPortConfig& requestedPortConfig, AudioPortConfig* result, bool* created) {
     bool applied = false;
@@ -364,6 +402,35 @@ status_t Hal2AidlMapper::findOrCreateDevicePortConfig(
     return OK;
 }
 
+status_t Hal2AidlMapper::findOrCreateMixPortConfig(
+        const AudioConfig& config, const std::optional<AudioIoFlags>& flags, int32_t ioHandle,
+        int32_t mixPortHalId, AudioSource source, const std::set<int32_t>& destinationPortIds,
+        AudioPortConfig* portConfig, bool* created) {
+    if (mixPortHalId == 0) {
+        // The mix port id is unknown, use the requested values to find the matched mix port
+        // configuration or create a new one if there is not a matched mix port configuration.
+        return findOrCreateMixPortConfig(
+                config, flags, ioHandle, source, destinationPortIds, portConfig, created);
+    }
+    if (auto portConfigIt = findPortConfig(config, flags, ioHandle);
+            portConfigIt == mPortConfigs.end()) {
+        // There is not mix port config found with the given values, created a new one with
+        // with the mix port id.
+        auto iter = mPorts.find(mixPortHalId);
+        if (iter == mPorts.end()) {
+            return BAD_VALUE;
+        }
+        return createOrUpdatePortConfig(
+                iter->second, config, flags, source, ioHandle, portConfig, created);
+    } else {
+        LOG_ALWAYS_FATAL_IF(portConfigIt->second.portId != mixPortHalId,
+                            "%s, existing mix port config with ioHandle=%d has port id=%d, "
+                           "different from the requested port id=%d",
+                           __func__, ioHandle, portConfigIt->second.portId, mixPortHalId);
+        return createOrUpdatePortConfig(portConfigIt->second, config, source, portConfig, created);
+    }
+}
+
 status_t Hal2AidlMapper::findOrCreateMixPortConfig(
         const AudioConfig& config, const std::optional<AudioIoFlags>& flags, int32_t ioHandle,
         AudioSource source, const std::set<int32_t>& destinationPortIds,
@@ -432,17 +499,8 @@ status_t Hal2AidlMapper::findOrCreateMixPortConfig(
                         config.toString().c_str(), matchFlags.toString().c_str());
             return BAD_VALUE;
         }
-        AudioPortConfig requestedPortConfig;
-        requestedPortConfig.portId = portsIt->first;
-        setPortConfigFromConfig(&requestedPortConfig, config);
-        requestedPortConfig.flags = portsIt->second.flags;
-        requestedPortConfig.ext = AudioPortMixExt{ .handle = ioHandle };
-        if (matchFlags.getTag() == AudioIoFlags::Tag::input
-                && source != AudioSource::SYS_RESERVED_INVALID) {
-            requestedPortConfig.ext.get<AudioPortExt::Tag::mix>().usecase =
-                    AudioPortMixExtUseCase::make<AudioPortMixExtUseCase::Tag::source>(source);
-        }
-        return createOrUpdatePortConfig(requestedPortConfig, portConfig, created);
+        return createOrUpdatePortConfig(
+                portsIt->second, config, flags, source, ioHandle, portConfig, created);
     } else if (portConfigIt == mPortConfigs.end() && !flags.has_value()) {
         AUGMENT_LOG(W,
                     "mix port config for %s, handle %d not found "
@@ -450,23 +508,8 @@ status_t Hal2AidlMapper::findOrCreateMixPortConfig(
                     config.toString().c_str(), ioHandle);
         return BAD_VALUE;
     } else {
-        AudioPortConfig requestedPortConfig = portConfigIt->second;
-        setPortConfigFromConfig(&requestedPortConfig, config);
-
-        AudioPortMixExt& mixExt = requestedPortConfig.ext.get<AudioPortExt::Tag::mix>();
-        if (mixExt.usecase.getTag() == AudioPortMixExtUseCase::Tag::source &&
-                source != AudioSource::SYS_RESERVED_INVALID) {
-            mixExt.usecase.get<AudioPortMixExtUseCase::Tag::source>() = source;
-        }
-
-        if (requestedPortConfig != portConfigIt->second) {
-            return createOrUpdatePortConfig(requestedPortConfig, portConfig, created);
-        } else {
-            *portConfig = portConfigIt->second;
-            *created = false;
-        }
+        return createOrUpdatePortConfig(portConfigIt->second, config, source, portConfig, created);
     }
-    return OK;
 }
 
 status_t Hal2AidlMapper::findOrCreatePortConfig(
@@ -488,8 +531,8 @@ status_t Hal2AidlMapper::findOrCreatePortConfig(
                 requestedPortConfig.ext.get<Tag::mix>().usecase.
                 get<AudioPortMixExtUseCase::Tag::source>() : AudioSource::SYS_RESERVED_INVALID;
         return findOrCreateMixPortConfig(config, requestedPortConfig.flags,
-                requestedPortConfig.ext.get<Tag::mix>().handle, source, destinationPortIds,
-                portConfig, created);
+                requestedPortConfig.ext.get<Tag::mix>().handle, 0 /*mixPortHalId*/,
+                source, destinationPortIds, portConfig, created);
     } else if (requestedPortConfig.ext.getTag() == Tag::device) {
         const auto& p = requestedPortConfig;
         const bool hasAudioConfig =
@@ -796,6 +839,16 @@ std::set<int32_t> Hal2AidlMapper::getPatchIdsByPortId(int32_t portId) {
     return result;
 }
 
+void Hal2AidlMapper::insertConnectedPort(
+      int32_t portId, const ::aidl::android::media::audio::common::AudioPort& devicePort) {
+    const auto [it, inserted] = mPorts.insert(std::make_pair(portId, devicePort));
+    LOG_ALWAYS_FATAL_IF(
+        !inserted, "%s duplicate port ID received from HAL: %s, existing port: %s",
+        __func__, devicePort.toString().c_str(), it->second.toString().c_str());
+    mConnectedPorts.insert(portId);
+    updateDynamicMixPorts();
+}
+
 status_t Hal2AidlMapper::prepareToDisconnectExternalDevice(const AudioPort& devicePort) {
     auto portsIt = findPort(devicePort.ext.get<AudioPortExt::device>().device);
     if (portsIt == mPorts.end()) {
@@ -805,11 +858,12 @@ status_t Hal2AidlMapper::prepareToDisconnectExternalDevice(const AudioPort& devi
 }
 
 status_t Hal2AidlMapper::prepareToOpenStream(
-        int32_t ioHandle, const AudioDevice& device, const AudioIoFlags& flags,
-        AudioSource source, Cleanups* cleanups, AudioConfig* config,
-        AudioPortConfig* mixPortConfig, AudioPatch* patch) {
-    AUGMENT_LOG(D, "handle %d, device %s, flags %s, source %s, config %s, mixport config %s",
-                ioHandle, device.toString().c_str(), flags.toString().c_str(),
+        int32_t ioHandle, int32_t mixPortHalId, const AudioDevice& device,
+        const AudioIoFlags& flags, AudioSource source, Cleanups* cleanups,
+        AudioConfig* config, AudioPortConfig* mixPortConfig, AudioPatch* patch) {
+    AUGMENT_LOG(D, "handle %d, mixPortHalId %d, device %s, flags %s, source %s, config %s, "
+                   "mixport config %s",
+                ioHandle, mixPortHalId, device.toString().c_str(), flags.toString().c_str(),
                 toString(source).c_str(), config->toString().c_str(),
                 mixPortConfig->toString().c_str());
     resetUnusedPatchesAndPortConfigs();
@@ -824,7 +878,7 @@ status_t Hal2AidlMapper::prepareToOpenStream(
     if (created) {
         cleanups->add(&Hal2AidlMapper::resetPortConfig, devicePortConfig.id);
     }
-    status_t status = prepareToOpenStreamHelper(ioHandle, devicePortConfig.portId,
+    status_t status = prepareToOpenStreamHelper(ioHandle, mixPortHalId, devicePortConfig.portId,
             devicePortConfig.id, flags, source, initialConfig, cleanups, config,
             mixPortConfig, patch);
     if (status != OK && !(mRemoteSubmixOut.has_value() &&
@@ -837,7 +891,7 @@ status_t Hal2AidlMapper::prepareToOpenStream(
         if (setConfigFromPortConfig(&deviceConfig, devicePortConfig)->base != initialConfig.base) {
             AUGMENT_LOG(D, "retrying with device port config: %s",
                         devicePortConfig.toString().c_str());
-            status = prepareToOpenStreamHelper(ioHandle, devicePortConfig.portId,
+            status = prepareToOpenStreamHelper(ioHandle, mixPortHalId, devicePortConfig.portId,
                     devicePortConfig.id, flags, source, initialConfig, cleanups,
                     &deviceConfig, mixPortConfig, patch);
             if (status == OK) {
@@ -849,13 +903,13 @@ status_t Hal2AidlMapper::prepareToOpenStream(
 }
 
 status_t Hal2AidlMapper::prepareToOpenStreamHelper(
-        int32_t ioHandle, int32_t devicePortId, int32_t devicePortConfigId,
+        int32_t ioHandle, int32_t mixPortHalId, int32_t devicePortId, int32_t devicePortConfigId,
         const AudioIoFlags& flags, AudioSource source, const AudioConfig& initialConfig,
         Cleanups* cleanups, AudioConfig* config, AudioPortConfig* mixPortConfig,
         AudioPatch* patch) {
     const bool isInput = flags.getTag() == AudioIoFlags::Tag::input;
     bool created = false;
-    RETURN_STATUS_IF_ERROR(findOrCreateMixPortConfig(*config, flags, ioHandle, source,
+    RETURN_STATUS_IF_ERROR(findOrCreateMixPortConfig(*config, flags, ioHandle, mixPortHalId, source,
                     std::set<int32_t>{devicePortId}, mixPortConfig, &created));
     if (created) {
         cleanups->add(&Hal2AidlMapper::resetPortConfig, mixPortConfig->id);
@@ -882,8 +936,8 @@ status_t Hal2AidlMapper::prepareToOpenStreamHelper(
     if (mixPortConfig->id == 0 && retryWithSuggestedConfig) {
         AUGMENT_LOG(D, "retrying to find/create a mix port config using config %s",
                     config->toString().c_str());
-        RETURN_STATUS_IF_ERROR(findOrCreateMixPortConfig(*config, flags, ioHandle, source,
-                        std::set<int32_t>{devicePortId}, mixPortConfig, &created));
+        RETURN_STATUS_IF_ERROR(findOrCreateMixPortConfig(*config, flags, ioHandle, mixPortHalId,
+                        source, std::set<int32_t>{devicePortId}, mixPortConfig, &created));
         if (created) {
             cleanups->add(&Hal2AidlMapper::resetPortConfig, mixPortConfig->id);
         }
@@ -1058,11 +1112,9 @@ status_t Hal2AidlMapper::setDevicePortConnectedState(const AudioPort& devicePort
         connectedPort.id = templatePort->id;
         RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(mModule->connectExternalDevice(
                                 connectedPort, &connectedPort)));
-        const auto [it, inserted] = mPorts.insert(std::make_pair(connectedPort.id, connectedPort));
-        LOG_ALWAYS_FATAL_IF(
-                !inserted, "%s duplicate port ID received from HAL: %s, existing port: %s",
-                __func__, connectedPort.toString().c_str(), it->second.toString().c_str());
-        mConnectedPorts.insert(connectedPort.id);
+
+        insertConnectedPort(connectedPort.id, connectedPort);
+
         if (erasePortAfterConnectionIt != mPorts.end()) {
             mPorts.erase(erasePortAfterConnectionIt);
         }
diff --git a/media/libaudiohal/impl/Hal2AidlMapper.h b/media/libaudiohal/impl/Hal2AidlMapper.h
index 254875223c..f05ea6ec68 100644
--- a/media/libaudiohal/impl/Hal2AidlMapper.h
+++ b/media/libaudiohal/impl/Hal2AidlMapper.h
@@ -79,6 +79,7 @@ class Hal2AidlMapper : public ConversionHelperAidl {
     // and 'config' is a suggested config.
     status_t prepareToOpenStream(
         int32_t ioHandle,
+        int32_t mixPortHalId,
         const ::aidl::android::media::audio::common::AudioDevice& device,
         const ::aidl::android::media::audio::common::AudioIoFlags& flags,
         ::aidl::android::media::audio::common::AudioSource source,
@@ -95,6 +96,8 @@ class Hal2AidlMapper : public ConversionHelperAidl {
     void resetUnusedPatchesAndPortConfigs();
     status_t setDevicePortConnectedState(
             const ::aidl::android::media::audio::common::AudioPort& devicePort, bool connected);
+    status_t updateAudioPort(
+            int32_t portId, ::aidl::android::media::audio::common::AudioPort* port);
 
     // Methods to work with FwkPatches.
     void eraseFwkPatch(int32_t fwkPatchId) { mFwkPatches.erase(fwkPatchId); }
@@ -106,6 +109,10 @@ class Hal2AidlMapper : public ConversionHelperAidl {
         mFwkPatches[fwkPatchId] = halPatchId;
     }
 
+    bool isRoutable(int32_t devicePortId, int32_t mixPortId) {
+        return mRoutingMatrix.count(std::make_pair(devicePortId, mixPortId)) > 0;
+    }
+
   private:
     // 'FwkPatches' is used to store patches that diverge from the framework's state.
     // Uses framework patch ID (aka audio_patch_handle_t) values for indexing.
@@ -144,6 +151,19 @@ class Hal2AidlMapper : public ConversionHelperAidl {
             const ::aidl::android::media::audio::common::AudioPortConfig& p);
     // If the 'result->id' is 0, that means, the config was not created/updated,
     // and the 'result' is a suggestion from the HAL.
+    status_t createOrUpdatePortConfig(
+            const ::aidl::android::media::audio::common::AudioPort& audioPort,
+            const ::aidl::android::media::audio::common::AudioConfig& config,
+            const std::optional<::aidl::android::media::audio::common::AudioIoFlags>& flags,
+            ::aidl::android::media::audio::common::AudioSource source,
+            int32_t ioHandle,
+            ::aidl::android::media::audio::common::AudioPortConfig* result,
+            bool *created);
+    status_t createOrUpdatePortConfig(
+            const ::aidl::android::media::audio::common::AudioPortConfig& requestedPortConfig,
+            const ::aidl::android::media::audio::common::AudioConfig& config,
+            ::aidl::android::media::audio::common::AudioSource source,
+            ::aidl::android::media::audio::common::AudioPortConfig* result, bool *created);
     status_t createOrUpdatePortConfig(
             const ::aidl::android::media::audio::common::AudioPortConfig& requestedPortConfig,
             ::aidl::android::media::audio::common::AudioPortConfig* result, bool *created);
@@ -168,6 +188,14 @@ class Hal2AidlMapper : public ConversionHelperAidl {
             bool* created);
     // If the resulting 'portConfig->id' is 0, that means the config was not created,
     // and 'portConfig' is a suggested config.
+    status_t findOrCreateMixPortConfig(
+            const ::aidl::android::media::audio::common::AudioConfig& config,
+            const std::optional<::aidl::android::media::audio::common::AudioIoFlags>& flags,
+            int32_t ioHandle,
+            int32_t mixPortHalId,
+            ::aidl::android::media::audio::common::AudioSource source,
+            const std::set<int32_t>& destinationPortIds,
+            ::aidl::android::media::audio::common::AudioPortConfig* portConfig, bool* created);
     status_t findOrCreateMixPortConfig(
             const ::aidl::android::media::audio::common::AudioConfig& config,
             const std::optional<::aidl::android::media::audio::common::AudioIoFlags>& flags,
@@ -193,8 +221,11 @@ class Hal2AidlMapper : public ConversionHelperAidl {
             const std::optional<::aidl::android::media::audio::common::AudioIoFlags>& flags,
             int32_t ioHandle);
     std::set<int32_t> getPatchIdsByPortId(int32_t portId);
+    void insertConnectedPort(
+            int32_t portId,
+            const ::aidl::android::media::audio::common::AudioPort& devicePort);
     status_t prepareToOpenStreamHelper(
-        int32_t ioHandle, int32_t devicePortId, int32_t devicePortConfigId,
+        int32_t ioHandle, int32_t mixPortHalId, int32_t devicePortId, int32_t devicePortConfigId,
         const ::aidl::android::media::audio::common::AudioIoFlags& flags,
         ::aidl::android::media::audio::common::AudioSource source,
         const ::aidl::android::media::audio::common::AudioConfig& initialConfig,
@@ -210,8 +241,6 @@ class Hal2AidlMapper : public ConversionHelperAidl {
     void resetPatch(int32_t patchId) { (void)releaseAudioPatch(patchId); }
     void resetPortConfig(int32_t portConfigId);
     void resetUnusedPortConfigs();
-    status_t updateAudioPort(
-            int32_t portId, ::aidl::android::media::audio::common::AudioPort* port);
     status_t updateRoutes();
     void updateDynamicMixPorts();
 
diff --git a/media/libaudiohal/impl/StreamHalAidl.cpp b/media/libaudiohal/impl/StreamHalAidl.cpp
index 89dbee3fb2..ff342a43ff 100644
--- a/media/libaudiohal/impl/StreamHalAidl.cpp
+++ b/media/libaudiohal/impl/StreamHalAidl.cpp
@@ -19,6 +19,7 @@
 
 #include <algorithm>
 #include <cstdint>
+#include <thread>
 
 #include <audio_utils/clock.h>
 #include <media/AidlConversion.h>
@@ -48,6 +49,7 @@ using ::aidl::android::hardware::audio::core::MmapBufferDescriptor;
 using ::aidl::android::hardware::audio::core::StreamDescriptor;
 using ::aidl::android::hardware::audio::core::VendorParameter;
 using ::aidl::android::media::audio::common::MicrophoneDynamicInfo;
+using ::aidl::android::hardware::audio::core::VendorParameter;
 using ::aidl::android::media::audio::IHalAdapterVendorExtension;
 
 /**
@@ -212,7 +214,8 @@ status_t StreamHalAidl::setParameters(const String8& kvPairs) {
                 return statusTFromBinderStatus(
                         serializeCall(mStream, &Stream::updateHwAvSyncId, hwAvSyncId));
             }));
-    return parseAndSetVendorParameters(mVendorExt, mStream, parameters);
+
+    return parseAndSetVendorParameters(parameters);
 }
 
 status_t StreamHalAidl::getParameters(const String8& keys __unused, String8 *values) {
@@ -224,7 +227,7 @@ status_t StreamHalAidl::getParameters(const String8& keys __unused, String8 *val
     }
     AudioParameter parameterKeys(keys), result;
     *values = result.toString();
-    return parseAndGetVendorParameters(mVendorExt, mStream, parameterKeys, values);
+    return parseAndGetVendorParameters(parameterKeys, values);
 }
 
 status_t StreamHalAidl::getFrameSize(size_t *size) {
@@ -313,10 +316,47 @@ status_t StreamHalAidl::standby() {
     }
 }
 
-status_t StreamHalAidl::dump(int fd, const Vector<String16>& args __unused) {
-    AUGMENT_LOG(D);
+// The behavior depends on the interface implementation version:
+//  - if the version < 3, only call `dump` on `IStreamCommon`.
+//  - if the version == 3, call on the concrete stream (`IStreamIn|Out`) first, then if there
+//       was nothing dumped, fallback to the "< 3" behavior.
+//  - if the version > 3, only call `dump` on the concrete stream.
+status_t StreamHalAidl::dumpImpl(int fd, const Vector<String16>& args, ::ndk::ICInterface* stream) {
+    if (!mStream || !stream) return NO_INIT;
+    Vector<String16> newArgs = args;
+    newArgs.push(String16(kDumpFromAudioServerArgument));
+    // Note: do not serialize the dump call with mCallLock.
+    status_t status;
+    if (mAidlInterfaceVersion > kAidlVersion3) {
+        status = stream->dump(fd, Args(newArgs).args(), newArgs.size());
+    } else if (mAidlInterfaceVersion < kAidlVersion3) {
+        status = mStream->dump(fd, Args(newArgs).args(), newArgs.size());
+    } else {  // mAidlInterfaceVersion == 3
+        int pipefd[2];
+        if (pipe(pipefd) == -1) {
+            AUGMENT_LOG(E, "pipe failed: %d", errno);
+            return NO_INIT;
+        }
+        bool hasOutput = false;
+        std::thread reader([&hasOutput](int inFd, int outFd) {
+                std::vector<char> buf(32768);
+                while (true) {
+                    ssize_t r = read(inFd, &buf[0], buf.size());
+                    if (r <= 0) break;
+                    write(outFd, &buf[0], r);
+                    hasOutput = true;
+                }
+        }, pipefd[0], fd);
+        status = stream->dump(pipefd[1], Args(newArgs).args(), newArgs.size());
+        close(pipefd[1]);
+        close(pipefd[0]);
+        reader.join();
+        if (status != OK || !hasOutput) {
+            status = mStream->dump(fd, Args(newArgs).args(), newArgs.size());
+        }
+    }
     mStreamPowerLog.dump(fd);
-    return OK;
+    return status;
 }
 
 status_t StreamHalAidl::start() {
@@ -374,12 +414,36 @@ status_t StreamHalAidl::stop() {
     }
     StreamDescriptor::Reply reply;
     RETURN_STATUS_IF_ERROR(updateCountersIfNeeded(&reply));
-    if (const auto state = reply.state; state == StreamDescriptor::State::ACTIVE) {
-        return drain(false /*earlyNotify*/, nullptr);
-    } else if (state == StreamDescriptor::State::DRAINING) {
-        RETURN_STATUS_IF_ERROR(pause());
-        return flush();
-    } else if (state == StreamDescriptor::State::PAUSED) {
+    const auto state = reply.state;
+    if (mIsInput) {
+        // For input, does not make sense to drain since the framework does not need that data.
+        if (state == StreamDescriptor::State::ACTIVE) {
+            RETURN_STATUS_IF_ERROR(pause());
+            return flush();
+        } else if (state == StreamDescriptor::State::DRAINING) {
+            // Drain until the stream enters standby due to empty buffer.
+            do {
+                if (status_t status = drain(false /*earlyNotify*/, &reply); status != OK) {
+                    if (reply.state == StreamDescriptor::State::STANDBY) break;
+                    AUGMENT_LOG(E, "HAL could not complete drain, left in %s state, status %d",
+                            toString(reply.state).c_str(), status);
+                    return status;
+                }
+            } while (reply.state == StreamDescriptor::State::DRAINING);
+            if (reply.state == StreamDescriptor::State::STANDBY) return OK;
+            AUGMENT_LOG(E, "HAL could not complete drain, left in %s state",
+                    toString(reply.state).c_str());
+            return INVALID_OPERATION;
+        }
+    } else {  // output
+        if (state == StreamDescriptor::State::ACTIVE) {
+            return drain(false /*earlyNotify*/, nullptr);
+        } else if (state == StreamDescriptor::State::DRAINING) {
+            RETURN_STATUS_IF_ERROR(pause());
+            return flush();
+        }
+    }
+    if (state == StreamDescriptor::State::PAUSED) {
         return flush();
     } else if (state != StreamDescriptor::State::IDLE &&
             state != StreamDescriptor::State::STANDBY) {
@@ -428,10 +492,15 @@ status_t StreamHalAidl::getHardwarePosition(int64_t *frames, int64_t *timestamp)
         AUGMENT_LOG(W, "No position was reported by the HAL");
         return INVALID_OPERATION;
     }
-    int64_t mostRecentResetPoint = std::max(statePositions.hardware.framesAtStandby,
-                                            statePositions.hardware.framesAtFlushOrDrain);
-    int64_t aidlFrames = reply.hardware.frames;
-    *frames = aidlFrames <= mostRecentResetPoint ? 0 : aidlFrames - mostRecentResetPoint;
+    if (mSupportsCreateMmapBuffer) {
+        // HAL is required to report continuous position. Reset for compatibility.
+        int64_t mostRecentResetPoint = std::max(statePositions.hardware.framesAtStandby,
+                statePositions.hardware.framesAtFlushOrDrain);
+        int64_t aidlFrames = reply.hardware.frames;
+        *frames = aidlFrames <= mostRecentResetPoint ? 0 : aidlFrames - mostRecentResetPoint;
+    } else {
+        *frames = reply.hardware.frames;
+    }
     *timestamp = reply.hardware.timeNs;
     return OK;
 }
@@ -583,15 +652,16 @@ status_t StreamHalAidl::flush(StreamDescriptor::Reply* reply) {
     TIME_CHECK();
     if (!mStream) return NO_INIT;
 
+    if (const auto state = getState(); isInPlayOrRecordState(state)) {
+        RETURN_STATUS_IF_ERROR(pause(reply));
+    }
+
     if (const auto state = getState(); isInPausedState(state)) {
         return sendCommand(
                 makeHalCommand<HalCommand::Tag::flush>(), reply,
                 true /*safeFromNonWorkerThread*/);  // The workers stops its I/O activity first.
-    } else if (isInPlayOrRecordState(state)) {
-        AUGMENT_LOG(E, "found stream in non-flushable state: %s", toString(state).c_str());
-        return INVALID_OPERATION;
     } else {
-        AUGMENT_LOG(D, "already stream in one of the flushable state: current state: %s",
+        AUGMENT_LOG(D, "already stream in one of the flushed state: current state: %s",
                     toString(state).c_str());
         return OK;
     }
@@ -732,6 +802,39 @@ status_t StreamHalAidl::legacyReleaseAudioPatch() {
     return INVALID_OPERATION;
 }
 
+status_t StreamHalAidl::parseAndGetVendorParameters(const AudioParameter& parameterKeys,
+                                                    String8* values) {
+    std::vector<std::string> vendorParameterIds;
+    RETURN_STATUS_IF_ERROR(
+            fillVendorParameterIds(mVendorExt, IHalAdapterVendorExtension::ParameterScope::STREAM,
+                                   parameterKeys, vendorParameterIds));
+    if (vendorParameterIds.empty()) {
+        return OK;
+    }
+    std::vector<VendorParameter> vendorParameters;
+    RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(serializeCall(
+            mStream, &Stream::getVendorParameters, vendorParameterIds, &vendorParameters)));
+
+    RETURN_STATUS_IF_ERROR(fillKeyValuePairsFromVendorParameters(
+            mVendorExt, IHalAdapterVendorExtension::ParameterScope::STREAM, vendorParameters,
+            values));
+    return OK;
+}
+
+status_t StreamHalAidl::parseAndSetVendorParameters(const AudioParameter& parameters) {
+    std::vector<VendorParameter> syncParameters, asyncParameters;
+    RETURN_STATUS_IF_ERROR(fillVendorParameters(mVendorExt,
+                                                IHalAdapterVendorExtension::ParameterScope::STREAM,
+                                                parameters, syncParameters, asyncParameters));
+    if (!syncParameters.empty())
+        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(serializeCall(
+                mStream, &Stream::setVendorParameters, syncParameters, false /*async*/)));
+    if (!asyncParameters.empty())
+        RETURN_STATUS_IF_ERROR(statusTFromBinderStatus(serializeCall(
+                mStream, &Stream::setVendorParameters, asyncParameters, true /*async*/)));
+    return OK;
+}
+
 status_t StreamHalAidl::sendCommand(
         const ::aidl::android::hardware::audio::core::StreamDescriptor::Command& command,
         ::aidl::android::hardware::audio::core::StreamDescriptor::Reply* reply,
@@ -782,13 +885,13 @@ status_t StreamHalAidl::sendCommand(
                     } else if (command.getTag() == StreamDescriptor::Command::flush &&
                             reply->state == StreamDescriptor::State::IDLE) {
                         mStatePositions.observable.framesAtFlushOrDrain = reply->observable.frames;
-                        mStatePositions.hardware.framesAtFlushOrDrain = reply->observable.frames;
+                        mStatePositions.hardware.framesAtFlushOrDrain = reply->hardware.frames;
                     } else if (!mContext.isAsynchronous() &&
                             command.getTag() == StreamDescriptor::Command::drain &&
                             (reply->state == StreamDescriptor::State::IDLE ||
                                     reply->state == StreamDescriptor::State::DRAINING)) {
                         mStatePositions.observable.framesAtFlushOrDrain = reply->observable.frames;
-                        mStatePositions.hardware.framesAtFlushOrDrain = reply->observable.frames;
+                        mStatePositions.hardware.framesAtFlushOrDrain = reply->hardware.frames;
                     } // for asynchronous drain, the frame count is saved in 'onAsyncDrainReady'
                 }
                 if (mContext.isAsynchronous() &&
@@ -1240,13 +1343,7 @@ status_t StreamOutHalAidl::filterAndUpdateOffloadMetadata(AudioParameter &parame
 status_t StreamOutHalAidl::dump(int fd, const Vector<String16>& args) {
     AUGMENT_LOG(D);
     TIME_CHECK();
-    if (!mStream) return NO_INIT;
-    Vector<String16> newArgs = args;
-    newArgs.push(String16(kDumpFromAudioServerArgument));
-    // Do not serialize the dump call with mCallLock
-    status_t status = mStream->dump(fd, Args(newArgs).args(), newArgs.size());
-    StreamHalAidl::dump(fd, args);
-    return status;
+    return dumpImpl(fd, args, mStream.get());
 }
 
 // static
@@ -1368,13 +1465,7 @@ status_t StreamInHalAidl::setPreferredMicrophoneFieldDimension(float zoom) {
 status_t StreamInHalAidl::dump(int fd, const Vector<String16>& args) {
     AUGMENT_LOG(D);
     TIME_CHECK();
-    if (!mStream) return NO_INIT;
-    Vector<String16> newArgs = args;
-    newArgs.push(String16(kDumpFromAudioServerArgument));
-    // Do not serialize the dump call with mCallLock
-    status_t status = mStream->dump(fd, Args(newArgs).args(), newArgs.size());
-    StreamHalAidl::dump(fd, args);
-    return status;
+    return dumpImpl(fd, args, mStream.get());
 }
 
 } // namespace android
diff --git a/media/libaudiohal/impl/StreamHalAidl.h b/media/libaudiohal/impl/StreamHalAidl.h
index a026f52bc0..b2cf3549dd 100644
--- a/media/libaudiohal/impl/StreamHalAidl.h
+++ b/media/libaudiohal/impl/StreamHalAidl.h
@@ -33,6 +33,7 @@
 #include <media/AidlConversionUtil.h>
 #include <media/AudioParameter.h>
 #include <mediautils/Synchronization.h>
+#include <audio_utils/mutex.h>
 
 #include "ConversionHelperAidl.h"
 #include "StreamPowerLog.h"
@@ -155,8 +156,6 @@ class StreamHalAidl : public virtual StreamHalInterface, public ConversionHelper
     // Put the audio hardware input/output into standby mode.
     status_t standby() override;
 
-    status_t dump(int fd, const Vector<String16>& args) override;
-
     // Start a stream operating in mmap mode.
     status_t start() override;
 
@@ -181,9 +180,6 @@ class StreamHalAidl : public virtual StreamHalInterface, public ConversionHelper
     status_t legacyReleaseAudioPatch() override;
 
   protected:
-    // For tests.
-    friend class sp<StreamHalAidl>;
-
     struct FrameCounters {
         int64_t framesAtFlushOrDrain;
         int64_t framesAtStandby;
@@ -210,6 +206,8 @@ class StreamHalAidl : public virtual StreamHalInterface, public ConversionHelper
 
     ~StreamHalAidl() override;
 
+    status_t dumpImpl(int fd, const Vector<String16>& args, ::ndk::ICInterface* stream);
+
     ::aidl::android::hardware::audio::core::StreamDescriptor::State getState() {
         std::lock_guard l(mLock);
         return mLastReply.state;
@@ -291,6 +289,9 @@ class StreamHalAidl : public virtual StreamHalInterface, public ConversionHelper
     void onAsyncDrainReady();
     void onAsyncError();
 
+    status_t parseAndGetVendorParameters(const AudioParameter& parameterKeys, String8* values);
+    status_t parseAndSetVendorParameters(const AudioParameter& parameters);
+
     const bool mIsInput;
     const audio_config_base_t mConfig;
     StreamContextAidl mContext;
@@ -302,7 +303,7 @@ class StreamHalAidl : public virtual StreamHalInterface, public ConversionHelper
     // Note that only access to command and reply MQs needs to be protected because the data MQ is
     // only accessed by the I/O thread. Also, there is no need to protect lookup operations on the
     // queues as they are thread-safe, only send/receive operation must be protected.
-    std::mutex mCommandReplyLock;
+    audio_utils::fair_mutex mCommandReplyLock;
 
   private:
     static audio_config_base_t configToBase(const audio_config& config) {
diff --git a/media/libaudiohal/impl/effectsAidlConversion/AidlConversionDynamicsProcessing.cpp b/media/libaudiohal/impl/effectsAidlConversion/AidlConversionDynamicsProcessing.cpp
index 711050dc7c..e33071774c 100644
--- a/media/libaudiohal/impl/effectsAidlConversion/AidlConversionDynamicsProcessing.cpp
+++ b/media/libaudiohal/impl/effectsAidlConversion/AidlConversionDynamicsProcessing.cpp
@@ -232,8 +232,9 @@ status_t AidlConversionDp::getParameter(EffectParamWriter& param) {
 
 ConversionResult<DynamicsProcessing::ChannelConfig>
 AidlConversionDp::readChannelConfigFromParam(EffectParamReader& param) {
-    int32_t enable, channel;
+    int32_t inUse, enable, channel;
     RETURN_IF_ERROR(param.readFromParameter(&channel));
+    RETURN_IF_ERROR(param.readFromValue(&inUse));
     RETURN_IF_ERROR(param.readFromValue(&enable));
 
     return DynamicsProcessing::ChannelConfig(
diff --git a/media/libaudiohal/include/media/audiohal/DeviceHalInterface.h b/media/libaudiohal/include/media/audiohal/DeviceHalInterface.h
index 3f16526f20..354457cdd5 100644
--- a/media/libaudiohal/include/media/audiohal/DeviceHalInterface.h
+++ b/media/libaudiohal/include/media/audiohal/DeviceHalInterface.h
@@ -91,7 +91,8 @@ class DeviceHalInterface : public virtual RefBase
             struct audio_config *config,
             const char *address,
             sp<StreamOutHalInterface> *outStream,
-            const std::vector<playback_track_metadata_v7_t>& sourceMetadata = {}) = 0;
+            const std::vector<playback_track_metadata_v7_t>& sourceMetadata = {},
+            int32_t mixPortHalId = 0) = 0;
 
     // Creates and opens the audio hardware input stream. The stream is closed
     // by releasing all references to the returned object.
@@ -104,7 +105,8 @@ class DeviceHalInterface : public virtual RefBase
             audio_source_t source,
             audio_devices_t outputDevice,
             const char *outputDeviceAddress,
-            sp<StreamInHalInterface> *inStream) = 0;
+            sp<StreamInHalInterface> *inStream,
+            int32_t mixPortHalId = 0) = 0;
 
     // Returns whether createAudioPatch and releaseAudioPatch operations are supported.
     virtual status_t supportsAudioPatches(bool *supportsPatches) = 0;
@@ -162,8 +164,12 @@ class DeviceHalInterface : public virtual RefBase
 
     virtual status_t prepareToDisconnectExternalDevice(const struct audio_port_v7* port) = 0;
 
+    // Finds the `mixPort` when associated with `devicePort`.
+    // If `mixPortHalId` is specified, AIDL HAL wrapper will use it for finding the port by ID
+    // directly. Otherwise, mixPort.ext.mix.handle will be used.
     virtual status_t getAudioMixPort(const struct audio_port_v7* devicePort,
-                                     struct audio_port_v7* mixPort) = 0;
+                                     struct audio_port_v7* mixPort,
+                                     int32_t mixPortHalId) = 0;
 
   protected:
     // Subclasses can not be constructed directly by clients.
diff --git a/media/libaudiohal/tests/Android.bp b/media/libaudiohal/tests/Android.bp
index e369d8b1e0..0fa1afed05 100644
--- a/media/libaudiohal/tests/Android.bp
+++ b/media/libaudiohal/tests/Android.bp
@@ -41,6 +41,7 @@ cc_test {
     ],
     defaults: ["libaudiohal_aidl_test_default"],
     header_libs: ["libaudiohalimpl_headers"],
+    static_libs: ["libflagtest"],
 }
 
 cc_test {
diff --git a/media/libaudiohal/tests/CoreAudioHalAidl_test.cpp b/media/libaudiohal/tests/CoreAudioHalAidl_test.cpp
index 1730bfaf6d..b364c06349 100644
--- a/media/libaudiohal/tests/CoreAudioHalAidl_test.cpp
+++ b/media/libaudiohal/tests/CoreAudioHalAidl_test.cpp
@@ -15,6 +15,7 @@
  */
 
 #include <algorithm>
+#include <map>
 #include <memory>
 #include <mutex>
 #include <string>
@@ -29,10 +30,14 @@
 #include <StreamHalAidl.h>
 #include <aidl/android/hardware/audio/core/BnModule.h>
 #include <aidl/android/hardware/audio/core/BnStreamCommon.h>
+#include <aidl/android/hardware/audio/core/BnStreamIn.h>
 #include <aidl/android/hardware/audio/core/BnStreamOut.h>
 #include <aidl/android/media/audio/BnHalAdapterVendorExtension.h>
 #include <aidl/android/media/audio/common/AudioGainMode.h>
 #include <aidl/android/media/audio/common/Int.h>
+#include <com_android_media_audio.h>
+#include <flag_macros.h>
+#include <media/AidlConversionCppNdk.h>
 #include <utils/Log.h>
 
 namespace {
@@ -98,6 +103,12 @@ struct Configuration {
     std::vector<AudioPortConfig> portConfigs;
     std::vector<AudioRoute> routes;
     std::vector<AudioPatch> patches;
+    std::map<int32_t, std::vector<AudioProfile>> connectedProfiles;
+    // In this test, by default, all routes will be enabled (i.e., fully-connected)
+    // w.r.t. the template, but the actual routing can be different and updated per
+    // `dis/connectExternalDevice`, in which case this allows to configure
+    // the exclusive endpoints of such ports in specific test cases.
+    std::map<int32_t, std::vector<int32_t>> exclusiveRoutingForDeviceTemplate;
     int32_t nextPortId = 1;
     int32_t nextPatchId = 1;
 };
@@ -194,7 +205,7 @@ Configuration getTestConfiguration() {
     c.ports.push_back(speakerOutDevice);
 
     AudioPort primaryOutMix =
-            createPort(c.nextPortId++, "primary output", 0, false, createPortMixExt(1, 1));
+            createPort(c.nextPortId++, "primary output", 0, false, createPortMixExt(0, 1));
     primaryOutMix.profiles = standardPcmAudioProfiles;
     c.ports.push_back(primaryOutMix);
 
@@ -210,16 +221,82 @@ Configuration getTestConfiguration() {
     btOutMix.profiles = standardPcmAudioProfiles;
     c.ports.push_back(btOutMix);
 
+    AudioPort usbOutDevice =
+            createPort(c.nextPortId++, "USB Out", 0, false,
+                       createPortDeviceExt(AudioDeviceType::OUT_DEVICE, 0,
+                                           AudioDeviceDescription::CONNECTION_USB));
+    c.ports.push_back(usbOutDevice);
+    c.connectedProfiles[usbOutDevice.id] = standardPcmAudioProfiles;
+
+    // Simulates the edge case where a detachable device with non-standard audio profiles
+    // whose template port routes to multiple mix ports ultimately routes to exactly
+    // one endpoint on `connectExternalDevice`, determined by the HAL.
+    //
+    // Note that this is using `OUT_HEADSET` instead of `OUT_DEVICE` because the latter
+    // is being used to test non-dynamic port behaviors. This makes a difference in
+    // the mapper determining the template port, which makes them independent to each other.
+    AudioPort usbDynamicHeadset =
+            createPort(c.nextPortId++, "USB Dynamic Out", 0, false,
+                       createPortDeviceExt(AudioDeviceType::OUT_HEADSET, 0,
+                                           AudioDeviceDescription::CONNECTION_USB));
+    c.ports.push_back(usbDynamicHeadset);
+    // The profiles are unknown until the HAL queries the device in practice.
+    // For testing, this will be set right before `connectExternalDevice` to
+    // simulate generating the unknown (until connection in the HAL) profile.
+    c.connectedProfiles[usbDynamicHeadset.id] = {};
+
+    AudioPort hifiOutMix1 =
+            createPort(c.nextPortId++, "hifi_out_1", 0, false, createPortMixExt(1, 1));
+    c.ports.push_back(hifiOutMix1);
+    c.connectedProfiles[hifiOutMix1.id] = standardPcmAudioProfiles;
+
+    AudioPort hifiOutMix2 =
+            createPort(c.nextPortId++, "hifi_out_2", 0, false, createPortMixExt(1, 1));
+    c.ports.push_back(hifiOutMix2);
+    c.connectedProfiles[hifiOutMix2.id] = standardPcmAudioProfiles;
+
+    AudioPort dynamicOutMix1 =
+            createPort(c.nextPortId++, "dynamic_out_1", 0, false, createPortMixExt(1, 1));
+    c.ports.push_back(dynamicOutMix1);
+    // The profiles are only populated by the HAL after `connectExternalDevice`
+    c.connectedProfiles[dynamicOutMix1.id] = {};
+
+    AudioPort dynamicOutMix2 =
+            createPort(c.nextPortId++, "dynamic_out_2", 0, false, createPortMixExt(1, 1));
+    c.ports.push_back(dynamicOutMix2);
+    c.connectedProfiles[dynamicOutMix2.id] = {};
+
+    AudioPort usbInDevice = createPort(c.nextPortId++, "USB In", 0, true,
+                                       createPortDeviceExt(AudioDeviceType::IN_DEVICE, 0,
+                                                           AudioDeviceDescription::CONNECTION_USB));
+    c.ports.push_back(usbInDevice);
+    c.connectedProfiles[usbInDevice.id] = standardPcmAudioProfiles;
+
+    AudioPort hifiInMix1 = createPort(c.nextPortId++, "hifi_in_1", 0, true, createPortMixExt(1, 1));
+    c.ports.push_back(hifiInMix1);
+    c.connectedProfiles[hifiInMix1.id] = standardPcmAudioProfiles;
+
+    AudioPort hifiInMix2 = createPort(c.nextPortId++, "hifi_in_2", 0, true, createPortMixExt(1, 1));
+    c.ports.push_back(hifiInMix2);
+    c.connectedProfiles[hifiInMix2.id] = standardPcmAudioProfiles;
+
     c.routes.push_back(createRoute({micInDevice, micInBackDevice}, primaryInMix));
     c.routes.push_back(createRoute({primaryOutMix}, speakerOutDevice));
     c.routes.push_back(createRoute({btOutMix}, btOutDevice));
+    c.routes.push_back(createRoute({hifiOutMix1, hifiOutMix2}, usbOutDevice));
+    c.routes.push_back(createRoute({dynamicOutMix1, dynamicOutMix2}, usbDynamicHeadset));
+    c.routes.push_back(createRoute({usbInDevice}, hifiInMix1));
+    c.routes.push_back(createRoute({usbInDevice}, hifiInMix2));
 
     return c;
 }
 
 class StreamCommonMock : public ::aidl::android::hardware::audio::core::BnStreamCommon,
                          public VendorParameterMock {
-    ndk::ScopedAStatus close() override { return ndk::ScopedAStatus::ok(); }
+    ndk::ScopedAStatus close() override {
+        mIsClosed = true;
+        return ndk::ScopedAStatus::ok();
+    }
     ndk::ScopedAStatus prepareToClose() override { return ndk::ScopedAStatus::ok(); }
     ndk::ScopedAStatus updateHwAvSyncId(int32_t) override { return ndk::ScopedAStatus::ok(); }
     ndk::ScopedAStatus getVendorParameters(const std::vector<std::string>& in_parameterIds,
@@ -238,6 +315,11 @@ class StreamCommonMock : public ::aidl::android::hardware::audio::core::BnStream
             const std::shared_ptr<::aidl::android::hardware::audio::effect::IEffect>&) override {
         return ndk::ScopedAStatus::ok();
     }
+
+    bool mIsClosed = false;
+
+  public:
+    bool isStreamClosed() const { return mIsClosed; }
 };
 
 class StreamContext {
@@ -281,10 +363,75 @@ class StreamContext {
     std::unique_ptr<DataMQ> mDataMQ = std::make_unique<DataMQ>(96);
 };
 
-class StreamOutMock : public ::aidl::android::hardware::audio::core::BnStreamOut {
+class StreamWrapper {
+  public:
+    virtual ~StreamWrapper() = default;
+    virtual bool isStreamClosed() const = 0;
+};
+
+class StreamInMock : public ::aidl::android::hardware::audio::core::BnStreamIn,
+                     public StreamWrapper {
+  public:
+    explicit StreamInMock(StreamContext&& ctx) : mContext(std::move(ctx)) {}
+
+    bool isStreamClosed() const final { return mCommon->isStreamClosed(); }
+
+  private:
+    ndk::ScopedAStatus getStreamCommon(
+            std::shared_ptr<::aidl::android::hardware::audio::core::IStreamCommon>* _aidl_return)
+            override {
+        if (!mCommon) {
+            mCommon = ndk::SharedRefBase::make<StreamCommonMock>();
+        }
+        *_aidl_return = mCommon;
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus getActiveMicrophones(
+            std::vector<::aidl::android::media::audio::common::MicrophoneDynamicInfo>*) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus getMicrophoneDirection(
+            ::aidl::android::hardware::audio::core::IStreamIn::MicrophoneDirection*) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus setMicrophoneDirection(
+            ::aidl::android::hardware::audio::core::IStreamIn::MicrophoneDirection) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus getMicrophoneFieldDimension(float*) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus setMicrophoneFieldDimension(float) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus updateMetadata(
+            const ::aidl::android::hardware::audio::common::SinkMetadata&) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    ndk::ScopedAStatus getHwGain(std::vector<float>*) override { return ndk::ScopedAStatus::ok(); }
+
+    ndk::ScopedAStatus setHwGain(const std::vector<float>&) override {
+        return ndk::ScopedAStatus::ok();
+    }
+
+    StreamContext mContext;
+    std::shared_ptr<StreamCommonMock> mCommon;
+};
+
+class StreamOutMock : public ::aidl::android::hardware::audio::core::BnStreamOut,
+                      public StreamWrapper {
   public:
     explicit StreamOutMock(StreamContext&& ctx) : mContext(std::move(ctx)) {}
 
+    bool isStreamClosed() const final { return !mCommon || mCommon->isStreamClosed(); }
+
   private:
     ndk::ScopedAStatus getStreamCommon(
             std::shared_ptr<::aidl::android::hardware::audio::core::IStreamCommon>* _aidl_return)
@@ -366,6 +513,84 @@ class ModuleMock : public ::aidl::android::hardware::audio::core::BnModule,
         return std::nullopt;
     }
 
+    std::vector<int32_t> getRoutableMixPortIdsFor(const AudioDeviceDescription& deviceDesc) {
+        std::vector<int32_t> result;
+        if (deviceDesc.type > AudioDeviceType::OUT_DEFAULT) {
+            for (const auto& route : mConfig.routes) {
+                auto sinkPort = findById<AudioPort>(mConfig.ports, route.sinkPortId);
+                if (sinkPort->ext.getTag() != AudioPortExt::Tag::device) {
+                    continue;
+                }
+                if (sinkPort->ext.get<AudioPortExt::Tag::device>().device.type == deviceDesc) {
+                    result = route.sourcePortIds;
+                    break;
+                }
+            }
+        } else {
+            for (const auto& route : mConfig.routes) {
+                for (int32_t sourcePortId : route.sourcePortIds) {
+                    auto sourcePort = findById<AudioPort>(mConfig.ports, sourcePortId);
+                    if (sourcePort->ext.getTag() != AudioPortExt::Tag::device) {
+                        continue;
+                    }
+                    if (sourcePort->ext.get<AudioPortExt::Tag::device>().device.type ==
+                        deviceDesc) {
+                        result.push_back(route.sinkPortId);
+                        break;
+                    }
+                }
+            }
+        }
+        return result;
+    }
+
+    int32_t getPortIdFor(int32_t ioHandle) {
+        for (auto& config : mConfig.portConfigs) {
+            if (config.ext.getTag() == AudioPortExt::Tag::mix &&
+                config.ext.get<AudioPortExt::Tag::mix>().handle == ioHandle) {
+                return config.portId;
+            }
+        }
+        return 0;
+    }
+
+    // Finds IDs of all device ports matching `deviceDesc`.
+    std::vector<int32_t> getDevicePortIds(const AudioDeviceDescription& deviceDesc) {
+        std::vector<int32_t> ids;
+        for (auto& port : mConfig.ports) {
+            if (port.ext.getTag() != AudioPortExt::Tag::device) continue;
+            if (port.ext.get<AudioPortExt::Tag::device>().device.type != deviceDesc) continue;
+            ids.push_back(port.id);
+        }
+        return ids;
+    }
+
+    // Finds device port ID by address for the specified direction.
+    // Returns -1 if not found.
+    int32_t getDevicePortIdWithAddress(const std::string& address, bool isInput) {
+        const auto directionFlag = isInput ? AudioIoFlags::Tag::input : AudioIoFlags::Tag::output;
+        for (auto& port : mConfig.ports) {
+            if (port.flags.getTag() != directionFlag) continue;
+            if (port.ext.getTag() != AudioPortExt::Tag::device) continue;
+            if (port.ext.get<AudioPortExt::Tag::device>().device.address != address) continue;
+            return port.id;
+        }
+        return -1;
+    }
+
+    // This updates the dynamic port referred to by the `id` so as if it, or the next
+    // device that refers to it as a template, will claim to support `profile`.
+    void setConnectedProfileForPort(int32_t id, const AudioProfile& profile) {
+        mConfig.connectedProfiles[id].clear();
+        mConfig.connectedProfiles[id].push_back(profile);
+    }
+
+    // If set, this determines the endpoints of the routes for upcoming connected
+    // devices referring to the template port identified by `id`.
+    void setExclusiveRoutingForPort(int32_t id, const std::vector<int32_t>& endpoints) {
+        mConfig.exclusiveRoutingForDeviceTemplate[id] = endpoints;
+    }
+
   private:
     ndk::ScopedAStatus setModuleDebug(
             const ::aidl::android::hardware::audio::core::ModuleDebug&) override {
@@ -397,17 +622,56 @@ class ModuleMock : public ::aidl::android::hardware::audio::core::BnModule,
         }
         *port = *iter;
         port->ext = src.ext;
+        if (auto it = mConfig.connectedProfiles.find(src.id);
+            it != mConfig.connectedProfiles.end()) {
+            // Update audio profiles for the device port when connecting
+            port->profiles = it->second;
+            // Update audio profile of mix ports that can be connected to the new connected device
+            for (auto& r : mConfig.routes) {
+                if (r.sinkPortId == src.id) {
+                    for (auto sourceId : r.sourcePortIds) {
+                        if (auto cpIt = mConfig.connectedProfiles.find(sourceId);
+                            cpIt != mConfig.connectedProfiles.end()) {
+                            findById<AudioPort>(mConfig.ports, cpIt->first)->profiles =
+                                    cpIt->second;
+                        }
+                    }
+                } else if (std::find(r.sourcePortIds.begin(), r.sourcePortIds.end(), src.id) !=
+                           r.sourcePortIds.end()) {
+                    if (auto cpIt = mConfig.connectedProfiles.find(r.sinkPortId);
+                        cpIt != mConfig.connectedProfiles.end()) {
+                        findById<AudioPort>(mConfig.ports, cpIt->first)->profiles = cpIt->second;
+                    }
+                }
+            }
+        }
         port->id = mConfig.nextPortId++;
         ALOGD("%s: returning %s", __func__, port->toString().c_str());
         mConfig.ports.push_back(*port);
         std::vector<AudioRoute> newRoutes;
         for (auto& r : mConfig.routes) {
             if (r.sinkPortId == src.id) {
-                newRoutes.push_back(AudioRoute{.sourcePortIds = r.sourcePortIds,
+                const auto& routableSourcePortIds =
+                        mConfig.exclusiveRoutingForDeviceTemplate.count(src.id)
+                                ? mConfig.exclusiveRoutingForDeviceTemplate[src.id]
+                                : r.sourcePortIds;
+
+                if (routableSourcePortIds.empty()) continue;
+
+                newRoutes.push_back(AudioRoute{.sourcePortIds = routableSourcePortIds,
                                                .sinkPortId = port->id,
                                                .isExclusive = r.isExclusive});
             } else if (std::find(r.sourcePortIds.begin(), r.sourcePortIds.end(), src.id) !=
                        r.sourcePortIds.end()) {
+                auto it = mConfig.exclusiveRoutingForDeviceTemplate.find(src.id);
+                if (it != mConfig.exclusiveRoutingForDeviceTemplate.end()) {
+                    const auto& routableSinkPortIds = it->second;
+                    if (std::find(routableSinkPortIds.begin(), routableSinkPortIds.end(),
+                                  r.sinkPortId) == routableSinkPortIds.end()) {
+                        continue;
+                    }
+                }
+
                 r.sourcePortIds.push_back(port->id);
             }
         }
@@ -423,11 +687,15 @@ class ModuleMock : public ::aidl::android::hardware::audio::core::BnModule,
         for (auto it = mConfig.routes.begin(); it != mConfig.routes.end();) {
             if (it->sinkPortId == portId) {
                 it = mConfig.routes.erase(it);
+                for (auto sourceId : it->sourcePortIds) {
+                    findById<AudioPort>(mConfig.ports, sourceId)->profiles.clear();
+                }
             } else {
                 if (auto srcIt =
                             std::find(it->sourcePortIds.begin(), it->sourcePortIds.end(), portId);
                     srcIt != it->sourcePortIds.end()) {
                     it->sourcePortIds.erase(srcIt);
+                    findById<AudioPort>(mConfig.ports, it->sinkPortId)->profiles.clear();
                 }
                 ++it;
             }
@@ -475,15 +743,36 @@ class ModuleMock : public ::aidl::android::hardware::audio::core::BnModule,
         }
         return ndk::ScopedAStatus::ok();
     }
-    ndk::ScopedAStatus openInputStream(const OpenInputStreamArguments&,
-                                       OpenInputStreamReturn*) override {
+    ndk::ScopedAStatus openInputStream(const OpenInputStreamArguments& in_args,
+                                       OpenInputStreamReturn* _aidl_return) override {
+        AudioPort* port = nullptr;
+        if (auto result = findPortForNewStream(in_args.portConfigId, &port); !result.isOk()) {
+            return result;
+        }
+        if (port->flags.getTag() != AudioIoFlags::Tag::input) {
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_ARGUMENT);
+        }
+        StreamContext context;
+        context.fillDescriptor(&_aidl_return->desc);
+        auto stream = ndk::SharedRefBase::make<StreamInMock>(std::move(context));
+        _aidl_return->stream = stream;
+        mStreams.emplace(port->id, stream);
         return ndk::ScopedAStatus::ok();
     }
-    ndk::ScopedAStatus openOutputStream(const OpenOutputStreamArguments&,
+    ndk::ScopedAStatus openOutputStream(const OpenOutputStreamArguments& in_args,
                                         OpenOutputStreamReturn* _aidl_return) override {
+        AudioPort* port = nullptr;
+        if (auto result = findPortForNewStream(in_args.portConfigId, &port); !result.isOk()) {
+            return result;
+        }
+        if (port->flags.getTag() != AudioIoFlags::Tag::output) {
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_ARGUMENT);
+        }
         StreamContext context;
         context.fillDescriptor(&_aidl_return->desc);
-        _aidl_return->stream = ndk::SharedRefBase::make<StreamOutMock>(std::move(context));
+        auto stream = ndk::SharedRefBase::make<StreamOutMock>(std::move(context));
+        _aidl_return->stream = stream;
+        mStreams.emplace(port->id, stream);
         return ndk::ScopedAStatus::ok();
     }
     ndk::ScopedAStatus getSupportedPlaybackRateFactors(SupportedPlaybackRateFactors*) override {
@@ -614,9 +903,41 @@ class ModuleMock : public ::aidl::android::hardware::audio::core::BnModule,
         return ndk::ScopedAStatus::ok();
     }
 
+    size_t count(int32_t id) {
+        // Streams do not remove themselves from the collection on close.
+        erase_if(mStreams, [](const auto& pair) {
+            auto streamWrapper = pair.second.lock();
+            return !streamWrapper || streamWrapper->isStreamClosed();
+        });
+        return mStreams.count(id);
+    }
+
+    ndk::ScopedAStatus findPortForNewStream(int32_t in_portConfigId, AudioPort** port) {
+        auto portConfig = getPortConfig(in_portConfigId);
+        if (portConfig == std::nullopt) {
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_ARGUMENT);
+        }
+        const int32_t portId = portConfig->portId;
+        auto portIt = findById<AudioPort>(mConfig.ports, portId);
+        if (portIt == mConfig.ports.end()) {
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_ARGUMENT);
+        }
+        if (portIt->ext.getTag() != AudioPortExt::Tag::mix) {
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_ARGUMENT);
+        }
+        const size_t maxOpenStreamCount =
+                portIt->ext.get<AudioPortExt::Tag::mix>().maxOpenStreamCount;
+        if (maxOpenStreamCount != 0 && mStreams.count(portId) >= maxOpenStreamCount) {
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_STATE);
+        }
+        *port = &(*portIt);
+        return ndk::ScopedAStatus::ok();
+    }
+
     Configuration mConfig;
     bool mIsScreenTurnedOn = false;
     ScreenRotation mScreenRotation = ScreenRotation::DEG_0;
+    std::multimap<int32_t, std::weak_ptr<StreamWrapper>> mStreams;
 };
 
 VendorParameter makeVendorParameter(const std::string& id, int value) {
@@ -738,6 +1059,21 @@ class TestHalAdapterVendorExtension
     }
 };
 
+class StreamHalAidlTest : public android::StreamHalAidl {
+  public:
+    StreamHalAidlTest(
+            std::string_view className, bool isInput, const audio_config& config,
+            int32_t nominalLatency, android::StreamContextAidl&& context,
+            const std::shared_ptr<::aidl::android::hardware::audio::core::IStreamCommon>& stream,
+            const std::shared_ptr<::aidl::android::media::audio::IHalAdapterVendorExtension>& vext)
+        : StreamHalAidl(className, isInput, config, nominalLatency, std::move(context), stream,
+                        vext) {}
+    android::status_t dump(int /*fd*/,
+                           const android::Vector<android::String16>& /*args*/) override {
+        return android::OK;
+    }
+};
+
 const std::string TestHalAdapterVendorExtension::kLegacyParameterKey = "aosp_test_param";
 const std::string TestHalAdapterVendorExtension::kLegacyAsyncParameterKey = "aosp_test_param_async";
 // Note: in real life, there is no need to explicitly separate "module" and "stream"
@@ -915,6 +1251,156 @@ TEST_F(DeviceHalAidlTest, StreamReleaseOnMapperCleanup) {
     }
 }
 
+TEST_F(DeviceHalAidlTest, MultipleOutputMixePortWithSameCapabilities) {
+    ASSERT_EQ(OK, mDevice->initCheck());
+    std::string deviceAddress = "card=1;device=0";
+    struct audio_port_device_ext usbDeviceExt{};
+    usbDeviceExt.type = AUDIO_DEVICE_OUT_USB_DEVICE;
+    strcpy(usbDeviceExt.address, deviceAddress.c_str());
+    struct audio_port_v7 usbDevice{};
+    usbDevice.id = AUDIO_PORT_HANDLE_NONE, usbDevice.role = AUDIO_PORT_ROLE_SINK,
+    usbDevice.type = AUDIO_PORT_TYPE_DEVICE, usbDevice.ext.device = usbDeviceExt;
+    ASSERT_EQ(OK, mDevice->setConnectedState(&usbDevice, true /*connected*/));
+
+    std::vector<media::AudioRoute> routes;
+    ASSERT_EQ(OK, mDevice->getAudioRoutes(&routes));
+    AudioDeviceDescription usbDeviceDesc;
+    usbDeviceDesc.type = AudioDeviceType::OUT_DEVICE;
+    usbDeviceDesc.connection = AudioDeviceDescription::CONNECTION_USB;
+    auto routablePortIds = mModule->getRoutableMixPortIdsFor(usbDeviceDesc);
+    std::vector<sp<StreamOutHalInterface>> streams;
+    int32_t ioHandle = 42;
+    for (auto portId : routablePortIds) {
+        struct audio_config config = AUDIO_CONFIG_INITIALIZER;
+        config.sample_rate = 48000;
+        config.channel_mask = AUDIO_CHANNEL_OUT_STEREO;
+        config.format = AUDIO_FORMAT_PCM_16_BIT;
+        sp<StreamOutHalInterface> stream;
+        ASSERT_EQ(OK, mDevice->openOutputStream(static_cast<audio_io_handle_t>(ioHandle),
+                                                AUDIO_DEVICE_OUT_USB_DEVICE, AUDIO_OUTPUT_FLAG_NONE,
+                                                &config, deviceAddress.c_str(), &stream,
+                                                {} /*sourceMetadata*/, portId));
+        ASSERT_EQ(portId, mModule->getPortIdFor(ioHandle));
+        // Cache the stream so that it is not closed.
+        streams.push_back(stream);
+        ioHandle++;
+    }
+
+    ASSERT_EQ(OK, mDevice->setConnectedState(&usbDevice, false /*connected*/));
+}
+
+TEST_F(DeviceHalAidlTest, MultipleInputMixePortWithSameCapabilities) {
+    ASSERT_EQ(OK, mDevice->initCheck());
+    std::string deviceAddress = "card=1;device=0";
+    struct audio_port_device_ext usbDeviceExt{};
+    usbDeviceExt.type = AUDIO_DEVICE_IN_USB_DEVICE;
+    strcpy(usbDeviceExt.address, deviceAddress.c_str());
+    struct audio_port_v7 usbDevice{};
+    usbDevice.id = AUDIO_PORT_HANDLE_NONE, usbDevice.role = AUDIO_PORT_ROLE_SOURCE,
+    usbDevice.type = AUDIO_PORT_TYPE_DEVICE, usbDevice.ext.device = usbDeviceExt;
+    ASSERT_EQ(OK, mDevice->setConnectedState(&usbDevice, true /*connected*/));
+
+    std::vector<media::AudioRoute> routes;
+    ASSERT_EQ(OK, mDevice->getAudioRoutes(&routes));
+    AudioDeviceDescription usbDeviceDesc;
+    usbDeviceDesc.type = AudioDeviceType::IN_DEVICE;
+    usbDeviceDesc.connection = AudioDeviceDescription::CONNECTION_USB;
+    auto routablePortIds = mModule->getRoutableMixPortIdsFor(usbDeviceDesc);
+    std::vector<sp<StreamInHalInterface>> streams;
+    int32_t ioHandle = 42;
+    for (auto portId : routablePortIds) {
+        struct audio_config config = AUDIO_CONFIG_INITIALIZER;
+        config.sample_rate = 48000;
+        config.channel_mask = AUDIO_CHANNEL_IN_STEREO;
+        config.format = AUDIO_FORMAT_PCM_16_BIT;
+        sp<StreamInHalInterface> stream;
+        ASSERT_EQ(OK, mDevice->openInputStream(static_cast<audio_io_handle_t>(ioHandle),
+                                               AUDIO_DEVICE_IN_USB_DEVICE, &config,
+                                               AUDIO_INPUT_FLAG_NONE, deviceAddress.c_str(),
+                                               AUDIO_SOURCE_MIC, AUDIO_DEVICE_NONE,
+                                               "" /*outputDeviceAddress*/, &stream, portId));
+        ASSERT_EQ(portId, mModule->getPortIdFor(ioHandle));
+        // Cache the stream so that it is not closed.
+        streams.push_back(stream);
+        ioHandle++;
+    }
+
+    ASSERT_EQ(OK, mDevice->setConnectedState(&usbDevice, false /*connected*/));
+}
+
+// Note `OUT_USB_HEADSET` is configured to be dynamic, see `getTestConfiguration`.
+TEST_F_WITH_FLAGS(DeviceHalAidlTest, MultipleDynamicConnectionsWithExclusiveRouting,
+                  REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(com::android::media::audio,
+                                                      check_route_in_get_audio_mix_port))) {
+    ASSERT_EQ(OK, mDevice->initCheck());
+
+    const size_t NUM_DEVICES = 2;
+
+    const std::vector<AudioProfile> pcmAudioProfiles = {
+            createProfile(PcmType::INT_24_BIT, {AudioChannelLayout::LAYOUT_STEREO}, {96000}),
+            createProfile(PcmType::INT_16_BIT, {AudioChannelLayout::LAYOUT_STEREO}, {16000}),
+    };
+
+    AudioDeviceDescription usbDeviceDesc = {
+            .type = AudioDeviceType::OUT_HEADSET,
+            .connection = AudioDeviceDescription::CONNECTION_USB,
+    };
+
+    std::vector<media::AudioRoute> routes;
+    ASSERT_EQ(OK, mDevice->getAudioRoutes(&routes));
+
+    // Find routable mix ports specified by the template.
+    const auto routablePortIds = mModule->getRoutableMixPortIdsFor(usbDeviceDesc);
+
+    // We will map the mix ports to device ports 1:1 to test routing.
+    ASSERT_EQ(NUM_DEVICES, routablePortIds.size());
+
+    const auto templatePortIds = mModule->getDevicePortIds(usbDeviceDesc);
+    ASSERT_EQ(1u, templatePortIds.size());
+    const int32_t templatePortId = templatePortIds[0];
+
+    std::vector<struct audio_port_v7> devices;
+    for (size_t i = 0; i < NUM_DEVICES; ++i) {
+        const std::string deviceAddress =
+                std::string("card=") + std::to_string(i + 1) + std::string(";device=0");
+
+        struct audio_port_device_ext usbDeviceExt{};
+        usbDeviceExt.type = AUDIO_DEVICE_OUT_USB_HEADSET;
+        strcpy(usbDeviceExt.address, deviceAddress.c_str());
+
+        struct audio_port_v7 usbDevice{};
+        usbDevice.id = AUDIO_PORT_HANDLE_NONE, usbDevice.role = AUDIO_PORT_ROLE_SINK,
+        usbDevice.type = AUDIO_PORT_TYPE_DEVICE, usbDevice.ext.device = usbDeviceExt;
+
+        // Override config so that the HAL would act as if this device
+        // is discovered to support the given profile and route.
+        mModule->setExclusiveRoutingForPort(templatePortId,
+                                            std::vector<int32_t>(1, routablePortIds[i]));
+        mModule->setConnectedProfileForPort(templatePortId, pcmAudioProfiles[i]);
+        mModule->setConnectedProfileForPort(routablePortIds[i], pcmAudioProfiles[i]);
+
+        ASSERT_EQ(OK, mDevice->setConnectedState(&usbDevice, /* connected= */ true));
+
+        devices.push_back(usbDevice);
+    }
+
+    for (size_t i_device = 0; i_device < NUM_DEVICES; ++i_device) {
+        for (size_t i_mix = 0; i_mix < NUM_DEVICES; ++i_mix) {
+            struct audio_port_v7 devicePort = devices[i_device];
+            struct audio_port_v7 mixPort = {.type = AUDIO_PORT_TYPE_MIX};
+            int32_t mixPortHalId = routablePortIds[i_mix];
+
+            status_t expected_status = i_device == i_mix ? OK : INVALID_OPERATION;
+            ASSERT_EQ(expected_status,
+                      mDevice->getAudioMixPort(&devicePort, &mixPort, mixPortHalId));
+        }
+    }
+
+    for (const auto& device : devices) {
+        ASSERT_EQ(OK, mDevice->setConnectedState(&device, /* connected= */ false));
+    }
+}
+
 class DeviceHalAidlVendorParametersTest : public testing::Test {
   public:
     void SetUp() override {
@@ -997,8 +1483,9 @@ class StreamHalAidlVendorParametersTest : public testing::Test {
         ::aidl::android::hardware::audio::core::StreamDescriptor descriptor;
         StreamContextAidl context(descriptor, false /*isAsynchronous*/, 0,
                                   false /*hasClipTransitionSupport*/);
-        mStream = sp<StreamHalAidl>::make("test", false /*isInput*/, config, 0 /*nominalLatency*/,
-                                          std::move(context), mStreamCommon, mVendorExt);
+        mStream =
+                sp<StreamHalAidlTest>::make("test", false /*isInput*/, config, 0 /*nominalLatency*/,
+                                            std::move(context), mStreamCommon, mVendorExt);
         // The stream may check for some properties after creating.
         mStreamCommon->clearParameters();
     }
@@ -1011,7 +1498,7 @@ class StreamHalAidlVendorParametersTest : public testing::Test {
   protected:
     std::shared_ptr<StreamCommonMock> mStreamCommon;
     std::shared_ptr<TestHalAdapterVendorExtension> mVendorExt;
-    sp<StreamHalAidl> mStream;
+    sp<StreamHalAidlTest> mStream;
 };
 
 TEST_F(StreamHalAidlVendorParametersTest, GetVendorParameter) {
@@ -1090,11 +1577,11 @@ class Hal2AidlMapperTest : public testing::Test {
         config.base.format =
                 AudioFormatDescription{.type = AudioFormatType::PCM, .pcm = PcmType::INT_16_BIT};
         config.base.sampleRate = 48000;
-        ASSERT_EQ(OK,
-                  mMapper->prepareToOpenStream(
-                          42 /*ioHandle*/, mConnectedPort.ext.get<AudioPortExt::device>().device,
-                          AudioIoFlags::make<AudioIoFlags::output>(0), AudioSource::DEFAULT,
-                          &cleanups, &config, &mMixPortConfig, &mPatch));
+        ASSERT_EQ(OK, mMapper->prepareToOpenStream(
+                              42 /*ioHandle*/, 0 /*mixPortHalId*/,
+                              mConnectedPort.ext.get<AudioPortExt::device>().device,
+                              AudioIoFlags::make<AudioIoFlags::output>(0), AudioSource::DEFAULT,
+                              &cleanups, &config, &mMixPortConfig, &mPatch));
         cleanups.disarmAll();
         ASSERT_NE(0, mPatch.id);
         ASSERT_NE(0, mMixPortConfig.id);
@@ -1377,7 +1864,7 @@ TEST_F(Hal2AidlMapperTest, ChangeTransientPatchDevice) {
     defaultDevice.type.type = AudioDeviceType::IN_DEFAULT;
     AudioPortConfig mixPortConfig;
     AudioPatch transientPatch;
-    ASSERT_EQ(OK, mMapper->prepareToOpenStream(43 /*ioHandle*/, defaultDevice,
+    ASSERT_EQ(OK, mMapper->prepareToOpenStream(43 /*ioHandle*/, 0 /*mixPortHalId*/, defaultDevice,
                                                AudioIoFlags::make<AudioIoFlags::input>(0),
                                                AudioSource::DEFAULT, &cleanups, &config,
                                                &mixPortConfig, &transientPatch));
@@ -1462,3 +1949,61 @@ TEST_F(Hal2AidlMapperTest, SetAudioPortConfigGainChangeFromScratch) {
     ASSERT_TRUE(portConfig->gain.has_value());
     EXPECT_EQ(gainConfig, portConfig->gain);
 }
+
+// Note `OUT_USB_HEADSET` is configured to be dynamic, see `getTestConfiguration`.
+TEST_F_WITH_FLAGS(Hal2AidlMapperTest, MultipleDynamicConnectionsWithExclusiveRouting,
+                  REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(com::android::media::audio,
+                                                      check_route_in_get_audio_mix_port))) {
+    const size_t NUM_DEVICES = 2;
+    const std::vector<AudioProfile> pcmAudioProfiles = {
+            createProfile(PcmType::INT_24_BIT, {AudioChannelLayout::LAYOUT_STEREO}, {96000}),
+            createProfile(PcmType::INT_16_BIT, {AudioChannelLayout::LAYOUT_STEREO}, {16000}),
+    };
+
+    AudioDeviceDescription usbDeviceDesc = {
+            .type = AudioDeviceType::OUT_HEADSET,
+            .connection = AudioDeviceDescription::CONNECTION_USB,
+    };
+
+    const auto routablePortIds = mModule->getRoutableMixPortIdsFor(usbDeviceDesc);
+
+    // We will map the mix ports to device ports 1:1 to test routing.
+    ASSERT_EQ(NUM_DEVICES, routablePortIds.size());
+
+    const auto templatePortIds = mModule->getDevicePortIds(usbDeviceDesc);
+    ASSERT_EQ(1u, templatePortIds.size());
+    const int32_t templatePortId = templatePortIds[0];
+
+    std::vector<int32_t> devicePortIds;
+    for (size_t i = 0; i < NUM_DEVICES; ++i) {
+        const std::string deviceAddress =
+                std::string("card=") + std::to_string(i + 1) + std::string(";device=0");
+
+        AudioPort usbDevicePort;
+        usbDevicePort.ext = createPortDeviceExt(AudioDeviceType::OUT_HEADSET, 0,
+                                                AudioDeviceDescription::CONNECTION_USB);
+        usbDevicePort.ext.get<AudioPortExt::device>().device.address = deviceAddress;
+
+        // Override config so that the HAL would act as if this device
+        // is discovered to support the given profile and route.
+        mModule->setExclusiveRoutingForPort(templatePortId,
+                                            std::vector<int32_t>(1, routablePortIds[i]));
+        mModule->setConnectedProfileForPort(routablePortIds[i], pcmAudioProfiles[i]);
+        mModule->setConnectedProfileForPort(templatePortId, pcmAudioProfiles[i]);
+
+        ASSERT_EQ(OK, mMapper->setDevicePortConnectedState(usbDevicePort, /* connected= */ true));
+
+        int32_t portId = mModule->getDevicePortIdWithAddress(deviceAddress, /* isInput= */ false);
+        ASSERT_NE(-1, portId);
+        devicePortIds.push_back(portId);
+    }
+
+    for (size_t i_device = 0; i_device < NUM_DEVICES; ++i_device) {
+        for (size_t i_mix = 0; i_mix < NUM_DEVICES; ++i_mix) {
+            int32_t devicePortId = devicePortIds[i_device];
+            int32_t mixPortId = routablePortIds[i_mix];
+            bool is_routable = i_device == i_mix;
+            ASSERT_EQ(is_routable, mMapper->isRoutable(devicePortId, mixPortId));
+        }
+    }
+}
diff --git a/media/libaudiopermission/NativePermissionController.cpp b/media/libaudiopermission/NativePermissionController.cpp
index 6234202d65..1710ea7fa6 100644
--- a/media/libaudiopermission/NativePermissionController.cpp
+++ b/media/libaudiopermission/NativePermissionController.cpp
@@ -145,9 +145,10 @@ BinderResult<bool> NativePermissionController::validateUidPackagePair(
     }
     const auto cursor = package_map_.find(uid);
     if (cursor == package_map_.end()) {
-        return unexpectedExceptionCode(
-                Status::EX_ILLEGAL_ARGUMENT,
-                "NPC::validatedUidPackagePair: unknown uid");
+        return unexpectedExceptionCode(Status::EX_ILLEGAL_ARGUMENT,
+                                      ("NPC::validateUidPackagePair: uid not found: " +
+                                        std::to_string(uid) + " for package " + packageName)
+                                               .c_str());
     }
     return (std::find(cursor->second.begin(), cursor->second.end(), packageName) !=
             cursor->second.end());
diff --git a/media/libaudioprocessing/BufferProviders.cpp b/media/libaudioprocessing/BufferProviders.cpp
index fbc7f90fb2..a488a80280 100644
--- a/media/libaudioprocessing/BufferProviders.cpp
+++ b/media/libaudioprocessing/BufferProviders.cpp
@@ -497,8 +497,10 @@ status_t TimestretchBufferProvider::getNextBuffer(
     const size_t outputDesired = pBuffer->frameCount - mRemaining;
     size_t dstAvailable;
     do {
-        mBuffer.frameCount = mPlaybackRate.mSpeed == AUDIO_TIMESTRETCH_SPEED_NORMAL
-                ? outputDesired : outputDesired * mPlaybackRate.mSpeed + 1;
+        const size_t completeFrameCount = mPlaybackRate.mSpeed == AUDIO_TIMESTRETCH_SPEED_NORMAL
+                                                  ? outputDesired
+                                                  : outputDesired * mPlaybackRate.mSpeed + 1;
+        mBuffer.frameCount = std::min(completeFrameCount, mLocalBufferFrameCount);
 
         status_t res = mTrackBufferProvider->getNextBuffer(&mBuffer);
 
diff --git a/media/libaudioprocessing/TEST_MAPPING b/media/libaudioprocessing/TEST_MAPPING
index 5d3fb0a013..da72a37eeb 100644
--- a/media/libaudioprocessing/TEST_MAPPING
+++ b/media/libaudioprocessing/TEST_MAPPING
@@ -14,6 +14,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     }
diff --git a/media/libeffects/data/Android.bp b/media/libeffects/data/Android.bp
index 2acf229d8e..aee84a5dca 100644
--- a/media/libeffects/data/Android.bp
+++ b/media/libeffects/data/Android.bp
@@ -17,3 +17,14 @@ prebuilt_etc {
     src: "audio_effects.xml",
     filename: "audio_effects.xml",
 }
+
+prebuilt_etc {
+    name: "aosp_audio_effects.xml",
+    src: "audio_effects.xml",
+    filename_from_src: true,
+    vendor: true,
+    enabled: select(soong_config_variable("frameworks_av", "use_aosp_audio_effects_config"), {
+        true: true,
+        default: false,
+    }),
+}
diff --git a/media/libeffects/dynamicsproc/aidl/DynamicsProcessingContext.cpp b/media/libeffects/dynamicsproc/aidl/DynamicsProcessingContext.cpp
index 81b52aae63..00538b403a 100644
--- a/media/libeffects/dynamicsproc/aidl/DynamicsProcessingContext.cpp
+++ b/media/libeffects/dynamicsproc/aidl/DynamicsProcessingContext.cpp
@@ -473,9 +473,8 @@ RetCode DynamicsProcessingContext::setDpChannelBand_l(const std::any& anyConfig,
         case StageType::POSTEQ: {
             dp_fx::DPEq* dp;
             const auto& config = std::any_cast<DynamicsProcessing::EqBandConfig>(anyConfig);
-            RETURN_VALUE_IF(
-                    nullptr == (dp = getEqWithType_l(type, config.channel)) || !dp->isEnabled(),
-                    RetCode::ERROR_ILLEGAL_PARAMETER, "dpEqNotExist");
+            RETURN_VALUE_IF(nullptr == (dp = getEqWithType_l(type, config.channel)),
+                            RetCode::ERROR_ILLEGAL_PARAMETER, "dpEqNotExist");
             dp_fx::DPEqBand band;
             band.init(config.enable, config.cutoffFrequencyHz, config.gainDb);
             dp->setBand(config.band, band);
@@ -485,7 +484,7 @@ RetCode DynamicsProcessingContext::setDpChannelBand_l(const std::any& anyConfig,
         case StageType::MBC: {
             dp_fx::DPMbc* dp;
             const auto& config = std::any_cast<DynamicsProcessing::MbcBandConfig>(anyConfig);
-            RETURN_VALUE_IF(nullptr == (dp = getMbc_l(config.channel)) || !dp->isEnabled(),
+            RETURN_VALUE_IF(nullptr == (dp = getMbc_l(config.channel)),
                             RetCode::ERROR_ILLEGAL_PARAMETER, "dpMbcNotExist");
             dp_fx::DPMbcBand band;
             band.init(config.enable, config.cutoffFrequencyHz, config.attackTimeMs,
diff --git a/media/libeffects/eraser/Android.bp b/media/libeffects/eraser/Android.bp
new file mode 100644
index 0000000000..9f074ba621
--- /dev/null
+++ b/media/libeffects/eraser/Android.bp
@@ -0,0 +1,80 @@
+// Copyright (C) 2025 The Android Open Source Project
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package {
+    default_applicable_licenses: [
+        "frameworks_av_media_libeffects_eraser_license",
+    ],
+}
+
+license {
+    name: "frameworks_av_media_libeffects_eraser_license",
+    visibility: [":__subpackages__"],
+    license_kinds: [
+        "SPDX-license-identifier-Apache-2.0",
+    ],
+    license_text: [
+        "NOTICE",
+    ],
+}
+
+prebuilt_etc {
+    name: "audio_eraser_classifier_model",
+    src: "models/classifier.tflite",
+    sub_dir: "models",
+    filename: "classifier.tflite",
+    vendor: true,
+}
+
+prebuilt_etc {
+    name: "audio_eraser_separator_model",
+    src: "models/separator.tflite",
+    sub_dir: "models",
+    filename: "separator.tflite",
+    vendor: true,
+}
+
+cc_library_shared {
+    name: "liberaser",
+    srcs: [
+        ":effectCommonFile",
+        "Eraser.cpp",
+        "EraserContext.cpp",
+        "LiteRTInstance.cpp",
+    ],
+    defaults: [
+        "aidlaudioeffectservice_defaults",
+    ],
+    cflags: [
+        "-Wall",
+        "-Werror",
+        "-Wextra",
+        "-Wthread-safety",
+    ],
+    header_libs: [
+        "flatbuffer_headers",
+        "libaudioeffects",
+        "tensorflow_headers",
+    ],
+    shared_libs: [
+        "libtflite",
+    ],
+    static_libs: [
+        "libbase",
+    ],
+    visibility: [
+        "//hardware/interfaces/audio/aidl/default:__subpackages__",
+    ],
+    relative_install_path: "soundfx",
+}
diff --git a/media/libeffects/eraser/Eraser.cpp b/media/libeffects/eraser/Eraser.cpp
new file mode 100644
index 0000000000..c78a594231
--- /dev/null
+++ b/media/libeffects/eraser/Eraser.cpp
@@ -0,0 +1,183 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "AHAL_EraserEffect"
+
+#include <android-base/logging.h>
+#include <aidl/android/hardware/audio/effect/Eraser.h>
+#include <system/audio_effects/effect_uuid.h>
+
+#include "Eraser.h"
+#include "EraserContext.h"
+
+#include <optional>
+
+using aidl::android::hardware::audio::common::getChannelCount;
+using aidl::android::hardware::audio::effect::Descriptor;
+using aidl::android::hardware::audio::effect::Eraser;
+using aidl::android::hardware::audio::effect::getEffectImplUuidEraser;
+using aidl::android::hardware::audio::effect::getEffectTypeUuidEraser;
+using aidl::android::hardware::audio::effect::IEffect;
+using aidl::android::hardware::audio::effect::State;
+using aidl::android::media::audio::common::AudioChannelLayout;
+using aidl::android::media::audio::common::AudioUuid;
+
+extern "C" binder_exception_t createEffect(const AudioUuid* in_impl_uuid,
+                                           std::shared_ptr<IEffect>* instanceSpp) {
+    if (!in_impl_uuid || *in_impl_uuid != getEffectImplUuidEraser()) {
+        LOG(ERROR) << __func__ << "uuid not supported";
+        return EX_ILLEGAL_ARGUMENT;
+    }
+
+    if (!instanceSpp) {
+        LOG(ERROR) << __func__ << " invalid input parameter!";
+        return EX_ILLEGAL_ARGUMENT;
+    }
+
+    *instanceSpp = ndk::SharedRefBase::make<aidl::android::hardware::audio::effect::EraserImpl>();
+    LOG(DEBUG) << __func__ << " instance " << instanceSpp->get() << " created";
+    return EX_NONE;
+}
+
+extern "C" binder_exception_t queryEffect(const AudioUuid* in_impl_uuid, Descriptor* _aidl_return) {
+    if (!in_impl_uuid || *in_impl_uuid != getEffectImplUuidEraser()) {
+        LOG(ERROR) << __func__ << "uuid not supported";
+        return EX_ILLEGAL_ARGUMENT;
+    }
+    *_aidl_return = aidl::android::hardware::audio::effect::EraserImpl::kDescriptor;
+    return EX_NONE;
+}
+
+namespace aidl::android::hardware::audio::effect {
+
+const std::string EraserImpl::kEffectName = "AOSP Audio Eraser";
+const Descriptor EraserImpl::kDescriptor = {
+        .common = {.id = {.type = getEffectTypeUuidEraser(), .uuid = getEffectImplUuidEraser()},
+                   .flags = {.hwAcceleratorMode = Flags::HardwareAccelerator::NONE},
+                   .name = EraserImpl::kEffectName,
+                   .implementor = "The Android Open Source Project"}};
+
+ndk::ScopedAStatus EraserImpl::getDescriptor(Descriptor* _aidl_return) {
+    LOG(DEBUG) << __func__ << kDescriptor.toString();
+    *_aidl_return = kDescriptor;
+    return ndk::ScopedAStatus::ok();
+}
+
+ndk::ScopedAStatus EraserImpl::setParameterSpecific(const Parameter::Specific& specific) {
+    RETURN_IF(Parameter::Specific::eraser != specific.getTag(), EX_ILLEGAL_ARGUMENT,
+              "EffectNotSupported");
+    RETURN_IF(!mContext, EX_NULL_POINTER, "nullContext");
+
+    auto param = specific.get<Parameter::Specific::eraser>();
+    return mContext->setParam(param);
+}
+
+ndk::ScopedAStatus EraserImpl::getParameterSpecific(const Parameter::Id& id,
+                                                    Parameter::Specific* specific) {
+    RETURN_IF(!mContext, EX_NULL_POINTER, "nullContext");
+
+    auto tag = id.getTag();
+    RETURN_IF(Parameter::Id::eraserTag != tag, EX_ILLEGAL_ARGUMENT, "wrongIdTag");
+    auto eraserId = id.get<Parameter::Id::eraserTag>();
+    auto eraserTag = eraserId.getTag();
+    switch (eraserTag) {
+        case Eraser::Id::commonTag: {
+            auto specificTag = eraserId.get<Eraser::Id::commonTag>();
+            std::optional<Eraser> param = mContext->getParam(specificTag);
+            if (!param.has_value()) {
+                return ndk::ScopedAStatus::fromExceptionCodeWithMessage(EX_ILLEGAL_ARGUMENT,
+                                                                        "EraserTagNotSupported");
+            }
+            specific->set<Parameter::Specific::eraser>(param.value());
+            break;
+        }
+        default: {
+            LOG(ERROR) << __func__ << " unsupported tag: " << toString(tag);
+            return ndk::ScopedAStatus::fromExceptionCodeWithMessage(EX_ILLEGAL_ARGUMENT,
+                                                                    "EraserTagNotSupported");
+        }
+    }
+    return ndk::ScopedAStatus::ok();
+}
+
+std::shared_ptr<EffectContext> EraserImpl::createContext(const Parameter::Common& common) {
+    if (mContext) {
+        LOG(DEBUG) << __func__ << " context already exist";
+    } else {
+        mContext = std::make_shared<EraserContext>(1 /* statusFmqDepth */, common);
+    }
+    return mContext;
+}
+
+RetCode EraserImpl::releaseContext() {
+    if (mContext) {
+        mContext.reset();
+    }
+    return RetCode::SUCCESS;
+}
+
+EraserImpl::~EraserImpl() {
+    cleanUp();
+    LOG(DEBUG) << __func__;
+}
+
+ndk::ScopedAStatus EraserImpl::command(CommandId command) {
+    std::lock_guard lg(mImplMutex);
+    RETURN_IF(mState == State::INIT, EX_ILLEGAL_STATE, "instanceNotOpen");
+
+    switch (command) {
+        case CommandId::START:
+            RETURN_OK_IF(mState == State::PROCESSING);
+            mState = State::PROCESSING;
+            mContext->enable();
+            startThread();
+            RETURN_IF(notifyEventFlag(mDataMqNotEmptyEf) != RetCode::SUCCESS, EX_ILLEGAL_STATE,
+                      "notifyEventFlagNotEmptyFailedOnStart");
+            break;
+        case CommandId::STOP:
+            RETURN_OK_IF(mState == State::IDLE);
+            mState = State::IDLE;
+            RETURN_IF(notifyEventFlag(mDataMqNotEmptyEf) != RetCode::SUCCESS, EX_ILLEGAL_STATE,
+                      "notifyEventFlagNotEmptyFailedOnStop");
+            stopThread();
+            mContext->disable();
+            break;
+        case CommandId::RESET:
+            mState = State::IDLE;
+            RETURN_IF(notifyEventFlag(mDataMqNotEmptyEf) != RetCode::SUCCESS, EX_ILLEGAL_STATE,
+                      "notifyEventFlagNotEmptyFailedOnReset");
+            stopThread();
+            mImplContext->disable();
+            mImplContext->reset();
+            mImplContext->resetBuffer();
+            break;
+        default:
+            LOG(ERROR) << getEffectNameWithVersion() << __func__ << " instance still processing";
+            return ndk::ScopedAStatus::fromExceptionCodeWithMessage(EX_ILLEGAL_ARGUMENT,
+                                                                    "CommandIdNotSupported");
+    }
+    LOG(VERBOSE) << getEffectNameWithVersion() << __func__
+                 << " transfer to state: " << toString(mState);
+    return ndk::ScopedAStatus::ok();
+}
+
+// Processing method running in EffectWorker thread.
+IEffect::Status EraserImpl::effectProcessImpl(float* in, float* out, int samples) {
+    RETURN_VALUE_IF(!mContext, (IEffect::Status{EX_NULL_POINTER, 0, 0}), "nullContext");
+    return mContext->process(in, out, samples);
+}
+
+}  // namespace aidl::android::hardware::audio::effect
diff --git a/media/libeffects/eraser/Eraser.h b/media/libeffects/eraser/Eraser.h
new file mode 100644
index 0000000000..6f3c194547
--- /dev/null
+++ b/media/libeffects/eraser/Eraser.h
@@ -0,0 +1,59 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+#include <string>
+#include <vector>
+
+#include <fmq/AidlMessageQueue.h>
+
+#include "effect-impl/EffectContext.h"
+#include "effect-impl/EffectImpl.h"
+
+#include "EraserContext.h"
+
+namespace aidl::android::hardware::audio::effect {
+
+class EraserImpl final : public EffectImpl {
+  public:
+    ~EraserImpl() final;
+
+    static const std::string kEffectName;
+    static const Capability kCapability;
+    static const Descriptor kDescriptor;
+
+    ndk::ScopedAStatus getDescriptor(Descriptor* _aidl_return) final;
+    ndk::ScopedAStatus setParameterSpecific(const Parameter::Specific& specific)
+            REQUIRES(mImplMutex) final;
+    ndk::ScopedAStatus getParameterSpecific(const Parameter::Id& id, Parameter::Specific* specific)
+            REQUIRES(mImplMutex) final;
+
+    std::shared_ptr<EffectContext> createContext(const Parameter::Common& common)
+            REQUIRES(mImplMutex) final;
+    RetCode releaseContext() REQUIRES(mImplMutex) final;
+
+    std::string getEffectName() final { return kEffectName; };
+    IEffect::Status effectProcessImpl(float* in, float* out, int samples)
+            REQUIRES(mImplMutex) final;
+
+    ndk::ScopedAStatus command(CommandId command) final EXCLUDES(mImplMutex);
+
+  private:
+    static const std::vector<Range::SpatializerRange> kRanges;
+    std::shared_ptr<EraserContext> mContext GUARDED_BY(mImplMutex);
+};
+}  // namespace aidl::android::hardware::audio::effect
diff --git a/media/libeffects/eraser/EraserContext.cpp b/media/libeffects/eraser/EraserContext.cpp
new file mode 100644
index 0000000000..e045a23632
--- /dev/null
+++ b/media/libeffects/eraser/EraserContext.cpp
@@ -0,0 +1,137 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "AHAL_EraserContext"
+
+#include <android-base/logging.h>
+#include <sys/param.h>
+#include <sys/stat.h>
+
+#include "EraserContext.h"
+#include "LiteRTInstance.h"
+
+using aidl::android::media::audio::eraser::Mode;
+
+namespace aidl::android::hardware::audio::effect {
+
+const EraserContext::EraserConfiguration EraserContext::kDefaultConfig = {
+        .mode = Mode::ERASER};
+const EraserContext::EraserCapability EraserContext::kCapability = {
+        .modes = {Mode::ERASER, Mode::CLASSIFIER}};
+
+EraserContext::EraserContext(int statusDepth, const Parameter::Common& common)
+    : EffectContext(statusDepth, common),
+      mCommon(common),
+      mConfig(kDefaultConfig) {
+    LOG(DEBUG) << __func__ << ": Creating EraserContext";
+    init();
+}
+
+EraserContext::~EraserContext() {
+    LOG(DEBUG) << __func__ << ": Destroying EraserContext";
+}
+
+void EraserContext::init() {
+    mChannelCount = static_cast<int>(::aidl::android::hardware::audio::common::getChannelCount(
+            mCommon.input.base.channelMask));
+}
+
+RetCode EraserContext::enable() {
+    if (mConfig.mode == Mode::ERASER) {
+        if (!mSeparatorInstance) {
+            mSeparatorInstance = std::make_unique<LiteRTInstance>(kSeparatorModelPath);
+        }
+        if (mSeparatorInstance && mSeparatorInstance->initialize()) {
+            mSeparatorInstance->warmup();
+        } else {
+            LOG(ERROR) << __func__ << ": failed to enable separator";
+            return RetCode::ERROR_EFFECT_LIB_ERROR;
+        }
+    } else {
+        mSeparatorInstance.reset();
+    }
+
+    if (!mClassifierInstance) {
+        mClassifierInstance = std::make_unique<LiteRTInstance>(kClassifierModelPath);
+    }
+    if (mClassifierInstance && mClassifierInstance->initialize()) {
+        mClassifierInstance->warmup();
+    } else {
+        LOG(ERROR) << __func__ << ": failed to enable classifier";
+        return RetCode::ERROR_EFFECT_LIB_ERROR;
+    }
+
+    return RetCode::SUCCESS;
+}
+
+RetCode EraserContext::disable() {
+    mClassifierInstance.reset();
+    mSeparatorInstance.reset();
+    return RetCode::SUCCESS;
+}
+
+RetCode EraserContext::reset() {
+    // reset model inference indexes
+    if (mSeparatorInstance) mSeparatorInstance->resetTensorIndex();
+    if (mClassifierInstance) mClassifierInstance->resetTensorIndex();
+    return RetCode::SUCCESS;
+}
+
+std::optional<Eraser> EraserContext::getParam(Eraser::Tag tag) {
+    switch (tag) {
+        case Eraser::capability:
+            return Eraser::make<Eraser::capability>(kCapability);
+        case Eraser::configuration:
+            return Eraser::make<Eraser::configuration>(mConfig);
+        default: {
+            LOG(ERROR) << __func__ << " unsupported tag: " << toString(tag);
+            return std::nullopt;
+        }
+    }
+}
+
+ndk::ScopedAStatus EraserContext::setParam(Eraser eraser) {
+    const auto tag = eraser.getTag();
+    switch (tag) {
+        case Eraser::configuration: {
+            mConfig = eraser.get<Eraser::configuration>();
+            return ndk::ScopedAStatus::ok();
+        }
+        default: {
+            LOG(ERROR) << __func__ << " unsupported tag: " << toString(tag);
+            return ndk::ScopedAStatus::fromExceptionCode(EX_ILLEGAL_ARGUMENT);
+        }
+    }
+}
+
+IEffect::Status EraserContext::process(float*, float*, int samples) {
+    IEffect::Status procStatus = {EX_ILLEGAL_ARGUMENT, 0, 0};
+    const auto inputChCount = common::getChannelCount(mCommon.input.base.channelMask);
+    const auto outputChCount = common::getChannelCount(mCommon.output.base.channelMask);
+    if (inputChCount < outputChCount) {
+        LOG(ERROR) << __func__ << " invalid channel count, in: " << inputChCount
+                   << " out: " << outputChCount;
+        return procStatus;
+    }
+
+    // TODO: convert input buffer to tensor input format (16kHz/mono/float16) and process
+
+    const int inputFrames = samples / inputChCount;
+    return IEffect::Status{STATUS_OK, static_cast<int32_t>(inputFrames * inputChCount),
+                           static_cast<int32_t>(inputFrames * outputChCount)};
+}
+
+}  // namespace aidl::android::hardware::audio::effect
diff --git a/media/libeffects/eraser/EraserContext.h b/media/libeffects/eraser/EraserContext.h
new file mode 100644
index 0000000000..f0aa2991b5
--- /dev/null
+++ b/media/libeffects/eraser/EraserContext.h
@@ -0,0 +1,72 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+#include <memory>
+#include <optional>
+#include <string>
+
+#include <aidl/android/hardware/audio/effect/Eraser.h>
+#include <aidl/android/media/audio/eraser/Capability.h>
+#include <aidl/android/media/audio/eraser/Configuration.h>
+
+#include "effect-impl/EffectContext.h"
+#include "LiteRTInstance.h"
+
+namespace aidl::android::hardware::audio::effect {
+
+class EraserContext final : public EffectContext {
+  public:
+    EraserContext(int statusDepth, const Parameter::Common& common);
+    ~EraserContext() final;
+
+    RetCode enable() override;
+    RetCode disable() override;
+    RetCode reset() override;
+
+    std::optional<Eraser> getParam(Eraser::Tag tag);
+    ndk::ScopedAStatus setParam(Eraser eraser);
+    IEffect::Status process(float* in, float* out, int samples);
+    using EraserConfiguration = android::media::audio::eraser::Configuration;
+    using EraserCapability = android::media::audio::eraser::Capability;
+
+  private:
+    static const EraserConfiguration kDefaultConfig;
+
+    static const EraserCapability kCapability;
+
+    // yamnet model was used for classifier:
+    // https://github.com/tensorflow/models/tree/master/research/audioset/yamnet
+    const std::string kClassifierModelPath =
+            "/apex/com.android.hardware.audio/etc/models/classifier.tflite";
+
+    // neurips2020_mixit model was used for separator:
+    // https://github.com/google-research/sound-separation/tree/master/models/neurips2020_mixit
+    const std::string kSeparatorModelPath =
+            "/apex/com.android.hardware.audio/etc/models/separator.tflite";
+
+    int mChannelCount;
+    Parameter::Common mCommon;
+    EraserConfiguration mConfig;
+
+    std::unique_ptr<LiteRTInstance> mClassifierInstance;
+    std::unique_ptr<LiteRTInstance> mSeparatorInstance;
+
+    void init();
+};
+
+}  // namespace aidl::android::hardware::audio::effect
\ No newline at end of file
diff --git a/media/libeffects/eraser/LiteRTInstance.cpp b/media/libeffects/eraser/LiteRTInstance.cpp
new file mode 100644
index 0000000000..5f4b690bc6
--- /dev/null
+++ b/media/libeffects/eraser/LiteRTInstance.cpp
@@ -0,0 +1,193 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "AHAL_LiteRTInstance"
+
+#include <sstream>
+#include <string>
+
+#include <android-base/logging.h>
+
+#include "LiteRTInstance.h"
+
+namespace aidl::android::hardware::audio::effect {
+
+LiteRTInstance::LiteRTInstance(const std::string_view& modelPath)
+    : mModelPath(modelPath),
+      mInputTensorIdx(-1),
+      mInputType(kTfLiteNoType),
+      mOutputTensorIdx(-1),
+      mOutputType(kTfLiteNoType) {
+    LOG(DEBUG) << "LiteRTInstance created for model: " << mModelPath;
+}
+
+LiteRTInstance::~LiteRTInstance() {
+    cleanup();
+    LOG(DEBUG) << "LiteRTInstance destructor called for model: " << mModelPath;
+}
+
+bool LiteRTInstance::initialize(int numThreads) {
+    if (isInitialized()) {
+        LOG(WARNING) << "Instance already initialized for model " << mModelPath;
+        return true;
+    }
+
+    mModel = tflite::FlatBufferModel::BuildFromFile(std::string(mModelPath).c_str());
+    if (!mModel) {
+        LOG(ERROR) << "Failed to load model file " << mModelPath;
+        return false;
+    }
+    LOG(INFO) << "Model " << mModelPath << "successfully loaded";
+
+    tflite::ops::builtin::BuiltinOpResolver resolver;
+    tflite::InterpreterBuilder builder(*mModel, resolver);
+    if (builder.SetNumThreads(numThreads) != kTfLiteOk) {
+        LOG(ERROR) << "Failed to set number of threads to: " << numThreads;
+        cleanup();
+        return false;
+    }
+
+    const TfLiteStatus status = builder(&mInterpreter);
+    if(status != kTfLiteOk || mInterpreter == nullptr) {
+        LOG(ERROR) << "Interpreter builder failed with ret " << status << ", interpreter "
+                   << mInterpreter;
+        return false;
+    }
+
+    if (mInterpreter->AllocateTensors() != kTfLiteOk) {
+        LOG(ERROR) << "Failed to allocate tensors";
+        cleanup();
+        return false;
+    }
+
+    // Get Input and Output Tensor Details for sanity checks
+    // Note: This assumes the model has at least one input and one output.
+    if (mInterpreter->inputs().empty() || mInterpreter->outputs().empty()) {
+        LOG(ERROR) << "Invalid input/output for model " << mModelPath;
+        cleanup();
+        return false;
+    }
+
+    mInputTensorIdx = mInterpreter->inputs()[0];
+    TfLiteTensor* inputTensor = mInterpreter->tensor(mInputTensorIdx);
+    if (!inputTensor) {
+        LOG(ERROR) << "Failed to get input tensor structure for index " << mInputTensorIdx;
+        cleanup();
+        return false;
+    }
+    mInputType = inputTensor->type;
+    // Perform type check if needed (e.g., assert mInputType == kTfLiteFloat16)
+
+    mOutputTensorIdx = mInterpreter->outputs()[0];
+    TfLiteTensor* outputTensor = mInterpreter->tensor(mOutputTensorIdx);
+    if (!outputTensor) {
+        LOG(ERROR) << "Failed to get output tensor structure for index " << mOutputTensorIdx;
+        cleanup();
+        return false;
+    }
+    mOutputType = outputTensor->type;
+
+    LOG(DEBUG) << "Model " << mModelPath << " loaded, tensor Info: " << dumpModelDetails();
+    return true;
+}
+
+TfLiteTensor* LiteRTInstance::inputTensor() const {
+    if (!isInitialized() || mInputTensorIdx < 0) {
+        return nullptr;
+    }
+    return mInterpreter->tensor(mInputTensorIdx);
+}
+
+TfLiteTensor* LiteRTInstance::outputTensor() const {
+    if (!isInitialized() || mOutputTensorIdx < 0) {
+        return nullptr;
+    }
+    return mInterpreter->tensor(mOutputTensorIdx);
+}
+
+void LiteRTInstance::resetTensorIndex() {
+    mInputTensorIdx = 0;
+    mOutputTensorIdx = 0;
+}
+
+// Releases resources in the correct order
+void LiteRTInstance::cleanup() {
+    // Interpreter must be reset before the delegate it uses
+    mInterpreter.reset();
+    mModel.reset();
+    LOG(INFO) << "Instance cleaned up " << mModelPath;
+}
+
+// warmup inference once with all zero data
+bool LiteRTInstance::warmup() {
+    if (!isInitialized()) {
+        LOG(DEBUG) << "Warmup called on non-initialized instance: " << mModelPath;
+        return false;
+    }
+
+    TfLiteStatus invokeStatus = mInterpreter->Invoke();
+    if (invokeStatus != kTfLiteOk) {
+        LOG(ERROR) << "Model " << mModelPath << " warmup failed: " <<  invokeStatus;
+        return false;
+    }
+    return true;
+}
+
+std::string LiteRTInstance::dumpTensorShape(const int tensorIndex) {
+    if (!isInitialized()) {
+        return "Not Initialized";
+    }
+    TfLiteTensor* tensor = mInterpreter->tensor(tensorIndex);
+    if (!tensor || !tensor->dims) {
+        return "Invalid Tensor or Dims";
+    }
+
+    // TODO: move to utility method
+    std::ostringstream oss;
+    oss << "[";
+    for (int i = 0; i < tensor->dims->size; ++i) {
+        oss << tensor->dims->data[i] << (i == tensor->dims->size - 1 ? "" : ", ");
+    }
+    oss << "]";
+    return oss.str();
+}
+
+std::string LiteRTInstance::dumpModelDetails() {
+    if (!isInitialized()) {
+       return "uninitialized.";
+   }
+
+   std::ostringstream oss;
+   oss << "Model Path: " << mModelPath << "\n";
+   oss << "Input Tensors (" << mInterpreter->inputs().size() << "):\n";
+   for (int index : mInterpreter->inputs()) {
+       TfLiteTensor* tensor = mInterpreter->tensor(index);
+       oss << "  Index " << index << ": " << (tensor ? tensor->name : "N/A")
+           << ", Type " << static_cast<int>(tensor ? tensor->type : kTfLiteNoType)
+           << ", Shape " << dumpTensorShape(index) << "\n";
+   }
+
+   oss << "Output Tensors (" << mInterpreter->outputs().size() << "):\n";
+   for (int index : mInterpreter->outputs()) {
+       TfLiteTensor* tensor = mInterpreter->tensor(index);
+       oss << "  Index " << index << ": " << (tensor ? tensor->name : "N/A")
+           << ", Type " << static_cast<int>(tensor ? tensor->type : kTfLiteNoType)
+           << ", Shape " << dumpTensorShape(index) << "\n";
+   }
+   return oss.str();
+}
+
+}  // namespace aidl::android::hardware::audio::effect
diff --git a/media/libeffects/eraser/LiteRTInstance.h b/media/libeffects/eraser/LiteRTInstance.h
new file mode 100644
index 0000000000..c58d4b3d67
--- /dev/null
+++ b/media/libeffects/eraser/LiteRTInstance.h
@@ -0,0 +1,124 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#pragma once
+
+#include <memory>
+#include <string>
+#include <string_view>
+
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wsign-compare"
+#pragma clang diagnostic ignored "-Wunused-parameter"
+
+#include <tensorflow/lite/c/c_api_types.h>
+#include <tensorflow/lite/interpreter.h>
+#include <tensorflow/lite/kernels/register.h>
+#include <tensorflow/lite/model.h>
+
+#pragma clang diagnostic pop
+
+namespace aidl::android::hardware::audio::effect {
+
+class LiteRTInstance {
+  public:
+    // Constructor stores configuration, does not load model yet
+    explicit LiteRTInstance(const std::string_view& modelPath);
+    ~LiteRTInstance();
+
+    /**
+     * @brief Initialization: Loads model, creates delegate, builds interpreter, allocate tensors.
+     * @param numThreads Optional: Number of threads for the interpreter. `-1` lets TFLite decide.
+     */
+    bool initialize(int numThreads = 1);
+
+    /**
+     * @brief Checks if the instance has been successfully initialized.
+     * @return true if initialized, false otherwise.
+     */
+    bool isInitialized() const { return mInterpreter != nullptr; }
+
+    // Releases TFLite resources (interpreter, model) in the correct order.
+    // Safe to call multiple times or on a non-initialized instance
+    void cleanup();
+
+    // Performs a warmup inference run, this can help optimize subsequent inference calls.
+    // Must be called after successful initialize().
+    bool warmup();
+
+    // Gets a pointer to the underlying TFLite interpreter.
+    tflite::Interpreter* interpreter() const { return mInterpreter.get(); }
+    // Gets the index of the primary input tensor.
+    int inputTensorIndex() const { return mInputTensorIdx; }
+    // Gets the data type of the primary input tensor.
+    TfLiteType inputType() const { return mInputType; }
+    // Gets the index of the primary output tensor.
+    int outputTensorIndex() const { return mOutputTensorIdx; }
+    // Gets the data type of the primary output tensor.
+    TfLiteType outputType() const { return mOutputType; }
+
+    void resetTensorIndex();
+
+    /**
+     * @brief Gets a pointer to the primary input tensor structure.
+     * Provides access to the input tensor metadata (dims, type) and data buffer.
+     * @return Pointer to the TfLiteTensor, or nullptr if not initialized or index is invalid.
+     */
+     TfLiteTensor* inputTensor() const;
+
+     /**
+      * @brief Gets a pointer to the primary output tensor structure.
+      * Provides access to the output tensor metadata (dims, type) and data buffer.
+      * @return Pointer to the TfLiteTensor, or nullptr if not initialized or index is invalid.
+      */
+     TfLiteTensor* outputTensor() const;
+
+     /**
+      * @brief Dumps details about the loaded model (inputs, outputs, ops).
+      * Useful for debugging. Requires interpreter to be initialized.
+      * @return A string containing model details, or an error message.
+      */
+     std::string dumpModelDetails();
+
+private:
+    const std::string mModelPath;
+    // Resources (Managed internally)
+    std::unique_ptr<tflite::FlatBufferModel> mModel;
+    std::unique_ptr<tflite::Interpreter> mInterpreter;
+    // TODO: Add delegate unique_ptr
+
+
+    // Metadata (Extracted during initialization)
+    int mInputTensorIdx;
+    TfLiteType mInputType;
+    int mOutputTensorIdx;
+    TfLiteType mOutputType;
+
+    /**
+     * @brief Dumps shape information for a specific tensor.
+     * @param tensorIndex The index of the tensor.
+     * @return A string describing the tensor's shape, or an error message.
+     */
+    std::string dumpTensorShape(const int tensorIndex);
+
+    // Prevent copying and moving as this class manages unique resources.
+    LiteRTInstance(const LiteRTInstance&) = delete;
+    LiteRTInstance& operator=(const LiteRTInstance&) = delete;
+    LiteRTInstance(LiteRTInstance&&) = delete;
+    LiteRTInstance& operator=(LiteRTInstance&&) = delete;
+};
+
+}  // namespace aidl::android::hardware::audio::effect
\ No newline at end of file
diff --git a/media/libeffects/eraser/NOTICE b/media/libeffects/eraser/NOTICE
new file mode 100644
index 0000000000..3ce6ced524
--- /dev/null
+++ b/media/libeffects/eraser/NOTICE
@@ -0,0 +1,190 @@
+
+   Copyright (c) 2025, The Android Open Source Project
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+
+
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
diff --git a/media/libeffects/eraser/models/classifier.tflite b/media/libeffects/eraser/models/classifier.tflite
new file mode 100644
index 0000000000..1a34c4bdc4
Binary files /dev/null and b/media/libeffects/eraser/models/classifier.tflite differ
diff --git a/media/libeffects/eraser/models/separator.tflite b/media/libeffects/eraser/models/separator.tflite
new file mode 100644
index 0000000000..fd593b2d61
Binary files /dev/null and b/media/libeffects/eraser/models/separator.tflite differ
diff --git a/media/libeffects/loudness/dsp/core/dynamic_range_compression.cpp b/media/libeffects/loudness/dsp/core/dynamic_range_compression.cpp
index 3d711840a4..e3f02bae96 100644
--- a/media/libeffects/loudness/dsp/core/dynamic_range_compression.cpp
+++ b/media/libeffects/loudness/dsp/core/dynamic_range_compression.cpp
@@ -19,6 +19,8 @@
 #include "dsp/core/dynamic_range_compression.h"
 #include <system/audio.h>
 
+#include <cmath>
+
 namespace le_fx {
 
 AdaptiveDynamicRangeCompression::AdaptiveDynamicRangeCompression() {
diff --git a/media/libeffects/preprocessing/Android.bp b/media/libeffects/preprocessing/Android.bp
index 232bf7acb2..df7b8e2d74 100644
--- a/media/libeffects/preprocessing/Android.bp
+++ b/media/libeffects/preprocessing/Android.bp
@@ -56,7 +56,8 @@ cc_library {
     relative_install_path: "soundfx",
     srcs: ["PreProcessing.cpp"],
     static_libs: [
-        "libabsl",
+        "absl_strings_string_view",
+        "absl_types_optional",
     ],
 }
 
@@ -77,7 +78,8 @@ cc_library_shared {
         "libutils",
     ],
     static_libs: [
-        "libabsl",
+        "absl_strings_string_view",
+        "absl_types_optional",
         "webrtc_audio_processing",
     ],
     header_libs: [
diff --git a/media/libeffects/preprocessing/PreProcessing.cpp b/media/libeffects/preprocessing/PreProcessing.cpp
index 59f1fc3c0e..0b3f9ae2fe 100644
--- a/media/libeffects/preprocessing/PreProcessing.cpp
+++ b/media/libeffects/preprocessing/PreProcessing.cpp
@@ -17,19 +17,19 @@
 #include <stdlib.h>
 #include <string.h>
 #define LOG_TAG "PreProcessing"
-//#define LOG_NDEBUG 0
+// #define LOG_NDEBUG 0
 #include <audio_effects/effect_aec.h>
 #include <audio_effects/effect_agc.h>
-#include <hardware/audio_effect.h>
-#include <utils/Log.h>
-#include <utils/Timers.h>
 #include <audio_effects/effect_agc2.h>
 #include <audio_effects/effect_ns.h>
 #include <audio_processing.h>
+#include <hardware/audio_effect.h>
 #include <module_common_types.h>
+#include <utils/Log.h>
+#include <utils/Timers.h>
 
 // undefine to perform multi channels API functional tests
-//#define DUAL_MIC_TEST
+// #define DUAL_MIC_TEST
 
 //------------------------------------------------------------------------------
 // local definitions
@@ -40,10 +40,10 @@
 
 // types of pre processing modules
 enum preproc_id {
-    PREPROC_AGC,  // Automatic Gain Control
+    PREPROC_AGC,   // Automatic Gain Control
     PREPROC_AGC2,  // Automatic Gain Control 2
-    PREPROC_AEC,  // Acoustic Echo Canceler
-    PREPROC_NS,   // Noise Suppressor
+    PREPROC_AEC,   // Acoustic Echo Canceler
+    PREPROC_NS,    // Noise Suppressor
     PREPROC_NUM_EFFECTS
 };
 
@@ -99,9 +99,9 @@ struct preproc_effect_s {
 // Session context
 struct preproc_session_s {
     struct preproc_effect_s effects[PREPROC_NUM_EFFECTS];  // effects in this session
-    uint32_t state;                // current state (enum preproc_session_state)
-    int id;                        // audio session ID
-    int io;                        // handle of input stream this session is on
+    uint32_t state;  // current state (enum preproc_session_state)
+    int id;          // audio session ID
+    int io;          // handle of input stream this session is on
     rtc::scoped_refptr<webrtc::AudioProcessing>
             apm;  // handle on webRTC audio processing module (APM)
     // Audio Processing module builder
@@ -119,11 +119,11 @@ struct preproc_session_s {
     webrtc::AudioProcessing::Config config;
     webrtc::StreamConfig inputConfig;   // input stream configuration
     webrtc::StreamConfig outputConfig;  // output stream configuration
-    uint32_t revChannelCount;  // number of channels on reverse stream
-    uint32_t revEnabledMsk;    // bit field containing IDs of enabled pre processors
-                               // with reverse channel
-    uint32_t revProcessedMsk;  // bit field containing IDs of pre processors with reverse
-                               // channel already processed in current round
+    uint32_t revChannelCount;           // number of channels on reverse stream
+    uint32_t revEnabledMsk;             // bit field containing IDs of enabled pre processors
+                                        // with reverse channel
+    uint32_t revProcessedMsk;           // bit field containing IDs of pre processors with reverse
+                                        // channel already processed in current round
     webrtc::StreamConfig revConfig;     // reverse stream configuration.
 };
 
@@ -212,17 +212,14 @@ static const effect_descriptor_t sNsDescriptor = {
         "Noise Suppression",
         "The Android Open Source Project"};
 
-static const effect_descriptor_t* sDescriptors[PREPROC_NUM_EFFECTS] = {&sAgcDescriptor,
-                                                                       &sAgc2Descriptor,
-                                                                       &sAecDescriptor,
-                                                                       &sNsDescriptor};
+static const effect_descriptor_t* sDescriptors[PREPROC_NUM_EFFECTS] = {
+        &sAgcDescriptor, &sAgc2Descriptor, &sAecDescriptor, &sNsDescriptor};
 
 //------------------------------------------------------------------------------
 // Helper functions
 //------------------------------------------------------------------------------
 
-const effect_uuid_t* const sUuidToPreProcTable[PREPROC_NUM_EFFECTS] = {FX_IID_AGC,
-                                                                       FX_IID_AGC2,
+const effect_uuid_t* const sUuidToPreProcTable[PREPROC_NUM_EFFECTS] = {FX_IID_AGC, FX_IID_AGC2,
                                                                        FX_IID_AEC, FX_IID_NS};
 
 const effect_uuid_t* ProcIdToUuid(int procId) {
@@ -433,16 +430,16 @@ int Agc2SetParameter(preproc_effect_t* effect, void* pParam, void* pValue) {
         case AGC2_PARAM_ADAPT_DIGI_LEVEL_ESTIMATOR:
             ALOGV("Agc2SetParameter() level estimator %d", *(uint32_t*)pValue);
             if (*(uint32_t*)pValue != 0) {
-              // only RMS is supported
-              status = -EINVAL;
+                // only RMS is supported
+                status = -EINVAL;
             }
             break;
         case AGC2_PARAM_ADAPT_DIGI_EXTRA_SATURATION_MARGIN:
             valueFloat = (float)(*(int32_t*)pValue);
             ALOGV("Agc2SetParameter() extra saturation margin %f dB", valueFloat);
             if (valueFloat != 2.0) {
-              // extra_staturation_margin_db is no longer configurable in webrtc
-              status = -EINVAL;
+                // extra_staturation_margin_db is no longer configurable in webrtc
+                status = -EINVAL;
             }
             break;
         case AGC2_PARAM_PROPERTIES:
@@ -452,7 +449,7 @@ int Agc2SetParameter(preproc_effect_t* effect, void* pParam, void* pValue) {
             effect->session->config.gain_controller2.fixed_digital.gain_db =
                     pProperties->fixedDigitalGain;
             if (pProperties->level_estimator != 0 || pProperties->extraSaturationMargin != 2.0) {
-              status = -EINVAL;
+                status = -EINVAL;
             }
             break;
         default:
@@ -543,11 +540,9 @@ static const preproc_ops_t sAgc2Ops = {Agc2Create,       Agc2Init,    NULL,
 // Acoustic Echo Canceler (AEC)
 //------------------------------------------------------------------------------
 
-
 int AecInit(preproc_effect_t* effect) {
     ALOGV("AecInit");
     effect->session->config = effect->session->apm->GetConfig();
-    effect->session->config.echo_canceller.mobile_mode = true;
     effect->session->apm->ApplyConfig(effect->session->config);
     return 0;
 }
@@ -571,9 +566,8 @@ int AecGetParameter(preproc_effect_t* effect, void* pParam, uint32_t* pValueSize
             ALOGV("AecGetParameter() echo delay %d us", *(uint32_t*)pValue);
             break;
         case AEC_PARAM_MOBILE_MODE:
-            effect->session->config = effect->session->apm->GetConfig();
-            *(uint32_t*)pValue = effect->session->config.echo_canceller.mobile_mode;
-            ALOGV("AecGetParameter() mobile mode %d us", *(uint32_t*)pValue);
+            *(uint32_t*)pValue = false;
+            ALOGI("%s: AEC_PARAM_MOBILE_MODE ignored", __func__);
             break;
         default:
             ALOGW("AecGetParameter() unknown param %08x value %08x", param, *(uint32_t*)pValue);
@@ -595,10 +589,8 @@ int AecSetParameter(preproc_effect_t* effect, void* pParam, void* pValue) {
             ALOGV("AecSetParameter() echo delay %d us, status %d", value, status);
             break;
         case AEC_PARAM_MOBILE_MODE:
-            effect->session->config = effect->session->apm->GetConfig();
-            effect->session->config.echo_canceller.mobile_mode = value;
-            ALOGV("AecSetParameter() mobile mode %d us", value);
-            effect->session->apm->ApplyConfig(effect->session->config);
+            ALOGI("%s: AEC_PARAM_MOBILE_MODE ignored", __func__);
+            status = (value != 0) ? -EINVAL : 0;
             break;
         default:
             ALOGW("AecSetParameter() unknown param %08x value %08x", param, *(uint32_t*)pValue);
@@ -697,9 +689,8 @@ void NsDisable(preproc_effect_t* effect) {
 static const preproc_ops_t sNsOps = {NsCreate,  NsInit,         NULL,           NsEnable,
                                      NsDisable, NsSetParameter, NsGetParameter, NULL};
 
-static const preproc_ops_t* sPreProcOps[PREPROC_NUM_EFFECTS] = {&sAgcOps,
-                                                                &sAgc2Ops,
-                                                                &sAecOps, &sNsOps};
+static const preproc_ops_t* sPreProcOps[PREPROC_NUM_EFFECTS] = {&sAgcOps, &sAgc2Ops, &sAecOps,
+                                                                &sNsOps};
 
 //------------------------------------------------------------------------------
 // Effect functions
diff --git a/media/libeffects/preprocessing/aidl/PreProcessingContext.cpp b/media/libeffects/preprocessing/aidl/PreProcessingContext.cpp
index 2d549ef0f0..6002e86ab9 100644
--- a/media/libeffects/preprocessing/aidl/PreProcessingContext.cpp
+++ b/media/libeffects/preprocessing/aidl/PreProcessingContext.cpp
@@ -16,6 +16,8 @@
 
 #include <cstddef>
 #define LOG_TAG "PreProcessingContext"
+#include <audio_utils/clock.h>
+#include <audio_utils/primitives.h>
 #include <Utils.h>
 
 #include "PreProcessingContext.h"
@@ -25,6 +27,9 @@ namespace aidl::android::hardware::audio::effect {
 using aidl::android::media::audio::common::AudioDeviceDescription;
 using aidl::android::media::audio::common::AudioDeviceType;
 
+// Webrtc processes and returns 10ms data
+constexpr int WEBRTC_FRAME_LENGTH_MS = 10;
+
 RetCode PreProcessingContext::init(const Parameter::Common& common) {
     webrtc::AudioProcessingBuilder apBuilder;
     mAudioProcessingModule = apBuilder.Create();
@@ -36,9 +41,7 @@ RetCode PreProcessingContext::init(const Parameter::Common& common) {
     updateConfigs(common);
 
     mEnabledMsk = 0;
-    mProcessedMsk = 0;
     mRevEnabledMsk = 0;
-    mRevProcessedMsk = 0;
 
     auto config = mAudioProcessingModule->GetConfig();
     switch (mType) {
@@ -84,7 +87,6 @@ RetCode PreProcessingContext::enable() {
             config.echo_canceller.enabled = true;
             // AEC has reverse stream
             mRevEnabledMsk |= typeMsk;
-            mRevProcessedMsk = 0;
             break;
         case PreProcessingEffectType::AUTOMATIC_GAIN_CONTROL_V1:
             config.gain_controller1.enabled = true;
@@ -96,7 +98,6 @@ RetCode PreProcessingContext::enable() {
             config.noise_suppression.enabled = true;
             break;
     }
-    mProcessedMsk = 0;
     mAudioProcessingModule->ApplyConfig(config);
     mState = PRE_PROC_STATE_ACTIVE;
     return RetCode::SUCCESS;
@@ -118,7 +119,6 @@ RetCode PreProcessingContext::disable() {
             config.echo_canceller.enabled = false;
             // AEC has reverse stream
             mRevEnabledMsk &= ~typeMsk;
-            mRevProcessedMsk = 0;
             break;
         case PreProcessingEffectType::AUTOMATIC_GAIN_CONTROL_V1:
             config.gain_controller1.enabled = false;
@@ -130,14 +130,13 @@ RetCode PreProcessingContext::disable() {
             config.noise_suppression.enabled = false;
             break;
     }
-    mProcessedMsk = 0;
     mAudioProcessingModule->ApplyConfig(config);
     mState = PRE_PROC_STATE_INITIALIZED;
     return RetCode::SUCCESS;
 }
 
 RetCode PreProcessingContext::setCommon(const Parameter::Common& common) {
-    if(auto ret = updateIOFrameSize(common); ret != RetCode::SUCCESS) {
+    if (auto ret = updateIOFrameSize(common); ret != RetCode::SUCCESS) {
         return ret;
     }
     mCommon = common;
@@ -148,10 +147,10 @@ RetCode PreProcessingContext::setCommon(const Parameter::Common& common) {
 void PreProcessingContext::updateConfigs(const Parameter::Common& common) {
     mInputConfig.set_sample_rate_hz(common.input.base.sampleRate);
     mInputConfig.set_num_channels(::aidl::android::hardware::audio::common::getChannelCount(
-                    common.input.base.channelMask));
+            common.input.base.channelMask));
     mOutputConfig.set_sample_rate_hz(common.input.base.sampleRate);
     mOutputConfig.set_num_channels(::aidl::android::hardware::audio::common::getChannelCount(
-                    common.output.base.channelMask));
+            common.output.base.channelMask));
 }
 
 RetCode PreProcessingContext::setAcousticEchoCancelerEchoDelay(int echoDelayUs) {
@@ -257,6 +256,12 @@ NoiseSuppression::Level PreProcessingContext::getNoiseSuppressionLevel() const {
     return mLevel;
 }
 
+int PreProcessingContext::calculateWebrtcChunkSizeInSamples() {
+    return getCommon().input.base.sampleRate * WEBRTC_FRAME_LENGTH_MS / MILLIS_PER_SECOND *
+           ::aidl::android::hardware::audio::common::getChannelCount(
+                   mCommon.input.base.channelMask);
+}
+
 IEffect::Status PreProcessingContext::process(float* in, float* out, int samples) {
     IEffect::Status status = {EX_NULL_POINTER, 0, 0};
     RETURN_VALUE_IF(!in, status, "nullInput");
@@ -267,31 +272,41 @@ IEffect::Status PreProcessingContext::process(float* in, float* out, int samples
     RETURN_VALUE_IF(inputFrameCount != outputFrameCount, status, "FrameCountMismatch");
     RETURN_VALUE_IF(0 == getInputFrameSize(), status, "zeroFrameSize");
 
-    mProcessedMsk |= (1 << int(mType));
-
-    // webrtc implementation clear out was_stream_delay_set every time after ProcessStream() call
-    mAudioProcessingModule->set_stream_delay_ms(mEchoDelayUs / 1000);
-
-    if ((mProcessedMsk & mEnabledMsk) == mEnabledMsk) {
-        mProcessedMsk = 0;
-        int processStatus = mAudioProcessingModule->ProcessStream(
-                (const int16_t* const)in, mInputConfig, mOutputConfig, (int16_t* const)out);
-        if (processStatus != 0) {
-            LOG(ERROR) << "Process stream failed with error " << processStatus;
-            return status;
-        }
+    bool processEnable = (1 << int(mType) & mEnabledMsk);
+    bool reverseProcessEnable = (((1 << int(mType)) & mRevEnabledMsk) &&
+                                 (mType == PreProcessingEffectType::ACOUSTIC_ECHO_CANCELLATION));
+    if (!(processEnable || reverseProcessEnable)) {
+        return {STATUS_OK, samples, samples};
     }
-
-    mRevProcessedMsk |= (1 << int(mType));
-
-    if ((mRevProcessedMsk & mRevEnabledMsk) == mRevEnabledMsk) {
-        mRevProcessedMsk = 0;
-        int revProcessStatus = mAudioProcessingModule->ProcessReverseStream(
-                (const int16_t* const)in, mInputConfig, mInputConfig, (int16_t* const)out);
-        if (revProcessStatus != 0) {
-            LOG(ERROR) << "Process reverse stream failed with error " << revProcessStatus;
-            return status;
+    const int processSamples = calculateWebrtcChunkSizeInSamples();
+    std::vector<int16_t> in16(processSamples, 0);
+    std::vector<int16_t> out16(processSamples, 0);
+
+    int samplesToProcess = std::min(samples, processSamples);
+    for (int processedSamples = 0; processedSamples < samples;
+         processedSamples += samplesToProcess) {
+        samplesToProcess = std::min(samples - processedSamples, processSamples);
+        // webrtc implementation clear out was_stream_delay_set every time after ProcessStream()
+        // call
+        mAudioProcessingModule->set_stream_delay_ms(mEchoDelayUs / 1000);
+        memcpy_to_i16_from_float(in16.data(), in + processedSamples, samplesToProcess);
+        if (processEnable) {
+            int processStatus = mAudioProcessingModule->ProcessStream(in16.data(), mInputConfig,
+                                                                      mOutputConfig, out16.data());
+            if (processStatus != 0) {
+                LOG(ERROR) << "Process stream failed with error " << processStatus;
+                return status;
+            }
+        }
+        if (reverseProcessEnable) {
+            int revProcessStatus = mAudioProcessingModule->ProcessReverseStream(
+                    in16.data(), mInputConfig, mInputConfig, out16.data());
+            if (revProcessStatus != 0) {
+                LOG(ERROR) << "Process reverse stream failed with error " << revProcessStatus;
+                return status;
+            }
         }
+        memcpy_to_float_from_i16(out + processedSamples, out16.data(), samplesToProcess);
     }
 
     return {STATUS_OK, samples, samples};
diff --git a/media/libeffects/preprocessing/aidl/PreProcessingContext.h b/media/libeffects/preprocessing/aidl/PreProcessingContext.h
index 1b9b77bb15..fc42b8b9fc 100644
--- a/media/libeffects/preprocessing/aidl/PreProcessingContext.h
+++ b/media/libeffects/preprocessing/aidl/PreProcessingContext.h
@@ -89,13 +89,9 @@ class PreProcessingContext final : public EffectContext {
     // handle on webRTC audio processing module (APM)
     rtc::scoped_refptr<webrtc::AudioProcessing> mAudioProcessingModule;
 
-    int mEnabledMsk;       // bit field containing IDs of enabled pre processors
-    int mProcessedMsk;     // bit field containing IDs of pre processors already
-                                              // processed in current round
-    int mRevEnabledMsk;    // bit field containing IDs of enabled pre processors
-                                              // with reverse channel
-    int mRevProcessedMsk;  // bit field containing IDs of pre processors with
-                           // reverse channel already processed in current round
+    int mEnabledMsk;     // bit field containing IDs of enabled pre processors
+    int mRevEnabledMsk;  // bit field containing IDs of enabled pre processors
+                         // with reverse channel
 
     webrtc::StreamConfig mInputConfig;   // input stream configuration
     webrtc::StreamConfig mOutputConfig;  // output stream configuration
@@ -117,6 +113,8 @@ class PreProcessingContext final : public EffectContext {
 
     // NoiseSuppression
     NoiseSuppression::Level mLevel = NoiseSuppression::Level::LOW;
+
+    int calculateWebrtcChunkSizeInSamples();
 };
 
 }  // namespace aidl::android::hardware::audio::effect
diff --git a/media/libmedia/Android.bp b/media/libmedia/Android.bp
index 13884f03a2..be05279004 100644
--- a/media/libmedia/Android.bp
+++ b/media/libmedia/Android.bp
@@ -436,11 +436,13 @@ cc_library {
     static_libs: [
         "framework-permission-aidl-cpp",
         "resourcemanager_aidl_interface-ndk",
+        "libguiflags",
     ],
 
     export_static_lib_headers: [
         "framework-permission-aidl-cpp",
         "resourcemanager_aidl_interface-ndk",
+        "libguiflags",
     ],
 
     export_include_dirs: [
diff --git a/media/libmedia/AudioCapabilities.cpp b/media/libmedia/AudioCapabilities.cpp
index dbbe9e81a5..4b2722aefb 100644
--- a/media/libmedia/AudioCapabilities.cpp
+++ b/media/libmedia/AudioCapabilities.cpp
@@ -262,6 +262,55 @@ void AudioCapabilities::applyLevelLimits() {
                     maxChannels = 32;
             }
         }
+    } else if (base::EqualsIgnoreCase(mMediaType, MIMETYPE_AUDIO_IAMF)) {
+        for (ProfileLevel profileLevel : mProfileLevels) {
+            auto iamfEncoding = profileLevel.mProfile & 0xff;
+            auto iamfProfile = profileLevel.mProfile & (0xff << 16);
+            switch (iamfProfile) {
+                case IAMF_PROFILE_SIMPLE:
+                    // Per the IAMF spec, the Simple profile can have only one Audio Element and 16
+                    // input channels.
+                    maxChannels = 16;
+                    break;
+                case IAMF_PROFILE_BASE:
+                    // The Base profile can have up to 18 input channels.
+                    maxChannels = 18;
+                    break;
+                case IAMF_PROFILE_BASE_ENHANCED:
+                    // The Base Enhanced profile can have up to 28 input channels.
+                    maxChannels = 28;
+                    break;
+                default:
+                    ALOGW("Unrecognized IAMF profile %d for %s", iamfProfile, mMediaType.c_str());
+                    mError |= ERROR_CAPABILITIES_UNRECOGNIZED;
+            }
+            // Samplerate and bitrate are only restricted by the underlying codecs, so for AAC,
+            // FLAC, and Opus these numbers match their numbers above.
+            switch (iamfEncoding) {
+                case IAMF_CODEC_OPUS:
+                    sampleRates = {48000};
+                    bitRates = Range<int32_t>(6000, 510000);
+                    break;
+                case IAMF_CODEC_AAC:
+                    sampleRates = {7350,  8000,  11025, 12000, 16000, 22050, 24000,
+                                   32000, 44100, 48000, 64000, 88200, 96000};
+                    bitRates = Range<int32_t>(8000, 510000);
+                    break;
+                case IAMF_CODEC_FLAC:
+                    sampleRateRange = Range<int32_t>(1, 655350);
+                    // Lossless, bitrate range ignored.  Possibly as wide as
+                    // Range<int32_t>(1, 21000000).
+                    break;
+                case IAMF_CODEC_PCM:
+                    // PCM is limited by the IAMF spec to the following.
+                    sampleRates = {16000, 32000, 44100, 48000, 96000};
+                    // Lossless, no bitrate range.
+                    break;
+                default:
+                    ALOGW("Unrecognized encoding %d for %s", iamfEncoding, mMediaType.c_str());
+                    mError |= ERROR_CAPABILITIES_UNRECOGNIZED;
+            }
+        }
     } else {
         ALOGW("Unsupported mediaType %s", mMediaType.c_str());
         mError |= ERROR_CAPABILITIES_UNSUPPORTED;
diff --git a/media/libmedia/IMediaDeathNotifier.cpp b/media/libmedia/IMediaDeathNotifier.cpp
index f4984534cf..0a5abd809e 100644
--- a/media/libmedia/IMediaDeathNotifier.cpp
+++ b/media/libmedia/IMediaDeathNotifier.cpp
@@ -19,7 +19,6 @@
 #include <utils/Log.h>
 
 #include <binder/IServiceManager.h>
-#include <binder/IPCThreadState.h>
 #include <media/IMediaDeathNotifier.h>
 
 namespace android {
diff --git a/media/libmedia/IMediaRecorder.cpp b/media/libmedia/IMediaRecorder.cpp
index 1f042172b7..6d1c56a971 100644
--- a/media/libmedia/IMediaRecorder.cpp
+++ b/media/libmedia/IMediaRecorder.cpp
@@ -28,6 +28,7 @@
 #include <media/IMediaRecorderClient.h>
 #include <media/IMediaRecorder.h>
 #include <gui/Surface.h>
+#include <gui/view/Surface.h>
 #include <gui/IGraphicBufferProducer.h>
 #include <media/stagefright/PersistentSurface.h>
 
@@ -39,6 +40,7 @@ enum {
     CLOSE,
     SET_INPUT_SURFACE,
     QUERY_SURFACE_MEDIASOURCE,
+    QUERY_SURFACE_MEDIASOURCE_V2,
     RESET,
     STOP,
     START,
@@ -55,6 +57,7 @@ enum {
     SET_VIDEO_FRAMERATE,
     SET_PARAMETERS,
     SET_PREVIEW_SURFACE,
+    SET_PREVIEW_SURFACE_V2,
     SET_CAMERA,
     SET_LISTENER,
     SET_CLIENT_NAME,
@@ -102,6 +105,38 @@ public:
         return reply.readInt32();
     }
 
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    sp<Surface> querySurfaceMediaSource()
+    {
+        ALOGV("Query SurfaceMediaSource");
+        Parcel data, reply;
+        data.writeInterfaceToken(IMediaRecorder::getInterfaceDescriptor());
+        remote()->transact(QUERY_SURFACE_MEDIASOURCE_V2, data, &reply);
+        int returnedNull = reply.readInt32();
+        if (returnedNull) {
+            return {};
+        }
+        view::Surface surface;
+        status_t status = reply.readParcelable(&surface);
+        if (status != OK) {
+            ALOGE("QUERY_SURFACE_MEDIASOURCE_V2 failed to read Parcelable view::Surface: %s",
+                statusToString(status).c_str());
+            return {};
+        }
+        return surface.toSurface();
+    }
+
+    status_t setPreviewSurface(const sp<Surface>& surface)
+    {
+        ALOGV("setPreviewSurface(%p)", surface.get());
+        Parcel data, reply;
+        data.writeInterfaceToken(IMediaRecorder::getInterfaceDescriptor());
+        view::Surface view_surface = view::Surface::fromSurface(surface);
+        data.writeParcelable(view_surface);
+        remote()->transact(SET_PREVIEW_SURFACE_V2, data, &reply);
+        return reply.readInt32();
+    }
+#else
     sp<IGraphicBufferProducer> querySurfaceMediaSource()
     {
         ALOGV("Query SurfaceMediaSource");
@@ -124,6 +159,7 @@ public:
         remote()->transact(SET_PREVIEW_SURFACE, data, &reply);
         return reply.readInt32();
     }
+#endif
 
     status_t init()
     {
@@ -683,9 +719,23 @@ status_t BnMediaRecorder::onTransact(
             CHECK_INTERFACE(IMediaRecorder, data, reply);
             sp<IGraphicBufferProducer> surface = interface_cast<IGraphicBufferProducer>(
                     data.readStrongBinder());
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+            reply->writeInt32(setPreviewSurface(sp<Surface>::make(surface)));
+#else
             reply->writeInt32(setPreviewSurface(surface));
+#endif
+            return NO_ERROR;
+        } break;
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+        case SET_PREVIEW_SURFACE_V2: {
+            ALOGV("SET_PREVIEW_SURFACE_V2");
+            CHECK_INTERFACE(IMediaRecorder, data, reply);
+            view::Surface surface;
+            data.readParcelable(&surface);
+            reply->writeInt32(setPreviewSurface(surface.toSurface()));
             return NO_ERROR;
         } break;
+#endif
         case SET_CAMERA: {
             ALOGV("SET_CAMERA");
             CHECK_INTERFACE(IMediaRecorder, data, reply);
@@ -707,9 +757,13 @@ status_t BnMediaRecorder::onTransact(
         case QUERY_SURFACE_MEDIASOURCE: {
             ALOGV("QUERY_SURFACE_MEDIASOURCE");
             CHECK_INTERFACE(IMediaRecorder, data, reply);
-            // call the mediaserver side to create
-            // a surfacemediasource
+            // call the mediaserver side to create a surfacemediasource
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+            sp<IGraphicBufferProducer> surfaceMediaSource =
+                querySurfaceMediaSource()->getIGraphicBufferProducer();
+#else
             sp<IGraphicBufferProducer> surfaceMediaSource = querySurfaceMediaSource();
+#endif
             // The mediaserver might have failed to create a source
             int returnedNull= (surfaceMediaSource == NULL) ? 1 : 0 ;
             reply->writeInt32(returnedNull);
@@ -718,6 +772,22 @@ status_t BnMediaRecorder::onTransact(
             }
             return NO_ERROR;
         } break;
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+        case QUERY_SURFACE_MEDIASOURCE_V2: {
+            ALOGV("QUERY_SURFACE_MEDIASOURCE_V2");
+            CHECK_INTERFACE(IMediaRecorder, data, reply);
+            // call the mediaserver side to create
+            // a surfacemediasource
+            sp<Surface> surfaceMediaSource = querySurfaceMediaSource();
+            // The mediaserver might have failed to create a source
+            int returnedNull= (surfaceMediaSource == NULL) ? 1 : 0 ;
+            reply->writeInt32(returnedNull);
+            if (!returnedNull) {
+                reply->writeParcelable(view::Surface::fromSurface(surfaceMediaSource));
+            }
+            return NO_ERROR;
+        } break;
+#endif
         case SET_INPUT_DEVICE: {
             ALOGV("SET_INPUT_DEVICE");
             CHECK_INTERFACE(IMediaRecorder, data, reply);
diff --git a/media/libmedia/include/media/IMediaDeathNotifier.h b/media/libmedia/include/media/IMediaDeathNotifier.h
index aca66787e4..7b7c541742 100644
--- a/media/libmedia/include/media/IMediaDeathNotifier.h
+++ b/media/libmedia/include/media/IMediaDeathNotifier.h
@@ -18,6 +18,7 @@
 #define ANDROID_IMEDIADEATHNOTIFIER_H
 
 #include <utils/threads.h>
+#include <binder/IPCThreadState.h>
 #include <media/IMediaPlayerService.h>
 #include <utils/SortedVector.h>
 
@@ -27,7 +28,10 @@ class IMediaDeathNotifier: virtual public RefBase
 {
 public:
     IMediaDeathNotifier() { addObitRecipient(this); }
-    virtual ~IMediaDeathNotifier() { removeObitRecipient(this); }
+    virtual ~IMediaDeathNotifier() {
+        removeObitRecipient(this);
+        IPCThreadState::self()->flushCommands();
+    }
 
     virtual void died() = 0;
     static const sp<IMediaPlayerService> getMediaPlayerService();
diff --git a/media/libmedia/include/media/IMediaRecorder.h b/media/libmedia/include/media/IMediaRecorder.h
index 8411ca70d6..7f3c75f5e8 100644
--- a/media/libmedia/include/media/IMediaRecorder.h
+++ b/media/libmedia/include/media/IMediaRecorder.h
@@ -23,16 +23,19 @@
 #include <media/AudioContainers.h>
 #include <system/audio.h>
 #include <vector>
+#include <gui/Flags.h> // Remove with MediaSurfaceType and WB_MEDIA_MIGRATION.
 
 namespace android {
 
 class Surface;
+namespace view {
+class Surface;
+}
 namespace hardware {
 class ICamera;
 }
 class ICameraRecordingProxy;
 class IMediaRecorderClient;
-class IGraphicBufferProducer;
 struct PersistentSurface;
 
 class IMediaRecorder: public IInterface
@@ -42,7 +45,7 @@ public:
 
     virtual status_t setCamera(const sp<hardware::ICamera>& camera,
                                const sp<ICameraRecordingProxy>& proxy) = 0;
-    virtual status_t setPreviewSurface(const sp<IGraphicBufferProducer>& surface) = 0;
+    virtual status_t setPreviewSurface(const sp<MediaSurfaceType>& surface) = 0;
     virtual status_t setVideoSource(int vs) = 0;
     virtual status_t setAudioSource(int as) = 0;
     virtual status_t setPrivacySensitive(bool privacySensitive) = 0;
@@ -69,8 +72,7 @@ public:
     virtual status_t close() = 0;
     virtual status_t release() = 0;
     virtual status_t setInputSurface(const sp<PersistentSurface>& surface) = 0;
-    virtual sp<IGraphicBufferProducer> querySurfaceMediaSource() = 0;
-
+    virtual sp<MediaSurfaceType> querySurfaceMediaSource() = 0;
     virtual status_t setInputDevice(audio_port_handle_t deviceId) = 0;
     virtual status_t getRoutedDeviceIds(DeviceIdVector& deviceIds) = 0;
     virtual status_t enableAudioDeviceCallback(bool enabled) = 0;
diff --git a/media/libmedia/include/media/MediaRecorderBase.h b/media/libmedia/include/media/MediaRecorderBase.h
index e3698e3be2..9dd5bbe9a7 100644
--- a/media/libmedia/include/media/MediaRecorderBase.h
+++ b/media/libmedia/include/media/MediaRecorderBase.h
@@ -20,6 +20,7 @@
 
 #include <media/AudioSystem.h>
 #include <media/mediarecorder.h>
+#include <gui/Flags.h> // Remove with MediaSurfaceType and WB_MEDIA_MIGRATION.
 #include <android/content/AttributionSourceState.h>
 
 #include <system/audio.h>
@@ -29,7 +30,6 @@
 namespace android {
 
 class ICameraRecordingProxy;
-class IGraphicBufferProducer;
 struct PersistentSurface;
 
 struct MediaRecorderBase {
@@ -49,7 +49,7 @@ struct MediaRecorderBase {
     virtual status_t setVideoFrameRate(int frames_per_second) = 0;
     virtual status_t setCamera(const sp<hardware::ICamera>& camera,
                                const sp<ICameraRecordingProxy>& proxy) = 0;
-    virtual status_t setPreviewSurface(const sp<IGraphicBufferProducer>& surface) = 0;
+    virtual status_t setPreviewSurface(const sp<MediaSurfaceType>& surface) = 0;
     virtual status_t setOutputFile(int fd) = 0;
     virtual status_t setNextOutputFile(int /*fd*/) {return INVALID_OPERATION;}
     virtual status_t setOutputFileAuxiliary(int /*fd*/) {return INVALID_OPERATION;}
@@ -67,7 +67,7 @@ struct MediaRecorderBase {
     virtual status_t getMetrics(Parcel *reply) = 0;
     virtual status_t dump(int fd, const Vector<String16>& args) const = 0;
     virtual status_t setInputSurface(const sp<PersistentSurface>& surface) = 0;
-    virtual sp<IGraphicBufferProducer> querySurfaceMediaSource() const = 0;
+    virtual sp<MediaSurfaceType> querySurfaceMediaSource() const = 0;
     virtual status_t setInputDevice(audio_port_handle_t deviceId) = 0;
     virtual status_t getRoutedDeviceIds(DeviceIdVector& deviceIds) = 0;
     virtual void setAudioDeviceCallback(const sp<AudioSystem::AudioDeviceCallback>& callback) = 0;
diff --git a/media/libmedia/include/media/mediarecorder.h b/media/libmedia/include/media/mediarecorder.h
index 1377d61053..3e7e72d4cd 100644
--- a/media/libmedia/include/media/mediarecorder.h
+++ b/media/libmedia/include/media/mediarecorder.h
@@ -27,13 +27,15 @@
 #include <media/IMediaDeathNotifier.h>
 #include <android/media/MicrophoneInfoFw.h>
 #include <android/content/AttributionSourceState.h>
+#include <gui/Flags.h> // Remove with MediaSurfaceType and WB_MEDIA_MIGRATION.
 
 namespace android {
 
-class Surface;
 class IMediaRecorder;
 class ICameraRecordingProxy;
+#if not COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
 class IGraphicBufferProducer;
+#endif
 struct PersistentSurface;
 class Surface;
 
@@ -237,7 +239,7 @@ public:
     status_t    initCheck();
     status_t    setCamera(const sp<hardware::ICamera>& camera,
             const sp<ICameraRecordingProxy>& proxy);
-    status_t    setPreviewSurface(const sp<IGraphicBufferProducer>& surface);
+    status_t    setPreviewSurface(const sp<MediaSurfaceType>& surface);
     status_t    setVideoSource(int vs);
     status_t    setAudioSource(int as);
     status_t    setPrivacySensitive(bool privacySensitive);
@@ -264,7 +266,7 @@ public:
     status_t    release();
     void        notify(int msg, int ext1, int ext2);
     status_t    setInputSurface(const sp<PersistentSurface>& surface);
-    sp<IGraphicBufferProducer>     querySurfaceMediaSourceFromMediaServer();
+    sp<MediaSurfaceType>     querySurfaceMediaSourceFromMediaServer();
     status_t    getMetrics(Parcel *reply);
     status_t    setInputDevice(audio_port_handle_t deviceId);
     status_t    getRoutedDeviceIds(DeviceIdVector& deviceIds);
@@ -283,10 +285,10 @@ private:
     sp<IMediaRecorder>          mMediaRecorder;
     sp<MediaRecorderListener>   mListener;
 
-    // Reference to IGraphicBufferProducer
+    // Reference to Surface
     // for encoding GL Frames. That is useful only when the
     // video source is set to VIDEO_SOURCE_GRALLOC_BUFFER
-    sp<IGraphicBufferProducer>  mSurfaceMediaSource;
+    sp<MediaSurfaceType> mSurfaceMediaSource;
 
     media_recorder_states       mCurrentState;
     bool                        mIsAudioSourceSet;
diff --git a/media/libmedia/mediarecorder.cpp b/media/libmedia/mediarecorder.cpp
index e676d5a328..87b4c7b312 100644
--- a/media/libmedia/mediarecorder.cpp
+++ b/media/libmedia/mediarecorder.cpp
@@ -29,7 +29,7 @@
 #include <media/IMediaRecorder.h>
 #include <media/mediaplayer.h>  // for MEDIA_ERROR_SERVER_DIED
 #include <media/stagefright/PersistentSurface.h>
-#include <gui/IGraphicBufferProducer.h>
+#include <gui/view/Surface.h>
 
 namespace android {
 
@@ -57,9 +57,14 @@ status_t MediaRecorder::setCamera(const sp<hardware::ICamera>& camera,
     return ret;
 }
 
-status_t MediaRecorder::setPreviewSurface(const sp<IGraphicBufferProducer>& surface)
+status_t MediaRecorder::setPreviewSurface(const sp<MediaSurfaceType>& surface)
 {
-    ALOGV("setPreviewSurface(%p)", surface.get());
+    if (surface != nullptr) {
+        ALOGV("setPreviewSurface(%p), consumerName: %s", surface.get(),
+            surface->getConsumerName().c_str());
+    } else {
+        ALOGV("setPreviewSurface(NULL)");
+    }
     if (mMediaRecorder == NULL) {
         ALOGE("media recorder is not initialized yet");
         return INVALID_OPERATION;
@@ -413,21 +418,17 @@ status_t MediaRecorder::setVideoSize(int width, int height)
 
 // Query a SurfaceMediaSurface through the Mediaserver, over the
 // binder interface. This is used by the Filter Framework (MediaEncoder)
-// to get an <IGraphicBufferProducer> object to hook up to ANativeWindow.
-sp<IGraphicBufferProducer> MediaRecorder::
-        querySurfaceMediaSourceFromMediaServer()
+// to get an <Surface> object to hook up to ANativeWindow.
+sp<MediaSurfaceType> MediaRecorder::querySurfaceMediaSourceFromMediaServer()
 {
     Mutex::Autolock _l(mLock);
-    mSurfaceMediaSource =
-            mMediaRecorder->querySurfaceMediaSource();
-    if (mSurfaceMediaSource == NULL) {
+    mSurfaceMediaSource = mMediaRecorder->querySurfaceMediaSource();
+    if (mSurfaceMediaSource == nullptr) {
         ALOGE("SurfaceMediaSource could not be initialized!");
     }
     return mSurfaceMediaSource;
 }
 
-
-
 status_t MediaRecorder::setInputSurface(const sp<PersistentSurface>& surface)
 {
     ALOGV("setInputSurface");
@@ -773,7 +774,6 @@ MediaRecorder::MediaRecorder(const AttributionSourceState &attributionSource)
         mCurrentState = MEDIA_RECORDER_IDLE;
     }
 
-
     doCleanUp();
 }
 
diff --git a/media/libmediaplayerservice/DeathNotifier.cpp b/media/libmediaplayerservice/DeathNotifier.cpp
index 241c52d84f..50259054f0 100644
--- a/media/libmediaplayerservice/DeathNotifier.cpp
+++ b/media/libmediaplayerservice/DeathNotifier.cpp
@@ -18,6 +18,7 @@
 #define LOG_TAG "MediaPlayerService-DeathNotifier"
 #include <android-base/logging.h>
 #include <map>
+#include <mutex>
 
 #include "DeathNotifier.h"
 
diff --git a/media/libmediaplayerservice/MediaRecorderClient.cpp b/media/libmediaplayerservice/MediaRecorderClient.cpp
index 53f4e61117..4d70a71c57 100644
--- a/media/libmediaplayerservice/MediaRecorderClient.cpp
+++ b/media/libmediaplayerservice/MediaRecorderClient.cpp
@@ -33,7 +33,12 @@
 #include <codec2/hidl/client.h>
 #include <cutils/atomic.h>
 #include <cutils/properties.h> // for property_get
+#include <gui/Flags.h> // Remove with MediaSurfaceType and WB_MEDIA_MIGRATION.
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+#include <gui/Surface.h>
+#else
 #include <gui/IGraphicBufferProducer.h>
+#endif
 #include <mediautils/ServiceUtilities.h>
 #include <sys/stat.h>
 #include <sys/types.h>
@@ -66,8 +71,7 @@ status_t MediaRecorderClient::setInputSurface(const sp<PersistentSurface>& surfa
     return mRecorder->setInputSurface(surface);
 }
 
-sp<IGraphicBufferProducer> MediaRecorderClient::querySurfaceMediaSource()
-{
+sp<MediaSurfaceType> MediaRecorderClient::querySurfaceMediaSource() {
     ALOGV("Query SurfaceMediaSource");
     Mutex::Autolock lock(mLock);
     if (mRecorder == NULL) {
@@ -77,8 +81,6 @@ sp<IGraphicBufferProducer> MediaRecorderClient::querySurfaceMediaSource()
     return mRecorder->querySurfaceMediaSource();
 }
 
-
-
 status_t MediaRecorderClient::setCamera(const sp<hardware::ICamera>& camera,
                                         const sp<ICameraRecordingProxy>& proxy)
 {
@@ -91,7 +93,7 @@ status_t MediaRecorderClient::setCamera(const sp<hardware::ICamera>& camera,
     return mRecorder->setCamera(camera, proxy);
 }
 
-status_t MediaRecorderClient::setPreviewSurface(const sp<IGraphicBufferProducer>& surface)
+status_t MediaRecorderClient::setPreviewSurface(const sp<MediaSurfaceType>& surface)
 {
     ALOGV("setPreviewSurface");
     Mutex::Autolock lock(mLock);
diff --git a/media/libmediaplayerservice/MediaRecorderClient.h b/media/libmediaplayerservice/MediaRecorderClient.h
index 3b9ab078f4..0f03b01aae 100644
--- a/media/libmediaplayerservice/MediaRecorderClient.h
+++ b/media/libmediaplayerservice/MediaRecorderClient.h
@@ -23,6 +23,7 @@
 #include <media/AudioSystem.h>
 #include <media/IMediaRecorder.h>
 #include <android/content/AttributionSourceState.h>
+#include <gui/Flags.h> // Remove with MediaSurfaceType and WB_MEDIA_MIGRATION.
 
 #include <vector>
 
@@ -49,7 +50,7 @@ class MediaRecorderClient : public BnMediaRecorder
 public:
     virtual     status_t   setCamera(const sp<hardware::ICamera>& camera,
                                     const sp<ICameraRecordingProxy>& proxy);
-    virtual     status_t   setPreviewSurface(const sp<IGraphicBufferProducer>& surface);
+    virtual     status_t   setPreviewSurface(const sp<MediaSurfaceType>& surface);
     virtual     status_t   setVideoSource(int vs);
     virtual     status_t   setAudioSource(int as);
                 status_t   setPrivacySensitive(bool privacySensitive) override;
@@ -78,7 +79,7 @@ public:
     virtual     status_t   release();
     virtual     status_t   dump(int fd, const Vector<String16>& args);
     virtual     status_t   setInputSurface(const sp<PersistentSurface>& surface);
-    virtual     sp<IGraphicBufferProducer> querySurfaceMediaSource();
+    virtual     sp<MediaSurfaceType> querySurfaceMediaSource();
     virtual     status_t   setInputDevice(audio_port_handle_t deviceId);
     virtual     status_t   getRoutedDeviceIds(DeviceIdVector& deviceIds);
     virtual     status_t   enableAudioDeviceCallback(bool enabled);
diff --git a/media/libmediaplayerservice/StagefrightRecorder.cpp b/media/libmediaplayerservice/StagefrightRecorder.cpp
index b93f22699b..81cbf07a59 100644
--- a/media/libmediaplayerservice/StagefrightRecorder.cpp
+++ b/media/libmediaplayerservice/StagefrightRecorder.cpp
@@ -251,9 +251,9 @@ status_t StagefrightRecorder::init() {
 // The client side of mediaserver asks it to create a SurfaceMediaSource
 // and return a interface reference. The client side will use that
 // while encoding GL Frames
-sp<IGraphicBufferProducer> StagefrightRecorder::querySurfaceMediaSource() const {
+sp<MediaSurfaceType> StagefrightRecorder::querySurfaceMediaSource() const {
     ALOGV("Get SurfaceMediaSource");
-    return mGraphicBufferProducer;
+    return mSurface;
 }
 
 status_t StagefrightRecorder::setAudioSource(audio_source_t as) {
@@ -401,10 +401,9 @@ status_t StagefrightRecorder::setCamera(const sp<hardware::ICamera> &camera,
     return OK;
 }
 
-status_t StagefrightRecorder::setPreviewSurface(const sp<IGraphicBufferProducer> &surface) {
+status_t StagefrightRecorder::setPreviewSurface(const sp<MediaSurfaceType> &surface) {
     ALOGV("setPreviewSurface: %p", surface.get());
     mPreviewSurface = surface;
-
     return OK;
 }
 
@@ -1936,32 +1935,15 @@ status_t StagefrightRecorder::setupCameraSource(
             return BAD_VALUE;
         }
 
-#if WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
-        sp<Surface> surface = new Surface(mPreviewSurface);
-        mCameraSourceTimeLapse = CameraSourceTimeLapse::CreateFromCamera(
-                mCamera, mCameraProxy, mCameraId, clientName, uid, pid,
-                videoSize, mFrameRate, surface,
-                std::llround(1e6 / mCaptureFps));
-#else
         mCameraSourceTimeLapse = CameraSourceTimeLapse::CreateFromCamera(
-                mCamera, mCameraProxy, mCameraId, clientName, uid, pid,
-                videoSize, mFrameRate, mPreviewSurface,
+                mCamera, mCameraProxy, mCameraId, clientName, uid, pid, videoSize, mFrameRate,
+                mediaflagtools::mediaSurfaceToCameraSurfaceType(mPreviewSurface),
                 std::llround(1e6 / mCaptureFps));
-#endif
         *cameraSource = mCameraSourceTimeLapse;
     } else {
-#if WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
-        sp<Surface> surface = new Surface(mPreviewSurface);
         *cameraSource = CameraSource::CreateFromCamera(
-                mCamera, mCameraProxy, mCameraId, clientName, uid, pid,
-                videoSize, mFrameRate,
-                surface);
-#else
-        *cameraSource = CameraSource::CreateFromCamera(
-                mCamera, mCameraProxy, mCameraId, clientName, uid, pid,
-                videoSize, mFrameRate,
-                mPreviewSurface);
-#endif
+                mCamera, mCameraProxy, mCameraId, clientName, uid, pid, videoSize, mFrameRate,
+                mediaflagtools::mediaSurfaceToCameraSurfaceType(mPreviewSurface));
     }
     mCamera.clear();
     mCameraProxy.clear();
@@ -2140,12 +2122,6 @@ status_t StagefrightRecorder::setupVideoEncoder(
 
     if (tsLayers > 1) {
         uint32_t bLayers = std::min(2u, tsLayers - 1); // use up-to 2 B-layers
-        // TODO(b/341121900): Remove this once B frames are handled correctly in screen recorder
-        // use case in case of mic only
-        if (!com::android::media::editing::flags::stagefrightrecorder_enable_b_frames()
-                && mAudioSource == AUDIO_SOURCE_MIC && mVideoSource == VIDEO_SOURCE_SURFACE) {
-            bLayers = 0;
-        }
         uint32_t pLayers = tsLayers - bLayers;
         format->setString(
                 "ts-schema", AStringPrintf("android.generic.%u+%u", pLayers, bLayers));
@@ -2181,7 +2157,7 @@ status_t StagefrightRecorder::setupVideoEncoder(
     }
 
     if (cameraSource == NULL) {
-        mGraphicBufferProducer = encoder->getGraphicBufferProducer();
+        mSurface = mediaflagtools::igbpToSurfaceType(encoder->getGraphicBufferProducer());
     }
 
     *source = encoder;
@@ -2462,7 +2438,7 @@ status_t StagefrightRecorder::stop() {
     mPauseStartTimeUs = 0;
     mStartedRecordingUs = 0;
 
-    mGraphicBufferProducer.clear();
+    mSurface.clear();
     mPersistentSurface.clear();
     mAudioEncoderSource.clear();
     mVideoEncoderSource.clear();
diff --git a/media/libmediaplayerservice/StagefrightRecorder.h b/media/libmediaplayerservice/StagefrightRecorder.h
index 4c5e62fab1..d9cf1b5437 100644
--- a/media/libmediaplayerservice/StagefrightRecorder.h
+++ b/media/libmediaplayerservice/StagefrightRecorder.h
@@ -22,6 +22,7 @@
 #include <media/MediaRecorderBase.h>
 #include <camera/CameraParameters.h>
 #include <utils/String8.h>
+#include <gui/Flags.h> // Remove with MediaSurfaceType and WB_MEDIA_MIGRATION.
 
 #include <system/audio.h>
 
@@ -60,7 +61,7 @@ struct StagefrightRecorder : public MediaRecorderBase {
     virtual status_t setVideoSize(int width, int height);
     virtual status_t setVideoFrameRate(int frames_per_second);
     virtual status_t setCamera(const sp<hardware::ICamera>& camera, const sp<ICameraRecordingProxy>& proxy);
-    virtual status_t setPreviewSurface(const sp<IGraphicBufferProducer>& surface);
+    virtual status_t setPreviewSurface(const sp<MediaSurfaceType>& surface);
     virtual status_t setInputSurface(const sp<PersistentSurface>& surface);
     virtual status_t setOutputFile(int fd);
     virtual status_t setNextOutputFile(int fd);
@@ -78,7 +79,7 @@ struct StagefrightRecorder : public MediaRecorderBase {
     virtual status_t getMetrics(Parcel *reply);
     virtual status_t dump(int fd, const Vector<String16> &args) const;
     // Querying a SurfaceMediaSourcer
-    virtual sp<IGraphicBufferProducer> querySurfaceMediaSource() const;
+    virtual sp<MediaSurfaceType> querySurfaceMediaSource() const;
     virtual status_t setInputDevice(audio_port_handle_t deviceId);
     virtual status_t getRoutedDeviceIds(DeviceIdVector& deviceIds);
     virtual void setAudioDeviceCallback(const sp<AudioSystem::AudioDeviceCallback>& callback);
@@ -100,7 +101,7 @@ private:
     mutable Mutex mLock;
     sp<hardware::ICamera> mCamera;
     sp<ICameraRecordingProxy> mCameraProxy;
-    sp<IGraphicBufferProducer> mPreviewSurface;
+    sp<MediaSurfaceType> mPreviewSurface;
     sp<PersistentSurface> mPersistentSurface;
     sp<IMediaRecorderClient> mListener;
     sp<MediaWriter> mWriter;
@@ -179,10 +180,10 @@ private:
 
     bool mStarted;
     // Needed when GLFrames are encoded.
-    // An <IGraphicBufferProducer> pointer
+    // An <MediaSurfaceType> pointer, currently changing from an IGBP to a Surface
     // will be sent to the client side using which the
     // frame buffers will be queued and dequeued
-    sp<IGraphicBufferProducer> mGraphicBufferProducer;
+    sp<MediaSurfaceType> mSurface;
     sp<ALooper> mLooper;
 
     audio_port_handle_t mSelectedDeviceId;
diff --git a/media/libmediaplayerservice/fuzzer/mediaplayer_fuzzer.cpp b/media/libmediaplayerservice/fuzzer/mediaplayer_fuzzer.cpp
index a52d751aec..148cdeac70 100644
--- a/media/libmediaplayerservice/fuzzer/mediaplayer_fuzzer.cpp
+++ b/media/libmediaplayerservice/fuzzer/mediaplayer_fuzzer.cpp
@@ -217,7 +217,8 @@ class FakeBnSurfaceComposerClient : public gui::BnSurfaceComposerClient {
                 (const sp<IBinder>& handle, gui::FrameStats* outStats), (override));
 
     MOCK_METHOD(binder::Status, mirrorSurface,
-                (const sp<IBinder>& mirrorFromHandle, gui::CreateSurfaceResult* outResult),
+                (const sp<IBinder>& mirrorFromHandle, const sp<IBinder>& stopAtHandle,
+                 gui::CreateSurfaceResult* outResult),
                 (override));
 
     MOCK_METHOD(binder::Status, mirrorDisplay,
diff --git a/media/libstagefright/Android.bp b/media/libstagefright/Android.bp
index 884c3982a1..3f7f1f0f6d 100644
--- a/media/libstagefright/Android.bp
+++ b/media/libstagefright/Android.bp
@@ -240,6 +240,7 @@ cc_library {
         "CameraSource.cpp",
         "CameraSourceTimeLapse.cpp",
         "CodecErrorLog.cpp",
+        "CodecTrace.cpp",
         "CryptoAsync.cpp",
         "FrameDecoder.cpp",
         "HevcUtils.cpp",
diff --git a/media/libstagefright/CodecTrace.cpp b/media/libstagefright/CodecTrace.cpp
new file mode 100644
index 0000000000..344937bef0
--- /dev/null
+++ b/media/libstagefright/CodecTrace.cpp
@@ -0,0 +1,310 @@
+/*
+ * Copyright 2025, The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#define LOG_TAG "CodecTrace"
+#define ATRACE_TAG  ATRACE_TAG_VIDEO
+#include <utils/Log.h>
+#include <utils/Trace.h>
+#include <android/binder_ibinder.h>
+#include <media/stagefright/CodecTrace.h>
+#include <media/stagefright/foundation/ABuffer.h>
+
+// Tracks and trace definitions
+// Track definitions
+static const char *const kCodecTracePrefixTrackState = "codec.track.state.";
+static const char *const kCodecTracePrefixTrackAction = "codec.track.action.";
+static const char *const kCodecTraceObjectKeyEvent = "event";
+static const char *const kCodecTraceObjectKeyMetadata = "metadata";
+
+// buffers
+static const uint32_t kCodecTraceValueBufferCountIntervalMs = 500;
+
+// reserved keys for traces
+static const char *const kCodecTraceObjectKeyPid = "pid";
+static const char *const kCodecTraceObjectKeyUid = "uid";
+static const char *const kCodecTraceObjectKeyBufferCount = "count";
+static const char *const kCodecTraceObjectKeyBufferCountIntervalMs = "intervalMs";
+namespace android {
+// CodecEvent base class
+CodecEvent::CodecEvent(std::string name, std::string eventType):
+        mEventType(eventType), mName(name), mMeta(new AMessage()) {
+}
+
+void CodecEvent::onEvent() {
+    if (ATRACE_ENABLED()) [[unlikely]] {
+	    mEventCtr++;
+	    mActive = true;
+	    ALOGV("Event %s fired with value %lld", mName.c_str(), (long long)mEventCtr);
+    }
+}
+
+void CodecEvent::clear() {
+    mEventCtr = 0;
+    mMeta->clear();
+    mMessageInfos.clear();
+    mActive = false;
+}
+
+void CodecEvent::getInfos(std::vector<audio_utils::trace::Object> &infos) const {
+    if (mMessageInfos.empty()) {
+        audio_utils::trace::Object info;
+        CodecEvent::getBaseInfo(info);
+        infos.push_back(info);
+    } else {
+        audio_utils::trace::Object info;
+        for (const audio_utils::trace::Object &msgInfo : mMessageInfos) {
+            info.clear();
+            info = msgInfo;
+            CodecEvent::getBaseInfo(info);
+            infos.push_back(info);
+        }
+    }
+}
+
+void CodecEvent::getType(std::string &type) const {
+    type = mEventType;
+}
+
+void CodecEvent::getName(std::string &name) const {
+    name = mName;
+}
+
+// Expose only specific settings as atrace cannot
+// handle nested messages
+void CodecEvent::setInt32(std::string key, int32_t v) {
+    if (key.empty()) {
+        return;
+    }
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        mMeta->setInt32(key.c_str(), v);
+    }
+}
+
+// This will cause the base info to be duplicated
+// while logging events.
+void CodecEvent::setMessage(const std::string key, const sp<AMessage> &msg) {
+    if (key.empty() || msg == nullptr) {
+        return;
+    }
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        audio_utils::trace::Object trace;
+        trace.set(kCodecTraceObjectKeyMetadata, key);
+        convertToTrace(msg, trace);
+        mMessageInfos.push_back(trace);
+    }
+}
+
+void CodecEvent::setString(const std::string key, const std::string v) {
+    if (key.empty() || v.empty()) {
+        return;
+    }
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        mMeta->setString(key.c_str(), v.c_str());
+    }
+}
+
+void CodecEvent::getBaseInfo(audio_utils::trace::Object &info) const {
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        info.set(kCodecTraceObjectKeyEvent, mName);
+        convertToTrace(mMeta, info);
+    }
+}
+
+bool CodecEvent::isActive() const {
+    return mActive;
+}
+
+
+void CodecEvent::convertToTrace(const sp<AMessage> &msg, audio_utils::trace::Object &trace) const {
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        if (msg == nullptr) {
+            return;
+        }
+        size_t numEntries = msg->countEntries();
+        AMessage::Type type;
+        for (size_t i = 0; i < numEntries; ++i) {
+            const char *name = msg->getEntryNameAt(i, &type);
+            AMessage::ItemData itemData = msg->getEntryAt(i);
+            switch (type) {
+                case AMessage::kTypeInt32: {
+                    int32_t value;
+                    itemData.find(&value);
+                    trace.set(name, value);
+                    break;
+                }
+                case AMessage::kTypeInt64: {
+                    int64_t value;
+                    itemData.find(&value);
+                    trace.set(name, value);
+                    break;
+                }
+                case AMessage::kTypeDouble: {
+                    double value;
+                    itemData.find(&value);
+                    trace.set(name, value);
+                    break;
+                }
+                case AMessage::kTypeString: {
+                    AString value;
+                    itemData.find(&value);
+                    trace.set(name, value.c_str());
+                    break;
+                }
+                // TODO: add support for other types
+                default:
+                    ALOGV("Trace values not updated");
+            }
+        }
+    }
+}
+
+// StateEvent
+StateEvent::StateEvent(const std::string name):
+		CodecEvent(name, kCodecTracePrefixTrackState){
+}
+
+//BufferEvent
+BufferEvent::BufferEvent(const std::string name, const pid_t pid, const uid_t uid):
+        CodecEvent(name, kCodecTracePrefixTrackAction),
+        mPid(pid), mUid(uid) {
+}
+
+void BufferEvent::getInfos(std::vector<audio_utils::trace::Object> &infos) const {
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        audio_utils::trace::Object info;
+        auto fillBufferInfo = [&info, this]() {
+            CodecEvent::getBaseInfo(info);
+            info
+                    .set(kCodecTraceObjectKeyPid, mPid)
+                    .set(kCodecTraceObjectKeyUid, mUid)
+                    .set(kCodecTraceObjectKeyBufferCount, mEventCtr)
+                    .set(kCodecTraceObjectKeyBufferCountIntervalMs,
+                            kCodecTraceValueBufferCountIntervalMs);
+        };
+        if (mMessageInfos.empty()) {
+            info.clear();
+            fillBufferInfo();
+            infos.push_back(info);
+        } else {
+            for (const audio_utils::trace::Object &msgInfo : mMessageInfos) {
+                info.clear();
+                info = msgInfo;
+                fillBufferInfo();
+                infos.push_back(info);
+            }
+        }
+    }
+}
+
+// Tracer
+Tracer::Tracer(const uid_t uid, const pid_t pid)
+        :mPid(pid == Tracer::kNoPid ? AIBinder_getCallingPid() : pid),
+         mUid(uid == Tracer::kNoUid ? AIBinder_getCallingUid() : uid) {
+    ALOGI("Constructing Tracer with uid : %u", mUid);
+    std::string bufferEvents[] = {
+        kCodecTraceActionQueueInputBuffer,
+        kCodecTraceActionOnInputBufferAvailable,
+        kCodecTraceActionQueueOutputBuffer,
+        kCodecTraceActionOnOutputBufferAvailable
+    };
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        for (std::string &bufferEvent : bufferEvents) {
+            std::shared_ptr<BufferEvent> e(new BufferEvent(bufferEvent, mPid, mUid));
+            mBufferEvents.push_back(e);
+        }
+    }
+}
+
+Tracer::~Tracer() {
+    process(false);
+    ALOGV("Destructing Tracer");
+}
+
+std::shared_ptr<BufferEvent> Tracer::getBufferEvent(
+        const std::string name) const {
+    if (name.empty()) {
+        return nullptr;
+    }
+    std::string eventName;
+    for (int i = 0 ; i < mBufferEvents.size(); i++) {
+        mBufferEvents[i]->getName(eventName);
+        if (eventName == name) {
+            return mBufferEvents[i];
+        }
+    }
+    return nullptr;
+}
+
+void Tracer::trace(const CodecEvent * const event) {
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        if (event == nullptr) {
+            return;
+        }
+        std::string name;
+        event->getName(name);
+        if (name == kCodecTraceStateReleased) {
+            // we have to log all buffer events now.
+            process(false);
+        }
+        traceInternal(event);
+    }
+}
+
+void Tracer::traceInternal(const CodecEvent * const event) {
+    if (event == nullptr) {
+        return;
+    }
+    std::string trackName;
+    std::string eType, eName;
+    std::vector<audio_utils::trace::Object> eventInfo;
+    event->getType(eType);
+    trackName = eType + mCodecNameId;
+    event->getInfos(eventInfo);
+    event->getName(eName);
+    for (auto &info : eventInfo) {
+        if (eName.find(kCodecTraceStateAllocated) != eName.npos) {
+            info.set(kCodecTraceObjectKeyPid, mPid)
+                    .set(kCodecTraceObjectKeyUid, mUid);
+        }
+        ATRACE_INSTANT_FOR_TRACK(trackName.c_str(), info.toTrace().c_str());
+    }
+}
+
+void Tracer::process(const bool delayed) {
+    if (ATRACE_ENABLED()) [[unlikely]] {
+        std::string _s;
+        int64_t now = ALooper::GetNowUs();
+        int64_t delayUs = (kCodecTraceValueBufferCountIntervalMs * 1000);
+        int64_t diff = delayed ? (now - mLastTraced) : delayUs;
+        if (mLastTraced == 0 || diff >= delayUs) {
+            ALOGV("Now: %lld LastTraced: %lld diff: %lld",
+                    (long long)now, (long long)mLastTraced, (long long)diff);
+            for (auto &event : mBufferEvents) {
+                if (event && event->isActive()) {
+                    trace(event.get());
+                    event->clear();
+                }
+            }
+            mLastTraced = now;
+        }
+    } else {
+        // clear any events already present
+        for (int i = 0; i < mBufferEvents.size(); i++) {
+            mBufferEvents[i]->clear();
+        }
+    }
+}
+
+}
\ No newline at end of file
diff --git a/media/libstagefright/FrameCaptureLayer.cpp b/media/libstagefright/FrameCaptureLayer.cpp
index 67a59e38d9..330569a56a 100644
--- a/media/libstagefright/FrameCaptureLayer.cpp
+++ b/media/libstagefright/FrameCaptureLayer.cpp
@@ -19,6 +19,7 @@
 
 #include <include/FrameCaptureLayer.h>
 #include <media/stagefright/FrameCaptureProcessor.h>
+#include <gui/BufferItemConsumer.h>
 #include <gui/BufferQueue.h>
 #include <gui/GLConsumer.h>
 #include <gui/IGraphicBufferConsumer.h>
@@ -123,6 +124,11 @@ status_t FrameCaptureLayer::init() {
         return ERROR_UNSUPPORTED;
     }
 
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    std::tie(mConsumer, mSurface) = BufferItemConsumer::create(GraphicBuffer::USAGE_HW_TEXTURE);
+    mConsumer->setName(String8("FrameDecoder"));
+    mConsumer->setFrameAvailableListener(this);
+#else
     // Mimic surfaceflinger's BufferQueueLayer::onFirstRef() to create a
     // BufferQueue for encoder output
     sp<IGraphicBufferProducer> producer;
@@ -143,6 +149,7 @@ status_t FrameCaptureLayer::init() {
 
     mConsumer = consumer;
     mSurface = sp<Surface>::make(producer);
+#endif
 
     return OK;
 }
@@ -187,6 +194,7 @@ void FrameCaptureLayer::onFrameAvailable(const BufferItem& /*item*/) {
     mCondition.signal();
 }
 
+#if !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
 void FrameCaptureLayer::onBuffersReleased() {
     ALOGV("onBuffersReleased");
     Mutex::Autolock _lock(mLock);
@@ -203,6 +211,7 @@ void FrameCaptureLayer::onBuffersReleased() {
 void FrameCaptureLayer::onSidebandStreamChanged() {
     ALOGV("onSidebandStreamChanged");
 }
+#endif
 
 status_t FrameCaptureLayer::acquireBuffer(BufferItem *bi) {
     ALOGV("acquireBuffer");
@@ -225,16 +234,19 @@ status_t FrameCaptureLayer::acquireBuffer(BufferItem *bi) {
         return err;
     }
 
+#if !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
     if (bi->mGraphicBuffer != nullptr) {
         mSlotToBufferMap[bi->mSlot] = bi->mGraphicBuffer;
     } else {
         bi->mGraphicBuffer = mSlotToBufferMap[bi->mSlot];
     }
+#endif
 
     if (bi->mGraphicBuffer == nullptr) {
         ALOGE("acquired null buffer!");
         return BAD_VALUE;
     }
+
     return OK;
 }
 
@@ -242,7 +254,11 @@ status_t FrameCaptureLayer::releaseBuffer(const BufferItem &bi) {
     ALOGV("releaseBuffer");
     Mutex::Autolock _lock(mLock);
 
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    return mConsumer->releaseBuffer(bi.mGraphicBuffer, bi.mFence);
+#else
     return mConsumer->releaseBuffer(bi.mSlot, bi.mFrameNumber, bi.mFence);
+#endif
 }
 
 }  // namespace android
diff --git a/media/libstagefright/FrameDecoder.cpp b/media/libstagefright/FrameDecoder.cpp
index ef3b3bc579..9cc5a28e2e 100644
--- a/media/libstagefright/FrameDecoder.cpp
+++ b/media/libstagefright/FrameDecoder.cpp
@@ -679,6 +679,11 @@ status_t FrameDecoder::extractInternalUsingBlockModel() {
     size_t inputSize = mediaBuffer->range_length();
     std::shared_ptr<C2LinearBlock> block =
             MediaCodec::FetchLinearBlock(inputSize, {std::string{mComponentName.c_str()}});
+    if (block == NULL) {
+        ALOGE("Fatal error: FetchLinearBlock returned NULL");
+        mediaBuffer->release();
+        return NO_MEMORY;
+    }
     C2WriteView view{block->map().get()};
     if (view.error() != C2_OK) {
         ALOGE("Fatal error: failed to allocate and map a block");
diff --git a/media/libstagefright/MPEG4Writer.cpp b/media/libstagefright/MPEG4Writer.cpp
index a83fd8a98d..58707e9097 100644
--- a/media/libstagefright/MPEG4Writer.cpp
+++ b/media/libstagefright/MPEG4Writer.cpp
@@ -5220,15 +5220,10 @@ void MPEG4Writer::Track::writeEdtsBox() {
             } else if (editDurationTicks < 0) {
                 // Only video tracks with B Frames would hit this case.
                 ALOGV("Edit list entry to negate start offset by B frames in other tracks");
-                if (com::android::media::editing::flags::
-                        stagefrightrecorder_enable_b_frames()) {
-                    int32_t mediaTimeTicks =
-                            ((trackStartOffsetUs + movieStartOffsetBFramesUs +
-                              trackStartOffsetBFramesUs) * mTimeScale - 5E5) / 1E6;
-                    addOneElstTableEntry(tkhdDurationTicks, std::abs(mediaTimeTicks), 1, 0);
-                } else {
-                    addOneElstTableEntry(tkhdDurationTicks, std::abs(editDurationTicks), 1, 0);
-                }
+                int32_t mediaTimeTicks =
+                        ((trackStartOffsetUs + movieStartOffsetBFramesUs +
+                            trackStartOffsetBFramesUs) * mTimeScale - 5E5) / 1E6;
+                addOneElstTableEntry(tkhdDurationTicks, std::abs(mediaTimeTicks), 1, 0);
             } else {
                 ALOGV("No edit list entry needed for this track");
             }
diff --git a/media/libstagefright/MediaAdapter.cpp b/media/libstagefright/MediaAdapter.cpp
index 5a2a9109f8..5de2f2ef01 100644
--- a/media/libstagefright/MediaAdapter.cpp
+++ b/media/libstagefright/MediaAdapter.cpp
@@ -22,6 +22,8 @@
 #include <media/stagefright/MediaAdapter.h>
 #include <media/stagefright/MediaBuffer.h>
 
+#include <mutex>
+
 namespace android {
 
 MediaAdapter::MediaAdapter(const sp<MetaData> &meta)
diff --git a/media/libstagefright/MediaCodec.cpp b/media/libstagefright/MediaCodec.cpp
index 97a9f18130..33b670e24e 100644
--- a/media/libstagefright/MediaCodec.cpp
+++ b/media/libstagefright/MediaCodec.cpp
@@ -50,6 +50,7 @@
 #include <binder/IMemory.h>
 #include <binder/IServiceManager.h>
 #include <binder/MemoryDealer.h>
+#include <bionic/dlext_namespaces.h>
 #include <com_android_graphics_libgui_flags.h>
 #include <cutils/properties.h>
 #include <gui/BufferItem.h>
@@ -78,6 +79,7 @@
 #include <media/stagefright/BatteryChecker.h>
 #include <media/stagefright/BufferProducerWrapper.h>
 #include <media/stagefright/CCodec.h>
+#include <media/stagefright/CodecTrace.h>
 #include <media/stagefright/CryptoAsync.h>
 #include <media/stagefright/MediaCodec.h>
 #include <media/stagefright/MediaCodecConstants.h>
@@ -88,7 +90,6 @@
 #include <media/stagefright/PersistentSurface.h>
 #include <media/stagefright/RenderedFrameInfo.h>
 #include <media/stagefright/SurfaceUtils.h>
-#include <nativeloader/dlext_namespaces.h>
 #include <private/android_filesystem_config.h>
 #include <server_configurable_flags/get_flags.h>
 #include <utils/Singleton.h>
@@ -337,7 +338,6 @@ static const C2MemoryUsage kDefaultReadWriteUsage{
     C2MemoryUsage::CPU_READ, C2MemoryUsage::CPU_WRITE};
 
 ////////////////////////////////////////////////////////////////////////////////
-
 /*
  * Implementation of IResourceManagerClient interrface that facilitates
  * MediaCodec reclaim for the ResourceManagerService.
@@ -1593,6 +1593,12 @@ MediaCodec::MediaCodec(
     // we want an empty metrics record for any early getMetrics() call
     // this should be the *only* initMediametrics() call that's not on the Looper thread
     initMediametrics();
+    // tracer
+    if (android::media::codec::provider_->trace_codec_activity()) {
+        if (ATRACE_ENABLED()) [[unlikely]] {
+            mTracer.reset(new Tracer(uid, pid));
+        }
+    }
 }
 
 MediaCodec::~MediaCodec() {
@@ -2097,12 +2103,12 @@ void MediaCodec::updatePictureProfile(const sp<AMessage>& msg, bool applyDefault
         return;
     }
 
-    sp<IMediaQualityManager> mediaQualityMgr =
-            waitForDeclaredService<IMediaQualityManager>(String16("media_quality"));
-    if (mediaQualityMgr == nullptr) {
-        ALOGE("Media Quality Service not found.");
+    sp<IBinder> binder = defaultServiceManager()->checkService(String16("media_quality"));
+    if (binder == nullptr) {
+        ALOGI("media_quality service unavailable, skipping updatePictureProfile");
         return;
     }
+    sp<IMediaQualityManager> mediaQualityMgr = interface_cast<IMediaQualityManager>(binder);
 
     int64_t pictureProfileHandle;
     AString pictureProfileId;
@@ -4296,6 +4302,10 @@ void MediaCodec::cancelPendingDequeueOperations() {
 }
 
 bool MediaCodec::handleDequeueInputBuffer(const sp<AReplyToken> &replyID, bool newRequest) {
+    std::shared_ptr<BufferEvent> event;
+    if (mTracer) {
+        event = mTracer->getBufferEvent(kCodecTraceActionOnInputBufferAvailable);
+    }
     if (!isExecuting()) {
         mErrorLog.log(LOG_TAG, base::StringPrintf(
                 "Invalid to call %s; only valid in executing state",
@@ -4319,6 +4329,9 @@ bool MediaCodec::handleDequeueInputBuffer(const sp<AReplyToken> &replyID, bool n
         CHECK_EQ(index, -EAGAIN);
         return false;
     }
+    if (event) {
+        event->onEvent();
+    }
 
     sp<AMessage> response = new AMessage;
     response->setSize("index", index);
@@ -4330,6 +4343,10 @@ bool MediaCodec::handleDequeueInputBuffer(const sp<AReplyToken> &replyID, bool n
 // always called from the looper thread
 MediaCodec::DequeueOutputResult MediaCodec::handleDequeueOutputBuffer(
         const sp<AReplyToken> &replyID, bool newRequest) {
+    std::shared_ptr<BufferEvent> event;
+    if (mTracer) {
+        event = mTracer->getBufferEvent(kCodecTraceActionOnOutputBufferAvailable);
+    }
     if (!isExecuting()) {
         mErrorLog.log(LOG_TAG, base::StringPrintf(
                 "Invalid to call %s; only valid in executing state",
@@ -4387,7 +4404,9 @@ MediaCodec::DequeueOutputResult MediaCodec::handleDequeueOutputBuffer(
         // already handled a potential output format change that could have
         // started a new subsession.
         statsBufferReceived(timeUs, buffer);
-
+        if (event) {
+            event->onEvent();
+        }
         response->postReply(replyID);
         return DequeueOutputResult::kSuccess;
     }
@@ -4647,6 +4666,10 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
 
                     CHECK(msg->findString("componentName", &mComponentName));
 
+                    if (mTracer) {
+                        mTracer->setCodecInfo(mComponentName.c_str(), mCodecId);
+                    }
+
                     if (mComponentName.c_str()) {
                         mIsHardware = !MediaCodecList::isSoftwareCodec(mComponentName);
                         mediametrics_setCString(mMetricsHandle, kCodecCodec,
@@ -4678,6 +4701,11 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
                     mResourceManagerProxy->addResource(MediaResource::CodecResource(
                             mFlags & kFlagIsSecure, toMediaResourceSubType(mIsHardware, mDomain)));
 
+                    if (mTracer) {
+                        StateEvent allocateEvent(kCodecTraceStateAllocated);
+                        mTracer->trace(&allocateEvent);
+                    }
+
                     postPendingRepliesAndDeferredMessages("kWhatComponentAllocated");
                     break;
                 }
@@ -4724,6 +4752,14 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
                     getRequiredSystemResources();
 
                     setState(CONFIGURED);
+
+                    if (mTracer) {
+                        StateEvent configuredEvent(kCodecTraceStateConfigured);
+                        configuredEvent.setMessage(kCodecTraceMetaKeyInputFormat, mInputFormat);
+                        configuredEvent.setMessage(kCodecTraceMetaKeyOutputFormat, mOutputFormat);
+                        mTracer->trace(&configuredEvent);
+                    }
+
                     postPendingRepliesAndDeferredMessages("kWhatComponentConfigured");
 
                     // augment our media metrics info, now that we know more things
@@ -4885,6 +4921,11 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
                     mResourceManagerProxy->notifyClientStarted(clientConfig);
 
                     setState(STARTED);
+
+                    if (mTracer) {
+                        StateEvent startedEvent(kCodecTraceStateStarted);
+                        mTracer->trace(&startedEvent);
+                    }
                     postPendingRepliesAndDeferredMessages("kWhatStartCompleted");
 
                     // Now that the codec has started, configure, by default, the peek behavior to
@@ -5208,6 +5249,11 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
                     mResourceManagerProxy->notifyClientStopped(clientConfig);
 
                     setState(INITIALIZED);
+
+                    if (mTracer) {
+                        StateEvent stoppedEvent(kCodecTraceStateStopped);
+                        mTracer->trace(&stoppedEvent);
+                    }
                     if (mReplyID) {
                         postPendingRepliesAndDeferredMessages("kWhatStopCompleted");
                     } else {
@@ -5226,6 +5272,12 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
                         break;
                     }
                     setState(UNINITIALIZED);
+
+                    if (mTracer) {
+                        StateEvent releasedEvent(kCodecTraceStateReleased);
+                        mTracer->trace(&releasedEvent);
+                    }
+
                     mComponentName.clear();
 
                     mFlags &= ~kFlagIsComponentAllocated;
@@ -5267,6 +5319,10 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
                         setState(STARTED);
                         mCodec->signalResume();
                     }
+                    if (mTracer) {
+                        StateEvent flushedEvent(kCodecTraceStateFlushed);
+                        mTracer->trace(&flushedEvent);
+                    }
                     mReliabilityContextMetrics.flushCount++;
 
                     postPendingRepliesAndDeferredMessages("kWhatFlushCompleted");
@@ -6341,6 +6397,9 @@ void MediaCodec::onMessageReceived(const sp<AMessage> &msg) {
         default:
             TRESPASS();
     }
+    if (mTracer) {
+        mTracer->process();
+    }
 }
 
 // always called from the looper thread
@@ -6584,6 +6643,10 @@ status_t MediaCodec::queueCSDInputBuffer(size_t bufferIndex) {
         } else {
             std::shared_ptr<C2LinearBlock> block =
                 FetchLinearBlock(csd->size(), {std::string{mComponentName.c_str()}});
+            if (block == NULL) {
+                mErrorLog.log(LOG_TAG, "Fatal error: FetchLinearBlock returned NULL");
+                return -EINVAL;
+            }
             C2WriteView view{block->map().get()};
             if (view.error() != C2_OK) {
                 mErrorLog.log(LOG_TAG, "Fatal error: failed to allocate and map a block");
@@ -7088,6 +7151,13 @@ status_t MediaCodec::onQueueInputBuffer(const sp<AMessage> &msg) {
         info->mData.clear();
 
         statsBufferSent(timeUs, buffer);
+        if (mTracer) {
+            std::shared_ptr<BufferEvent> event =
+                    mTracer->getBufferEvent(kCodecTraceActionQueueInputBuffer);
+            if (event) {
+                event->onEvent();
+            }
+        }
     }
 
     return err;
@@ -7251,6 +7321,14 @@ status_t MediaCodec::onReleaseOutputBuffer(const sp<AMessage> &msg) {
         }
         mBufferChannel->discardBuffer(buffer);
     }
+    std::shared_ptr<BufferEvent> event;
+    if (mTracer) {
+        event = mTracer->getBufferEvent(kCodecTraceActionQueueOutputBuffer);
+        if (event) {
+            event->setString(kCodecTracerMetaKeyRender, (render ? "true" : "false"));
+            event->onEvent();
+        }
+    }
 
     return OK;
 }
@@ -7460,10 +7538,17 @@ status_t MediaCodec::handleSetSurface(const sp<Surface> &surface) {
 
 void MediaCodec::onInputBufferAvailable() {
     int32_t index;
+    std::shared_ptr<BufferEvent> event;
+    if (mTracer) {
+        event = mTracer->getBufferEvent(kCodecTraceActionOnInputBufferAvailable);
+    }
     while ((index = dequeuePortBuffer(kPortIndexInput)) >= 0) {
         sp<AMessage> msg = mCallback->dup();
         msg->setInt32("callbackID", CB_INPUT_AVAILABLE);
         msg->setInt32("index", index);
+        if (event) {
+            event->onEvent();
+        }
         msg->post();
     }
 }
@@ -7471,6 +7556,10 @@ void MediaCodec::onInputBufferAvailable() {
 void MediaCodec::onOutputBufferAvailable() {
     ScopedTrace trace(ATRACE_TAG, "MediaCodec::onOutputBufferAvailable#native");
     int32_t index;
+    std::shared_ptr<BufferEvent> event;
+    if (mTracer) {
+        event = mTracer->getBufferEvent(kCodecTraceActionOnOutputBufferAvailable);
+    }
     while ((index = dequeuePortBuffer(kPortIndexOutput)) >= 0) {
         if (discardDecodeOnlyOutputBuffer(index)) {
             continue;
@@ -7502,6 +7591,9 @@ void MediaCodec::onOutputBufferAvailable() {
              auInfo->value.back().mFlags |= flags & BUFFER_FLAG_END_OF_STREAM;
         }
         msg->setInt32("callbackID", outputCallbackID);
+        if (event) {
+            event->onEvent();
+        }
 
         statsBufferReceived(timeUs, buffer);
 
diff --git a/media/libstagefright/MediaExtractorFactory.cpp b/media/libstagefright/MediaExtractorFactory.cpp
index 1c72a65493..e1c713fccc 100644
--- a/media/libstagefright/MediaExtractorFactory.cpp
+++ b/media/libstagefright/MediaExtractorFactory.cpp
@@ -23,13 +23,13 @@
 #include <binder/IPCThreadState.h>
 #include <binder/PermissionCache.h>
 #include <binder/IServiceManager.h>
+#include <bionic/dlext_namespaces.h>
 #include <media/DataSource.h>
 #include <media/stagefright/InterfaceUtils.h>
 #include <media/stagefright/MediaExtractor.h>
 #include <media/stagefright/MediaExtractorFactory.h>
 #include <android/IMediaExtractor.h>
 #include <android/IMediaExtractorService.h>
-#include <nativeloader/dlext_namespaces.h>
 #include <private/android_filesystem_config.h>
 #include <cutils/properties.h>
 #include <utils/String8.h>
diff --git a/media/libstagefright/data/media_codecs_google_c2_audio.xml b/media/libstagefright/data/media_codecs_google_c2_audio.xml
index 0d9e0ecc3c..252ff79d23 100644
--- a/media/libstagefright/data/media_codecs_google_c2_audio.xml
+++ b/media/libstagefright/data/media_codecs_google_c2_audio.xml
@@ -76,6 +76,18 @@
             <Limit name="sample-rate" ranges="1-655350" />
             <Limit name="bitrate" range="1-21000000" />
         </MediaCodec>
+        <MediaCodec name="c2.android.iamf.decoder" type="audio/iamf" minsdk="36" variant="!slow-cpu">
+            <!-- IAMF v1.0 (Simple and Base profiles) support up to 18 input channels.
+                 See https://aomediacodec.github.io/iamf/v1.0.0-errata.html#syntax-layout. -->
+            <Limit name="channel-count" max="18" />
+            <!-- The decoder currently supports Opus and PCM which are limited to 48k and
+                 16, 32, 44.1, 48, and 96k, respectively, by the IAMF spec.
+                 This will need to be updated when AAC and FLAC are added. -->
+            <Limit name="sample-rate" ranges="16000,32000,44100,48000,96000" />
+            <!-- Permissive bitrate range, representing the max range of FLAC, the
+                 widest range of the IAMF encoding types. -->
+            <Limit name="bitrate" range="1-21000000" />
+        </MediaCodec>
     </Decoders>
     <Encoders>
         <MediaCodec name="c2.android.aac.encoder" type="audio/mp4a-latm">
diff --git a/media/libstagefright/data/media_codecs_sw.xml b/media/libstagefright/data/media_codecs_sw.xml
index 4f458178bb..b1cc7199c8 100644
--- a/media/libstagefright/data/media_codecs_sw.xml
+++ b/media/libstagefright/data/media_codecs_sw.xml
@@ -99,6 +99,19 @@
             <Limit name="bitrate" range="13000" />
             <Attribute name="software-codec" />
         </MediaCodec>
+        <MediaCodec name="c2.android.iamf.decoder" type="audio/iamf" minsdk="36" variant="!slow-cpu">
+            <!-- IAMF v1.0 (Simple and Base profiles) support up to 18 input channels.
+                 See https://aomediacodec.github.io/iamf/v1.0.0-errata.html#syntax-layout. -->
+            <Limit name="channel-count" max="18" />
+            <!-- The decoder currently supports Opus and PCM which are limited to 48k and
+                 16, 32, 44.1, 48, and 96k, respectively, by the IAMF spec.
+                 This will need to be updated when AAC and FLAC are added. -->
+            <Limit name="sample-rate" ranges="16000,32000,44100,48000,96000" />
+            <!-- Permissive bitrate range, representing the max range of FLAC, the
+                 widest range of the IAMF encoding types. -->
+            <Limit name="bitrate" range="1-21000000" />
+            <Attribute name="software-codec" />
+        </MediaCodec>
         <MediaCodec name="c2.android.mpeg4.decoder" type="video/mp4v-es">
             <Alias name="OMX.google.mpeg4.decoder" />
             <!-- profiles and levels:  ProfileSimple : Level3 -->
diff --git a/media/libstagefright/include/FrameCaptureLayer.h b/media/libstagefright/include/FrameCaptureLayer.h
index 23fd5e5d02..f34b58d2ad 100644
--- a/media/libstagefright/include/FrameCaptureLayer.h
+++ b/media/libstagefright/include/FrameCaptureLayer.h
@@ -17,16 +17,22 @@
 #ifndef FRAME_CAPTURE_LAYER_H_
 #define FRAME_CAPTURE_LAYER_H_
 
+#include <com_android_graphics_libgui_flags.h>
 #include <media/stagefright/foundation/ABase.h>
+#include <gui/BufferItemConsumer.h>
 #include <gui/IConsumerListener.h>
 #include <ui/GraphicTypes.h>
 #include <utils/Mutex.h>
 #include <utils/Condition.h>
+#include "gui/BufferItemConsumer.h"
 
 namespace android {
 
-class GraphicBuffer;
+#if !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
 class IGraphicBufferConsumer;
+#endif
+
+class GraphicBuffer;
 class Rect;
 class Surface;
 
@@ -36,14 +42,20 @@ class Surface;
  * buffer is then sent to FrameCaptureProcessor to be converted
  * to sRGB properly.
  */
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+struct FrameCaptureLayer : public BufferItemConsumer::FrameAvailableListener {
+#else
 struct FrameCaptureLayer : public ConsumerListener {
+#endif
     FrameCaptureLayer();
     ~FrameCaptureLayer() = default;
 
     // ConsumerListener
     void onFrameAvailable(const BufferItem& /*item*/) override;
+#if !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
     void onBuffersReleased() override;
     void onSidebandStreamChanged() override;
+#endif
 
     status_t init();
 
@@ -58,9 +70,13 @@ private:
     // GraphicBufferSource is holding an sp to us, holding any sp ref
     // to GraphicBufferSource will cause circular dependency and both
     // object will not be released.
-    sp<IGraphicBufferConsumer> mConsumer;
     sp<Surface> mSurface;
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    sp<BufferItemConsumer> mConsumer;
+#else
+    sp<IGraphicBufferConsumer> mConsumer;
     std::map<int32_t, sp<GraphicBuffer> > mSlotToBufferMap;
+#endif
 
     Mutex mLock;
     Condition mCondition;
diff --git a/media/libstagefright/include/media/stagefright/CodecTrace.h b/media/libstagefright/include/media/stagefright/CodecTrace.h
new file mode 100644
index 0000000000..3324611e55
--- /dev/null
+++ b/media/libstagefright/include/media/stagefright/CodecTrace.h
@@ -0,0 +1,189 @@
+/*
+ * Copyright 2025, The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#ifndef CODEC_TRACE_H_
+#define CODEC_TRACE_H_
+#include <list>
+#include <vector>
+#include <audio_utils/Trace.h>
+#include <media/stagefright/foundation/AMessage.h>
+////////////////////////////////////////////////////////////////////////////////
+/*
+ * Tracer - For logging mediacodec instant event to Perfetto
+ * To make it simple and lock-free, tracer and its events are
+ * by itself not designed to be used from different threads.
+ * This is currently used only within the looper where all events are
+ * serialized.
+ * The definitions for traces are below. Two types of events are defined:
+ *  1. StateEvent
+ *      - These are for logging mediacodec states.
+ *  2. BufferEvent
+ *      - These are for logging buffer events.
+ *          -   queueInputBuffer
+ *          -   onInputBufferAvailable
+ *          -   queueOutputBuffer
+ *          -   onOutputBufferAvailable
+ * As buffer events can be several in a sec, these events are batched while
+ * logging by the tracer. State events are logged immediately as they happen.
+ */
+////////////////////////////////////////////////////////////////////////////////
+namespace android {
+
+// state events
+const char *const kCodecTraceStateAllocated = "allocated";
+const char *const kCodecTraceStateConfigured = "configured";
+const char *const kCodecTraceStateStarted = "started";
+const char *const kCodecTraceStateStopped = "stopped";
+const char *const kCodecTraceStateFlushed = "flushed";
+const char *const kCodecTraceStateReleased = "released";
+//buffer events
+// For input buffers into mediacodec from client
+const char *const kCodecTraceActionQueueInputBuffer = "queueInputBuffer";
+// For input buffers going out from mediacodec to client
+const char *const kCodecTraceActionOnInputBufferAvailable = "onInputBufferAvailable";
+// For output buffers into mediacodec from client
+const char *const kCodecTraceActionQueueOutputBuffer = "queueOutputBuffer";
+// For output buffers going out from mediacodec to client
+const char *const kCodecTraceActionOnOutputBufferAvailable = "onOutputBufferAvailable";
+// metadata keys for buffer events
+const char *const kCodecTracerMetaKeyRender = "render";
+const char *const kCodecTraceMetaKeyInputFormat = "inputFormat";
+const char *const kCodecTraceMetaKeyOutputFormat = "outputFormat";
+
+struct Tracer;
+struct CodecEvent {
+public:
+
+    virtual ~CodecEvent() {
+    }
+
+    // Called when an event is triggered
+    void onEvent();
+
+    // Clear this event immediately, all history of this event is cleared.
+    virtual void clear();
+
+    // Gets all information associated with this event.
+    virtual void getInfos(std::vector<audio_utils::trace::Object> &infos) const;
+
+    // Expose only specific settings as atrace cannot
+    // handle nested messages
+    void setInt32(const std::string key, const int32_t v);
+
+    // This will cause the base info to be duplicated
+    // while logging events.
+    void setMessage(const std::string key, const sp<AMessage> &msg);
+
+    // Sets a key value pair for this event.
+    void setString(const std::string key, const std::string v);
+
+protected:
+    CodecEvent(std::string name, std::string eventType);
+
+    void convertToTrace(const sp<AMessage> &msg, audio_utils::trace::Object &trace) const;
+
+    void getType(std::string &type) const;
+
+    void getName(std::string &name) const;
+
+    bool isActive() const;
+
+    void getBaseInfo(audio_utils::trace::Object &info) const;
+
+    const std::string mEventType;
+    const std::string mName;
+    // Extra infos that will become as part of the base info.
+    const sp<AMessage> mMeta;
+    // Due to limiation in parsing atrace strings,
+    // mMessageInfo will be duplicated for the same event
+    std::list<audio_utils::trace::Object> mMessageInfos;
+    uint64_t mEventCtr = 0;
+    bool mActive = false;
+
+    friend struct Tracer;
+};
+
+struct StateEvent : public CodecEvent {
+public:
+    StateEvent(std::string name);
+
+    virtual ~StateEvent() {}
+};
+
+struct BufferEvent : public CodecEvent {
+
+public:
+    BufferEvent(const std::string name, const pid_t pid, const uid_t uid);
+    virtual ~BufferEvent() {}
+
+protected:
+    // As buffer events are batched, this event can be cleared only by tracer.
+    using CodecEvent::clear;
+
+    void getInfos(std::vector<audio_utils::trace::Object> &infos) const override;
+private:
+    pid_t mPid;
+    uid_t mUid;
+
+    friend struct Tracer;
+};
+
+struct Tracer {
+public:
+    // If initialization from mediacodec happens with kNoPid/kNoUid
+    // then we will try to get pid and uid using AIBinder_getCallingPid()
+    // and AIBinder_getCallingUid().
+    static constexpr pid_t kNoPid = -1;
+    static constexpr uid_t kNoUid = -1;
+
+    // Every action messages in the trace has pid and uid.
+    // These ids along with process tables are used
+    // to track the apps and processes using the codec.
+    Tracer(const uint_t uid, const pid_t pid);
+    virtual ~Tracer();
+
+    // name and id will be used to create unique perfetto tracks
+    void setCodecInfo(std::string name, uint64_t id) {
+        mCodecName = name;
+        mCodecId = id;
+        mCodecNameId = name + "." + std::to_string(id);
+    }
+
+    // BufferEvents are pre-defined and is meant to be requested from
+    // the tracer. The Tracer aggregates events and may use
+    // delayed logging.
+    std::shared_ptr<BufferEvent> getBufferEvent(const std::string name) const;
+
+    // Typically used for state events. This event is logged immediately.
+    void trace(const CodecEvent * const event);
+
+    // process all buffer events. By default it will be delayed.
+    // But 'delayed' can override to make it log right away.
+    void process(const bool delayed = true);
+private:
+    // Internal function for logging events
+    void traceInternal(const CodecEvent * const event);
+    std::vector<std::shared_ptr<BufferEvent>> mBufferEvents;
+    int64_t mLastTraced = 0;
+    uint64_t mCodecId = 0;
+    std::string mCodecName;
+    std::string mCodecNameId;
+    const pid_t mPid;
+    const uid_t mUid;
+};
+
+}  // namespace android
+
+#endif  // CODEC_TRACE_H_
diff --git a/media/libstagefright/include/media/stagefright/MediaAdapter.h b/media/libstagefright/include/media/stagefright/MediaAdapter.h
index c7d77659ce..dabc3fe3ea 100644
--- a/media/libstagefright/include/media/stagefright/MediaAdapter.h
+++ b/media/libstagefright/include/media/stagefright/MediaAdapter.h
@@ -23,6 +23,8 @@
 #include <media/stagefright/MetaData.h>
 #include <utils/threads.h>
 
+#include <mutex>
+
 namespace android {
 
 // Convert the MediaMuxer's push model into MPEG4Writer's pull model.
diff --git a/media/libstagefright/include/media/stagefright/MediaCodec.h b/media/libstagefright/include/media/stagefright/MediaCodec.h
index f03a2a0300..e60ff6eb2d 100644
--- a/media/libstagefright/include/media/stagefright/MediaCodec.h
+++ b/media/libstagefright/include/media/stagefright/MediaCodec.h
@@ -65,6 +65,7 @@ struct CodecCryptoInfo;
 struct CodecParameterDescriptor;
 class IBatteryStats;
 struct ICrypto;
+struct Tracer;
 class CryptoAsync;
 class MediaCodecBuffer;
 class IMemory;
@@ -608,6 +609,8 @@ private:
     } mReliabilityContextMetrics;
     int32_t mSubsessionCount;
 
+    std::shared_ptr<Tracer> mTracer;
+
     // initial create parameters
     AString mInitName;
 
diff --git a/media/libstagefright/include/media/stagefright/MediaCodecConstants.h b/media/libstagefright/include/media/stagefright/MediaCodecConstants.h
index af1e6dd7dc..93819252e5 100644
--- a/media/libstagefright/include/media/stagefright/MediaCodecConstants.h
+++ b/media/libstagefright/include/media/stagefright/MediaCodecConstants.h
@@ -18,6 +18,8 @@
 #ifndef MEDIA_CODEC_CONSTANTS_H_
 #define MEDIA_CODEC_CONSTANTS_H_
 
+#include <string>
+
 namespace {
 
 // from MediaCodecInfo.java
@@ -719,6 +721,58 @@ inline static const char *asString_APVBandLevel(int32_t i, const char *def = "??
     }
 }
 
+// IAMF ProfileLevel
+inline constexpr int32_t IAMF_CODEC_OPUS            = 0x1;
+inline constexpr int32_t IAMF_CODEC_AAC             = 0x1 << 1;
+inline constexpr int32_t IAMF_CODEC_FLAC            = 0x1 << 2;
+inline constexpr int32_t IAMF_CODEC_PCM             = 0x1 << 3;
+inline constexpr int32_t IAMF_PROFILE_SIMPLE        = 0x1 << 16;
+inline constexpr int32_t IAMF_PROFILE_BASE          = 0x1 << 17;
+inline constexpr int32_t IAMF_PROFILE_BASE_ENHANCED = 0x1 << 18;
+inline constexpr int32_t IAMF_v1                    = 0x1 << 24;
+
+inline static const char* asString_IamfProfile(int32_t i, const char* def = "??") {
+    std::string version, profile, codec;
+    switch (i & (0xff << 24)) {
+        case IAMF_v1:
+            version = "IAMF v1";
+            break;
+        default:
+            version = def;
+    }
+    switch (i & (0xff << 16)) {
+        case IAMF_PROFILE_SIMPLE:
+            profile = "Simple";
+            break;
+        case IAMF_PROFILE_BASE:
+            profile = "Base";
+            break;
+        case IAMF_PROFILE_BASE_ENHANCED:
+            profile = "Base Enhanced";
+            break;
+        default:
+            profile = def;
+    }
+    switch (i & (0xff << 8)) {
+        case IAMF_CODEC_OPUS:
+            codec = "Opus";
+            break;
+        case IAMF_CODEC_AAC:
+            codec = "AAC";
+            break;
+        case IAMF_CODEC_FLAC:
+            codec = "FLAC";
+            break;
+        case IAMF_CODEC_PCM:
+            codec = "PCM";
+            break;
+        default:
+            codec = def;
+    }
+    static std::string iamfProfile = version + " " + profile + " " + codec;
+    return iamfProfile.c_str();
+}
+
 // Profiles and levels for AC-4 Codec, corresponding to the definitions in
 // "The MIME codecs parameter", Annex E.13
 // found at https://www.etsi.org/deliver/etsi_ts/103100_103199/10319002/01.02.01_60/ts_10319002v010201p.pdf
@@ -953,6 +1007,7 @@ inline constexpr char MIMETYPE_AUDIO_SCRAMBLED[] = "audio/scrambled";
 inline constexpr char MIMETYPE_AUDIO_DTS[] = "audio/vnd.dts";
 inline constexpr char MIMETYPE_AUDIO_DTS_HD[] = "audio/vnd.dts.hd";
 inline constexpr char MIMETYPE_AUDIO_DTS_UHD[] = "audio/vnd.dts.uhd";
+inline constexpr char MIMETYPE_AUDIO_IAMF[] = "audio/iamf";
 
 inline constexpr char MIMETYPE_IMAGE_ANDROID_HEIC[] = "image/vnd.android.heic";
 
@@ -992,6 +1047,7 @@ inline constexpr char KEY_AAC_MAX_OUTPUT_CHANNEL_COUNT[] = "aac-max-output-chann
 inline constexpr char KEY_AAC_PROFILE[] = "aac-profile";
 inline constexpr char KEY_AAC_SBR_MODE[] = "aac-sbr-mode";
 inline constexpr char KEY_ALLOW_FRAME_DROP[] = "allow-frame-drop";
+inline constexpr char KEY_AUDIO_PRESENTATION_ID[] = "audio-presentation-id";
 inline constexpr char KEY_AUDIO_SESSION_ID[] = "audio-session-id";
 inline constexpr char KEY_BIT_RATE[] = "bitrate";
 inline constexpr char KEY_BITRATE_MODE[] = "bitrate-mode";
diff --git a/media/libstagefright/tests/HEVC/AndroidTest.xml b/media/libstagefright/tests/HEVC/AndroidTest.xml
index 8c7bb91fb5..93c614c9b7 100644
--- a/media/libstagefright/tests/HEVC/AndroidTest.xml
+++ b/media/libstagefright/tests/HEVC/AndroidTest.xml
@@ -27,13 +27,13 @@
     </target_preparer>
     <target_preparer class="com.android.compatibility.common.tradefed.targetprep.MediaPreparer">
         <option name="push-all" value="true" />
-        <option name="media-folder-name" value="HEVCUtilsUnitTest-1.0" />
+        <option name="media-folder-name" value="/data/local/tmp/HEVCUtilsUnitTest-1.0" />
         <option name="dynamic-config-module" value="HEVCUtilsUnitTest" />
     </target_preparer>
 
     <test class="com.android.tradefed.testtype.GTest" >
         <option name="native-test-device-path" value="/data/local/tmp" />
         <option name="module-name" value="HEVCUtilsUnitTest" />
-        <option name="native-test-flag" value="-P /sdcard/test/HEVCUtilsUnitTest-1.0/" />
+        <option name="native-test-flag" value="-P /data/local/tmp/HEVCUtilsUnitTest-1.0/" />
     </test>
 </configuration>
diff --git a/media/mediaserver/manifest_media_c2_software.xml b/media/mediaserver/manifest_media_c2_software.xml
index 31dfafb6ff..04024c8fd5 100644
--- a/media/mediaserver/manifest_media_c2_software.xml
+++ b/media/mediaserver/manifest_media_c2_software.xml
@@ -8,7 +8,20 @@
             <instance>software</instance>
         </interface>
     </hal>
-    <hal format="aidl">
+
+    <!--
+        This (and above) are actually served as part of the swcodec APEX.
+        However, this was one of the first APEXEes, so they were created
+        before APEX supported VINTF manifest. So, devices have old manifest
+        entries, and the manifest is not in the APEX. The manifest also
+        does not contain updatable-via-apex until Android 16 (B). Because of
+        this, if the version is updated, vts_treble_vintf_vendor_test may
+        fail on old devices which have the updated mainline module. If the
+        manifest entry is conditionally added to the APEX, so that it is only
+        read on new devices, we could move this entry from the platform into
+        the APEX.
+    -->
+    <hal format="aidl" updatable-via-apex="com.android.media.swcodec">
         <name>android.hardware.media.c2</name>
         <version>1</version>
         <fqname>IComponentStore/software</fqname>
diff --git a/media/module/bqhelper/Android.bp b/media/module/bqhelper/Android.bp
index f9b7deaf41..89cf7098be 100644
--- a/media/module/bqhelper/Android.bp
+++ b/media/module/bqhelper/Android.bp
@@ -28,6 +28,14 @@ cc_defaults {
         "media_plugin_headers",
     ],
 
+    static_libs: [
+        "libguiflags",
+    ],
+
+    export_static_lib_headers: [
+        "libguiflags",
+    ],
+
     shared_libs: [
         "libbase",
         "libcutils",
@@ -37,16 +45,13 @@ cc_defaults {
         "libstagefright_foundation",
         "libui",
         "libutils",
-
         "android.hardware.graphics.bufferqueue@1.0",
-        "android.hardware.graphics.bufferqueue@2.0",
     ],
 
     export_shared_lib_headers: [
         "libhidlmemory",
         "libstagefright_foundation",
         "android.hardware.graphics.bufferqueue@1.0",
-        "android.hardware.graphics.bufferqueue@2.0",
     ],
 
     cflags: [
@@ -71,7 +76,7 @@ cc_library_shared {
     vendor_available: true,
     min_sdk_version: "29",
 
-    shared_libs: [ "libgui" ],
+    shared_libs: ["libgui"],
     target: {
         vendor: {
             exclude_shared_libs: [
@@ -92,32 +97,3 @@ cc_library_shared {
         },
     },
 }
-
-// This lib is needed on devices that doesn't use vndk,
-// on these devices we still don't want libgui to be pulled
-// in onto the apex build. It should only be used by
-// libcodec2_hidl@1.x, etc. from service side. It could
-// be removed if all builds are using vndk.
-cc_library_shared {
-    name: "libstagefright_bufferqueue_helper_novndk",
-    defaults: ["libstagefright_bufferqueue-defaults"],
-    apex_available: [
-        "com.android.media.swcodec",
-        "test_com.android.media.swcodec",
-        "//apex_available:platform",
-    ],
-    vendor_available: false,
-    min_sdk_version: "29",
-    static_libs: [
-        "libgui_bufferqueue_static",
-    ],
-    shared_libs: [
-        "android.hidl.token@1.0-utils",
-        "libEGL",
-        "libnativewindow",
-        "libvndksupport",
-    ],
-    cflags: [
-        "-DNO_BINDER",
-    ],
-}
diff --git a/media/module/bqhelper/GraphicBufferSource.cpp b/media/module/bqhelper/GraphicBufferSource.cpp
index c9082f20ff..cf16bbf018 100644
--- a/media/module/bqhelper/GraphicBufferSource.cpp
+++ b/media/module/bqhelper/GraphicBufferSource.cpp
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2013 The Android Open Source Project
+ * Copyright (C) 2025 The Android Open Source Project
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
@@ -14,1464 +14,10 @@
  * limitations under the License.
  */
 
-#include <inttypes.h>
+#include <com_android_graphics_libgui_flags.h>
 
-#define LOG_TAG "GraphicBufferSource"
-//#define LOG_NDEBUG 0
-#include <utils/Log.h>
-
-#define STRINGIFY_ENUMS // for asString in HardwareAPI.h/VideoAPI.h
-
-#include <media/stagefright/bqhelper/GraphicBufferSource.h>
-#include <media/stagefright/bqhelper/FrameDropper.h>
-#include <media/stagefright/foundation/ADebug.h>
-#include <media/stagefright/foundation/AMessage.h>
-#include <media/stagefright/foundation/ColorUtils.h>
-#include <media/stagefright/foundation/FileDescriptor.h>
-
-#include <android-base/properties.h>
-#include <media/hardware/MetadataBufferType.h>
-#include <ui/GraphicBuffer.h>
-#include <gui/BufferItem.h>
-#include <gui/BufferQueue.h>
-#include <gui/bufferqueue/1.0/WGraphicBufferProducer.h>
-#include <gui/bufferqueue/2.0/B2HGraphicBufferProducer.h>
-#include <gui/IGraphicBufferProducer.h>
-#include <gui/IGraphicBufferConsumer.h>
-#include <media/hardware/HardwareAPI.h>
-
-#include <inttypes.h>
-
-#include <functional>
-#include <memory>
-#include <cmath>
-
-namespace android {
-
-namespace {
-// kTimestampFluctuation is an upper bound of timestamp fluctuation from the
-// source that GraphicBufferSource allows. The unit of kTimestampFluctuation is
-// frames. More specifically, GraphicBufferSource will drop a frame if
-//
-// expectedNewFrametimestamp - actualNewFrameTimestamp <
-//     (0.5 - kTimestampFluctuation) * expectedtimePeriodBetweenFrames
-//
-// where
-// - expectedNewFrameTimestamp is the calculated ideal timestamp of the new
-//   incoming frame
-// - actualNewFrameTimestamp is the timestamp received from the source
-// - expectedTimePeriodBetweenFrames is the ideal difference of the timestamps
-//   of two adjacent frames
-//
-// See GraphicBufferSource::calculateCodecTimestamp_l() for more detail about
-// how kTimestampFluctuation is used.
-//
-// kTimestampFluctuation should be non-negative. A higher value causes a smaller
-// chance of dropping frames, but at the same time a higher bound on the
-// difference between the source timestamp and the interpreted (snapped)
-// timestamp.
-//
-// The value of 0.05 means that GraphicBufferSource expects the input timestamps
-// to fluctuate no more than 5% from the regular time period.
-//
-// TODO: Justify the choice of this value, or make it configurable.
-constexpr double kTimestampFluctuation = 0.05;
-}
-
-/**
- * A copiable object managing a buffer in the buffer cache managed by the producer. This object
- * holds a reference to the buffer, and maintains which buffer slot it belongs to (if any), and
- * whether it is still in a buffer slot. It also maintains whether there are any outstanging acquire
- * references to it (by buffers acquired from the slot) mainly so that we can keep a debug
- * count of how many buffers we need to still release back to the producer.
- */
-struct GraphicBufferSource::CachedBuffer {
-    /**
-     * Token that is used to track acquire counts (as opposed to all references to this object).
-     */
-    struct Acquirable { };
-
-    /**
-     * Create using a buffer cached in a slot.
-     */
-    CachedBuffer(slot_id slot, const sp<GraphicBuffer> &graphicBuffer)
-        : mIsCached(true),
-          mSlot(slot),
-          mGraphicBuffer(graphicBuffer),
-          mAcquirable(std::make_shared<Acquirable>()) {
-    }
-
-    /**
-     * Returns the cache slot that this buffer is cached in, or -1 if it is no longer cached.
-     *
-     * This assumes that -1 slot id is invalid; though, it is just a benign collision used for
-     * debugging. This object explicitly manages whether it is still cached.
-     */
-    slot_id getSlot() const {
-        return mIsCached ? mSlot : -1;
-    }
-
-    /**
-     * Returns the cached buffer.
-     */
-    sp<GraphicBuffer> getGraphicBuffer() const {
-        return mGraphicBuffer;
-    }
-
-    /**
-     * Checks whether this buffer is still in the buffer cache.
-     */
-    bool isCached() const {
-        return mIsCached;
-    }
-
-    /**
-     * Checks whether this buffer has an acquired reference.
-     */
-    bool isAcquired() const {
-        return mAcquirable.use_count() > 1;
-    }
-
-    /**
-     * Gets and returns a shared acquired reference.
-     */
-    std::shared_ptr<Acquirable> getAcquirable() {
-        return mAcquirable;
-    }
-
-private:
-    friend void GraphicBufferSource::discardBufferAtSlotIndex_l(ssize_t);
-
-    /**
-     * This method to be called when the buffer is no longer in the buffer cache.
-     * Called from discardBufferAtSlotIndex_l.
-     */
-    void onDroppedFromCache() {
-        CHECK_DBG(mIsCached);
-        mIsCached = false;
-    }
-
-    bool mIsCached;
-    slot_id mSlot;
-    sp<GraphicBuffer> mGraphicBuffer;
-    std::shared_ptr<Acquirable> mAcquirable;
-};
-
-/**
- * A copiable object managing a buffer acquired from the producer. This must always be a cached
- * buffer. This objects also manages its acquire fence and any release fences that may be returned
- * by the encoder for this buffer (this buffer may be queued to the encoder multiple times).
- * If no release fences are added by the encoder, the acquire fence is returned as the release
- * fence for this - as it is assumed that noone waited for the acquire fence. Otherwise, it is
- * assumed that the encoder has waited for the acquire fence (or returned it as the release
- * fence).
- */
-struct GraphicBufferSource::AcquiredBuffer {
-    AcquiredBuffer(
-            const std::shared_ptr<CachedBuffer> &buffer,
-            std::function<void(AcquiredBuffer *)> onReleased,
-            const sp<Fence> &acquireFence)
-        : mBuffer(buffer),
-          mAcquirable(buffer->getAcquirable()),
-          mAcquireFence(acquireFence),
-          mGotReleaseFences(false),
-          mOnReleased(onReleased) {
-    }
-
-    /**
-     * Adds a release fence returned by the encoder to this object. If this is called with an
-     * valid file descriptor, it is added to the list of release fences. These are returned to the
-     * producer on release() as a merged fence. Regardless of the validity of the file descriptor,
-     * we take note that a release fence was attempted to be added and the acquire fence can now be
-     * assumed as acquired.
-     */
-    void addReleaseFenceFd(int fenceFd) {
-        // save all release fences - these will be propagated to the producer if this buffer is
-        // ever released to it
-        if (fenceFd >= 0) {
-            mReleaseFenceFds.push_back(fenceFd);
-        }
-        mGotReleaseFences = true;
-    }
-
-    /**
-     * Returns the acquire fence file descriptor associated with this object.
-     */
-    int getAcquireFenceFd() {
-        if (mAcquireFence == nullptr || !mAcquireFence->isValid()) {
-            return -1;
-        }
-        return mAcquireFence->dup();
-    }
-
-    /**
-     * Returns whether the buffer is still in the buffer cache.
-     */
-    bool isCached() const {
-        return mBuffer->isCached();
-    }
-
-    /**
-     * Returns the acquired buffer.
-     */
-    sp<GraphicBuffer> getGraphicBuffer() const {
-        return mBuffer->getGraphicBuffer();
-    }
-
-    /**
-     * Returns the slot that this buffer is cached at, or -1 otherwise.
-     *
-     * This assumes that -1 slot id is invalid; though, it is just a benign collision used for
-     * debugging. This object explicitly manages whether it is still cached.
-     */
-    slot_id getSlot() const {
-        return mBuffer->getSlot();
-    }
-
-    /**
-     * Creates and returns a release fence object from the acquire fence and/or any release fences
-     * added. If no release fences were added (even if invalid), returns the acquire fence.
-     * Otherwise, it returns a merged fence from all the valid release fences added.
-     */
-    sp<Fence> getReleaseFence() {
-        // If did not receive release fences, we assume this buffer was not consumed (it was
-        // discarded or dropped). In this case release the acquire fence as the release fence.
-        // We do this here to avoid a dup, close and recreation of the Fence object.
-        if (!mGotReleaseFences) {
-            return mAcquireFence;
-        }
-        sp<Fence> ret = getReleaseFence(0, mReleaseFenceFds.size());
-        // clear fds as fence took ownership of them
-        mReleaseFenceFds.clear();
-        return ret;
-    }
-
-    // this video buffer is no longer referenced by the codec (or kept for later encoding)
-    // it is now safe to release to the producer
-    ~AcquiredBuffer() {
-        //mAcquirable.clear();
-        mOnReleased(this);
-        // mOnRelease method should call getReleaseFence() that releases all fds but just in case
-        ALOGW_IF(!mReleaseFenceFds.empty(), "release fences were not obtained, closing fds");
-        for (int fildes : mReleaseFenceFds) {
-            ::close(fildes);
-            TRESPASS_DBG();
-        }
-    }
-
-private:
-    std::shared_ptr<GraphicBufferSource::CachedBuffer> mBuffer;
-    std::shared_ptr<GraphicBufferSource::CachedBuffer::Acquirable> mAcquirable;
-    sp<Fence> mAcquireFence;
-    Vector<int> mReleaseFenceFds;
-    bool mGotReleaseFences;
-    std::function<void(AcquiredBuffer *)> mOnReleased;
-
-    /**
-     * Creates and returns a release fence from 0 or more release fence file descriptors in from
-     * the specified range in the array.
-     *
-     * @param start start index
-     * @param num   number of release fds to merge
-     */
-    sp<Fence> getReleaseFence(size_t start, size_t num) const {
-        if (num == 0) {
-            return Fence::NO_FENCE;
-        } else if (num == 1) {
-            return new Fence(mReleaseFenceFds[start]);
-        } else {
-            return Fence::merge("GBS::AB",
-                                getReleaseFence(start, num >> 1),
-                                getReleaseFence(start + (num >> 1), num - (num >> 1)));
-        }
-    }
-};
-
-struct GraphicBufferSource::ConsumerProxy : public BufferQueue::ConsumerListener {
-    ConsumerProxy(const wp<GraphicBufferSource> &gbs) : mGbs(gbs) {}
-
-    ~ConsumerProxy() = default;
-
-    void onFrameAvailable(const BufferItem& item) override {
-        sp<GraphicBufferSource> gbs = mGbs.promote();
-        if (gbs != nullptr) {
-            gbs->onFrameAvailable(item);
-        }
-    }
-
-    void onBuffersReleased() override {
-        sp<GraphicBufferSource> gbs = mGbs.promote();
-        if (gbs != nullptr) {
-            gbs->onBuffersReleased();
-        }
-    }
-
-    void onSidebandStreamChanged() override {
-        sp<GraphicBufferSource> gbs = mGbs.promote();
-        if (gbs != nullptr) {
-            gbs->onSidebandStreamChanged();
-        }
-    }
-
-private:
-    // Note that GraphicBufferSource is holding an sp to us, we can't hold
-    // an sp back to GraphicBufferSource as the circular dependency will
-    // make both immortal.
-    wp<GraphicBufferSource> mGbs;
-};
-
-GraphicBufferSource::GraphicBufferSource() :
-    mInitCheck(UNKNOWN_ERROR),
-    mNumAvailableUnacquiredBuffers(0),
-    mNumOutstandingAcquires(0),
-    mEndOfStream(false),
-    mEndOfStreamSent(false),
-    mLastDataspace(HAL_DATASPACE_UNKNOWN),
-    mExecuting(false),
-    mSuspended(false),
-    mLastFrameTimestampUs(-1),
-    mStopTimeUs(-1),
-    mLastActionTimeUs(-1LL),
-    mSkipFramesBeforeNs(-1LL),
-    mFrameRepeatIntervalUs(-1LL),
-    mRepeatLastFrameGeneration(0),
-    mOutstandingFrameRepeatCount(0),
-    mFrameRepeatBlockedOnCodecBuffer(false),
-    mFps(-1.0),
-    mCaptureFps(-1.0),
-    mBaseCaptureUs(-1LL),
-    mBaseFrameUs(-1LL),
-    mFrameCount(0),
-    mPrevCaptureUs(-1LL),
-    mPrevFrameUs(-1LL),
-    mInputBufferTimeOffsetUs(0LL) {
-    ALOGV("GraphicBufferSource");
-
-    String8 name("GraphicBufferSource");
-
-    BufferQueue::createBufferQueue(&mProducer, &mConsumer);
-    mConsumer->setConsumerName(name);
-
-    // create the consumer listener interface, and hold sp so that this
-    // interface lives as long as the GraphicBufferSource.
-    mConsumerProxy = new ConsumerProxy(this);
-
-    sp<IConsumerListener> proxy =
-            new BufferQueue::ProxyConsumerListener(mConsumerProxy);
-
-    mInitCheck = mConsumer->consumerConnect(proxy, false);
-    if (mInitCheck != NO_ERROR) {
-        ALOGE("Error connecting to BufferQueue: %s (%d)",
-                strerror(-mInitCheck), mInitCheck);
-        return;
-    }
-
-    memset(&mDefaultColorAspectsPacked, 0, sizeof(mDefaultColorAspectsPacked));
-
-    CHECK(mInitCheck == NO_ERROR);
-}
-
-GraphicBufferSource::~GraphicBufferSource() {
-    ALOGV("~GraphicBufferSource");
-    {
-        // all acquired buffers must be freed with the mutex locked otherwise our debug assertion
-        // may trigger
-        Mutex::Autolock autoLock(mMutex);
-        mAvailableBuffers.clear();
-        mSubmittedCodecBuffers.clear();
-        mLatestBuffer.mBuffer.reset();
-    }
-
-    if (mNumOutstandingAcquires != 0) {
-        ALOGW("potential buffer leak: acquired=%d", mNumOutstandingAcquires);
-        TRESPASS_DBG();
-    }
-    if (mConsumer != NULL) {
-        status_t err = mConsumer->consumerDisconnect();
-        if (err != NO_ERROR) {
-            ALOGW("consumerDisconnect failed: %d", err);
-        }
-    }
-}
-
-sp<IGraphicBufferProducer> GraphicBufferSource::getIGraphicBufferProducer() const {
-    return mProducer;
-}
-
-sp<::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>
-GraphicBufferSource::getHGraphicBufferProducer_V1_0() const {
-    using TWGraphicBufferProducer = ::android::TWGraphicBufferProducer<
-        ::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>;
-
-    return new TWGraphicBufferProducer(getIGraphicBufferProducer());
-}
-
-sp<::android::hardware::graphics::bufferqueue::V2_0::IGraphicBufferProducer>
-GraphicBufferSource::getHGraphicBufferProducer() const {
-    return new ::android::hardware::graphics::bufferqueue::V2_0::utils::
-                    B2HGraphicBufferProducer(getIGraphicBufferProducer());
-}
-
-status_t GraphicBufferSource::start() {
-    Mutex::Autolock autoLock(mMutex);
-    ALOGV("--> start; available=%zu, submittable=%zd",
-            mAvailableBuffers.size(), mFreeCodecBuffers.size());
-    CHECK(!mExecuting);
-    mExecuting = true;
-    mLastDataspace = HAL_DATASPACE_UNKNOWN;
-    ALOGV("clearing last dataSpace");
-
-    // Start by loading up as many buffers as possible.  We want to do this,
-    // rather than just submit the first buffer, to avoid a degenerate case:
-    // if all BQ buffers arrive before we start executing, and we only submit
-    // one here, the other BQ buffers will just sit until we get notified
-    // that the codec buffer has been released.  We'd then acquire and
-    // submit a single additional buffer, repeatedly, never using more than
-    // one codec buffer simultaneously.  (We could instead try to submit
-    // all BQ buffers whenever any codec buffer is freed, but if we get the
-    // initial conditions right that will never be useful.)
-    while (haveAvailableBuffers_l()) {
-        if (!fillCodecBuffer_l()) {
-            ALOGV("stop load with available=%zu+%d",
-                    mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
-            break;
-        }
-    }
-
-    ALOGV("done loading initial frames, available=%zu+%d",
-            mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
-
-    // If EOS has already been signaled, and there are no more frames to
-    // submit, try to send EOS now as well.
-    if (mStopTimeUs == -1 && mEndOfStream && !haveAvailableBuffers_l()) {
-        submitEndOfInputStream_l();
-    }
-
-    if (mFrameRepeatIntervalUs > 0LL && mLooper == NULL) {
-        mReflector = new AHandlerReflector<GraphicBufferSource>(this);
-
-        mLooper = new ALooper;
-        mLooper->registerHandler(mReflector);
-        mLooper->start();
-
-        if (mLatestBuffer.mBuffer != nullptr) {
-            queueFrameRepeat_l();
-        }
-    }
-
-    return OK;
-}
-
-status_t GraphicBufferSource::stop() {
-    ALOGV("stop");
-
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mExecuting) {
-        // We are only interested in the transition from executing->idle,
-        // not loaded->idle.
-        mExecuting = false;
-    }
-    return OK;
-}
-
-status_t GraphicBufferSource::release(){
-    sp<ALooper> looper;
-    {
-        Mutex::Autolock autoLock(mMutex);
-        looper = mLooper;
-        if (mLooper != NULL) {
-            mLooper->unregisterHandler(mReflector->id());
-            mReflector.clear();
-
-            mLooper.clear();
-        }
-
-        ALOGV("--> release; available=%zu+%d eos=%d eosSent=%d acquired=%d",
-                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers,
-                mEndOfStream, mEndOfStreamSent, mNumOutstandingAcquires);
-
-        // Codec is no longer executing.  Releasing all buffers to bq.
-        mFreeCodecBuffers.clear();
-        mSubmittedCodecBuffers.clear();
-        mLatestBuffer.mBuffer.reset();
-        mComponent.clear();
-        mExecuting = false;
-    }
-    if (looper != NULL) {
-        looper->stop();
-    }
-    return OK;
-}
-
-status_t GraphicBufferSource::onInputBufferAdded(codec_buffer_id bufferId) {
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mExecuting) {
-        // This should never happen -- buffers can only be allocated when
-        // transitioning from "loaded" to "idle".
-        ALOGE("addCodecBuffer: buffer added while executing");
-        return INVALID_OPERATION;
-    }
-
-    ALOGV("addCodecBuffer: bufferId=%u", bufferId);
-
-    mFreeCodecBuffers.push_back(bufferId);
-    return OK;
-}
-
-status_t GraphicBufferSource::onInputBufferEmptied(codec_buffer_id bufferId, int fenceFd) {
-    Mutex::Autolock autoLock(mMutex);
-    FileDescriptor::Autoclose fence(fenceFd);
-
-    ssize_t cbi = mSubmittedCodecBuffers.indexOfKey(bufferId);
-    if (cbi < 0) {
-        // This should never happen.
-        ALOGE("onInputBufferEmptied: buffer not recognized (bufferId=%u)", bufferId);
-        return BAD_VALUE;
-    }
-
-    std::shared_ptr<AcquiredBuffer> buffer = mSubmittedCodecBuffers.valueAt(cbi);
-
-    // Move buffer to available buffers
-    mSubmittedCodecBuffers.removeItemsAt(cbi);
-    mFreeCodecBuffers.push_back(bufferId);
-
-    // header->nFilledLen may not be the original value, so we can't compare
-    // that to zero to see of this was the EOS buffer.  Instead we just
-    // see if there is a null AcquiredBuffer, which should only ever happen for EOS.
-    if (buffer == nullptr) {
-        if (!(mEndOfStream && mEndOfStreamSent)) {
-            // This can happen when broken code sends us the same buffer twice in a row.
-            ALOGE("onInputBufferEmptied: non-EOS null buffer (bufferId=%u)", bufferId);
-        } else {
-            ALOGV("onInputBufferEmptied: EOS null buffer (bufferId=%u@%zd)", bufferId, cbi);
-        }
-        // No GraphicBuffer to deal with, no additional input or output is expected, so just return.
-        return BAD_VALUE;
-    }
-
-    if (!mExecuting) {
-        // this is fine since this could happen when going from Idle to Loaded
-        ALOGV("onInputBufferEmptied: no longer executing (bufferId=%u@%zd)", bufferId, cbi);
-        return OK;
-    }
-
-    ALOGV("onInputBufferEmptied: bufferId=%d@%zd [slot=%d, useCount=%ld, handle=%p] acquired=%d",
-            bufferId, cbi, buffer->getSlot(), buffer.use_count(), buffer->getGraphicBuffer()->handle,
-            mNumOutstandingAcquires);
-
-    buffer->addReleaseFenceFd(fence.release());
-    // release codec reference for video buffer just in case remove does not it
-    buffer.reset();
-
-    if (haveAvailableBuffers_l()) {
-        // Fill this codec buffer.
-        CHECK(!mEndOfStreamSent);
-        ALOGV("onInputBufferEmptied: buffer freed, feeding codec (available=%zu+%d, eos=%d)",
-                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream);
-        fillCodecBuffer_l();
-    } else if (mEndOfStream && mStopTimeUs == -1) {
-        // No frames available, but EOS is pending and no stop time, so use this buffer to
-        // send that.
-        ALOGV("onInputBufferEmptied: buffer freed, submitting EOS");
-        submitEndOfInputStream_l();
-    } else if (mFrameRepeatBlockedOnCodecBuffer) {
-        bool success = repeatLatestBuffer_l();
-        ALOGV("onInputBufferEmptied: completing deferred repeatLatestBuffer_l %s",
-                success ? "SUCCESS" : "FAILURE");
-        mFrameRepeatBlockedOnCodecBuffer = false;
-    }
-
-    // releaseReleasableBuffers_l();
-    return OK;
-}
-
-void GraphicBufferSource::onDataspaceChanged_l(
-        android_dataspace dataspace, android_pixel_format pixelFormat) {
-    ALOGD("got buffer with new dataSpace %#x", dataspace);
-    mLastDataspace = dataspace;
-
-    if (ColorUtils::convertDataSpaceToV0(dataspace)) {
-        mComponent->dispatchDataSpaceChanged(
-                mLastDataspace, mDefaultColorAspectsPacked, pixelFormat);
-    }
-}
-
-bool GraphicBufferSource::fillCodecBuffer_l() {
-    CHECK(mExecuting && haveAvailableBuffers_l());
-
-    if (mFreeCodecBuffers.empty()) {
-        // No buffers available, bail.
-        ALOGV("fillCodecBuffer_l: no codec buffers, available=%zu+%d",
-                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
-        return false;
-    }
-
-    VideoBuffer item;
-    if (mAvailableBuffers.empty()) {
-        ALOGV("fillCodecBuffer_l: acquiring available buffer, available=%zu+%d",
-                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
-        if (acquireBuffer_l(&item) != OK) {
-            ALOGE("fillCodecBuffer_l: failed to acquire available buffer");
-            return false;
-        }
-    } else {
-        ALOGV("fillCodecBuffer_l: getting available buffer, available=%zu+%d",
-                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
-        item = *mAvailableBuffers.begin();
-        mAvailableBuffers.erase(mAvailableBuffers.begin());
-    }
-
-    int64_t itemTimeUs = item.mTimestampNs / 1000;
-
-    // Process ActionItem in the Queue if there is any. If a buffer's timestamp
-    // is smaller than the first action's timestamp, no action need to be performed.
-    // If buffer's timestamp is larger or equal than the last action's timestamp,
-    // only the last action needs to be performed as all the acitions before the
-    // the action are overridden by the last action. For the other cases, traverse
-    // the Queue to find the newest action that with timestamp smaller or equal to
-    // the buffer's timestamp. For example, an action queue like
-    // [pause 1us], [resume 2us], [pause 3us], [resume 4us], [pause 5us].... Upon
-    // receiving a buffer with timestamp 3.5us, only the action [pause, 3us] needs
-    // to be handled and [pause, 1us], [resume 2us] will be discarded.
-    bool done = false;
-    bool seeStopAction = false;
-    if (!mActionQueue.empty()) {
-        // First scan to check if bufferTimestamp is smaller than first action's timestamp.
-        ActionItem nextAction = *(mActionQueue.begin());
-        if (itemTimeUs < nextAction.mActionTimeUs) {
-            ALOGV("No action. buffer timestamp %lld us < action timestamp: %lld us",
-                (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
-            // All the actions are ahead. No action need to perform now.
-            // Release the buffer if is in suspended state, or process the buffer
-            // if not in suspended state.
-            done = true;
-        }
-
-        if (!done) {
-            // Find the newest action that with timestamp smaller than itemTimeUs. Then
-            // remove all the actions before and include the newest action.
-            List<ActionItem>::iterator it = mActionQueue.begin();
-            while (it != mActionQueue.end() && it->mActionTimeUs <= itemTimeUs
-                    && nextAction.mAction != ActionItem::STOP) {
-                nextAction = *it;
-                ++it;
-            }
-            mActionQueue.erase(mActionQueue.begin(), it);
-
-            CHECK(itemTimeUs >= nextAction.mActionTimeUs);
-            switch (nextAction.mAction) {
-                case ActionItem::PAUSE:
-                {
-                    mSuspended = true;
-                    ALOGV("RUNNING/PAUSE -> PAUSE at buffer %lld us  PAUSE Time: %lld us",
-                            (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
-                    break;
-                }
-                case ActionItem::RESUME:
-                {
-                    mSuspended = false;
-                    ALOGV("PAUSE/RUNNING -> RUNNING at buffer %lld us  RESUME Time: %lld us",
-                            (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
-                    break;
-                }
-                case ActionItem::STOP:
-                {
-                    ALOGV("RUNNING/PAUSE -> STOP at buffer %lld us  STOP Time: %lld us",
-                            (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
-                    // Clear the whole ActionQueue as recording is done
-                    mActionQueue.clear();
-                    seeStopAction = true;
-                    break;
-                }
-                default:
-                    TRESPASS_DBG("Unknown action type");
-                    // return true here because we did consume an available buffer, so the
-                    // loop in start will eventually terminate even if we hit this.
-                    return false;
-            }
-        }
-    }
-
-    if (seeStopAction) {
-        // Clear all the buffers before setting mEndOfStream and signal EndOfInputStream.
-        releaseAllAvailableBuffers_l();
-        mEndOfStream = true;
-        submitEndOfInputStream_l();
-        return true;
-    }
-
-    if (mSuspended) {
-        return true;
-    }
-
-    int err = UNKNOWN_ERROR;
-
-    // only submit sample if start time is unspecified, or sample
-    // is queued after the specified start time
-    if (mSkipFramesBeforeNs < 0LL || item.mTimestampNs >= mSkipFramesBeforeNs) {
-        // if start time is set, offset time stamp by start time
-        if (mSkipFramesBeforeNs > 0) {
-            item.mTimestampNs -= mSkipFramesBeforeNs;
-        }
-
-        int64_t timeUs = item.mTimestampNs / 1000;
-        if (mFrameDropper != NULL && mFrameDropper->shouldDrop(timeUs)) {
-            ALOGV("skipping frame (%lld) to meet max framerate", static_cast<long long>(timeUs));
-            // set err to OK so that the skipped frame can still be saved as the lastest frame
-            err = OK;
-        } else {
-            err = submitBuffer_l(item); // this takes shared ownership of the acquired buffer on succeess
-        }
-    }
-
-    if (err != OK) {
-        ALOGV("submitBuffer_l failed, will release bq slot %d", item.mBuffer->getSlot());
-        return true;
-    } else {
-        // Don't set the last buffer id if we're not repeating,
-        // we'll be holding on to the last buffer for nothing.
-        if (mFrameRepeatIntervalUs > 0LL) {
-            setLatestBuffer_l(item);
-        }
-        ALOGV("buffer submitted [slot=%d, useCount=%ld] acquired=%d",
-                item.mBuffer->getSlot(), item.mBuffer.use_count(), mNumOutstandingAcquires);
-        mLastFrameTimestampUs = itemTimeUs;
-    }
-
-    return true;
-}
-
-bool GraphicBufferSource::repeatLatestBuffer_l() {
-    CHECK(mExecuting && !haveAvailableBuffers_l());
-
-    if (mLatestBuffer.mBuffer == nullptr || mSuspended) {
-        return false;
-    }
-
-    if (mFreeCodecBuffers.empty()) {
-        // No buffers available, bail.
-        ALOGV("repeatLatestBuffer_l: no codec buffers.");
-        return false;
-    }
-
-    if (!mLatestBuffer.mBuffer->isCached()) {
-        ALOGV("repeatLatestBuffer_l: slot was discarded, but repeating our own reference");
-    }
-
-    // it is ok to update the timestamp of latest buffer as it is only used for submission
-    status_t err = submitBuffer_l(mLatestBuffer);
-    if (err != OK) {
-        return false;
-    }
-
-    /* repeat last frame up to kRepeatLastFrameCount times.
-     * in case of static scene, a single repeat might not get rid of encoder
-     * ghosting completely, refresh a couple more times to get better quality
-     */
-    if (--mOutstandingFrameRepeatCount > 0) {
-        // set up timestamp for repeat frame
-        mLatestBuffer.mTimestampNs += mFrameRepeatIntervalUs * 1000;
-        queueFrameRepeat_l();
-    }
-
-    return true;
-}
-
-void GraphicBufferSource::setLatestBuffer_l(const VideoBuffer &item) {
-    mLatestBuffer = item;
-
-    ALOGV("setLatestBuffer_l: [slot=%d, useCount=%ld]",
-            mLatestBuffer.mBuffer->getSlot(), mLatestBuffer.mBuffer.use_count());
-
-    mOutstandingFrameRepeatCount = kRepeatLastFrameCount;
-    // set up timestamp for repeat frame
-    mLatestBuffer.mTimestampNs += mFrameRepeatIntervalUs * 1000;
-    queueFrameRepeat_l();
-}
-
-void GraphicBufferSource::queueFrameRepeat_l() {
-    mFrameRepeatBlockedOnCodecBuffer = false;
-
-    if (mReflector != NULL) {
-        sp<AMessage> msg = new AMessage(kWhatRepeatLastFrame, mReflector);
-        msg->setInt32("generation", ++mRepeatLastFrameGeneration);
-        msg->post(mFrameRepeatIntervalUs);
-    }
-}
-
-#ifdef __clang__
-__attribute__((no_sanitize("integer")))
-#endif
-bool GraphicBufferSource::calculateCodecTimestamp_l(
-        nsecs_t bufferTimeNs, int64_t *codecTimeUs) {
-    int64_t timeUs = bufferTimeNs / 1000;
-    timeUs += mInputBufferTimeOffsetUs;
-
-    if (mCaptureFps > 0.
-            && (mFps > 2 * mCaptureFps
-            || mCaptureFps > 2 * mFps)) {
-        // Time lapse or slow motion mode
-        if (mPrevCaptureUs < 0LL) {
-            // first capture
-            mPrevCaptureUs = mBaseCaptureUs = timeUs;
-            // adjust the first sample timestamp.
-            mPrevFrameUs = mBaseFrameUs =
-                    std::llround((timeUs * mCaptureFps) / mFps);
-            mFrameCount = 0;
-        } else if (mSnapTimestamps) {
-            double nFrames = (timeUs - mPrevCaptureUs) * mCaptureFps / 1000000;
-            if (nFrames < 0.5 - kTimestampFluctuation) {
-                // skip this frame as it's too close to previous capture
-                ALOGD("skipping frame, timeUs %lld",
-                      static_cast<long long>(timeUs));
-                return false;
-            }
-            // snap to nearest capture point
-            if (nFrames <= 1.0) {
-                nFrames = 1.0;
-            }
-            mFrameCount += std::llround(nFrames);
-            mPrevCaptureUs = mBaseCaptureUs + std::llround(
-                    mFrameCount * 1000000 / mCaptureFps);
-            mPrevFrameUs = mBaseFrameUs + std::llround(
-                    mFrameCount * 1000000 / mFps);
-        } else {
-            if (timeUs <= mPrevCaptureUs) {
-                if (mFrameDropper != NULL && mFrameDropper->disabled()) {
-                    // Warn only, client has disabled frame drop logic possibly for image
-                    // encoding cases where camera's ZSL mode could send out of order frames.
-                    ALOGW("Received frame that's going backward in time");
-                } else {
-                    // Drop the frame if it's going backward in time. Bad timestamp
-                    // could disrupt encoder's rate control completely.
-                    ALOGW("Dropping frame that's going backward in time");
-                    return false;
-                }
-            }
-            mPrevCaptureUs = timeUs;
-            mPrevFrameUs = mBaseFrameUs + std::llround(
-                    (timeUs - mBaseCaptureUs) * (mCaptureFps / mFps));
-        }
-
-        ALOGV("timeUs %lld, captureUs %lld, frameUs %lld",
-                static_cast<long long>(timeUs),
-                static_cast<long long>(mPrevCaptureUs),
-                static_cast<long long>(mPrevFrameUs));
-    } else {
-        if (timeUs <= mPrevFrameUs) {
-            if (mFrameDropper != NULL && mFrameDropper->disabled()) {
-                // Warn only, client has disabled frame drop logic possibly for image
-                // encoding cases where camera's ZSL mode could send out of order frames.
-                ALOGW("Received frame that's going backward in time");
-            } else {
-                // Drop the frame if it's going backward in time. Bad timestamp
-                // could disrupt encoder's rate control completely.
-                ALOGW("Dropping frame that's going backward in time");
-                return false;
-            }
-        }
-
-        mPrevFrameUs = timeUs;
-    }
-
-    *codecTimeUs = mPrevFrameUs;
-    return true;
-}
-
-status_t GraphicBufferSource::submitBuffer_l(const VideoBuffer &item) {
-    CHECK(!mFreeCodecBuffers.empty());
-    uint32_t codecBufferId = *mFreeCodecBuffers.begin();
-
-    ALOGV("submitBuffer_l [slot=%d, bufferId=%d]", item.mBuffer->getSlot(), codecBufferId);
-
-    int64_t codecTimeUs;
-    if (!calculateCodecTimestamp_l(item.mTimestampNs, &codecTimeUs)) {
-        return UNKNOWN_ERROR;
-    }
-
-    if ((android_dataspace)item.mDataspace != mLastDataspace) {
-        onDataspaceChanged_l(
-                item.mDataspace,
-                (android_pixel_format)item.mBuffer->getGraphicBuffer()->format);
-    }
-
-    std::shared_ptr<AcquiredBuffer> buffer = item.mBuffer;
-    // use a GraphicBuffer for now as component is using GraphicBuffers to hold references
-    // and it requires this graphic buffer to be able to hold its reference
-    // and thus we would need to create a new GraphicBuffer from an ANWBuffer separate from the
-    // acquired GraphicBuffer.
-    // TODO: this can be reworked globally to use ANWBuffer references
-    sp<GraphicBuffer> graphicBuffer = buffer->getGraphicBuffer();
-    status_t err = mComponent->submitBuffer(
-            codecBufferId, graphicBuffer, codecTimeUs, buffer->getAcquireFenceFd());
-
-    if (err != OK) {
-        ALOGW("WARNING: emptyGraphicBuffer failed: 0x%x", err);
-        return err;
-    }
-
-    mFreeCodecBuffers.erase(mFreeCodecBuffers.begin());
-
-    ssize_t cbix = mSubmittedCodecBuffers.add(codecBufferId, buffer);
-    ALOGV("emptyGraphicBuffer succeeded, bufferId=%u@%zd bufhandle=%p",
-            codecBufferId, cbix, graphicBuffer->handle);
-    return OK;
-}
-
-void GraphicBufferSource::submitEndOfInputStream_l() {
-    CHECK(mEndOfStream);
-    if (mEndOfStreamSent) {
-        ALOGV("EOS already sent");
-        return;
-    }
-
-    if (mFreeCodecBuffers.empty()) {
-        ALOGV("submitEndOfInputStream_l: no codec buffers available");
-        return;
-    }
-    uint32_t codecBufferId = *mFreeCodecBuffers.begin();
-
-    // We reject any additional incoming graphic buffers. There is no acquired buffer used for EOS
-    status_t err = mComponent->submitEos(codecBufferId);
-    if (err != OK) {
-        ALOGW("emptyDirectBuffer EOS failed: 0x%x", err);
-    } else {
-        mFreeCodecBuffers.erase(mFreeCodecBuffers.begin());
-        ssize_t cbix = mSubmittedCodecBuffers.add(codecBufferId, nullptr);
-        ALOGV("submitEndOfInputStream_l: buffer submitted, bufferId=%u@%zd", codecBufferId, cbix);
-        mEndOfStreamSent = true;
-
-        // no need to hold onto any buffers for frame repeating
-        ++mRepeatLastFrameGeneration;
-        mLatestBuffer.mBuffer.reset();
-    }
-}
-
-status_t GraphicBufferSource::acquireBuffer_l(VideoBuffer *ab) {
-    BufferItem bi;
-    status_t err = mConsumer->acquireBuffer(&bi, 0);
-    if (err == BufferQueue::NO_BUFFER_AVAILABLE) {
-        // shouldn't happen
-        ALOGW("acquireBuffer_l: frame was not available");
-        return err;
-    } else if (err != OK) {
-        ALOGW("acquireBuffer_l: failed with err=%d", err);
-        return err;
-    }
-    --mNumAvailableUnacquiredBuffers;
-
-    // Manage our buffer cache.
-    std::shared_ptr<CachedBuffer> buffer;
-    ssize_t bsi = mBufferSlots.indexOfKey(bi.mSlot);
-    if (bi.mGraphicBuffer != NULL) {
-        // replace/initialize slot with new buffer
-        ALOGV("acquireBuffer_l: %s buffer slot %d", bsi < 0 ? "setting" : "UPDATING", bi.mSlot);
-        if (bsi >= 0) {
-            discardBufferAtSlotIndex_l(bsi);
-        } else {
-            bsi = mBufferSlots.add(bi.mSlot, nullptr);
-        }
-        buffer = std::make_shared<CachedBuffer>(bi.mSlot, bi.mGraphicBuffer);
-        mBufferSlots.replaceValueAt(bsi, buffer);
-    } else {
-        buffer = mBufferSlots.valueAt(bsi);
-    }
-    int64_t frameNum = bi.mFrameNumber;
-
-    std::shared_ptr<AcquiredBuffer> acquiredBuffer =
-        std::make_shared<AcquiredBuffer>(
-                buffer,
-                [frameNum, this](AcquiredBuffer *buffer){
-                    // AcquiredBuffer's destructor should always be called when mMutex is locked.
-                    // If we had a reentrant mutex, we could just lock it again to ensure this.
-                    if (mMutex.tryLock() == 0) {
-                        TRESPASS_DBG();
-                        mMutex.unlock();
-                    }
-
-                    // we can release buffers immediately if not using adapters
-                    // alternately, we could add them to mSlotsToRelease, but we would
-                    // somehow need to propagate frame number to that queue
-                    if (buffer->isCached()) {
-                        --mNumOutstandingAcquires;
-                        mConsumer->releaseBuffer(buffer->getSlot(), frameNum,
-                                                 buffer->getReleaseFence());
-                    }
-                },
-                bi.mFence);
-    VideoBuffer videoBuffer{acquiredBuffer, bi.mTimestamp, bi.mDataSpace};
-    *ab = videoBuffer;
-    ++mNumOutstandingAcquires;
-    return OK;
-}
-
-// BufferQueue::ConsumerListener callback
-void GraphicBufferSource::onFrameAvailable(const BufferItem& item __unused) {
-    Mutex::Autolock autoLock(mMutex);
-
-    ALOGV("onFrameAvailable: executing=%d available=%zu+%d",
-            mExecuting, mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
-    ++mNumAvailableUnacquiredBuffers;
-
-    // For BufferQueue we cannot acquire a buffer if we cannot immediately feed it to the codec
-    // UNLESS we are discarding this buffer (acquiring and immediately releasing it), which makes
-    // this an ugly logic.
-    // NOTE: We could also rely on our debug counter but that is meant only as a debug counter.
-    if (!areWeDiscardingAvailableBuffers_l() && mFreeCodecBuffers.empty()) {
-        // we may not be allowed to acquire a possibly encodable buffer, so just note that
-        // it is available
-        ALOGV("onFrameAvailable: cannot acquire buffer right now, do it later");
-
-        ++mRepeatLastFrameGeneration; // cancel any pending frame repeat
-        return;
-    }
-
-    VideoBuffer buffer;
-    status_t err = acquireBuffer_l(&buffer);
-    if (err != OK) {
-        ALOGE("onFrameAvailable: acquireBuffer returned err=%d", err);
-    } else {
-        onBufferAcquired_l(buffer);
-    }
-}
-
-bool GraphicBufferSource::areWeDiscardingAvailableBuffers_l() {
-    return mEndOfStreamSent // already sent EOS to codec
-            || mComponent == nullptr // there is no codec connected
-            || (mSuspended && mActionQueue.empty()) // we are suspended and not waiting for
-                                                    // any further action
-            || !mExecuting;
-}
-
-void GraphicBufferSource::onBufferAcquired_l(const VideoBuffer &buffer) {
-    if (mEndOfStreamSent) {
-        // This should only be possible if a new buffer was queued after
-        // EOS was signaled, i.e. the app is misbehaving.
-        ALOGW("onFrameAvailable: EOS is sent, ignoring frame");
-    } else if (mComponent == NULL || (mSuspended && mActionQueue.empty())) {
-        // FIXME: if we are suspended but have a resume queued we will stop repeating the last
-        // frame. Is that the desired behavior?
-        ALOGV("onFrameAvailable: suspended, ignoring frame");
-    } else {
-        ++mRepeatLastFrameGeneration; // cancel any pending frame repeat
-        mAvailableBuffers.push_back(buffer);
-        if (mExecuting) {
-            fillCodecBuffer_l();
-        }
-    }
-}
-
-// BufferQueue::ConsumerListener callback
-void GraphicBufferSource::onBuffersReleased() {
-    Mutex::Autolock lock(mMutex);
-
-    uint64_t slotMask;
-    uint64_t releaseMask;
-    if (mConsumer->getReleasedBuffers(&releaseMask) != NO_ERROR) {
-        slotMask = 0xffffffffffffffffULL;
-        ALOGW("onBuffersReleased: unable to get released buffer set");
-    } else {
-        slotMask = releaseMask;
-        ALOGV("onBuffersReleased: 0x%016" PRIx64, slotMask);
-    }
-
-    AString unpopulated;
-    for (int i = 0; i < BufferQueue::NUM_BUFFER_SLOTS; i++) {
-        if ((slotMask & 0x01) != 0) {
-            if (!discardBufferInSlot_l(i)) {
-                if (!unpopulated.empty()) {
-                    unpopulated.append(", ");
-                }
-                unpopulated.append(i);
-            }
-        }
-        slotMask >>= 1;
-    }
-    if (!unpopulated.empty()) {
-        ALOGW("released unpopulated slots: [%s]", unpopulated.c_str());
-    }
-}
-
-bool GraphicBufferSource::discardBufferInSlot_l(GraphicBufferSource::slot_id i) {
-    ssize_t bsi = mBufferSlots.indexOfKey(i);
-    if (bsi < 0) {
-        return false;
-    } else {
-        discardBufferAtSlotIndex_l(bsi);
-        mBufferSlots.removeItemsAt(bsi);
-        return true;
-    }
-}
-
-void GraphicBufferSource::discardBufferAtSlotIndex_l(ssize_t bsi) {
-    const std::shared_ptr<CachedBuffer>& buffer = mBufferSlots.valueAt(bsi);
-    // use -2 if there is no latest buffer, and -1 if it is no longer cached
-    slot_id latestBufferSlot =
-        mLatestBuffer.mBuffer == nullptr ? -2 : mLatestBuffer.mBuffer->getSlot();
-    ALOGV("releasing acquired buffer: [slot=%d, useCount=%ld], latest: [slot=%d]",
-            mBufferSlots.keyAt(bsi), buffer.use_count(), latestBufferSlot);
-    mBufferSlots.valueAt(bsi)->onDroppedFromCache();
-
-    // If the slot of an acquired buffer is discarded, that buffer will not have to be
-    // released to the producer, so account it here. However, it is possible that the
-    // acquired buffer has already been discarded so check if it still is.
-    if (buffer->isAcquired()) {
-        --mNumOutstandingAcquires;
-    }
-
-    // clear the buffer reference (not technically needed as caller either replaces or deletes
-    // it; done here for safety).
-    mBufferSlots.editValueAt(bsi).reset();
-    CHECK_DBG(buffer == nullptr);
-}
-
-void GraphicBufferSource::releaseAllAvailableBuffers_l() {
-    mAvailableBuffers.clear();
-    while (mNumAvailableUnacquiredBuffers > 0) {
-        VideoBuffer item;
-        if (acquireBuffer_l(&item) != OK) {
-            ALOGW("releaseAllAvailableBuffers: failed to acquire available unacquired buffer");
-            break;
-        }
-    }
-}
-
-// BufferQueue::ConsumerListener callback
-void GraphicBufferSource::onSidebandStreamChanged() {
-    ALOG_ASSERT(false, "GraphicBufferSource can't consume sideband streams");
-}
-
-status_t GraphicBufferSource::configure(
-        const sp<ComponentWrapper>& component,
-        int32_t dataSpace,
-        int32_t bufferCount,
-        uint32_t frameWidth,
-        uint32_t frameHeight,
-        uint32_t consumerUsage) {
-    uint64_t consumerUsage64 = static_cast<uint64_t>(consumerUsage);
-    return configure(component, dataSpace, bufferCount,
-                     frameWidth, frameHeight, consumerUsage64);
-}
-
-status_t GraphicBufferSource::configure(
-        const sp<ComponentWrapper>& component,
-        int32_t dataSpace,
-        int32_t bufferCount,
-        uint32_t frameWidth,
-        uint32_t frameHeight,
-        uint64_t consumerUsage) {
-    if (component == NULL) {
-        return BAD_VALUE;
-    }
-
-
-    // Call setMaxAcquiredBufferCount without lock.
-    // setMaxAcquiredBufferCount could call back to onBuffersReleased
-    // if the buffer count change results in releasing of existing buffers,
-    // which would lead to deadlock.
-    status_t err = mConsumer->setMaxAcquiredBufferCount(bufferCount);
-    if (err != NO_ERROR) {
-        ALOGE("Unable to set BQ max acquired buffer count to %u: %d",
-                bufferCount, err);
-        return err;
-    }
-
-    {
-        Mutex::Autolock autoLock(mMutex);
-        mComponent = component;
-
-        err = mConsumer->setDefaultBufferSize(frameWidth, frameHeight);
-        if (err != NO_ERROR) {
-            ALOGE("Unable to set BQ default buffer size to %ux%u: %d",
-                    frameWidth, frameHeight, err);
-            return err;
-        }
-
-        consumerUsage |= GRALLOC_USAGE_HW_VIDEO_ENCODER;
-        mConsumer->setConsumerUsageBits(consumerUsage);
-
-        // Set impl. defined format as default. Depending on the usage flags
-        // the device-specific implementation will derive the exact format.
-        err = mConsumer->setDefaultBufferFormat(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
-        if (err != NO_ERROR) {
-            ALOGE("Failed to configure surface default format ret: %d", err);
-            return err;
-        }
-
-        // Sets the default buffer data space
-        ALOGD("setting dataspace: %#x, acquired=%d", dataSpace, mNumOutstandingAcquires);
-        mConsumer->setDefaultBufferDataSpace((android_dataspace)dataSpace);
-        mLastDataspace = (android_dataspace)dataSpace;
-
-        mExecuting = false;
-        mSuspended = false;
-        mEndOfStream = false;
-        mEndOfStreamSent = false;
-        mSkipFramesBeforeNs = -1LL;
-        mFrameDropper.clear();
-        mFrameRepeatIntervalUs = -1LL;
-        mRepeatLastFrameGeneration = 0;
-        mOutstandingFrameRepeatCount = 0;
-        mLatestBuffer.mBuffer.reset();
-        mFrameRepeatBlockedOnCodecBuffer = false;
-        mFps = -1.0;
-        mCaptureFps = -1.0;
-        mBaseCaptureUs = -1LL;
-        mBaseFrameUs = -1LL;
-        mPrevCaptureUs = -1LL;
-        mPrevFrameUs = -1LL;
-        mFrameCount = 0;
-        mInputBufferTimeOffsetUs = 0;
-        mStopTimeUs = -1;
-        mActionQueue.clear();
-    }
-
-    return OK;
-}
-
-status_t GraphicBufferSource::setSuspend(bool suspend, int64_t suspendStartTimeUs) {
-    ALOGV("setSuspend=%d at time %lld us", suspend, (long long)suspendStartTimeUs);
-
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mStopTimeUs != -1) {
-        ALOGE("setSuspend failed as STOP action is pending");
-        return INVALID_OPERATION;
-    }
-
-    // Push the action to the queue.
-    if (suspendStartTimeUs != -1) {
-        // suspendStartTimeUs must be smaller or equal to current systemTime.
-        int64_t currentSystemTimeUs = systemTime() / 1000;
-        if (suspendStartTimeUs > currentSystemTimeUs) {
-            ALOGE("setSuspend failed. %lld is larger than current system time %lld us",
-                    (long long)suspendStartTimeUs, (long long)currentSystemTimeUs);
-            return INVALID_OPERATION;
-        }
-        if (mLastActionTimeUs != -1 && suspendStartTimeUs < mLastActionTimeUs) {
-            ALOGE("setSuspend failed. %lld is smaller than last action time %lld us",
-                    (long long)suspendStartTimeUs, (long long)mLastActionTimeUs);
-            return INVALID_OPERATION;
-        }
-        mLastActionTimeUs = suspendStartTimeUs;
-        ActionItem action;
-        action.mAction = suspend ? ActionItem::PAUSE : ActionItem::RESUME;
-        action.mActionTimeUs = suspendStartTimeUs;
-        ALOGV("Push %s action into actionQueue", suspend ? "PAUSE" : "RESUME");
-        mActionQueue.push_back(action);
-    } else {
-        if (suspend) {
-            mSuspended = true;
-            releaseAllAvailableBuffers_l();
-            return OK;
-        } else {
-            mSuspended = false;
-            if (mExecuting && !haveAvailableBuffers_l()
-                    && mFrameRepeatBlockedOnCodecBuffer) {
-                if (repeatLatestBuffer_l()) {
-                    ALOGV("suspend/deferred repeatLatestBuffer_l SUCCESS");
-                    mFrameRepeatBlockedOnCodecBuffer = false;
-                } else {
-                    ALOGV("suspend/deferred repeatLatestBuffer_l FAILURE");
-                }
-            }
-        }
-    }
-    return OK;
-}
-
-status_t GraphicBufferSource::setRepeatPreviousFrameDelayUs(int64_t repeatAfterUs) {
-    ALOGV("setRepeatPreviousFrameDelayUs: delayUs=%lld", (long long)repeatAfterUs);
-
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mExecuting || repeatAfterUs <= 0LL) {
-        return INVALID_OPERATION;
-    }
-
-    mFrameRepeatIntervalUs = repeatAfterUs;
-    return OK;
-}
-
-status_t GraphicBufferSource::setTimeOffsetUs(int64_t timeOffsetUs) {
-    Mutex::Autolock autoLock(mMutex);
-
-    // timeOffsetUs must be negative for adjustment.
-    if (timeOffsetUs >= 0LL) {
-        return INVALID_OPERATION;
-    }
-
-    mInputBufferTimeOffsetUs = timeOffsetUs;
-    return OK;
-}
-
-status_t GraphicBufferSource::setMaxFps(float maxFps) {
-    ALOGV("setMaxFps: maxFps=%lld", (long long)maxFps);
-
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mExecuting) {
-        return INVALID_OPERATION;
-    }
-
-    mFrameDropper = new FrameDropper();
-    status_t err = mFrameDropper->setMaxFrameRate(maxFps);
-    if (err != OK) {
-        mFrameDropper.clear();
-        return err;
-    }
-
-    return OK;
-}
-
-status_t GraphicBufferSource::setStartTimeUs(int64_t skipFramesBeforeUs) {
-    ALOGV("setStartTimeUs: skipFramesBeforeUs=%lld", (long long)skipFramesBeforeUs);
-
-    Mutex::Autolock autoLock(mMutex);
-
-    mSkipFramesBeforeNs =
-            (skipFramesBeforeUs > 0 && skipFramesBeforeUs <= INT64_MAX / 1000) ?
-            (skipFramesBeforeUs * 1000) : -1LL;
-
-    return OK;
-}
-
-status_t GraphicBufferSource::setStopTimeUs(int64_t stopTimeUs) {
-    ALOGV("setStopTimeUs: %lld us", (long long)stopTimeUs);
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mStopTimeUs != -1) {
-        // Ignore if stop time has already been set
-        return OK;
-    }
-
-    // stopTimeUs must be smaller or equal to current systemTime.
-    int64_t currentSystemTimeUs = systemTime() / 1000;
-    if (stopTimeUs > currentSystemTimeUs) {
-        ALOGE("setStopTimeUs failed. %lld is larger than current system time %lld us",
-            (long long)stopTimeUs, (long long)currentSystemTimeUs);
-        return INVALID_OPERATION;
-    }
-    if (mLastActionTimeUs != -1 && stopTimeUs < mLastActionTimeUs) {
-        ALOGE("setSuspend failed. %lld is smaller than last action time %lld us",
-            (long long)stopTimeUs, (long long)mLastActionTimeUs);
-        return INVALID_OPERATION;
-    }
-    mLastActionTimeUs = stopTimeUs;
-    ActionItem action;
-    action.mAction = ActionItem::STOP;
-    action.mActionTimeUs = stopTimeUs;
-    mActionQueue.push_back(action);
-    mStopTimeUs = stopTimeUs;
-    return OK;
-}
-
-status_t GraphicBufferSource::getStopTimeOffsetUs(int64_t *stopTimeOffsetUs) {
-    ALOGV("getStopTimeOffsetUs");
-    Mutex::Autolock autoLock(mMutex);
-    if (mStopTimeUs == -1) {
-        ALOGW("Fail to return stopTimeOffsetUs as stop time is not set");
-        return INVALID_OPERATION;
-    }
-    *stopTimeOffsetUs =
-        mLastFrameTimestampUs == -1 ? 0 : mStopTimeUs - mLastFrameTimestampUs;
-    return OK;
-}
-
-status_t GraphicBufferSource::setTimeLapseConfig(double fps, double captureFps) {
-    ALOGV("setTimeLapseConfig: fps=%lg, captureFps=%lg",
-            fps, captureFps);
-    Mutex::Autolock autoLock(mMutex);
-
-    if (mExecuting || !(fps > 0) || !(captureFps > 0)) {
-        return INVALID_OPERATION;
-    }
-
-    mFps = fps;
-    mCaptureFps = captureFps;
-    if (captureFps > fps) {
-        mSnapTimestamps = 1 == base::GetIntProperty(
-                "debug.stagefright.snap_timestamps", int64_t(0));
-    } else {
-        mSnapTimestamps = false;
-    }
-
-    return OK;
-}
-
-status_t GraphicBufferSource::setColorAspects(int32_t aspectsPacked) {
-    Mutex::Autolock autoLock(mMutex);
-    mDefaultColorAspectsPacked = aspectsPacked;
-    ColorAspects colorAspects = ColorUtils::unpackToColorAspects(aspectsPacked);
-    ALOGD("requesting color aspects (R:%d(%s), P:%d(%s), M:%d(%s), T:%d(%s))",
-            colorAspects.mRange, asString(colorAspects.mRange),
-            colorAspects.mPrimaries, asString(colorAspects.mPrimaries),
-            colorAspects.mMatrixCoeffs, asString(colorAspects.mMatrixCoeffs),
-            colorAspects.mTransfer, asString(colorAspects.mTransfer));
-
-    return OK;
-}
-
-status_t GraphicBufferSource::signalEndOfInputStream() {
-    Mutex::Autolock autoLock(mMutex);
-    ALOGV("signalEndOfInputStream: executing=%d available=%zu+%d eos=%d",
-            mExecuting, mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream);
-
-    if (mEndOfStream) {
-        ALOGE("EOS was already signaled");
-        return INVALID_OPERATION;
-    }
-
-    // Set the end-of-stream flag.  If no frames are pending from the
-    // BufferQueue, and a codec buffer is available, and we're executing,
-    // and there is no stop timestamp, we initiate the EOS from here.
-    // Otherwise, we'll let codecBufferEmptied() (or start) do it.
-    //
-    // Note: if there are no pending frames and all codec buffers are
-    // available, we *must* submit the EOS from here or we'll just
-    // stall since no future events are expected.
-    mEndOfStream = true;
-
-    if (mStopTimeUs == -1 && mExecuting && !haveAvailableBuffers_l()) {
-        submitEndOfInputStream_l();
-    }
-
-    return OK;
-}
-
-void GraphicBufferSource::onMessageReceived(const sp<AMessage> &msg) {
-    switch (msg->what()) {
-        case kWhatRepeatLastFrame:
-        {
-            Mutex::Autolock autoLock(mMutex);
-
-            int32_t generation;
-            CHECK(msg->findInt32("generation", &generation));
-
-            if (generation != mRepeatLastFrameGeneration) {
-                // stale
-                break;
-            }
-
-            if (!mExecuting || haveAvailableBuffers_l()) {
-                break;
-            }
-
-            bool success = repeatLatestBuffer_l();
-            if (success) {
-                ALOGV("repeatLatestBuffer_l SUCCESS");
-            } else {
-                ALOGV("repeatLatestBuffer_l FAILURE");
-                mFrameRepeatBlockedOnCodecBuffer = true;
-            }
-            break;
-        }
-
-        default:
-            TRESPASS();
-    }
-}
-
-}  // namespace android
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+ #include "flagged_files/GraphicBufferSource.inc"
+ #else
+ #include "flagged_files/DeprecatedGraphicBufferSource.inc"
+ #endif
diff --git a/media/module/bqhelper/flagged_files/DeprecatedGraphicBufferSource.inc b/media/module/bqhelper/flagged_files/DeprecatedGraphicBufferSource.inc
new file mode 100644
index 0000000000..8d4c8c513f
--- /dev/null
+++ b/media/module/bqhelper/flagged_files/DeprecatedGraphicBufferSource.inc
@@ -0,0 +1,1470 @@
+/*
+ * Copyright (C) 2013 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <inttypes.h>
+
+#define LOG_TAG "GraphicBufferSource"
+//#define LOG_NDEBUG 0
+#include <utils/Log.h>
+
+#define STRINGIFY_ENUMS // for asString in HardwareAPI.h/VideoAPI.h
+
+#include <media/stagefright/bqhelper/GraphicBufferSource.h>
+#include <media/stagefright/bqhelper/FrameDropper.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/foundation/ColorUtils.h>
+#include <media/stagefright/foundation/FileDescriptor.h>
+
+#include <android-base/properties.h>
+#include <media/hardware/MetadataBufferType.h>
+#include <ui/GraphicBuffer.h>
+#include <gui/BufferItem.h>
+#include <gui/BufferQueue.h>
+#include <gui/bufferqueue/1.0/WGraphicBufferProducer.h>
+#include <gui/IGraphicBufferProducer.h>
+#include <gui/IGraphicBufferConsumer.h>
+#include <media/hardware/HardwareAPI.h>
+
+#include <inttypes.h>
+
+#include <functional>
+#include <memory>
+#include <cmath>
+
+namespace android {
+
+namespace {
+// kTimestampFluctuation is an upper bound of timestamp fluctuation from the
+// source that GraphicBufferSource allows. The unit of kTimestampFluctuation is
+// frames. More specifically, GraphicBufferSource will drop a frame if
+//
+// expectedNewFrametimestamp - actualNewFrameTimestamp <
+//     (0.5 - kTimestampFluctuation) * expectedtimePeriodBetweenFrames
+//
+// where
+// - expectedNewFrameTimestamp is the calculated ideal timestamp of the new
+//   incoming frame
+// - actualNewFrameTimestamp is the timestamp received from the source
+// - expectedTimePeriodBetweenFrames is the ideal difference of the timestamps
+//   of two adjacent frames
+//
+// See GraphicBufferSource::calculateCodecTimestamp_l() for more detail about
+// how kTimestampFluctuation is used.
+//
+// kTimestampFluctuation should be non-negative. A higher value causes a smaller
+// chance of dropping frames, but at the same time a higher bound on the
+// difference between the source timestamp and the interpreted (snapped)
+// timestamp.
+//
+// The value of 0.05 means that GraphicBufferSource expects the input timestamps
+// to fluctuate no more than 5% from the regular time period.
+//
+// TODO: Justify the choice of this value, or make it configurable.
+constexpr double kTimestampFluctuation = 0.05;
+}
+
+/**
+ * A copiable object managing a buffer in the buffer cache managed by the producer. This object
+ * holds a reference to the buffer, and maintains which buffer slot it belongs to (if any), and
+ * whether it is still in a buffer slot. It also maintains whether there are any outstanging acquire
+ * references to it (by buffers acquired from the slot) mainly so that we can keep a debug
+ * count of how many buffers we need to still release back to the producer.
+ */
+struct GraphicBufferSource::CachedBuffer {
+    /**
+     * Token that is used to track acquire counts (as opposed to all references to this object).
+     */
+    struct Acquirable { };
+
+    /**
+     * Create using a buffer cached in a slot.
+     */
+    CachedBuffer(slot_id slot, const sp<GraphicBuffer> &graphicBuffer)
+        : mIsCached(true),
+          mSlot(slot),
+          mGraphicBuffer(graphicBuffer),
+          mAcquirable(std::make_shared<Acquirable>()) {
+    }
+
+    /**
+     * Returns the cache slot that this buffer is cached in, or -1 if it is no longer cached.
+     *
+     * This assumes that -1 slot id is invalid; though, it is just a benign collision used for
+     * debugging. This object explicitly manages whether it is still cached.
+     */
+    slot_id getSlot() const {
+        return mIsCached ? mSlot : -1;
+    }
+
+    /**
+     * Returns the cached buffer.
+     */
+    sp<GraphicBuffer> getGraphicBuffer() const {
+        return mGraphicBuffer;
+    }
+
+    /**
+     * Checks whether this buffer is still in the buffer cache.
+     */
+    bool isCached() const {
+        return mIsCached;
+    }
+
+    /**
+     * Checks whether this buffer has an acquired reference.
+     */
+    bool isAcquired() const {
+        return mAcquirable.use_count() > 1;
+    }
+
+    /**
+     * Gets and returns a shared acquired reference.
+     */
+    std::shared_ptr<Acquirable> getAcquirable() {
+        return mAcquirable;
+    }
+
+private:
+    friend void GraphicBufferSource::discardBufferAtSlotIndex_l(ssize_t);
+
+    /**
+     * This method to be called when the buffer is no longer in the buffer cache.
+     * Called from discardBufferAtSlotIndex_l.
+     */
+    void onDroppedFromCache() {
+        CHECK_DBG(mIsCached);
+        mIsCached = false;
+    }
+
+    bool mIsCached;
+    slot_id mSlot;
+    sp<GraphicBuffer> mGraphicBuffer;
+    std::shared_ptr<Acquirable> mAcquirable;
+};
+
+/**
+ * A copiable object managing a buffer acquired from the producer. This must always be a cached
+ * buffer. This objects also manages its acquire fence and any release fences that may be returned
+ * by the encoder for this buffer (this buffer may be queued to the encoder multiple times).
+ * If no release fences are added by the encoder, the acquire fence is returned as the release
+ * fence for this - as it is assumed that noone waited for the acquire fence. Otherwise, it is
+ * assumed that the encoder has waited for the acquire fence (or returned it as the release
+ * fence).
+ */
+struct GraphicBufferSource::AcquiredBuffer {
+    AcquiredBuffer(
+            const std::shared_ptr<CachedBuffer> &buffer,
+            std::function<void(AcquiredBuffer *)> onReleased,
+            const sp<Fence> &acquireFence)
+        : mBuffer(buffer),
+          mAcquirable(buffer->getAcquirable()),
+          mAcquireFence(acquireFence),
+          mGotReleaseFences(false),
+          mOnReleased(onReleased) {
+    }
+
+    /**
+     * Adds a release fence returned by the encoder to this object. If this is called with an
+     * valid file descriptor, it is added to the list of release fences. These are returned to the
+     * producer on release() as a merged fence. Regardless of the validity of the file descriptor,
+     * we take note that a release fence was attempted to be added and the acquire fence can now be
+     * assumed as acquired.
+     */
+    void addReleaseFenceFd(int fenceFd) {
+        // save all release fences - these will be propagated to the producer if this buffer is
+        // ever released to it
+        if (fenceFd >= 0) {
+            mReleaseFenceFds.push_back(fenceFd);
+        }
+        mGotReleaseFences = true;
+    }
+
+    /**
+     * Returns the acquire fence file descriptor associated with this object.
+     */
+    int getAcquireFenceFd() {
+        if (mAcquireFence == nullptr || !mAcquireFence->isValid()) {
+            return -1;
+        }
+        return mAcquireFence->dup();
+    }
+
+    /**
+     * Returns whether the buffer is still in the buffer cache.
+     */
+    bool isCached() const {
+        return mBuffer->isCached();
+    }
+
+    /**
+     * Returns the acquired buffer.
+     */
+    sp<GraphicBuffer> getGraphicBuffer() const {
+        return mBuffer->getGraphicBuffer();
+    }
+
+    /**
+     * Returns the slot that this buffer is cached at, or -1 otherwise.
+     *
+     * This assumes that -1 slot id is invalid; though, it is just a benign collision used for
+     * debugging. This object explicitly manages whether it is still cached.
+     */
+    slot_id getSlot() const {
+        return mBuffer->getSlot();
+    }
+
+    /**
+     * Creates and returns a release fence object from the acquire fence and/or any release fences
+     * added. If no release fences were added (even if invalid), returns the acquire fence.
+     * Otherwise, it returns a merged fence from all the valid release fences added.
+     */
+    sp<Fence> getReleaseFence() {
+        // If did not receive release fences, we assume this buffer was not consumed (it was
+        // discarded or dropped). In this case release the acquire fence as the release fence.
+        // We do this here to avoid a dup, close and recreation of the Fence object.
+        if (!mGotReleaseFences) {
+            return mAcquireFence;
+        }
+        sp<Fence> ret = getReleaseFence(0, mReleaseFenceFds.size());
+        // clear fds as fence took ownership of them
+        mReleaseFenceFds.clear();
+        return ret;
+    }
+
+    // this video buffer is no longer referenced by the codec (or kept for later encoding)
+    // it is now safe to release to the producer
+    ~AcquiredBuffer() {
+        //mAcquirable.clear();
+        mOnReleased(this);
+        // mOnRelease method should call getReleaseFence() that releases all fds but just in case
+        ALOGW_IF(!mReleaseFenceFds.empty(), "release fences were not obtained, closing fds");
+        for (int fildes : mReleaseFenceFds) {
+            ::close(fildes);
+            TRESPASS_DBG();
+        }
+    }
+
+private:
+    std::shared_ptr<GraphicBufferSource::CachedBuffer> mBuffer;
+    std::shared_ptr<GraphicBufferSource::CachedBuffer::Acquirable> mAcquirable;
+    sp<Fence> mAcquireFence;
+    Vector<int> mReleaseFenceFds;
+    bool mGotReleaseFences;
+    std::function<void(AcquiredBuffer *)> mOnReleased;
+
+    /**
+     * Creates and returns a release fence from 0 or more release fence file descriptors in from
+     * the specified range in the array.
+     *
+     * @param start start index
+     * @param num   number of release fds to merge
+     */
+    sp<Fence> getReleaseFence(size_t start, size_t num) const {
+        if (num == 0) {
+            return Fence::NO_FENCE;
+        } else if (num == 1) {
+            return new Fence(mReleaseFenceFds[start]);
+        } else {
+            return Fence::merge("GBS::AB",
+                                getReleaseFence(start, num >> 1),
+                                getReleaseFence(start + (num >> 1), num - (num >> 1)));
+        }
+    }
+};
+
+struct GraphicBufferSource::ConsumerProxy : public BufferQueue::ConsumerListener {
+    ConsumerProxy(const wp<GraphicBufferSource> &gbs) : mGbs(gbs) {}
+
+    ~ConsumerProxy() = default;
+
+    void onFrameAvailable(const BufferItem& item) override {
+        sp<GraphicBufferSource> gbs = mGbs.promote();
+        if (gbs != nullptr) {
+            gbs->onFrameAvailable(item);
+        }
+    }
+
+    void onBuffersReleased() override {
+        sp<GraphicBufferSource> gbs = mGbs.promote();
+        if (gbs != nullptr) {
+            gbs->onBuffersReleased();
+        }
+    }
+
+    void onSidebandStreamChanged() override {
+        sp<GraphicBufferSource> gbs = mGbs.promote();
+        if (gbs != nullptr) {
+            gbs->onSidebandStreamChanged();
+        }
+    }
+
+private:
+    // Note that GraphicBufferSource is holding an sp to us, we can't hold
+    // an sp back to GraphicBufferSource as the circular dependency will
+    // make both immortal.
+    wp<GraphicBufferSource> mGbs;
+};
+
+GraphicBufferSource::GraphicBufferSource() :
+    mInitCheck(UNKNOWN_ERROR),
+    mNumAvailableUnacquiredBuffers(0),
+    mNumOutstandingAcquires(0),
+    mEndOfStream(false),
+    mEndOfStreamSent(false),
+    mLastDataspace(HAL_DATASPACE_UNKNOWN),
+    mExecuting(false),
+    mSuspended(false),
+    mLastFrameTimestampUs(-1),
+    mStopTimeUs(-1),
+    mLastActionTimeUs(-1LL),
+    mSkipFramesBeforeNs(-1LL),
+    mFrameRepeatIntervalUs(-1LL),
+    mRepeatLastFrameGeneration(0),
+    mOutstandingFrameRepeatCount(0),
+    mFrameRepeatBlockedOnCodecBuffer(false),
+    mFps(-1.0),
+    mCaptureFps(-1.0),
+    mBaseCaptureUs(-1LL),
+    mBaseFrameUs(-1LL),
+    mFrameCount(0),
+    mPrevCaptureUs(-1LL),
+    mPrevFrameUs(-1LL),
+    mInputBufferTimeOffsetUs(0LL) {
+    ALOGV("GraphicBufferSource");
+
+    String8 name("GraphicBufferSource");
+
+    BufferQueue::createBufferQueue(&mProducer, &mConsumer);
+    mConsumer->setConsumerName(name);
+
+    // create the consumer listener interface, and hold sp so that this
+    // interface lives as long as the GraphicBufferSource.
+    mConsumerProxy = new ConsumerProxy(this);
+
+    sp<IConsumerListener> proxy =
+            new BufferQueue::ProxyConsumerListener(mConsumerProxy);
+
+    mInitCheck = mConsumer->consumerConnect(proxy, false);
+    if (mInitCheck != NO_ERROR) {
+        ALOGE("Error connecting to BufferQueue: %s (%d)",
+                strerror(-mInitCheck), mInitCheck);
+        return;
+    }
+
+    memset(&mDefaultColorAspectsPacked, 0, sizeof(mDefaultColorAspectsPacked));
+
+    CHECK(mInitCheck == NO_ERROR);
+}
+
+GraphicBufferSource::~GraphicBufferSource() {
+    ALOGV("~GraphicBufferSource");
+    {
+        // all acquired buffers must be freed with the mutex locked otherwise our debug assertion
+        // may trigger
+        Mutex::Autolock autoLock(mMutex);
+        mAvailableBuffers.clear();
+        mSubmittedCodecBuffers.clear();
+        mLatestBuffer.mBuffer.reset();
+    }
+
+    if (mNumOutstandingAcquires != 0) {
+        ALOGW("potential buffer leak: acquired=%d", mNumOutstandingAcquires);
+        TRESPASS_DBG();
+    }
+    if (mConsumer != NULL) {
+        status_t err = mConsumer->consumerDisconnect();
+        if (err != NO_ERROR) {
+            ALOGW("consumerDisconnect failed: %d", err);
+        }
+    }
+}
+
+sp<IGraphicBufferProducer> GraphicBufferSource::getIGraphicBufferProducer() const {
+    return mProducer;
+}
+
+sp<::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>
+GraphicBufferSource::getHGraphicBufferProducer_V1_0() const {
+    using TWGraphicBufferProducer = ::android::TWGraphicBufferProducer<
+        ::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>;
+
+    return new TWGraphicBufferProducer(getIGraphicBufferProducer());
+}
+
+status_t GraphicBufferSource::start() {
+    Mutex::Autolock autoLock(mMutex);
+    ALOGV("--> start; available=%zu, submittable=%zd",
+            mAvailableBuffers.size(), mFreeCodecBuffers.size());
+    CHECK(!mExecuting);
+    mExecuting = true;
+    mLastDataspace = HAL_DATASPACE_UNKNOWN;
+    ALOGV("clearing last dataSpace");
+
+    // Start by loading up as many buffers as possible.  We want to do this,
+    // rather than just submit the first buffer, to avoid a degenerate case:
+    // if all BQ buffers arrive before we start executing, and we only submit
+    // one here, the other BQ buffers will just sit until we get notified
+    // that the codec buffer has been released.  We'd then acquire and
+    // submit a single additional buffer, repeatedly, never using more than
+    // one codec buffer simultaneously.  (We could instead try to submit
+    // all BQ buffers whenever any codec buffer is freed, but if we get the
+    // initial conditions right that will never be useful.)
+    while (haveAvailableBuffers_l()) {
+        if (!fillCodecBuffer_l()) {
+            ALOGV("stop load with available=%zu+%d",
+                    mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+            break;
+        }
+    }
+
+    ALOGV("done loading initial frames, available=%zu+%d",
+            mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+
+    // If EOS has already been signaled, and there are no more frames to
+    // submit, try to send EOS now as well.
+    if (mStopTimeUs == -1 && mEndOfStream && !haveAvailableBuffers_l()) {
+        submitEndOfInputStream_l();
+    }
+
+    if (mFrameRepeatIntervalUs > 0LL && mLooper == NULL) {
+        mReflector = new AHandlerReflector<GraphicBufferSource>(this);
+
+        mLooper = new ALooper;
+        mLooper->registerHandler(mReflector);
+        mLooper->start();
+
+        if (mLatestBuffer.mBuffer != nullptr) {
+            queueFrameRepeat_l();
+        }
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::stop() {
+    ALOGV("stop");
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting) {
+        // We are only interested in the transition from executing->idle,
+        // not loaded->idle.
+        mExecuting = false;
+    }
+    return OK;
+}
+
+status_t GraphicBufferSource::release(){
+    sp<ALooper> looper;
+    {
+        Mutex::Autolock autoLock(mMutex);
+        looper = mLooper;
+        if (mLooper != NULL) {
+            mLooper->unregisterHandler(mReflector->id());
+            mReflector.clear();
+
+            mLooper.clear();
+        }
+
+        ALOGV("--> release; available=%zu+%d eos=%d eosSent=%d acquired=%d",
+                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers,
+                mEndOfStream, mEndOfStreamSent, mNumOutstandingAcquires);
+
+        // Codec is no longer executing.  Releasing all buffers to bq.
+        mFreeCodecBuffers.clear();
+        mSubmittedCodecBuffers.clear();
+        mLatestBuffer.mBuffer.reset();
+        mComponent.clear();
+        mExecuting = false;
+    }
+    if (looper != NULL) {
+        looper->stop();
+    }
+    return OK;
+}
+
+status_t GraphicBufferSource::onInputBufferAdded(codec_buffer_id bufferId) {
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting) {
+        // This should never happen -- buffers can only be allocated when
+        // transitioning from "loaded" to "idle".
+        ALOGE("addCodecBuffer: buffer added while executing");
+        return INVALID_OPERATION;
+    }
+
+    ALOGV("addCodecBuffer: bufferId=%u", bufferId);
+
+    mFreeCodecBuffers.push_back(bufferId);
+    return OK;
+}
+
+status_t GraphicBufferSource::onInputBufferEmptied(codec_buffer_id bufferId, int fenceFd) {
+    Mutex::Autolock autoLock(mMutex);
+    FileDescriptor::Autoclose fence(fenceFd);
+
+    ssize_t cbi = mSubmittedCodecBuffers.indexOfKey(bufferId);
+    if (cbi < 0) {
+        // This should never happen.
+        ALOGE("onInputBufferEmptied: buffer not recognized (bufferId=%u)", bufferId);
+        return BAD_VALUE;
+    }
+
+    std::shared_ptr<AcquiredBuffer> buffer = mSubmittedCodecBuffers.valueAt(cbi);
+
+    // Move buffer to available buffers
+    mSubmittedCodecBuffers.removeItemsAt(cbi);
+    mFreeCodecBuffers.push_back(bufferId);
+
+    // header->nFilledLen may not be the original value, so we can't compare
+    // that to zero to see of this was the EOS buffer.  Instead we just
+    // see if there is a null AcquiredBuffer, which should only ever happen for EOS.
+    if (buffer == nullptr) {
+        if (!(mEndOfStream && mEndOfStreamSent)) {
+            // This can happen when broken code sends us the same buffer twice in a row.
+            ALOGE("onInputBufferEmptied: non-EOS null buffer (bufferId=%u)", bufferId);
+        } else {
+            ALOGV("onInputBufferEmptied: EOS null buffer (bufferId=%u@%zd)", bufferId, cbi);
+        }
+        // No GraphicBuffer to deal with, no additional input or output is expected, so just return.
+        return BAD_VALUE;
+    }
+
+    if (!mExecuting) {
+        // this is fine since this could happen when going from Idle to Loaded
+        ALOGV("onInputBufferEmptied: no longer executing (bufferId=%u@%zd)", bufferId, cbi);
+        return OK;
+    }
+
+    ALOGV("onInputBufferEmptied: bufferId=%d@%zd [slot=%d, useCount=%ld, handle=%p] acquired=%d",
+            bufferId, cbi, buffer->getSlot(), buffer.use_count(), buffer->getGraphicBuffer()->handle,
+            mNumOutstandingAcquires);
+
+    buffer->addReleaseFenceFd(fence.release());
+    // release codec reference for video buffer just in case remove does not it
+    buffer.reset();
+
+    if (haveAvailableBuffers_l()) {
+        // Fill this codec buffer.
+        CHECK(!mEndOfStreamSent);
+        ALOGV("onInputBufferEmptied: buffer freed, feeding codec (available=%zu+%d, eos=%d)",
+                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream);
+        fillCodecBuffer_l();
+    } else if (mEndOfStream && mStopTimeUs == -1) {
+        // No frames available, but EOS is pending and no stop time, so use this buffer to
+        // send that.
+        ALOGV("onInputBufferEmptied: buffer freed, submitting EOS");
+        submitEndOfInputStream_l();
+    } else if (mFrameRepeatBlockedOnCodecBuffer) {
+        bool success = repeatLatestBuffer_l();
+        ALOGV("onInputBufferEmptied: completing deferred repeatLatestBuffer_l %s",
+                success ? "SUCCESS" : "FAILURE");
+        mFrameRepeatBlockedOnCodecBuffer = false;
+    }
+
+    // releaseReleasableBuffers_l();
+    return OK;
+}
+
+void GraphicBufferSource::onDataspaceChanged_l(
+        android_dataspace dataspace, android_pixel_format pixelFormat) {
+    ALOGD("got buffer with new dataSpace %#x", dataspace);
+    mLastDataspace = dataspace;
+
+    if (ColorUtils::convertDataSpaceToV0(dataspace)) {
+        mComponent->dispatchDataSpaceChanged(
+                mLastDataspace, mDefaultColorAspectsPacked, pixelFormat);
+    }
+}
+
+bool GraphicBufferSource::fillCodecBuffer_l() {
+    CHECK(mExecuting && haveAvailableBuffers_l());
+
+    if (mFreeCodecBuffers.empty()) {
+        // No buffers available, bail.
+        ALOGV("fillCodecBuffer_l: no codec buffers, available=%zu+%d",
+                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+        return false;
+    }
+
+    VideoBuffer item;
+    if (mAvailableBuffers.empty()) {
+        ALOGV("fillCodecBuffer_l: acquiring available buffer, available=%zu+%d",
+                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+        if (acquireBuffer_l(&item) != OK) {
+            ALOGE("fillCodecBuffer_l: failed to acquire available buffer");
+            return false;
+        }
+    } else {
+        ALOGV("fillCodecBuffer_l: getting available buffer, available=%zu+%d",
+                mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+        item = *mAvailableBuffers.begin();
+        mAvailableBuffers.erase(mAvailableBuffers.begin());
+    }
+
+    int64_t itemTimeUs = item.mTimestampNs / 1000;
+
+    // Process ActionItem in the Queue if there is any. If a buffer's timestamp
+    // is smaller than the first action's timestamp, no action need to be performed.
+    // If buffer's timestamp is larger or equal than the last action's timestamp,
+    // only the last action needs to be performed as all the acitions before the
+    // the action are overridden by the last action. For the other cases, traverse
+    // the Queue to find the newest action that with timestamp smaller or equal to
+    // the buffer's timestamp. For example, an action queue like
+    // [pause 1us], [resume 2us], [pause 3us], [resume 4us], [pause 5us].... Upon
+    // receiving a buffer with timestamp 3.5us, only the action [pause, 3us] needs
+    // to be handled and [pause, 1us], [resume 2us] will be discarded.
+    bool done = false;
+    bool seeStopAction = false;
+    if (!mActionQueue.empty()) {
+        // First scan to check if bufferTimestamp is smaller than first action's timestamp.
+        ActionItem nextAction = *(mActionQueue.begin());
+        if (itemTimeUs < nextAction.mActionTimeUs) {
+            ALOGV("No action. buffer timestamp %lld us < action timestamp: %lld us",
+                (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+            // All the actions are ahead. No action need to perform now.
+            // Release the buffer if is in suspended state, or process the buffer
+            // if not in suspended state.
+            done = true;
+        }
+
+        if (!done) {
+            // Find the newest action that with timestamp smaller than itemTimeUs. Then
+            // remove all the actions before and include the newest action.
+            List<ActionItem>::iterator it = mActionQueue.begin();
+            while (it != mActionQueue.end() && it->mActionTimeUs <= itemTimeUs
+                    && nextAction.mAction != ActionItem::STOP) {
+                nextAction = *it;
+                ++it;
+            }
+            mActionQueue.erase(mActionQueue.begin(), it);
+
+            CHECK(itemTimeUs >= nextAction.mActionTimeUs);
+            switch (nextAction.mAction) {
+                case ActionItem::PAUSE:
+                {
+                    mSuspended = true;
+                    ALOGV("RUNNING/PAUSE -> PAUSE at buffer %lld us  PAUSE Time: %lld us",
+                            (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+                    break;
+                }
+                case ActionItem::RESUME:
+                {
+                    mSuspended = false;
+                    ALOGV("PAUSE/RUNNING -> RUNNING at buffer %lld us  RESUME Time: %lld us",
+                            (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+                    break;
+                }
+                case ActionItem::STOP:
+                {
+                    ALOGV("RUNNING/PAUSE -> STOP at buffer %lld us  STOP Time: %lld us",
+                            (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+                    // Clear the whole ActionQueue as recording is done
+                    mActionQueue.clear();
+                    seeStopAction = true;
+                    break;
+                }
+                default:
+                    TRESPASS_DBG("Unknown action type");
+                    // return true here because we did consume an available buffer, so the
+                    // loop in start will eventually terminate even if we hit this.
+                    return false;
+            }
+        }
+    }
+
+    if (seeStopAction) {
+        // Clear all the buffers before setting mEndOfStream and signal EndOfInputStream.
+        releaseAllAvailableBuffers_l();
+        mEndOfStream = true;
+        submitEndOfInputStream_l();
+        return true;
+    }
+
+    if (mSuspended) {
+        return true;
+    }
+
+    int err = UNKNOWN_ERROR;
+
+    // only submit sample if start time is unspecified, or sample
+    // is queued after the specified start time
+    if (mSkipFramesBeforeNs < 0LL || item.mTimestampNs >= mSkipFramesBeforeNs) {
+        // if start time is set, offset time stamp by start time
+        if (mSkipFramesBeforeNs > 0) {
+            item.mTimestampNs -= mSkipFramesBeforeNs;
+        }
+
+        int64_t timeUs = item.mTimestampNs / 1000;
+        if (mFrameDropper != NULL && mFrameDropper->shouldDrop(timeUs)) {
+            ALOGV("skipping frame (%lld) to meet max framerate", static_cast<long long>(timeUs));
+            // set err to OK so that the skipped frame can still be saved as the lastest frame
+            err = OK;
+        } else {
+            err = submitBuffer_l(item); // this takes shared ownership of the acquired buffer on succeess
+        }
+    }
+
+    if (err != OK) {
+        ALOGV("submitBuffer_l failed, will release bq slot %d", item.mBuffer->getSlot());
+        return true;
+    } else {
+        // Don't set the last buffer id if we're not repeating,
+        // we'll be holding on to the last buffer for nothing.
+        if (mFrameRepeatIntervalUs > 0LL) {
+            setLatestBuffer_l(item);
+        }
+        ALOGV("buffer submitted [slot=%d, useCount=%ld] acquired=%d",
+                item.mBuffer->getSlot(), item.mBuffer.use_count(), mNumOutstandingAcquires);
+        mLastFrameTimestampUs = itemTimeUs;
+    }
+
+    return true;
+}
+
+bool GraphicBufferSource::repeatLatestBuffer_l() {
+    CHECK(mExecuting && !haveAvailableBuffers_l());
+
+    if (mLatestBuffer.mBuffer == nullptr || mSuspended) {
+        return false;
+    }
+
+    if (mFreeCodecBuffers.empty()) {
+        // No buffers available, bail.
+        ALOGV("repeatLatestBuffer_l: no codec buffers.");
+        return false;
+    }
+
+    if (!mLatestBuffer.mBuffer->isCached()) {
+        ALOGV("repeatLatestBuffer_l: slot was discarded, but repeating our own reference");
+    }
+
+    // it is ok to update the timestamp of latest buffer as it is only used for submission
+    status_t err = submitBuffer_l(mLatestBuffer);
+    if (err != OK) {
+        return false;
+    }
+
+    /* repeat last frame up to kRepeatLastFrameCount times.
+     * in case of static scene, a single repeat might not get rid of encoder
+     * ghosting completely, refresh a couple more times to get better quality
+     */
+    if (--mOutstandingFrameRepeatCount > 0) {
+        // set up timestamp for repeat frame
+        mLatestBuffer.mTimestampNs += mFrameRepeatIntervalUs * 1000;
+        queueFrameRepeat_l();
+    }
+
+    return true;
+}
+
+void GraphicBufferSource::setLatestBuffer_l(const VideoBuffer &item) {
+    mLatestBuffer = item;
+
+    ALOGV("setLatestBuffer_l: [slot=%d, useCount=%ld]",
+            mLatestBuffer.mBuffer->getSlot(), mLatestBuffer.mBuffer.use_count());
+
+    mOutstandingFrameRepeatCount = kRepeatLastFrameCount;
+    // set up timestamp for repeat frame
+    mLatestBuffer.mTimestampNs += mFrameRepeatIntervalUs * 1000;
+    queueFrameRepeat_l();
+}
+
+void GraphicBufferSource::queueFrameRepeat_l() {
+    mFrameRepeatBlockedOnCodecBuffer = false;
+
+    if (mReflector != NULL) {
+        sp<AMessage> msg = new AMessage(kWhatRepeatLastFrame, mReflector);
+        msg->setInt32("generation", ++mRepeatLastFrameGeneration);
+        msg->post(mFrameRepeatIntervalUs);
+    }
+}
+
+#ifdef __clang__
+__attribute__((no_sanitize("integer")))
+#endif
+bool GraphicBufferSource::calculateCodecTimestamp_l(
+        nsecs_t bufferTimeNs, int64_t *codecTimeUs) {
+    int64_t timeUs = bufferTimeNs / 1000;
+    timeUs += mInputBufferTimeOffsetUs;
+
+    if (mCaptureFps > 0.
+            && (mFps > 2 * mCaptureFps
+            || mCaptureFps > 2 * mFps)) {
+        // Time lapse or slow motion mode
+        if (mPrevCaptureUs < 0LL) {
+            // first capture
+            mPrevCaptureUs = mBaseCaptureUs = timeUs;
+            // adjust the first sample timestamp.
+            mPrevFrameUs = mBaseFrameUs =
+                    std::llround((timeUs * mCaptureFps) / mFps);
+            mFrameCount = 0;
+        } else if (mSnapTimestamps) {
+            double nFrames = (timeUs - mPrevCaptureUs) * mCaptureFps / 1000000;
+            if (nFrames < 0.5 - kTimestampFluctuation) {
+                // skip this frame as it's too close to previous capture
+                ALOGD("skipping frame, timeUs %lld",
+                      static_cast<long long>(timeUs));
+                return false;
+            }
+            // snap to nearest capture point
+            if (nFrames <= 1.0) {
+                nFrames = 1.0;
+            }
+            mFrameCount += std::llround(nFrames);
+            mPrevCaptureUs = mBaseCaptureUs + std::llround(
+                    mFrameCount * 1000000 / mCaptureFps);
+            mPrevFrameUs = mBaseFrameUs + std::llround(
+                    mFrameCount * 1000000 / mFps);
+        } else {
+            if (timeUs <= mPrevCaptureUs) {
+                if (mFrameDropper != NULL && mFrameDropper->disabled()) {
+                    // Warn only, client has disabled frame drop logic possibly for image
+                    // encoding cases where camera's ZSL mode could send out of order frames.
+                    ALOGW("Received frame that's going backward in time");
+                } else {
+                    // Drop the frame if it's going backward in time. Bad timestamp
+                    // could disrupt encoder's rate control completely.
+                    ALOGW("Dropping frame that's going backward in time");
+                    return false;
+                }
+            }
+            mPrevCaptureUs = timeUs;
+            mPrevFrameUs = mBaseFrameUs + std::llround(
+                    (timeUs - mBaseCaptureUs) * (mCaptureFps / mFps));
+        }
+
+        ALOGV("timeUs %lld, captureUs %lld, frameUs %lld",
+                static_cast<long long>(timeUs),
+                static_cast<long long>(mPrevCaptureUs),
+                static_cast<long long>(mPrevFrameUs));
+    } else {
+        if (timeUs <= mPrevFrameUs) {
+            if (mFrameDropper != NULL && mFrameDropper->disabled()) {
+                // Warn only, client has disabled frame drop logic possibly for image
+                // encoding cases where camera's ZSL mode could send out of order frames.
+                ALOGW("Received frame that's going backward in time");
+            } else {
+                // Drop the frame if it's going backward in time. Bad timestamp
+                // could disrupt encoder's rate control completely.
+                ALOGW("Dropping frame that's going backward in time");
+                return false;
+            }
+        }
+
+        mPrevFrameUs = timeUs;
+    }
+
+    *codecTimeUs = mPrevFrameUs;
+    return true;
+}
+
+status_t GraphicBufferSource::submitBuffer_l(const VideoBuffer &item) {
+    CHECK(!mFreeCodecBuffers.empty());
+    uint32_t codecBufferId = *mFreeCodecBuffers.begin();
+
+    ALOGV("submitBuffer_l [slot=%d, bufferId=%d]", item.mBuffer->getSlot(), codecBufferId);
+
+    int64_t codecTimeUs;
+    if (!calculateCodecTimestamp_l(item.mTimestampNs, &codecTimeUs)) {
+        return UNKNOWN_ERROR;
+    }
+
+    if ((android_dataspace)item.mDataspace != mLastDataspace) {
+        onDataspaceChanged_l(
+                item.mDataspace,
+                (android_pixel_format)item.mBuffer->getGraphicBuffer()->format);
+    }
+
+    std::shared_ptr<AcquiredBuffer> buffer = item.mBuffer;
+    // use a GraphicBuffer for now as component is using GraphicBuffers to hold references
+    // and it requires this graphic buffer to be able to hold its reference
+    // and thus we would need to create a new GraphicBuffer from an ANWBuffer separate from the
+    // acquired GraphicBuffer.
+    // TODO: this can be reworked globally to use ANWBuffer references
+    sp<GraphicBuffer> graphicBuffer = buffer->getGraphicBuffer();
+    status_t err = mComponent->submitBuffer(
+            codecBufferId, graphicBuffer, codecTimeUs, buffer->getAcquireFenceFd());
+
+    if (err != OK) {
+        ALOGW("WARNING: emptyGraphicBuffer failed: 0x%x", err);
+        return err;
+    }
+
+    mFreeCodecBuffers.erase(mFreeCodecBuffers.begin());
+
+    ssize_t cbix = mSubmittedCodecBuffers.add(codecBufferId, buffer);
+    ALOGV("emptyGraphicBuffer succeeded, bufferId=%u@%zd bufhandle=%p",
+            codecBufferId, cbix, graphicBuffer->handle);
+    return OK;
+}
+
+void GraphicBufferSource::submitEndOfInputStream_l() {
+    CHECK(mEndOfStream);
+    if (mEndOfStreamSent) {
+        ALOGV("EOS already sent");
+        return;
+    }
+
+    if (mFreeCodecBuffers.empty()) {
+        ALOGV("submitEndOfInputStream_l: no codec buffers available");
+        return;
+    }
+    uint32_t codecBufferId = *mFreeCodecBuffers.begin();
+
+    // We reject any additional incoming graphic buffers. There is no acquired buffer used for EOS
+    status_t err = mComponent->submitEos(codecBufferId);
+    if (err != OK) {
+        ALOGW("emptyDirectBuffer EOS failed: 0x%x", err);
+    } else {
+        mFreeCodecBuffers.erase(mFreeCodecBuffers.begin());
+        ssize_t cbix = mSubmittedCodecBuffers.add(codecBufferId, nullptr);
+        ALOGV("submitEndOfInputStream_l: buffer submitted, bufferId=%u@%zd", codecBufferId, cbix);
+        mEndOfStreamSent = true;
+
+        // no need to hold onto any buffers for frame repeating
+        ++mRepeatLastFrameGeneration;
+        mLatestBuffer.mBuffer.reset();
+    }
+}
+
+status_t GraphicBufferSource::acquireBuffer_l(VideoBuffer *ab) {
+    BufferItem bi;
+    status_t err = mConsumer->acquireBuffer(&bi, 0);
+    if (err == BufferQueue::NO_BUFFER_AVAILABLE) {
+        // shouldn't happen
+        ALOGW("acquireBuffer_l: frame was not available");
+        return err;
+    } else if (err != OK) {
+        ALOGW("acquireBuffer_l: failed with err=%d", err);
+        return err;
+    }
+    --mNumAvailableUnacquiredBuffers;
+
+    // Manage our buffer cache.
+    std::shared_ptr<CachedBuffer> buffer;
+    ssize_t bsi = mBufferSlots.indexOfKey(bi.mSlot);
+    if (bi.mGraphicBuffer != NULL) {
+        // replace/initialize slot with new buffer
+        ALOGV("acquireBuffer_l: %s buffer slot %d", bsi < 0 ? "setting" : "UPDATING", bi.mSlot);
+        if (bsi >= 0) {
+            discardBufferAtSlotIndex_l(bsi);
+        } else {
+            bsi = mBufferSlots.add(bi.mSlot, nullptr);
+        }
+        buffer = std::make_shared<CachedBuffer>(bi.mSlot, bi.mGraphicBuffer);
+        mBufferSlots.replaceValueAt(bsi, buffer);
+    } else {
+        buffer = mBufferSlots.valueAt(bsi);
+    }
+    int64_t frameNum = bi.mFrameNumber;
+
+    std::shared_ptr<AcquiredBuffer> acquiredBuffer =
+        std::make_shared<AcquiredBuffer>(
+                buffer,
+                [frameNum, this](AcquiredBuffer *buffer){
+                    // AcquiredBuffer's destructor should always be called when mMutex is locked.
+                    // If we had a reentrant mutex, we could just lock it again to ensure this.
+                    if (mMutex.tryLock() == 0) {
+                        TRESPASS_DBG();
+                        mMutex.unlock();
+                    }
+
+                    // we can release buffers immediately if not using adapters
+                    // alternately, we could add them to mSlotsToRelease, but we would
+                    // somehow need to propagate frame number to that queue
+                    if (buffer->isCached()) {
+                        --mNumOutstandingAcquires;
+                        mConsumer->releaseBuffer(buffer->getSlot(), frameNum,
+                                                 buffer->getReleaseFence());
+                    }
+                },
+                bi.mFence);
+    VideoBuffer videoBuffer{acquiredBuffer, bi.mTimestamp, bi.mDataSpace};
+    *ab = videoBuffer;
+    ++mNumOutstandingAcquires;
+    return OK;
+}
+
+// BufferQueue::ConsumerListener callback
+void GraphicBufferSource::onFrameAvailable(const BufferItem& item __unused) {
+    Mutex::Autolock autoLock(mMutex);
+
+    ALOGV("onFrameAvailable: executing=%d available=%zu+%d",
+            mExecuting, mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+    ++mNumAvailableUnacquiredBuffers;
+
+    // For BufferQueue we cannot acquire a buffer if we cannot immediately feed it to the codec
+    // UNLESS we are discarding this buffer (acquiring and immediately releasing it), which makes
+    // this an ugly logic.
+    // NOTE: We could also rely on our debug counter but that is meant only as a debug counter.
+    if (!areWeDiscardingAvailableBuffers_l() && mFreeCodecBuffers.empty()) {
+        // we may not be allowed to acquire a possibly encodable buffer, so just note that
+        // it is available
+        ALOGV("onFrameAvailable: cannot acquire buffer right now, do it later");
+
+        ++mRepeatLastFrameGeneration; // cancel any pending frame repeat
+        return;
+    }
+
+    VideoBuffer buffer;
+    status_t err = acquireBuffer_l(&buffer);
+    if (err != OK) {
+        ALOGE("onFrameAvailable: acquireBuffer returned err=%d", err);
+    } else {
+        onBufferAcquired_l(buffer);
+    }
+}
+
+bool GraphicBufferSource::areWeDiscardingAvailableBuffers_l() {
+    return mEndOfStreamSent // already sent EOS to codec
+            || mComponent == nullptr // there is no codec connected
+            || (mSuspended && mActionQueue.empty()) // we are suspended and not waiting for
+                                                    // any further action
+            || !mExecuting;
+}
+
+void GraphicBufferSource::onBufferAcquired_l(const VideoBuffer &buffer) {
+    if (mEndOfStreamSent) {
+        // This should only be possible if a new buffer was queued after
+        // EOS was signaled, i.e. the app is misbehaving.
+        ALOGW("onFrameAvailable: EOS is sent, ignoring frame");
+    } else if (mComponent == NULL || (mSuspended && mActionQueue.empty())) {
+        // FIXME: if we are suspended but have a resume queued we will stop repeating the last
+        // frame. Is that the desired behavior?
+        ALOGV("onFrameAvailable: suspended, ignoring frame");
+    } else {
+        ++mRepeatLastFrameGeneration; // cancel any pending frame repeat
+        mAvailableBuffers.push_back(buffer);
+        if (mExecuting) {
+            fillCodecBuffer_l();
+        }
+    }
+}
+
+// BufferQueue::ConsumerListener callback
+void GraphicBufferSource::onBuffersReleased() {
+    Mutex::Autolock lock(mMutex);
+
+    uint64_t slotMask;
+    uint64_t releaseMask;
+    if (mConsumer->getReleasedBuffers(&releaseMask) != NO_ERROR) {
+        slotMask = 0xffffffffffffffffULL;
+        ALOGW("onBuffersReleased: unable to get released buffer set");
+    } else {
+        slotMask = releaseMask;
+        ALOGV("onBuffersReleased: 0x%016" PRIx64, slotMask);
+    }
+
+    AString unpopulated;
+    for (int i = 0; i < BufferQueue::NUM_BUFFER_SLOTS; i++) {
+        if ((slotMask & 0x01) != 0) {
+            if (!discardBufferInSlot_l(i)) {
+                if (!unpopulated.empty()) {
+                    unpopulated.append(", ");
+                }
+                unpopulated.append(i);
+            }
+        }
+        slotMask >>= 1;
+    }
+    if (!unpopulated.empty()) {
+        ALOGW("released unpopulated slots: [%s]", unpopulated.c_str());
+    }
+}
+
+bool GraphicBufferSource::discardBufferInSlot_l(GraphicBufferSource::slot_id i) {
+    ssize_t bsi = mBufferSlots.indexOfKey(i);
+    if (bsi < 0) {
+        return false;
+    } else {
+        discardBufferAtSlotIndex_l(bsi);
+        mBufferSlots.removeItemsAt(bsi);
+        return true;
+    }
+}
+
+void GraphicBufferSource::discardBufferAtSlotIndex_l(ssize_t bsi) {
+    const std::shared_ptr<CachedBuffer>& buffer = mBufferSlots.valueAt(bsi);
+    // use -2 if there is no latest buffer, and -1 if it is no longer cached
+    slot_id latestBufferSlot =
+        mLatestBuffer.mBuffer == nullptr ? -2 : mLatestBuffer.mBuffer->getSlot();
+    ALOGV("releasing acquired buffer: [slot=%d, useCount=%ld], latest: [slot=%d]",
+            mBufferSlots.keyAt(bsi), buffer.use_count(), latestBufferSlot);
+    mBufferSlots.valueAt(bsi)->onDroppedFromCache();
+
+    // If the slot of an acquired buffer is discarded, that buffer will not have to be
+    // released to the producer, so account it here. However, it is possible that the
+    // acquired buffer has already been discarded so check if it still is.
+    if (buffer->isAcquired()) {
+        --mNumOutstandingAcquires;
+    }
+
+    // clear the buffer reference (not technically needed as caller either replaces or deletes
+    // it; done here for safety).
+    mBufferSlots.editValueAt(bsi).reset();
+    CHECK_DBG(buffer == nullptr);
+}
+
+void GraphicBufferSource::releaseAllAvailableBuffers_l() {
+    mAvailableBuffers.clear();
+    while (mNumAvailableUnacquiredBuffers > 0) {
+        VideoBuffer item;
+        if (acquireBuffer_l(&item) != OK) {
+            ALOGW("releaseAllAvailableBuffers: failed to acquire available unacquired buffer");
+            break;
+        }
+    }
+}
+
+// BufferQueue::ConsumerListener callback
+void GraphicBufferSource::onSidebandStreamChanged() {
+    ALOG_ASSERT(false, "GraphicBufferSource can't consume sideband streams");
+}
+
+status_t GraphicBufferSource::configure(
+        const sp<ComponentWrapper>& component,
+        int32_t dataSpace,
+        int32_t bufferCount,
+        uint32_t frameWidth,
+        uint32_t frameHeight,
+        uint32_t consumerUsage) {
+    uint64_t consumerUsage64 = static_cast<uint64_t>(consumerUsage);
+    return configure(component, dataSpace, bufferCount,
+                     frameWidth, frameHeight, consumerUsage64);
+}
+
+status_t GraphicBufferSource::configure(
+        const sp<ComponentWrapper>& component,
+        int32_t dataSpace,
+        int32_t bufferCount,
+        uint32_t frameWidth,
+        uint32_t frameHeight,
+        uint64_t consumerUsage) {
+    if (component == NULL) {
+        return BAD_VALUE;
+    }
+
+
+    // Call setMaxAcquiredBufferCount without lock.
+    // setMaxAcquiredBufferCount could call back to onBuffersReleased
+    // if the buffer count change results in releasing of existing buffers,
+    // which would lead to deadlock.
+    status_t err = mConsumer->setMaxAcquiredBufferCount(bufferCount);
+    if (err != NO_ERROR) {
+        ALOGE("Unable to set BQ max acquired buffer count to %u: %d",
+                bufferCount, err);
+        return err;
+    }
+
+    {
+        Mutex::Autolock autoLock(mMutex);
+        mComponent = component;
+
+        err = mConsumer->setDefaultBufferSize(frameWidth, frameHeight);
+        if (err != NO_ERROR) {
+            ALOGE("Unable to set BQ default buffer size to %ux%u: %d",
+                    frameWidth, frameHeight, err);
+            return err;
+        }
+
+        consumerUsage |= GRALLOC_USAGE_HW_VIDEO_ENCODER;
+        mConsumer->setConsumerUsageBits(consumerUsage);
+
+        // Set impl. defined format as default. Depending on the usage flags
+        // the device-specific implementation will derive the exact format.
+        err = mConsumer->setDefaultBufferFormat(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
+        if (err != NO_ERROR) {
+            ALOGE("Failed to configure surface default format ret: %d", err);
+            return err;
+        }
+
+        // Sets the default buffer data space
+        ALOGD("setting dataspace: %#x, acquired=%d", dataSpace, mNumOutstandingAcquires);
+        mConsumer->setDefaultBufferDataSpace((android_dataspace)dataSpace);
+        mLastDataspace = (android_dataspace)dataSpace;
+
+        mExecuting = false;
+        mSuspended = false;
+        mEndOfStream = false;
+        mEndOfStreamSent = false;
+        mSkipFramesBeforeNs = -1LL;
+        mFrameDropper.clear();
+        mFrameRepeatIntervalUs = -1LL;
+        mRepeatLastFrameGeneration = 0;
+        mOutstandingFrameRepeatCount = 0;
+        mLatestBuffer.mBuffer.reset();
+        mFrameRepeatBlockedOnCodecBuffer = false;
+        mFps = -1.0;
+        mCaptureFps = -1.0;
+        mBaseCaptureUs = -1LL;
+        mBaseFrameUs = -1LL;
+        mPrevCaptureUs = -1LL;
+        mPrevFrameUs = -1LL;
+        mFrameCount = 0;
+        mInputBufferTimeOffsetUs = 0;
+        mStopTimeUs = -1;
+        mActionQueue.clear();
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setSuspend(bool suspend, int64_t suspendStartTimeUs) {
+    ALOGV("setSuspend=%d at time %lld us", suspend, (long long)suspendStartTimeUs);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mStopTimeUs != -1) {
+        ALOGE("setSuspend failed as STOP action is pending");
+        return INVALID_OPERATION;
+    }
+
+    // Push the action to the queue.
+    if (suspendStartTimeUs != -1) {
+        // suspendStartTimeUs must be smaller or equal to current systemTime.
+        int64_t currentSystemTimeUs = systemTime() / 1000;
+        if (suspendStartTimeUs > currentSystemTimeUs) {
+            ALOGE("setSuspend failed. %lld is larger than current system time %lld us",
+                    (long long)suspendStartTimeUs, (long long)currentSystemTimeUs);
+            return INVALID_OPERATION;
+        }
+        if (mLastActionTimeUs != -1 && suspendStartTimeUs < mLastActionTimeUs) {
+            ALOGE("setSuspend failed. %lld is smaller than last action time %lld us",
+                    (long long)suspendStartTimeUs, (long long)mLastActionTimeUs);
+            return INVALID_OPERATION;
+        }
+        mLastActionTimeUs = suspendStartTimeUs;
+        ActionItem action;
+        action.mAction = suspend ? ActionItem::PAUSE : ActionItem::RESUME;
+        action.mActionTimeUs = suspendStartTimeUs;
+        ALOGV("Push %s action into actionQueue", suspend ? "PAUSE" : "RESUME");
+        mActionQueue.push_back(action);
+    } else {
+        if (suspend) {
+            mSuspended = true;
+            releaseAllAvailableBuffers_l();
+            return OK;
+        } else {
+            mSuspended = false;
+            if (mExecuting && !haveAvailableBuffers_l()
+                    && mFrameRepeatBlockedOnCodecBuffer) {
+                if (repeatLatestBuffer_l()) {
+                    ALOGV("suspend/deferred repeatLatestBuffer_l SUCCESS");
+                    mFrameRepeatBlockedOnCodecBuffer = false;
+                } else {
+                    ALOGV("suspend/deferred repeatLatestBuffer_l FAILURE");
+                }
+            }
+        }
+    }
+    return OK;
+}
+
+status_t GraphicBufferSource::setRepeatPreviousFrameDelayUs(int64_t repeatAfterUs) {
+    ALOGV("setRepeatPreviousFrameDelayUs: delayUs=%lld", (long long)repeatAfterUs);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting || repeatAfterUs <= 0LL) {
+        return INVALID_OPERATION;
+    }
+
+    mFrameRepeatIntervalUs = repeatAfterUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::setTimeOffsetUs(int64_t timeOffsetUs) {
+    Mutex::Autolock autoLock(mMutex);
+
+    // timeOffsetUs must be negative for adjustment.
+    if (timeOffsetUs >= 0LL) {
+        return INVALID_OPERATION;
+    }
+
+    mInputBufferTimeOffsetUs = timeOffsetUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::setMaxFps(float maxFps) {
+    ALOGV("setMaxFps: maxFps=%lld", (long long)maxFps);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting) {
+        return INVALID_OPERATION;
+    }
+
+    mFrameDropper = new FrameDropper();
+    status_t err = mFrameDropper->setMaxFrameRate(maxFps);
+    if (err != OK) {
+        mFrameDropper.clear();
+        return err;
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setStartTimeUs(int64_t skipFramesBeforeUs) {
+    ALOGV("setStartTimeUs: skipFramesBeforeUs=%lld", (long long)skipFramesBeforeUs);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    mSkipFramesBeforeNs =
+            (skipFramesBeforeUs > 0 && skipFramesBeforeUs <= INT64_MAX / 1000) ?
+            (skipFramesBeforeUs * 1000) : -1LL;
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setStopTimeUs(int64_t stopTimeUs) {
+    ALOGV("setStopTimeUs: %lld us", (long long)stopTimeUs);
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mStopTimeUs != -1) {
+        // Ignore if stop time has already been set
+        return OK;
+    }
+
+    // stopTimeUs must be smaller or equal to current systemTime.
+    int64_t currentSystemTimeUs = systemTime() / 1000;
+    if (stopTimeUs > currentSystemTimeUs) {
+        ALOGE("setStopTimeUs failed. %lld is larger than current system time %lld us",
+            (long long)stopTimeUs, (long long)currentSystemTimeUs);
+        return INVALID_OPERATION;
+    }
+    if (mLastActionTimeUs != -1 && stopTimeUs < mLastActionTimeUs) {
+        ALOGE("setSuspend failed. %lld is smaller than last action time %lld us",
+            (long long)stopTimeUs, (long long)mLastActionTimeUs);
+        return INVALID_OPERATION;
+    }
+    mLastActionTimeUs = stopTimeUs;
+    ActionItem action;
+    action.mAction = ActionItem::STOP;
+    action.mActionTimeUs = stopTimeUs;
+    mActionQueue.push_back(action);
+    mStopTimeUs = stopTimeUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::getStopTimeOffsetUs(int64_t *stopTimeOffsetUs) {
+    ALOGV("getStopTimeOffsetUs");
+    Mutex::Autolock autoLock(mMutex);
+    if (mStopTimeUs == -1) {
+        ALOGW("Fail to return stopTimeOffsetUs as stop time is not set");
+        return INVALID_OPERATION;
+    }
+    *stopTimeOffsetUs =
+        mLastFrameTimestampUs == -1 ? 0 : mStopTimeUs - mLastFrameTimestampUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::setTimeLapseConfig(double fps, double captureFps) {
+    ALOGV("setTimeLapseConfig: fps=%lg, captureFps=%lg",
+            fps, captureFps);
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting || !(fps > 0) || !(captureFps > 0)) {
+        return INVALID_OPERATION;
+    }
+
+    mFps = fps;
+    mCaptureFps = captureFps;
+    if (captureFps > fps) {
+        mSnapTimestamps = 1 == base::GetIntProperty(
+                "debug.stagefright.snap_timestamps", int64_t(0));
+    } else {
+        mSnapTimestamps = false;
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setColorAspects(int32_t aspectsPacked) {
+    Mutex::Autolock autoLock(mMutex);
+    mDefaultColorAspectsPacked = aspectsPacked;
+    ColorAspects colorAspects = ColorUtils::unpackToColorAspects(aspectsPacked);
+    ALOGD("requesting color aspects (R:%d(%s), P:%d(%s), M:%d(%s), T:%d(%s))",
+            colorAspects.mRange, asString(colorAspects.mRange),
+            colorAspects.mPrimaries, asString(colorAspects.mPrimaries),
+            colorAspects.mMatrixCoeffs, asString(colorAspects.mMatrixCoeffs),
+            colorAspects.mTransfer, asString(colorAspects.mTransfer));
+
+    return OK;
+}
+
+status_t GraphicBufferSource::signalEndOfInputStream() {
+    Mutex::Autolock autoLock(mMutex);
+    ALOGV("signalEndOfInputStream: executing=%d available=%zu+%d eos=%d",
+            mExecuting, mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream);
+
+    if (mEndOfStream) {
+        ALOGE("EOS was already signaled");
+        return INVALID_OPERATION;
+    }
+
+    // Set the end-of-stream flag.  If no frames are pending from the
+    // BufferQueue, and a codec buffer is available, and we're executing,
+    // and there is no stop timestamp, we initiate the EOS from here.
+    // Otherwise, we'll let codecBufferEmptied() (or start) do it.
+    //
+    // Note: if there are no pending frames and all codec buffers are
+    // available, we *must* submit the EOS from here or we'll just
+    // stall since no future events are expected.
+    mEndOfStream = true;
+
+    if (mStopTimeUs == -1 && mExecuting && !haveAvailableBuffers_l()) {
+        submitEndOfInputStream_l();
+    }
+
+    return OK;
+}
+
+void GraphicBufferSource::onMessageReceived(const sp<AMessage> &msg) {
+    switch (msg->what()) {
+        case kWhatRepeatLastFrame:
+        {
+            Mutex::Autolock autoLock(mMutex);
+
+            int32_t generation;
+            CHECK(msg->findInt32("generation", &generation));
+
+            if (generation != mRepeatLastFrameGeneration) {
+                // stale
+                break;
+            }
+
+            if (!mExecuting || haveAvailableBuffers_l()) {
+                break;
+            }
+
+            bool success = repeatLatestBuffer_l();
+            if (success) {
+                ALOGV("repeatLatestBuffer_l SUCCESS");
+            } else {
+                ALOGV("repeatLatestBuffer_l FAILURE");
+                mFrameRepeatBlockedOnCodecBuffer = true;
+            }
+            break;
+        }
+
+        default:
+            TRESPASS();
+    }
+}
+
+}  // namespace android
diff --git a/media/module/bqhelper/flagged_files/GraphicBufferSource.inc b/media/module/bqhelper/flagged_files/GraphicBufferSource.inc
new file mode 100644
index 0000000000..368c97902e
--- /dev/null
+++ b/media/module/bqhelper/flagged_files/GraphicBufferSource.inc
@@ -0,0 +1,1269 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include <inttypes.h>
+
+#define LOG_TAG "GraphicBufferSource"
+// #define LOG_NDEBUG 0
+#include <utils/Log.h>
+
+#define STRINGIFY_ENUMS  // for asString in HardwareAPI.h/VideoAPI.h
+
+#include <media/stagefright/bqhelper/FrameDropper.h>
+#include <media/stagefright/bqhelper/GraphicBufferSource.h>
+#include <media/stagefright/foundation/ADebug.h>
+#include <media/stagefright/foundation/AMessage.h>
+#include <media/stagefright/foundation/ColorUtils.h>
+#include <media/stagefright/foundation/FileDescriptor.h>
+
+#include <android-base/properties.h>
+#include <gui/BufferItem.h>
+#include <gui/BufferItemConsumer.h>
+#include <gui/BufferQueue.h>
+#include <gui/Surface.h>
+#include <gui/bufferqueue/1.0/WGraphicBufferProducer.h>
+#include <media/hardware/HardwareAPI.h>
+#include <media/hardware/MetadataBufferType.h>
+#include <ui/GraphicBuffer.h>
+
+#include <inttypes.h>
+#include <cmath>
+
+namespace android {
+
+namespace {
+// kTimestampFluctuation is an upper bound of timestamp fluctuation from the
+// source that GraphicBufferSource allows. The unit of kTimestampFluctuation is
+// frames. More specifically, GraphicBufferSource will drop a frame if
+//
+// expectedNewFrametimestamp - actualNewFrameTimestamp <
+//     (0.5 - kTimestampFluctuation) * expectedtimePeriodBetweenFrames
+//
+// where
+// - expectedNewFrameTimestamp is the calculated ideal timestamp of the new
+//   incoming frame
+// - actualNewFrameTimestamp is the timestamp received from the source
+// - expectedTimePeriodBetweenFrames is the ideal difference of the timestamps
+//   of two adjacent frames
+//
+// See GraphicBufferSource::calculateCodecTimestamp_l() for more detail about
+// how kTimestampFluctuation is used.
+//
+// kTimestampFluctuation should be non-negative. A higher value causes a smaller
+// chance of dropping frames, but at the same time a higher bound on the
+// difference between the source timestamp and the interpreted (snapped)
+// timestamp.
+//
+// The value of 0.05 means that GraphicBufferSource expects the input timestamps
+// to fluctuate no more than 5% from the regular time period.
+//
+// TODO: Justify the choice of this value, or make it configurable.
+constexpr double kTimestampFluctuation = 0.05;
+}  // namespace
+
+/**
+ * A copiable object managing a buffer in the buffer cache managed by the producer. This object
+ * holds a reference to the buffer. It also maintains whether there are any outstanging acquire
+ * references to it mainly so that we can keep a debug count of how many buffers we need to still
+ * release back to the producer.
+ */
+struct GraphicBufferSource::Buffer {
+    /**
+     * Token that is used to track acquire counts (as opposed to all references to this object).
+     */
+    struct Acquirable {};
+
+    /**
+     *
+     */
+    Buffer(const sp<GraphicBuffer>& graphicBuffer)
+        : mGraphicBuffer(graphicBuffer), mAcquirable(std::make_shared<Acquirable>()) {}
+
+    /**
+     * Returns the buffer ID.
+     */
+    uint64_t getId() const { return mGraphicBuffer->getId(); }
+
+    /**
+     * Returns the cached buffer.
+     */
+    sp<GraphicBuffer> getGraphicBuffer() const { return mGraphicBuffer; }
+
+    /**
+     * Checks whether this buffer has an acquired reference.
+     */
+    bool isAcquired() const { return mAcquirable.use_count() > 1; }
+
+    /**
+     * Gets and returns a shared acquired reference.
+     */
+    std::shared_ptr<Acquirable> getAcquirable() { return mAcquirable; }
+
+  private:
+    sp<GraphicBuffer> mGraphicBuffer;
+    std::shared_ptr<Acquirable> mAcquirable;
+};
+
+/**
+ * A copiable object managing a buffer acquired from the producer. This must always be a cached
+ * buffer. This objects also manages its acquire fence and any release fences that may be returned
+ * by the encoder for this buffer (this buffer may be queued to the encoder multiple times).
+ * If no release fences are added by the encoder, the acquire fence is returned as the release
+ * fence for this - as it is assumed that noone waited for the acquire fence. Otherwise, it is
+ * assumed that the encoder has waited for the acquire fence (or returned it as the release
+ * fence).
+ */
+struct GraphicBufferSource::AcquiredBuffer {
+    AcquiredBuffer(const std::shared_ptr<Buffer>& buffer,
+                   std::function<void(AcquiredBuffer*)> onReleased, const sp<Fence>& acquireFence)
+        : mBuffer(buffer),
+          mAcquirable(buffer->getAcquirable()),
+          mAcquireFence(acquireFence),
+          mGotReleaseFences(false),
+          mOnReleased(onReleased) {}
+
+    /**
+     * Adds a release fence returned by the encoder to this object. If this is called with an
+     * valid file descriptor, it is added to the list of release fences. These are returned to the
+     * producer on release() as a merged fence. Regardless of the validity of the file descriptor,
+     * we take note that a release fence was attempted to be added and the acquire fence can now be
+     * assumed as acquired.
+     */
+    void addReleaseFenceFd(int fenceFd) {
+        // save all release fences - these will be propagated to the producer if this buffer is
+        // ever released to it
+        if (fenceFd >= 0) {
+            mReleaseFenceFds.push_back(fenceFd);
+        }
+        mGotReleaseFences = true;
+    }
+
+    /**
+     * Returns the acquire fence file descriptor associated with this object.
+     */
+    int getAcquireFenceFd() {
+        if (mAcquireFence == nullptr || !mAcquireFence->isValid()) {
+            return -1;
+        }
+        return mAcquireFence->dup();
+    }
+
+    /**
+     * Returns the acquired buffer.
+     */
+    sp<GraphicBuffer> getGraphicBuffer() const { return mBuffer->getGraphicBuffer(); }
+
+
+    /**
+     * Returns the buffer ID.
+     */
+    uint64_t getId() const {
+        return mBuffer->getId();
+    }
+
+    /**
+     * Creates and returns a release fence object from the acquire fence and/or any release fences
+     * added. If no release fences were added (even if invalid), returns the acquire fence.
+     * Otherwise, it returns a merged fence from all the valid release fences added.
+     */
+    sp<Fence> getReleaseFence() {
+        // If did not receive release fences, we assume this buffer was not consumed (it was
+        // discarded or dropped). In this case release the acquire fence as the release fence.
+        // We do this here to avoid a dup, close and recreation of the Fence object.
+        if (!mGotReleaseFences) {
+            return mAcquireFence;
+        }
+        sp<Fence> ret = getReleaseFence(0, mReleaseFenceFds.size());
+        // clear fds as fence took ownership of them
+        mReleaseFenceFds.clear();
+        return ret;
+    }
+
+    // this video buffer is no longer referenced by the codec (or kept for later encoding)
+    // it is now safe to release to the producer
+    ~AcquiredBuffer() {
+        // mAcquirable.clear();
+        mOnReleased(this);
+        // mOnRelease method should call getReleaseFence() that releases all fds but just in case
+        ALOGW_IF(!mReleaseFenceFds.empty(), "release fences were not obtained, closing fds");
+        for (int fildes : mReleaseFenceFds) {
+            ::close(fildes);
+            TRESPASS_DBG();
+        }
+    }
+
+  private:
+    std::shared_ptr<GraphicBufferSource::Buffer> mBuffer;
+    std::shared_ptr<GraphicBufferSource::Buffer::Acquirable> mAcquirable;
+    sp<Fence> mAcquireFence;
+    Vector<int> mReleaseFenceFds;
+    bool mGotReleaseFences;
+    std::function<void(AcquiredBuffer*)> mOnReleased;
+
+    /**
+     * Creates and returns a release fence from 0 or more release fence file descriptors in from
+     * the specified range in the array.
+     *
+     * @param start start index
+     * @param num   number of release fds to merge
+     */
+    sp<Fence> getReleaseFence(size_t start, size_t num) const {
+        if (num == 0) {
+            return Fence::NO_FENCE;
+        } else if (num == 1) {
+            return new Fence(mReleaseFenceFds[start]);
+        } else {
+            return Fence::merge("GBS::AB", getReleaseFence(start, num >> 1),
+                                getReleaseFence(start + (num >> 1), num - (num >> 1)));
+        }
+    }
+};
+
+struct GraphicBufferSource::ConsumerProxy : public ConsumerBase::FrameAvailableListener {
+    ConsumerProxy(const wp<GraphicBufferSource>& gbs) : mGbs(gbs) {}
+
+    ~ConsumerProxy() = default;
+
+    void onFrameAvailable(const BufferItem&) override {
+        sp<GraphicBufferSource> gbs = mGbs.promote();
+        if (gbs != nullptr) {
+            gbs->onFrameAvailable();
+        }
+    }
+
+    void onFrameReplaced(const BufferItem&) override {
+        sp<GraphicBufferSource> gbs = mGbs.promote();
+        if (gbs != nullptr) {
+            gbs->onFrameAvailable();
+        }
+    }
+
+  private:
+    // Note that GraphicBufferSource is holding an sp to us, we can't hold
+    // an sp back to GraphicBufferSource as the circular dependency will
+    // make both immortal.
+    wp<GraphicBufferSource> mGbs;
+};
+
+GraphicBufferSource::GraphicBufferSource()
+    : mNumAvailableUnacquiredBuffers(0),
+      mNumOutstandingAcquires(0),
+      mEndOfStream(false),
+      mEndOfStreamSent(false),
+      mLastDataspace(HAL_DATASPACE_UNKNOWN),
+      mExecuting(false),
+      mSuspended(false),
+      mLastFrameTimestampUs(-1),
+      mStopTimeUs(-1),
+      mLastActionTimeUs(-1LL),
+      mSkipFramesBeforeNs(-1LL),
+      mFrameRepeatIntervalUs(-1LL),
+      mRepeatLastFrameGeneration(0),
+      mOutstandingFrameRepeatCount(0),
+      mFrameRepeatBlockedOnCodecBuffer(false),
+      mFps(-1.0),
+      mCaptureFps(-1.0),
+      mBaseCaptureUs(-1LL),
+      mBaseFrameUs(-1LL),
+      mFrameCount(0),
+      mPrevCaptureUs(-1LL),
+      mPrevFrameUs(-1LL),
+      mInputBufferTimeOffsetUs(0LL) {
+    ALOGV("GraphicBufferSource");
+
+    memset(&mDefaultColorAspectsPacked, 0, sizeof(mDefaultColorAspectsPacked));
+}
+
+void GraphicBufferSource::onFirstRef() {
+    mConsumerProxy = sp<GraphicBufferSource::ConsumerProxy>::make(this);
+
+    // This consumer usage is just temporary, it will be replaced by configure.
+    const uint64_t consumerUsage = GRALLOC_USAGE_SW_READ_NEVER;
+    std::tie(mBufferItemConsumer, mSurface) = BufferItemConsumer::create(consumerUsage);
+    mBufferItemConsumer->setFrameAvailableListener(mConsumerProxy);
+}
+
+GraphicBufferSource::~GraphicBufferSource() {
+    ALOGV("~GraphicBufferSource");
+    {
+        // all acquired buffers must be freed with the mutex locked otherwise our debug assertion
+        // may trigger
+        Mutex::Autolock autoLock(mMutex);
+        mAvailableBuffers.clear();
+        mSubmittedCodecBuffers.clear();
+        mLatestBuffer.mBuffer.reset();
+    }
+
+    if (mNumOutstandingAcquires != 0) {
+        ALOGW("potential buffer leak: acquired=%d", mNumOutstandingAcquires);
+        TRESPASS_DBG();
+    }
+    if (mBufferItemConsumer != NULL) {
+        mBufferItemConsumer->abandon();
+    }
+}
+
+sp<IGraphicBufferProducer> GraphicBufferSource::getIGraphicBufferProducer() const {
+    return mSurface->getIGraphicBufferProducer();
+}
+
+sp<::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>
+GraphicBufferSource::getHGraphicBufferProducer_V1_0() const {
+    using TWGraphicBufferProducer = ::android::TWGraphicBufferProducer<
+            ::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>;
+
+    return new TWGraphicBufferProducer(getIGraphicBufferProducer());
+}
+
+status_t GraphicBufferSource::start() {
+    Mutex::Autolock autoLock(mMutex);
+    ALOGV("--> start; available=%zu, submittable=%zd", mAvailableBuffers.size(),
+          mFreeCodecBuffers.size());
+    CHECK(!mExecuting);
+    mExecuting = true;
+    mLastDataspace = HAL_DATASPACE_UNKNOWN;
+    ALOGV("clearing last dataSpace");
+
+    // Start by loading up as many buffers as possible.  We want to do this,
+    // rather than just submit the first buffer, to avoid a degenerate case:
+    // if all BQ buffers arrive before we start executing, and we only submit
+    // one here, the other BQ buffers will just sit until we get notified
+    // that the codec buffer has been released.  We'd then acquire and
+    // submit a single additional buffer, repeatedly, never using more than
+    // one codec buffer simultaneously.  (We could instead try to submit
+    // all BQ buffers whenever any codec buffer is freed, but if we get the
+    // initial conditions right that will never be useful.)
+    while (haveAvailableBuffers_l()) {
+        if (!fillCodecBuffer_l()) {
+            ALOGV("stop load with available=%zu+%d", mAvailableBuffers.size(),
+                  mNumAvailableUnacquiredBuffers);
+            break;
+        }
+    }
+
+    ALOGV("done loading initial frames, available=%zu+%d", mAvailableBuffers.size(),
+          mNumAvailableUnacquiredBuffers);
+
+    // If EOS has already been signaled, and there are no more frames to
+    // submit, try to send EOS now as well.
+    if (mStopTimeUs == -1 && mEndOfStream && !haveAvailableBuffers_l()) {
+        submitEndOfInputStream_l();
+    }
+
+    if (mFrameRepeatIntervalUs > 0LL && mLooper == NULL) {
+        mReflector = new AHandlerReflector<GraphicBufferSource>(this);
+
+        mLooper = new ALooper;
+        mLooper->registerHandler(mReflector);
+        mLooper->start();
+
+        if (mLatestBuffer.mBuffer != nullptr) {
+            queueFrameRepeat_l();
+        }
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::stop() {
+    ALOGV("stop");
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting) {
+        // We are only interested in the transition from executing->idle,
+        // not loaded->idle.
+        mExecuting = false;
+    }
+    return OK;
+}
+
+status_t GraphicBufferSource::release() {
+    sp<ALooper> looper;
+    {
+        Mutex::Autolock autoLock(mMutex);
+        looper = mLooper;
+        if (mLooper != NULL) {
+            mLooper->unregisterHandler(mReflector->id());
+            mReflector.clear();
+
+            mLooper.clear();
+        }
+
+        ALOGV("--> release; available=%zu+%d eos=%d eosSent=%d acquired=%d",
+              mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream,
+              mEndOfStreamSent, mNumOutstandingAcquires);
+
+        // Codec is no longer executing.  Releasing all buffers to bq.
+        mFreeCodecBuffers.clear();
+        mSubmittedCodecBuffers.clear();
+        mLatestBuffer.mBuffer.reset();
+        mComponent.clear();
+        mExecuting = false;
+    }
+    if (looper != NULL) {
+        looper->stop();
+    }
+    return OK;
+}
+
+status_t GraphicBufferSource::onInputBufferAdded(codec_buffer_id bufferId) {
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting) {
+        // This should never happen -- buffers can only be allocated when
+        // transitioning from "loaded" to "idle".
+        ALOGE("addCodecBuffer: buffer added while executing");
+        return INVALID_OPERATION;
+    }
+
+    ALOGV("addCodecBuffer: bufferId=%u", bufferId);
+
+    mFreeCodecBuffers.push_back(bufferId);
+    return OK;
+}
+
+status_t GraphicBufferSource::onInputBufferEmptied(codec_buffer_id bufferId, int fenceFd) {
+    Mutex::Autolock autoLock(mMutex);
+    FileDescriptor::Autoclose fence(fenceFd);
+
+    ssize_t cbi = mSubmittedCodecBuffers.indexOfKey(bufferId);
+    if (cbi < 0) {
+        // This should never happen.
+        ALOGE("onInputBufferEmptied: buffer not recognized (bufferId=%u)", bufferId);
+        return BAD_VALUE;
+    }
+
+    std::shared_ptr<AcquiredBuffer> buffer = mSubmittedCodecBuffers.valueAt(cbi);
+
+    // Move buffer to available buffers
+    mSubmittedCodecBuffers.removeItemsAt(cbi);
+    mFreeCodecBuffers.push_back(bufferId);
+
+    // header->nFilledLen may not be the original value, so we can't compare
+    // that to zero to see of this was the EOS buffer.  Instead we just
+    // see if there is a null AcquiredBuffer, which should only ever happen for EOS.
+    if (buffer == nullptr) {
+        if (!(mEndOfStream && mEndOfStreamSent)) {
+            // This can happen when broken code sends us the same buffer twice in a row.
+            ALOGE("onInputBufferEmptied: non-EOS null buffer (bufferId=%u)", bufferId);
+        } else {
+            ALOGV("onInputBufferEmptied: EOS null buffer (bufferId=%u@%zd)", bufferId, cbi);
+        }
+        // No GraphicBuffer to deal with, no additional input or output is expected, so just return.
+        return BAD_VALUE;
+    }
+
+    if (!mExecuting) {
+        // this is fine since this could happen when going from Idle to Loaded
+        ALOGV("onInputBufferEmptied: no longer executing (bufferId=%u@%zd)", bufferId, cbi);
+        return OK;
+    }
+
+    ALOGV("onInputBufferEmptied: bufferId=%d@%zd [slot=%" PRIu64 ", useCount=%ld, handle=%p] acquired=%d", bufferId,
+          cbi, buffer->getId(), buffer.use_count(), buffer->getGraphicBuffer()->handle, mNumOutstandingAcquires);
+
+    buffer->addReleaseFenceFd(fence.release());
+    // release codec reference for video buffer just in case remove does not it
+    buffer.reset();
+
+    if (haveAvailableBuffers_l()) {
+        // Fill this codec buffer.
+        CHECK(!mEndOfStreamSent);
+        ALOGV("onInputBufferEmptied: buffer freed, feeding codec (available=%zu+%d, eos=%d)",
+              mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream);
+        fillCodecBuffer_l();
+    } else if (mEndOfStream && mStopTimeUs == -1) {
+        // No frames available, but EOS is pending and no stop time, so use this buffer to
+        // send that.
+        ALOGV("onInputBufferEmptied: buffer freed, submitting EOS");
+        submitEndOfInputStream_l();
+    } else if (mFrameRepeatBlockedOnCodecBuffer) {
+        bool success = repeatLatestBuffer_l();
+        ALOGV("onInputBufferEmptied: completing deferred repeatLatestBuffer_l %s",
+              success ? "SUCCESS" : "FAILURE");
+        mFrameRepeatBlockedOnCodecBuffer = false;
+    }
+
+    // releaseReleasableBuffers_l();
+    return OK;
+}
+
+void GraphicBufferSource::onDataspaceChanged_l(android_dataspace dataspace,
+                                               android_pixel_format pixelFormat) {
+    ALOGD("got buffer with new dataSpace %#x", dataspace);
+    mLastDataspace = dataspace;
+
+    if (ColorUtils::convertDataSpaceToV0(dataspace)) {
+        mComponent->dispatchDataSpaceChanged(mLastDataspace, mDefaultColorAspectsPacked,
+                                             pixelFormat);
+    }
+}
+
+bool GraphicBufferSource::fillCodecBuffer_l() {
+    CHECK(mExecuting && haveAvailableBuffers_l());
+
+    if (mFreeCodecBuffers.empty()) {
+        // No buffers available, bail.
+        ALOGV("fillCodecBuffer_l: no codec buffers, available=%zu+%d", mAvailableBuffers.size(),
+              mNumAvailableUnacquiredBuffers);
+        return false;
+    }
+
+    VideoBuffer item;
+    if (mAvailableBuffers.empty()) {
+        ALOGV("fillCodecBuffer_l: acquiring available buffer, available=%zu+%d",
+              mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+        if (acquireBuffer_l(&item) != OK) {
+            ALOGE("fillCodecBuffer_l: failed to acquire available buffer");
+            return false;
+        }
+    } else {
+        ALOGV("fillCodecBuffer_l: getting available buffer, available=%zu+%d",
+              mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers);
+        item = *mAvailableBuffers.begin();
+        mAvailableBuffers.erase(mAvailableBuffers.begin());
+    }
+
+    int64_t itemTimeUs = item.mTimestampNs / 1000;
+
+    // Process ActionItem in the Queue if there is any. If a buffer's timestamp
+    // is smaller than the first action's timestamp, no action need to be performed.
+    // If buffer's timestamp is larger or equal than the last action's timestamp,
+    // only the last action needs to be performed as all the acitions before the
+    // the action are overridden by the last action. For the other cases, traverse
+    // the Queue to find the newest action that with timestamp smaller or equal to
+    // the buffer's timestamp. For example, an action queue like
+    // [pause 1us], [resume 2us], [pause 3us], [resume 4us], [pause 5us].... Upon
+    // receiving a buffer with timestamp 3.5us, only the action [pause, 3us] needs
+    // to be handled and [pause, 1us], [resume 2us] will be discarded.
+    bool done = false;
+    bool seeStopAction = false;
+    if (!mActionQueue.empty()) {
+        // First scan to check if bufferTimestamp is smaller than first action's timestamp.
+        ActionItem nextAction = *(mActionQueue.begin());
+        if (itemTimeUs < nextAction.mActionTimeUs) {
+            ALOGV("No action. buffer timestamp %lld us < action timestamp: %lld us",
+                  (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+            // All the actions are ahead. No action need to perform now.
+            // Release the buffer if is in suspended state, or process the buffer
+            // if not in suspended state.
+            done = true;
+        }
+
+        if (!done) {
+            // Find the newest action that with timestamp smaller than itemTimeUs. Then
+            // remove all the actions before and include the newest action.
+            List<ActionItem>::iterator it = mActionQueue.begin();
+            while (it != mActionQueue.end() && it->mActionTimeUs <= itemTimeUs &&
+                   nextAction.mAction != ActionItem::STOP) {
+                nextAction = *it;
+                ++it;
+            }
+            mActionQueue.erase(mActionQueue.begin(), it);
+
+            CHECK(itemTimeUs >= nextAction.mActionTimeUs);
+            switch (nextAction.mAction) {
+                case ActionItem::PAUSE: {
+                    mSuspended = true;
+                    ALOGV("RUNNING/PAUSE -> PAUSE at buffer %lld us  PAUSE Time: %lld us",
+                          (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+                    break;
+                }
+                case ActionItem::RESUME: {
+                    mSuspended = false;
+                    ALOGV("PAUSE/RUNNING -> RUNNING at buffer %lld us  RESUME Time: %lld us",
+                          (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+                    break;
+                }
+                case ActionItem::STOP: {
+                    ALOGV("RUNNING/PAUSE -> STOP at buffer %lld us  STOP Time: %lld us",
+                          (long long)itemTimeUs, (long long)nextAction.mActionTimeUs);
+                    // Clear the whole ActionQueue as recording is done
+                    mActionQueue.clear();
+                    seeStopAction = true;
+                    break;
+                }
+                default:
+                    TRESPASS_DBG("Unknown action type");
+                    // return true here because we did consume an available buffer, so the
+                    // loop in start will eventually terminate even if we hit this.
+                    return false;
+            }
+        }
+    }
+
+    if (seeStopAction) {
+        // Clear all the buffers before setting mEndOfStream and signal EndOfInputStream.
+        releaseAllAvailableBuffers_l();
+        mEndOfStream = true;
+        submitEndOfInputStream_l();
+        return true;
+    }
+
+    if (mSuspended) {
+        return true;
+    }
+
+    int err = UNKNOWN_ERROR;
+
+    // only submit sample if start time is unspecified, or sample
+    // is queued after the specified start time
+    if (mSkipFramesBeforeNs < 0LL || item.mTimestampNs >= mSkipFramesBeforeNs) {
+        // if start time is set, offset time stamp by start time
+        if (mSkipFramesBeforeNs > 0) {
+            item.mTimestampNs -= mSkipFramesBeforeNs;
+        }
+
+        int64_t timeUs = item.mTimestampNs / 1000;
+        if (mFrameDropper != NULL && mFrameDropper->shouldDrop(timeUs)) {
+            ALOGV("skipping frame (%lld) to meet max framerate", static_cast<long long>(timeUs));
+            // set err to OK so that the skipped frame can still be saved as the lastest frame
+            err = OK;
+        } else {
+            err = submitBuffer_l(
+                    item);  // this takes shared ownership of the acquired buffer on succeess
+        }
+    }
+
+    if (err != OK) {
+        ALOGV("submitBuffer_l failed, will release bq buffer id %" PRIu64, item.mBuffer->getId());
+        return true;
+    } else {
+        // Don't set the last buffer id if we're not repeating,
+        // we'll be holding on to the last buffer for nothing.
+        if (mFrameRepeatIntervalUs > 0LL) {
+            setLatestBuffer_l(item);
+        }
+        ALOGV("buffer submitted [buffer id=%" PRIu64 ", useCount=%ld] acquired=%d",
+              item.mBuffer->getId(), item.mBuffer.use_count(), mNumOutstandingAcquires);
+        mLastFrameTimestampUs = itemTimeUs;
+    }
+
+    return true;
+}
+
+bool GraphicBufferSource::repeatLatestBuffer_l() {
+    CHECK(mExecuting && !haveAvailableBuffers_l());
+
+    if (mLatestBuffer.mBuffer == nullptr || mSuspended) {
+        return false;
+    }
+
+    if (mFreeCodecBuffers.empty()) {
+        // No buffers available, bail.
+        ALOGV("repeatLatestBuffer_l: no codec buffers.");
+        return false;
+    }
+
+    // it is ok to update the timestamp of latest buffer as it is only used for submission
+    status_t err = submitBuffer_l(mLatestBuffer);
+    if (err != OK) {
+        return false;
+    }
+
+    /* repeat last frame up to kRepeatLastFrameCount times.
+     * in case of static scene, a single repeat might not get rid of encoder
+     * ghosting completely, refresh a couple more times to get better quality
+     */
+    if (--mOutstandingFrameRepeatCount > 0) {
+        // set up timestamp for repeat frame
+        mLatestBuffer.mTimestampNs += mFrameRepeatIntervalUs * 1000;
+        queueFrameRepeat_l();
+    }
+
+    return true;
+}
+
+void GraphicBufferSource::setLatestBuffer_l(const VideoBuffer& item) {
+    mLatestBuffer = item;
+
+    ALOGV("setLatestBuffer_l: [buffer_id=%" PRIu64 ", useCount=%ld]",
+            mLatestBuffer.mBuffer->getId(), mLatestBuffer.mBuffer.use_count());
+
+    mOutstandingFrameRepeatCount = kRepeatLastFrameCount;
+    // set up timestamp for repeat frame
+    mLatestBuffer.mTimestampNs += mFrameRepeatIntervalUs * 1000;
+    queueFrameRepeat_l();
+}
+
+void GraphicBufferSource::queueFrameRepeat_l() {
+    mFrameRepeatBlockedOnCodecBuffer = false;
+
+    if (mReflector != NULL) {
+        sp<AMessage> msg = new AMessage(kWhatRepeatLastFrame, mReflector);
+        msg->setInt32("generation", ++mRepeatLastFrameGeneration);
+        msg->post(mFrameRepeatIntervalUs);
+    }
+}
+
+#ifdef __clang__
+__attribute__((no_sanitize("integer")))
+#endif
+bool GraphicBufferSource::calculateCodecTimestamp_l(nsecs_t bufferTimeNs, int64_t* codecTimeUs) {
+    int64_t timeUs = bufferTimeNs / 1000;
+    timeUs += mInputBufferTimeOffsetUs;
+
+    if (mCaptureFps > 0. && (mFps > 2 * mCaptureFps || mCaptureFps > 2 * mFps)) {
+        // Time lapse or slow motion mode
+        if (mPrevCaptureUs < 0LL) {
+            // first capture
+            mPrevCaptureUs = mBaseCaptureUs = timeUs;
+            // adjust the first sample timestamp.
+            mPrevFrameUs = mBaseFrameUs = std::llround((timeUs * mCaptureFps) / mFps);
+            mFrameCount = 0;
+        } else if (mSnapTimestamps) {
+            double nFrames = (timeUs - mPrevCaptureUs) * mCaptureFps / 1000000;
+            if (nFrames < 0.5 - kTimestampFluctuation) {
+                // skip this frame as it's too close to previous capture
+                ALOGD("skipping frame, timeUs %lld", static_cast<long long>(timeUs));
+                return false;
+            }
+            // snap to nearest capture point
+            if (nFrames <= 1.0) {
+                nFrames = 1.0;
+            }
+            mFrameCount += std::llround(nFrames);
+            mPrevCaptureUs = mBaseCaptureUs + std::llround(mFrameCount * 1000000 / mCaptureFps);
+            mPrevFrameUs = mBaseFrameUs + std::llround(mFrameCount * 1000000 / mFps);
+        } else {
+            if (timeUs <= mPrevCaptureUs) {
+                if (mFrameDropper != NULL && mFrameDropper->disabled()) {
+                    // Warn only, client has disabled frame drop logic possibly for image
+                    // encoding cases where camera's ZSL mode could send out of order frames.
+                    ALOGW("Received frame that's going backward in time");
+                } else {
+                    // Drop the frame if it's going backward in time. Bad timestamp
+                    // could disrupt encoder's rate control completely.
+                    ALOGW("Dropping frame that's going backward in time");
+                    return false;
+                }
+            }
+            mPrevCaptureUs = timeUs;
+            mPrevFrameUs =
+                    mBaseFrameUs + std::llround((timeUs - mBaseCaptureUs) * (mCaptureFps / mFps));
+        }
+
+        ALOGV("timeUs %lld, captureUs %lld, frameUs %lld", static_cast<long long>(timeUs),
+              static_cast<long long>(mPrevCaptureUs), static_cast<long long>(mPrevFrameUs));
+    } else {
+        if (timeUs <= mPrevFrameUs) {
+            if (mFrameDropper != NULL && mFrameDropper->disabled()) {
+                // Warn only, client has disabled frame drop logic possibly for image
+                // encoding cases where camera's ZSL mode could send out of order frames.
+                ALOGW("Received frame that's going backward in time");
+            } else {
+                // Drop the frame if it's going backward in time. Bad timestamp
+                // could disrupt encoder's rate control completely.
+                ALOGW("Dropping frame that's going backward in time");
+                return false;
+            }
+        }
+
+        mPrevFrameUs = timeUs;
+    }
+
+    *codecTimeUs = mPrevFrameUs;
+    return true;
+}
+
+status_t GraphicBufferSource::submitBuffer_l(const VideoBuffer& item) {
+    CHECK(!mFreeCodecBuffers.empty());
+    uint32_t codecBufferId = *mFreeCodecBuffers.begin();
+
+    ALOGV("submitBuffer_l [bufferId=%" PRIu64 ", codecBufferId=%d]", item.mBuffer->getId(),
+        codecBufferId);
+
+    int64_t codecTimeUs;
+    if (!calculateCodecTimestamp_l(item.mTimestampNs, &codecTimeUs)) {
+        return UNKNOWN_ERROR;
+    }
+
+    if ((android_dataspace)item.mDataspace != mLastDataspace) {
+        onDataspaceChanged_l(item.mDataspace,
+                             (android_pixel_format)item.mBuffer->getGraphicBuffer()->format);
+    }
+
+    std::shared_ptr<AcquiredBuffer> buffer = item.mBuffer;
+    // use a GraphicBuffer for now as component is using GraphicBuffers to hold references
+    // and it requires this graphic buffer to be able to hold its reference
+    // and thus we would need to create a new GraphicBuffer from an ANWBuffer separate from the
+    // acquired GraphicBuffer.
+    // TODO: this can be reworked globally to use ANWBuffer references
+    sp<GraphicBuffer> graphicBuffer = buffer->getGraphicBuffer();
+    status_t err = mComponent->submitBuffer(codecBufferId, graphicBuffer, codecTimeUs,
+                                            buffer->getAcquireFenceFd());
+
+    if (err != OK) {
+        ALOGW("WARNING: emptyGraphicBuffer failed: 0x%x", err);
+        return err;
+    }
+
+    mFreeCodecBuffers.erase(mFreeCodecBuffers.begin());
+
+    ssize_t cbix = mSubmittedCodecBuffers.add(codecBufferId, buffer);
+    ALOGV("emptyGraphicBuffer succeeded, bufferId=%u@%zd bufhandle=%p", codecBufferId, cbix,
+          graphicBuffer->handle);
+    return OK;
+}
+
+void GraphicBufferSource::submitEndOfInputStream_l() {
+    CHECK(mEndOfStream);
+    if (mEndOfStreamSent) {
+        ALOGV("EOS already sent");
+        return;
+    }
+
+    if (mFreeCodecBuffers.empty()) {
+        ALOGV("submitEndOfInputStream_l: no codec buffers available");
+        return;
+    }
+    uint32_t codecBufferId = *mFreeCodecBuffers.begin();
+
+    // We reject any additional incoming graphic buffers. There is no acquired buffer used for EOS
+    status_t err = mComponent->submitEos(codecBufferId);
+    if (err != OK) {
+        ALOGW("emptyDirectBuffer EOS failed: 0x%x", err);
+    } else {
+        mFreeCodecBuffers.erase(mFreeCodecBuffers.begin());
+        ssize_t cbix = mSubmittedCodecBuffers.add(codecBufferId, nullptr);
+        ALOGV("submitEndOfInputStream_l: buffer submitted, bufferId=%u@%zd", codecBufferId, cbix);
+        mEndOfStreamSent = true;
+
+        // no need to hold onto any buffers for frame repeating
+        ++mRepeatLastFrameGeneration;
+        mLatestBuffer.mBuffer.reset();
+    }
+}
+
+status_t GraphicBufferSource::acquireBuffer_l(VideoBuffer* ab) {
+    BufferItem bi;
+    status_t err = mBufferItemConsumer->acquireBuffer(&bi, 0);
+    if (err == BufferQueue::NO_BUFFER_AVAILABLE) {
+        // shouldn't happen
+        ALOGW("acquireBuffer_l: frame was not available");
+        return err;
+    } else if (err != OK) {
+        ALOGW("acquireBuffer_l: failed with err=%d", err);
+        return err;
+    }
+    --mNumAvailableUnacquiredBuffers;
+    std::shared_ptr<Buffer> buffer = std::make_shared<Buffer>(bi.mGraphicBuffer);
+
+    std::shared_ptr<AcquiredBuffer> acquiredBuffer = std::make_shared<AcquiredBuffer>(
+            buffer,
+            [this](AcquiredBuffer* buffer) {
+                // AcquiredBuffer's destructor should always be called when mMutex is locked.
+                // If we had a reentrant mutex, we could just lock it again to ensure this.
+                if (mMutex.tryLock() == 0) {
+                    TRESPASS_DBG();
+                    mMutex.unlock();
+                }
+
+                --mNumOutstandingAcquires;
+                mBufferItemConsumer->releaseBuffer(buffer->getGraphicBuffer(),
+                                                   buffer->getReleaseFence());
+            },
+            bi.mFence);
+    VideoBuffer videoBuffer{acquiredBuffer, bi.mTimestamp, bi.mDataSpace};
+    *ab = videoBuffer;
+    ++mNumOutstandingAcquires;
+    return OK;
+}
+
+// ConsumerBase::FrameAvailableListener callback
+void GraphicBufferSource::onFrameAvailable() {
+    Mutex::Autolock autoLock(mMutex);
+
+    ALOGV("onFrameAvailable: executing=%d available=%zu+%d", mExecuting, mAvailableBuffers.size(),
+          mNumAvailableUnacquiredBuffers);
+    ++mNumAvailableUnacquiredBuffers;
+
+    // For BufferQueue we cannot acquire a buffer if we cannot immediately feed it to the codec
+    // UNLESS we are discarding this buffer (acquiring and immediately releasing it), which makes
+    // this an ugly logic.
+    // NOTE: We could also rely on our debug counter but that is meant only as a debug counter.
+    if (!areWeDiscardingAvailableBuffers_l() && mFreeCodecBuffers.empty()) {
+        // we may not be allowed to acquire a possibly encodable buffer, so just note that
+        // it is available
+        ALOGV("onFrameAvailable: cannot acquire buffer right now, do it later");
+
+        ++mRepeatLastFrameGeneration;  // cancel any pending frame repeat
+        return;
+    }
+
+    VideoBuffer buffer;
+    status_t err = acquireBuffer_l(&buffer);
+    if (err != OK) {
+        ALOGE("onFrameAvailable: acquireBuffer returned err=%d", err);
+    } else {
+        onBufferAcquired_l(buffer);
+    }
+}
+
+bool GraphicBufferSource::areWeDiscardingAvailableBuffers_l() {
+    return mEndOfStreamSent                         // already sent EOS to codec
+           || mComponent == nullptr                 // there is no codec connected
+           || (mSuspended && mActionQueue.empty())  // we are suspended and not waiting for
+                                                    // any further action
+           || !mExecuting;
+}
+
+void GraphicBufferSource::onBufferAcquired_l(const VideoBuffer& buffer) {
+    if (mEndOfStreamSent) {
+        // This should only be possible if a new buffer was queued after
+        // EOS was signaled, i.e. the app is misbehaving.
+        ALOGW("onFrameAvailable: EOS is sent, ignoring frame");
+    } else if (mComponent == NULL || (mSuspended && mActionQueue.empty())) {
+        // FIXME: if we are suspended but have a resume queued we will stop repeating the last
+        // frame. Is that the desired behavior?
+        ALOGV("onFrameAvailable: suspended, ignoring frame");
+    } else {
+        ++mRepeatLastFrameGeneration;  // cancel any pending frame repeat
+        mAvailableBuffers.push_back(buffer);
+        if (mExecuting) {
+            fillCodecBuffer_l();
+        }
+    }
+}
+
+void GraphicBufferSource::releaseAllAvailableBuffers_l() {
+    mAvailableBuffers.clear();
+    while (mNumAvailableUnacquiredBuffers > 0) {
+        VideoBuffer item;
+        if (acquireBuffer_l(&item) != OK) {
+            ALOGW("releaseAllAvailableBuffers: failed to acquire available unacquired buffer");
+            break;
+        }
+    }
+}
+
+status_t GraphicBufferSource::configure(const sp<ComponentWrapper>& component, int32_t dataSpace,
+                                        int32_t bufferCount, uint32_t frameWidth,
+                                        uint32_t frameHeight, uint32_t consumerUsage) {
+    uint64_t consumerUsage64 = static_cast<uint64_t>(consumerUsage);
+    return configure(component, dataSpace, bufferCount, frameWidth, frameHeight, consumerUsage64);
+}
+
+status_t GraphicBufferSource::configure(const sp<ComponentWrapper>& component, int32_t dataSpace,
+                                        int32_t bufferCount, uint32_t frameWidth,
+                                        uint32_t frameHeight, uint64_t consumerUsage) {
+    if (component == NULL) {
+        return BAD_VALUE;
+    }
+
+    // Call setMaxAcquiredBufferCount without lock.
+    // setMaxAcquiredBufferCount could call back to onBuffersReleased
+    // if the buffer count change results in releasing of existing buffers,
+    // which would lead to deadlock.
+    status_t err = mBufferItemConsumer->setMaxAcquiredBufferCount(bufferCount);
+    if (err != NO_ERROR) {
+        ALOGE("Unable to set BQ max acquired buffer count to %u: %d", bufferCount, err);
+        return err;
+    }
+
+    {
+        Mutex::Autolock autoLock(mMutex);
+        mComponent = component;
+
+        err = mBufferItemConsumer->setDefaultBufferSize(frameWidth, frameHeight);
+        if (err != NO_ERROR) {
+            ALOGE("Unable to set BQ default buffer size to %ux%u: %d", frameWidth, frameHeight,
+                  err);
+            return err;
+        }
+
+        consumerUsage |= GRALLOC_USAGE_HW_VIDEO_ENCODER;
+        mBufferItemConsumer->setConsumerUsageBits(consumerUsage);
+
+        // Set impl. defined format as default. Depending on the usage flags
+        // the device-specific implementation will derive the exact format.
+        err = mBufferItemConsumer->setDefaultBufferFormat(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
+        if (err != NO_ERROR) {
+            ALOGE("Failed to configure surface default format ret: %d", err);
+            return err;
+        }
+
+        // Sets the default buffer data space
+        ALOGD("setting dataspace: %#x, acquired=%d", dataSpace, mNumOutstandingAcquires);
+        mBufferItemConsumer->setDefaultBufferDataSpace((android_dataspace)dataSpace);
+        mLastDataspace = (android_dataspace)dataSpace;
+
+        mExecuting = false;
+        mSuspended = false;
+        mEndOfStream = false;
+        mEndOfStreamSent = false;
+        mSkipFramesBeforeNs = -1LL;
+        mFrameDropper.clear();
+        mFrameRepeatIntervalUs = -1LL;
+        mRepeatLastFrameGeneration = 0;
+        mOutstandingFrameRepeatCount = 0;
+        mLatestBuffer.mBuffer.reset();
+        mFrameRepeatBlockedOnCodecBuffer = false;
+        mFps = -1.0;
+        mCaptureFps = -1.0;
+        mBaseCaptureUs = -1LL;
+        mBaseFrameUs = -1LL;
+        mPrevCaptureUs = -1LL;
+        mPrevFrameUs = -1LL;
+        mFrameCount = 0;
+        mInputBufferTimeOffsetUs = 0;
+        mStopTimeUs = -1;
+        mActionQueue.clear();
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setSuspend(bool suspend, int64_t suspendStartTimeUs) {
+    ALOGV("setSuspend=%d at time %lld us", suspend, (long long)suspendStartTimeUs);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mStopTimeUs != -1) {
+        ALOGE("setSuspend failed as STOP action is pending");
+        return INVALID_OPERATION;
+    }
+
+    // Push the action to the queue.
+    if (suspendStartTimeUs != -1) {
+        // suspendStartTimeUs must be smaller or equal to current systemTime.
+        int64_t currentSystemTimeUs = systemTime() / 1000;
+        if (suspendStartTimeUs > currentSystemTimeUs) {
+            ALOGE("setSuspend failed. %lld is larger than current system time %lld us",
+                  (long long)suspendStartTimeUs, (long long)currentSystemTimeUs);
+            return INVALID_OPERATION;
+        }
+        if (mLastActionTimeUs != -1 && suspendStartTimeUs < mLastActionTimeUs) {
+            ALOGE("setSuspend failed. %lld is smaller than last action time %lld us",
+                  (long long)suspendStartTimeUs, (long long)mLastActionTimeUs);
+            return INVALID_OPERATION;
+        }
+        mLastActionTimeUs = suspendStartTimeUs;
+        ActionItem action;
+        action.mAction = suspend ? ActionItem::PAUSE : ActionItem::RESUME;
+        action.mActionTimeUs = suspendStartTimeUs;
+        ALOGV("Push %s action into actionQueue", suspend ? "PAUSE" : "RESUME");
+        mActionQueue.push_back(action);
+    } else {
+        if (suspend) {
+            mSuspended = true;
+            releaseAllAvailableBuffers_l();
+            return OK;
+        } else {
+            mSuspended = false;
+            if (mExecuting && !haveAvailableBuffers_l() && mFrameRepeatBlockedOnCodecBuffer) {
+                if (repeatLatestBuffer_l()) {
+                    ALOGV("suspend/deferred repeatLatestBuffer_l SUCCESS");
+                    mFrameRepeatBlockedOnCodecBuffer = false;
+                } else {
+                    ALOGV("suspend/deferred repeatLatestBuffer_l FAILURE");
+                }
+            }
+        }
+    }
+    return OK;
+}
+
+status_t GraphicBufferSource::setRepeatPreviousFrameDelayUs(int64_t repeatAfterUs) {
+    ALOGV("setRepeatPreviousFrameDelayUs: delayUs=%lld", (long long)repeatAfterUs);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting || repeatAfterUs <= 0LL) {
+        return INVALID_OPERATION;
+    }
+
+    mFrameRepeatIntervalUs = repeatAfterUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::setTimeOffsetUs(int64_t timeOffsetUs) {
+    Mutex::Autolock autoLock(mMutex);
+
+    // timeOffsetUs must be negative for adjustment.
+    if (timeOffsetUs >= 0LL) {
+        return INVALID_OPERATION;
+    }
+
+    mInputBufferTimeOffsetUs = timeOffsetUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::setMaxFps(float maxFps) {
+    ALOGV("setMaxFps: maxFps=%lld", (long long)maxFps);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting) {
+        return INVALID_OPERATION;
+    }
+
+    mFrameDropper = new FrameDropper();
+    status_t err = mFrameDropper->setMaxFrameRate(maxFps);
+    if (err != OK) {
+        mFrameDropper.clear();
+        return err;
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setStartTimeUs(int64_t skipFramesBeforeUs) {
+    ALOGV("setStartTimeUs: skipFramesBeforeUs=%lld", (long long)skipFramesBeforeUs);
+
+    Mutex::Autolock autoLock(mMutex);
+
+    mSkipFramesBeforeNs = (skipFramesBeforeUs > 0 && skipFramesBeforeUs <= INT64_MAX / 1000)
+                                  ? (skipFramesBeforeUs * 1000)
+                                  : -1LL;
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setStopTimeUs(int64_t stopTimeUs) {
+    ALOGV("setStopTimeUs: %lld us", (long long)stopTimeUs);
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mStopTimeUs != -1) {
+        // Ignore if stop time has already been set
+        return OK;
+    }
+
+    // stopTimeUs must be smaller or equal to current systemTime.
+    int64_t currentSystemTimeUs = systemTime() / 1000;
+    if (stopTimeUs > currentSystemTimeUs) {
+        ALOGE("setStopTimeUs failed. %lld is larger than current system time %lld us",
+              (long long)stopTimeUs, (long long)currentSystemTimeUs);
+        return INVALID_OPERATION;
+    }
+    if (mLastActionTimeUs != -1 && stopTimeUs < mLastActionTimeUs) {
+        ALOGE("setSuspend failed. %lld is smaller than last action time %lld us",
+              (long long)stopTimeUs, (long long)mLastActionTimeUs);
+        return INVALID_OPERATION;
+    }
+    mLastActionTimeUs = stopTimeUs;
+    ActionItem action;
+    action.mAction = ActionItem::STOP;
+    action.mActionTimeUs = stopTimeUs;
+    mActionQueue.push_back(action);
+    mStopTimeUs = stopTimeUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::getStopTimeOffsetUs(int64_t* stopTimeOffsetUs) {
+    ALOGV("getStopTimeOffsetUs");
+    Mutex::Autolock autoLock(mMutex);
+    if (mStopTimeUs == -1) {
+        ALOGW("Fail to return stopTimeOffsetUs as stop time is not set");
+        return INVALID_OPERATION;
+    }
+    *stopTimeOffsetUs = mLastFrameTimestampUs == -1 ? 0 : mStopTimeUs - mLastFrameTimestampUs;
+    return OK;
+}
+
+status_t GraphicBufferSource::setTimeLapseConfig(double fps, double captureFps) {
+    ALOGV("setTimeLapseConfig: fps=%lg, captureFps=%lg", fps, captureFps);
+    Mutex::Autolock autoLock(mMutex);
+
+    if (mExecuting || !(fps > 0) || !(captureFps > 0)) {
+        return INVALID_OPERATION;
+    }
+
+    mFps = fps;
+    mCaptureFps = captureFps;
+    if (captureFps > fps) {
+        mSnapTimestamps =
+                1 == base::GetIntProperty("debug.stagefright.snap_timestamps", int64_t(0));
+    } else {
+        mSnapTimestamps = false;
+    }
+
+    return OK;
+}
+
+status_t GraphicBufferSource::setColorAspects(int32_t aspectsPacked) {
+    Mutex::Autolock autoLock(mMutex);
+    mDefaultColorAspectsPacked = aspectsPacked;
+    ColorAspects colorAspects = ColorUtils::unpackToColorAspects(aspectsPacked);
+    ALOGD("requesting color aspects (R:%d(%s), P:%d(%s), M:%d(%s), T:%d(%s))", colorAspects.mRange,
+          asString(colorAspects.mRange), colorAspects.mPrimaries, asString(colorAspects.mPrimaries),
+          colorAspects.mMatrixCoeffs, asString(colorAspects.mMatrixCoeffs), colorAspects.mTransfer,
+          asString(colorAspects.mTransfer));
+
+    return OK;
+}
+
+status_t GraphicBufferSource::signalEndOfInputStream() {
+    Mutex::Autolock autoLock(mMutex);
+    ALOGV("signalEndOfInputStream: executing=%d available=%zu+%d eos=%d", mExecuting,
+          mAvailableBuffers.size(), mNumAvailableUnacquiredBuffers, mEndOfStream);
+
+    if (mEndOfStream) {
+        ALOGE("EOS was already signaled");
+        return INVALID_OPERATION;
+    }
+
+    // Set the end-of-stream flag.  If no frames are pending from the
+    // BufferQueue, and a codec buffer is available, and we're executing,
+    // and there is no stop timestamp, we initiate the EOS from here.
+    // Otherwise, we'll let codecBufferEmptied() (or start) do it.
+    //
+    // Note: if there are no pending frames and all codec buffers are
+    // available, we *must* submit the EOS from here or we'll just
+    // stall since no future events are expected.
+    mEndOfStream = true;
+
+    if (mStopTimeUs == -1 && mExecuting && !haveAvailableBuffers_l()) {
+        submitEndOfInputStream_l();
+    }
+
+    return OK;
+}
+
+void GraphicBufferSource::onMessageReceived(const sp<AMessage>& msg) {
+    switch (msg->what()) {
+        case kWhatRepeatLastFrame: {
+            Mutex::Autolock autoLock(mMutex);
+
+            int32_t generation;
+            CHECK(msg->findInt32("generation", &generation));
+
+            if (generation != mRepeatLastFrameGeneration) {
+                // stale
+                break;
+            }
+
+            if (!mExecuting || haveAvailableBuffers_l()) {
+                break;
+            }
+
+            bool success = repeatLatestBuffer_l();
+            if (success) {
+                ALOGV("repeatLatestBuffer_l SUCCESS");
+            } else {
+                ALOGV("repeatLatestBuffer_l FAILURE");
+                mFrameRepeatBlockedOnCodecBuffer = true;
+            }
+            break;
+        }
+
+        default:
+            TRESPASS();
+    }
+}
+
+}  // namespace android
diff --git a/media/module/bqhelper/include/media/stagefright/bqhelper/GraphicBufferSource.h b/media/module/bqhelper/include/media/stagefright/bqhelper/GraphicBufferSource.h
index 5225a48057..1521ef31df 100644
--- a/media/module/bqhelper/include/media/stagefright/bqhelper/GraphicBufferSource.h
+++ b/media/module/bqhelper/include/media/stagefright/bqhelper/GraphicBufferSource.h
@@ -20,6 +20,7 @@
 
 #include <binder/Status.h>
 #include <utils/RefBase.h>
+#include <com_android_graphics_libgui_flags.h> // Remove with WB_MEDIA_MIGRATION.
 
 #include <media/hardware/VideoAPI.h>
 #include <media/stagefright/foundation/ABase.h>
@@ -27,14 +28,19 @@
 #include <media/stagefright/foundation/ALooper.h>
 #include <media/stagefright/bqhelper/ComponentWrapper.h>
 #include <android/hardware/graphics/bufferqueue/1.0/IGraphicBufferProducer.h>
-#include <android/hardware/graphics/bufferqueue/2.0/IGraphicBufferProducer.h>
 
 namespace android {
 
 struct FrameDropper;
 class BufferItem;
 class IGraphicBufferProducer;
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+class Surface;
+class BufferItemConsumer;
+#else
 class IGraphicBufferConsumer;
+#endif
+
 /*
  * This class is used to feed codecs from a Surface via BufferQueue or
  * HW producer.
@@ -71,14 +77,23 @@ class IGraphicBufferConsumer;
 class GraphicBufferSource : public RefBase {
 public:
     GraphicBufferSource();
-
     virtual ~GraphicBufferSource();
 
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    void onFirstRef() override;
+
+    // Current version does not have a way to set this to false.
+    [[deprecated("Will never return false.")]]
+    status_t initCheck() const {
+        return OK;
+    }
+#else
     // We can't throw an exception if the constructor fails, so we just set
     // this and require that the caller test the value.
     status_t initCheck() const {
         return mInitCheck;
     }
+#endif
 
     // Returns the handle to the producer side of the BufferQueue.  Buffers
     // queued on this will be received by GraphicBufferSource.
@@ -89,11 +104,6 @@ public:
     sp<::android::hardware::graphics::bufferqueue::V1_0::IGraphicBufferProducer>
         getHGraphicBufferProducer_V1_0() const;
 
-    // Returns the handle to the bufferqueue HAL producer side of the BufferQueue.
-    // Buffers queued on this will be received by GraphicBufferSource.
-    sp<::android::hardware::graphics::bufferqueue::V2_0::IGraphicBufferProducer>
-        getHGraphicBufferProducer() const;
-
     // This is called when component transitions to running state, which means
     // we can start handing it buffers.  If we already have buffers of data
     // sitting in the BufferQueue, this will send them to the codec.
@@ -210,7 +220,17 @@ public:
     status_t setColorAspects(int32_t aspectsPacked);
 
 protected:
-
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    // ConsumerBase::FrameAvailableListener interface, called when a new frame of
+    // data is available.  If we're executing and a codec buffer is
+    // available, we acquire the buffer, copy the GraphicBuffer reference
+    // into the codec buffer, and call Empty[This]Buffer.
+    void onFrameAvailable();
+    // Similar to onFrameAvailable, but buffer item is indeed replacing a buffer
+    // in the buffer queue. This can happen when buffer queue is in droppable
+    // mode.
+    void onFrameReplaced();
+#else
     // BufferQueue::ConsumerListener interface, called when a new frame of
     // data is available.  If we're executing and a codec buffer is
     // available, we acquire the buffer, copy the GraphicBuffer reference
@@ -228,7 +248,7 @@ protected:
     // changed the sideband stream. GraphicBufferSource doesn't handle sideband
     // streams so this is a no-op (and should never be called).
     void onSidebandStreamChanged() ;
-
+#endif
 private:
     // BQ::ConsumerListener interface
     // ------------------------------
@@ -238,8 +258,10 @@ private:
     // Lock, covers all member variables.
     mutable Mutex mMutex;
 
+#if not COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
     // Used to report constructor failure.
     status_t mInitCheck;
+#endif
 
     // Graphic buffer reference objects
     // --------------------------------
@@ -250,8 +272,12 @@ private:
 
     // When we get a buffer from the producer (BQ) it designates them to be cached into specific
     // slots. Each slot owns a shared reference to the graphic buffer (we track these using
-    // CachedBuffer) that is in that slot, but the producer controls the slots.
+    // Buffer) that is in that slot, but the producer controls the slots.
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    struct Buffer;
+#else
     struct CachedBuffer;
+#endif
 
     // When we acquire a buffer, we must release it back to the producer once we (or the codec)
     // no longer uses it (as long as the buffer is still in the cache slot). We use shared
@@ -267,6 +293,7 @@ private:
         android_dataspace_t mDataspace;
     };
 
+#if not COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
     // Cached and aquired buffers
     // --------------------------------
 
@@ -274,6 +301,7 @@ private:
 
     // Maps a slot to the cached buffer in that slot
     KeyedVector<slot_id, std::shared_ptr<CachedBuffer>> mBufferSlots;
+#endif
 
     // Queue of buffers acquired in chronological order that are not yet submitted to the codec
     List<VideoBuffer> mAvailableBuffers;
@@ -293,6 +321,7 @@ private:
     // Called when a buffer was acquired from the producer
     void onBufferAcquired_l(const VideoBuffer &buffer);
 
+#if not COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
     // marks the buffer at the slot no longer cached, and accounts for the outstanding
     // acquire count. Returns true if the slot was populated; otherwise, false.
     bool discardBufferInSlot_l(slot_id i);
@@ -300,6 +329,7 @@ private:
     // marks the buffer at the slot index no longer cached, and accounts for the outstanding
     // acquire count
     void discardBufferAtSlotIndex_l(ssize_t bsi);
+#endif
 
     // release all acquired and unacquired available buffers
     // This method will return if it fails to acquire an unacquired available buffer, which will
@@ -315,7 +345,7 @@ private:
     // -------------
 
     // When we queue buffers to the encoder, we must hold the references to the graphic buffers
-    // in those buffers - as the producer may free the slots.
+    // in those buffers.
 
     typedef int32_t codec_buffer_id;
 
@@ -379,11 +409,16 @@ private:
 
     int64_t mLastFrameTimestampUs;
 
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+    sp<BufferItemConsumer> mBufferItemConsumer;
+    sp<Surface> mSurface;
+#else
     // Our BufferQueue interfaces. mProducer is passed to the producer through
     // getIGraphicBufferProducer, and mConsumer is used internally to retrieve
     // the buffers queued by the producer.
     sp<IGraphicBufferProducer> mProducer;
     sp<IGraphicBufferConsumer> mConsumer;
+#endif
 
     // The time to stop sending buffers.
     int64_t mStopTimeUs;
diff --git a/media/module/codecserviceregistrant/Android.bp b/media/module/codecserviceregistrant/Android.bp
index 1d1dd714a7..76dc373858 100644
--- a/media/module/codecserviceregistrant/Android.bp
+++ b/media/module/codecserviceregistrant/Android.bp
@@ -10,41 +10,42 @@ cc_defaults {
     name: "libcodec2-runtime-libs",
     // Codecs
     runtime_libs: [
-        "libcodec2_soft_avcdec",
-        "libcodec2_soft_avcenc",
         "libcodec2_soft_aacdec",
         "libcodec2_soft_aacenc",
         "libcodec2_soft_amrnbdec",
         "libcodec2_soft_amrnbenc",
         "libcodec2_soft_amrwbdec",
         "libcodec2_soft_amrwbenc",
-        "libcodec2_soft_hevcdec",
-        "libcodec2_soft_hevcenc",
+        "libcodec2_soft_apvdec",
+        "libcodec2_soft_apvenc",
+        "libcodec2_soft_av1dec_dav1d",
+        // "libcodec2_soft_av1dec_aom",  // replaced by the gav1 implementation
+        "libcodec2_soft_av1dec_gav1",
+        "libcodec2_soft_av1enc",
+        "libcodec2_soft_avcdec",
+        "libcodec2_soft_avcenc",
+        "libcodec2_soft_flacdec",
+        "libcodec2_soft_flacenc",
         "libcodec2_soft_g711alawdec",
         "libcodec2_soft_g711mlawdec",
-        "libcodec2_soft_mpeg2dec",
+        "libcodec2_soft_gsmdec",
         "libcodec2_soft_h263dec",
         "libcodec2_soft_h263enc",
+        "libcodec2_soft_hevcdec",
+        "libcodec2_soft_hevcenc",
+        "libcodec2_soft_iamfdec",
+        "libcodec2_soft_mp3dec",
+        "libcodec2_soft_mpeg2dec",
         "libcodec2_soft_mpeg4dec",
         "libcodec2_soft_mpeg4enc",
-        "libcodec2_soft_mp3dec",
-        "libcodec2_soft_vorbisdec",
         "libcodec2_soft_opusdec",
         "libcodec2_soft_opusenc",
+        "libcodec2_soft_rawdec",
+        "libcodec2_soft_vorbisdec",
         "libcodec2_soft_vp8dec",
-        "libcodec2_soft_vp9dec",
-        // "libcodec2_soft_av1dec_aom",  // replaced by the gav1 implementation
-        "libcodec2_soft_av1dec_gav1",
-        "libcodec2_soft_av1dec_dav1d",
-        "libcodec2_soft_av1enc",
         "libcodec2_soft_vp8enc",
+        "libcodec2_soft_vp9dec",
         "libcodec2_soft_vp9enc",
-        "libcodec2_soft_rawdec",
-        "libcodec2_soft_flacdec",
-        "libcodec2_soft_flacenc",
-        "libcodec2_soft_gsmdec",
-        "libcodec2_soft_apvenc",
-        "libcodec2_soft_apvdec",
     ],
 }
 
diff --git a/media/module/extractors/mp4/ItemTable.cpp b/media/module/extractors/mp4/ItemTable.cpp
index c6586fcbd9..0680a3761c 100644
--- a/media/module/extractors/mp4/ItemTable.cpp
+++ b/media/module/extractors/mp4/ItemTable.cpp
@@ -17,6 +17,7 @@
 //#define LOG_NDEBUG 0
 #define LOG_TAG "ItemTable"
 
+#include <algorithm>
 #include <unordered_set>
 
 #include <HeifCleanAperture.h>
diff --git a/media/module/extractors/mp4/MPEG4Extractor.cpp b/media/module/extractors/mp4/MPEG4Extractor.cpp
index 0695ceb674..aa9a924f5c 100644
--- a/media/module/extractors/mp4/MPEG4Extractor.cpp
+++ b/media/module/extractors/mp4/MPEG4Extractor.cpp
@@ -4579,6 +4579,11 @@ MediaTrackHelper *MPEG4Extractor::getTrack(size_t index) {
         return NULL;
     }
 
+    // Check if the track's timescale is within the valid range of std::int32_t.
+    if (track->timescale >= std::numeric_limits<std::int32_t>::max()) {
+        ALOGE("track->timescale overflow");
+        return NULL;
+    }
 
     Trex *trex = NULL;
     int32_t trackId;
diff --git a/media/module/libapexcodecs/Android.bp b/media/module/libapexcodecs/Android.bp
index 27c1d22114..c0c53c53be 100644
--- a/media/module/libapexcodecs/Android.bp
+++ b/media/module/libapexcodecs/Android.bp
@@ -21,18 +21,16 @@ package {
 cc_defaults {
     name: "libcom.android.media.swcodec.apexcodecs-defaults",
 
-    defaults: [
-        "libcodec2-internal-defaults",
-    ],
-
     header_libs: [
         "libbase_headers",
+        "libcodec2_internal",
     ],
 
     srcs: ["ApexCodecs.cpp"],
 
     shared_libs: [
         "libbase",
+        "libcodec2",
         "libnativewindow",
     ],
 
diff --git a/media/module/libapexcodecs/ApexCodecs.cpp b/media/module/libapexcodecs/ApexCodecs.cpp
index 8dec43974c..738bb2b0fe 100644
--- a/media/module/libapexcodecs/ApexCodecs.cpp
+++ b/media/module/libapexcodecs/ApexCodecs.cpp
@@ -22,7 +22,9 @@
 #include <map>
 #include <vector>
 
+#include <C2Param.h>
 #include <C2ParamInternal.h>
+#include <C2Work.h>
 #include <android_media_swcodec_flags.h>
 
 #include <android-base/no_destructor.h>
@@ -36,11 +38,90 @@
 
 using ::android::apexcodecs::ApexComponentIntf;
 using ::android::apexcodecs::ApexComponentStoreIntf;
+using ::android::apexcodecs::ApexConfigurableIntf;
 using ::android::base::ERROR;
 
+struct ApexCodec_Configurable {
+    ApexCodec_Configurable(
+            std::unique_ptr<ApexConfigurableIntf> &&configurable,
+            const std::shared_ptr<C2ParamReflector> &reflector)
+        : mConfigurable(std::move(configurable)),
+          mReflector(reflector) {
+    }
+
+    ApexCodec_Status config(
+            ApexCodec_LinearBuffer *params,
+            ApexCodec_SettingResults **results);
+
+    ApexCodec_Status query(
+            uint32_t indices[],
+            size_t numIndices,
+            ApexCodec_LinearBuffer *config,
+            size_t *writtenOrRequired);
+
+    ApexCodec_Status querySupportedParams(
+            ApexCodec_ParamDescriptors **descriptors);
+
+    ApexCodec_Status querySupportedValues(
+            ApexCodec_SupportedValuesQuery *queries,
+            size_t numQueries);
+
+private:
+    std::unique_ptr<ApexConfigurableIntf> mConfigurable;
+    std::shared_ptr<C2ParamReflector> mReflector;
+
+    uint32_t findSize(C2Param::Index index, uint32_t offset) {
+        // NOTE: we probably could cache the (index, offset) -> size mapping
+        if (mReflector == nullptr) {
+            return 0;
+        }
+        std::shared_ptr<C2StructDescriptor> structDesc = mReflector->describe(index);
+        if (structDesc == nullptr) {
+            return 0;
+        }
+        for (const C2FieldDescriptor &fieldDesc : *structDesc) {
+            if (_C2ParamInspector::GetOffset(fieldDesc) == offset) {
+                return _C2ParamInspector::GetSize(fieldDesc);
+            }
+        }
+        return 0;
+    }
+};
+
+struct ApexCodec_ParamDescriptors {
+public:
+    explicit ApexCodec_ParamDescriptors(
+            const std::vector<std::shared_ptr<C2ParamDescriptor>> &paramDescriptors);
+
+    ~ApexCodec_ParamDescriptors() = default;
+
+    ApexCodec_Status getIndices(uint32_t **indices, size_t *numIndices);
+
+    ApexCodec_Status getDescriptor(
+            uint32_t index,
+            ApexCodec_ParamAttribute *attr,
+            const char **name,
+            uint32_t **dependencies,
+            size_t *numDependencies);
+
+private:
+    struct Entry {
+        uint32_t index;
+        ApexCodec_ParamAttribute attr;
+        C2String name;
+        std::vector<uint32_t> dependencies;
+    };
+    std::map<uint32_t, Entry> mDescriptors;
+    std::vector<uint32_t> mIndices;
+};
+
 struct ApexCodec_Component {
-    explicit ApexCodec_Component(std::unique_ptr<ApexComponentIntf> &&comp)
+    ApexCodec_Component(
+            std::unique_ptr<ApexComponentIntf> &&comp,
+            const std::shared_ptr<C2ParamReflector> &reflector)
         : mComponent(std::move(comp)) {
+        mConfigurable.reset(new ApexCodec_Configurable(
+                mComponent->getConfigurable(), reflector));
     }
 
     ApexCodec_Status start() {
@@ -55,8 +136,25 @@ struct ApexCodec_Component {
         return mComponent->reset();
     }
 
+    ApexCodec_Configurable *getConfigurable() {
+        return mConfigurable.get();
+    }
+
+    ApexCodec_Status process(
+            const ApexCodec_Buffer *input,
+            ApexCodec_Buffer *output,
+            size_t *consumed,
+            size_t *produced) {
+        if (input == nullptr || output == nullptr || consumed == nullptr || produced == nullptr) {
+            return APEXCODEC_STATUS_BAD_VALUE;
+        }
+        return mComponent->process(input, output, consumed, produced);
+    }
+
+
 private:
     std::unique_ptr<ApexComponentIntf> mComponent;
+    std::unique_ptr<ApexCodec_Configurable> mConfigurable;
 };
 
 struct ApexCodec_ComponentStore {
@@ -93,6 +191,14 @@ struct ApexCodec_ComponentStore {
         }
         return mStore->createComponent(name);
     }
+
+    std::shared_ptr<C2ParamReflector> getParamReflector() const {
+        if (mStore == nullptr) {
+            return nullptr;
+        }
+        return mStore->getParamReflector();
+    }
+
 private:
     ApexComponentStoreIntf *mStore;
     std::vector<std::shared_ptr<const C2Component::Traits>> mC2Traits;
@@ -100,7 +206,7 @@ private:
 };
 
 ApexCodec_ComponentStore *ApexCodec_GetComponentStore() {
-    ::android::base::NoDestructor<ApexCodec_ComponentStore> store;
+    static ::android::base::NoDestructor<ApexCodec_ComponentStore> store;
     return store.get();
 }
 
@@ -134,7 +240,7 @@ ApexCodec_Status ApexCodec_Component_create(
     if (compIntf == nullptr) {
         return APEXCODEC_STATUS_NOT_FOUND;
     }
-    *comp = new ApexCodec_Component(std::move(compIntf));
+    *comp = new ApexCodec_Component(std::move(compIntf), store->getParamReflector());
     return APEXCODEC_STATUS_OK;
 }
 
@@ -165,7 +271,10 @@ ApexCodec_Status ApexCodec_Component_reset(ApexCodec_Component *comp) {
 
 ApexCodec_Configurable *ApexCodec_Component_getConfigurable(
         ApexCodec_Component *comp) {
-    return nullptr;
+    if (comp == nullptr) {
+        return nullptr;
+    }
+    return comp->getConfigurable();
 }
 
 struct ApexCodec_Buffer {
@@ -546,24 +655,24 @@ struct ApexCodec_SettingResults {
 public:
     explicit ApexCodec_SettingResults(
             const std::shared_ptr<C2ParamReflector> &reflector,
-            const std::vector<C2SettingResult> &results) : mReflector(reflector) {
-        for (const C2SettingResult &c2Result : results) {
+            const std::vector<std::unique_ptr<C2SettingResult>> &results) : mReflector(reflector) {
+        for (const std::unique_ptr<C2SettingResult> &c2Result : results) {
             mResults.emplace_back();
             Entry &entry = mResults.back();
-            entry.failure = (ApexCodec_SettingResultFailure)c2Result.failure;
-            entry.field.index = _C2ParamInspector::GetIndex(c2Result.field.paramOrField);
-            entry.field.offset = _C2ParamInspector::GetOffset(c2Result.field.paramOrField);
-            entry.field.size = _C2ParamInspector::GetSize(c2Result.field.paramOrField);
-            if (c2Result.field.values) {
+            entry.failure = (ApexCodec_SettingResultFailure)c2Result->failure;
+            entry.field.index = _C2ParamInspector::GetIndex(c2Result->field.paramOrField);
+            entry.field.offset = _C2ParamInspector::GetOffset(c2Result->field.paramOrField);
+            entry.field.size = _C2ParamInspector::GetSize(c2Result->field.paramOrField);
+            if (c2Result->field.values) {
                 entry.fieldValues = std::make_unique<ApexCodec_SupportedValues>(
-                        *c2Result.field.values,
+                        *c2Result->field.values,
                         ApexCodec_SupportedValues::GetFieldType(mReflector,
-                                                                c2Result.field.paramOrField));
+                                                                c2Result->field.paramOrField));
                 entry.field.values = entry.fieldValues.get();
             } else {
                 entry.field.values = nullptr;
             }
-            for (const C2ParamFieldValues &c2Conflict : c2Result.conflicts) {
+            for (const C2ParamFieldValues &c2Conflict : c2Result->conflicts) {
                 entry.conflicts.emplace_back();
                 ApexCodec_ParamFieldValues &conflict = entry.conflicts.back();
                 conflict.index = _C2ParamInspector::GetIndex(c2Conflict.paramOrField);
@@ -647,14 +756,125 @@ ApexCodec_Status ApexCodec_Component_process(
         ApexCodec_Buffer *output,
         size_t *consumed,
         size_t *produced) {
-    return APEXCODEC_STATUS_OMITTED;
+    if (comp == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    return comp->process(input, output, consumed, produced);
+}
+
+ApexCodec_Status ApexCodec_Configurable::config(
+        ApexCodec_LinearBuffer *params,
+        ApexCodec_SettingResults **results) {
+    if (results == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    *results = nullptr;
+    std::vector<C2Param *> c2Params;
+    uint8_t *data = params->data;
+    size_t size = params->size;
+    while (size > 0) {
+        size_t paramSize = ((C2Param *)data)->size();
+        if (paramSize > size || paramSize == 0) {
+            return APEXCODEC_STATUS_BAD_VALUE;
+        }
+        c2Params.emplace_back(C2Param::From(data, paramSize));
+        data += paramSize;
+        size -= paramSize;
+    }
+    std::vector<std::unique_ptr<C2SettingResult>> c2Results;
+    ApexCodec_Status status = mConfigurable->config(c2Params, &c2Results);
+    if (status != APEXCODEC_STATUS_OK) {
+        return status;
+    }
+    *results = new ApexCodec_SettingResults(mReflector, c2Results);
+    return APEXCODEC_STATUS_OK;
+}
+
+ApexCodec_Status ApexCodec_Configurable::query(
+        uint32_t indices[],
+        size_t numIndices,
+        ApexCodec_LinearBuffer *config,
+        size_t *writtenOrRequired) {
+    if (config == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    if (writtenOrRequired == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    *writtenOrRequired = 0;
+    std::vector<C2Param::Index> heapParamIndices;
+    for (size_t i = 0; i < numIndices; ++i) {
+        heapParamIndices.push_back(indices[i]);
+    }
+    std::vector<std::unique_ptr<C2Param>> params;
+    ApexCodec_Status status = mConfigurable->query(heapParamIndices, &params);
+    if (status != APEXCODEC_STATUS_OK) {
+        return status;
+    }
+    for (const std::unique_ptr<C2Param> &param : params) {
+        *writtenOrRequired += param->size();
+    }
+    if (*writtenOrRequired > config->size) {
+        return APEXCODEC_STATUS_NO_MEMORY;
+    }
+    size_t offset = 0;
+    for (const std::unique_ptr<C2Param> &param : params) {
+        memcpy(config->data + offset, param.get(), param->size());
+        offset += param->size();
+    }
+    return APEXCODEC_STATUS_OK;
+}
+
+ApexCodec_Status ApexCodec_Configurable::querySupportedParams(
+        ApexCodec_ParamDescriptors **descriptors) {
+    if (descriptors == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    *descriptors = nullptr;
+    std::vector<std::shared_ptr<C2ParamDescriptor>> c2Descs;
+    mConfigurable->querySupportedParams(&c2Descs);
+    *descriptors = new ApexCodec_ParamDescriptors(c2Descs);
+    return APEXCODEC_STATUS_OK;
+}
+
+ApexCodec_Status ApexCodec_Configurable::querySupportedValues(
+        ApexCodec_SupportedValuesQuery *queries,
+        size_t numQueries) {
+    if (queries == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    if (mReflector == nullptr) {
+        return APEXCODEC_STATUS_BAD_STATE;
+    }
+    std::vector<C2FieldSupportedValuesQuery> c2Queries;
+    std::vector<C2ParamField> c2Fields;
+    c2Queries.reserve(numQueries);
+    for (size_t i = 0; i < numQueries; ++i) {
+        C2Param::Index index = queries[i].index;
+        uint32_t offset = queries[i].offset;
+        uint32_t size = findSize(index, offset);
+        c2Fields.push_back(_C2ParamInspector::CreateParamField(index, offset, size));
+        c2Queries.emplace_back(c2Fields.back(),
+                               (C2FieldSupportedValuesQuery::type_t)queries[i].type);
+    }
+    mConfigurable->querySupportedValues(c2Queries);
+    for (size_t i = 0; i < numQueries; ++i) {
+        queries[i].status = (ApexCodec_Status)c2Queries[i].status;
+        queries[i].values = new ApexCodec_SupportedValues(
+                c2Queries[i].values,
+                ApexCodec_SupportedValues::GetFieldType(mReflector, c2Fields[i]));
+    }
+    return APEXCODEC_STATUS_OK;
 }
 
 ApexCodec_Status ApexCodec_Configurable_config(
         ApexCodec_Configurable *comp,
-        ApexCodec_LinearBuffer *config,
+        ApexCodec_LinearBuffer *params,
         ApexCodec_SettingResults **results) {
-    return APEXCODEC_STATUS_OMITTED;
+    if (comp == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    return comp->config(params, results);
 }
 
 ApexCodec_Status ApexCodec_Configurable_query(
@@ -663,84 +883,71 @@ ApexCodec_Status ApexCodec_Configurable_query(
         size_t numIndices,
         ApexCodec_LinearBuffer *config,
         size_t *writtenOrRequired) {
-    return APEXCODEC_STATUS_OMITTED;
+    if (comp == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    return comp->query(indices, numIndices, config, writtenOrRequired);
 }
 
-struct ApexCodec_ParamDescriptors {
-public:
-    explicit ApexCodec_ParamDescriptors(
-            const std::vector<std::shared_ptr<C2ParamDescriptor>> &paramDescriptors) {
-        for (const std::shared_ptr<C2ParamDescriptor> &c2Descriptor : paramDescriptors) {
-            if (!c2Descriptor) {
-                continue;
-            }
-            uint32_t index = c2Descriptor->index();
-            Entry &entry = mDescriptors[index];
-            entry.index = index;
-            entry.attr = (ApexCodec_ParamAttribute)_C2ParamInspector::GetAttrib(*c2Descriptor);
-            entry.name = c2Descriptor->name();
-            for (const C2Param::Index &dependency : c2Descriptor->dependencies()) {
-                entry.dependencies.emplace_back((uint32_t)dependency);
-            }
-            mIndices.push_back(entry.index);
+ApexCodec_ParamDescriptors::ApexCodec_ParamDescriptors(
+        const std::vector<std::shared_ptr<C2ParamDescriptor>> &paramDescriptors) {
+    for (const std::shared_ptr<C2ParamDescriptor> &c2Descriptor : paramDescriptors) {
+        if (!c2Descriptor) {
+            continue;
         }
+        uint32_t index = c2Descriptor->index();
+        Entry &entry = mDescriptors[index];
+        entry.index = index;
+        entry.attr = (ApexCodec_ParamAttribute)_C2ParamInspector::GetAttrib(*c2Descriptor);
+        entry.name = c2Descriptor->name();
+        for (const C2Param::Index &dependency : c2Descriptor->dependencies()) {
+            entry.dependencies.emplace_back((uint32_t)dependency);
+        }
+        mIndices.push_back(entry.index);
     }
+}
 
-    ~ApexCodec_ParamDescriptors() {
+ApexCodec_Status ApexCodec_ParamDescriptors::getIndices(uint32_t **indices, size_t *numIndices) {
+    if (indices == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
     }
-
-    ApexCodec_Status getIndices(uint32_t **indices, size_t *numIndices) {
-        if (indices == nullptr) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        if (numIndices == nullptr) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        *indices = mIndices.data();
-        *numIndices = mIndices.size();
-        return APEXCODEC_STATUS_OK;
+    if (numIndices == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
     }
+    *indices = mIndices.data();
+    *numIndices = mIndices.size();
+    return APEXCODEC_STATUS_OK;
+}
 
-    ApexCodec_Status getDescriptor(
-            uint32_t index,
-            ApexCodec_ParamAttribute *attr,
-            const char **name,
-            uint32_t **dependencies,
-            size_t *numDependencies) {
-        if (attr == nullptr) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        if (name == nullptr) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        if (dependencies == nullptr) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        if (numDependencies == nullptr) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        auto it = mDescriptors.find(index);
-        if (it == mDescriptors.end()) {
-            return APEXCODEC_STATUS_BAD_VALUE;
-        }
-        const Entry &entry = it->second;
-        *attr = entry.attr;
-        *name = entry.name.c_str();
-        *dependencies = const_cast<uint32_t *>(entry.dependencies.data());
-        *numDependencies = entry.dependencies.size();
-        return APEXCODEC_STATUS_OK;
+ApexCodec_Status ApexCodec_ParamDescriptors::getDescriptor(
+        uint32_t index,
+        ApexCodec_ParamAttribute *attr,
+        const char **name,
+        uint32_t **dependencies,
+        size_t *numDependencies) {
+    if (attr == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
     }
-
-private:
-    struct Entry {
-        uint32_t index;
-        ApexCodec_ParamAttribute attr;
-        C2String name;
-        std::vector<uint32_t> dependencies;
-    };
-    std::map<uint32_t, Entry> mDescriptors;
-    std::vector<uint32_t> mIndices;
-};
+    if (name == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    if (dependencies == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    if (numDependencies == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    auto it = mDescriptors.find(index);
+    if (it == mDescriptors.end()) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    const Entry &entry = it->second;
+    *attr = entry.attr;
+    *name = entry.name.c_str();
+    *dependencies = const_cast<uint32_t *>(entry.dependencies.data());
+    *numDependencies = entry.dependencies.size();
+    return APEXCODEC_STATUS_OK;
+}
 
 ApexCodec_Status ApexCodec_ParamDescriptors_getIndices(
         ApexCodec_ParamDescriptors *descriptors,
@@ -772,14 +979,20 @@ void ApexCodec_ParamDescriptors_destroy(ApexCodec_ParamDescriptors *descriptors)
 ApexCodec_Status ApexCodec_Configurable_querySupportedParams(
         ApexCodec_Configurable *comp,
         ApexCodec_ParamDescriptors **descriptors) {
-    return APEXCODEC_STATUS_OMITTED;
+    if (comp == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    return comp->querySupportedParams(descriptors);
 }
 
 ApexCodec_Status ApexCodec_Configurable_querySupportedValues(
         ApexCodec_Configurable *comp,
         ApexCodec_SupportedValuesQuery *queries,
         size_t numQueries) {
-    return APEXCODEC_STATUS_OMITTED;
+    if (comp == nullptr) {
+        return APEXCODEC_STATUS_BAD_VALUE;
+    }
+    return comp->querySupportedValues(queries, numQueries);
 }
 
-#pragma clang diagnostic pop
\ No newline at end of file
+#pragma clang diagnostic pop
diff --git a/media/module/libapexcodecs/ApexCodecsStoreImpl.cpp b/media/module/libapexcodecs/ApexCodecsStoreImpl.cpp
index 3beb510539..793a542f8e 100644
--- a/media/module/libapexcodecs/ApexCodecsStoreImpl.cpp
+++ b/media/module/libapexcodecs/ApexCodecsStoreImpl.cpp
@@ -26,7 +26,10 @@ public:
     std::vector<std::shared_ptr<const C2Component::Traits>> listComponents() const override {
         return {};
     }
-    virtual std::unique_ptr<ApexComponentIntf> createComponent(const char *name [[maybe_unused]]) {
+    std::unique_ptr<ApexComponentIntf> createComponent(const char *name [[maybe_unused]]) override {
+        return nullptr;
+    }
+    std::shared_ptr<C2ParamReflector> getParamReflector() const override {
         return nullptr;
     }
 };
diff --git a/media/module/libapexcodecs/private/apex/ApexCodecsImpl.h b/media/module/libapexcodecs/private/apex/ApexCodecsImpl.h
index f01af876d9..cb08116917 100644
--- a/media/module/libapexcodecs/private/apex/ApexCodecsImpl.h
+++ b/media/module/libapexcodecs/private/apex/ApexCodecsImpl.h
@@ -26,13 +26,33 @@
 
 namespace android::apexcodecs {
 
+class ApexConfigurableIntf {
+public:
+    virtual ~ApexConfigurableIntf() = default;
+
+    virtual ApexCodec_Status config(
+            const std::vector<C2Param *> &params,
+            std::vector<std::unique_ptr<C2SettingResult>> *results) const = 0;
+
+    virtual ApexCodec_Status query(
+            const std::vector<C2Param::Index> &heapParamIndices,
+            std::vector<std::unique_ptr<C2Param>>* const heapParams) const = 0;
+
+    virtual ApexCodec_Status querySupportedParams(
+            std::vector<std::shared_ptr<C2ParamDescriptor>> * const params) const = 0;
+
+    virtual ApexCodec_Status querySupportedValues(
+            std::vector<C2FieldSupportedValuesQuery> &fields) const = 0;
+};
+
+
 class ApexComponentIntf {
 public:
     virtual ~ApexComponentIntf() = default;
     virtual ApexCodec_Status start() = 0;
     virtual ApexCodec_Status flush() = 0;
     virtual ApexCodec_Status reset() = 0;
-    virtual ApexCodec_Configurable *getConfigurable() = 0;
+    virtual std::unique_ptr<ApexConfigurableIntf> getConfigurable() = 0;
     virtual ApexCodec_Status process(
             const ApexCodec_Buffer *input,
             ApexCodec_Buffer *output,
@@ -45,6 +65,7 @@ public:
     virtual ~ApexComponentStoreIntf() = default;
     virtual std::vector<std::shared_ptr<const C2Component::Traits>> listComponents() const = 0;
     virtual std::unique_ptr<ApexComponentIntf> createComponent(const char *name) = 0;
+    virtual std::shared_ptr<C2ParamReflector> getParamReflector() const = 0;
 };
 
 }  // namespace android
diff --git a/media/module/libapexcodecs/tests/ApexCodecsStoreTestImpl.cpp b/media/module/libapexcodecs/tests/ApexCodecsStoreTestImpl.cpp
index fb0e98ed62..66b85f189b 100644
--- a/media/module/libapexcodecs/tests/ApexCodecsStoreTestImpl.cpp
+++ b/media/module/libapexcodecs/tests/ApexCodecsStoreTestImpl.cpp
@@ -31,6 +31,9 @@ public:
     virtual std::unique_ptr<ApexComponentIntf> createComponent(const char *name [[maybe_unused]]) {
         return nullptr;
     }
+    virtual std::shared_ptr<C2ParamReflector> getParamReflector() const override {
+        return nullptr;
+    }
 };
 
 }  // namespace android::apexcodecs::test
diff --git a/media/module/libmediatranscoding/include/media/TranscodingLogger.h b/media/module/libmediatranscoding/include/media/TranscodingLogger.h
index dc245518e1..099aeddbda 100644
--- a/media/module/libmediatranscoding/include/media/TranscodingLogger.h
+++ b/media/module/libmediatranscoding/include/media/TranscodingLogger.h
@@ -21,6 +21,7 @@
 #include <utils/Condition.h>
 
 #include <chrono>
+#include <functional>
 #include <memory>
 #include <mutex>
 #include <queue>
diff --git a/media/mtp/MtpServer.cpp b/media/mtp/MtpServer.cpp
index 80fe51abce..6f4f797cc7 100644
--- a/media/mtp/MtpServer.cpp
+++ b/media/mtp/MtpServer.cpp
@@ -133,6 +133,7 @@ MtpServer::MtpServer(IMtpDatabase* database, int controlFd, bool ptp,
 
 MtpServer::~MtpServer() {
     if (mHandle) {
+        mHandle->close();
         delete mHandle;
         mHandle = NULL;
     }
diff --git a/media/mtp/OWNERS b/media/mtp/OWNERS
index 7a2ee74514..f4b8d5ddf2 100644
--- a/media/mtp/OWNERS
+++ b/media/mtp/OWNERS
@@ -1,6 +1,4 @@
 set noparent
-
-vmartensson@google.com
 nkapron@google.com
 febinthattil@google.com
 shubhankarm@google.com
diff --git a/media/ndk/NdkImage.cpp b/media/ndk/NdkImage.cpp
index c2093ace1a..06ec96767e 100644
--- a/media/ndk/NdkImage.cpp
+++ b/media/ndk/NdkImage.cpp
@@ -665,6 +665,17 @@ AImage::getHardwareBuffer(/*out*/AHardwareBuffer** buffer) const {
     return AMEDIA_OK;
 }
 
+media_status_t
+AImage::getTransform(/*out*/int32_t* transform) const {
+    if (mBuffer == nullptr || mBuffer->mGraphicBuffer == nullptr) {
+        ALOGE("%s: AImage %p has no buffer.", __FUNCTION__, this);
+        return AMEDIA_ERROR_INVALID_OBJECT;
+    }
+
+    *transform = mBuffer->mTransform;
+    return AMEDIA_OK;
+}
+
 EXPORT
 void AImage_delete(AImage* image) {
     ALOGV("%s", __FUNCTION__);
@@ -845,4 +856,16 @@ media_status_t AImage_getDataSpace(
         return AMEDIA_ERROR_INVALID_PARAMETER;
     }
     return image->getDataSpace((android_dataspace*)(dataSpace));
+}
+
+EXPORT
+media_status_t AImage_getTransform(
+    AImage* image, /*out*/int32_t* transform) {
+    ALOGV("%s", __FUNCTION__);
+
+    if (image == nullptr || transform == nullptr) {
+        ALOGE("%s: bad argument. image %p transform %p", __FUNCTION__, image, transform);
+        return AMEDIA_ERROR_INVALID_PARAMETER;
+    }
+    return image->getTransform(transform);
 }
\ No newline at end of file
diff --git a/media/ndk/NdkImagePriv.h b/media/ndk/NdkImagePriv.h
index dc10a6a7ce..6d3d272e9c 100644
--- a/media/ndk/NdkImagePriv.h
+++ b/media/ndk/NdkImagePriv.h
@@ -83,6 +83,7 @@ struct AImage {
     media_status_t getPlaneData(int planeIdx,/*out*/uint8_t** data, /*out*/int* dataLength) const;
     media_status_t getHardwareBuffer(/*out*/AHardwareBuffer** buffer) const;
     media_status_t getDataSpace(/*out*/android_dataspace* dataSpace) const;
+    media_status_t getTransform(/*out*/int32_t* transform) const;
 
   private:
     // AImage should be deleted through free() API.
diff --git a/media/ndk/NdkImageReader.cpp b/media/ndk/NdkImageReader.cpp
index 7a7675304e..d0fb3b4f7f 100644
--- a/media/ndk/NdkImageReader.cpp
+++ b/media/ndk/NdkImageReader.cpp
@@ -304,9 +304,6 @@ AImageReader::init() {
         return AMEDIA_ERROR_UNKNOWN;
     }
 
-#if !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
-    mProducer = mSurface->getIGraphicBufferProducer();
-#endif
     mBufferItemConsumer->setName(consumerName);
     mBufferItemConsumer->setFrameAvailableListener(mFrameListener);
     mBufferItemConsumer->setBufferFreedListener(mBufferRemovedListener);
@@ -577,13 +574,8 @@ media_status_t AImageReader::getWindowNativeHandle(native_handle **handle) {
         *handle = mWindowHandle;
         return AMEDIA_OK;
     }
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
     sp<HGraphicBufferProducer> hgbp = new TWGraphicBufferProducer<HGraphicBufferProducer>(
             mSurface->getIGraphicBufferProducer());
-#else
-    sp<HGraphicBufferProducer> hgbp =
-        new TWGraphicBufferProducer<HGraphicBufferProducer>(mProducer);
-#endif  // COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
     HalToken halToken;
     if (!createHalToken(hgbp, &halToken)) {
         return AMEDIA_ERROR_UNKNOWN;
diff --git a/media/ndk/NdkImageReaderPriv.h b/media/ndk/NdkImageReaderPriv.h
index 89a33f81f2..a964c57334 100644
--- a/media/ndk/NdkImageReaderPriv.h
+++ b/media/ndk/NdkImageReaderPriv.h
@@ -164,9 +164,6 @@ struct AImageReader : public RefBase {
 
     uint64_t mHalUsage;
 
-#if !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
-    sp<IGraphicBufferProducer> mProducer;
-#endif  // !COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
     sp<Surface>                mSurface;
     sp<BufferItemConsumer>     mBufferItemConsumer;
     sp<ANativeWindow>          mWindow;
diff --git a/media/ndk/NdkMediaCodec.cpp b/media/ndk/NdkMediaCodec.cpp
index 9971731bbc..b1f8c6702f 100644
--- a/media/ndk/NdkMediaCodec.cpp
+++ b/media/ndk/NdkMediaCodec.cpp
@@ -30,6 +30,7 @@
 #include <utils/Log.h>
 #include <utils/StrongPointer.h>
 #include <gui/Surface.h>
+#include <gui/Flags.h>
 
 #include <media/stagefright/foundation/ALooper.h>
 #include <media/stagefright/foundation/ABuffer.h>
@@ -85,9 +86,14 @@ enum {
 struct AMediaCodecPersistentSurface : public Surface {
     sp<PersistentSurface> mPersistentSurface;
     AMediaCodecPersistentSurface(
-            const sp<IGraphicBufferProducer>& igbp,
+            const sp<MediaSurfaceType>& surface,
             const sp<PersistentSurface>& ps)
-            : Surface(igbp) {
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_MEDIA_MIGRATION)
+            : Surface(surface->getIGraphicBufferProducer()) {
+#else
+            : Surface(surface) {
+#endif
+
         mPersistentSurface = ps;
     }
     virtual ~AMediaCodecPersistentSurface() {
@@ -900,12 +906,12 @@ media_status_t AMediaCodec_createPersistentInputSurface(ANativeWindow **surface)
         return AMEDIA_ERROR_UNKNOWN;
     }
 
-    sp<IGraphicBufferProducer> igbp = ps->getBufferProducer();
-    if (igbp == NULL) {
+    sp<MediaSurfaceType> s = mediaflagtools::igbpToSurfaceType(ps->getBufferProducer());
+    if (s == NULL) {
         return AMEDIA_ERROR_UNKNOWN;
     }
 
-    *surface = new AMediaCodecPersistentSurface(igbp, ps);
+    *surface = new AMediaCodecPersistentSurface(s, ps);
     ANativeWindow_acquire(*surface);
 
     return AMEDIA_OK;
diff --git a/media/ndk/include/media/NdkImage.h b/media/ndk/include/media/NdkImage.h
index 76270d3069..a81d48e351 100644
--- a/media/ndk/include/media/NdkImage.h
+++ b/media/ndk/include/media/NdkImage.h
@@ -575,7 +575,7 @@ typedef struct AImageCropRect {
  *
  * @param image The {@link AImage} to be deleted.
  */
-void AImage_delete(AImage* image) __INTRODUCED_IN(24);
+void AImage_delete(AImage* _Nullable image) __INTRODUCED_IN(24);
 
 /**
  * Query the width of the input {@link AImage}.
@@ -591,7 +591,8 @@ void AImage_delete(AImage* image) __INTRODUCED_IN(24);
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getWidth(const AImage* image, /*out*/int32_t* width) __INTRODUCED_IN(24);
+media_status_t AImage_getWidth(const AImage* _Nonnull image, /*out*/int32_t* _Nonnull width)
+                               __INTRODUCED_IN(24);
 
 /**
  * Query the height of the input {@link AImage}.
@@ -607,7 +608,8 @@ media_status_t AImage_getWidth(const AImage* image, /*out*/int32_t* width) __INT
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getHeight(const AImage* image, /*out*/int32_t* height) __INTRODUCED_IN(24);
+media_status_t AImage_getHeight(const AImage* _Nonnull image, /*out*/int32_t* _Nonnull height)
+                                __INTRODUCED_IN(24);
 
 /**
  * Query the format of the input {@link AImage}.
@@ -625,7 +627,8 @@ media_status_t AImage_getHeight(const AImage* image, /*out*/int32_t* height) __I
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getFormat(const AImage* image, /*out*/int32_t* format) __INTRODUCED_IN(24);
+media_status_t AImage_getFormat(const AImage* _Nonnull image, /*out*/int32_t* _Nonnull format)
+                                __INTRODUCED_IN(24);
 
 /**
  * Query the cropped rectangle of the input {@link AImage}.
@@ -644,7 +647,8 @@ media_status_t AImage_getFormat(const AImage* image, /*out*/int32_t* format) __I
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getCropRect(const AImage* image, /*out*/AImageCropRect* rect) __INTRODUCED_IN(24);
+media_status_t AImage_getCropRect(const AImage* _Nonnull image,
+                                  /*out*/AImageCropRect* _Nonnull rect) __INTRODUCED_IN(24);
 
 /**
  * Query the timestamp of the input {@link AImage}.
@@ -670,7 +674,8 @@ media_status_t AImage_getCropRect(const AImage* image, /*out*/AImageCropRect* re
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getTimestamp(const AImage* image, /*out*/int64_t* timestampNs) __INTRODUCED_IN(24);
+media_status_t AImage_getTimestamp(const AImage* _Nonnull image,
+                                   /*out*/int64_t* _Nonnull timestampNs) __INTRODUCED_IN(24);
 
 /**
  * Query the number of planes of the input {@link AImage}.
@@ -690,7 +695,8 @@ media_status_t AImage_getTimestamp(const AImage* image, /*out*/int64_t* timestam
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getNumberOfPlanes(const AImage* image, /*out*/int32_t* numPlanes) __INTRODUCED_IN(24);
+media_status_t AImage_getNumberOfPlanes(const AImage* _Nonnull image,
+                                        /*out*/int32_t* _Nonnull numPlanes) __INTRODUCED_IN(24);
 
 /**
  * Query the pixel stride of the input {@link AImage}.
@@ -719,8 +725,8 @@ media_status_t AImage_getNumberOfPlanes(const AImage* image, /*out*/int32_t* num
  *         <li>{@link AMEDIA_IMGREADER_CANNOT_LOCK_IMAGE} if the {@link AImage} cannot be locked
  *                 for CPU access.</li></ul>
  */
-media_status_t AImage_getPlanePixelStride(
-        const AImage* image, int planeIdx, /*out*/int32_t* pixelStride) __INTRODUCED_IN(24);
+media_status_t AImage_getPlanePixelStride(const AImage* _Nonnull image, int planeIdx,
+                                          /*out*/int32_t* _Nonnull pixelStride) __INTRODUCED_IN(24);
 
 /**
  * Query the row stride of the input {@link AImage}.
@@ -749,7 +755,8 @@ media_status_t AImage_getPlanePixelStride(
  *                 for CPU access.</li></ul>
  */
 media_status_t AImage_getPlaneRowStride(
-        const AImage* image, int planeIdx, /*out*/int32_t* rowStride) __INTRODUCED_IN(24);
+        const AImage* _Nonnull image, int planeIdx, /*out*/int32_t* _Nonnull rowStride)
+        __INTRODUCED_IN(24);
 
 /**
  * Get the data pointer of the input image for direct application access.
@@ -775,8 +782,8 @@ media_status_t AImage_getPlaneRowStride(
  *                 for CPU access.</li></ul>
  */
 media_status_t AImage_getPlaneData(
-        const AImage* image, int planeIdx,
-        /*out*/uint8_t** data, /*out*/int* dataLength) __INTRODUCED_IN(24);
+        const AImage* _Nonnull image, int planeIdx, /*out*/uint8_t* _Nullable * _Nonnull data,
+        /*out*/int* _Nonnull dataLength) __INTRODUCED_IN(24);
 
 /**
  * Return the image back the the system and delete the AImage object from memory asynchronously.
@@ -794,7 +801,7 @@ media_status_t AImage_getPlaneData(
  *
  * @see sync.h
  */
-void AImage_deleteAsync(AImage* image, int releaseFenceFd) __INTRODUCED_IN(26);
+void AImage_deleteAsync(AImage* _Nullable image, int releaseFenceFd) __INTRODUCED_IN(26);
 
 /**
  * Get the hardware buffer handle of the input image intended for GPU and/or hardware access.
@@ -824,7 +831,9 @@ void AImage_deleteAsync(AImage* image, int releaseFenceFd) __INTRODUCED_IN(26);
  *
  * @see AImageReader_ImageCallback
  */
-media_status_t AImage_getHardwareBuffer(const AImage* image, /*out*/AHardwareBuffer** buffer) __INTRODUCED_IN(26);
+media_status_t AImage_getHardwareBuffer(
+        const AImage* _Nonnull image, /*out*/AHardwareBuffer* _Nullable * _Nonnull buffer)
+        __INTRODUCED_IN(26);
 
 /**
  * Query the dataspace of the input {@link AImage}.
@@ -842,8 +851,36 @@ media_status_t AImage_getHardwareBuffer(const AImage* image, /*out*/AHardwareBuf
  *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader} generated this
  *                 image has been deleted.</li></ul>
  */
-media_status_t AImage_getDataSpace(const AImage* image,
-                                   /*out*/int32_t* dataSpace) __INTRODUCED_IN(34);
+media_status_t AImage_getDataSpace(const AImage* _Nonnull image,
+                                   /*out*/int32_t* _Nonnull dataSpace) __INTRODUCED_IN(34);
+
+/**
+ * Query the transform of the input {@link AImage}.
+ *
+ * <p>getTransform retrieves the image transform associated with the {@link AImage}
+ * set by the most recent call to updateTexImage.</p>
+ *
+ * <p>This transform can be a combination of horizontal mirror, vertical
+ * mirror, and clockwise 90 degree rotation. See {@link ANativeWindowTransform}
+ * for more details. This transform is necessary to compensate for transforms
+ * that the stream content producer may implicitly apply to the content. By
+ * forcing users of an AImage to apply this transform we avoid performing an
+ * extracopy of the data that would be needed to hide the transform from the user.</p>
+ *
+ * Available since API level 37.
+ *
+ * @param image the {@link AImage} of interest.
+ * @param transform the transform of the image will be filled here if the method call
+ *         succeeds.
+ *
+ * @return <ul>
+ *         <li>{@link AMEDIA_OK} if the method call succeeds.</li>
+ *         <li>{@link AMEDIA_ERROR_INVALID_PARAMETER} if image is NULL.</li>
+ *         <li>{@link AMEDIA_ERROR_INVALID_OBJECT} if the {@link AImageReader}
+ * generated this image has been deleted.</li></ul>
+ */
+media_status_t AImage_getTransform(AImage* _Nonnull image,
+                                  /*out*/int32_t* _Nonnull transform) __INTRODUCED_IN(37);
 
 __END_DECLS
 
diff --git a/media/ndk/libmediandk.map.txt b/media/ndk/libmediandk.map.txt
index a141b64eba..50c4f3ef16 100644
--- a/media/ndk/libmediandk.map.txt
+++ b/media/ndk/libmediandk.map.txt
@@ -57,6 +57,7 @@ LIBMEDIANDK {
     AImage_getPlanePixelStride; # introduced=24
     AImage_getPlaneRowStride; # introduced=24
     AImage_getTimestamp; # introduced=24
+    AImage_getTransform; # introduced=37
     AImage_getWidth; # introduced=24
     AMEDIACODEC_KEY_HDR10_PLUS_INFO; # var introduced=31
     AMEDIACODEC_KEY_LOW_LATENCY; # var introduced=31
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/BlockModelDecoder.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/BlockModelDecoder.java
index 3b3640edf3..5769b97647 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/BlockModelDecoder.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/BlockModelDecoder.java
@@ -28,6 +28,8 @@ import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.List;
 
+import java.util.ArrayDeque;
+
 import com.android.media.benchmark.library.Decoder;
 
 public class BlockModelDecoder extends Decoder {
@@ -84,6 +86,21 @@ public class BlockModelDecoder extends Decoder {
         }
     }
 
+    @Override
+    public boolean returnBuffers(ArrayDeque<IBufferXfer.IProducerData> datas) {
+        for (IBufferXfer.IProducerData data : datas) {
+            DecoderData decoderData = (DecoderData)data;
+            if (decoderData.mOutputFrame != null
+                    && decoderData.mOutputFrame.getLinearBlock() != null) {
+                decoderData.mOutputFrame.getLinearBlock().recycle();
+                decoderData.mOutputFrame  = null;
+            } else {
+                Log.d(TAG, "Error, output frame not found in decoder data");
+            }
+        }
+        return super.returnBuffers(datas);
+    }
+
     public BlockModelDecoder() {
         // empty
     }
@@ -93,6 +110,10 @@ public class BlockModelDecoder extends Decoder {
 
     }
 
+    protected boolean isOutputBufferLinear() {
+        return mMime.startsWith("audio");
+    }
+
     /**
      * Decodes the given input buffer,
      * provided valid list of buffer info and format are passed as inputs.
@@ -112,6 +133,13 @@ public class BlockModelDecoder extends Decoder {
         @NonNull MediaFormat format, String codecName)
         throws IOException, InterruptedException {
         setExtraConfigureFlags(MediaCodec.CONFIGURE_FLAG_USE_BLOCK_MODEL);
+        if (format.containsKey(MediaFormat.KEY_MIME)) {
+            String mime = format.getString(MediaFormat.KEY_MIME);
+            if (mConsumer != null && !mime.startsWith("audio/")) {
+                Log.e(TAG, "Non-linear input buffers cannot be instantiated for buffer transfer.");
+                throw new IOException();
+            }
+        }
         return super.decode(inputBuffer, inputBufferInfo, asyncMode, format, codecName);
     }
 
@@ -136,7 +164,7 @@ public class BlockModelDecoder extends Decoder {
         }
         codecFlags |= mSawInputEOS ? MediaCodec.BUFFER_FLAG_END_OF_STREAM : 0;
         if (DEBUG) {
-            Log.v(TAG, "input: id: " + inputBufferId
+            Log.v(TAG, "Input: id: " + inputBufferId
                     + " size: " + bufInfo.size
                     + " pts: " + bufInfo.presentationTimeUs
                     + " flags: " + codecFlags);
@@ -166,26 +194,26 @@ public class BlockModelDecoder extends Decoder {
         if (mSawOutputEOS || outputBufferId < 0) {
             return;
         }
+        boolean canGetBtyeBuffer = isOutputBufferLinear();;
+
         mNumOutputFrame++;
         if (DEBUG) {
             Log.d(TAG,
                     "In OutputBufferAvailable ,"
                             + " output frame number = " + mNumOutputFrame
                             + " timestamp = " + outputBufferInfo.presentationTimeUs
-                            + " size = " + outputBufferInfo.size);
+                            + " size = " + outputBufferInfo.size
+                            + " flags = " + outputBufferInfo.flags);
         }
         MediaCodec.OutputFrame outFrame = mediaCodec.getOutputFrame(outputBufferId);
         ByteBuffer outputBuffer = null;
-        try {
-            if (outFrame.getLinearBlock() != null) {
-                outputBuffer = outFrame.getLinearBlock().map();
-            }
-        } catch(IllegalStateException e) {
-            // buffer may not be linear, this is ok
-            // as we are handling non-linear buffers below.
-        }
-        if (mOutputStream != null) {
+        if (mOutputStream != null && canGetBtyeBuffer == true) {
             try {
+                if (outputBuffer == null) {
+                    if (outFrame != null && outFrame.getLinearBlock() != null) {
+                        outputBuffer = outFrame.getLinearBlock().map();
+                    }
+                }
                 if (outputBuffer != null) {
                     byte[] bytesOutput = new byte[outputBuffer.remaining()];
                     outputBuffer.get(bytesOutput);
@@ -196,21 +224,29 @@ public class BlockModelDecoder extends Decoder {
                 Log.d(TAG, "Error Dumping File: Exception " + e.toString());
             }
         }
-        ByteBuffer copiedBuffer = null;
-        int bytesRemaining = 0;
-        if (outputBuffer != null) {
-            bytesRemaining = outputBuffer.remaining();
-            if (mIBufferSend != null) {
-                copiedBuffer = ByteBuffer.allocate(outputBuffer.remaining());
-                copiedBuffer.put(outputBuffer);
+        mSawOutputEOS = (outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0;
+        if (mConsumer != null && canGetBtyeBuffer == true) {
+            ArrayDeque<MediaCodec.BufferInfo> infos = new ArrayDeque<>();
+            infos.add(outputBufferInfo);
+            if (outputBuffer == null) {
+                if (outFrame != null && outFrame.getLinearBlock() != null) {
+                    outputBuffer = outFrame.getLinearBlock().map();
+                }
             }
-            outFrame.getLinearBlock().recycle();
-            outputBuffer = null;
-        }
-        if (mFrameReleaseQueue != null) {
+            DecoderData data = prepareDecoderData(outputBufferId, outputBuffer, infos);
+            if (data != null) {
+                ArrayDeque<IBufferXfer.IProducerData> buffers = new ArrayDeque<>();
+                data.mOutputFrame = outFrame;
+                buffers.add(data);
+                sendToConsumer(buffers);
+            } else if (outputBuffer != null) {
+                outFrame.getLinearBlock().recycle();
+                outputBuffer = null;
+            }
+        } else if (mFrameReleaseQueue != null) {
             if (mMime.startsWith("audio/")) {
                 try {
-                    mFrameReleaseQueue.pushFrame(outputBufferId, bytesRemaining);
+                    mFrameReleaseQueue.pushFrame(outputBufferId, outFrame, outputBufferInfo.size);
                 } catch (Exception e) {
                     Log.d(TAG, "Error in getting MediaCodec buffer" + e.toString());
                 }
@@ -218,21 +254,13 @@ public class BlockModelDecoder extends Decoder {
                 mFrameReleaseQueue.pushFrame(mNumOutputFrame, outputBufferId,
                                                 outputBufferInfo.presentationTimeUs);
             }
-
-        } else if (mIBufferSend != null) {
-            IBufferXfer.BufferXferInfo info = new IBufferXfer.BufferXferInfo();
-            // TODO: may be inefficient;
-            info.buf = copiedBuffer;
-            info.idx = outputBufferId;
-            info.obj = mediaCodec;
-            info.bytesRead = outputBufferInfo.size;
-            info.presentationTimeUs = outputBufferInfo.presentationTimeUs;
-            info.flag = outputBufferInfo.flags;
-            mIBufferSend.sendBuffer(this, info);
         } else {
+            if (canGetBtyeBuffer == true && outFrame != null && outFrame.getLinearBlock() != null) {
+                outFrame.getLinearBlock().recycle();
+                outputBuffer = null;
+            }
             mediaCodec.releaseOutputBuffer(outputBufferId, mRender);
         }
-        mSawOutputEOS = (outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0;
         if (DEBUG && mSawOutputEOS) {
             Log.i(TAG, "Saw output EOS");
         }
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Decoder.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Decoder.java
index 2ea0ed254c..a46f59c7d3 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Decoder.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Decoder.java
@@ -29,6 +29,18 @@ import androidx.annotation.NonNull;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.nio.ByteBuffer;
+
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.CancellationException;
+import java.util.concurrent.ExecutionException;
+
+
+
 import java.util.ArrayDeque;
 import java.util.ArrayList;
 import java.util.Iterator;
@@ -36,12 +48,14 @@ import java.util.List;
 
 import com.android.media.benchmark.library.IBufferXfer;
 
-public class Decoder implements IBufferXfer.IReceiveBuffer {
+public class Decoder implements IBufferXfer.IProducer {
     private static final String TAG = "Decoder";
     private static final boolean DEBUG = false;
+    private static final int TIMEOUT_IN_SEC_FOR_TASK = 2;
     private static final int kQueueDequeueTimeoutUs = 1000;
-
+    protected int DEFAULT_AUDIO_FRAME_SIZE = 4096;
     protected final Object mLock = new Object();
+    private final Object mFuturesLock = new Object();
     protected MediaCodec mCodec;
     protected int mExtraFlags = 0;
     protected Surface mSurface = null;
@@ -65,7 +79,6 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
     protected ArrayList<ByteBuffer> mInputBuffer;
     protected FileOutputStream mOutputStream;
     protected FrameReleaseQueue mFrameReleaseQueue = null;
-    protected IBufferXfer.ISendBuffer mIBufferSend = null;
 
     /* success for decoder */
     public static final int DECODE_SUCCESS = 0;
@@ -73,23 +86,97 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
     public static final int DECODE_DECODER_ERROR = -1;
     /* error while creating a decoder */
     public static final int DECODE_CREATE_ERROR = -2;
-    public Decoder() { mStats = new Stats(); }
-    public Stats getStats() { return mStats; };
+    protected final ArrayDeque<DecoderData> mDecoderDataCache = new ArrayDeque<>();
+    protected final ArrayDeque<MediaCodec.BufferInfo> mBufferInfoCache = new ArrayDeque<>();
+    private final ExecutorService mScheduler = Executors.newFixedThreadPool(1);
+    private final ArrayDeque<Future<?>> mSchedulerFutures = new ArrayDeque<>();
+    protected IBufferXfer.IConsumer mConsumer = null;
+
+
     @Override
-    public boolean receiveBuffer(IBufferXfer.BufferXferInfo info) {
-        MediaCodec codec = (MediaCodec)info.obj;
-        if (info.isComplete) {
-            codec.releaseOutputBuffer(info.idx, mRender);
-        }
+    public boolean setConsumer (@NonNull IBufferXfer.IConsumer consumer) {
+        mConsumer = consumer;
         return true;
     }
+
     @Override
-    public boolean connect(IBufferXfer.ISendBuffer receiver) {
-        Log.d(TAG,"Setting interface of the sender");
-        mIBufferSend = receiver;
+    public boolean returnBuffers(ArrayDeque<IBufferXfer.IProducerData> datas) {
+        if (datas == null || datas.isEmpty()) {
+            Log.d(TAG, "Returned data is empty");
+            return true;
+        }
+        ArrayDeque<IBufferXfer.IProducerData> dataClone = datas.clone();
+        Future<?> future = mScheduler.submit(() -> { returnToCodec(dataClone); });
+        datas.clear();
+        handleFuture(future);
         return true;
     }
 
+    public void handleFuture(Future<?> future) {
+        synchronized(mFuturesLock) {
+            if (future != null) {
+                mSchedulerFutures.add(future);
+            }
+            while (mSchedulerFutures.isEmpty() == false
+                && mSchedulerFutures.peekFirst().isDone() == true) {
+                Future<?> task = mSchedulerFutures.pollFirst();
+                try {
+                    task.get();
+                } catch(Exception e) {
+                    Log.d (TAG, "Scheduler encountered an exception " + e.toString());
+                }
+            }
+        }
+    }
+
+    public static class DecoderData implements IBufferXfer.IProducerData{
+        public int mIdx = -1;
+        public ByteBuffer mBuffer = null;
+        MediaCodec.OutputFrame mOutputFrame = null;
+        public final ArrayDeque<MediaCodec.BufferInfo> mInfos = new ArrayDeque<>();
+
+        public ByteBuffer getBuffer() {
+            return mBuffer;
+        }
+
+        public ArrayDeque<MediaCodec.BufferInfo> getInfo() {
+            return mInfos;
+        }
+    }
+
+    void sendToConsumer(ArrayDeque<IBufferXfer.IProducerData> datas) {
+        if (DEBUG) {
+            Log.d(TAG, "Sending to consumer data size " + datas.size());
+        }
+        mConsumer.consume(datas);
+    }
+
+    void returnToCodec(ArrayDeque<IBufferXfer.IProducerData> datas) {
+        ArrayList<Integer> decoderIds = new ArrayList<>();
+        synchronized(mLock) {
+            for (IBufferXfer.IProducerData data : datas) {
+                DecoderData decoderData = (DecoderData)data;
+                decoderIds.add(decoderData.mIdx);
+                decoderData.mIdx = -1;
+                decoderData.mBuffer = null;
+                if (decoderData.getInfo().isEmpty() == false) {
+                    mBufferInfoCache.addAll(decoderData.getInfo());
+                    decoderData.getInfo().clear();
+                }
+                mDecoderDataCache.add(decoderData);
+            }
+        }
+        for (int id : decoderIds) {
+            if (DEBUG) {
+                Log.d(TAG, "Returning buffers to decoder ID " + id);
+            }
+            mCodec.releaseOutputBuffer(id, mRender);
+        }
+    }
+
+    public Decoder() { mStats = new Stats(); }
+    public Stats getStats() { return mStats; };
+
     public void setExtraConfigureFlags(int flags) {
         this.mExtraFlags = flags;
     }
@@ -157,7 +244,8 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
             }
         } catch (IllegalArgumentException ex) {
             ex.printStackTrace();
-            Log.e(TAG, "Failed to create decoder for " + codecName + " mime:" + mMime);
+            Log.e(TAG, "Failed to create decoder for "
+                    + codecName + " mime:" + mMime + ex.toString());
             return null;
         }
     }
@@ -213,8 +301,6 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
             synchronized (mLock) { mLock.notify(); }
         }
     });
-
-
     }
 
     /**
@@ -305,6 +391,18 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
                     if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
                         MediaFormat outFormat = mCodec.getOutputFormat();
                         Log.i(TAG, "Output format changed. Format: " + outFormat.toString());
+                        if (mUseFrameReleaseQueue
+                                && mFrameReleaseQueue == null && mMime.startsWith("audio/")) {
+                            // start a frame release thread for this configuration.
+                            int bytesPerSample = AudioFormat.getBytesPerSample(
+                                    outFormat.getInteger(MediaFormat.KEY_PCM_ENCODING,
+                                            AudioFormat.ENCODING_PCM_16BIT));
+                            int sampleRate = outFormat.getInteger(MediaFormat.KEY_SAMPLE_RATE);
+                            int channelCount = outFormat.getInteger(MediaFormat.KEY_CHANNEL_COUNT);
+                            mFrameReleaseQueue = new FrameReleaseQueue(
+                                    mRender, sampleRate, channelCount, bytesPerSample);
+                            mFrameReleaseQueue.setMediaCodec(mCodec);
+                        }
                     } else if (outputBufferId == MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED) {
                         Log.i(TAG, "Ignoring deprecated flag: INFO_OUTPUT_BUFFERS_CHANGED");
                     } else if (outputBufferId != MediaCodec.INFO_TRY_AGAIN_LATER) {
@@ -364,7 +462,25 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
     /**
      * Resets the stats
      */
-    public void resetDecoder() { mStats.reset(); }
+    public void resetDecoder() {
+        mStats.reset();
+        synchronized(mFuturesLock) {
+            while (mSchedulerFutures.isEmpty() == false) {
+                Future<?> future = mSchedulerFutures.pollFirst();
+                try {
+                    future.get(TIMEOUT_IN_SEC_FOR_TASK, TimeUnit.SECONDS);
+                } catch (TimeoutException e) {
+                    Log.d(TAG, "Future timed-out in scheduler " + e.toString());
+                    future.cancel(true);
+                } catch (InterruptedException | ExecutionException e) {
+                    Log.d(TAG, "Future exception in scheduler " + e.toString());
+                }
+            }
+        }
+        if (mScheduler != null) {
+            mScheduler.shutdownNow();
+        }
+    }
 
     /**
      * Returns the format of the output buffers
@@ -405,6 +521,37 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
         }
     }
 
+    protected DecoderData prepareDecoderData(
+            int outputBufferId, ByteBuffer buffer, ArrayDeque<BufferInfo> infos) {
+        if (infos == null || infos.isEmpty() == true) {
+            Log.d(TAG, "Something wrong with buffers -- cannot send data");
+            return null;
+        }
+        DecoderData decoderData = null;
+        MediaCodec.BufferInfo ifo = null;
+        synchronized(mLock) {
+            decoderData = mDecoderDataCache.pollFirst();
+            if (decoderData == null) {
+                decoderData = new DecoderData();
+            }
+            decoderData.getInfo().clear();
+            decoderData.mBuffer = buffer;
+            decoderData.mIdx = outputBufferId;
+            for (MediaCodec.BufferInfo info : infos) {
+                ifo = mBufferInfoCache.pollFirst();
+                if (ifo == null) {
+                    ifo = new MediaCodec.BufferInfo();
+                }
+                ifo.set(info.offset,
+                        info.size,
+                        info.presentationTimeUs,
+                        info.flags);
+                decoderData.getInfo().add(ifo);
+            }
+        }
+        return decoderData;
+    }
+
     protected void onOutputAvailable(
             MediaCodec mediaCodec, int outputBufferId, BufferInfo outputBufferInfo) {
         if (mSawOutputEOS || outputBufferId < 0) {
@@ -414,26 +561,30 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
         if (DEBUG) {
             Log.d(TAG,
                     "In OutputBufferAvailable ,"
+                            + " MediaCodec buffer ID: " + outputBufferId
                             + " output frame number = " + mNumOutputFrame
                             + " timestamp = " + outputBufferInfo.presentationTimeUs
                             + " size = " + outputBufferInfo.size);
         }
-        if (mOutputStream != null) {
+        ByteBuffer outputBuffer = null;
+        if (mOutputStream != null && mSurface == null) {
             try {
-                ByteBuffer outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
-                byte[] bytesOutput = new byte[outputBuffer.remaining()];
-                outputBuffer.get(bytesOutput);
-                mOutputStream.write(bytesOutput);
+                outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
+                if (outputBuffer != null) {
+                    byte[] bytesOutput = new byte[outputBuffer.remaining()];
+                    outputBuffer.get(bytesOutput);
+                    mOutputStream.write(bytesOutput);
+                }
             } catch (IOException e) {
                 e.printStackTrace();
                 Log.d(TAG, "Error Dumping File: Exception " + e.toString());
             }
         }
+        mSawOutputEOS = (outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0;
         if (mFrameReleaseQueue != null) {
             if (mMime.startsWith("audio/")) {
                 try {
-                    ByteBuffer outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
-                    mFrameReleaseQueue.pushFrame(outputBufferId, outputBuffer.remaining());
+                    mFrameReleaseQueue.pushFrame(outputBufferId, outputBufferInfo.size);
                 } catch (Exception e) {
                     Log.d(TAG, "Error in getting MediaCodec buffer" + e.toString());
                 }
@@ -441,21 +592,24 @@ public class Decoder implements IBufferXfer.IReceiveBuffer {
                 mFrameReleaseQueue.pushFrame(mNumOutputFrame, outputBufferId,
                                                 outputBufferInfo.presentationTimeUs);
             }
-        } else if (mIBufferSend != null) {
-            IBufferXfer.BufferXferInfo info = new IBufferXfer.BufferXferInfo();
-            info.buf = mediaCodec.getOutputBuffer(outputBufferId);
-            info.idx = outputBufferId;
-            info.obj = mediaCodec;
-            info.bytesRead = outputBufferInfo.size;
-            info.presentationTimeUs = outputBufferInfo.presentationTimeUs;
-            info.flag = outputBufferInfo.flags;
-            mIBufferSend.sendBuffer(this, info);
+        } else if (mConsumer != null && mSurface == null) {
+            ArrayDeque<MediaCodec.BufferInfo> infos = new ArrayDeque<>();
+            infos.add(outputBufferInfo);
+            if(outputBuffer == null) {
+                outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
+            }
+            DecoderData data = prepareDecoderData(
+                    outputBufferId, outputBuffer, infos);
+            if (data != null) {
+                ArrayDeque<IBufferXfer.IProducerData> buffers = new ArrayDeque<>();
+                buffers.add(data);
+                sendToConsumer(buffers);
+            }
         } else {
             mediaCodec.releaseOutputBuffer(outputBufferId, mRender);
         }
-        mSawOutputEOS = (outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0;
         if (mSawOutputEOS) {
             Log.i(TAG, "Saw output EOS");
         }
     }
-}
+}
\ No newline at end of file
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Encoder.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Encoder.java
index 3aa38d1d43..1e15608ed6 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Encoder.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Encoder.java
@@ -19,6 +19,7 @@ package com.android.media.benchmark.library;
 import android.media.MediaCodec;
 import android.media.MediaCodec.CodecException;
 import android.media.MediaFormat;
+import android.media.MediaMuxer;
 import android.view.Surface;
 import android.util.Log;
 
@@ -29,17 +30,40 @@ import java.io.FileOutputStream;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 
-public class Encoder implements IBufferXfer.IReceiveBuffer {
+import java.util.ArrayDeque;
+import java.util.Iterator;
+
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.CancellationException;
+import java.util.concurrent.ExecutionException;
+
+import com.android.media.benchmark.library.IBufferXfer;
+import com.android.media.benchmark.library.Muxer;
+import com.android.media.benchmark.library.BlockModelDecoder.LinearBlockWrapper;
+
+public class Encoder implements IBufferXfer.IConsumer {
     // Change in AUDIO_ENCODE_DEFAULT_MAX_INPUT_SIZE should also be taken to
     // kDefaultAudioEncodeFrameSize present in BenchmarkCommon.h
+    private static final int TIMEOUT_IN_SEC_FOR_TASK = 2;
     private static final int AUDIO_ENCODE_DEFAULT_MAX_INPUT_SIZE = 4096;
     private static final String TAG = "Encoder";
     private static final boolean DEBUG = false;
     private static final int kQueueDequeueTimeoutUs = 1000;
     private final Object mLock = new Object();
+    private final Object mFuturesLock = new Object();
+    private MediaFormat mConfiguredInputFormat = null;
     private MediaCodec mCodec = null;
+    private Muxer mMuxer = null;
+    int mTrackIndex = -1;
     private String mMime;
     private Stats mStats;
+    private long mInitTimeFragment = 0;
+    private int mFlags = 0;
 
     private int mOffset;
     private int mFrameSize;
@@ -47,7 +71,8 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
     private int mNumFrames = 0;
     private int mFrameRate;
     private int mSampleRate;
-    private long mInputBufferSize;
+    private long mInputBufferSize = 0;
+    private int mMaxInputSizeForBlockModel = 4096;
 
     private int mMinOutputBuffers = 0;
     private int mNumOutputBuffers = 0;
@@ -59,7 +84,20 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
 
     private FileInputStream mInputStream = null;
     private FileOutputStream mOutputStream = null;
-    private IBufferXfer.ISendBuffer mIBufferSend = null;
+
+    private boolean mHandleSingleInfo = true;
+    private boolean mFeederActive = false;
+    final private ArrayDeque<MediaCodec.BufferInfo> mPendingInfos = new ArrayDeque<>();
+    private final ArrayDeque<IBufferXfer.IProducerData> mReturnBuffers = new ArrayDeque<>();
+    private final ArrayDeque<QueueData> mQueueDeque = new ArrayDeque<>();
+    private final ArrayDeque<IBufferXfer.IProducerData> mProducerDataQueue = new ArrayDeque<>();
+    private final ArrayDeque<Integer> mEncoderInputBufferQueue = new ArrayDeque<>();
+    private final ArrayDeque<Future<?>> mSchedulerFutures = new ArrayDeque<>();
+    private IBufferXfer.IProducer mProducer = null;
+
+    // Need a thread to make sure that this works independently
+    private final ExecutorService mScheduler = Executors.newFixedThreadPool(1);
+
     /* success for encoder */
     public static final int ENCODE_SUCCESS = 0;
     /* some error happened during encoding */
@@ -73,24 +111,356 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
         mSawOutputEOS = false;
         mSignalledError = false;
     }
+
+    private boolean isCodecInBlockModel() {
+            return ((mFlags & MediaCodec.CONFIGURE_FLAG_USE_BLOCK_MODEL) != 0);
+    }
+
+    private class CodecBuffer {
+        private LinearBlockWrapper mLinearBlock = null;
+        private int mIdx = -1;
+        private ByteBuffer mBuffer = null;
+
+        CodecBuffer(int idx, int size) {
+            recycle(idx, size);
+        }
+
+        public int getId() {
+            return mIdx;
+        }
+
+        public LinearBlockWrapper getLinearBlock() {
+            return mLinearBlock;
+        }
+
+        public int remaining() {
+            if (isCodecInBlockModel()) {
+                return isBufferValidInBlockModel() ? mLinearBlock.getBuffer().remaining() : 0;
+            } else if (mBuffer != null) {
+                return mBuffer.remaining();
+            }
+            return 0;
+        }
+
+        public void recycle(int bufferIdx, int size) {
+            if (mLinearBlock != null) {
+                release();
+            }
+            setBuffer(bufferIdx, size);
+        }
+
+        public void release() {
+            if (mLinearBlock != null) {
+                mLinearBlock.recycle();
+            }
+            mLinearBlock = null;
+            mBuffer = null;
+            mIdx = -1;
+        }
+
+        public boolean put(ByteBuffer buffer) {
+            if (buffer == null) {
+                return true;
+            }
+            if (isCodecInBlockModel()) {
+                if (isBufferValidInBlockModel()) {
+                    int size = buffer.remaining();
+                    mLinearBlock.getBuffer().put(buffer);
+                    mLinearBlock.setOffset(mLinearBlock.getOffset() + size);
+                    return true;
+                }
+
+            } else if (mBuffer != null) {
+                mBuffer.put(buffer);
+                return true;
+            }
+            return false;
+        }
+
+        public boolean put(byte[] buffer, int offset, int size) {
+            if (buffer == null) {
+                return true;
+            }
+            if (isCodecInBlockModel()) {
+                if (isBufferValidInBlockModel()) {
+                    mLinearBlock.getBuffer().put(buffer, offset, size);
+                    mLinearBlock.setOffset(offset + size);
+                    return true;
+                }
+
+            } else if (mBuffer != null) {
+                mBuffer.put(buffer, offset, size);
+                return true;
+            }
+            return false;
+        }
+
+        private void setBuffer(int bufferIdx, int size) {
+            if (isCodecInBlockModel()) {
+                if (isBufferValidInBlockModel() == false) {
+                    mLinearBlock = new LinearBlockWrapper();
+                }
+                if ((mLinearBlock.getBufferCapacity() - mLinearBlock.getOffset()) < size) {
+                    mLinearBlock.allocateBlock(mCodec.getCanonicalName(), size);
+                }
+            } else {
+                mBuffer = mCodec.getInputBuffer(bufferIdx);
+            }
+            mIdx = bufferIdx;
+        }
+
+        private boolean isBufferValidInBlockModel() {
+            return (mLinearBlock != null);
+        }
+    }
+
+    public void handleFuture(Future<?> future) {
+        synchronized(mFuturesLock) {
+            if (future != null) {
+                mSchedulerFutures.add(future);
+            }
+            while (mSchedulerFutures.isEmpty() == false
+                && mSchedulerFutures.peekFirst().isDone() == true) {
+                Future<?> task = mSchedulerFutures.pollFirst();
+                try {
+                    task.get();
+                } catch(Exception e) {
+                    Log.d (TAG, "Scheduler encountered an exception " + e.toString());
+                }
+            }
+        }
+    }
+
+    private static class QueueData {
+        public CodecBuffer mBuffer;
+        public ArrayDeque<MediaCodec.BufferInfo> mInfo;
+    }
+
     @Override
-    public boolean receiveBuffer(IBufferXfer.BufferXferInfo info) {
-        if (DEBUG) {
-            Log.d(TAG,"Encoder Getting buffers from external: "
-                + " Bytes Read: " + info.bytesRead
-                + " PresentationUs " + info.presentationTimeUs
-                + " flags: " + info.flag);
-        }
-        MediaCodec codec = (MediaCodec)info.obj;
-        codec.queueInputBuffer(info.idx, 0, info.bytesRead,
-            info.presentationTimeUs, info.flag);
+    public boolean setProducer(@NonNull IBufferXfer.IProducer producer) {
+        mProducer = producer;
         return true;
     }
+
     @Override
-    public boolean connect(IBufferXfer.ISendBuffer receiver) {
-        mIBufferSend = receiver;
+    public boolean consume(final ArrayDeque<IBufferXfer.IProducerData> buffers) {
+        boolean shouldSchedule = false;
+        synchronized(mLock) {
+            mProducerDataQueue.addAll(buffers);
+            shouldSchedule = (mEncoderInputBufferQueue.isEmpty() == false)
+                    && (mFeederActive == false);
+            if (shouldSchedule) {
+                mFeederActive = true;
+            }
+        }
+        if (shouldSchedule == true) {
+            Future<?> future = mScheduler.submit(() -> { feedBuffersToEncoder(); });
+            handleFuture(future);
+        }
+        return true;
+    }
+
+    private boolean queueBuffersArrayToCodec(ArrayDeque<QueueData> buffers) {
+        if (buffers == null) {
+            return false;
+        }
+        for (QueueData buffer : buffers) {
+            queueBuffersToCodec(buffer.mBuffer, buffer.mInfo);
+        }
         return true;
     }
+
+    private boolean queueBuffersToCodec(
+            CodecBuffer buffer, ArrayDeque<MediaCodec.BufferInfo> infos) {
+        if (infos == null || infos.isEmpty()) {
+            Log.d(TAG, "Problem with infos Cannot send buffers to codec");
+            return false;
+        }
+        int nBuffers = infos.size();
+        if (nBuffers == 1) {
+            MediaCodec.BufferInfo info = infos.getFirst();
+            if (isCodecInBlockModel()) {
+                MediaCodec.QueueRequest request = mCodec.getQueueRequest(buffer.getId());
+                request.setLinearBlock(
+                        buffer.getLinearBlock().getBlock(), info.offset, info.size);
+                request.setPresentationTimeUs(info.presentationTimeUs);
+                request.setFlags(info.flags);
+                request.queue();
+            } else {
+                mCodec.queueInputBuffer(
+                        buffer.getId(),
+                        info.offset,
+                        info.size,
+                        info.presentationTimeUs,
+                        info.flags);
+            }
+         } else {
+            if (isCodecInBlockModel()) {
+                MediaCodec.QueueRequest request = mCodec.getQueueRequest(buffer.getId());
+                request.setMultiFrameLinearBlock(buffer.getLinearBlock().getBlock(), infos);
+                request.queue();
+            } else {
+                mCodec.queueInputBuffers(buffer.getId(), infos);
+            }
+         }
+         mNumInputFrame += nBuffers;
+         return true;
+    }
+
+    // Called from a thread
+    private void feedBuffersToEncoder() {
+        int processedBuffers = 0;
+        synchronized(mLock) {
+            mFeederActive = false;
+            mQueueDeque.clear();
+            mReturnBuffers.clear();
+            if (mProducerDataQueue.isEmpty() == true
+                    || mEncoderInputBufferQueue.isEmpty() == true) {
+                Log.d(TAG, "Nothing to process, produced " + mProducerDataQueue.size()
+                        + " # codec buffers " + mEncoderInputBufferQueue.size());
+                return;
+            }
+            ArrayDeque<MediaCodec.BufferInfo> codecInfos = new ArrayDeque<>();
+            IBufferXfer.IProducerData pData = null;
+            ByteBuffer pBuffer = null;
+            Iterator<MediaCodec.BufferInfo> pInfoCheck = null;
+            Iterator<Integer> encoderBufIt = mEncoderInputBufferQueue.iterator();
+            // first handle any pending infos
+            if (mPendingInfos.isEmpty() == false) {
+                // Log.d(TAG, "loading with pending size " + mPendingInfos.size());
+                pData = mProducerDataQueue.peekFirst();
+                pBuffer = pData.getBuffer();
+                pInfoCheck = (pData != null && mPendingInfos.isEmpty() == false) ?
+                        mPendingInfos.iterator() : null;
+            } else {
+                pData = mProducerDataQueue.peekFirst();
+                pInfoCheck = (pData != null && pData.getInfo().isEmpty() == false) ?
+                        pData.getInfo().iterator() : null;
+                // Log.d(TAG, "loading with normal " + pData.getInfo().size());
+                pBuffer = pData.getBuffer();
+            }
+            if (pInfoCheck == null || pInfoCheck.hasNext() == false) {
+                Log.d(TAG, "Something wrong with input data, no infos found");
+                return;
+            }
+            int encoderIdx = encoderBufIt.next();
+            encoderBufIt.remove();
+            //TODO for blockmodel
+            if (pBuffer != null) {
+                mMaxInputSizeForBlockModel = Math.max(
+                        mMaxInputSizeForBlockModel, pBuffer.remaining());
+            }
+            CodecBuffer codecBuffer = new CodecBuffer(encoderIdx, mMaxInputSizeForBlockModel);
+            if (DEBUG) {
+                Log.d(TAG, "MaxInputSize for BlockModel " + mMaxInputSizeForBlockModel);
+            }
+            MediaCodec.BufferInfo currentPInfo = null;
+            while (encoderIdx != -1) {
+                int toCopy = 0;
+                boolean handleSingleInfo = mHandleSingleInfo;
+                boolean isArrayBackedBuffer =
+                        (pBuffer != null && pBuffer.hasArray()) ? true : false;
+                codecInfos.clear();
+                if (currentPInfo == null && pInfoCheck.hasNext()) {
+                    currentPInfo = pInfoCheck.next();
+                }
+                if (isArrayBackedBuffer == false) {
+                    handleSingleInfo = false;
+                }
+                while (currentPInfo != null &&
+                        ((toCopy + currentPInfo.size) <= codecBuffer.remaining())) {
+                    toCopy += currentPInfo.size;
+                    codecInfos.add(currentPInfo);
+                    if (mPendingInfos.isEmpty() == false) {
+                        pInfoCheck.remove();
+                    }
+                    currentPInfo = null;
+                    if (handleSingleInfo == false && pInfoCheck.hasNext()) {
+                        currentPInfo = pInfoCheck.next();
+                    }
+                }
+                if (toCopy > 0) {
+                    if (isArrayBackedBuffer == true) {
+                        codecBuffer.put(pBuffer.array(), pBuffer.arrayOffset(), toCopy);
+                    } else {
+                        if (currentPInfo != null) {
+                            Log.d(TAG,"Butter without backing size " + currentPInfo.size
+                                    + "cannot fit into codec buffer size "
+                                    + codecBuffer.remaining());
+                            return;
+                        }
+                        codecBuffer.put(pBuffer);
+                    }
+                }
+                if (codecInfos.isEmpty()) {
+                    Log.d(TAG, "Cannot find any infos for codec id " + encoderIdx
+                        + ", problem with input."
+                        + " Codec Buffer size " + codecBuffer.remaining()
+                        + " toCopy " + toCopy);
+                    return;
+                }
+                QueueData qData = new QueueData();
+                qData.mBuffer = codecBuffer;
+                qData.mInfo = codecInfos.clone();
+                mQueueDeque.add(qData);
+                codecInfos.clear(); encoderIdx = -1;
+
+                if (currentPInfo == null && pInfoCheck.hasNext() == false) {
+                    mReturnBuffers.add(pData);
+                    mProducerDataQueue.removeFirst();
+                    processedBuffers++;
+                }
+
+                if (mPendingInfos.isEmpty() == true && encoderBufIt.hasNext() == false) {
+                    if (currentPInfo != null) {
+                        mPendingInfos.add(currentPInfo);
+                        currentPInfo = null;
+                    }
+                    while (pInfoCheck.hasNext()) {
+                        currentPInfo = pInfoCheck.next();
+                        mPendingInfos.add(currentPInfo);
+                        currentPInfo = null;
+                    }
+                }
+
+                if (mProducerDataQueue.isEmpty() == false && encoderBufIt.hasNext() == true) {
+                    // Continue if we have more producer and encoder buffer
+                    encoderIdx = encoderBufIt.hasNext() ? encoderBufIt.next() : -1;
+                    if (encoderIdx != -1) {
+                        codecBuffer = new CodecBuffer(encoderIdx, mMaxInputSizeForBlockModel);
+                        encoderBufIt.remove();
+                        pData = mProducerDataQueue.peekFirst();
+                        pBuffer = pData.getBuffer();
+                        if (pData.getInfo() == null) {
+                            Log.d(TAG, "Corrupted input data, wrong infos");
+                            return;
+                        }
+                        if (currentPInfo == null && pInfoCheck.hasNext() == false) {
+                            pInfoCheck = pData.getInfo().iterator();
+                        }
+                    }
+                }
+            }
+        }
+        if (mQueueDeque.isEmpty() == false) {
+            queueBuffersArrayToCodec(mQueueDeque);
+            for (QueueData data : mQueueDeque) {
+                data.mBuffer.release();
+            }
+            mQueueDeque.clear();
+        }
+        if (mReturnBuffers.isEmpty() == false) {
+            if (DEBUG) {
+                Log.d(TAG, "Returning " + mReturnBuffers.size() + " buffers to producer");
+            }
+            mProducer.returnBuffers(mReturnBuffers);
+        }
+        if (DEBUG) {
+            Log.d(TAG, "Processed " + processedBuffers + " during this call "
+                    +  "remain: " + mProducerDataQueue.size());
+        }
+    }
+
     public Stats getStats() { return mStats; };
 
     /**
@@ -116,7 +486,7 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
         this.mMinOutputBuffers = numOutputBuffers;
     }
 
-    private MediaCodec createCodec(String codecName, String mime) throws IOException {
+    private MediaCodec createCodec_l(String codecName, String mime) throws IOException {
         try {
             MediaCodec codec;
             if (codecName.isEmpty()) {
@@ -147,44 +517,138 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
      * use for encode.
      *
      * @param codecName    Will create the encoder with codecName
-     * @param encodeFormat Format of the output data
      * @param mime         For creating encode format
      * @return ENCODE_SUCCESS if encode was successful,
      *         ENCODE_CREATE_ERROR for encoder not created
      * @throws IOException If the codec cannot be created.
      */
 
-    public int createAndConfigure(String codecName, MediaFormat encodeFormat,
-                                  String mime) throws IOException {
+    public int createCodec(String codecName, String mime) throws IOException {
         if (mCodec == null) {
+            long sTime = mStats.getCurTime();
             mMime = mime;
-            mCodec = createCodec(codecName, mime);
+            mCodec = createCodec_l(codecName, mime);
             if (mCodec == null) {
                 return ENCODE_CREATE_ERROR;
             }
-            /*Configure Codec*/
-            try {
-                mCodec.configure(encodeFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE);
-            } catch(IllegalArgumentException
-                  | IllegalStateException
-                  | MediaCodec.CryptoException e) {
-                Log.e(TAG, "Failed to configure " + mCodec.getName() + " encoder.");
-                e.printStackTrace();
-                return ENCODE_CREATE_ERROR;
-            }
+            mInitTimeFragment += mStats.getTimeDiff(sTime, mStats.getCurTime());
+        }
+        return ENCODE_SUCCESS;
+    }
+    public MediaFormat getInputFormat() {
+        return mConfiguredInputFormat;
+    }
+    public int configureCodec(MediaFormat encodeFormat, boolean asyncMode, int flags) {
+        mFlags = flags;
+        return configureCodec(encodeFormat, asyncMode);
+    }
+    public int configureCodec(MediaFormat encodeFormat, boolean asyncMode) {
+        if (mCodec == null) {
+            Log.d(TAG, "Cannot configure without a valid codec");
+            return ENCODE_CREATE_ERROR;
+        }
+        long sTime = mStats.getCurTime();
+        if (asyncMode) {
+            setCallback();
+        }
+        /*Configure Codec*/
+        try {
+            mCodec.configure(encodeFormat, null, null, MediaCodec.CONFIGURE_FLAG_ENCODE | mFlags);
+        } catch(IllegalArgumentException
+              | IllegalStateException
+              | MediaCodec.CryptoException e) {
+            Log.e(TAG, "Failed to configure " + mCodec.getName() + " encoder.");
+            e.printStackTrace();
+            return ENCODE_CREATE_ERROR;
         }
+        mInitTimeFragment += mStats.getTimeDiff(sTime, mStats.getCurTime());
+        mConfiguredInputFormat = mCodec.getInputFormat();
         return ENCODE_SUCCESS;
     }
+    public void setCallback() {
+        mCodec.setCallback(new MediaCodec.Callback() {
+            @Override
+            public void onInputBufferAvailable(@NonNull MediaCodec mediaCodec,
+                                               int inputBufferId) {
+                try {
+                    mStats.addInputTime();
+                    onInputAvailable(mediaCodec, inputBufferId);
+                } catch (Exception e) {
+                    e.printStackTrace();
+                    Log.e(TAG, e.toString());
+                }
+            }
+
+            @Override
+            public void onOutputBufferAvailable(@NonNull MediaCodec mediaCodec,
+                                                int outputBufferId,
+                                                @NonNull MediaCodec.BufferInfo bufferInfo) {
+                mStats.addOutputTime();
+                onOutputAvailable(mediaCodec, outputBufferId, bufferInfo);
+                if (mSawOutputEOS) {
+                    Log.i(TAG, "Saw output EOS");
+                    synchronized (mLock) { mLock.notify(); }
+                }
+            }
+
+            @Override
+            public void onOutputBuffersAvailable(@NonNull MediaCodec mediaCodec,
+                                                int outputBufferId,
+                                                @NonNull ArrayDeque<MediaCodec.BufferInfo> infos) {
+                mStats.addOutputTime(infos.size());
+                onOutputsAvailable(mediaCodec, outputBufferId, infos);
+                if (mSawOutputEOS) {
+                    Log.i(TAG, "Saw output EOS");
+                    synchronized (mLock) { mLock.notify(); }
+                }
+            }
+
+            @Override
+            public void onError(@NonNull MediaCodec mediaCodec, @NonNull CodecException e) {
+                mSignalledError = true;
+                Log.e(TAG, "Codec Error: " + e.toString());
+                e.printStackTrace();
+                synchronized (mLock) { mLock.notify(); }
+            }
+
+            @Override
+            public void onOutputFormatChanged(@NonNull MediaCodec mediaCodec,
+                                              @NonNull MediaFormat format) {
+                Log.i(TAG, "Output format changed. Format: " + format.toString());
+                if (format != null) {
+                    if (format.containsKey(MediaFormat.KEY_BUFFER_BATCH_MAX_OUTPUT_SIZE)) {
+                        int maxOutputSize = format.getInteger(
+                                MediaFormat.KEY_BUFFER_BATCH_MAX_OUTPUT_SIZE);
+                        if (maxOutputSize > 0) {
+                            Log.d(TAG, "Output format Large Audio max " + maxOutputSize);
+                            mHandleSingleInfo = false;
+                        }
+                    }
+                    if (mMuxer != null) {
+                        try {
+                            mTrackIndex = mMuxer.setUpMuxer(mOutputStream.getFD(),
+                                    MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4, format);
+                        } catch (IOException e) {
+                            Log.d(TAG, "Muxer initialization failed.");
+                            mTrackIndex = -1;
+                            mMuxer.deInitMuxer();
+                            mMuxer = null;
+                        }
+                    }
+                }
+            }
+        });
+    }
     /**
      * Requests the surface to use as input to the encoder
      * @return a valid surface or null if not called after configure.
      */
     public Surface getInputSurface() {
-        Surface inputSurface = null;
-        if (mCodec != null) {
-            inputSurface = mCodec.createInputSurface();
+        if (mCodec == null) {
+            Log.d(TAG, "Codec is null, cannot get input surface");
+            return null;
         }
-        return inputSurface;
+        return mCodec.createInputSurface();
     }
     /**
      * Encodes the given raw input file and measures the performance of encode operation,
@@ -206,12 +670,24 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
         mOffset = 0;
         mFrameRate = frameRate;
         mSampleRate = sampleRate;
-        long sTime = mStats.getCurTime();
         if (mCodec == null) {
-            int status = createAndConfigure(codecName, encodeFormat, mime);
+            long sTime = mStats.getCurTime();
+            int status = createCodec(codecName, mime);
             if(status != ENCODE_SUCCESS) {
               return status;
             }
+            if (asyncMode) {
+                setCallback();
+            }
+            status = configureCodec(encodeFormat, asyncMode);
+            if (status != ENCODE_SUCCESS) {
+                return status;
+            }
+            mInitTimeFragment += mStats.getTimeDiff(sTime, mStats.getCurTime());
+
+        }
+        if (mOutputStream != null) {
+            mMuxer = new Muxer();
         }
         if (!mUseSurface) {
             if (mMime.startsWith("video/")) {
@@ -229,50 +705,11 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
             }
             mNumFrames = (int) ((mInputBufferSize + mFrameSize - 1) / mFrameSize);
         }
-        if (asyncMode) {
-            mCodec.setCallback(new MediaCodec.Callback() {
-                @Override
-                public void onInputBufferAvailable(@NonNull MediaCodec mediaCodec,
-                                                   int inputBufferId) {
-                    try {
-                        mStats.addInputTime();
-                        onInputAvailable(mediaCodec, inputBufferId);
-                    } catch (Exception e) {
-                        e.printStackTrace();
-                        Log.e(TAG, e.toString());
-                    }
-                }
-
-                @Override
-                public void onOutputBufferAvailable(@NonNull MediaCodec mediaCodec,
-                                                    int outputBufferId,
-                                                    @NonNull MediaCodec.BufferInfo bufferInfo) {
-                    mStats.addOutputTime();
-                    onOutputAvailable(mediaCodec, outputBufferId, bufferInfo);
-                    if (mSawOutputEOS) {
-                        Log.i(TAG, "Saw output EOS");
-                        synchronized (mLock) { mLock.notify(); }
-                    }
-                }
-
-                @Override
-                public void onError(@NonNull MediaCodec mediaCodec, @NonNull CodecException e) {
-                    mSignalledError = true;
-                    Log.e(TAG, "Codec Error: " + e.toString());
-                    e.printStackTrace();
-                    synchronized (mLock) { mLock.notify(); }
-                }
-
-                @Override
-                public void onOutputFormatChanged(@NonNull MediaCodec mediaCodec,
-                                                  @NonNull MediaFormat format) {
-                    Log.i(TAG, "Output format changed. Format: " + format.toString());
-                }
-            });
-        }
         mCodec.start();
-        long eTime = mStats.getCurTime();
-        mStats.setInitTime(mStats.getTimeDiff(sTime, eTime));
+        if (mInitTimeFragment != 0) {
+            mStats.setInitTime(mInitTimeFragment);
+            mInitTimeFragment = 0;
+        }
         mStats.setStartTime();
         if (asyncMode) {
             try {
@@ -307,6 +744,17 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
                 if (outputBufferId < 0) {
                     if (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
                         MediaFormat outFormat = mCodec.getOutputFormat();
+                        if (mMuxer != null) {
+                            try {
+                                mTrackIndex = mMuxer.setUpMuxer(mOutputStream.getFD(),
+                                    MediaMuxer.OutputFormat.MUXER_OUTPUT_MPEG_4, outFormat);
+                            } catch (IOException e) {
+                                Log.d(TAG, "Muxer initialization failed.");
+                                mTrackIndex = -1;
+                                mMuxer.deInitMuxer();
+                                mMuxer = null;
+                            }
+                        }
                         Log.i(TAG, "Output format changed. Format: " + outFormat.toString());
                     } else if (outputBufferId != MediaCodec.INFO_TRY_AGAIN_LATER) {
                         Log.e(TAG, "MediaCodec.dequeueOutputBuffer" + " returned invalid index " +
@@ -322,9 +770,81 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
                 }
             }
         }
+        if (mMuxer != null && mTrackIndex != -1) {
+            mMuxer.deInitMuxer();
+            mMuxer.resetMuxer();
+        }
         return ENCODE_SUCCESS;
     }
 
+    private void onOutputsAvailable(MediaCodec mediaCodec, int outputBufferId,
+                                   ArrayDeque<MediaCodec.BufferInfo> infos) {
+        if (mSawOutputEOS || outputBufferId < 0) {
+            if (mSawOutputEOS) {
+                Log.i(TAG, "Saw output EOS");
+            }
+            return;
+        }
+        ByteBuffer outputBuffer = null;
+        MediaCodec.OutputFrame outFrame = null;
+        if (isCodecInBlockModel()) {
+            outFrame = mediaCodec.getOutputFrame(outputBufferId);
+            try {
+                if (outFrame.getLinearBlock() != null) {
+                    outputBuffer = outFrame.getLinearBlock().map();
+                }
+            } catch(IllegalStateException e) {
+                // buffer may not be linear, this is ok
+                // as we are handling non-linear buffers below.
+            }
+
+        } else {
+            outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
+        }
+        if (outputBuffer != null) {
+            mStats.addFrameSize(outputBuffer.remaining());
+            if (DEBUG) {
+                Log.d(TAG,
+                        "In OutputBufferAvailable ,"
+                        + " info size = " + infos.size()
+                        + " info first ts " + infos.getFirst().presentationTimeUs
+                        + " total size = " + outputBuffer.remaining());
+            }
+        }
+
+        if (mOutputStream != null) {
+            if (mMuxer != null && mTrackIndex != -1) {
+                mMuxer.mux(mTrackIndex, outputBuffer, infos);
+            } else {
+                try {
+                    if (outputBuffer != null) {
+                        byte[] bytesOutput = new byte[outputBuffer.remaining()];
+                        outputBuffer.get(bytesOutput);
+                        mOutputStream.write(bytesOutput);
+                    }
+                } catch (IOException e) {
+                    e.printStackTrace();
+                    Log.d(TAG, "Error Dumping File: Exception " + e.toString());
+                    return;
+                }
+            }
+        }
+        if (outFrame != null && (outFrame.getLinearBlock() != null)) {
+            outFrame.getLinearBlock().recycle();
+        }
+        mNumOutputBuffers += infos.size();
+        int flag = 0;
+        if (!infos.isEmpty()) {
+            flag = infos.peekLast().flags;
+        }
+
+        mediaCodec.releaseOutputBuffer(outputBufferId, false);
+        mSawOutputEOS = (flag & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0;
+        if (mUseSurface && !mSawOutputEOS) {
+            mSawOutputEOS = (mNumOutputBuffers >= mMinOutputBuffers) ? true : false;
+        }
+    }
+
     private void onOutputAvailable(MediaCodec mediaCodec, int outputBufferId,
                                    MediaCodec.BufferInfo outputBufferInfo) {
         if (mSawOutputEOS || outputBufferId < 0) {
@@ -333,29 +853,55 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
             }
             return;
         }
-        ByteBuffer outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
-        if (mOutputStream != null) {
+        ByteBuffer outputBuffer = null;
+        MediaCodec.OutputFrame outFrame = null;
+        if (isCodecInBlockModel()) {
+            outFrame = mediaCodec.getOutputFrame(outputBufferId);
             try {
-
-                byte[] bytesOutput = new byte[outputBuffer.remaining()];
-                outputBuffer.get(bytesOutput);
-                mOutputStream.write(bytesOutput);
-            } catch (IOException e) {
-                e.printStackTrace();
-                Log.d(TAG, "Error Dumping File: Exception " + e.toString());
-                return;
+                if (outFrame.getLinearBlock() != null) {
+                    outputBuffer = outFrame.getLinearBlock().map();
+                }
+            } catch(IllegalStateException e) {
+                // buffer may not be linear, this is ok
+                // as we are handling non-linear buffers below.
             }
+        } else {
+            outputBuffer = mediaCodec.getOutputBuffer(outputBufferId);
+        }
+        if (outputBuffer != null) {
+            mStats.addFrameSize(outputBuffer.remaining());
         }
+        if (mOutputStream != null) {
+            if (mMuxer != null && mTrackIndex != -1) {
+                ArrayDeque<MediaCodec.BufferInfo> infos = new ArrayDeque<>();
+                infos.add(outputBufferInfo);
+                mMuxer.mux(mTrackIndex, outputBuffer, infos);
+            } else {
+                try {
+                    byte[] bytesOutput = new byte[outputBuffer.remaining()];
+                    outputBuffer.get(bytesOutput);
+                    mOutputStream.write(bytesOutput);
+                } catch (IOException e) {
+                    e.printStackTrace();
+                    Log.d(TAG, "Error Dumping File: Exception " + e.toString());
+                    return;
+                }
+            }
+
+        }
+        if ((outFrame != null) && (outFrame.getLinearBlock() != null)) {
+            outFrame.getLinearBlock().recycle();
+        }
+
         mNumOutputBuffers++;
         if (DEBUG) {
             Log.d(TAG,
-                "In OutputBufferAvailable ,"
-                + " timestamp = " + outputBufferInfo.presentationTimeUs
-                + " size = " + outputBufferInfo.size
-                + " flags = " + outputBufferInfo.flags);
+                    "In OutputBufferAvailable ,"
+                    + " timestamp = " + outputBufferInfo.presentationTimeUs
+                    + " size = " + outputBufferInfo.size
+                    + " flags = " + outputBufferInfo.flags);
         }
 
-        mStats.addFrameSize(outputBuffer.remaining());
         mediaCodec.releaseOutputBuffer(outputBufferId, false);
         mSawOutputEOS = (outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0;
         if (mUseSurface && !mSawOutputEOS) {
@@ -375,19 +921,31 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
             mSignalledError = true;
             return;
         }
+        if (DEBUG) {
+            Log.d(TAG, "onInputAvailable ID " + inputBufferId);
+        }
+
+        if (mProducer != null) {
+            boolean shouldSchedule = false;
+            synchronized(mLock) {
+                mEncoderInputBufferQueue.add(inputBufferId);
+                if ((mProducerDataQueue.isEmpty() == false)
+                        && (mFeederActive == false)) {
+                    shouldSchedule = true;
+                    mFeederActive = true;
+                }
+            }
+            if (shouldSchedule == true) {
+                Future<?> future = mScheduler.submit(() -> { feedBuffersToEncoder(); });
+                handleFuture(future);
+            }
+            return;
+        }
         ByteBuffer inputBuffer = mCodec.getInputBuffer(inputBufferId);
         if (inputBuffer == null) {
             mSignalledError = true;
             return;
         }
-        if (mIBufferSend != null) {
-            IBufferXfer.BufferXferInfo info = new IBufferXfer.BufferXferInfo();
-            info.buf = inputBuffer;
-            info.idx = inputBufferId;
-            info.obj = mediaCodec;
-            mIBufferSend.sendBuffer(this, info);
-            return;
-        }
         int bufSize = inputBuffer.capacity();
         int bytesToRead = mFrameSize;
         if (mInputBufferSize - mOffset < mFrameSize) {
@@ -468,5 +1026,21 @@ public class Encoder implements IBufferXfer.IReceiveBuffer {
         mSignalledError = false;
         mUseSurface = false;
         mStats.reset();
+        synchronized(mFuturesLock) {
+            while (mSchedulerFutures.isEmpty() == false) {
+                Future<?> future = mSchedulerFutures.pollFirst();
+                try {
+                    future.get(TIMEOUT_IN_SEC_FOR_TASK, TimeUnit.SECONDS);
+                } catch (TimeoutException e) {
+                    Log.d(TAG, "Future timed-out in scheduler " +  e.toString());
+                    future.cancel(true);
+                } catch (InterruptedException | ExecutionException e) {
+                    Log.d(TAG, "Future exception in scheduler " + e.toString());
+                }
+            }
+        }
+        if (mScheduler != null) {
+            mScheduler.shutdownNow();
+        }
     }
 }
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/FrameReleaseQueue.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/FrameReleaseQueue.java
index 0861c2ce7b..704d12428d 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/FrameReleaseQueue.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/FrameReleaseQueue.java
@@ -72,10 +72,11 @@ public class FrameReleaseQueue {
     }
 
     private static class FrameInfo {
-        private int number;
+        private int number = 0;
         private int bufferId;
         private int displayTime;
         private int bytes;
+        private MediaCodec.OutputFrame mOutputFrame = null;
         public FrameInfo(int frameNumber, int frameBufferId, int frameDisplayTime) {
             this.number = frameNumber;
             this.bufferId = frameBufferId;
@@ -85,6 +86,9 @@ public class FrameReleaseQueue {
             this.bufferId = frameBufferId;
             this.bytes = bytes;
         }
+        public void setOutputFrame(MediaCodec.OutputFrame frame) {
+            mOutputFrame = frame;
+        }
     }
 
     private class ReleaseThread extends Thread {
@@ -205,7 +209,17 @@ public class FrameReleaseQueue {
             }
             if (mCurrentFrameInfo != null) {
                 try {
-                    mCodec.releaseOutputBuffer(mCurrentFrameInfo.bufferId, mRender);
+                    if (mCurrentFrameInfo.mOutputFrame != null) {
+                        try {
+                            if (mCurrentFrameInfo.mOutputFrame.getLinearBlock() != null) {
+                                mCurrentFrameInfo.mOutputFrame.getLinearBlock().recycle();
+                            }
+                        } catch (IllegalStateException e) {
+                            Log.d(TAG, "Block model buffer recycle error " + e.toString());
+                            e.printStackTrace();
+                        }
+                    }
+                    mCodec.releaseOutputBuffer(mCurrentFrameInfo.bufferId, false);
                 } catch (IllegalStateException e) {
                     doFrameRelease.set(false);
                     Log.e(TAG, "Threw InterruptedException on releaseOutputBuffer");
@@ -276,6 +290,22 @@ public class FrameReleaseQueue {
         }
         return true;
     }
+
+    // For Block_Model (audio)
+    public boolean pushFrame(int frameBufferId, MediaCodec.OutputFrame outFrame, int bytes) {
+        FrameInfo info = new FrameInfo(frameBufferId, bytes);
+        info.setOutputFrame(outFrame);
+        boolean pushSuccess = mFrameInfoQueue.offer(info);
+        if (!pushSuccess) {
+            Log.e(TAG, "Failed to push frame with buffer id " + info.bufferId);
+            return false;
+        }
+        if (!mReleaseJobStarted.get()) {
+            mScheduler.execute(mReleaseThread);
+            mReleaseJobStarted.set(true);
+        }
+        return true;
+    }
     public boolean pushFrame(int frameNumber, int frameBufferId, long frameDisplayTime) {
         int frameDisplayTimeMs = (int)(frameDisplayTime/1000);
         FrameInfo curFrameInfo = new FrameInfo(frameNumber, frameBufferId, frameDisplayTimeMs);
@@ -305,6 +335,15 @@ public class FrameReleaseQueue {
 
             CompletableFuture.runAsync(() -> {
                 try {
+                    if (curFrameInfo.mOutputFrame != null) {
+                        try {
+                            if (curFrameInfo.mOutputFrame.getLinearBlock() != null) {
+                                curFrameInfo.mOutputFrame.getLinearBlock().recycle();
+                            }
+                        } catch (IllegalStateException e) {
+                            // nothing to do
+                        }
+                    }
                     mCodec.releaseOutputBuffer(curFrameInfo.bufferId, actualRender);
                 } catch (IllegalStateException e) {
                     throw(e);
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXfer.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXfer.java
index bbc3d48fad..63d22ee847 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXfer.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXfer.java
@@ -17,6 +17,8 @@
 package com.android.media.benchmark.library;
 import android.media.MediaCodec;
 
+import androidx.annotation.NonNull;
+
 import java.util.ArrayDeque;
 import java.nio.ByteBuffer;
 /**
@@ -35,20 +37,23 @@ public class IBufferXfer {
       public long presentationTimeUs;
   }
 
-  public interface IReceiveBuffer {
-      // Implemented by sender to get buffers back
-      boolean receiveBuffer(BufferXferInfo info);
-      // Establishes a connection between the buffer sender and receiver.
-      // Implemented by the entity that sends the buffers to receiver.
-      // the receiverInterface is the interface of the receiver.
-      // The sender uses this interface to send buffers.
-      boolean connect(IBufferXfer.ISendBuffer receiverInterface);
-  }
-  // Implemented by an entity that does not own the buffers and only
-  // wants to manage the buffers. ( Usually the receiver)
-  // The receiver uses returnIface to return the buffers to sender
-  public interface ISendBuffer {
-      boolean sendBuffer(IBufferXfer.IReceiveBuffer returnIface,
-                              BufferXferInfo info);
-  }
+    public interface IProducerData {
+          ByteBuffer getBuffer();
+          ArrayDeque<MediaCodec.BufferInfo> getInfo();
+    }
+    public interface IProducer {
+        // sets the consumer for sending buffers using 'consume'
+        boolean setConsumer(@NonNull IConsumer consumer);
+        // to enable consumers to send set of buffers back after consumption
+        boolean returnBuffers(@NonNull ArrayDeque<IProducerData> buffers);
+    }
+
+    public interface IConsumer {
+        // To let consumer know that if will receive buffers from here
+        // also to return buffers using 'returnBuffers'
+        boolean setProducer(@NonNull IProducer producer);
+
+        // Called by producer to send buffers to consumer.
+        boolean consume(final ArrayDeque<IProducerData> buffers);
+    }
 }
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXferImpl.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXferImpl.java
deleted file mode 100644
index c68ac8aeee..0000000000
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/IBufferXferImpl.java
+++ /dev/null
@@ -1,127 +0,0 @@
-/*
- * Copyright (C) 2022 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package com.android.media.benchmark.library;
-
-/*
- * Class that manages the buffer senders
- */
-import com.android.media.benchmark.library.IBufferXfer;
-import java.util.ArrayDeque;
-import android.util.Log;
-public class IBufferXferImpl implements IBufferXfer.ISendBuffer {
-
-  private static class BufferInfo {
-      public IBufferXfer.IReceiveBuffer rIface;
-      public IBufferXfer.BufferXferInfo info;
-  }
-  private final String TAG = "IBufferXferImpl";
-  private final ArrayDeque<BufferInfo> mProducerQueue = new ArrayDeque<>();
-  private final ArrayDeque<BufferInfo> mConsumerQueue = new ArrayDeque<>();
-  private IBufferXfer.IReceiveBuffer mProducer = null;
-  private IBufferXfer.IReceiveBuffer mConsumer = null;
-  private final Object mLock = new Object();
-
-  public IBufferXferImpl(IBufferXfer.IReceiveBuffer producer,
-      IBufferXfer.IReceiveBuffer consumer) {
-      mProducer = producer;
-      mConsumer = consumer;
-      // Attach this to be their receiver
-      mProducer.connect(this);
-      mConsumer.connect(this);
-  }
-  @Override
-  public boolean sendBuffer(IBufferXfer.IReceiveBuffer rIface,
-                     IBufferXfer.BufferXferInfo bufferInfo) {
-      if (rIface != mProducer && rIface != mConsumer) {
-         Log.e(TAG, "Interfaces does not match");
-        return false;
-      }
-      boolean status = true;
-      BufferInfo pBuf = null, cBuf = null;
-      synchronized(mLock) {
-          // see which interface this buffer belongs to
-          // producer has a filled buffer and the consumer
-          // buffer needs to be filled.
-          if ( rIface == mProducer ) {
-              if (mConsumerQueue.size() > 0) {
-                  cBuf = mConsumerQueue.remove();
-                  pBuf = new BufferInfo();
-                  pBuf.rIface = rIface;
-                  pBuf.info = bufferInfo;
-              } else {
-                  BufferInfo info = new BufferInfo();
-                  info.rIface = rIface;
-                  info.info = bufferInfo;
-                  mProducerQueue.add(info);
-              }
-          } else if(rIface == mConsumer) {
-              if (mProducerQueue.size() > 0) {
-                  pBuf = mProducerQueue.remove();
-                  cBuf = new BufferInfo();
-                  cBuf.rIface = rIface;
-                  cBuf.info = bufferInfo;
-              } else {
-                  BufferInfo info = new BufferInfo();
-                  info.rIface = rIface;
-                  info.info = bufferInfo;
-                  mConsumerQueue.add(info);
-              }
-          } else {
-              status = false;
-          }
-      }
-
-      if ( pBuf != null && cBuf != null) {
-          int bytesRead = 0;
-          if (cBuf.info.buf != null && pBuf.info.buf != null) {
-              if (cBuf.info.buf.remaining() >= pBuf.info.buf.remaining()) {
-                  bytesRead = pBuf.info.buf.remaining();
-                  cBuf.info.buf.put(pBuf.info.buf);
-              } else {
-                  Log.e(TAG, "Something is wrong with the sizes P:" +
-                      pBuf.info.buf.remaining() +" C:" + cBuf.info.buf.remaining());
-              }
-          }
-          cBuf.info.infos = pBuf.info.infos;
-          cBuf.info.bytesRead = bytesRead;
-          cBuf.info.presentationTimeUs = pBuf.info.presentationTimeUs;
-          cBuf.info.flag = pBuf.info.flag;
-          if (pBuf.rIface != null) {
-              pBuf.rIface.receiveBuffer(pBuf.info);
-          }
-          if (cBuf.rIface != null) {
-              cBuf.rIface.receiveBuffer(cBuf.info);
-          }
-      }
-      return status;
-  }
-  public boolean resetAll() {
-      synchronized(mLock) {
-          while (mProducerQueue.size() > 0) {
-              BufferInfo info = mProducerQueue.remove();
-              info.rIface.receiveBuffer(info.info);
-          }
-          while (mConsumerQueue.size() > 0) {
-              BufferInfo info = mConsumerQueue.remove();
-              info.rIface.receiveBuffer(info.info);
-          }
-          mProducer = null;
-          mConsumer = null;
-      }
-  return true;
-  }
-}
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitBlockModelDecoder.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitBlockModelDecoder.java
index d1a5d79719..58ae1a428e 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitBlockModelDecoder.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitBlockModelDecoder.java
@@ -65,6 +65,13 @@ public class MultiAccessUnitBlockModelDecoder extends BlockModelDecoder {
         throws IOException, InterruptedException {
         setExtraConfigureFlags(MediaCodec.CONFIGURE_FLAG_USE_BLOCK_MODEL);
         configureMaxInputSize(format);
+        if (format.containsKey(MediaFormat.KEY_MIME)) {
+            String mime = format.getString(MediaFormat.KEY_MIME);
+            if (!mime.startsWith("audio")) {
+                Log.d(TAG, "Multi access unit decoders are valid only for audio");
+                return -1;
+            }
+        }
         return super.decode(inputBuffer, inputBufferInfo, asyncMode, format, codecName);
     }
 
@@ -116,10 +123,11 @@ public class MultiAccessUnitBlockModelDecoder extends BlockModelDecoder {
             public void onOutputBuffersAvailable(
                     @NonNull MediaCodec mediaCodec,
                             int outputBufferId, @NonNull ArrayDeque<MediaCodec.BufferInfo> infos) {
-                int i = 0;
-                while(i++ < infos.size()) {
-                    mStats.addOutputTime();
+                double size = 0;
+                for (MediaCodec.BufferInfo info : infos) {
+                    size += info.size;
                 }
+                mStats.addOutputTime(size / DEFAULT_AUDIO_FRAME_SIZE);
                 onOutputsAvailable(mediaCodec, outputBufferId, infos);
                 if (mSawOutputEOS) {
                     synchronized (mLock) { mLock.notify(); }
@@ -217,11 +225,18 @@ public class MultiAccessUnitBlockModelDecoder extends BlockModelDecoder {
         if (mSawOutputEOS || outputBufferId < 0) {
             return;
         }
+        // Since this is only about audio, we should always check for
+        // a valid linear block.
         MediaCodec.OutputFrame outFrame = mediaCodec.getOutputFrame(outputBufferId);
         ByteBuffer outputBuffer = null;
         try {
             if (outFrame.getLinearBlock() != null) {
                 outputBuffer = outFrame.getLinearBlock().map();
+                if (DEBUG) {
+                    Log.d(TAG, "onOutputsAvailable ID : " + outputBufferId
+                            + " output info size: " + infos.size()
+                            + " Output remaining: " + outputBuffer.remaining());
+                }
             }
         } catch(IllegalStateException e) {
             // buffer may not be linear, this is ok
@@ -229,7 +244,11 @@ public class MultiAccessUnitBlockModelDecoder extends BlockModelDecoder {
         }
         if (mOutputStream != null) {
             try {
-                if (outputBuffer != null) {
+                if (outFrame.getLinearBlock() != null) {
+                    if (outputBuffer == null) {
+                        outputBuffer = outFrame.getLinearBlock().map();
+                    }
+                    int savedPosition = outputBuffer.position();
                     byte[] bytesOutput = new byte[outputBuffer.remaining()];
                     outputBuffer.get(bytesOutput);
                     mOutputStream.write(bytesOutput);
@@ -237,6 +256,7 @@ public class MultiAccessUnitBlockModelDecoder extends BlockModelDecoder {
                         Log.d(TAG, "Received outputs buffer size : " + outputBuffer.remaining()
                                 + " infos size " + infos.size());
                     }
+                    outputBuffer.position(savedPosition);
                 }
             } catch (IOException e) {
                 e.printStackTrace();
@@ -248,15 +268,36 @@ public class MultiAccessUnitBlockModelDecoder extends BlockModelDecoder {
         if (last != null) {
             mSawOutputEOS |= ((last.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0);
         }
-        int bytesRemaining = 0;
-        if (outputBuffer != null) {
-            bytesRemaining = outputBuffer.remaining();
-            outFrame.getLinearBlock().recycle();
-            outputBuffer = null;
-        }
-        if (mFrameReleaseQueue != null) {
-            mFrameReleaseQueue.pushFrame(outputBufferId, bytesRemaining);
-        } else if (mIBufferSend == null) {
+        if (mConsumer != null) {
+            if (outFrame.getLinearBlock() != null) {
+                if (outputBuffer == null) {
+                    outputBuffer = outFrame.getLinearBlock().map();
+                }
+            }
+            DecoderData data = prepareDecoderData(outputBufferId, outputBuffer, infos);
+            if (data != null) {
+                ArrayDeque<IBufferXfer.IProducerData> buffers = new ArrayDeque<>();
+                data.mOutputFrame = outFrame;
+                buffers.add(data);
+                sendToConsumer(buffers);
+            } else if (outputBuffer != null) {
+                outFrame.getLinearBlock().recycle();
+            }
+        } else if (mFrameReleaseQueue != null) {
+            // Should not come here for a video stream.
+            int bytesRemaining = 0;
+            if (outFrame.getLinearBlock() != null) {
+                if (outputBuffer == null) {
+                    outputBuffer = outFrame.getLinearBlock().map();
+                }
+                bytesRemaining = outputBuffer.remaining();
+            }
+            mFrameReleaseQueue.pushFrame(outputBufferId, outFrame, bytesRemaining);
+        } else {
+            if (outFrame != null && outFrame.getLinearBlock() != null) {
+                outFrame.getLinearBlock().recycle();
+                outputBuffer = null;
+            }
             mediaCodec.releaseOutputBuffer(outputBufferId, mRender);
         }
         if (mSawOutputEOS) {
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitDecoder.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitDecoder.java
index fd8859beb5..49b398aa1c 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitDecoder.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/MultiAccessUnitDecoder.java
@@ -77,10 +77,11 @@ public class MultiAccessUnitDecoder extends Decoder {
             public void onOutputBuffersAvailable(
                     @NonNull MediaCodec mediaCodec,
                             int outputBufferId, @NonNull ArrayDeque<BufferInfo> infos) {
-                int i = 0;
-                while(i++ < infos.size()) {
-                    mStats.addOutputTime();
+                double size = 0;
+                for (BufferInfo info : infos) {
+                    size += info.size;
                 }
+                mStats.addOutputTime(size / DEFAULT_AUDIO_FRAME_SIZE);
                 onOutputsAvailable(mediaCodec, outputBufferId, infos);
                 if (mSawOutputEOS) {
                     synchronized (mLock) { mLock.notify(); }
@@ -135,6 +136,13 @@ public class MultiAccessUnitDecoder extends Decoder {
             @NonNull List<BufferInfo> inputBufferInfo, final boolean asyncMode,
             @NonNull MediaFormat format, String codecName)
             throws IOException, InterruptedException {
+        if (format.containsKey(MediaFormat.KEY_MIME)) {
+            String mime = format.getString(MediaFormat.KEY_MIME);
+            if (!mime.startsWith("audio")) {
+                Log.d(TAG, "Multi access unit decoders are valid only for audio");
+                return -1;
+            }
+        }
         return super.decode(inputBuffer, inputBufferInfo, asyncMode, format, codecName);
     }
 
@@ -160,6 +168,11 @@ public class MultiAccessUnitDecoder extends Decoder {
                 mNumInFramesProvided++;
                 mIndex = mNumInFramesProvided % (mInputBufferInfo.size() - 1);
             }
+            if (DEBUG) {
+                Log.d(TAG, "inputsAvailable ID : " + inputBufferId
+                        + " queued info size: " + mInputInfos.size()
+                        + " Total queued size: " + offset);
+            }
             if (mNumInFramesProvided >= mNumInFramesRequired) {
                 mIndex = mInputBufferInfo.size() - 1;
                 bufInfo = mInputBufferInfo.get(mIndex);
@@ -188,33 +201,56 @@ public class MultiAccessUnitDecoder extends Decoder {
         if (mSawOutputEOS || outputBufferId < 0) {
             return;
         }
+        ByteBuffer outputBuffer = null;
         if (mOutputStream != null) {
             try {
-                ByteBuffer outputBuffer = mc.getOutputBuffer(outputBufferId);
-                byte[] bytesOutput = new byte[outputBuffer.remaining()];
-                outputBuffer.get(bytesOutput);
-                mOutputStream.write(bytesOutput);
+                outputBuffer = mc.getOutputBuffer(outputBufferId);
+                if (outputBuffer != null) {
+                    int savedPosition = outputBuffer.position();
+                    byte[] bytesOutput = new byte[outputBuffer.remaining()];
+                    outputBuffer.get(bytesOutput);
+                    mOutputStream.write(bytesOutput);
+                    outputBuffer.position(savedPosition);
+                }
             } catch (IOException e) {
                 e.printStackTrace();
                 Log.d(TAG, "Error Dumping File: Exception " + e.toString());
             }
         }
+        if (DEBUG) {
+            Log.d(TAG, "onOutputsAvailable ID : " + outputBufferId
+                    + " output info size: " + infos.size());
+        }
         mNumOutputFrame += infos.size();
         MediaCodec.BufferInfo last = infos.peekLast();
         if (last != null) {
             mSawOutputEOS |= ((last.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0);
         }
-        if (mIBufferSend != null) {
-            IBufferXfer.BufferXferInfo info = new IBufferXfer.BufferXferInfo();
-            info.buf = mc.getOutputBuffer(outputBufferId);
-            info.idx = outputBufferId;
-            info.obj = mc;
-            info.infos = infos;
-            mIBufferSend.sendBuffer(this, info);
-        } else if (mFrameReleaseQueue != null) {
-            ByteBuffer outputBuffer = mc.getOutputBuffer(outputBufferId);
+        if (mConsumer != null) {
+            if (outputBuffer == null) {
+                outputBuffer = mc.getOutputBuffer(outputBufferId);
+            }
+            DecoderData data = prepareDecoderData(
+                    outputBufferId,
+                    outputBuffer,
+                    infos);
+            if (data != null) {
+                ArrayDeque<IBufferXfer.IProducerData> buffers = new ArrayDeque<>();
+                buffers.add(data);
+                sendToConsumer(buffers);
+            }
+        }
+        else if (mFrameReleaseQueue != null) {
+            // this should be here for a video stream
+            int remaining = 0;
+            if (outputBuffer == null) {
+                outputBuffer = mc.getOutputBuffer(outputBufferId);
+                if (outputBuffer != null) {
+                    remaining = outputBuffer.remaining();
+                }
+            }
             mFrameReleaseQueue.pushFrame(
-                    outputBufferId, outputBuffer.remaining());
+                    outputBufferId, remaining);
         } else {
             mc.releaseOutputBuffer(outputBufferId, mRender);
         }
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Muxer.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Muxer.java
index 786290d477..309368083f 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Muxer.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Muxer.java
@@ -19,9 +19,10 @@ import android.content.Context;
 import android.media.MediaCodec;
 import android.media.MediaFormat;
 import android.media.MediaMuxer;
-
+import java.io.FileDescriptor;
 import java.io.IOException;
 import java.nio.ByteBuffer;
+import java.util.ArrayDeque;
 import java.util.ArrayList;
 import java.util.List;
 
@@ -54,6 +55,31 @@ public class Muxer {
         }
     }
 
+    /**
+     * Creates a Media Muxer for the specified path
+     *
+     * @param fd      FileDescriptor to which muxer should write data
+     * @param outputFormat Format of the output media file
+     * @param trackFormat  Format of the current track
+     * @return Returns the track index of the newly added track, -1 otherwise
+     */
+    public int setUpMuxer(FileDescriptor fd, int outputFormat, MediaFormat trackFormat) {
+        try {
+            mStats = new Stats();
+            long sTime = mStats.getCurTime();
+            mMuxer = new MediaMuxer(fd, outputFormat);
+            int trackIndex = mMuxer.addTrack(trackFormat);
+            mMuxer.start();
+            long eTime = mStats.getCurTime();
+            long timeTaken = mStats.getTimeDiff(sTime, eTime);
+            mStats.setInitTime(timeTaken);
+            return trackIndex;
+        } catch (IllegalArgumentException | IOException e) {
+            e.printStackTrace();
+            return -1;
+        }
+    }
+
     /**
      * Performs the Mux operation
      *
@@ -79,6 +105,29 @@ public class Muxer {
         return 0;
     }
 
+    /**
+     * Performs the Mux operation
+     *
+     * @param trackIndex            Track index of the sample
+     * @param buffer                Buffer containing encoded samples
+     * @param infos                 Buffer information related to these samples
+     * @return Returns Status as 0 if write operation is successful, -1 otherwise
+     */
+    public int mux(int trackIndex, ByteBuffer buffer,
+                   ArrayDeque<MediaCodec.BufferInfo> infos) {
+        for (MediaCodec.BufferInfo info : infos) {
+            try {
+                mMuxer.writeSampleData(trackIndex, buffer, info);
+                mStats.addOutputTime();
+                mStats.addFrameSize(info.size);
+            } catch(IllegalStateException | IllegalArgumentException e) {
+                e.printStackTrace();
+                return -1;
+            }
+        }
+        return 0;
+    }
+
     /**
      * Stops the muxer and free up the resources
      */
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/RawMediaFileStreamer.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/RawMediaFileStreamer.java
new file mode 100644
index 0000000000..81cc093d8a
--- /dev/null
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/RawMediaFileStreamer.java
@@ -0,0 +1,389 @@
+/*
+ * Copyright (C) 2025 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.android.media.benchmark.library;
+import android.media.MediaCodec;
+
+import androidx.annotation.NonNull;
+import android.util.Log;
+
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.CancellationException;
+import java.util.concurrent.ExecutionException;
+
+import java.lang.Math.*;
+import java.util.ArrayDeque;
+import java.util.Iterator;
+
+import java.io.FileInputStream;
+import java.io.FileDescriptor;
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.channels.FileChannel;
+
+import java.util.ArrayDeque;
+
+public class RawMediaFileStreamer implements IBufferXfer.IProducer {
+    private static String TAG = RawMediaFileStreamer.class.getSimpleName();
+    private static boolean DEBUG = false;
+    private static float MEMORY_USE_RATIO = 0.5f;
+    private static final int TIMEOUT_IN_SEC_FOR_TASK = 2;
+    private IBufferXfer.IConsumer mConsumer = null;
+    private FileInputStream mFile = null;
+    private FileChannel mChannel = null;
+    private int mMaxMemory = 0;
+    private int mBytesTobeConsumed = 0;
+    private boolean mEOFReached = false;
+    private int mChunkSize = 0;
+    private int mMaxChunks = 0;
+    private long mChunkTime = 0;
+    private int mChunkCounter = 0;
+    private final Object mObject = new Object();
+    private final Object mFuturesLock = new Object();
+    // a softlimit
+    private int mLowWater = 0;
+    private final ArrayDeque<IBufferXfer.IProducerData> mFileDataCache = new ArrayDeque<>();
+    private final ArrayDeque<MediaCodec.BufferInfo> mBufferInfoCache = new ArrayDeque<>();
+    private final ArrayDeque<IBufferXfer.IProducerData> mPreRoll = new ArrayDeque<>();
+    private final ArrayDeque<Future<?>> mSchedulerFutures = new ArrayDeque<>();
+    private final ExecutorService mScheduler = Executors.newFixedThreadPool(1);
+
+    private static class FileData implements IBufferXfer.IProducerData {
+        public ByteBuffer mBuffer = null;
+        public final ArrayDeque<MediaCodec.BufferInfo> mInfos = new ArrayDeque<>();
+
+        public ByteBuffer getBuffer() {
+            return mBuffer;
+        }
+        public ArrayDeque<MediaCodec.BufferInfo> getInfo() {
+            return mInfos;
+        }
+    }
+
+    public RawMediaFileStreamer (@NonNull FileInputStream file,
+            int memoryMax, int chunkSize, int maxChunks, long chunkTime) {
+        mFile = file;
+        mChannel = mFile.getChannel();
+        if (chunkSize <= 0 || memoryMax <= 0 || maxChunks <= 0) {
+            Log.e(TAG, "Cannot feed as memory is "
+                    + chunkSize + "/" + memoryMax + " with max chunks " + maxChunks);
+            return;
+        }
+        mMaxMemory = Math.max(memoryMax, chunkSize  * maxChunks);
+        mMaxMemory = (mMaxMemory / chunkSize) * chunkSize;
+        mChunkSize = chunkSize;
+        mMaxChunks = maxChunks;
+        // 70% of max memory
+        mLowWater = (int)
+                ((MEMORY_USE_RATIO * ((mMaxMemory / (float)mChunkSize) + 0.5f)) * mChunkSize);
+        mChunkTime = chunkTime;
+        Log.d(TAG, "Max " + mMaxMemory + " LW " + mLowWater
+                + " CS " + mChunkSize + "MaxChunks " + mMaxChunks + " CT " + mChunkTime);
+    }
+
+    public void handleFuture(Future<?> future) {
+        synchronized(mFuturesLock) {
+            if (future != null) {
+                mSchedulerFutures.add(future);
+            }
+            while (mSchedulerFutures.isEmpty() == false
+                && mSchedulerFutures.peekFirst().isDone() == true) {
+                Future<?> task = mSchedulerFutures.pollFirst();
+                try {
+                    task.get();
+                } catch(Exception e) {
+                    Log.d (TAG, "Scheduler encountered an exception " + e.toString());
+                }
+            }
+        }
+    }
+
+    private boolean schedule(ArrayDeque<IBufferXfer.IProducerData> buffers) {
+        if (mScheduler == null || mScheduler.isShutdown()) {
+            Log.e(TAG, "Scheduler is shutdown, cannot schedule");
+            return false;
+        }
+        if (!buffers.isEmpty()) {
+            Future<?> future = mScheduler.submit(() -> { mConsumer.consume(buffers); });
+            handleFuture(future);
+        }
+        return true;
+    }
+
+    private boolean streamFile(
+        @NonNull ArrayDeque<IBufferXfer.IProducerData> datas, boolean preroll) {
+        if (mChunkSize == 0) {
+            Log.d(TAG, "Nothing to send ChunkSize == 0");
+            return false;
+        }
+        int bytesToBeConsumed = 0, addedData = 0;
+        boolean eofReached = false;
+        synchronized (mObject) {
+            bytesToBeConsumed = mBytesTobeConsumed;
+            eofReached = mEOFReached;
+        }
+        ArrayDeque<IBufferXfer.IProducerData> buffersToSend = new ArrayDeque<>();
+        ArrayDeque<IBufferXfer.IProducerData> activeDeque =
+                (preroll == true) ? mPreRoll : buffersToSend;
+        if (datas != null && datas.isEmpty() == false) {
+            for ( IBufferXfer.IProducerData buffer : datas) {
+                mBufferInfoCache.addAll(buffer.getInfo());
+                buffer.getInfo().clear();
+            }
+            mFileDataCache.addAll(datas);
+        }
+        if (preroll == false && !mPreRoll.isEmpty()) {
+            if (DEBUG) {
+                Log.d(TAG, "Sending preroll buffers");
+            }
+            ArrayDeque<IBufferXfer.IProducerData> prerollBuffers = mPreRoll.clone();
+            mPreRoll.clear();
+            schedule(prerollBuffers);
+        }
+        FileData currentData = null;
+        Iterator<IBufferXfer.IProducerData> dataCacheIter = mFileDataCache.iterator();
+        ByteBuffer currentBuffer = null;
+        Iterator<MediaCodec.BufferInfo> infoCacheIter = mBufferInfoCache.iterator();
+        MediaCodec.BufferInfo currentInfo = null;
+        int offset = 0;
+        while (((bytesToBeConsumed + addedData) < mLowWater) && (eofReached == false)) {
+            if ((mMaxMemory - (bytesToBeConsumed + addedData)) < mChunkSize) {
+                Log.d(TAG, "Enough memory already for consumption");
+                break;
+            }
+            if (currentData == null) {
+                if (dataCacheIter.hasNext() == true) {
+                    currentData = (FileData)(dataCacheIter.next());
+                    dataCacheIter.remove();
+                } else {
+                    currentData = new FileData();
+                }
+                currentData.getInfo().clear();
+                currentBuffer = currentData.getBuffer();
+                if(currentBuffer == null) {
+                    currentBuffer = ByteBuffer.allocate(mChunkSize * mMaxChunks);
+                    currentData.mBuffer = currentBuffer;
+                }
+                offset = 0;
+                currentBuffer.clear();
+            }
+            if (currentInfo == null) {
+                if (infoCacheIter.hasNext() == true) {
+                    currentInfo = infoCacheIter.next();
+                    infoCacheIter.remove();
+                } else {
+                    currentInfo = new MediaCodec.BufferInfo();
+                }
+            }
+            try {
+                long available = (mChannel.size() - mChannel.position());
+                int availableChunks = (int)(available / mChunkSize);
+                int readChunks = availableChunks >= mMaxChunks ? mMaxChunks  : availableChunks;
+                if (readChunks == 0) {
+                    eofReached = true;
+                    currentInfo.set(
+                            offset,
+                            0,
+                            mChunkTime * mChunkCounter,
+                            MediaCodec.BUFFER_FLAG_END_OF_STREAM);
+                    currentData.mInfos.add(currentInfo);
+                    currentBuffer.position(0);
+                    currentData.mBuffer = currentBuffer;
+                    activeDeque.add(currentData);
+                    if (DEBUG) {
+                        Log.d(TAG, "Signaling EOF -> file ending");
+                        Log.d(TAG, "readBytes " + 0
+                                + " readChunks " + readChunks
+                                + " ts " + currentInfo.presentationTimeUs
+                                + " flags " + currentInfo.flags);
+
+                    }
+                    offset = 0;
+                    currentData = null; currentBuffer = null; currentInfo = null;
+                } else {
+                    // try to read from the file and update the actual read.
+                    // if the file reaches EOF, then signal that in the flag.
+                    if (currentBuffer.remaining() < (readChunks * mChunkSize)) {
+                        if (currentBuffer.position() == 0) {
+                            Log.d(TAG, "Producer buffer seems to be small to read chunks");
+                        }
+                        offset = 0;
+                        currentBuffer.position(0);
+                        currentData.mBuffer = currentBuffer;
+                        activeDeque.add(currentData);
+                        currentData = null; currentBuffer = null;
+                    } else {
+                        if (DEBUG) {
+                            Log.d(TAG, "Reading: offset " + offset + "readChunks " + readChunks
+                                    + " length " + readChunks * mChunkSize);
+                        }
+                        int readBytes = mFile.read(
+                            currentBuffer.array(), offset , (int)(readChunks * mChunkSize));
+                        if (readBytes == -1) {
+                            eofReached = true;
+                            currentInfo.set(
+                                    offset,
+                                    0,
+                                    mChunkTime * mChunkCounter,
+                                    MediaCodec.BUFFER_FLAG_END_OF_STREAM);
+                            currentData.mInfos.add(currentInfo);
+                            currentBuffer.position(0);
+                            currentData.mBuffer = currentBuffer;
+                            activeDeque.add(currentData);
+                            currentData = null; currentBuffer = null;
+                            if (DEBUG) {
+                                Log.d(TAG, "EOF reached");
+                                Log.d(TAG, "readBytes " + readBytes
+                                        + " readChunks " + readChunks
+                                        + " ts " + currentInfo.presentationTimeUs
+                                        + " flags " + currentInfo.flags);
+
+                            }
+                        } else {
+                            // set as many info as it relates to one chunk size.
+                            int nInfos = readBytes / mChunkSize;
+                            for (int i = 0; i < nInfos; i++) {
+                                if (currentInfo == null) {
+                                    if (infoCacheIter.hasNext() == true) {
+                                        currentInfo = infoCacheIter.next();
+                                        infoCacheIter.remove();
+                                    } else {
+                                        currentInfo = new MediaCodec.BufferInfo();
+                                    }
+                                }
+                                currentInfo.set(
+                                        offset + (i * mChunkSize),
+                                        mChunkSize,
+                                        mChunkTime * mChunkCounter,
+                                        0);
+                                currentData.mInfos.add(currentInfo);
+                                mChunkCounter++;
+                                currentInfo = null;
+                            }
+                            currentBuffer.position(readBytes);
+                            addedData += readBytes;
+                            offset += readBytes;
+                            if (DEBUG) {
+                                Log.d(TAG, "readBytes " + readBytes
+                                        + " readChunks " + readChunks);
+                            }
+                        }
+                        currentInfo = null;
+                    }
+                }
+            } catch (NullPointerException e) {
+                Log.e(TAG, "Buffer array return null");
+                e.printStackTrace();
+                return false;
+            } catch (IndexOutOfBoundsException | IOException e) {
+                Log.e(TAG, "Error with len " + mChunkSize + " msg: " + e.getMessage());
+                e.printStackTrace();
+                return false;
+            }
+        }
+        if (currentData != null) {
+            if (currentBuffer == null) {
+                Log.d(TAG, "Error with data, buffers not present");
+            } else {
+                currentBuffer.position(0);
+            }
+            currentData.mBuffer = currentBuffer;
+            activeDeque.add(currentData);
+            currentData = null; currentBuffer = null; currentInfo = null;
+        }
+        if (DEBUG) {
+            Log.d(TAG, "(Preroll " + preroll + ")Memory for consumption "
+                + bytesToBeConsumed + "/" + mMaxMemory
+                + "(" + bytesToBeConsumed/(float)mMaxMemory * 100.0f + "%)");
+        }
+        synchronized(mObject) {
+            mBytesTobeConsumed += addedData;
+            mEOFReached = eofReached;
+        }
+        schedule(buffersToSend);
+        return true;
+    }
+
+    @Override
+    public boolean returnBuffers(ArrayDeque<IBufferXfer.IProducerData> datas) {
+        int usedSize = 0, numBuffers = 0;
+        boolean shouldSchedule = false;
+        ArrayDeque<IBufferXfer.IProducerData> deque = null;
+        if (datas != null) {
+            deque = datas.clone();
+            for (IBufferXfer.IProducerData data : datas) {
+                ArrayDeque<MediaCodec.BufferInfo> infos = data.getInfo();
+                for (MediaCodec.BufferInfo info : infos) {
+                    usedSize += info.size;
+                    numBuffers++;
+                }
+            }
+            if (DEBUG) {
+                Log.d(TAG, "Memory for consumption inf-all-used " + usedSize
+                        + " #buf " + numBuffers);
+            }
+        }
+        int bytesConsumed = 0;
+        synchronized (mObject) {
+            mBytesTobeConsumed -= usedSize;
+            bytesConsumed = mBytesTobeConsumed;
+            if (mEOFReached == false) {
+                shouldSchedule = true;
+            }
+        }
+        Future<?> future = null;
+        if (shouldSchedule == true) {
+            final ArrayDeque<IBufferXfer.IProducerData> cloned = deque;
+            future = mScheduler.submit(() -> { streamFile(cloned, false); });
+        }
+        handleFuture(future);
+        if (DEBUG) {
+            Log.d(TAG, "Memory for consumption "
+                + bytesConsumed + "/" + mMaxMemory
+                + "(" + bytesConsumed/(float)mMaxMemory * 100.0f + "%)");
+        }
+        return true;
+    }
+
+    @Override
+    public boolean setConsumer (@NonNull IBufferXfer.IConsumer consumer) {
+        mConsumer = consumer;
+        Future<?> future = mScheduler.submit(() -> {streamFile(null, false);});
+        handleFuture(future);
+        return true;
+    }
+
+    public boolean preroll() {
+        return streamFile(null, true);
+    }
+
+    public void stop() {
+        while (mSchedulerFutures.isEmpty() == false) {
+            Future<?> future = mSchedulerFutures.pollFirst();
+            try {
+                future.get(TIMEOUT_IN_SEC_FOR_TASK, TimeUnit.SECONDS);;
+            } catch(Exception e) {
+                Log.d (TAG, "Scheduler encountered an exception " + e.toString());
+            }
+        }
+        mScheduler.shutdown();
+    }
+}
\ No newline at end of file
diff --git a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Stats.java b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Stats.java
index 17de1e773e..634d4d8579 100644
--- a/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Stats.java
+++ b/media/tests/benchmark/MediaBenchmarkTest/src/main/java/com/android/media/benchmark/library/Stats.java
@@ -33,6 +33,7 @@ public class Stats {
     private long mInitTimeNs;
     private long mDeInitTimeNs;
     private long mStartTimeNs;
+    private double mNumFrames;
     private ArrayList<Integer> mFrameSizes;
     /*
      * Array for holding the wallclock time
@@ -53,6 +54,8 @@ public class Stats {
         mOutputTimer = new ArrayList<>();
         mInitTimeNs = 0;
         mDeInitTimeNs = 0;
+        mStartTimeNs = 0;
+        mNumFrames = 0;
     }
 
     public long getCurTime() { return System.nanoTime(); }
@@ -67,7 +70,14 @@ public class Stats {
 
     public void addInputTime() { mInputTimer.add(System.nanoTime()); }
 
-    public void addOutputTime() { mOutputTimer.add(System.nanoTime()); }
+    public void addOutputTime(double nFrames) {
+        mOutputTimer.add(System.nanoTime());
+        mNumFrames += nFrames;
+    }
+    public void addOutputTime() {
+        mOutputTimer.add(System.nanoTime());
+        mNumFrames++;
+    }
 
     public void reset() {
         if (mFrameSizes.size() != 0) {
@@ -91,6 +101,10 @@ public class Stats {
 
     public List<Long> getOutputTimers() { return mOutputTimer; }
 
+    public long getNumFrames() {
+        return (long)(mNumFrames + 0.5f);
+    }
+
     public List<Long> getInputTimers() { return mInputTimer; }
 
     public long getTimeDiff(long sTime, long eTime) { return (eTime - sTime); }
diff --git a/media/utils/include/mediautils/ServiceSingleton.h b/media/utils/include/mediautils/ServiceSingleton.h
index bbd44d3502..6996a030bf 100644
--- a/media/utils/include/mediautils/ServiceSingleton.h
+++ b/media/utils/include/mediautils/ServiceSingleton.h
@@ -25,6 +25,11 @@
 #include <mutex>
 #include <utils/Log.h>
 #include <utils/Timers.h>
+#include <variant>
+
+#pragma push_macro("LOG_TAG")
+#undef LOG_TAG
+#define LOG_TAG "ServiceSingleton"
 
 /**
  * ServiceSingleton provides a non-blocking NDK/CPP compatible service cache.
@@ -115,6 +120,14 @@ namespace details {
 
 class ServiceHandler
 {
+    // State of the service interface (mService), determines when to expose service to client.
+    enum class State {
+        kInvalid,  // service invalid.
+        kValid,    // service valid but notification callback not sent,
+                   // at least one client waiting for callback.
+        kNotified, // service valid and notification callback completed (okay to expose).
+    };
+
 public:
     /**
      * Returns a ServiceHandler, templated type T is String16 for the native type
@@ -163,7 +176,9 @@ public:
         auto& service = std::get<BaseInterfaceType<Service>>(mService);
 
         // early check.
-        if (mSkipMode == SkipMode::kImmediate || (service && mValid)) return service;
+        if (mSkipMode == SkipMode::kImmediate || (service && mState == State::kNotified)) {
+            return service;
+        }
 
         // clamp to avoid numeric overflow.  INT64_MAX / 2 is effectively forever for a device.
         std::chrono::nanoseconds kWaitLimitNs(
@@ -171,20 +186,22 @@ public:
         waitNs = std::clamp(waitNs, decltype(waitNs)(0), kWaitLimitNs);
         const auto end = std::chrono::steady_clock::now() + waitNs;
 
-        for (bool first = true; true; first = false) {
+        while (true) {
             // we may have released mMutex, so see if service has been obtained.
-            if (mSkipMode == SkipMode::kImmediate || (service && mValid))  return service;
+            if (mSkipMode == SkipMode::kImmediate || (service && mState == State::kNotified)) {
+                return service;
+            }
 
             int options = 0;
-            if (mSkipMode == SkipMode::kNone) {
+            if (mSkipMode == SkipMode::kNone && mState == State::kInvalid) {
                 const auto traits = getTraits_l<Service>();
 
-                // first time or not using callback, check the service.
-                if (first || !useCallback) {
+                // no service callback handle, check the service.
+                if (!mServiceNotificationHandle) {
                     auto service_new = checkServicePassThrough<Service>(
                             traits->getServiceName());
                     if (service_new) {
-                        mValid = true;
+                        mState = State::kValid;
                         service = std::move(service_new);
                         // service is a reference, so we copy to service_fixed as
                         // we're releasing the mutex.
@@ -192,13 +209,20 @@ public:
                         ul.unlock();
                         traits->onNewService(interfaceFromBase<Service>(service_fixed));
                         ul.lock();
+                        if (mState == State::kValid) {
+                            mState = State::kNotified;  // ok to expose.
+                        } else {
+                            ALOGW("%s: state expected to be State::kValid but was %s",
+                                    __func__, stateToString(mState));
+                        }
                         setDeathNotifier_l<Service>(service_fixed);
                         ul.unlock();
                         mCv.notify_all();
                         return service_fixed;
                     }
                 }
-                // install service callback if needed.
+                // install service callback only if flag set and we need it.
+                // once set, we don't remove it.
                 if (useCallback && !mServiceNotificationHandle) {
                     setServiceNotifier_l<Service>();
                 }
@@ -243,9 +267,22 @@ public:
             traits->onServiceDied(interfaceFromBase<Service>(orig_service));
         }
         service = service_new;
+        if (!service_new) {
+             ALOGW("%s: setting null service override, should use non-null service", __func__);
+             return;  // invalid state already set.
+        }
+        mState = State::kValid;
         ul.unlock();
         // should we set the death notifier?  It could be a local service.
         if (service_new) traits->onNewService(service_new);
+        ul.lock();
+        if (mState != State::kValid) {
+            ALOGW("%s: state expected to be State::kValid but was %s",
+                    __func__, stateToString(mState));
+            return;
+        }
+        mState = State::kNotified;
+        ul.unlock();
         mCv.notify_all();
     }
 
@@ -292,7 +329,7 @@ private:
     void invalidateService_l() REQUIRES(mMutex) {
         mDeathNotificationHandle.reset();
         const auto traits = getTraits_l<Service>();
-        mValid = false;
+        mState = State::kInvalid;
         if (!(static_cast<int>(traits->options()) & static_cast<int>(ServiceOptions::kNonNull))
                 || mSkipMode != SkipMode::kNone) {
             auto &service = std::get<BaseInterfaceType<Service>>(mService);
@@ -325,14 +362,23 @@ private:
                             invalidateService_l<Service>();
                         }
                         mService = service;
-                        mValid = true;
+                        ALOGD_IF(mState != State::kInvalid,
+                                "%s: state expected to be State::kInvalid but was %s",
+                                __func__, stateToString(mState));
+                        mState = State::kValid;
                         ul.unlock();
                         if (originalService != nullptr) {
                             traits->onServiceDied(interfaceFromBase<Service>(originalService));
                         }
                         traits->onNewService(service);
                         ul.lock();
+                        if (mState != State::kValid) {
+                            ALOGW("%s: state expected to be State::kValid but was %s",
+                                    __func__, stateToString(mState));
+                            return;
+                        }
                         setDeathNotifier_l<Service>(service);
+                        mState = State::kNotified;  // ok for other clients to use.
                     } else {
                         ALOGW("%s: ignoring duplicated service: %p",
                                 __func__, originalService.get());
@@ -397,6 +443,15 @@ private:
         mService = sp<::android::IInterface>{};
     }
 
+    static const char *stateToString(State state) {
+        switch (state) {
+            case State::kInvalid: return "kInvalid";
+            case State::kValid: return "kValid";
+            case State::kNotified: return "kNotified";
+            default: return "Unknown";
+        }
+    }
+
     static std::string toString(const std::string& s) { return s; }
     static std::string toString(const String16& s) { return String8(s).c_str(); }
 
@@ -412,8 +467,8 @@ private:
     std::shared_ptr<void> mServiceNotificationHandle GUARDED_BY(mMutex);
     std::shared_ptr<void> mTraits GUARDED_BY(mMutex);
 
-    // mValid is true iff the service is non-null and alive.
-    bool mValid GUARDED_BY(mMutex) = false;
+    // State of the service (mService).
+    State mState GUARDED_BY(mMutex) = State::kInvalid;
 
     // mSkipMode indicates the service cache state:
     //
@@ -517,3 +572,5 @@ void skipService(SkipMode skipMode = SkipMode::kImmediate) {
 }
 
 } // namespace android::mediautils
+
+#pragma pop_macro("LOG_TAG")
diff --git a/media/utils/tests/service_singleton_tests.cpp b/media/utils/tests/service_singleton_tests.cpp
index 78a2173a08..3c873873d2 100644
--- a/media/utils/tests/service_singleton_tests.cpp
+++ b/media/utils/tests/service_singleton_tests.cpp
@@ -26,6 +26,9 @@
 #include <gtest/gtest.h>
 #include <utils/Log.h>
 
+#include <thread>
+#include <vector>
+
 using namespace android;
 
 /**
@@ -65,6 +68,37 @@ struct TestServiceTraits : public mediautils::DefaultServiceTraits<Service> {
     }
 };
 
+// SetServiceTraits just increments a counter for each onNewService called.
+// This is used to check calling set on the service.
+template <typename Service>
+struct SetServiceTraits : public mediautils::DefaultServiceTraits<Service> {
+    static constexpr const char* getServiceName() { return ""; }
+    static constexpr void onNewService(const mediautils::InterfaceType<Service>&) {
+        ++newCounter;
+    }
+    static constexpr void onServiceDied(const mediautils::InterfaceType<Service>&) {
+        ++diedCounter;
+    }
+    static inline std::atomic_int32_t newCounter = 0;
+    static inline std::atomic_int32_t diedCounter = 0;
+};
+
+// ConcurrentServiceTraits checks that concurrent requests to get the service
+// return only after the onNewService callback has completed.
+template <typename Service>
+struct ConcurrentServiceTraits : public mediautils::DefaultServiceTraits<Service> {
+    static constexpr const char* getServiceName() { return ""; }
+    static constexpr void onNewService(const mediautils::InterfaceType<Service>&) {
+        sleep(1); // delay - this ensures that a concurrent request that doesn't block sees 0.
+        ++newCounter;
+    }
+    static constexpr void onServiceDied(const mediautils::InterfaceType<Service>&) {
+        ++diedCounter;
+    }
+    static inline std::atomic_int32_t newCounter = 0;
+    static inline std::atomic_int32_t diedCounter = 0;
+};
+
 // Here we have an alternative set of service traits,
 // used to validate that we can switch traits for the service singleton.
 static std::atomic_int32_t sNewService2 = 0;
@@ -87,11 +121,11 @@ struct TestServiceTraits2 : public mediautils::DefaultServiceTraits<Service> {
  * The WorkerThread is used to launch and kill the ServiceThread in a remote process.
  */
 static void ServiceThread(audio_utils::RunRemote& runRemote) {
-    int c = runRemote.getc();  // requires any character to launch
+    int c = runRemote.getChar();  // requires any character to launch
     auto service = sp<IServiceSingletonTest>::cast(sp<ServiceSingletonTestCpp>::make());
     mediautils::addService(service);
     ProcessState::self()->startThreadPool();
-    runRemote.putc(c);  // echo character.
+    runRemote.putChar(c);  // echo character.
     IPCThreadState::self()->joinThreadPool();
 }
 
@@ -102,30 +136,52 @@ static void ServiceThread(audio_utils::RunRemote& runRemote) {
 static void WorkerThread(audio_utils::RunRemote& runRemote) {
     std::shared_ptr<audio_utils::RunRemote> remoteService;
     while (true) {
-        const int c = runRemote.getc();
+        const int c = runRemote.getChar();
         switch (c) {
             case 'a':  // launch a new service.
                 // if the old service isn't destroyed, it will be destroyed here
                 // when the RunRemote is replaced.
                 remoteService = std::make_shared<audio_utils::RunRemote>(ServiceThread);
                 remoteService->run();
-                remoteService->putc('a');  // create service.
-                (void)remoteService->getc(); // ensure it is created.
-                runRemote.putc(c);  // echo
+                remoteService->putChar('a');  // create service.
+                (void)remoteService->getChar(); // ensure it is created.
+                runRemote.putChar(c);  // echo
                 break;
             case 'b':  // destroys the old service.
                 remoteService.reset();  // this kills the service.
-                runRemote.putc(c);  // echo
+                runRemote.putChar(c);  // echo
                 break;
             default:  // respond that we don't know what happened!
-                runRemote.putc('?');
+                runRemote.putChar('?');
                 break;
         }
     }
 }
 
+class ServiceSingletonTests : public ::testing::Test {
+protected:
+    std::shared_ptr<audio_utils::RunRemote> mRemoteWorker = getRemoteWorker();
+
+    // Use a worker singleton because once we set up binder,
+    // we can't spawn the remote worker again.
+    static std::shared_ptr<audio_utils::RunRemote> getRemoteWorker() {
+        [[clang::no_destroy]]
+        static std::shared_ptr<audio_utils::RunRemote> remoteWorker = []() {
+            // create worker that spawns service in a different process.
+            const auto worker = std::make_shared<audio_utils::RunRemote>(WorkerThread);
+            worker->run();
+
+            // now we are ready for binder.
+            ProcessState::self()->startThreadPool();
+
+            return worker;
+        }();
+        return remoteWorker;
+    }
+};
+
 // This is a monolithic test.
-TEST(service_singleton_tests, one_and_only) {
+TEST_F(ServiceSingletonTests, Basic) {
     std::atomic_int32_t listenerServiceCreated = 0;
     std::atomic_int32_t listenerServiceDied = 0;
 
@@ -135,13 +191,6 @@ TEST(service_singleton_tests, one_and_only) {
     mediautils::initService<
         aidl::IServiceSingletonTest, TestServiceTraits<aidl::IServiceSingletonTest>>({});
 
-    // start the worker thread that spawns the services.
-    auto remoteWorker = std::make_shared<audio_utils::RunRemote>(WorkerThread);
-    remoteWorker->run();
-
-    // now we are ready for binder.
-    ProcessState::self()->startThreadPool();
-
     // check that our service isn't preexisting.
     {
         auto service = mediautils::checkServicePassThrough<IServiceSingletonTest>();
@@ -176,8 +225,8 @@ TEST(service_singleton_tests, one_and_only) {
     EXPECT_EQ(0, sServiceDied);
 
     // now spawn the service.
-    remoteWorker->putc('a');
-    EXPECT_EQ('a', remoteWorker->getc());
+    mRemoteWorker->putChar('a');
+    EXPECT_EQ('a', mRemoteWorker->getChar());
 
     sleep(1);  // In the background, 2 services were fetched.
 
@@ -216,8 +265,8 @@ TEST(service_singleton_tests, one_and_only) {
     EXPECT_EQ(0, sServiceDied);
 
     // destroy the service.
-    remoteWorker->putc('b');
-    EXPECT_EQ('b', remoteWorker->getc());
+    mRemoteWorker->putChar('b');
+    EXPECT_EQ('b', mRemoteWorker->getChar());
 
     sleep(1);
 
@@ -235,8 +284,8 @@ TEST(service_singleton_tests, one_and_only) {
                 ++listenerServiceCreated; });
 
     // Spawn the service again.
-    remoteWorker->putc('a');
-    EXPECT_EQ('a', remoteWorker->getc());
+    mRemoteWorker->putChar('a');
+    EXPECT_EQ('a', mRemoteWorker->getChar());
 
     sleep(1);  // In the background, 2 services were fetched.
 
@@ -294,8 +343,8 @@ TEST(service_singleton_tests, one_and_only) {
 
     // destroy the service.
 
-    remoteWorker->putc('b');
-    EXPECT_EQ('b', remoteWorker->getc());
+    mRemoteWorker->putChar('b');
+    EXPECT_EQ('b', mRemoteWorker->getChar());
 
     sleep(1);
 
@@ -315,8 +364,8 @@ TEST(service_singleton_tests, one_and_only) {
     mediautils::skipService<aidl::IServiceSingletonTest>();
 
     // Spawn the service again.
-    remoteWorker->putc('a');
-    EXPECT_EQ('a', remoteWorker->getc());
+    mRemoteWorker->putChar('a');
+    EXPECT_EQ('a', mRemoteWorker->getChar());
 
     sleep(1);
 
@@ -362,8 +411,8 @@ TEST(service_singleton_tests, one_and_only) {
     }
 
     // remove service
-    remoteWorker->putc('b');
-    EXPECT_EQ('b', remoteWorker->getc());
+    mRemoteWorker->putChar('b');
+    EXPECT_EQ('b', mRemoteWorker->getChar());
 
     sleep(1);
 
@@ -404,8 +453,8 @@ TEST(service_singleton_tests, one_and_only) {
     EXPECT_EQ(0, sServiceDied2);
 
     // Spawn the service again.
-    remoteWorker->putc('a');
-    EXPECT_EQ('a', remoteWorker->getc());
+    mRemoteWorker->putChar('a');
+    EXPECT_EQ('a', mRemoteWorker->getChar());
 
     sleep(1);
 
@@ -424,8 +473,8 @@ TEST(service_singleton_tests, one_and_only) {
     EXPECT_TRUE(stale_service2);  // not stale yet.
 
     // Release the service.
-    remoteWorker->putc('b');
-    EXPECT_EQ('b', remoteWorker->getc());
+    mRemoteWorker->putChar('b');
+    EXPECT_EQ('b', mRemoteWorker->getChar());
 
     sleep(1);
 
@@ -444,4 +493,149 @@ TEST(service_singleton_tests, one_and_only) {
         EXPECT_FALSE(handle2);
         EXPECT_EQ(0, postDied);  // no callbacks issued.
     }
+
+    // Cancel the singleton cache.
+    mediautils::skipService<IServiceSingletonTest>();
+    mediautils::skipService<aidl::IServiceSingletonTest>();
+}
+
+TEST_F(ServiceSingletonTests, Set) {
+    // Initialize the service cache with a custom handler for set service request
+
+    mediautils::initService<
+            IServiceSingletonTest,
+            SetServiceTraits<IServiceSingletonTest>>({});
+    mediautils::initService<
+            aidl::IServiceSingletonTest,
+            SetServiceTraits<aidl::IServiceSingletonTest>>({});
+
+    constexpr int32_t kThreads = 4;
+    std::vector<std::shared_ptr<std::thread>> threads;
+    std::atomic_int32_t services = 0;
+
+    auto test1 = [&]() {
+        auto service = mediautils::getService<IServiceSingletonTest>(std::chrono::seconds(2000));
+        EXPECT_TRUE(service);
+        EXPECT_EQ(1, SetServiceTraits<IServiceSingletonTest>::newCounter);
+        ++services;
+    };
+
+    for (int32_t i = 0; i < kThreads; ++i) {
+        threads.push_back(std::make_shared<std::thread>(test1));
+    }
+    EXPECT_EQ(0, services);
+    EXPECT_EQ(0, SetServiceTraits<IServiceSingletonTest>::newCounter);
+    EXPECT_EQ(0, SetServiceTraits<IServiceSingletonTest>::diedCounter);
+
+    // The threads are blocked since there is no registered service.
+    // Once we set the service, then we are able to join.
+    sp<IServiceSingletonTest> testLocalService = sp<ServiceSingletonTestCpp>::make();
+    mediautils::setService<IServiceSingletonTest>(testLocalService);
+
+    for (auto& thread : threads) {
+        thread->join();
+    }
+    threads.clear();
+    EXPECT_EQ(kThreads, services);
+    EXPECT_EQ(0, SetServiceTraits<IServiceSingletonTest>::diedCounter);
+
+    // Test concurrent getService (AIDL).
+    // A slightly different test, we check if we can cancel the service.
+
+    std::atomic_int32_t services2 = 0;
+    auto test2 = [&]() {
+        auto service = mediautils::getService<aidl::IServiceSingletonTest>(
+                std::chrono::seconds(2000));
+        // we expect to cancel the request, so no service is obtained.
+        EXPECT_FALSE(service);
+        EXPECT_EQ(0, SetServiceTraits<aidl::IServiceSingletonTest>::newCounter);
+        ++services2;
+    };
+    for (size_t i = 0; i < kThreads; ++i) {
+        threads.push_back(std::make_shared<std::thread>(test2));
+    }
+
+    EXPECT_EQ(0, services2);
+    EXPECT_EQ(0, SetServiceTraits<aidl::IServiceSingletonTest>::newCounter);
+
+    // The threads are blocked since there is no registered service.
+    // Once we cancel the service, then we are able to join.
+
+    // Cancel the singleton cache.
+    mediautils::skipService<IServiceSingletonTest>();
+    mediautils::skipService<aidl::IServiceSingletonTest>();
+
+    for (auto& thread : threads) {
+        thread->join();
+    }
+    threads.clear();
+
+    EXPECT_EQ(4, services2);
+    EXPECT_EQ(0, SetServiceTraits<aidl::IServiceSingletonTest>::newCounter);
+    EXPECT_EQ(0, SetServiceTraits<aidl::IServiceSingletonTest>::diedCounter);
+}
+
+TEST_F(ServiceSingletonTests, ConcurrentWait) {
+    // Initialize the service cache with a custom handler for concurrent service request
+    // testing.  ConcurrentServiceTraits has a very slow onNewService(),
+    // and all concurrent service requests must wait for the onNewService to complete.
+
+    mediautils::initService<
+            IServiceSingletonTest,
+            ConcurrentServiceTraits<IServiceSingletonTest>>({});
+    mediautils::initService<
+            aidl::IServiceSingletonTest,
+            ConcurrentServiceTraits<aidl::IServiceSingletonTest>>({});
+
+    // Spawn the service again.
+    mRemoteWorker->putChar('a');
+    EXPECT_EQ('a', mRemoteWorker->getChar());
+
+    constexpr size_t kThreads = 4;
+    std::vector<std::shared_ptr<std::thread>> threads;
+
+    // Test concurrent getService.
+    auto test1 = []() {
+        auto service = mediautils::getService<IServiceSingletonTest>(std::chrono::seconds(2));
+        EXPECT_TRUE(service);
+        EXPECT_EQ(1, ConcurrentServiceTraits<IServiceSingletonTest>::newCounter);
+    };
+    for (size_t i = 0; i < kThreads; ++i) {
+        threads.push_back(std::make_shared<std::thread>(test1));
+    }
+    for (auto& thread : threads) {
+        thread->join();
+    }
+    threads.clear();
+
+    // Test concurrent getService (AIDL).
+    auto test2 = []() {
+        auto service = mediautils::getService<aidl::IServiceSingletonTest>(
+                std::chrono::seconds(2));
+        EXPECT_TRUE(service);
+        EXPECT_EQ(1, ConcurrentServiceTraits<aidl::IServiceSingletonTest>::newCounter);
+    };
+    for (size_t i = 0; i < kThreads; ++i) {
+        threads.push_back(std::make_shared<std::thread>(test2));
+    }
+    for (auto& thread : threads) {
+        thread->join();
+    }
+    threads.clear();
+
+    EXPECT_EQ(0, ConcurrentServiceTraits<IServiceSingletonTest>::diedCounter);
+    EXPECT_EQ(0, ConcurrentServiceTraits<aidl::IServiceSingletonTest>::diedCounter);
+
+    // Release the service.
+    mRemoteWorker->putChar('b');
+    EXPECT_EQ('b', mRemoteWorker->getChar());
+
+    sleep(1);
+
+    EXPECT_EQ(1, ConcurrentServiceTraits<IServiceSingletonTest>::diedCounter);
+    EXPECT_EQ(1, ConcurrentServiceTraits<aidl::IServiceSingletonTest>::diedCounter);
+
+    // Cancel the singleton cache.
+    mediautils::skipService<IServiceSingletonTest>();
+    mediautils::skipService<aidl::IServiceSingletonTest>();
 }
diff --git a/services/audioflinger/AudioFlinger.cpp b/services/audioflinger/AudioFlinger.cpp
index a4b06ee141..695af41c07 100644
--- a/services/audioflinger/AudioFlinger.cpp
+++ b/services/audioflinger/AudioFlinger.cpp
@@ -63,6 +63,7 @@
 #include <utils/Log.h>
 
 // not needed with the includes above, added to prevent transitive include dependency.
+#include <atomic>
 #include <chrono>
 #include <thread>
 #include <string_view>
@@ -371,13 +372,13 @@ status_t AudioFlinger::updateSecondaryOutputs(
     audio_utils::lock_guard _l(mutex());
     for (const auto& [trackId, secondaryOutputs] : trackSecondaryOutputs) {
         size_t i = 0;
-        for (; i < mPlaybackThreads.size(); ++i) {
-            IAfPlaybackThread* thread = mPlaybackThreads.valueAt(i).get();
+        for (const auto& [_, thread] : mPlaybackThreads) {
             audio_utils::lock_guard _tl(thread->mutex());
-            sp<IAfTrack> track = thread->getTrackById_l(trackId);
+            sp<IAfTrackBase> track = thread->getTrackById_l(trackId);
             if (track != nullptr) {
                 ALOGD("%s trackId: %u", __func__, trackId);
-                updateSecondaryOutputsForTrack_l(track.get(), thread, secondaryOutputs);
+                updateSecondaryOutputsForTrack_l(
+                        track->asIAfTrack(), thread.get(), secondaryOutputs);
                 break;
             }
         }
@@ -427,23 +428,22 @@ int32_t AudioFlinger::getAAudioHardwareBurstMinUsec() const {
 
 status_t AudioFlinger::setDeviceConnectedState(const struct audio_port_v7 *port,
                                                media::DeviceConnectedState state) {
-    status_t final_result = NO_INIT;
+    status_t result = NO_INIT;
     audio_utils::lock_guard _l(mutex());
     audio_utils::lock_guard lock(hardwareMutex());
-    mHardwareStatus = AUDIO_HW_SET_CONNECTED_STATE;
-    for (size_t i = 0; i < mAudioHwDevs.size(); i++) {
-        sp<DeviceHalInterface> dev = mAudioHwDevs.valueAt(i)->hwDevice();
-        status_t result = state == media::DeviceConnectedState::PREPARE_TO_DISCONNECT
+    AudioHwDevice *audioHwDevice = mAudioHwDevs.valueFor(port->ext.device.hw_module);
+    if (audioHwDevice != nullptr) {
+        mHardwareStatus = AUDIO_HW_SET_CONNECTED_STATE;
+        sp<DeviceHalInterface> dev = audioHwDevice->hwDevice();
+        result = state == media::DeviceConnectedState::PREPARE_TO_DISCONNECT
                 ? dev->prepareToDisconnectExternalDevice(port)
                 : dev->setConnectedState(port, state == media::DeviceConnectedState::CONNECTED);
-        // Same logic as with setParameter: it's a success if at least one
-        // HAL module accepts the update.
-        if (final_result != NO_ERROR) {
-            final_result = result;
-        }
+        mHardwareStatus = AUDIO_HW_IDLE;
+    } else {
+        ALOGE("%s could not find HAL module %d for device %#x",
+              __func__, port->ext.device.hw_module, port->ext.device.type);
     }
-    mHardwareStatus = AUDIO_HW_IDLE;
-    return final_result;
+    return result;
 }
 
 status_t AudioFlinger::setSimulateDeviceConnections(bool enabled) {
@@ -475,17 +475,17 @@ std::optional<media::AudioVibratorInfo> AudioFlinger::getDefaultVibratorInfo_l()
 
 AudioFlinger::~AudioFlinger()
 {
-    while (!mRecordThreads.isEmpty()) {
+    while (!mRecordThreads.empty()) {
         // closeInput_nonvirtual() will remove specified entry from mRecordThreads
-        closeInput_nonvirtual(mRecordThreads.keyAt(0));
+        closeInput_nonvirtual(mRecordThreads.begin()->first);
     }
-    while (!mPlaybackThreads.isEmpty()) {
+    while (!mPlaybackThreads.empty()) {
         // closeOutput_nonvirtual() will remove specified entry from mPlaybackThreads
-        closeOutput_nonvirtual(mPlaybackThreads.keyAt(0));
+        closeOutput_nonvirtual(mPlaybackThreads.begin()->first);
     }
-    while (!mMmapThreads.isEmpty()) {
-        const audio_io_handle_t io = mMmapThreads.keyAt(0);
-        if (mMmapThreads.valueAt(0)->isOutput()) {
+    while (!mMmapThreads.empty()) {
+        const audio_io_handle_t io = mMmapThreads.begin()->first;
+        if (mMmapThreads.begin()->second->isOutput()) {
             closeOutput_nonvirtual(io); // removes entry from mMmapThreads
         } else {
             closeInput_nonvirtual(io);  // removes entry from mMmapThreads
@@ -508,6 +508,7 @@ status_t MmapStreamInterface::openMmapStream(MmapStreamInterface::stream_directi
                                              DeviceIdVector *deviceIds,
                                              audio_session_t *sessionId,
                                              const sp<MmapStreamCallback>& callback,
+                                             const audio_offload_info_t* offloadInfo,
                                              sp<MmapStreamInterface>& interface,
                                              audio_port_handle_t *handle)
 {
@@ -518,7 +519,7 @@ status_t MmapStreamInterface::openMmapStream(MmapStreamInterface::stream_directi
     if (af != 0) {
         ret = af->openMmapStream(
                 direction, attr, config, client, deviceIds,
-                sessionId, callback, interface, handle);
+                sessionId, callback, offloadInfo, interface, handle);
     }
     return ret;
 }
@@ -530,6 +531,7 @@ status_t AudioFlinger::openMmapStream(MmapStreamInterface::stream_direction_t di
                                       DeviceIdVector *deviceIds,
                                       audio_session_t *sessionId,
                                       const sp<MmapStreamCallback>& callback,
+                                      const audio_offload_info_t* offloadInfo,
                                       sp<MmapStreamInterface>& interface,
                                       audio_port_handle_t *handle)
 {
@@ -592,19 +594,20 @@ status_t AudioFlinger::openMmapStream(MmapStreamInterface::stream_direction_t di
         std::vector<audio_io_handle_t> secondaryOutputs;
         bool isSpatialized;
         bool isBitPerfect;
-        float volume;
-        bool muted;
+        audio_output_flags_t flags = static_cast<audio_output_flags_t>(
+                AUDIO_OUTPUT_FLAG_MMAP_NOIRQ | AUDIO_OUTPUT_FLAG_DIRECT);
+        if (offloadInfo != nullptr) {
+            flags = static_cast<audio_output_flags_t>(flags | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD);
+            fullConfig.offload_info = *offloadInfo;
+        }
         ret = AudioSystem::getOutputForAttr(&localAttr, &io,
                                             actualSessionId,
                                             &streamType, adjAttributionSource,
                                             &fullConfig,
-                                            (audio_output_flags_t)(AUDIO_OUTPUT_FLAG_MMAP_NOIRQ |
-                                                    AUDIO_OUTPUT_FLAG_DIRECT),
+                                            flags,
                                             deviceIds, &portId, &secondaryOutputs,
                                             &isSpatialized,
-                                            &isBitPerfect,
-                                            &volume,
-                                            &muted);
+                                            &isBitPerfect);
         if (ret != NO_ERROR) {
             config->sample_rate = fullConfig.sample_rate;
             config->channel_mask = fullConfig.channel_mask;
@@ -642,10 +645,13 @@ status_t AudioFlinger::openMmapStream(MmapStreamInterface::stream_direction_t di
 
     // at this stage, a MmapThread was created when openOutput() or openInput() was called by
     // audio policy manager and we can retrieve it
-    const sp<IAfMmapThread> thread = mMmapThreads.valueFor(io);
-    if (thread != 0) {
+
+    if (const auto it = mMmapThreads.find(io);
+            it != mMmapThreads.end()) {
+        const sp<IAfMmapThread>& thread = it->second;
         interface = IAfMmapThread::createMmapStreamInterfaceAdapter(thread);
-        thread->configure(&localAttr, streamType, actualSessionId, callback, *deviceIds, portId);
+        thread->configure(&localAttr, streamType, actualSessionId, callback, *deviceIds, portId,
+                          offloadInfo);
         *handle = portId;
         *sessionId = actualSessionId;
         config->sample_rate = thread->sampleRate();
@@ -937,18 +943,18 @@ status_t AudioFlinger::dump(int fd, const Vector<String16>& args)
 
         dprintf(fd, "\n ## BEGIN thread dump \n");
         // dump playback threads
-        for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-            mPlaybackThreads.valueAt(i)->dump(fd, args);
+        for (const auto& [_, thread] : mPlaybackThreads) {
+            thread->dump(fd, args);
         }
 
         // dump record threads
-        for (size_t i = 0; i < mRecordThreads.size(); i++) {
-            mRecordThreads.valueAt(i)->dump(fd, args);
+        for (const auto& [_, thread] : mRecordThreads) {
+            thread->dump(fd, args);
         }
 
         // dump mmap threads
-        for (size_t i = 0; i < mMmapThreads.size(); i++) {
-            mMmapThreads.valueAt(i)->dump(fd, args);
+        for (const auto& [_, thread] : mMmapThreads) {
+            thread->dump(fd, args);
         }
 
         // dump orphan effect chains
@@ -1055,8 +1061,6 @@ status_t AudioFlinger::createTrack(const media::CreateTrackRequest& _input,
     std::vector<audio_io_handle_t> secondaryOutputs;
     bool isSpatialized = false;
     bool isBitPerfect = false;
-    float volume;
-    bool muted;
 
     audio_io_handle_t effectThreadId = AUDIO_IO_HANDLE_NONE;
     std::vector<int> effectIds;
@@ -1120,7 +1124,7 @@ status_t AudioFlinger::createTrack(const media::CreateTrackRequest& _input,
     lStatus = AudioSystem::getOutputForAttr(&localAttr, &output.outputId, sessionId, &streamType,
                                             adjAttributionSource, &input.config, input.flags,
                                             &selectedDeviceIds, &portId, &secondaryOutputs,
-                                            &isSpatialized, &isBitPerfect, &volume, &muted);
+                                            &isSpatialized, &isBitPerfect);
     output.selectedDeviceIds = selectedDeviceIds;
 
     if (lStatus != NO_ERROR || output.outputId == AUDIO_IO_HANDLE_NONE) {
@@ -1164,9 +1168,8 @@ status_t AudioFlinger::createTrack(const media::CreateTrackRequest& _input,
         sp<IAfEffectChain> effectChain = nullptr;
         // check if an effect chain with the same session ID is present on another
         // output thread and move it here.
-        for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-            sp<IAfPlaybackThread> t = mPlaybackThreads.valueAt(i);
-            if (mPlaybackThreads.keyAt(i) != output.outputId) {
+        for (const auto& [outputId, t] : mPlaybackThreads) {
+            if (outputId != output.outputId) {
                 uint32_t sessions = t->hasAudioSession(sessionId);
                 if (sessions & IAfThreadBase::EFFECT_SESSION) {
                     effectThread = t.get();
@@ -1178,7 +1181,7 @@ status_t AudioFlinger::createTrack(const media::CreateTrackRequest& _input,
         if (effectThread == nullptr) {
             effectChain = getOrphanEffectChain_l(sessionId);
         }
-        ALOGV("createTrack() sessionId: %d volume: %f muted %d", sessionId, volume, muted);
+        ALOGV("createTrack() sessionId: %d", sessionId);
 
         output.sampleRate = input.config.sample_rate;
         output.frameCount = input.frameCount;
@@ -1193,7 +1196,7 @@ status_t AudioFlinger::createTrack(const media::CreateTrackRequest& _input,
                                       input.sharedBuffer, sessionId, &output.flags,
                                       callingPid, adjAttributionSource, input.clientInfo.clientTid,
                                       &lStatus, portId, input.audioTrackCallback, isSpatialized,
-                                      isBitPerfect, &output.afTrackFlags, volume, muted);
+                                      isBitPerfect, &output.afTrackFlags);
         LOG_ALWAYS_FATAL_IF((lStatus == NO_ERROR) && (track == 0));
         // we don't abort yet if lStatus != NO_ERROR; there is still work to be done regardless
 
@@ -1211,7 +1214,7 @@ status_t AudioFlinger::createTrack(const media::CreateTrackRequest& _input,
             // Connect secondary outputs. Failure on a secondary output must not imped the primary
             // Any secondary output setup failure will lead to a desync between the AP and AF until
             // the track is destroyed.
-            updateSecondaryOutputsForTrack_l(track.get(), thread, secondaryOutputs);
+            updateSecondaryOutputsForTrack_l(track, thread, secondaryOutputs);
             // move effect chain to this output thread if an effect on same session was waiting
             // for a track to be created
             if (effectThread != nullptr) {
@@ -1373,11 +1376,11 @@ status_t AudioFlinger::setMasterVolume(float value)
     // assigned to HALs which do not have master volume support will apply
     // master volume during the mix operation.  Threads with HALs which do
     // support master volume will simply ignore the setting.
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        if (mPlaybackThreads.valueAt(i)->isDuplicating()) {
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        if (thread->isDuplicating()) {
             continue;
         }
-        mPlaybackThreads.valueAt(i)->setMasterVolume(value);
+        thread->asVolumeInterface()->setMasterVolume(value);
     }
 
     return NO_ERROR;
@@ -1411,11 +1414,11 @@ status_t AudioFlinger::setMasterBalance(float balance)
 
     mMasterBalance = balance;
 
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        if (mPlaybackThreads.valueAt(i)->isDuplicating()) {
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        if (thread->isDuplicating()) {
             continue;
         }
-        mPlaybackThreads.valueAt(i)->setMasterBalance(balance);
+        thread->asVolumeInterface()->setMasterBalance(balance);
     }
 
     return NO_ERROR;
@@ -1455,8 +1458,8 @@ status_t AudioFlinger::setMode(audio_mode_t mode)
     if (NO_ERROR == ret) {
         audio_utils::lock_guard _l(mutex());
         mMode = mode;
-        for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-            mPlaybackThreads.valueAt(i)->setMode(mode);
+        for (const auto& [_, thread] : mPlaybackThreads) {
+            thread->setMode(mode);
         }
     }
 
@@ -1533,11 +1536,11 @@ void AudioFlinger::setRecordSilenced(audio_port_handle_t portId, bool silenced)
     ALOGV("AudioFlinger::setRecordSilenced(portId:%d, silenced:%d)", portId, silenced);
 
     audio_utils::lock_guard lock(mutex());
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        mRecordThreads[i]->setRecordSilenced(portId, silenced);
+    for (const auto& [_, thread] : mRecordThreads) {
+        thread->setRecordSilenced(portId, silenced);
     }
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        mMmapThreads[i]->setRecordSilenced(portId, silenced);
+    for (const auto& [_, thread] : mMmapThreads) {
+        thread->setRecordSilenced(portId, silenced);
     }
 }
 
@@ -1689,8 +1692,7 @@ status_t AudioFlinger::setPortsVolume(
     }
     const sp<IAfMmapThread> mmapThread = checkMmapThread_l(output);
     if (mmapThread != nullptr && mmapThread->isOutput()) {
-        IAfMmapPlaybackThread *mmapPlaybackThread = mmapThread->asIAfMmapPlaybackThread().get();
-        return mmapPlaybackThread->setPortsVolume(ports, volume, muted);
+        return mmapThread->setPortsVolume(ports, volume, muted);
     }
     return BAD_VALUE;
 }
@@ -1724,16 +1726,22 @@ status_t AudioFlinger::getSupportedLatencyModes(audio_io_handle_t output,
 status_t AudioFlinger::setBluetoothVariableLatencyEnabled(bool enabled) {
     audio_utils::lock_guard _l(mutex());
     status_t status = INVALID_OPERATION;
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        // Success if at least one PlaybackThread supports Bluetooth latency modes
-        if (mPlaybackThreads.valueAt(i)->setBluetoothVariableLatencyEnabled(enabled) == NO_ERROR) {
-            status = NO_ERROR;
+    bool usesModuleWithVariableLatencySupport = false;
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        // Success if at least one PlaybackThread from a module which supports variable latency
+        // is able to set variable latency.
+        if (thread->supportsBluetoothVariableLatency()) {
+            usesModuleWithVariableLatencySupport = true;
+            if (thread->setBluetoothVariableLatencyEnabled(enabled)
+                    == NO_ERROR) {
+                status = NO_ERROR;
+            }
         }
     }
-    if (status == NO_ERROR) {
+    if (!usesModuleWithVariableLatencySupport || status == NO_ERROR) {
         mBluetoothLatencyModesEnabled.store(enabled);
     }
-    return status;
+    return usesModuleWithVariableLatencySupport ? status : NO_ERROR;
 }
 
 status_t AudioFlinger::isBluetoothVariableLatencyEnabled(bool* enabled) const {
@@ -1803,15 +1811,15 @@ status_t AudioFlinger::setStreamMute(audio_stream_type_t stream, bool muted)
 
 void AudioFlinger::broadcastParametersToRecordThreads_l(const String8& keyValuePairs)
 {
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        mRecordThreads.valueAt(i)->setParameters(keyValuePairs);
+    for (const auto& [_, thread] : mRecordThreads) {
+        thread->setParameters(keyValuePairs);
     }
 }
 
 void AudioFlinger::updateOutDevicesForRecordThreads_l(const DeviceDescriptorBaseVector& devices)
 {
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        mRecordThreads.valueAt(i)->updateOutDevices(devices);
+    for (const auto& [_, thread] : mRecordThreads) {
+        thread->updateOutDevices(devices);
     }
 }
 
@@ -1948,8 +1956,8 @@ status_t AudioFlinger::setParameters(audio_io_handle_t ioHandle, const String8&
         if (param.get(String8(AudioParameter::keyBtNrec), value) == NO_ERROR) {
             bool btNrecIsOff = (value == AudioParameter::valueOff);
             if (mBtNrecIsOff.exchange(btNrecIsOff) != btNrecIsOff) {
-                for (size_t i = 0; i < mRecordThreads.size(); i++) {
-                    mRecordThreads.valueAt(i)->checkBtNrec();
+                for (const auto& [_, thread] : mRecordThreads) {
+                    thread->checkBtNrec();
                 }
             }
         }
@@ -2220,12 +2228,12 @@ void AudioFlinger::registerClient(const sp<media::IAudioFlingerClient>& client)
     // ThreadBase::mutex() then AudioFlinger::clientMutex().
     // The config change is always sent from playback or record threads to avoid deadlock
     // with AudioSystem::gLock
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        mPlaybackThreads.valueAt(i)->sendIoConfigEvent(AUDIO_OUTPUT_REGISTERED, pid);
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        thread->sendIoConfigEvent(AUDIO_OUTPUT_REGISTERED, pid);
     }
 
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        mRecordThreads.valueAt(i)->sendIoConfigEvent(AUDIO_INPUT_REGISTERED, pid);
+    for (const auto& [_, thread] : mRecordThreads) {
+        thread->sendIoConfigEvent(AUDIO_INPUT_REGISTERED, pid);
     }
 }
 
@@ -2267,8 +2275,7 @@ void AudioFlinger::removeNotificationClient(pid_t pid)
     }
 }
 
-// Hold either AudioFlinger::mutex or ThreadBase::mutex
-void AudioFlinger::ioConfigChanged_l(audio_io_config_event_t event,
+void AudioFlinger::ioConfigChanged(audio_io_config_event_t event,
                                    const sp<AudioIoDescriptor>& ioDesc,
                                    pid_t pid) {
     media::AudioIoConfigEvent eventAidl = VALUE_OR_FATAL(
@@ -2333,22 +2340,17 @@ void AudioFlinger::removeClient_l(pid_t pid)
 sp<IAfThreadBase> AudioFlinger::getEffectThread_l(audio_session_t sessionId,
         int effectId)
 {
-    sp<IAfThreadBase> thread;
-
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        thread = mPlaybackThreads.valueAt(i);
+    for (const auto& [_, thread] : mPlaybackThreads) {
         if (thread->getEffect(sessionId, effectId) != 0) {
             return thread;
         }
     }
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        thread = mRecordThreads.valueAt(i);
+    for (const auto& [_, thread] : mRecordThreads) {
         if (thread->getEffect(sessionId, effectId) != 0) {
             return thread;
         }
     }
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        thread = mMmapThreads.valueAt(i);
+    for (const auto& [_, thread] : mMmapThreads) {
         if (thread->getEffect(sessionId, effectId) != 0) {
             return thread;
         }
@@ -2593,16 +2595,12 @@ void AudioFlinger::setHasAlreadyCaptured_l(uid_t uid) {
         if (mCapturingClients.count(uid)) return;
         mCapturingClients.emplace(uid);
     }
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        IAfPlaybackThread* const playbackThread = mPlaybackThreads.valueAt(i).get();
-        playbackThread->checkUpdateTrackMetadataForUid(uid);
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        thread->checkUpdateTrackMetadataForUid(uid);
     }
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        IAfMmapThread* const mmapThread = mMmapThreads.valueAt(i).get();
-        if (mmapThread->isOutput()) {
-            IAfMmapPlaybackThread* const mmapPlaybackThread =
-                    mmapThread->asIAfMmapPlaybackThread().get();
-            mmapPlaybackThread->checkUpdateTrackMetadataForUid(uid);
+    for (const auto& [_, thread] : mMmapThreads) {
+        if (thread->isOutput()) {
+            thread->checkUpdateTrackMetadataForUid(uid);
         }
     }
 }
@@ -2944,8 +2942,7 @@ audio_hw_sync_t AudioFlinger::getAudioHwSyncForSession(audio_session_t sessionId
 
     mHwAvSyncIds.add(sessionId, value);
 
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        const sp<IAfPlaybackThread> thread = mPlaybackThreads.valueAt(i);
+    for (const auto& [_, thread] : mPlaybackThreads) {
         uint32_t sessions = thread->hasAudioSession(sessionId);
         if (sessions & IAfThreadBase::TRACK_SESSION) {
             AudioParameter param = AudioParameter();
@@ -2953,7 +2950,7 @@ audio_hw_sync_t AudioFlinger::getAudioHwSyncForSession(audio_session_t sessionId
             String8 keyValuePairs = param.toString();
             thread->setParameters(keyValuePairs);
             forwardParametersToDownstreamPatches_l(thread->id(), keyValuePairs,
-                    [](const sp<IAfPlaybackThread>& thread) { return thread->usesHwAvSync(); });
+                    [](const sp<IAfPlaybackThread>& t) { return t->usesHwAvSync(); });
             break;
         }
     }
@@ -2971,16 +2968,13 @@ status_t AudioFlinger::systemReady()
         return NO_ERROR;
     }
     mSystemReady = true;
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        IAfThreadBase* const thread = mPlaybackThreads.valueAt(i).get();
+    for (const auto& [_, thread] : mPlaybackThreads) {
         thread->systemReady();
     }
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        IAfThreadBase* const thread = mRecordThreads.valueAt(i).get();
+    for (const auto& [_, thread] : mRecordThreads) {
         thread->systemReady();
     }
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        IAfThreadBase* const thread = mMmapThreads.valueAt(i).get();
+    for (const auto& [_, thread] : mMmapThreads) {
         thread->systemReady();
     }
 
@@ -3061,13 +3055,14 @@ void AudioFlinger::setAudioHwSyncForSession_l(
 
 
 sp<IAfThreadBase> AudioFlinger::openOutput_l(audio_module_handle_t module,
-                                                        audio_io_handle_t *output,
-                                                        audio_config_t *halConfig,
-                                                        audio_config_base_t *mixerConfig,
-                                                        audio_devices_t deviceType,
-                                                        const String8& address,
-                                                        audio_output_flags_t *flags,
-                                                        const audio_attributes_t attributes)
+                                             audio_io_handle_t *output,
+                                             audio_config_t *halConfig,
+                                             audio_config_base_t *mixerConfig,
+                                             audio_devices_t deviceType,
+                                             const String8& address,
+                                             audio_output_flags_t *flags,
+                                             const audio_attributes_t attributes,
+                                             int32_t mixPortHalId)
 {
     AudioHwDevice *outHwDev = findSuitableHwDev_l(module, deviceType);
     if (outHwDev == NULL) {
@@ -3096,15 +3091,16 @@ sp<IAfThreadBase> AudioFlinger::openOutput_l(audio_module_handle_t module,
             flags,
             halConfig,
             address.c_str(),
-            {trackMetadata});
+            {trackMetadata},
+            mixPortHalId);
 
     mHardwareStatus = AUDIO_HW_IDLE;
 
     if (status == NO_ERROR) {
         if (*flags & AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) {
-            const sp<IAfMmapPlaybackThread> thread = IAfMmapPlaybackThread::create(
+            const sp<IAfMmapThread> thread = IAfMmapThread::create(
                     this, *output, outHwDev, outputStream, mSystemReady);
-            mMmapThreads.add(*output, thread);
+            mMmapThreads[*output] = thread;
             ALOGV("openOutput_l() created mmap playback thread: ID %d thread %p",
                   *output, thread.get());
             return thread;
@@ -3138,7 +3134,7 @@ sp<IAfThreadBase> AudioFlinger::openOutput_l(audio_module_handle_t module,
                 ALOGV("openOutput_l() created mixer output: ID %d thread %p",
                       *output, thread.get());
             }
-            mPlaybackThreads.add(*output, thread);
+            mPlaybackThreads[*output] = thread;
             struct audio_patch patch;
             mPatchPanel->notifyStreamOpened(outHwDev, *output, &patch);
             if (thread->isMsdDevice()) {
@@ -3189,22 +3185,24 @@ status_t AudioFlinger::openOutput(const media::OpenOutputRequest& request,
     audio_utils::lock_guard _l(mutex());
 
     const sp<IAfThreadBase> thread = openOutput_l(module, &output, &halConfig,
-            &mixerConfig, deviceType, address, &flags, attributes);
+            &mixerConfig, deviceType, address, &flags, attributes, request.mixPortHalId);
     if (thread != 0) {
         uint32_t latencyMs = 0;
+        audio_utils::lock_guard lock(thread->mutex());
         if ((flags & AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) == 0) {
             const auto playbackThread = thread->asIAfPlaybackThread();
-            latencyMs = playbackThread->latency();
+
+            latencyMs = playbackThread->latency_l();
 
             // notify client processes of the new output creation
             playbackThread->ioConfigChanged_l(AUDIO_OUTPUT_OPENED);
 
             // the first primary output opened designates the primary hw device if no HW module
             // named "primary" was already loaded.
-            audio_utils::lock_guard lock(hardwareMutex());
+            audio_utils::lock_guard lock2(hardwareMutex());
             if ((mPrimaryHardwareDev == nullptr) && (flags & AUDIO_OUTPUT_FLAG_PRIMARY)) {
                 ALOGI("Using module %d as the primary audio interface", module);
-                mPrimaryHardwareDev = playbackThread->getOutput()->audioHwDev;
+                mPrimaryHardwareDev = playbackThread->getOutput_l()->audioHwDev;
 
                 mHardwareStatus = AUDIO_HW_SET_MODE;
                 mPrimaryHardwareDev.load()->hwDevice()->setMode(mMode);
@@ -3242,8 +3240,10 @@ audio_io_handle_t AudioFlinger::openDuplicateOutput(audio_io_handle_t output1,
     const sp<IAfDuplicatingThread> thread = IAfDuplicatingThread::create(
             this, thread1, id, mSystemReady);
     thread->addOutputTrack(thread2);
-    mPlaybackThreads.add(id, thread);
+    mPlaybackThreads[id] = thread;
     // notify client processes of the new output creation
+
+    audio_utils::lock_guard lock(thread->mutex());
     thread->ioConfigChanged_l(AUDIO_OUTPUT_OPENED);
     return id;
 }
@@ -3258,7 +3258,7 @@ status_t AudioFlinger::closeOutput_nonvirtual(audio_io_handle_t output)
     // keep strong reference on the playback thread so that
     // it is not destroyed while exit() is executed
     sp<IAfPlaybackThread> playbackThread;
-    sp<IAfMmapPlaybackThread> mmapThread;
+    sp<IAfMmapThread> mmapThread;
     {
         audio_utils::lock_guard _l(mutex());
         playbackThread = checkPlaybackThread_l(output);
@@ -3268,17 +3268,16 @@ status_t AudioFlinger::closeOutput_nonvirtual(audio_io_handle_t output)
             dumpToThreadLog_l(playbackThread);
 
             if (playbackThread->type() == IAfThreadBase::MIXER) {
-                for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-                    if (mPlaybackThreads.valueAt(i)->isDuplicating()) {
-                        IAfDuplicatingThread* const dupThread =
-                                mPlaybackThreads.valueAt(i)->asIAfDuplicatingThread().get();
+                for (const auto& [_, thread] : mPlaybackThreads) {
+                    if (const auto dupThread = thread->asIAfDuplicatingThread();
+                            dupThread != nullptr) {
                         dupThread->removeOutputTrack(playbackThread.get());
                     }
                 }
             }
 
 
-            mPlaybackThreads.removeItem(output);
+            mPlaybackThreads.erase(output);
             // Save AUDIO_SESSION_OUTPUT_MIX effect to orphan chains
             // Output Mix Effect session is used to manage Music Effect by AudioPolicy Manager.
             // It exists across all playback threads.
@@ -3300,8 +3299,8 @@ status_t AudioFlinger::closeOutput_nonvirtual(audio_io_handle_t output)
             }
             // save all effects to the default thread
             if (mPlaybackThreads.size()) {
-                IAfPlaybackThread* const dstThread =
-                        checkPlaybackThread_l(mPlaybackThreads.keyAt(0));
+                const sp<IAfPlaybackThread> dstThread =
+                        checkPlaybackThread_l(mPlaybackThreads.begin()->first);
                 if (dstThread != NULL) {
                     // audioflinger lock is held so order of thread lock acquisition doesn't matter
                     // Use scoped_lock to avoid deadlock order issues with duplicating threads.
@@ -3309,21 +3308,20 @@ status_t AudioFlinger::closeOutput_nonvirtual(audio_io_handle_t output)
                     Vector<sp<IAfEffectChain>> effectChains = playbackThread->getEffectChains_l();
                     for (size_t i = 0; i < effectChains.size(); i ++) {
                         moveEffectChain_ll(effectChains[i]->sessionId(), playbackThread.get(),
-                                dstThread);
+                                dstThread.get());
                     }
                 }
             }
         } else {
-            const sp<IAfMmapThread> mt = checkMmapThread_l(output);
-            mmapThread = mt ? mt->asIAfMmapPlaybackThread().get() : nullptr;
-            if (mmapThread == 0) {
+            mmapThread = checkMmapThread_l(output);
+            if (mmapThread == nullptr || !mmapThread->isOutput()) {
                 return BAD_VALUE;
             }
             dumpToThreadLog_l(mmapThread);
-            mMmapThreads.removeItem(output);
+            mMmapThreads.erase(output);
             ALOGD("closing mmapThread %p", mmapThread.get());
         }
-        ioConfigChanged_l(AUDIO_OUTPUT_CLOSED, sp<AudioIoDescriptor>::make(output));
+        ioConfigChanged(AUDIO_OUTPUT_CLOSED, sp<AudioIoDescriptor>::make(output));
         mPatchPanel->notifyStreamClosed(output);
     }
     // The thread entity (active unit of execution) is no longer running here,
@@ -3356,13 +3354,18 @@ void AudioFlinger::closeOutputFinish(const sp<IAfPlaybackThread>& thread)
 
 void AudioFlinger::closeThreadInternal_l(const sp<IAfPlaybackThread>& thread)
 {
-    mPlaybackThreads.removeItem(thread->id());
+    mPlaybackThreads.erase(thread->id());
     thread->exit();
     closeOutputFinish(thread);
 }
 
 status_t AudioFlinger::suspendOutput(audio_io_handle_t output)
 {
+    if (audioserver_flags::remove_stream_suspend()) {
+        LOG_ALWAYS_FATAL("%s should not be called with remove_stream_suspend flag enabled",
+                         __func__);
+        return INVALID_OPERATION;
+    }
     audio_utils::lock_guard _l(mutex());
     IAfPlaybackThread* const thread = checkPlaybackThread_l(output);
 
@@ -3378,6 +3381,12 @@ status_t AudioFlinger::suspendOutput(audio_io_handle_t output)
 
 status_t AudioFlinger::restoreOutput(audio_io_handle_t output)
 {
+    if (audioserver_flags::remove_stream_suspend()) {
+        LOG_ALWAYS_FATAL("%s should not be called with remove_stream_suspend flag enabled",
+                         __func__);
+        return INVALID_OPERATION;
+    }
+
     audio_utils::lock_guard _l(mutex());
     IAfPlaybackThread* const thread = checkPlaybackThread_l(output);
 
@@ -3417,7 +3426,8 @@ status_t AudioFlinger::openInput(const media::OpenInputRequest& request,
             VALUE_OR_RETURN_STATUS(aidl2legacy_AudioSource_audio_source_t(request.source)),
             VALUE_OR_RETURN_STATUS(aidl2legacy_int32_t_audio_input_flags_t_mask(request.flags)),
             AUDIO_DEVICE_NONE,
-            String8{});
+            String8{},
+            request.mixPortHalId);
 
     response->input = VALUE_OR_RETURN_STATUS(legacy2aidl_audio_io_handle_t_int32_t(input));
     response->config = VALUE_OR_RETURN_STATUS(
@@ -3426,6 +3436,8 @@ status_t AudioFlinger::openInput(const media::OpenInputRequest& request,
 
     if (thread != 0) {
         // notify client processes of the new input creation
+
+        audio_utils::lock_guard lock(thread->mutex());
         thread->ioConfigChanged_l(AUDIO_INPUT_OPENED);
         return NO_ERROR;
     }
@@ -3433,14 +3445,15 @@ status_t AudioFlinger::openInput(const media::OpenInputRequest& request,
 }
 
 sp<IAfThreadBase> AudioFlinger::openInput_l(audio_module_handle_t module,
-                                                         audio_io_handle_t *input,
-                                                         audio_config_t *config,
-                                                         audio_devices_t devices,
-                                                         const char* address,
-                                                         audio_source_t source,
-                                                         audio_input_flags_t flags,
-                                                         audio_devices_t outputDevice,
-                                                         const String8& outputDeviceAddress)
+                                            audio_io_handle_t *input,
+                                            audio_config_t *config,
+                                            audio_devices_t devices,
+                                            const char* address,
+                                            audio_source_t source,
+                                            audio_input_flags_t flags,
+                                            audio_devices_t outputDevice,
+                                            const String8& outputDeviceAddress,
+                                            int32_t mixPortHalId)
 {
     AudioHwDevice *inHwDev = findSuitableHwDev_l(module, devices);
     if (inHwDev == NULL) {
@@ -3456,7 +3469,7 @@ sp<IAfThreadBase> AudioFlinger::openInput_l(audio_module_handle_t module,
     } else if (audio_unique_id_get_use(*input) != AUDIO_UNIQUE_ID_USE_INPUT) {
         ALOGE("openInput_l() requested input handle %d is invalid", *input);
         return 0;
-    } else if (mRecordThreads.indexOfKey(*input) >= 0) {
+    } else if (mRecordThreads.count(*input) > 0) {
         // This should not happen in a transient state with current design.
         ALOGE("openInput_l() requested input handle %d is already assigned", *input);
         return 0;
@@ -3472,13 +3485,14 @@ sp<IAfThreadBase> AudioFlinger::openInput_l(audio_module_handle_t module,
             address,
             source,
             outputDevice,
-            outputDeviceAddress.c_str());
+            outputDeviceAddress.c_str(),
+            mixPortHalId);
 
     if (status == NO_ERROR) {
         if ((flags & AUDIO_INPUT_FLAG_MMAP_NOIRQ) != 0) {
-            const sp<IAfMmapCaptureThread> thread =
-                    IAfMmapCaptureThread::create(this, *input, inHwDev, inputStream, mSystemReady);
-            mMmapThreads.add(*input, thread);
+            const auto thread =
+                    IAfMmapThread::create(this, *input, inHwDev, inputStream, mSystemReady);
+            mMmapThreads[*input] = thread;
             ALOGV("openInput_l() created mmap capture thread: ID %d thread %p", *input,
                     thread.get());
             return thread;
@@ -3488,7 +3502,7 @@ sp<IAfThreadBase> AudioFlinger::openInput_l(audio_module_handle_t module,
             // to forward to audio pre processing modules
             const sp<IAfRecordThread> thread =
                     IAfRecordThread::create(this, inputStream, *input, mSystemReady);
-            mRecordThreads.add(*input, thread);
+            mRecordThreads[*input] = thread;
             ALOGV("openInput_l() created record thread: ID %d thread %p", *input, thread.get());
             return thread;
         }
@@ -3508,7 +3522,7 @@ status_t AudioFlinger::closeInput_nonvirtual(audio_io_handle_t input)
     // keep strong reference on the record thread so that
     // it is not destroyed while exit() is executed
     sp<IAfRecordThread> recordThread;
-    sp<IAfMmapCaptureThread> mmapThread;
+    sp<IAfMmapThread> mmapThread;
     {
         audio_utils::lock_guard _l(mutex());
         recordThread = checkRecordThread_l(input);
@@ -3534,9 +3548,8 @@ status_t AudioFlinger::closeInput_nonvirtual(audio_io_handle_t input)
                 // first check if a record thread is already opened with a client on same session.
                 // This should only happen in case of overlap between one thread tear down and the
                 // creation of its replacement
-                size_t i;
-                for (i = 0; i < mRecordThreads.size(); i++) {
-                    const sp<IAfRecordThread> t = mRecordThreads.valueAt(i);
+                bool found = false;
+                for (const auto& [_, t] : mRecordThreads) {
                     if (t == recordThread) {
                         continue;
                     }
@@ -3545,25 +3558,25 @@ status_t AudioFlinger::closeInput_nonvirtual(audio_io_handle_t input)
                         ALOGV("closeInput() found thread %d for effect session %d",
                               t->id(), chain->sessionId());
                         t->addEffectChain_l(chain);
+                        found = true;
                         break;
                     }
                 }
                 // put the chain aside if we could not find a record thread with the same session id
-                if (i == mRecordThreads.size()) {
+                if (!found) {
                     putOrphanEffectChain_l(chain);
                 }
             }
-            mRecordThreads.removeItem(input);
+            mRecordThreads.erase(input);
         } else {
-            const sp<IAfMmapThread> mt = checkMmapThread_l(input);
-            mmapThread = mt ? mt->asIAfMmapCaptureThread().get() : nullptr;
-            if (mmapThread == 0) {
+            mmapThread = checkMmapThread_l(input);
+            if (mmapThread == nullptr || mmapThread->isOutput()) {
                 return BAD_VALUE;
             }
             dumpToThreadLog_l(mmapThread);
-            mMmapThreads.removeItem(input);
+            mMmapThreads.erase(input);
         }
-        ioConfigChanged_l(AUDIO_INPUT_CLOSED, sp<AudioIoDescriptor>::make(input));
+        ioConfigChanged(AUDIO_INPUT_CLOSED, sp<AudioIoDescriptor>::make(input));
     }
     // FIXME: calling thread->exit() without mutex() held should not be needed anymore now that
     // we have a different lock for notification client
@@ -3590,7 +3603,7 @@ void AudioFlinger::closeInputFinish(const sp<IAfRecordThread>& thread)
 
 void AudioFlinger::closeThreadInternal_l(const sp<IAfRecordThread>& thread)
 {
-    mRecordThreads.removeItem(thread->id());
+    mRecordThreads.erase(thread->id());
     closeInputFinish(thread);
 }
 
@@ -3599,15 +3612,14 @@ status_t AudioFlinger::invalidateTracks(const std::vector<audio_port_handle_t> &
     ALOGV("%s", __func__);
 
     std::set<audio_port_handle_t> portIdSet(portIds.begin(), portIds.end());
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        IAfPlaybackThread* const thread = mPlaybackThreads.valueAt(i).get();
-        thread->invalidateTracks(portIdSet);
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        thread->invalidateTracks(&portIdSet);
         if (portIdSet.empty()) {
             return NO_ERROR;
         }
     }
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        mMmapThreads[i]->invalidateTracks(portIdSet);
+    for (const auto& [_, thread] : mMmapThreads) {
+        thread->invalidateTracks(&portIdSet);
         if (portIdSet.empty()) {
             return NO_ERROR;
         }
@@ -3723,8 +3735,7 @@ std::vector<sp<IAfEffectModule>> AudioFlinger::purgeStaleEffects_l() {
     Vector<sp<IAfEffectChain>> chains;
     std::vector< sp<IAfEffectModule> > removedEffects;
 
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        sp<IAfPlaybackThread> t = mPlaybackThreads.valueAt(i);
+    for (const auto& [_, t] : mPlaybackThreads) {
         audio_utils::lock_guard _l(t->mutex());
         const Vector<sp<IAfEffectChain>> threadChains = t->getEffectChains_l();
         for (size_t j = 0; j < threadChains.size(); j++) {
@@ -3735,8 +3746,7 @@ std::vector<sp<IAfEffectModule>> AudioFlinger::purgeStaleEffects_l() {
         }
     }
 
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        sp<IAfRecordThread> t = mRecordThreads.valueAt(i);
+    for (const auto& [_, t] : mRecordThreads) {
         audio_utils::lock_guard _l(t->mutex());
         const Vector<sp<IAfEffectChain>> threadChains = t->getEffectChains_l();
         for (size_t j = 0; j < threadChains.size(); j++) {
@@ -3745,8 +3755,7 @@ std::vector<sp<IAfEffectModule>> AudioFlinger::purgeStaleEffects_l() {
         }
     }
 
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        const sp<IAfMmapThread> t = mMmapThreads.valueAt(i);
+    for (const auto& [_, t] : mMmapThreads) {
         audio_utils::lock_guard _l(t->mutex());
         const Vector<sp<IAfEffectChain>> threadChains = t->getEffectChains_l();
         for (size_t j = 0; j < threadChains.size(); j++) {
@@ -3865,17 +3874,25 @@ sp<IAfThreadBase> AudioFlinger::checkOutputThread_l(audio_io_handle_t ioHandle)
         return nullptr;
     }
 
-    sp<IAfThreadBase> thread = mPlaybackThreads.valueFor(ioHandle);
-    if (thread == nullptr) {
-        thread = mMmapThreads.valueFor(ioHandle);
+    if (const auto it = mPlaybackThreads.find(ioHandle);
+            it != mPlaybackThreads.end()) {
+        return it->second;
     }
-    return thread;
+    if (const auto it = mMmapThreads.find(ioHandle);
+            it != mMmapThreads.end()) {
+        return it->second;
+    }
+    return {};
 }
 
 // checkPlaybackThread_l() must be called with AudioFlinger::mutex() held
 IAfPlaybackThread* AudioFlinger::checkPlaybackThread_l(audio_io_handle_t output) const
 {
-    return mPlaybackThreads.valueFor(output).get();
+    if (const auto it = mPlaybackThreads.find(output);
+            it != mPlaybackThreads.end()) {
+        return it->second.get();
+    }
+    return {};
 }
 
 // checkMixerThread_l() must be called with AudioFlinger::mutex() held
@@ -3888,43 +3905,49 @@ IAfPlaybackThread* AudioFlinger::checkMixerThread_l(audio_io_handle_t output) co
 // checkRecordThread_l() must be called with AudioFlinger::mutex() held
 IAfRecordThread* AudioFlinger::checkRecordThread_l(audio_io_handle_t input) const
 {
-    return mRecordThreads.valueFor(input).get();
+    if (const auto it = mRecordThreads.find(input);
+            it != mRecordThreads.end()) {
+        return it->second.get();
+    }
+    return {};
 }
 
 // checkMmapThread_l() must be called with AudioFlinger::mutex() held
 IAfMmapThread* AudioFlinger::checkMmapThread_l(audio_io_handle_t io) const
 {
-    return mMmapThreads.valueFor(io).get();
+    if (const auto it = mMmapThreads.find(io);
+            it != mMmapThreads.end()) {
+        return it->second.get();
+    }
+    return {};
 }
 
 
 // checkPlaybackThread_l() must be called with AudioFlinger::mutex() held
 sp<VolumeInterface> AudioFlinger::getVolumeInterface_l(audio_io_handle_t output) const {
-    sp<VolumeInterface> volumeInterface = mPlaybackThreads.valueFor(output).get();
-    if (volumeInterface == nullptr) {
-        IAfMmapThread* const mmapThread = mMmapThreads.valueFor(output).get();
-        if (mmapThread != nullptr) {
-            if (mmapThread->isOutput()) {
-                IAfMmapPlaybackThread* const mmapPlaybackThread =
-                        mmapThread->asIAfMmapPlaybackThread().get();
-                volumeInterface = mmapPlaybackThread;
-            }
+    if (const auto it = mPlaybackThreads.find(output);
+            it != mPlaybackThreads.end()) {
+        return it->second->asVolumeInterface();
+    }
+    if (const auto it = mMmapThreads.find(output);
+            it != mMmapThreads.end()) {
+        const auto& mmapThread = it->second;
+        if (mmapThread->isOutput()) {
+            return mmapThread->asVolumeInterface();
         }
     }
-    return volumeInterface;
+    return {};
 }
 
 std::vector<sp<VolumeInterface>> AudioFlinger::getAllVolumeInterfaces_l() const
 {
     std::vector<sp<VolumeInterface>> volumeInterfaces;
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        volumeInterfaces.push_back(mPlaybackThreads.valueAt(i).get());
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        volumeInterfaces.push_back(thread->asVolumeInterface());
     }
-    for (size_t i = 0; i < mMmapThreads.size(); i++) {
-        if (mMmapThreads.valueAt(i)->isOutput()) {
-            IAfMmapPlaybackThread* const mmapPlaybackThread =
-                    mMmapThreads.valueAt(i)->asIAfMmapPlaybackThread().get();
-            volumeInterfaces.push_back(mmapPlaybackThread);
+    for (const auto& [_, thread] : mMmapThreads) {
+        if (thread->isOutput()) {
+            volumeInterfaces.push_back(thread->asVolumeInterface());
         }
     }
     return volumeInterfaces;
@@ -3937,8 +3960,8 @@ audio_unique_id_t AudioFlinger::nextUniqueId(audio_unique_id_use_t use)
     const int maxRetries = use == AUDIO_UNIQUE_ID_USE_SESSION ? 3 : 1;
     for (int retry = 0; retry < maxRetries; retry++) {
         // The cast allows wraparound from max positive to min negative instead of abort
-        uint32_t base = (uint32_t) atomic_fetch_add_explicit(&mNextUniqueIds[use],
-                (uint_fast32_t) AUDIO_UNIQUE_ID_USE_MAX, memory_order_acq_rel);
+        uint32_t base = (uint32_t) mNextUniqueIds[use].fetch_add(
+                (uint_fast32_t) AUDIO_UNIQUE_ID_USE_MAX, std::memory_order_acq_rel);
         ALOG_ASSERT(audio_unique_id_get_use(base) == AUDIO_UNIQUE_ID_USE_UNSPECIFIED);
         // allow wrap by skipping 0 and -1 for session ids
         if (!(base == 0 || base == (~0u & ~AUDIO_UNIQUE_ID_USE_MASK))) {
@@ -3961,14 +3984,13 @@ IAfPlaybackThread* AudioFlinger::primaryPlaybackThread_l() const
     if (mPrimaryHardwareDev == nullptr) {
         return nullptr;
     }
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        IAfPlaybackThread* const thread = mPlaybackThreads.valueAt(i).get();
-        if(thread->isDuplicating()) {
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        if (thread->isDuplicating()) {
             continue;
         }
         AudioStreamOut *output = thread->getOutput();
         if (output != NULL && output->audioHwDev == mPrimaryHardwareDev) {
-            return thread;
+            return thread.get();
         }
     }
     return nullptr;
@@ -3990,15 +4012,14 @@ IAfPlaybackThread* AudioFlinger::fastPlaybackThread_l() const
 {
     size_t minFrameCount = 0;
     IAfPlaybackThread* minThread = nullptr;
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        IAfPlaybackThread* const thread = mPlaybackThreads.valueAt(i).get();
+    for (const auto& [_, thread] : mPlaybackThreads) {
         if (!thread->isDuplicating()) {
             size_t frameCount = thread->frameCountHAL();
             if (frameCount != 0 && (minFrameCount == 0 || frameCount < minFrameCount ||
                     (frameCount == minFrameCount && thread->hasFastMixer() &&
                     /*minThread != NULL &&*/ !minThread->hasFastMixer()))) {
                 minFrameCount = frameCount;
-                minThread = thread;
+                minThread = thread.get();
             }
         }
     }
@@ -4006,17 +4027,16 @@ IAfPlaybackThread* AudioFlinger::fastPlaybackThread_l() const
 }
 
 IAfThreadBase* AudioFlinger::hapticPlaybackThread_l() const {
-    for (size_t i  = 0; i < mPlaybackThreads.size(); ++i) {
-        IAfPlaybackThread* const thread = mPlaybackThreads.valueAt(i).get();
+    for (const auto& [_, thread] : mPlaybackThreads) {
         if (thread->hapticChannelMask() != AUDIO_CHANNEL_NONE) {
-            return thread;
+            return thread.get();
         }
     }
     return nullptr;
 }
 
 void AudioFlinger::updateSecondaryOutputsForTrack_l(
-        IAfTrack* track,
+        const sp<IAfTrack>& track,
         IAfPlaybackThread* thread,
         const std::vector<audio_io_handle_t> &secondaryOutputs) const {
     TeePatches teePatches;
@@ -4087,6 +4107,7 @@ void AudioFlinger::updateSecondaryOutputsForTrack_l(
 
         const audio_output_flags_t outputFlags =
                 (audio_output_flags_t)(track->getOutputFlags() & ~kIncompatiblePatchTrackFlags);
+        const AudioPlaybackRate playbackRate = track->audioTrackServerProxy()->getPlaybackRate();
         sp<IAfPatchTrack> patchTrack = IAfPatchTrack::create(secondaryThread,
                                                        track->streamType(),
                                                        track->sampleRate(),
@@ -4098,9 +4119,7 @@ void AudioFlinger::updateSecondaryOutputsForTrack_l(
                                                        outputFlags,
                                                        0ns /* timeout */,
                                                        frameCountToBeReady,
-                                                       track->getSpeed(),
-                                                       1.f /* volume */,
-                                                       false /* muted */);
+                                                       playbackRate.mSpeed);
         status = patchTrack->initCheck();
         if (status != NO_ERROR) {
             ALOGE("Secondary output patchTrack init failed: %d", status);
@@ -4128,14 +4147,14 @@ sp<audioflinger::SyncEvent> AudioFlinger::createSyncEvent(AudioSystem::sync_even
             type, triggerSession, listenerSession, callBack, cookie);
     status_t playStatus = NAME_NOT_FOUND;
     status_t recStatus = NAME_NOT_FOUND;
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        playStatus = mPlaybackThreads.valueAt(i)->setSyncEvent(event);
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        playStatus = thread->setSyncEvent(event);
         if (playStatus == NO_ERROR) {
             return event;
         }
     }
-    for (size_t i = 0; i < mRecordThreads.size(); i++) {
-        recStatus = mRecordThreads.valueAt(i)->setSyncEvent(event);
+    for (const auto& [_, thread] : mRecordThreads) {
+        recStatus = thread->setSyncEvent(event);
         if (recStatus == NO_ERROR) {
             return event;
         }
@@ -4507,12 +4526,10 @@ status_t AudioFlinger::createEffect(const media::CreateEffectRequest& request,
         } else if (checkPlaybackThread_l(io) != nullptr
                         && sessionId != AUDIO_SESSION_OUTPUT_STAGE) {
             // allow only one effect chain per sessionId on mPlaybackThreads.
-            for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-                const audio_io_handle_t checkIo = mPlaybackThreads.keyAt(i);
+            for (const auto& [checkIo, thread] : mPlaybackThreads) {
                 if (io == checkIo) {
                     if (hapticPlaybackRequired
-                            && mPlaybackThreads.valueAt(i)
-                                    ->hapticChannelMask() == AUDIO_CHANNEL_NONE) {
+                            && thread->hapticChannelMask() == AUDIO_CHANNEL_NONE) {
                         ALOGE("%s: haptic playback thread is required while the required playback "
                               "thread(io=%d) doesn't support", __func__, (int)io);
                         lStatus = BAD_VALUE;
@@ -4521,7 +4538,7 @@ status_t AudioFlinger::createEffect(const media::CreateEffectRequest& request,
                     continue;
                 }
                 const uint32_t sessionType =
-                        mPlaybackThreads.valueAt(i)->hasAudioSession(sessionId);
+                        thread->hasAudioSession(sessionId);
                 if ((sessionType & IAfThreadBase::EFFECT_SESSION) != 0) {
                     ALOGE("%s: effect %s io %d denied because session %d effect exists on io %d",
                           __func__, descOut.name, (int) io, (int) sessionId, (int) checkIo);
@@ -4737,8 +4754,7 @@ NO_THREAD_SAFETY_ANALYSIS
     sp<IAfEffectChain> orphanChain = getOrphanEffectChain_l(sessionId);
     if (srcThread == nullptr && orphanChain == nullptr && sessionId == AUDIO_SESSION_OUTPUT_MIX) {
         ALOGW("%s() AUDIO_SESSION_OUTPUT_MIX not found in orphans, checking other mix", __func__);
-        for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-            const sp<IAfPlaybackThread> pt = mPlaybackThreads.valueAt(i);
+        for (const auto& [_, pt] : mPlaybackThreads) {
             const uint32_t sessionType = pt->hasAudioSession(AUDIO_SESSION_OUTPUT_MIX);
             if ((pt->type() == IAfThreadBase::MIXER || pt->type() == IAfThreadBase::OFFLOAD) &&
                     ((sessionType & IAfThreadBase::EFFECT_SESSION) != 0)) {
@@ -5002,8 +5018,7 @@ Exit:
 
 bool AudioFlinger::isNonOffloadableGlobalEffectEnabled_l() const
 {
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        const auto thread = mPlaybackThreads.valueAt(i);
+    for (const auto& [_, thread] : mPlaybackThreads) {
         audio_utils::lock_guard l(thread->mutex());
         const sp<IAfEffectChain> ec = thread->getEffectChain_l(AUDIO_SESSION_OUTPUT_MIX);
         if (ec != 0 && ec->isNonOffloadableEnabled()) {
@@ -5017,10 +5032,11 @@ void AudioFlinger::onNonOffloadableGlobalEffectEnable()
 {
     audio_utils::lock_guard _l(mutex());
 
-    for (size_t i = 0; i < mPlaybackThreads.size(); i++) {
-        const sp<IAfPlaybackThread> t = mPlaybackThreads.valueAt(i);
-        if (t->type() == IAfThreadBase::OFFLOAD) {
-            t->invalidateTracks(AUDIO_STREAM_MUSIC);
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        if (thread->type() == IAfThreadBase::OFFLOAD) {
+            // we could invalidate based on session id, but offload threads
+            // are based on single client access, so we invalidate everything.
+            thread->invalidateTracks();
         }
     }
 
@@ -5130,9 +5146,12 @@ status_t AudioFlinger::listAudioPatches(
 
 /**
  * Get the attributes of the mix port when connecting to the given device port.
+ * If `mixPortHalId` is not `AUDIO_PORT_HANDLE_NONE`, it will be used to determine
+ * the mix port. Otherwise, `mixPort->ext.mix.handle` will be used.
  */
 status_t AudioFlinger::getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                       struct audio_port_v7 *mixPort) const {
+                                       struct audio_port_v7 *mixPort,
+                                       int32_t mixPortHalId) const {
     if (status_t status = AudioValidator::validateAudioPort(*devicePort); status != NO_ERROR) {
         ALOGE("%s, invalid device port, status=%d", __func__, status);
         return status;
@@ -5143,7 +5162,7 @@ status_t AudioFlinger::getAudioMixPort(const struct audio_port_v7 *devicePort,
     }
 
     audio_utils::lock_guard _l(mutex());
-    return mPatchPanel->getAudioMixPort_l(devicePort, mixPort);
+    return mPatchPanel->getAudioMixPort_l(devicePort, mixPort, mixPortHalId);
 }
 
 status_t AudioFlinger::setTracksInternalMute(
@@ -5157,8 +5176,9 @@ status_t AudioFlinger::setTracksInternalMute(
                 aidl2legacy_int32_t_audio_port_handle_t(trackInternalMute.portId));
         tracksInternalMuteMap.emplace(portId, trackInternalMute.muted);
     }
-    for (size_t i = 0; i < mPlaybackThreads.size() && !tracksInternalMuteMap.empty(); i++) {
-        mPlaybackThreads.valueAt(i)->setTracksInternalMute(&tracksInternalMuteMap);
+    for (const auto& [_, thread] : mPlaybackThreads) {
+        if (tracksInternalMuteMap.empty()) break;
+        thread->setTracksInternalMute(&tracksInternalMuteMap);
     }
     return NO_ERROR;
 }
diff --git a/services/audioflinger/AudioFlinger.h b/services/audioflinger/AudioFlinger.h
index 88a06c0ea1..19afe09992 100644
--- a/services/audioflinger/AudioFlinger.h
+++ b/services/audioflinger/AudioFlinger.h
@@ -267,8 +267,11 @@ private:
             EXCLUDES_AudioFlinger_Mutex;
 
     // Get the attributes of the mix port when connecting to the given device port.
+    // If `mixPortHalId` is not `AUDIO_PORT_HANDLE_NONE`, it will be used to determine
+    // the mix port. Otherwise, `mixPort->ext.mix.handle` will be used.
     status_t getAudioMixPort(const struct audio_port_v7* devicePort,
-                             struct audio_port_v7* mixPort) const final EXCLUDES_AudioFlinger_Mutex;
+                             struct audio_port_v7* mixPort,
+                             int32_t mixPortHalId) const final EXCLUDES_AudioFlinger_Mutex;
 
     status_t setTracksInternalMute(
             const std::vector<media::TrackInternalMuteInfo>& tracksInternalMute) final
@@ -338,7 +341,8 @@ private:
             audio_source_t source,
             audio_input_flags_t flags,
             audio_devices_t outputDevice,
-            const String8& outputDeviceAddress) final REQUIRES(mutex());
+            const String8& outputDeviceAddress,
+            int32_t mixPortHalId) final REQUIRES(mutex());
     sp<IAfThreadBase> openOutput_l(audio_module_handle_t module,
             audio_io_handle_t* output,
             audio_config_t* halConfig,
@@ -346,7 +350,8 @@ private:
             audio_devices_t deviceType,
             const String8& address,
             audio_output_flags_t* flags,
-            audio_attributes_t attributes) final REQUIRES(mutex());
+            audio_attributes_t attributes,
+            int32_t mixPortHalId) final REQUIRES(mutex());
     const DefaultKeyedVector<audio_module_handle_t, AudioHwDevice*>&
             getAudioHwDevs_l() const final REQUIRES(mutex(), hardwareMutex()) {
               return mAudioHwDevs;
@@ -402,8 +407,7 @@ private:
             const audioflinger::SyncEventCallback& callBack,
             const wp<IAfTrackBase>& cookie) final EXCLUDES_AudioFlinger_Mutex;
 
-    // Hold either AudioFlinger::mutex or ThreadBase::mutex
-    void ioConfigChanged_l(audio_io_config_event_t event,
+    void ioConfigChanged(audio_io_config_event_t event,
             const sp<AudioIoDescriptor>& ioDesc,
             pid_t pid = 0) final EXCLUDES_AudioFlinger_ClientMutex;
     void onNonOffloadableGlobalEffectEnable() final EXCLUDES_AudioFlinger_Mutex;
@@ -448,8 +452,9 @@ public:
                             DeviceIdVector *deviceIds,
                             audio_session_t *sessionId,
                             const sp<MmapStreamCallback>& callback,
+                            const audio_offload_info_t* offloadInfo,
                             sp<MmapStreamInterface>& interface,
-            audio_port_handle_t *handle) EXCLUDES_AudioFlinger_Mutex;
+                            audio_port_handle_t *handle) EXCLUDES_AudioFlinger_Mutex;
 
     void initAudioPolicyLocal(sp<media::IAudioPolicyServiceLocal> audioPolicyLocal) {
         if (mAudioPolicyServiceLocal.load() == nullptr) {
@@ -532,10 +537,10 @@ private:
             REQUIRES(audio_utils::AudioFlinger_Mutex) {
         audio_io_handle_t io = AUDIO_IO_HANDLE_NONE;
 
-        for (size_t i = 0; i < threads.size(); i++) {
-            const uint32_t sessionType = threads.valueAt(i)->hasAudioSession(sessionId);
+        for (const auto& [ioHandle, thread] : threads) {
+            const uint32_t sessionType = thread->hasAudioSession(sessionId);
             if (sessionType != 0) {
-                io = threads.keyAt(i);
+                io = ioHandle;
                 if ((sessionType & IAfThreadBase::EFFECT_SESSION) != 0) {
                     break; // effect chain here.
                 }
@@ -585,7 +590,7 @@ private:
     IAfThreadBase* hapticPlaybackThread_l() const REQUIRES(mutex());
 
               void updateSecondaryOutputsForTrack_l(
-                      IAfTrack* track,
+            const sp<IAfTrack>& track,
                       IAfPlaybackThread* thread,
             const std::vector<audio_io_handle_t>& secondaryOutputs) const REQUIRES(mutex());
 
@@ -681,7 +686,7 @@ private:
     };
 
     mutable hardware_call_state mHardwareStatus = AUDIO_HW_IDLE;  // for dump only
-    DefaultKeyedVector<audio_io_handle_t, sp<IAfPlaybackThread>> mPlaybackThreads
+    std::map<audio_io_handle_t, sp<IAfPlaybackThread>> mPlaybackThreads
             GUARDED_BY(mutex());
     stream_type_t mStreamTypes[AUDIO_STREAM_CNT] GUARDED_BY(mutex());
 
@@ -689,12 +694,12 @@ private:
     bool mMasterMute GUARDED_BY(mutex()) = false;
     float mMasterBalance GUARDED_BY(mutex()) = 0.f;
 
-    DefaultKeyedVector<audio_io_handle_t, sp<IAfRecordThread>> mRecordThreads GUARDED_BY(mutex());
+    std::map<audio_io_handle_t, sp<IAfRecordThread>> mRecordThreads GUARDED_BY(mutex());
 
     std::map<pid_t, sp<NotificationClient>> mNotificationClients GUARDED_BY(clientMutex());
 
                 // updated by atomic_fetch_add_explicit
-    volatile atomic_uint_fast32_t mNextUniqueIds[AUDIO_UNIQUE_ID_USE_MAX];  // ctor init
+    std::atomic<uint_fast32_t> mNextUniqueIds[AUDIO_UNIQUE_ID_USE_MAX];  // ctor init
 
     std::atomic<audio_mode_t> mMode = AUDIO_MODE_INVALID;
     std::atomic<bool> mBtNrecIsOff = false;
@@ -716,7 +721,7 @@ private:
                 // list of MMAP stream control threads. Those threads allow for wake lock, routing
                 // and volume control for activity on the associated MMAP stream at the HAL.
                 // Audio data transfer is directly handled by the client creating the MMAP stream
-    DefaultKeyedVector<audio_io_handle_t, sp<IAfMmapThread>> mMmapThreads GUARDED_BY(mutex());
+    std::map<audio_io_handle_t, sp<IAfMmapThread>> mMmapThreads GUARDED_BY(mutex());
 
     // always returns non-null
     sp<Client> registerClient(pid_t pid, uid_t uid) EXCLUDES_AudioFlinger_ClientMutex;
diff --git a/services/audioflinger/Effects.cpp b/services/audioflinger/Effects.cpp
index 6d5f684bfb..6890ebe87c 100644
--- a/services/audioflinger/Effects.cpp
+++ b/services/audioflinger/Effects.cpp
@@ -2293,6 +2293,24 @@ sp<IAfEffectModule> EffectChain::getEffectFromType_l(
     return 0;
 }
 
+// getEffectFromUuid_l() must be called with IAfThreadBase::mutex() held
+sp<IAfEffectModule> EffectChain::getEffectFromUuid_l(const effect_uuid_t *uuid) const
+{
+    audio_utils::lock_guard _l(mutex());
+
+    if (!uuid) {
+        return 0;
+    }
+
+    for (auto& effect : mEffects) {
+        if (effect->isEffect(*uuid)) {
+            return effect;
+        }
+    }
+
+    return 0;
+}
+
 std::vector<int> EffectChain::getEffectIds_l() const
 {
     std::vector<int> ids;
@@ -3375,7 +3393,19 @@ void EffectChain::EffectCallback::checkSuspendOnEffectEnabled(const sp<IAfEffect
         return;
     }
     // in EffectChain context, an EffectBase is always from an EffectModule so static cast is safe
-    c->checkSuspendOnEffectEnabled_l(effect->asEffectModule(), enabled);
+    if (!threadLocked) {
+        t->mutex().lock();
+    }
+
+    sp<IAfEffectModule> em = effect->asEffectModule();
+    if (em == nullptr) {
+        return;
+    }
+    c->checkSuspendOnEffectEnabled_l(em, enabled);
+
+    if (!threadLocked) {
+        t->mutex().unlock();
+    }
 }
 
 void EffectChain::EffectCallback::onEffectEnable(const sp<IAfEffectBase>& effect) {
@@ -3394,7 +3424,7 @@ void EffectChain::EffectCallback::onEffectDisable(const sp<IAfEffectBase>& effec
     if (t == nullptr) {
         return;
     }
-    t->onEffectDisable();
+    t->onEffectDisable(effect->asEffectModule());
 }
 
 bool EffectChain::EffectCallback::disconnectEffectHandle(IAfEffectHandle *handle,
diff --git a/services/audioflinger/Effects.h b/services/audioflinger/Effects.h
index 9d99b65f5b..5392df38b3 100644
--- a/services/audioflinger/Effects.h
+++ b/services/audioflinger/Effects.h
@@ -499,6 +499,8 @@ public:
             REQUIRES(audio_utils::ThreadBase_Mutex) EXCLUDES_EffectChain_Mutex;
     sp<IAfEffectModule> getEffectFromType_l(const effect_uuid_t* type) const final
             REQUIRES(audio_utils::ThreadBase_Mutex) EXCLUDES_EffectChain_Mutex;
+    sp<IAfEffectModule> getEffectFromUuid_l(const effect_uuid_t* uuid) const final
+            REQUIRES(audio_utils::ThreadBase_Mutex) EXCLUDES_EffectChain_Mutex;
     std::vector<int> getEffectIds_l() const final REQUIRES(audio_utils::ThreadBase_Mutex);
     // FIXME use float to improve the dynamic range
 
diff --git a/services/audioflinger/IAfEffect.h b/services/audioflinger/IAfEffect.h
index 69c7321722..7163897373 100644
--- a/services/audioflinger/IAfEffect.h
+++ b/services/audioflinger/IAfEffect.h
@@ -259,6 +259,8 @@ public:
             REQUIRES(audio_utils::ThreadBase_Mutex) EXCLUDES_EffectChain_Mutex = 0;
     virtual sp<IAfEffectModule> getEffectFromType_l(const effect_uuid_t* type) const
             REQUIRES(audio_utils::ThreadBase_Mutex) EXCLUDES_EffectChain_Mutex = 0;
+    virtual sp<IAfEffectModule> getEffectFromUuid_l(const effect_uuid_t* uuid) const
+            REQUIRES(audio_utils::ThreadBase_Mutex) EXCLUDES_EffectChain_Mutex = 0;
     virtual std::vector<int> getEffectIds_l() const = 0;
     virtual bool setVolume(uint32_t* left, uint32_t* right,
                            bool force = false) EXCLUDES_EffectChain_Mutex = 0;
diff --git a/services/audioflinger/IAfPatchPanel.h b/services/audioflinger/IAfPatchPanel.h
index 15b6ddfed9..63f2a7c052 100644
--- a/services/audioflinger/IAfPatchPanel.h
+++ b/services/audioflinger/IAfPatchPanel.h
@@ -75,7 +75,8 @@ public:
             audio_source_t source,
             audio_input_flags_t flags,
             audio_devices_t outputDevice,
-            const String8& outputDeviceAddress) REQUIRES(mutex()) = 0;
+            const String8& outputDeviceAddress,
+            int32_t mixPortHalId) REQUIRES(mutex()) = 0;
     virtual sp<IAfThreadBase> openOutput_l(audio_module_handle_t module,
             audio_io_handle_t* output,
             audio_config_t* halConfig,
@@ -83,7 +84,8 @@ public:
             audio_devices_t deviceType,
             const String8& address,
             audio_output_flags_t* flags,
-            audio_attributes_t attributes) REQUIRES(mutex()) = 0;
+            audio_attributes_t attributes,
+            int32_t mixPortHalId) REQUIRES(mutex()) = 0;
     virtual audio_utils::mutex& mutex() const
             RETURN_CAPABILITY(audio_utils::AudioFlinger_Mutex) = 0;
     virtual const DefaultKeyedVector<audio_module_handle_t, AudioHwDevice*>&
@@ -306,10 +308,13 @@ public:
 
     /**
      * Get the attributes of the mix port when connecting to the given device port.
+     * If `mixPortHalId` is not `AUDIO_PORT_HANDLE_NONE`, it will be used to determine
+     * the mix port. Otherwise, `mixPort->ext.mix.handle` will be used.
      */
     virtual status_t getAudioMixPort_l(
             const struct audio_port_v7* devicePort,
-            struct audio_port_v7* mixPort) REQUIRES(audio_utils::AudioFlinger_Mutex) = 0;
+            struct audio_port_v7* mixPort,
+            int32_t mixPortHalId) REQUIRES(audio_utils::AudioFlinger_Mutex) = 0;
 };
 
 }  // namespace android
diff --git a/services/audioflinger/IAfThread.h b/services/audioflinger/IAfThread.h
index 8b9ab1995b..7696632da6 100644
--- a/services/audioflinger/IAfThread.h
+++ b/services/audioflinger/IAfThread.h
@@ -46,8 +46,6 @@ namespace android {
 
 class IAfDirectOutputThread;
 class IAfDuplicatingThread;
-class IAfMmapCaptureThread;
-class IAfMmapPlaybackThread;
 class IAfPlaybackThread;
 class IAfRecordThread;
 
@@ -115,8 +113,7 @@ public:
             const wp<IAfTrackBase>& cookie)
             EXCLUDES_AudioFlinger_Mutex = 0;
 
-    // Hold either AudioFlinger::mutex or ThreadBase::mutex
-    virtual void ioConfigChanged_l(audio_io_config_event_t event,
+    virtual void ioConfigChanged(audio_io_config_event_t event,
             const sp<AudioIoDescriptor>& ioDesc,
             pid_t pid = 0) EXCLUDES_AudioFlinger_ClientMutex = 0;
     virtual void onNonOffloadableGlobalEffectEnable() EXCLUDES_AudioFlinger_Mutex = 0;
@@ -157,7 +154,8 @@ public:
 
     virtual status_t readyToRun() = 0;
     virtual void clearPowerManager() EXCLUDES_ThreadBase_Mutex = 0;
-    virtual status_t initCheck() const = 0;
+    virtual status_t initCheck_l() const REQUIRES(mutex()) = 0;
+    virtual status_t initCheck() const EXCLUDES_ThreadBase_Mutex = 0;
     virtual type_t type() const = 0;
     virtual bool isDuplicating() const = 0;
     virtual audio_io_handle_t id() const = 0;
@@ -189,7 +187,7 @@ public:
     virtual void ioConfigChanged_l(
             audio_io_config_event_t event, pid_t pid = 0,
             audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE)
-            /* holds either AF::mutex or TB::mutex */ = 0;
+            REQUIRES(mutex()) = 0;
 
     // sendConfigEvent_l() must be called with ThreadBase::mLock held
     // Can temporarily release the lock if waiting for a reply from
@@ -380,7 +378,7 @@ public:
             RETURN_CAPABILITY(audio_utils::ThreadBase_Mutex) = 0;
 
     virtual void onEffectEnable(const sp<IAfEffectModule>& effect) EXCLUDES_ThreadBase_Mutex = 0;
-    virtual void onEffectDisable() EXCLUDES_ThreadBase_Mutex = 0;
+    virtual void onEffectDisable(const sp<IAfEffectModule>& effect) EXCLUDES_ThreadBase_Mutex = 0;
 
     // invalidateTracksForAudioSession_l must be called with holding mLock.
     virtual void invalidateTracksForAudioSession_l(audio_session_t sessionId) const
@@ -389,7 +387,8 @@ public:
     virtual void invalidateTracksForAudioSession(audio_session_t sessionId) const
             EXCLUDES_ThreadBase_Mutex = 0;
 
-    virtual bool isStreamInitialized() const = 0;
+    virtual bool isStreamInitialized_l() const REQUIRES(mutex()) = 0;
+    virtual bool isStreamInitialized() const EXCLUDES_ThreadBase_Mutex = 0;
     virtual void startMelComputation_l(const sp<audio_utils::MelProcessor>& processor)
             REQUIRES(audio_utils::AudioFlinger_Mutex) = 0;
     virtual void stopMelComputation_l()
@@ -414,6 +413,38 @@ public:
     // processing period cycle).
     virtual audio_utils::DeferredExecutor& getThreadloopExecutor() = 0;
 
+    virtual sp<IAfTrackBase> getTrackById_l(audio_port_handle_t trackId) REQUIRES(mutex()) = 0;
+
+    virtual std::vector<sp<IAfTrackBase>> getTracks_l() REQUIRES(mutex()) = 0;
+
+    // Invalidate tracks by a set of port ids. The port id will be removed from
+    // the given set if the corresponding track is found and invalidated.
+    //
+    // If portIds == nullptr, all tracks, including internal tracks are invalidated.
+    virtual bool invalidateTracks_l(std::set<audio_port_handle_t>* portIds = {})
+            REQUIRES(mutex()) = 0;
+
+    virtual bool invalidateTracks(std::set<audio_port_handle_t>* portIds = {})
+            EXCLUDES_ThreadBase_Mutex = 0;
+
+    virtual status_t setPortsVolume(const std::vector<audio_port_handle_t> &portIds, float volume,
+            bool muted) EXCLUDES_ThreadBase_Mutex = 0;
+
+    virtual void checkUpdateTrackMetadataForUid(uid_t uid) EXCLUDES_ThreadBase_Mutex = 0;
+
+    virtual AudioStreamOut* getOutput_l() const REQUIRES(mutex()) = 0;
+    virtual AudioStreamOut* getOutput() const EXCLUDES_ThreadBase_Mutex = 0;
+    virtual AudioStreamOut* clearOutput_l() REQUIRES(mutex()) = 0;
+    virtual AudioStreamOut* clearOutput() EXCLUDES_ThreadBase_Mutex = 0;
+
+    virtual AudioStreamIn* getInput_l() const REQUIRES(mutex()) = 0;
+    virtual AudioStreamIn* getInput() const EXCLUDES_ThreadBase_Mutex = 0;
+    virtual AudioStreamIn* clearInput_l() REQUIRES(mutex()) = 0;
+    virtual AudioStreamIn* clearInput() EXCLUDES_ThreadBase_Mutex = 0;
+
+    // we use "asVolumeInterface" as the Thread has an isa relationship with VolumeInterface.
+    virtual sp<VolumeInterface> asVolumeInterface() { return nullptr; }
+
     // Dynamic cast to derived interface
     virtual sp<IAfDirectOutputThread> asIAfDirectOutputThread() { return nullptr; }
     virtual sp<IAfDuplicatingThread> asIAfDuplicatingThread() { return nullptr; }
@@ -422,7 +453,7 @@ public:
     virtual IAfThreadCallback* afThreadCallback() const = 0;
 };
 
-class IAfPlaybackThread : public virtual IAfThreadBase, public virtual VolumeInterface {
+class IAfPlaybackThread : public virtual IAfThreadBase {
 public:
     static sp<IAfPlaybackThread> createBitPerfectThread(
             const sp<IAfThreadCallback>& afThreadCallback, AudioStreamOut* output,
@@ -484,20 +515,14 @@ public:
             const sp<media::IAudioTrackCallback>& callback,
             bool isSpatialized,
             bool isBitPerfect,
-            audio_output_flags_t* afTrackFlags,
-            float volume,
-            bool muted)
+            audio_output_flags_t* afTrackFlags)
             REQUIRES(audio_utils::AudioFlinger_Mutex) = 0;
 
     virtual status_t addTrack_l(const sp<IAfTrack>& track) REQUIRES(mutex()) = 0;
     virtual bool destroyTrack_l(const sp<IAfTrack>& track) REQUIRES(mutex()) = 0;
-    virtual bool isTrackActive(const sp<IAfTrack>& track) const REQUIRES(mutex()) = 0;
+    virtual bool isTrackActive_l(const sp<IAfTrack>& track) const REQUIRES(mutex()) = 0;
     virtual void addOutputTrack_l(const sp<IAfTrack>& track) REQUIRES(mutex()) = 0;
 
-    virtual AudioStreamOut* getOutput_l() const REQUIRES(mutex()) = 0;
-    virtual AudioStreamOut* getOutput() const EXCLUDES_ThreadBase_Mutex = 0;
-    virtual AudioStreamOut* clearOutput() EXCLUDES_ThreadBase_Mutex = 0;
-
     // a very large number of suspend() will eventually wraparound, but unlikely
     virtual void suspend() = 0;
     virtual void restore() = 0;
@@ -513,16 +538,6 @@ public:
     virtual status_t attachAuxEffect_l(const sp<IAfTrack>& track, int EffectId)
             REQUIRES(mutex()) = 0;
 
-    // called with AudioFlinger lock held
-    virtual bool invalidateTracks_l(audio_stream_type_t streamType) REQUIRES(mutex()) = 0;
-    virtual bool invalidateTracks_l(std::set<audio_port_handle_t>& portIds) REQUIRES(mutex()) = 0;
-    virtual void invalidateTracks(audio_stream_type_t streamType)
-            EXCLUDES_ThreadBase_Mutex = 0;
-    // Invalidate tracks by a set of port ids. The port id will be removed from
-    // the given set if the corresponding track is found and invalidated.
-    virtual void invalidateTracks(std::set<audio_port_handle_t>& portIds)
-            EXCLUDES_ThreadBase_Mutex = 0;
-
     virtual status_t getTimestamp_l(AudioTimestamp& timestamp) REQUIRES(mutex()) = 0;
     virtual void addPatchTrack(const sp<IAfPatchTrack>& track) EXCLUDES_ThreadBase_Mutex = 0;
     virtual void deletePatchTrack(const sp<IAfPatchTrack>& track) EXCLUDES_ThreadBase_Mutex = 0;
@@ -539,10 +554,6 @@ public:
     virtual void setDownStreamPatch(const struct audio_patch* patch)
             EXCLUDES_ThreadBase_Mutex = 0;
 
-    virtual IAfTrack* getTrackById_l(audio_port_handle_t trackId) REQUIRES(mutex()) = 0;
-
-    virtual std::vector<sp<IAfTrack>> getTracks_l() REQUIRES(mutex()) = 0;
-
     virtual bool hasMixer() const = 0;
 
     virtual status_t setRequestedLatencyMode(audio_latency_mode_t mode) = 0;
@@ -550,11 +561,16 @@ public:
     virtual status_t getSupportedLatencyModes(std::vector<audio_latency_mode_t>* modes)
            EXCLUDES_ThreadBase_Mutex = 0;
 
+    virtual bool supportsBluetoothVariableLatency() const = 0;
+
     virtual status_t setBluetoothVariableLatencyEnabled(bool enabled) = 0;
 
     virtual void setStandby() EXCLUDES_ThreadBase_Mutex = 0;
     virtual void setStandby_l() REQUIRES(mutex()) = 0;
-    virtual bool waitForHalStart() EXCLUDES_ThreadBase_Mutex = 0;
+
+    static constexpr uint32_t kWaitHalTimeoutMs = 2'000;
+    virtual bool waitForHalStart(uint32_t timeoutMs = kWaitHalTimeoutMs)
+            EXCLUDES_ThreadBase_Mutex = 0;
 
     virtual bool hasFastMixer() const = 0;
     virtual FastTrackUnderruns getFastTrackUnderruns(size_t fastIndex) const = 0;
@@ -565,9 +581,6 @@ public:
     virtual void setTracksInternalMute(std::map<audio_port_handle_t, bool>* tracksInternalMute)
             EXCLUDES_ThreadBase_Mutex = 0;
 
-    virtual status_t setPortsVolume(const std::vector<audio_port_handle_t> &portIds, float volume,
-                                    bool muted) EXCLUDES_ThreadBase_Mutex = 0;
-    virtual void checkUpdateTrackMetadataForUid(uid_t uid) EXCLUDES_ThreadBase_Mutex = 0;
 };
 
 class IAfDirectOutputThread : public virtual IAfPlaybackThread {
@@ -620,10 +633,6 @@ public:
     // return true if the caller should then do it's part of the stopping process
     virtual bool stop(IAfRecordTrack* recordTrack) EXCLUDES_ThreadBase_Mutex = 0;
 
-    // NO_THREAD_SAFETY_ANALYSIS: consider atomics
-    virtual AudioStreamIn* getInput() const = 0;
-    virtual AudioStreamIn* clearInput() = 0;
-
     virtual status_t getActiveMicrophones(
             std::vector<media::MicrophoneInfoFw>* activeMicrophones)
             const EXCLUDES_ThreadBase_Mutex = 0;
@@ -663,13 +672,24 @@ public:
     static sp<MmapStreamInterface> createMmapStreamInterfaceAdapter(
             const sp<IAfMmapThread>& mmapThread);
 
+    // Creates a Mmap playback thread from an AudioStreamOut ptr.
+    static sp<IAfMmapThread> create(
+            const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
+            AudioHwDevice* hwDev, AudioStreamOut* output, bool systemReady);
+
+    // Creates a Mmap capture thread from an AudioStreamIn ptr.
+    static sp<IAfMmapThread> create(
+            const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
+            AudioHwDevice* hwDev, AudioStreamIn* input, bool systemReady);
+
     virtual void configure(
             const audio_attributes_t* attr,
             audio_stream_type_t streamType,
             audio_session_t sessionId,
             const sp<MmapStreamCallback>& callback,
             const DeviceIdVector& deviceIds,
-            audio_port_handle_t portId) EXCLUDES_ThreadBase_Mutex = 0;
+            audio_port_handle_t portId,
+            const audio_offload_info_t* offloadInfo) EXCLUDES_ThreadBase_Mutex = 0;
     virtual void disconnect() EXCLUDES_ThreadBase_Mutex = 0;
 
     // MmapStreamInterface handling (see adapter)
@@ -688,41 +708,10 @@ public:
     virtual status_t reportData(const void* buffer, size_t frameCount)
             EXCLUDES_ThreadBase_Mutex = 0;
 
-    // TODO(b/291317898)  move to IAfThreadBase?
-    virtual void invalidateTracks(std::set<audio_port_handle_t>& portIds)
-            EXCLUDES_ThreadBase_Mutex = 0;
-
-    virtual void invalidateTracks(audio_stream_type_t streamType)
-            EXCLUDES_ThreadBase_Mutex = 0;
-
     // Sets the UID records silence - TODO(b/291317898)  move to IAfMmapCaptureThread
     virtual void setRecordSilenced(audio_port_handle_t portId, bool silenced)
             EXCLUDES_ThreadBase_Mutex = 0;
-
-    virtual sp<IAfMmapPlaybackThread> asIAfMmapPlaybackThread() { return nullptr; }
-    virtual sp<IAfMmapCaptureThread> asIAfMmapCaptureThread() { return nullptr; }
-};
-
-class IAfMmapPlaybackThread : public virtual IAfMmapThread, public virtual VolumeInterface {
-public:
-    static sp<IAfMmapPlaybackThread> create(
-            const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
-            AudioHwDevice* hwDev, AudioStreamOut* output, bool systemReady);
-
-    virtual AudioStreamOut* clearOutput() EXCLUDES_ThreadBase_Mutex = 0;
-
-    virtual status_t setPortsVolume(const std::vector<audio_port_handle_t>& portIds, float volume,
-                                    bool muted) EXCLUDES_ThreadBase_Mutex = 0;
-    virtual void checkUpdateTrackMetadataForUid(uid_t uid) EXCLUDES_ThreadBase_Mutex = 0;
 };
 
-class IAfMmapCaptureThread : public virtual IAfMmapThread {
-public:
-    static sp<IAfMmapCaptureThread> create(
-            const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
-            AudioHwDevice* hwDev, AudioStreamIn* input, bool systemReady);
-
-    virtual AudioStreamIn* clearInput() EXCLUDES_ThreadBase_Mutex = 0;
-};
 
 }  // namespace android
diff --git a/services/audioflinger/IAfTrack.h b/services/audioflinger/IAfTrack.h
index ad5ccc6cd5..26ec35e5f0 100644
--- a/services/audioflinger/IAfTrack.h
+++ b/services/audioflinger/IAfTrack.h
@@ -42,22 +42,108 @@ class ResamplerBufferProvider;
 struct Source;
 
 class IAfDuplicatingThread;
+class IAfMmapTrack;
+class IAfOutputTrack;
 class IAfPatchRecord;
 class IAfPatchTrack;
 class IAfPlaybackThread;
 class IAfRecordThread;
+class IAfRecordTrack;
 class IAfThreadBase;
 class IAfThreadCallback;
+class IAfTrack;
+
+/**
+ * Create an iterable view on an existing container of sp<IAfTrackBase>
+ * that automatically converts to a derived interface (i.e. sp<IAfTrack>)
+ * suitable for range based fors.
+ *
+ * We place this view in derived Thread classes (ie. PlaybackThread), where we
+ * know that the Track interface must be compatible with a given Track type
+ * (i.e. IAfTrack).
+ */
+template <typename C, typename T>
+class ContainerView {
+public:
+    using I = std::decay_t<decltype(std::begin(std::declval<C&>()))>;
+
+    explicit ContainerView(C& container) : mContainer(container) {}
+
+    class Iterator {
+    public:
+        explicit Iterator(const I& it) : mIterator(it) {}
+
+        bool operator==(const Iterator& it) const = default;
+
+        bool operator!=(const Iterator& it) const = default;
+
+        Iterator& operator++() {
+             ++mIterator;
+             return *this;
+        }
+
+        // There is no automatic casting here as we use virtual base classes.
+        auto operator*() {
+            if constexpr (std::is_same_v<std::decay_t<T>, sp<IAfTrack>>) {
+                return (*mIterator)->asIAfTrack();
+            } else if constexpr (std::is_same_v<std::decay_t<T>, sp<IAfRecordTrack>>) {
+                return (*mIterator)->asIAfRecordTrack();
+            } else if constexpr (std::is_same_v<std::decay_t<T>, sp<IAfMmapTrack>>) {
+                return (*mIterator)->asIAfMmapTrack();
+            }
+            // Omit IAfOutputTrack, IAfPatchRecord, IAfPatchTrack as not needed at the moment.
+        }
+
+    private:
+        I mIterator;
+    };
+
+    auto begin() {
+        return Iterator(mContainer.begin());
+    }
+
+    auto end() {
+        return Iterator(mContainer.end());
+    }
+
+    auto begin() const {
+        return Iterator(mContainer.begin());
+    }
+
+    auto end() const {
+        return Iterator(mContainer.end());
+    }
+
+private:
+    C& mContainer;
+};
 
 struct TeePatch {
     sp<IAfPatchRecord> patchRecord;
     sp<IAfPatchTrack> patchTrack;
 };
 
+class VolumePortImpl {
+public:
+    // VolumePortInterface implementation
+    // for now the secondary patch tracks will always be not muted
+    // TODO(b/388241142): use volume capture rules to forward the vol/mute to patch tracks
+
+    void setPortVolume(float volume) { mVolume = volume; }
+    float getPortVolume() const { return mVolume; }
+
+    void setPortMute(bool muted) { mMuted = muted; }
+    bool getPortMute() const { return mMuted; }
+
+private:
+    std::atomic<bool> mMuted = false;
+    std::atomic<float> mVolume = 0.f;
+};
+
 using TeePatches = std::vector<TeePatch>;
 
 // Common interface to all Playback and Record tracks.
-class IAfTrackBase : public virtual RefBase {
+class IAfTrackBase : public VolumePortInterface {
 public:
     enum track_state : int32_t {
         IDLE,
@@ -260,12 +346,19 @@ public:
     virtual bool isStopping() const = 0;
     virtual bool isStopping_1() const = 0;
     virtual bool isStopping_2() const = 0;
+
+    virtual sp<IAfTrack> asIAfTrack() { return {}; }
+    virtual sp<IAfMmapTrack> asIAfMmapTrack() { return {}; }
+    virtual sp<IAfOutputTrack> asIAfOutputTrack() { return {}; }
+    virtual sp<IAfPatchTrack> asIAfPatchTrack() { return {}; }
+    virtual sp<IAfPatchRecord> asIAfPatchRecord() { return {}; }
+    virtual sp<IAfRecordTrack> asIAfRecordTrack() { return {}; }
 };
 
 // Functionality shared between MMAP and audioflinger datapath playback tracks. Note that MMAP
 // tracks don't implement the IAfTrack, just IAfTrackBase
 // Not a pure interface since no forward declaration necessary.
-class AfPlaybackCommon : public virtual VolumePortInterface {
+class AfPlaybackCommon : public virtual RefBase {
     using AppOpsSession = media::permission::AppOpsSession<media::permission::DefaultAppOpsFacade>;
 
   public:
@@ -275,7 +368,7 @@ class AfPlaybackCommon : public virtual VolumePortInterface {
         FULL, // enforcement for CONTROL
     };
 
-    AfPlaybackCommon(IAfTrackBase& self, IAfThreadBase& thread, float volume, bool muted,
+    AfPlaybackCommon(IAfTrackBase& self, IAfThreadBase& thread,
                      const audio_attributes_t& attr,
                      const AttributionSourceState& attributionSource,
                      bool isOffloadOrMmap,
@@ -311,20 +404,6 @@ class AfPlaybackCommon : public virtual VolumePortInterface {
         }
     }
 
-    // VolumePortInterface implementation
-    // for now the secondary patch tracks will always be not muted
-    // TODO(b/388241142): use volume capture rules to forward the vol/mute to patch tracks
-
-    void setPortVolume(float volume) final { mVolume = volume; }
-
-    void setPortMute(bool muted) final {
-        mMutedFromPort = muted;
-    }
-
-    float getPortVolume() const final { return mVolume; }
-
-    bool getPortMute() const final { return mMutedFromPort; }
-
   protected:
     // The following methods are for notifying that sonifying playback intends to begin/end
     // for playback hardening purposes.
@@ -339,9 +418,6 @@ class AfPlaybackCommon : public virtual VolumePortInterface {
     std::optional<mediautils::SingleThreadExecutor> mExecutor;
     // TODO: atomic necessary if underneath thread lock?
     std::atomic<mute_state_t> mMuteState;
-    std::atomic<bool> mMutedFromPort;
-    // associated with port
-    std::atomic<float> mVolume = 0.0f;
 
     const EnforcementLevel mEnforcementLevel;
 
@@ -390,9 +466,7 @@ public:
             size_t frameCountToBeReady = SIZE_MAX,
             float speed = 1.0f,
             bool isSpatialized = false,
-            bool isBitPerfect = false,
-            float volume = 0.0f,
-            bool muted = false);
+            bool isBitPerfect = false);
 
     static constexpr std::string_view getLogHeader() {
         using namespace std::literals;
@@ -404,6 +478,8 @@ public:
                         "   Latency\n"sv;
     }
 
+    sp<IAfTrack> asIAfTrack() final { return this; }
+
     virtual void pause() = 0;
     virtual void flush() = 0;
     virtual audio_stream_type_t streamType() const = 0;
@@ -540,6 +616,8 @@ public:
     // Internal mute, this is currently only used for bit-perfect playback
     virtual bool getInternalMute() const = 0;
     virtual void setInternalMute(bool muted) = 0;
+    virtual void setTeePatchesPlaybackRate_l(const AudioPlaybackRate& playbackRate)
+            REQUIRES(audio_utils::ThreadBase_Mutex) = 0;
 };
 
 // playback track, used by DuplicatingThread
@@ -551,6 +629,8 @@ public:
             audio_format_t format, audio_channel_mask_t channelMask, size_t frameCount,
             const AttributionSourceState& attributionSource);
 
+    sp<IAfOutputTrack> asIAfOutputTrack() final { return this; }
+
     virtual ssize_t write(void* data, uint32_t frames) = 0;
     virtual bool bufferQueueEmpty() const = 0;
     virtual bool isActive() const = 0;
@@ -572,9 +652,7 @@ public:
             bool isOut,
             const android::content::AttributionSourceState& attributionSource,
             pid_t creatorPid,
-            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE,
-            float volume = 0.0f,
-            bool muted = false);
+            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE);
 
     static constexpr std::string_view getLogHeader() {
         using namespace std::literals;
@@ -582,6 +660,8 @@ public:
                 "   Format Chn mask  SRate Flags Usg/Src PortVol dB PortMuted\n"sv;
     };
 
+    sp<IAfMmapTrack> asIAfMmapTrack() final { return this; }
+
     // protected by MMapThread::mLock
     virtual void setSilenced_l(bool silenced) = 0;
     // protected by MMapThread::mLock
@@ -625,6 +705,8 @@ public:
                         " Server FrmCnt FrmRdy Sil   Latency\n"sv;
     }
 
+    sp<IAfRecordTrack> asIAfRecordTrack() final { return this; }
+
     // clear the buffer overflow flag
     virtual void clearOverflow() = 0;
     // set the buffer overflow flag and return previous value
@@ -701,9 +783,11 @@ public:
                                              *  as soon as possible to have
                                              *  the lowest possible latency
                                              *  even if it might glitch. */
-            float speed = 1.0f,
-            float volume = 1.0f,
-            bool muted = false);
+            float speed = 1.0f);
+
+    sp<IAfPatchTrack> asIAfPatchTrack() final { return this; }
+
+    virtual void setPlaybackRate(const AudioPlaybackRate &playbackRate) = 0;
 };
 
 class IAfPatchRecord : public virtual IAfRecordTrack, public virtual IAfPatchTrackBase {
@@ -729,6 +813,8 @@ public:
             audio_input_flags_t flags,
             audio_source_t source = AUDIO_SOURCE_DEFAULT);
 
+    sp<IAfPatchRecord> asIAfPatchRecord() final { return this; }
+
     virtual Source* getSource() = 0;
     virtual size_t writeFrames(const void* src, size_t frameCount, size_t frameSize) = 0;
 };
diff --git a/services/audioflinger/MmapTracks.h b/services/audioflinger/MmapTracks.h
index 4e2dd063b4..9429d8aa69 100644
--- a/services/audioflinger/MmapTracks.h
+++ b/services/audioflinger/MmapTracks.h
@@ -36,9 +36,7 @@ public:
                             bool isOut,
                             const android::content::AttributionSourceState& attributionSource,
                             pid_t creatorPid,
-                            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE,
-                            float volume = 0.0f,
-                            bool muted = false);
+                            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE);
     ~MmapTrack() override;
 
     status_t initCheck() const final;
diff --git a/services/audioflinger/PatchPanel.cpp b/services/audioflinger/PatchPanel.cpp
index be59299aef..7cd4d2854a 100644
--- a/services/audioflinger/PatchPanel.cpp
+++ b/services/audioflinger/PatchPanel.cpp
@@ -269,7 +269,8 @@ status_t PatchPanel::createAudioPatch_l(const struct audio_patch* patch,
                                                             outputDevice,
                                                             outputDeviceAddress,
                                                             &flags,
-                                                            attributes);
+                                                            attributes,
+                                                            0 /*mixPortHalId*/);
                     ALOGV("mAfPatchPanelCallback->openOutput_l() returned %p", thread.get());
                     if (thread == 0) {
                         status = NO_MEMORY;
@@ -317,7 +318,8 @@ status_t PatchPanel::createAudioPatch_l(const struct audio_patch* patch,
                                                                     source,
                                                                     flags,
                                                                     outputDevice,
-                                                                    outputDeviceAddress);
+                                                                    outputDeviceAddress,
+                                                                    0 /*mixPortHalId*/);
                 ALOGV("mAfPatchPanelCallback->openInput_l() returned %p inChannelMask %08x",
                       thread.get(), config.channel_mask);
                 if (thread == 0) {
@@ -484,7 +486,8 @@ exit:
 }
 
 status_t PatchPanel::getAudioMixPort_l(const audio_port_v7 *devicePort,
-                                       audio_port_v7 *mixPort) {
+                                       audio_port_v7 *mixPort,
+                                       int32_t mixPortHalId) {
     if (devicePort->type != AUDIO_PORT_TYPE_DEVICE) {
         ALOGE("%s the type of given device port is not DEVICE", __func__);
         return INVALID_OPERATION;
@@ -498,7 +501,7 @@ status_t PatchPanel::getAudioMixPort_l(const audio_port_v7 *devicePort,
         ALOGW("%s cannot find hw module %d", __func__, devicePort->ext.device.hw_module);
         return BAD_VALUE;
     }
-    return hwDevice->getAudioMixPort(devicePort, mixPort);
+    return hwDevice->getAudioMixPort(devicePort, mixPort, mixPortHalId);
 }
 
 PatchPanel::Patch::~Patch()
@@ -649,9 +652,7 @@ status_t PatchPanel::Patch::createConnections_l(const sp<IAfPatchPanel>& panel)
                                            outputFlags,
                                            {} /*timeout*/,
                                            frameCountToBeReady,
-                                           1.0f /*speed*/,
-                                           1.0f /*volume*/,
-                                           false /*muted*/);
+                                           1.0f /*speed*/);
     status = mPlayback.checkTrack(tempPatchTrack.get());
     if (status != NO_ERROR) {
         return status;
diff --git a/services/audioflinger/PatchPanel.h b/services/audioflinger/PatchPanel.h
index f84b40ed61..2c7b792c74 100644
--- a/services/audioflinger/PatchPanel.h
+++ b/services/audioflinger/PatchPanel.h
@@ -76,7 +76,9 @@ public:
     /**
      * Get the attributes of the mix port when connecting to the given device port
      */
-    status_t getAudioMixPort_l(const audio_port_v7* devicePort, audio_port_v7* mixPort) final
+    status_t getAudioMixPort_l(const audio_port_v7* devicePort,
+                               audio_port_v7* mixPort,
+                               int32_t mixPortHalId) final
             REQUIRES(audio_utils::AudioFlinger_Mutex);
 
 private:
diff --git a/services/audioflinger/PlaybackTracks.h b/services/audioflinger/PlaybackTracks.h
index dac5959e89..e4d743b126 100644
--- a/services/audioflinger/PlaybackTracks.h
+++ b/services/audioflinger/PlaybackTracks.h
@@ -96,9 +96,7 @@ public:
                                 size_t frameCountToBeReady = SIZE_MAX,
                                 float speed = 1.0f,
                                 bool isSpatialized = false,
-                                bool isBitPerfect = false,
-                                float volume = 0.0f,
-                                bool muted = false);
+                                bool isBitPerfect = false);
     ~Track() override;
     status_t initCheck() const final;
     void appendDumpHeader(String8& result) const final;
@@ -314,6 +312,12 @@ protected:
     int8_t& retryCount() final { return mRetryCount; }
     FastTrackUnderruns& fastTrackUnderruns() final { return mObservedUnderruns; }
 
+    void setTeePatchesPlaybackRate_l(const AudioPlaybackRate& playbackRate) override
+            REQUIRES(audio_utils::ThreadBase_Mutex) {
+        forEachTeePatchTrack_l([playbackRate](const auto& patchTrack) {
+            patchTrack->setPlaybackRate(playbackRate);
+        });
+    }
 protected:
     mutable FillingStatus mFillingStatus;
     int8_t              mRetryCount;
@@ -504,9 +508,7 @@ public:
                                                                     *  as soon as possible to have
                                                                     *  the lowest possible latency
                                                                     *  even if it might glitch. */
-                                   float speed = 1.0f,
-                                   float volume = 1.0f,
-                                   bool muted = false);
+                                   float speed = 1.0f);
     ~PatchTrack() override;
 
     size_t framesReady() const final;
@@ -523,6 +525,8 @@ public:
     status_t obtainBuffer(Proxy::Buffer* buffer, const struct timespec* timeOut = nullptr) final;
     void releaseBuffer(Proxy::Buffer* buffer) final;
 
+    void setPlaybackRate (const AudioPlaybackRate &playbackRate) override;
+
 private:
     void restartIfDisabled() override;
 };  // end of PatchTrack
diff --git a/services/audioflinger/TEST_MAPPING b/services/audioflinger/TEST_MAPPING
index 5d3fb0a013..da72a37eeb 100644
--- a/services/audioflinger/TEST_MAPPING
+++ b/services/audioflinger/TEST_MAPPING
@@ -14,6 +14,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     }
diff --git a/services/audioflinger/Threads.cpp b/services/audioflinger/Threads.cpp
index 2f5c872aaa..55eb8491a0 100644
--- a/services/audioflinger/Threads.cpp
+++ b/services/audioflinger/Threads.cpp
@@ -643,7 +643,7 @@ const char* IAfThreadBase::threadTypeToString(ThreadBase::type_t type)
 }
 
 ThreadBase::ThreadBase(const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
-        type_t type, bool systemReady, bool isOut)
+        type_t type, bool systemReady, bool isOut, AudioStreamIn* input, AudioStreamOut* output)
     :   Thread(false /*canCallJava*/),
         mType(type),
         mAfThreadCallback(afThreadCallback),
@@ -659,7 +659,9 @@ ThreadBase::ThreadBase(const sp<IAfThreadCallback>& afThreadCallback, audio_io_h
         // mName will be set by concrete (non-virtual) subclass
         mDeathRecipient(new PMDeathRecipient(this)),
         mSystemReady(systemReady),
-        mSignalPending(false)
+        mSignalPending(false),
+        mInput(input),
+        mOutput(output)
 {
     mThreadMetrics.logConstructor(getpid(), threadTypeToString(type), id);
     memset(&mPatch, 0, sizeof(struct audio_patch));
@@ -1271,7 +1273,7 @@ void ThreadBase::getPowerManager_l() {
     }
 }
 
-void ThreadBase::updateWakeLockUids_l(const SortedVector<uid_t>& uids) {
+void ThreadBase::updateWakeLockUids_l(const std::vector<uid_t>& uids) {
     getPowerManager_l();
 
 #if !LOG_NDEBUG
@@ -1793,7 +1795,7 @@ void ThreadBase::onEffectEnable(const sp<IAfEffectModule>& effect) {
     if (!effect->isOffloadable()) {
         if (mType == ThreadBase::OFFLOAD) {
             PlaybackThread *t = (PlaybackThread *)this;
-            t->invalidateTracks(AUDIO_STREAM_MUSIC);
+            t->invalidateTracks();
         }
         if (effect->sessionId() == AUDIO_SESSION_OUTPUT_MIX) {
             mAfThreadCallback->onNonOffloadableGlobalEffectEnable();
@@ -1801,7 +1803,7 @@ void ThreadBase::onEffectEnable(const sp<IAfEffectModule>& effect) {
     }
 }
 
-void ThreadBase::onEffectDisable() {
+void ThreadBase::onEffectDisable([[maybe_unused]] const sp<IAfEffectModule>& effect) {
     if (isOffloadOrMmap()) {
         audio_utils::lock_guard _l(mutex());
         broadcast_l();
@@ -1963,27 +1965,24 @@ void ThreadBase::systemReady()
     mPendingConfigEvents.clear();
 }
 
-template <typename T>
-ssize_t ThreadBase::ActiveTracks<T>::add(const sp<T>& track) {
-    ssize_t index = mActiveTracks.indexOf(track);
-    if (index >= 0) {
-        ALOGW("ActiveTracks<T>::add track %p already there", track.get());
-        return index;
+bool ThreadBase::ActiveTracks::add(const sp<IAfTrackBase>& track) {
+    if (mActiveTracks.count(track) > 0) {
+        ALOGW("ActiveTracks::add track %p already there", track.get());
+        return false;
     }
     logTrack("add", track);
     mActiveTracksGeneration++;
     mLatestActiveTrack = track;
     track->beginBatteryAttribution();
     mHasChanged = true;
-    return mActiveTracks.add(track);
+    mActiveTracks.insert(track);
+    return true;
 }
 
-template <typename T>
-ssize_t ThreadBase::ActiveTracks<T>::remove(const sp<T>& track) {
-    ssize_t index = mActiveTracks.remove(track);
-    if (index < 0) {
-        ALOGW("ActiveTracks<T>::remove nonexistent track %p", track.get());
-        return index;
+bool ThreadBase::ActiveTracks::remove(const sp<IAfTrackBase>& track) {
+    if (mActiveTracks.erase(track) == 0) {
+        ALOGW("ActiveTracks::remove nonexistent track %p", track.get());
+        return false;
     }
     logTrack("remove", track);
     mActiveTracksGeneration++;
@@ -1994,12 +1993,11 @@ ssize_t ThreadBase::ActiveTracks<T>::remove(const sp<T>& track) {
     track->dumpTee(-1 /* fd */, "_REMOVE");
 #endif
     track->logEndInterval(); // log to MediaMetrics
-    return index;
+    return true;
 }
 
-template <typename T>
-void ThreadBase::ActiveTracks<T>::clear() {
-    for (const sp<T> &track : mActiveTracks) {
+void ThreadBase::ActiveTracks::clear() {
+    for (const sp<IAfTrackBase> &track : mActiveTracks) {
         track->endBatteryAttribution();
         logTrack("clear", track);
     }
@@ -2009,8 +2007,7 @@ void ThreadBase::ActiveTracks<T>::clear() {
     mLatestActiveTrack.clear();
 }
 
-template <typename T>
-void ThreadBase::ActiveTracks<T>::updatePowerState_l(
+void ThreadBase::ActiveTracks::updatePowerState_l(
         const sp<ThreadBase>& thread, bool force) {
     // Updates ActiveTracks client uids to the thread wakelock.
     if (mActiveTracksGeneration != mLastActiveTracksGeneration || force) {
@@ -2019,12 +2016,11 @@ void ThreadBase::ActiveTracks<T>::updatePowerState_l(
     }
 }
 
-template <typename T>
-bool ThreadBase::ActiveTracks<T>::readAndClearHasChanged() {
+bool ThreadBase::ActiveTracks::readAndClearHasChanged() {
     bool hasChanged = mHasChanged;
     mHasChanged = false;
 
-    for (const sp<T> &track : mActiveTracks) {
+    for (const auto& track : mActiveTracks) {
         // Do not short-circuit as all hasChanged states must be reset
         // as all the metadata are going to be sent
         hasChanged |= track->readAndClearHasChanged();
@@ -2032,9 +2028,8 @@ bool ThreadBase::ActiveTracks<T>::readAndClearHasChanged() {
     return hasChanged;
 }
 
-template <typename T>
-void ThreadBase::ActiveTracks<T>::logTrack(
-        const char *funcName, const sp<T> &track) const {
+void ThreadBase::ActiveTracks::logTrack(
+        const char *funcName, const sp<IAfTrackBase>& track) const {
     if (mLocalLog != nullptr) {
         String8 result;
         track->appendDump(result, false /* active */);
@@ -2042,6 +2037,37 @@ void ThreadBase::ActiveTracks<T>::logTrack(
     }
 }
 
+bool ThreadBase::Tracks::remove(const sp<IAfTrackBase>& track)
+{
+    const int trackId = track->id();
+    const bool removed = mTracks.erase(track) > 0;
+    if (removed) {
+        if (mSaveDeletedTrackIds) {
+            // We can't directly access mAudioMixer since the caller may be outside of threadLoop.
+            // Instead, we add to mDeletedTrackIds which is solely used for mAudioMixer update,
+            // to be handled when MixerThread::prepareTracks_l() next changes mAudioMixer.
+            mDeletedTrackIds.emplace(trackId);
+        }
+    }
+    return removed;
+}
+
+// getTrackById_l must be called with holding thread lock
+sp<IAfTrackBase> ThreadBase::getTrackById_l(
+        audio_port_handle_t trackPortId) {
+    for (const auto& track : mTracks) {
+        if (track->portId() == trackPortId) {
+            return track;
+        }
+    }
+    return {};
+}
+
+// getTracks_l must be called with holding thread lock
+std::vector<sp<IAfTrackBase>> ThreadBase::getTracks_l() {
+    return std::vector(mTracks.begin(), mTracks.end());
+}
+
 void ThreadBase::broadcast_l()
 {
     // Thread could be blocked waiting for async
@@ -2141,6 +2167,75 @@ void ThreadBase::stopMelComputation_l()
     ALOGW("%s: ThreadBase does not support CSD", __func__);
 }
 
+std::set<audio_port_handle_t> ThreadBase::getTrackPortIds_l() const
+{
+    std::set<int32_t> result;
+    for (const auto& t : mTracks) {
+        if (t->isExternalTrack()) {
+            result.insert(t->portId());
+        }
+    }
+    return result;
+}
+
+std::set<audio_port_handle_t> ThreadBase::getTrackPortIds() const
+{
+    audio_utils::lock_guard _l(mutex());
+    return getTrackPortIds_l();
+}
+
+bool ThreadBase::invalidateTracks(std::set<audio_port_handle_t>* portIds) {
+    audio_utils::lock_guard _l(mutex());
+    return invalidateTracks_l(portIds);
+}
+
+// Only Playback Threads invalidate tracks based on portIds, but we keep
+// open the possibility that Record / Capture Threads may eventually use it.
+bool ThreadBase::invalidateTracks_l(std::set<audio_port_handle_t>* portIds) {
+    bool trackMatch = false;
+    for (const auto& t : mTracks) {
+        if (portIds == nullptr ||
+                (t->isExternalTrack() && portIds->find(t->portId()) != portIds->end())) {
+            t->invalidate();
+            if (portIds) portIds->erase(t->portId());
+            trackMatch = true;
+        }
+    }
+
+    // TODO(b/410038399) consider to apply to all threads for symmetry.
+    if (trackMatch && (type() == MMAP_PLAYBACK || type() == MMAP_CAPTURE)) {
+        broadcast_l();
+    }
+    return trackMatch;
+}
+
+status_t ThreadBase::setPortsVolume(
+        const std::vector<audio_port_handle_t>& portIds, float volume, bool muted) {
+    audio_utils::lock_guard _l(mutex());
+    for (const auto& portId : portIds) {
+        // we only consider active tracks because inactive tracks have volume updated
+        // when added to the active track list; also MmapTracks only exist on mActiveTracks.
+        for (const auto& track : mActiveTracks) {
+            if (portId == track->portId()) {
+                track->setPortVolume(volume);
+                track->setPortMute(muted);
+                break;
+            }
+        }
+    }
+    broadcast_l();
+    return NO_ERROR;
+}
+
+void ThreadBase::checkUpdateTrackMetadataForUid(uid_t uid) {
+    audio_utils::lock_guard _l(mutex());
+    for (const auto& track : mActiveTracks) {
+        if (track->uid() == uid) {
+            track->setMetadataHasChanged();
+        }
+    }
+}
+
 // ----------------------------------------------------------------------------
 //      Playback
 // ----------------------------------------------------------------------------
@@ -2151,7 +2246,8 @@ PlaybackThread::PlaybackThread(const sp<IAfThreadCallback>& afThreadCallback,
                                              type_t type,
                                              bool systemReady,
                                              audio_config_base_t *mixerConfig)
-    :   ThreadBase(afThreadCallback, id, type, systemReady, true /* isOut */),
+    :   ThreadBase(afThreadCallback, id, type, systemReady, true /* isOut */,
+            nullptr /* input */, output),
         mNormalFrameCount(0), mSinkBuffer(NULL),
         mMixerBufferEnabled(kEnableExtendedPrecision || type == SPATIALIZER),
         mMixerBuffer(NULL),
@@ -2166,10 +2262,7 @@ PlaybackThread::PlaybackThread(const sp<IAfThreadCallback>& afThreadCallback,
         mSuspended(0), mBytesWritten(0),
         mFramesWritten(0),
         mSuspendedFrames(0),
-        mActiveTracks(&this->mLocalLog),
         // mStreamTypes[] initialized in constructor body
-        mTracks(type == MIXER),
-        mOutput(output),
         mNumWrites(0), mNumDelayedWrites(0), mInWrite(false),
         mMixerStatus(MIXER_IDLE),
         mMixerStatusIgnoringFastTracks(MIXER_IDLE),
@@ -2323,11 +2416,10 @@ void PlaybackThread::dumpTracks_l(int fd, const Vector<String16>& /* args */)
     if (numtracks) {
         dprintf(fd, " of which %zu are active\n", numactive);
         result.append(prefix);
-        mTracks[0]->appendDumpHeader(result);
-        for (size_t i = 0; i < numtracks; ++i) {
-            sp<IAfTrack> track = mTracks[i];
+        (*mTracks.begin())->appendDumpHeader(result);
+        for (const auto& track : mTracks) {
             if (track != 0) {
-                bool active = mActiveTracks.indexOf(track) >= 0;
+                bool active = mActiveTracks.count(track) > 0;
                 if (active) {
                     numactiveseen++;
                 }
@@ -2343,10 +2435,9 @@ void PlaybackThread::dumpTracks_l(int fd, const Vector<String16>& /* args */)
         result.append("  The following tracks are in the active list but"
                 " not in the track list\n");
         result.append(prefix);
-        mActiveTracks[0]->appendDumpHeader(result);
-        for (size_t i = 0; i < numactive; ++i) {
-            sp<IAfTrack> track = mActiveTracks[i];
-            if (mTracks.indexOf(track) < 0) {
+        (*mActiveTracks.begin())->appendDumpHeader(result);
+        for (const auto& track : mActiveTracks) {
+            if (mTracks.count(track) == 0) {
                 result.append(prefix);
                 track->appendDump(result, true /* active */);
             }
@@ -2373,6 +2464,9 @@ void PlaybackThread::dumpInternals_l(int fd, const Vector<String16>& args)
     dprintf(fd, "  Suspend count: %d\n", (int32_t)mSuspended);
     dprintf(fd, "  Fast track availMask=%#x\n", mFastTrackAvailMask);
     dprintf(fd, "  Standby delay ns=%lld\n", (long long)mStandbyDelayNs);
+    dprintf(fd, "  Hw supports pause: %s\n", mHwSupportsPause ? "yes" : "no");
+    dprintf(fd, "  Hw paused: %s\n", mHwPaused ? "yes" : "no");
+    dprintf(fd, "  Flush pending: %s\n", mFlushPending ? "yes" : "no");
     AudioStreamOut *output = mOutput;
     audio_output_flags_t flags = output != NULL ? output->flags : AUDIO_OUTPUT_FLAG_NONE;
     dprintf(fd, "  AudioStreamOut: %p flags %#x (%s)\n",
@@ -2411,9 +2505,7 @@ sp<IAfTrack> PlaybackThread::createTrack_l(
         const sp<media::IAudioTrackCallback>& callback,
         bool isSpatialized,
         bool isBitPerfect,
-        audio_output_flags_t *afTrackFlags,
-        float volume,
-        bool muted)
+        audio_output_flags_t *afTrackFlags)
 {
     size_t frameCount = *pFrameCount;
     size_t notificationFrameCount = *pNotificationFrameCount;
@@ -2586,7 +2678,7 @@ sp<IAfTrack> PlaybackThread::createTrack_l(
             // cover audio hardware latency.
             // This is probably too conservative, but legacy application code may depend on it.
             // If you change this calculation, also review the start threshold which is related.
-            uint32_t latencyMs = latency_l();
+            uint32_t latencyMs = latency();
             if (latencyMs == 0) {
                 ALOGE("Error when retrieving output stream latency");
                 lStatus = UNKNOWN_ERROR;
@@ -2710,8 +2802,7 @@ sp<IAfTrack> PlaybackThread::createTrack_l(
         // conflicts will happen when tracks are moved from one output to another by audio policy
         // manager
         product_strategy_t strategy = getStrategyForStream(streamType);
-        for (size_t i = 0; i < mTracks.size(); ++i) {
-            sp<IAfTrack> t = mTracks[i];
+        for (const auto& t : mPlaybackTracksView) {
             if (t != 0 && t->isExternalTrack()) {
                 product_strategy_t actual = getStrategyForStream(t->streamType());
                 if (sessionId == t->sessionId() && strategy != actual) {
@@ -2742,7 +2833,7 @@ sp<IAfTrack> PlaybackThread::createTrack_l(
                           nullptr /* buffer */, (size_t)0 /* bufferSize */, sharedBuffer,
                           sessionId, creatorPid, attributionSource, trackFlags,
                           IAfTrackBase::TYPE_DEFAULT, portId, SIZE_MAX /*frameCountToBeReady*/,
-                          speed, isSpatialized, isBitPerfect, volume, muted);
+                          speed, isSpatialized, isBitPerfect);
 
         lStatus = track != 0 ? track->initCheck() : (status_t) NO_MEMORY;
         if (lStatus != NO_ERROR) {
@@ -2781,22 +2872,6 @@ Exit:
     return track;
 }
 
-template<typename T>
-ssize_t PlaybackThread::Tracks<T>::remove(const sp<T>& track)
-{
-    const int trackId = track->id();
-    const ssize_t index = mTracks.remove(track);
-    if (index >= 0) {
-        if (mSaveDeletedTrackIds) {
-            // We can't directly access mAudioMixer since the caller may be outside of threadLoop.
-            // Instead, we add to mDeletedTrackIds which is solely used for mAudioMixer update,
-            // to be handled when MixerThread::prepareTracks_l() next changes mAudioMixer.
-            mDeletedTrackIds.emplace(trackId);
-        }
-    }
-    return index;
-}
-
 uint32_t PlaybackThread::correctLatency_l(uint32_t latency) const
 {
     return latency;
@@ -2808,11 +2883,9 @@ uint32_t PlaybackThread::latency() const
     return latency_l();
 }
 uint32_t PlaybackThread::latency_l() const
-NO_THREAD_SAFETY_ANALYSIS
-// Fix later.
 {
     uint32_t latency;
-    if (initCheck() == NO_ERROR && mOutput->stream->getLatency(&latency) == OK) {
+    if (initCheck_l() == NO_ERROR && mOutput->stream->getLatency(&latency) == OK) {
         return correctLatency_l(latency);
     }
     return 0;
@@ -2874,43 +2947,17 @@ float PlaybackThread::streamVolume(audio_stream_type_t stream) const
     return mStreamTypes[stream].volume;
 }
 
-status_t PlaybackThread::setPortsVolume(
-        const std::vector<audio_port_handle_t>& portIds, float volume, bool muted) {
-    audio_utils::lock_guard _l(mutex());
-    for (const auto& portId : portIds) {
-        for (size_t i = 0; i < mTracks.size(); i++) {
-            sp<IAfTrack> track = mTracks[i].get();
-            if (portId == track->portId()) {
-                track->setPortVolume(volume);
-                track->setPortMute(muted);
-                break;
-            }
-        }
-    }
-    broadcast_l();
-    return NO_ERROR;
-}
-
 void PlaybackThread::setVolumeForOutput_l(float left, float right) const
 {
     mOutput->stream->setVolume(left, right);
 }
 
-void PlaybackThread::checkUpdateTrackMetadataForUid(uid_t uid) {
-    audio_utils::lock_guard _l(mutex());
-    for (const sp<IAfTrack>& track : mActiveTracks) {
-        if (track->uid() == uid) {
-            track->setMetadataHasChanged();
-        }
-    }
-}
-
 // addTrack_l() must be called with ThreadBase::mutex() held
 status_t PlaybackThread::addTrack_l(const sp<IAfTrack>& track)
 {
     status_t status = ALREADY_EXISTS;
 
-    if (mActiveTracks.indexOf(track) < 0) {
+    if (mActiveTracks.count(track) == 0) {
         // the track is newly added, make sure it fills up all its
         // buffers before playing. This is to ensure the client will
         // effectively get the latency it requested.
@@ -2918,8 +2965,10 @@ status_t PlaybackThread::addTrack_l(const sp<IAfTrack>& track)
             IAfTrackBase::track_state state = track->state();
             // Because the track is not on the ActiveTracks,
             // at this point, only the TrackHandle will be adding the track.
+            float volume;
+            bool muted;
             mutex().unlock();
-            status = AudioSystem::startOutput(track->portId());
+            status = AudioSystem::startOutput(track->portId(), &volume, &muted);
             mutex().lock();
             // abort track was stopped/paused while we released the lock
             if (state != track->state()) {
@@ -2938,6 +2987,8 @@ status_t PlaybackThread::addTrack_l(const sp<IAfTrack>& track)
                 // immediately.
                 return status == DEAD_OBJECT ? status : PERMISSION_DENIED;
             }
+            track->setPortVolume(volume);
+            track->setPortMute(muted);
 #ifdef ADD_BATTERY_DATA
             // to track the speaker usage
             addBatteryData(IMediaPlayerService::kBatteryDataAudioFlingerStart);
@@ -2985,7 +3036,7 @@ status_t PlaybackThread::addTrack_l(const sp<IAfTrack>& track)
             if (track->getHapticPlaybackEnabled()) {
                 // Disable haptic playback of all active track to ensure only
                 // one track playing haptic if current track should play haptic.
-                for (const auto &t : mActiveTracks) {
+                for (const auto& t : mActivePlaybackTracksView) {
                     t->setHapticPlaybackEnabled(false);
                 }
             }
@@ -3022,7 +3073,7 @@ bool PlaybackThread::destroyTrack_l(const sp<IAfTrack>& track)
 {
     track->terminate();
     // active tracks are removed by threadLoop()
-    bool trackActive = (mActiveTracks.indexOf(track) >= 0);
+    bool trackActive = (mActiveTracks.count(track) > 0);
     track->setState(IAfTrackBase::STOPPED);
     if (!trackActive) {
         removeTrack_l(track);
@@ -3063,28 +3114,11 @@ void PlaybackThread::removeTrack_l(const sp<IAfTrack>& track)
     }
 }
 
-std::set<audio_port_handle_t> PlaybackThread::getTrackPortIds_l()
-{
-    std::set<int32_t> result;
-    for (const auto& t : mTracks) {
-        if (t->isExternalTrack()) {
-            result.insert(t->portId());
-        }
-    }
-    return result;
-}
-
-std::set<audio_port_handle_t> PlaybackThread::getTrackPortIds()
-{
-    audio_utils::lock_guard _l(mutex());
-    return getTrackPortIds_l();
-}
-
 String8 PlaybackThread::getParameters(const String8& keys)
 {
     audio_utils::lock_guard _l(mutex());
     String8 out_s8;
-    if (initCheck() == NO_ERROR && mOutput->stream->getParameters(keys, &out_s8) == OK) {
+    if (initCheck_l() == NO_ERROR && mOutput->stream->getParameters(keys, &out_s8) == OK) {
         return out_s8;
     }
     return {};
@@ -3092,14 +3126,14 @@ String8 PlaybackThread::getParameters(const String8& keys)
 
 status_t DirectOutputThread::selectPresentation(int presentationId, int programId) {
     audio_utils::lock_guard _l(mutex());
-    if (!isStreamInitialized()) {
+    if (!isStreamInitialized_l()) {
         return NO_INIT;
     }
     return mOutput->stream->selectPresentation(presentationId, programId);
 }
 
-void PlaybackThread::ioConfigChanged_l(audio_io_config_event_t event, pid_t pid,
-                                                   audio_port_handle_t portId) {
+void PlaybackThread::ioConfigChanged_l(
+        audio_io_config_event_t event, pid_t pid, audio_port_handle_t portId) {
     ALOGV("PlaybackThread::ioConfigChanged, thread %p, event %d", this, event);
     sp<AudioIoDescriptor> desc;
     const struct audio_patch patch = isMsdDevice() ? mDownStreamPatch : mPatch;
@@ -3120,7 +3154,7 @@ void PlaybackThread::ioConfigChanged_l(audio_io_config_event_t event, pid_t pid,
         desc = sp<AudioIoDescriptor>::make(mId);
         break;
     }
-    mAfThreadCallback->ioConfigChanged_l(event, desc, pid);
+    mAfThreadCallback->ioConfigChanged(event, desc, pid);
 }
 
 void PlaybackThread::onWriteReady()
@@ -3398,12 +3432,12 @@ NO_THREAD_SAFETY_ANALYSIS
 
 ThreadBase::MetadataUpdate PlaybackThread::updateMetadata_l()
 {
-    if (!isStreamInitialized() || !mActiveTracks.readAndClearHasChanged()) {
+    if (!isStreamInitialized_l() || !mActiveTracks.readAndClearHasChanged()) {
         return {}; // nothing to do
     }
     StreamOutHalInterface::SourceMetadata metadata;
     std::map<audio_session_t, std::vector<playback_track_metadata_v7_t> >allSessionsMetadata;
-    for (const sp<IAfTrack>& track : mActiveTracks) {
+    for (const auto& track : mActivePlaybackTracksView) {
         std::vector<playback_track_metadata_v7_t>& sessionMetadata =
                 allSessionsMetadata[track->sessionId()];
         auto backInserter = std::back_inserter(sessionMetadata);
@@ -3452,7 +3486,7 @@ status_t PlaybackThread::getRenderPosition(
         return BAD_VALUE;
     }
     audio_utils::lock_guard _l(mutex());
-    if (initCheck() != NO_ERROR) {
+    if (initCheck_l() != NO_ERROR) {
         return INVALID_OPERATION;
     }
     int64_t framesWritten = mBytesWritten / mFrameSize;
@@ -3480,8 +3514,7 @@ product_strategy_t PlaybackThread::getStrategyForSession_l(audio_session_t sessi
     if (sessionId == AUDIO_SESSION_OUTPUT_MIX) {
         return getStrategyForStream(AUDIO_STREAM_MUSIC);
     }
-    for (size_t i = 0; i < mTracks.size(); i++) {
-        sp<IAfTrack> track = mTracks[i];
+    for (const auto& track : mPlaybackTracksView) {
         if (sessionId == track->sessionId() && !track->isInvalid()) {
             return getStrategyForStream(track->streamType());
         }
@@ -3489,18 +3522,9 @@ product_strategy_t PlaybackThread::getStrategyForSession_l(audio_session_t sessi
     return getStrategyForStream(AUDIO_STREAM_MUSIC);
 }
 
-
-AudioStreamOut* PlaybackThread::getOutput() const
+AudioStreamOut* PlaybackThread::clearOutput_l()
 {
-    audio_utils::lock_guard _l(mutex());
-    return mOutput;
-}
-
-AudioStreamOut* PlaybackThread::clearOutput()
-{
-    audio_utils::lock_guard _l(mutex());
-    AudioStreamOut *output = mOutput;
-    mOutput = NULL;
+    AudioStreamOut* output = ThreadBase::clearOutput_l();
     // FIXME FastMixer might also have a raw ptr to mOutputSink;
     //       must push a NULL and wait for ack
     mOutputSink.clear();
@@ -3531,8 +3555,7 @@ status_t PlaybackThread::setSyncEvent(const sp<SyncEvent>& event)
 
     audio_utils::lock_guard _l(mutex());
 
-    for (size_t i = 0; i < mTracks.size(); ++i) {
-        sp<IAfTrack> track = mTracks[i];
+    for (const auto& track: mPlaybackTracksView) {
         if (event->triggerSession() == track->sessionId()) {
             (void) track->setSyncEvent(event);
             return NO_ERROR;
@@ -3548,7 +3571,7 @@ bool PlaybackThread::isValidSyncEvent(const sp<SyncEvent>& event) const
 }
 
 void PlaybackThread::threadLoop_removeTracks(
-        [[maybe_unused]] const Vector<sp<IAfTrack>>& tracksToRemove)
+        [[maybe_unused]] const std::vector<sp<IAfTrackBase>>& tracksToRemove)
 {
     // Miscellaneous track cleanup when removed from the active list,
     // called without Thread lock but synchronized with threadLoop processing.
@@ -3562,13 +3585,6 @@ void PlaybackThread::threadLoop_removeTracks(
 #endif
 }
 
-void PlaybackThread::checkSilentMode_l()
-{
-    if (property_get_bool("ro.audio.silent", false)) {
-        ALOGW("ro.audio.silent is now ignored");
-    }
-}
-
 // shared by MIXER and DIRECT, overridden by DUPLICATING
 ssize_t PlaybackThread::threadLoop_write()
 {
@@ -3680,8 +3696,7 @@ void PlaybackThread::threadLoop_exit()
 {
     {
         audio_utils::lock_guard _l(mutex());
-        for (size_t i = 0; i < mTracks.size(); i++) {
-            sp<IAfTrack> track = mTracks[i];
+        for (const auto& track : mTracks) {
             track->invalidate();
         }
         // Clear ActiveTracks to update BatteryNotifier in case active tracks remain.
@@ -3729,66 +3744,6 @@ void PlaybackThread::cacheParameters_l()
     }
 }
 
-bool PlaybackThread::invalidateTracks_l(audio_stream_type_t streamType)
-{
-    ALOGV("MixerThread::invalidateTracks() mixer %p, streamType %d, mTracks.size %zu",
-            this,  streamType, mTracks.size());
-    bool trackMatch = false;
-    size_t size = mTracks.size();
-    for (size_t i = 0; i < size; i++) {
-        sp<IAfTrack> t = mTracks[i];
-        if (t->streamType() == streamType && t->isExternalTrack()) {
-            t->invalidate();
-            trackMatch = true;
-        }
-    }
-    return trackMatch;
-}
-
-void PlaybackThread::invalidateTracks(audio_stream_type_t streamType)
-{
-    audio_utils::lock_guard _l(mutex());
-    invalidateTracks_l(streamType);
-}
-
-void PlaybackThread::invalidateTracks(std::set<audio_port_handle_t>& portIds) {
-    audio_utils::lock_guard _l(mutex());
-    invalidateTracks_l(portIds);
-}
-
-bool PlaybackThread::invalidateTracks_l(std::set<audio_port_handle_t>& portIds) {
-    bool trackMatch = false;
-    const size_t size = mTracks.size();
-    for (size_t i = 0; i < size; i++) {
-        sp<IAfTrack> t = mTracks[i];
-        if (t->isExternalTrack() && portIds.find(t->portId()) != portIds.end()) {
-            t->invalidate();
-            portIds.erase(t->portId());
-            trackMatch = true;
-        }
-        if (portIds.empty()) {
-            break;
-        }
-    }
-    return trackMatch;
-}
-
-// getTrackById_l must be called with holding thread lock
-IAfTrack* PlaybackThread::getTrackById_l(
-        audio_port_handle_t trackPortId) {
-    for (size_t i = 0; i < mTracks.size(); i++) {
-        if (mTracks[i]->portId() == trackPortId) {
-            return mTracks[i].get();
-        }
-    }
-    return nullptr;
-}
-
-// getTracks_l must be called with holding thread lock
-std::vector<sp<IAfTrack>> PlaybackThread::getTracks_l() {
-    return std::vector(mTracks.begin(), mTracks.end());
-}
-
 status_t PlaybackThread::addEffectChain_l(const sp<IAfEffectChain>& chain)
 {
     audio_session_t session = chain->sessionId();
@@ -3885,8 +3840,7 @@ status_t PlaybackThread::addEffectChain_l(const sp<IAfEffectChain>& chain)
 
     if (!audio_is_global_session(session)) {
         // Attach all tracks with same session ID to this chain.
-        for (size_t i = 0; i < mTracks.size(); ++i) {
-            sp<IAfTrack> track = mTracks[i];
+        for (const auto& track : mPlaybackTracksView) {
             if (session == track->sessionId()) {
                 ALOGV("addEffectChain_l() track->setMainBuffer track %p buffer %p",
                         track.get(), buffer);
@@ -3896,7 +3850,7 @@ status_t PlaybackThread::addEffectChain_l(const sp<IAfEffectChain>& chain)
         }
 
         // indicate all active tracks in the chain
-        for (const sp<IAfTrack>& track : mActiveTracks) {
+        for (const auto& track : mActiveTracks) {
             if (session == track->sessionId()) {
                 ALOGV("addEffectChain_l() activating track %p on session %d",
                         track.get(), session);
@@ -3948,7 +3902,7 @@ size_t PlaybackThread::removeEffectChain_l(const sp<IAfEffectChain>& chain)
         if (chain == mEffectChains[i]) {
             mEffectChains.removeAt(i);
             // detach all active tracks from the chain
-            for (const sp<IAfTrack>& track : mActiveTracks) {
+            for (const auto& track : mActiveTracks) {
                 if (session == track->sessionId()) {
                     ALOGV("removeEffectChain_l(): stopping track on chain %p for session Id: %d",
                             chain.get(), session);
@@ -3957,8 +3911,7 @@ size_t PlaybackThread::removeEffectChain_l(const sp<IAfEffectChain>& chain)
             }
 
             // detach all tracks with same session ID from this chain
-            for (size_t j = 0; j < mTracks.size(); ++j) {
-                sp<IAfTrack> track = mTracks[j];
+            for (const auto& track : mPlaybackTracksView) {
                 if (session == track->sessionId()) {
                     track->setMainBuffer(reinterpret_cast<float*>(mSinkBuffer));
                     chain->decTrackCnt();
@@ -4002,8 +3955,7 @@ status_t PlaybackThread::attachAuxEffect_l(
 
 void PlaybackThread::detachAuxEffect_l(int effectId)
 {
-    for (size_t i = 0; i < mTracks.size(); ++i) {
-        sp<IAfTrack> track = mTracks[i];
+    for (const auto& track : mPlaybackTracksView) {
         if (track->auxEffectId() == effectId) {
             attachAuxEffect_l(track, 0);
         }
@@ -4013,7 +3965,9 @@ void PlaybackThread::detachAuxEffect_l(int effectId)
 bool PlaybackThread::threadLoop()
 NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
 {
-    if (mType == SPATIALIZER) {
+    // Check the flag and not the mixer type to also boost the duplicating thread priority
+    // when one of the outputs is a spatializer thread.
+    if (mOutput != nullptr && ((mOutput->flags & AUDIO_OUTPUT_FLAG_SPATIALIZER) != 0)) {
         const pid_t tid = getTid();
         if (tid == -1) {  // odd: we are here, we must be a running thread.
             ALOGW("%s: Cannot update Spatializer mixer thread priority, no tid", __func__);
@@ -4046,7 +4000,7 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
         }
     }
 
-    Vector<sp<IAfTrack>> tracksToRemove;
+    std::vector<sp<IAfTrackBase>> tracksToRemove;
 
     mStandbyTimeNs = systemTime();
     int64_t lastLoopCountWritten = -2; // never matches "previous" loop, when loopCount = 0.
@@ -4062,7 +4016,6 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
         audio_utils::lock_guard l(mutex());
 
         cacheParameters_l();
-        checkSilentMode_l();
     }
 
     mSleepTimeUs = mIdleSleepTimeUs;
@@ -4092,7 +4045,7 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
         Vector<sp<IAfEffectChain>> effectChains;
         audio_session_t activeHapticSessionId = AUDIO_SESSION_NONE;
         bool isHapticSessionSpatialized = false;
-        std::vector<sp<IAfTrack>> activeTracks;
+        std::vector<sp<IAfTrackBase>> activeTracks;
 
         // If the device is AUDIO_DEVICE_OUT_BUS, check for downstream latency.
         //
@@ -4183,7 +4136,7 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
 
                 continue;
             }
-            if ((mActiveTracks.isEmpty() && systemTime() > mStandbyTimeNs) ||
+            if ((mActiveTracks.empty() && systemTime() > mStandbyTimeNs) ||
                                    isSuspended()) {
                 // put audio hardware into standby after short delay
                 if (shouldStandby_l()) {
@@ -4200,7 +4153,7 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
                     sendStatistics(false /* force */);
                 }
 
-                if (mActiveTracks.isEmpty() && mConfigEvents.isEmpty()) {
+                if (mActiveTracks.empty() && mConfigEvents.isEmpty()) {
                     // we're about to wait, flush the binder command buffer
                     IPCThreadState::self()->flushCommands();
 
@@ -4221,7 +4174,6 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
                     mMixerStatusIgnoringFastTracks = MIXER_IDLE;
                     mBytesWritten = 0;
                     mBytesRemaining = 0;
-                    checkSilentMode_l();
 
                     mStandbyTimeNs = systemTime() + mStandbyDelayNs;
                     mSleepTimeUs = mIdleSleepTimeUs;
@@ -4250,7 +4202,7 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
 
             // updateTeePatches_l will acquire the ThreadBase_Mutex of other threads,
             // so this is done before we lock our effect chains.
-            for (const auto& track : mActiveTracks) {
+            for (const auto& track : mActivePlaybackTracksView) {
                 track->updateTeePatches_l();
             }
 
@@ -4284,7 +4236,7 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
             // The haptic data from the effect is at a higher priority than the one from track.
             // TODO: Write haptic data directly to sink buffer when mixing.
             if (mHapticChannelCount > 0) {
-                for (const auto& track : mActiveTracks) {
+                for (const auto& track : mActivePlaybackTracksView) {
                     sp<IAfEffectChain> effectChain = getEffectChain_l(track->sessionId());
                     if (effectChain != nullptr
                             && effectChain->containsHapticGeneratingEffect_l()) {
@@ -4317,7 +4269,8 @@ NO_THREAD_SAFETY_ANALYSIS  // manual locking of AudioFlinger
                     mCurrentWriteLength = mSinkBufferSize;
 
                     // Tally underrun frames as we are inserting 0s here.
-                    for (const auto& track : activeTracks) {
+                    for (const auto& tb : activeTracks) {
+                        const auto track = tb->asIAfTrack();
                         if (track->fillingStatus() == IAfTrack::FS_ACTIVE
                                 && !track->isStopped()
                                 && !track->isPaused()
@@ -4806,7 +4759,7 @@ void PlaybackThread::collectTimestamps_l()
                     ? systemTime() : (int64_t)mLastIoBeginNs;
         }
 
-        for (const sp<IAfTrack>& t : mActiveTracks) {
+        for (const auto& t : mActivePlaybackTracksView) {
             if (!t->isFastTrack()) {
                 t->updateTrackFrameInfo(
                         t->audioTrackServerProxy()->framesReleased(),
@@ -4837,7 +4790,7 @@ void PlaybackThread::collectTimestamps_l()
 }
 
 // removeTracks_l() must be called with ThreadBase::mutex() held
-void PlaybackThread::removeTracks_l(const Vector<sp<IAfTrack>>& tracksToRemove)
+void PlaybackThread::removeTracks_l(const std::vector<sp<IAfTrackBase>>& tracksToRemove)
 NO_THREAD_SAFETY_ANALYSIS  // release and re-acquire mutex()
 {
     if (tracksToRemove.empty()) return;
@@ -4870,7 +4823,7 @@ NO_THREAD_SAFETY_ANALYSIS  // release and re-acquire mutex()
             mutex().unlock();
             // Unlock due to VibratorService will lock for this call and will
             // call Tracks.mute/unmute which also require thread's lock.
-            afutils::onExternalVibrationStop(track->getExternalVibration());
+            afutils::onExternalVibrationStop(track->asIAfTrack()->getExternalVibration());
             mutex().lock();
 
             // When the track is stop, set the haptic intensity as MUTE
@@ -4890,7 +4843,7 @@ NO_THREAD_SAFETY_ANALYSIS  // release and re-acquire mutex()
 
         if (track->isTerminated()) {
             // remove from our tracks vector
-            removeTrack_l(track);
+            removeTrack_l(track->asIAfTrack());
         }
     }
 
@@ -5018,7 +4971,6 @@ status_t PlaybackThread::createAudioPatch_l(const struct audio_patch *patch,
                          (mPatch.sinks[0].id != sinkPortId);
     mPatch = *patch;
     mOutDeviceTypeAddrs = deviceTypeAddrs;
-    checkSilentMode_l();
 
     if (mOutput->audioHwDev->supportsAudioPatches()) {
         sp<DeviceHalInterface> hwDevice = mOutput->audioHwDev->hwDevice();
@@ -5513,9 +5465,7 @@ void PlaybackThread::onAddNewTrack_l()
 void PlaybackThread::onAsyncError(bool isHardError)
 {
     auto allTrackPortIds = getTrackPortIds();
-    for (int i = AUDIO_STREAM_SYSTEM; i < (int)AUDIO_STREAM_CNT; i++) {
-        invalidateTracks((audio_stream_type_t)i);
-    }
+    invalidateTracks();
     if (isHardError) {
         mAfThreadCallback->onHardError(allTrackPortIds);
     }
@@ -5594,7 +5544,7 @@ void MixerThread::threadLoop_sleepTime()
 
 // prepareTracks_l() must be called with ThreadBase::mutex() held
 PlaybackThread::mixer_state MixerThread::prepareTracks_l(
-        Vector<sp<IAfTrack>>* tracksToRemove)
+        std::vector<sp<IAfTrackBase>>* tracksToRemove)
 {
     // clean up deleted track ids in AudioMixer before allocating new tracks
     (void)mTracks.processDeletedTrackIds([this](int trackId) {
@@ -5612,7 +5562,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
     size_t tracksWithEffect = 0;
     // counts only _active_ fast tracks
     size_t fastTracks = 0;
-    uint32_t resetMask = 0; // bit mask of fast tracks that need to be reset
+    std::vector<sp<IAfTrack>> resetTracks;
 
     float masterVolume = mMasterVolume;
     bool masterMute = mMasterMute;
@@ -5682,9 +5632,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
     // implicit nested scope for variable capture
 
     bool noFastHapticTrack = true;
-    for (size_t i=0 ; i<count ; i++) {
-        const sp<IAfTrack> t = mActiveTracks[i];
-
+    for (const auto& t : mActivePlaybackTracksView) {
         // this const just means the local variable doesn't change
         IAfTrack* const track = t.get();
 
@@ -5805,7 +5753,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
                     // Can't reset directly, as fast mixer is still polling this track
                     //   track->reset();
                     // So instead mark this track as needing to be reset after push with ack
-                    resetMask |= 1 << i;
+                    resetTracks.push_back(track);
                 }
                 isActive = false;
                 break;
@@ -5919,7 +5867,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
                             track->sharedBuffer() != 0);
                     // Since the FastMixer state already has the track inactive, do nothing here.
                 }
-                tracksToRemove->add(track);
+                tracksToRemove->push_back(track);
                 // Avoids a misleading display in dumpsys
                 track->fastTrackUnderruns().mBitFields.mMostRecent = UNDERRUN_FULL;
             }
@@ -5951,7 +5899,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
                         " mask %#x, format %#x, sessionId %d",
                         __func__, trackId,
                         track->channelMask(), track->format(), track->sessionId());
-                tracksToRemove->add(track);
+                tracksToRemove->push_back(track);
                 track->invalidate(); // consider it dead.
                 continue;
             }
@@ -6192,6 +6140,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
                 // cast away constness for this generic API.
                 const_cast<void *>(reinterpret_cast<const void *>(&playbackRate)));
 
+            track->setTeePatchesPlaybackRate_l(playbackRate);
             /*
              * Select the appropriate output buffer for the track.
              *
@@ -6305,7 +6254,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
                     if (track->isStopped()) {
                         track->reset();
                     }
-                    tracksToRemove->add(track);
+                    tracksToRemove->push_back(track);
                 }
             } else {
                 // No buffers for this track. Give it a few chances to
@@ -6313,7 +6262,7 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
                 if (--(track->retryCount()) <= 0) {
                     ALOGI("%s BUFFER TIMEOUT: remove track(%d) from active list due to underrun"
                           " on thread %d", __func__, trackId, mId);
-                    tracksToRemove->add(track);
+                    tracksToRemove->push_back(track);
                     // indicate to client process that the track was disabled because of underrun;
                     // it will then automatically call start() when data is available
                     track->disable();
@@ -6385,12 +6334,8 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
 #endif
 
     // Now perform the deferred reset on fast tracks that have stopped
-    while (resetMask != 0) {
-        size_t i = __builtin_ctz(resetMask);
-        ALOG_ASSERT(i < count);
-        resetMask &= ~(1 << i);
-        sp<IAfTrack> track = mActiveTracks[i];
-        ALOG_ASSERT(track->isFastTrack() && track->isStopped());
+    for (const auto& track : resetTracks) {
+        // ALOG_ASSERT(track->isFastTrack() && track->isStopped());
         track->reset();
     }
 
@@ -6457,13 +6402,8 @@ PlaybackThread::mixer_state MixerThread::prepareTracks_l(
 // trackCountForUid_l() must be called with ThreadBase::mutex() held
 uint32_t PlaybackThread::trackCountForUid_l(uid_t uid) const
 {
-    uint32_t trackCount = 0;
-    for (size_t i = 0; i < mTracks.size() ; i++) {
-        if (mTracks[i]->uid() == uid) {
-            trackCount++;
-        }
-    }
-    return trackCount;
+    return std::count_if(mTracks.begin(), mTracks.end(),
+            [uid](const auto& track) { return track->uid() == uid; });
 }
 
 bool PlaybackThread::IsTimestampAdvancing::check(AudioStreamOut* output)
@@ -6551,7 +6491,7 @@ bool MixerThread::checkForNewParameter_l(const String8& keyValuePair,
         // do not accept frame count changes if tracks are open as the track buffer
         // size depends on frame count and correct behavior would not be guaranteed
         // if frame count is changed after track creation
-        if (!mTracks.isEmpty()) {
+        if (!mTracks.empty()) {
             status = INVALID_OPERATION;
         } else {
             reconfig = true;
@@ -6751,9 +6691,13 @@ void MixerThread::onRecommendedLatencyModeChanged(
     }
 }
 
+bool MixerThread::supportsBluetoothVariableLatency() const {
+    return mOutput != nullptr && mOutput->audioHwDev != nullptr
+            && mOutput->audioHwDev->supportsBluetoothVariableLatency();
+}
+
 status_t MixerThread::setBluetoothVariableLatencyEnabled(bool enabled) {
-    if (mOutput == nullptr || mOutput->audioHwDev == nullptr
-            || !mOutput->audioHwDev->supportsBluetoothVariableLatency()) {
+    if (!supportsBluetoothVariableLatency()) {
         return INVALID_OPERATION;
     }
     mBluetoothLatencyModesEnabled.store(enabled);
@@ -6801,7 +6745,7 @@ void DirectOutputThread::setMasterBalance(float balance)
     }
 }
 
-void DirectOutputThread::processVolume_l(IAfTrack* track, bool lastTrack)
+void DirectOutputThread::processVolume_l(const sp<IAfTrack>& track, bool lastTrack)
 {
     float left, right;
 
@@ -6923,7 +6867,7 @@ void DirectOutputThread::processVolume_l(IAfTrack* track, bool lastTrack)
 void DirectOutputThread::onAddNewTrack_l()
 {
     sp<IAfTrack> previousTrack = mPreviousTrack.promote();
-    sp<IAfTrack> latestTrack = mActiveTracks.getLatest();
+    const sp<IAfTrack> latestTrack = mActiveTracks.getLatest()->asIAfTrack();
 
     if (previousTrack != 0 && latestTrack != 0) {
         if (mType == DIRECT) {
@@ -6946,7 +6890,7 @@ void DirectOutputThread::onAddNewTrack_l()
 }
 
 PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
-    Vector<sp<IAfTrack>>* tracksToRemove
+    std::vector<sp<IAfTrackBase>>* tracksToRemove
 )
 {
     size_t count = mActiveTracks.size();
@@ -6955,14 +6899,14 @@ PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
     bool doHwResume = false;
 
     // find out which tracks need to be processed
-    for (const sp<IAfTrack>& t : mActiveTracks) {
+    for (const auto& t : mActiveTracks) {
         if (t->isInvalid()) {
             ALOGW("An invalidated track shouldn't be in active list");
-            tracksToRemove->add(t);
+            tracksToRemove->push_back(t);
             continue;
         }
 
-        IAfTrack* const track = t.get();
+        const auto track = t->asIAfTrack();
 #ifdef VERY_VERY_VERBOSE_LOGGING
         audio_track_cblk_t* cblk = track->cblk();
 #endif
@@ -6970,7 +6914,7 @@ PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
         // In theory an older track could underrun and restart after the new one starts
         // but as we only care about the transition phase between two tracks on a
         // direct output, it is not a problem to ignore the underrun case.
-        sp<IAfTrack> l = mActiveTracks.getLatest();
+        const sp<IAfTrack> l = mActiveTracks.getLatest()->asIAfTrack();
         bool last = l.get() == track;
 
         if (track->isPausePending()) {
@@ -7063,7 +7007,7 @@ PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
 
                 // reset retry count
                 track->retryCount() = targetRetryCount;
-                mActiveTrack = t;
+                mActiveTrack = t->asIAfTrack();
                 mixerStatus = MIXER_TRACKS_READY;
                 if (mHwPaused) {
                     doHwResume = true;
@@ -7100,7 +7044,7 @@ PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
                     if (track->isStopped()) {
                         track->reset();
                     }
-                    tracksToRemove->add(track);
+                    tracksToRemove->push_back(track);
                 }
             } else {
                 // No buffers for this track. Give it a few chances to
@@ -7114,7 +7058,7 @@ PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
                     } else {
                         ALOGI("%s BUFFER TIMEOUT: remove track(%d) from active list due to"
                               " underrun on thread %d", __func__, trackId, mId);
-                        tracksToRemove->add(track);
+                        tracksToRemove->push_back(track);
                         // indicate to client process that the track was disabled because of
                         // underrun; it will then automatically call start() when data is available
                         track->disable();
@@ -7137,9 +7081,9 @@ PlaybackThread::mixer_state DirectOutputThread::prepareTracks_l(
 
     // if an active track did not command a flush, check for pending flush on stopped tracks
     if (!mFlushPending) {
-        for (size_t i = 0; i < mTracks.size(); i++) {
-            if (mTracks[i]->isFlushPending()) {
-                mTracks[i]->flushAck();
+        for (const auto& track: mPlaybackTracksView) {
+            if (track->isFlushPending()) {
+                track->flushAck();
                 mFlushPending = true;
             }
         }
@@ -7215,9 +7159,9 @@ void DirectOutputThread::threadLoop_exit()
 {
     {
         audio_utils::lock_guard _l(mutex());
-        for (size_t i = 0; i < mTracks.size(); i++) {
-            if (mTracks[i]->isFlushPending()) {
-                mTracks[i]->flushAck();
+        for (const auto& track : mPlaybackTracksView) {
+            if (track->isFlushPending()) {
+                track->flushAck();
                 mFlushPending = true;
             }
         }
@@ -7239,7 +7183,8 @@ bool DirectOutputThread::shouldStandby_l()
     // after a timeout and we will enter standby then.
     // On offload threads, do not enter standby if the main track is still underrunning.
     if (mTracks.size() > 0) {
-        const auto& mainTrack = mTracks[mTracks.size() - 1];
+        // TODO(b/410038399) last track is main track?
+        const auto& mainTrack = (*mTracks.begin())->asIAfTrack();
 
         trackPaused = mainTrack->isPaused();
         trackStopped = mainTrack->isStopped() || mainTrack->state() == IAfTrackBase::IDLE;
@@ -7265,7 +7210,7 @@ bool DirectOutputThread::checkForNewParameter_l(const String8& keyValuePair,
         // do not accept frame count changes if tracks are open as the track buffer
         // size depends on frame count and correct behavior would not be garantied
         // if frame count is changed after track creation
-        if (!mTracks.isEmpty()) {
+        if (!mTracks.empty()) {
             status = INVALID_OPERATION;
         } else {
             reconfig = true;
@@ -7514,7 +7459,7 @@ void OffloadThread::threadLoop_exit()
 }
 
 PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
-    Vector<sp<IAfTrack>>* tracksToRemove
+        std::vector<sp<IAfTrackBase>>* tracksToRemove
 )
 {
     size_t count = mActiveTracks.size();
@@ -7526,7 +7471,7 @@ PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
     ALOGV("OffloadThread::prepareTracks_l active tracks %zu", count);
 
     // find out which tracks need to be processed
-    for (const sp<IAfTrack>& t : mActiveTracks) {
+    for (const auto& t : mActivePlaybackTracksView) {
         IAfTrack* const track = t.get();
 #ifdef VERY_VERY_VERBOSE_LOGGING
         audio_track_cblk_t* cblk = track->cblk();
@@ -7535,12 +7480,12 @@ PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
         // In theory an older track could underrun and restart after the new one starts
         // but as we only care about the transition phase between two tracks on a
         // direct output, it is not a problem to ignore the underrun case.
-        sp<IAfTrack> l = mActiveTracks.getLatest();
+        const sp<IAfTrack> l = mActiveTracks.getLatest()->asIAfTrack();
         bool last = l.get() == track;
 
         if (track->isInvalid()) {
             ALOGW("An invalidated track shouldn't be in active list");
-            tracksToRemove->add(track);
+            tracksToRemove->push_back(track);
             continue;
         }
 
@@ -7578,7 +7523,7 @@ PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
                 mPausedBytesRemaining = mBytesRemaining;
                 mBytesRemaining = 0;    // stop writing
             }
-            tracksToRemove->add(track);
+            tracksToRemove->push_back(track);
         } else if (track->isFlushPending()) {
             if (track->isStopping_1()) {
                 track->retryCount() = kMaxTrackStopRetriesOffload;
@@ -7654,8 +7599,14 @@ PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
                 } else {
                     track->retryCount() = kMaxTrackRetriesOffload;
                 }
-                mActiveTrack = t;
+                mActiveTrack = t->asIAfTrack();
                 mixerStatus = MIXER_TRACKS_READY;
+
+                // start after flush needs a resume here.
+                if (mHwPaused) {
+                    doHwResume = true;
+                    mHwPaused = false;
+                }
             }
         } else {
             ALOGVV("OffloadThread: track(%d) s=%08x [NOT READY]", track->id(), cblk->mServer);
@@ -7699,7 +7650,7 @@ PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
                     mOutput->presentationComplete();
                     track->presentationComplete(latency_l()); // always returns true
                     track->reset();
-                    tracksToRemove->add(track);
+                    tracksToRemove->push_back(track);
                     // OFFLOADED stop resets frame counts.
                     if (!mUseAsyncWrite) {
                         // If we don't get explicit drain notification we must
@@ -7721,7 +7672,7 @@ PlaybackThread::mixer_state OffloadThread::prepareTracks_l(
                     } else {
                         ALOGI("%s BUFFER TIMEOUT: remove track(%d) from active list due to"
                               " underrun on thread %d", __func__, track->id(), mId);
-                        tracksToRemove->add(track);
+                        tracksToRemove->push_back(track);
                         // tell client process that the track was disabled because of underrun;
                         // it will then automatically call start() when data is available
                         track->disable();
@@ -7798,19 +7749,25 @@ void OffloadThread::flushHw_l()
     }
 }
 
-void OffloadThread::invalidateTracks(audio_stream_type_t streamType)
-{
-    audio_utils::lock_guard _l(mutex());
-    if (PlaybackThread::invalidateTracks_l(streamType)) {
-        mFlushPending = true;
-    }
-}
+// TODO(b/410038399) move to base class and unify with Mmap implementation for clarity.
 
-void OffloadThread::invalidateTracks(std::set<audio_port_handle_t>& portIds) {
-    audio_utils::lock_guard _l(mutex());
-    if (PlaybackThread::invalidateTracks_l(portIds)) {
+bool OffloadThread::invalidateTracks_l(std::set<audio_port_handle_t>* portIds) {
+    const bool trackMatch = ThreadBase::invalidateTracks_l(portIds);
+    if (trackMatch) {
+        // On invalidating an offload track, the IAudioTrack instance is
+        // destroyed and the offload output is released. If it so happens
+        // that APM::getOutputForAttr for the new IAudioTrack is called before
+        // OffloadThread::prepareTracks_l checks and removes an invalid track,
+        // the same output can get reused.
+        //
+        // The side effect of this is data present in HAL and below from before the
+        // invalidate will be rendered before data from the new seek position
+        // is rendered. This is unexpected.
+        //
+        // To fix this, set hint to issue flush when an offload track is invalidated.
         mFlushPending = true;
     }
+    return trackMatch;
 }
 
 // ----------------------------------------------------------------------------
@@ -7833,8 +7790,8 @@ DuplicatingThread::DuplicatingThread(const sp<IAfThreadCallback>& afThreadCallba
 
 DuplicatingThread::~DuplicatingThread()
 {
-    for (size_t i = 0; i < mOutputTracks.size(); i++) {
-        mOutputTracks[i]->destroy();
+    for (const auto& track : mOutputTracks) {
+        track->destroy();
     }
 }
 
@@ -7879,20 +7836,27 @@ void DuplicatingThread::threadLoop_sleepTime()
 ssize_t DuplicatingThread::threadLoop_write()
 {
     ATRACE_BEGIN("write");
-    for (size_t i = 0; i < outputTracks.size(); i++) {
-        const ssize_t actualWritten = outputTracks[i]->write(mSinkBuffer, writeFrames);
+    {
+        audio_utils::lock_guard _l(mutex());
+        updateWaitTime_l();
+    }
+
+    bool first = true;
+    for (const auto& t : tlOutputTracks) {
+        const ssize_t actualWritten = t->write(mSinkBuffer, writeFrames);
 
         // Consider the first OutputTrack for timestamp and frame counting.
 
         // The threadLoop() generally assumes writing a full sink buffer size at a time.
         // Here, we correct for writeFrames of 0 (a stop) or underruns because
         // we always claim success.
-        if (i == 0) {
+        if (first) {
             const ssize_t correction = mSinkBufferSize / mFrameSize - actualWritten;
             ALOGD_IF(correction != 0 && writeFrames != 0,
                     "%s: writeFrames:%u  actualWritten:%zd  correction:%zd  mFramesWritten:%lld",
                     __func__, writeFrames, actualWritten, correction, (long long)mFramesWritten);
             mFramesWritten -= correction;
+            first = false;
         }
 
         // TODO: Report correction for the other output tracks and show in the dump.
@@ -7909,8 +7873,8 @@ ssize_t DuplicatingThread::threadLoop_write()
 void DuplicatingThread::threadLoop_standby()
 {
     // DuplicatingThread implements standby by stopping all tracks
-    for (size_t i = 0; i < outputTracks.size(); i++) {
-        outputTracks[i]->stop();
+    for (const auto& track : tlOutputTracks) {
+        track->stop();
     }
 }
 
@@ -7920,17 +7884,17 @@ void DuplicatingThread::threadLoop_exit()
     // where other mutexes (i.e. AudioPolicyService_Mutex) may be held.
     // Do so here in the threadLoop_exit().
 
-    SortedVector <sp<IAfOutputTrack>> localTracks;
+    std::set<sp<IAfOutputTrack>> localTracks;
     {
         audio_utils::lock_guard l(mutex());
         localTracks = std::move(mOutputTracks);
         mOutputTracks.clear();
-        for (size_t i = 0; i < localTracks.size(); ++i) {
-            localTracks[i]->destroy();
+        for (const auto& track : localTracks) {
+            track->destroy();
         }
     }
     localTracks.clear();
-    outputTracks.clear();
+    tlOutputTracks.clear();
     PlaybackThread::threadLoop_exit();
 }
 
@@ -7961,12 +7925,12 @@ void DuplicatingThread::dumpInternals_l(int fd, const Vector<String16>& args)
 
 void DuplicatingThread::saveOutputTracks()
 {
-    outputTracks = mOutputTracks;
+    tlOutputTracks = mOutputTracks;
 }
 
 void DuplicatingThread::clearOutputTracks()
 {
-    outputTracks.clear();
+    tlOutputTracks.clear();
 }
 
 void DuplicatingThread::addOutputTrack(IAfPlaybackThread* thread)
@@ -8001,10 +7965,11 @@ void DuplicatingThread::addOutputTrack(IAfPlaybackThread* thread)
         return;
     }
     if (!audioserver_flags::portid_volume_management()) {
-        thread->setStreamVolume(AUDIO_STREAM_PATCH, /*volume=*/1.0f, /*muted=*/false);
+        thread->asVolumeInterface()->setStreamVolume(
+                AUDIO_STREAM_PATCH, /*volume=*/1.0f, /*muted=*/false);
     }
 
-    mOutputTracks.add(outputTrack);
+    mOutputTracks.emplace(outputTrack);
     ALOGV("addOutputTrack() track %p, on thread %p", outputTrack.get(), thread);
     updateWaitTime_l();
 }
@@ -8012,10 +7977,10 @@ void DuplicatingThread::addOutputTrack(IAfPlaybackThread* thread)
 void DuplicatingThread::removeOutputTrack(IAfPlaybackThread* thread)
 {
     audio_utils::lock_guard _l(mutex());
-    for (size_t i = 0; i < mOutputTracks.size(); i++) {
-        if (mOutputTracks[i]->thread() == thread) {
-            mOutputTracks[i]->destroy();
-            mOutputTracks.removeAt(i);
+    for (const auto& track : mOutputTracks) {
+        if (track->thread() == thread) {
+            track->destroy();
+            mOutputTracks.erase(track);  // OK to erase as we return afterwards.
             updateWaitTime_l();
             // NO_THREAD_SAFETY_ANALYSIS
             // Lambda workaround: as thread != this
@@ -8035,11 +8000,18 @@ void DuplicatingThread::removeOutputTrack(IAfPlaybackThread* thread)
 void DuplicatingThread::updateWaitTime_l()
 {
     // Initialize mWaitTimeMs according to the mixer buffer size.
-    mWaitTimeMs = mNormalFrameCount * 2 * 1000 / mSampleRate;
-    for (size_t i = 0; i < mOutputTracks.size(); i++) {
-        const auto strong = mOutputTracks[i]->thread().promote();
+    mWaitTimeMs = mNormalFrameCount * 1000 / mSampleRate;
+    for (const auto& track : mOutputTracks) {
+        const auto strong = track->thread().promote();
         if (strong != 0) {
-            uint32_t waitTimeMs = (strong->frameCount() * 2 * 1000) / strong->sampleRate();
+            size_t frames = strong->frameCount();
+            // Do not wait in OutputTrack::write() if one of the tracks does not have enough frames
+            // ready to be mixed
+            if (track->isActive() && track->framesReady() < sourceFramesNeededWithTimestretch(
+                track->sampleRate(), frames, strong->sampleRate(), 1.0f /*speed*/)) {
+                frames = 0;
+            }
+            uint32_t waitTimeMs = (frames * 1000) / strong->sampleRate();
             if (waitTimeMs < mWaitTimeMs) {
                 mWaitTimeMs = waitTimeMs;
             }
@@ -8049,17 +8021,16 @@ void DuplicatingThread::updateWaitTime_l()
 
 bool DuplicatingThread::outputsReady()
 {
-    for (size_t i = 0; i < outputTracks.size(); i++) {
-        const auto thread = outputTracks[i]->thread().promote();
+    for (const auto& track : tlOutputTracks) {
+        const auto thread = track->thread().promote();
         if (thread == 0) {
             ALOGW("DuplicatingThread::outputsReady() could not promote thread on output track %p",
-                    outputTracks[i].get());
+                    track.get());
             return false;
         }
         IAfPlaybackThread* const playbackThread = thread->asIAfPlaybackThread().get();
-        // see note at standby() declaration
-        if (playbackThread->inStandby() && !playbackThread->isSuspended()) {
-            ALOGV("DuplicatingThread output track %p on thread %p Not Ready", outputTracks[i].get(),
+        if (!playbackThread->waitForHalStart(0/* timeoutMs */)) {
+            ALOGV("DuplicatingThread output track %p on thread %p Not Ready", track.get(),
                     thread.get());
             return false;
         }
@@ -8070,7 +8041,7 @@ bool DuplicatingThread::outputsReady()
 void DuplicatingThread::sendMetadataToBackend_l(
         const StreamOutHalInterface::SourceMetadata& metadata)
 {
-    for (auto& outputTrack : outputTracks) { // not mOutputTracks
+    for (auto& outputTrack : tlOutputTracks) { // not mOutputTracks
         outputTrack->setMetadatas(metadata.tracks);
     }
 }
@@ -8117,7 +8088,7 @@ void SpatializerThread::setHalLatencyMode_l() {
         return;
     }
     // Do not update the HAL latency mode if no track is active
-    if (mActiveTracks.isEmpty()) {
+    if (mActiveTracks.empty()) {
         return;
     }
 
@@ -8241,10 +8212,9 @@ RecordThread::RecordThread(const sp<IAfThreadCallback>& afThreadCallback,
                                          audio_io_handle_t id,
                                          bool systemReady
                                          ) :
-    ThreadBase(afThreadCallback, id, type, systemReady, false /* isOut */),
-    mInput(input),
+    ThreadBase(afThreadCallback, id, type, systemReady, false /* isOut */,
+        input, nullptr /* output */),
     mSource(mInput),
-    mActiveTracks(&this->mLocalLog),
     mRsmpInBuffer(NULL),
     // mRsmpInFrames, mRsmpInFramesP2, and mRsmpInFramesOA are set by readInputParameters_l()
     mRsmpInRear(0)
@@ -8428,8 +8398,7 @@ void RecordThread::preExit()
 {
     ALOGV("  preExit()");
     audio_utils::lock_guard _l(mutex());
-    for (size_t i = 0; i < mTracks.size(); i++) {
-        sp<IAfRecordTrack> track = mTracks[i];
+    for (const auto& track : mTracks) {
         track->invalidate();
     }
     mActiveTracks.clear();
@@ -8495,8 +8464,7 @@ reacquire_wakelock:
             }
 
             // if no active track(s), then standby and release wakelock
-            size_t size = mActiveTracks.size();
-            if (size == 0) {
+            if (mActiveTracks.empty()) {
                 standbyIfNotAlreadyInStandby();
                 // exitPending() can't become true here
                 releaseWakeLock_l();
@@ -8509,19 +8477,18 @@ reacquire_wakelock:
 
             bool doBroadcast = false;
             bool allStopped = true;
-            for (size_t i = 0; i < size; ) {
+            for (auto it = mActiveTracks.begin() ; it != mActiveTracks.end(); ) {
                 if (activeTrack) {  // ensure track release is outside lock.
                     oldActiveTracks.emplace_back(std::move(activeTrack));
                 }
-                activeTrack = mActiveTracks[i];
+                activeTrack = (*it)->asIAfRecordTrack();
                 if (activeTrack->isTerminated()) {
                     if (activeTrack->isFastTrack()) {
                         ALOG_ASSERT(fastTrackToRemove == 0);
                         fastTrackToRemove = activeTrack;
                     }
                     removeTrack_l(activeTrack);
-                    mActiveTracks.remove(activeTrack);
-                    size--;
+                    it = mActiveTracks.erase(it);
                     continue;
                 }
 
@@ -8529,7 +8496,7 @@ reacquire_wakelock:
                 switch (activeTrackState) {
 
                 case IAfTrackBase::PAUSING:
-                    mActiveTracks.remove(activeTrack);
+                    it = mActiveTracks.erase(it);
                     activeTrack->setState(IAfTrackBase::PAUSED);
                     if (activeTrack->isFastTrack()) {
                         ALOGV("%s fast track is paused, thus removed from active list", __func__);
@@ -8538,12 +8505,11 @@ reacquire_wakelock:
                         fastTrackToRemove = activeTrack;
                     }
                     doBroadcast = true;
-                    size--;
                     continue;
 
                 case IAfTrackBase::STARTING_1:
                     sleepUs = 10000;
-                    i++;
+                    ++it;
                     allStopped = false;
                     continue;
 
@@ -8566,8 +8532,8 @@ reacquire_wakelock:
                 case IAfTrackBase::PAUSED:  // cannot be on ActiveTracks if paused
                 case IAfTrackBase::STOPPED: // cannot be on ActiveTracks if destroyed/terminated
                 default:
-                    LOG_ALWAYS_FATAL("%s: Unexpected active track state:%d, id:%d, tracks:%zu",
-                            __func__, activeTrackState, activeTrack->id(), size);
+                    LOG_ALWAYS_FATAL("%s: Unexpected active track state:%d, id:%d",
+                            __func__, activeTrackState, activeTrack->id());
                 }
 
                 if (activeTrack->isFastTrack()) {
@@ -8580,7 +8546,7 @@ reacquire_wakelock:
                     //    be invalidated again until unsilenced
                     bool invalidate = false;
                     if (activeTrack->isSilenced()) {
-                        if (size > 1) {
+                        if (mActiveTracks.size() > 1) {
                             invalidate = true;
                         } else {
                             silenceFastCapture = true;
@@ -8596,16 +8562,14 @@ reacquire_wakelock:
                         activeTrack->invalidate();
                         fastTrackToRemove = activeTrack;
                         removeTrack_l(activeTrack);
-                        mActiveTracks.remove(activeTrack);
-                        size--;
+                        it = mActiveTracks.erase(it);
                         continue;
                     }
                     fastTrack = activeTrack;
                 }
 
                 activeTracks.add(activeTrack);
-                i++;
-
+                ++it;
             }
 
             mActiveTracks.updatePowerState_l(this);
@@ -8955,8 +8919,12 @@ reacquire_wakelock:
                         // Sanitize before releasing if the track has no access to the source data
                         // An idle UID receives silence from non virtual devices until active
                         if (activeTrack->isSilenced()) {
-                            memset(activeTrack->sinkBuffer().raw,
-                                    0, framesOut * activeTrack->frameSize());
+                            if (type() == IAfThreadBase::DIRECT_RECORD && mIsHwSilenced) {
+                                // do not silence
+                            } else {
+                                memset(activeTrack->sinkBuffer().raw, 0,
+                                       framesOut * activeTrack->frameSize());
+                            }
                         }
                         activeTrack->releaseBuffer(&activeTrack->sinkBuffer());
                     }
@@ -9022,8 +8990,7 @@ unlock:
 
     {
         audio_utils::lock_guard _l(mutex());
-        for (size_t i = 0; i < mTracks.size(); i++) {
-            sp<IAfRecordTrack> track = mTracks[i];
+        for (const auto& track : mTracks) {
             track->invalidate();
         }
         mActiveTracks.clear();
@@ -9331,7 +9298,7 @@ status_t RecordThread::start(IAfRecordTrack* recordTrack,
             ALOGW("%s track %d: invalidated before startInput", __func__, recordTrack->portId());
             return DEAD_OBJECT;
         }
-        if (mActiveTracks.indexOf(recordTrack) >= 0) {
+        if (mActiveTracks.count(recordTrack) > 0) {
             if (recordTrack->state() == IAfTrackBase::PAUSING) {
                 // We haven't stopped yet (moved to PAUSED and not in mActiveTracks)
                 // so no need to startInput().
@@ -9419,8 +9386,16 @@ void RecordThread::syncStartEventCallback(const wp<SyncEvent>& event)
 bool RecordThread::stop(IAfRecordTrack* recordTrack) {
     ALOGV("RecordThread::stop");
     audio_utils::unique_lock _l(mutex());
+    // A case where destroy is handled first followed by stop before track is
+    // removed from active tracks. While destroy removes record track from
+    // mTracks, threadloop removes it from mActiveTracks.
+    if (recordTrack->isTerminated()) {
+        ALOGW("%s(%d): unsychronized stop. Destroy track executed prior to stop",
+                __func__, recordTrack->id());
+        return false;
+    }
     // if we're invalid, we can't be on the ActiveTracks.
-    if (mActiveTracks.indexOf(recordTrack) < 0 || recordTrack->state() == IAfTrackBase::PAUSING) {
+    if (mActiveTracks.count(recordTrack) == 0 || recordTrack->state() == IAfTrackBase::PAUSING) {
         return false;
     }
     // note that threadLoop may still be processing the track at this point [without lock]
@@ -9439,7 +9414,7 @@ bool RecordThread::stop(IAfRecordTrack* recordTrack) {
     }
 
     // don't handle anything - we've been invalidated or restarted and in a different state
-    ALOGW_IF("%s(%d): unsynchronized stop, state: %d",
+    ALOGW("%s(%d): unsynchronized stop, state: %d",
             __func__, recordTrack->id(), recordTrack->state());
     return false;
 }
@@ -9479,7 +9454,7 @@ status_t RecordThread::getActiveMicrophones(
 {
     ALOGV("RecordThread::getActiveMicrophones");
      audio_utils::lock_guard _l(mutex());
-    if (!isStreamInitialized()) {
+    if (!isStreamInitialized_l()) {
         return NO_INIT;
     }
     status_t status = mInput->stream->getActiveMicrophones(activeMicrophones);
@@ -9491,7 +9466,7 @@ status_t RecordThread::setPreferredMicrophoneDirection(
 {
     ALOGV("setPreferredMicrophoneDirection(%d)", direction);
      audio_utils::lock_guard _l(mutex());
-    if (!isStreamInitialized()) {
+    if (!isStreamInitialized_l()) {
         return NO_INIT;
     }
     return mInput->stream->setPreferredMicrophoneDirection(direction);
@@ -9501,7 +9476,7 @@ status_t RecordThread::setPreferredMicrophoneFieldDimension(float zoom)
 {
     ALOGV("setPreferredMicrophoneFieldDimension(%f)", zoom);
      audio_utils::lock_guard _l(mutex());
-    if (!isStreamInitialized()) {
+    if (!isStreamInitialized_l()) {
         return NO_INIT;
     }
     return mInput->stream->setPreferredMicrophoneFieldDimension(zoom);
@@ -9562,12 +9537,12 @@ void RecordThread::resetAudioHistory_l() {
 
 ThreadBase::MetadataUpdate RecordThread::updateMetadata_l()
 {
-    if (!isStreamInitialized() || !mActiveTracks.readAndClearHasChanged()) {
+    if (!isStreamInitialized_l() || !mActiveTracks.readAndClearHasChanged()) {
         return {}; // nothing to do
     }
     StreamInHalInterface::SinkMetadata metadata;
     auto backInserter = std::back_inserter(metadata.tracks);
-    for (const sp<IAfRecordTrack>& track : mActiveTracks) {
+    for (const auto& track : mActiveRecordTracksView) {
         track->copyMetadataTo(backInserter);
     }
     mInput->stream->updateSinkMetadata(metadata);
@@ -9583,7 +9558,7 @@ void RecordThread::destroyTrack_l(const sp<IAfRecordTrack>& track)
     track->setState(IAfTrackBase::STOPPED);
 
     // active tracks are removed by threadLoop()
-    if (mActiveTracks.indexOf(track) < 0) {
+    if (mActiveTracks.count(track) == 0) {
         removeTrack_l(track);
     }
 }
@@ -9609,7 +9584,7 @@ void RecordThread::dumpInternals_l(int fd, const Vector<String16>& /* args */)
     dprintf(fd, "  AudioStreamIn: %p flags %#x (%s)\n",
             input, flags, toString(flags).c_str());
     dprintf(fd, "  Frames read: %lld\n", (long long)mFramesRead);
-    if (mActiveTracks.isEmpty()) {
+    if (mActiveTracks.empty()) {
         dprintf(fd, "  No active record clients\n");
     }
 
@@ -9620,6 +9595,7 @@ void RecordThread::dumpInternals_l(int fd, const Vector<String16>& /* args */)
 
     dprintf(fd, "  Fast capture thread: %s\n", hasFastCapture() ? "yes" : "no");
     dprintf(fd, "  Fast track available: %s\n", mFastTrackAvail ? "yes" : "no");
+    dprintf(fd, "  Hw silenced: %s\n", mIsHwSilenced ? "yes" : "no");
 
     // Make a non-atomic copy of fast capture dump state so it won't change underneath us
     // while we are dumping it.  It may be inconsistent, but it won't mutate!
@@ -9641,11 +9617,10 @@ void RecordThread::dumpTracks_l(int fd, const Vector<String16>& /* args */)
     if (numtracks) {
         dprintf(fd, " of which %zu are active\n", numactive);
         result.append(prefix);
-        mTracks[0]->appendDumpHeader(result);
-        for (size_t i = 0; i < numtracks ; ++i) {
-            sp<IAfRecordTrack> track = mTracks[i];
+        (*mTracks.begin())->appendDumpHeader(result);
+        for (const auto& track : mTracks) {
             if (track != 0) {
-                bool active = mActiveTracks.indexOf(track) >= 0;
+                bool active = mActiveTracks.count(track) > 0;
                 if (active) {
                     numactiveseen++;
                 }
@@ -9661,10 +9636,9 @@ void RecordThread::dumpTracks_l(int fd, const Vector<String16>& /* args */)
         result.append("  The following tracks are in the active list but"
                 " not in the track list\n");
         result.append(prefix);
-        mActiveTracks[0]->appendDumpHeader(result);
-        for (size_t i = 0; i < numactive; ++i) {
-            sp<IAfRecordTrack> track = mActiveTracks[i];
-            if (mTracks.indexOf(track) < 0) {
+        (*mActiveTracks.begin())->appendDumpHeader(result);
+        for (const auto& track : mActiveRecordTracksView) {
+            if (mTracks.count(track) == 0) {
                 result.append(prefix);
                 track->appendDump(result, true /* active */);
             }
@@ -9677,8 +9651,13 @@ void RecordThread::dumpTracks_l(int fd, const Vector<String16>& /* args */)
 void RecordThread::setRecordSilenced(audio_port_handle_t portId, bool silenced)
 {
     audio_utils::lock_guard _l(mutex());
-    for (size_t i = 0; i < mTracks.size() ; i++) {
-        sp<IAfRecordTrack> track = mTracks[i];
+
+    if (type() == IAfThreadBase::DIRECT_RECORD && mIsHwSilenced != silenced) {
+        auto status = mInput->stream->setGain(silenced ? 0.0f : 1.0f);
+        mIsHwSilenced = silenced && status == NO_ERROR;
+    }
+
+    for (const auto& track : mRecordTracksView) {
         if (track != 0 && track->portId() == portId) {
             track->setSilenced(silenced);
         }
@@ -9923,7 +9902,7 @@ bool RecordThread::checkForNewParameter_l(const String8& keyValuePair,
 String8 RecordThread::getParameters(const String8& keys)
 {
     audio_utils::lock_guard _l(mutex());
-    if (initCheck() == NO_ERROR) {
+    if (initCheck_l() == NO_ERROR) {
         String8 out_s8;
         if (mInput->stream->getParameters(keys, &out_s8) == OK) {
             return out_s8;
@@ -9950,7 +9929,7 @@ void RecordThread::ioConfigChanged_l(audio_io_config_event_t event, pid_t pid,
         desc = sp<AudioIoDescriptor>::make(mId);
         break;
     }
-    mAfThreadCallback->ioConfigChanged_l(event, desc, pid);
+    mAfThreadCallback->ioConfigChanged(event, desc, pid);
 }
 
 void RecordThread::readInputParameters_l()
@@ -10013,7 +9992,7 @@ uint32_t RecordThread::getInputFramesLost() const
 {
     audio_utils::lock_guard _l(mutex());
     uint32_t result;
-    if (initCheck() == NO_ERROR && mInput->stream->getInputFramesLost(&result) == OK) {
+    if (initCheck_l() == NO_ERROR && mInput->stream->getInputFramesLost(&result) == OK) {
         return result;
     }
     return 0;
@@ -10023,8 +10002,7 @@ KeyedVector<audio_session_t, bool> RecordThread::sessionIds() const
 {
     KeyedVector<audio_session_t, bool> ids;
     audio_utils::lock_guard _l(mutex());
-    for (size_t j = 0; j < mTracks.size(); ++j) {
-        sp<IAfRecordTrack> track = mTracks[j];
+    for (const auto& track : mTracks) {
         audio_session_t sessionId = track->sessionId();
         if (ids.indexOfKey(sessionId) < 0) {
             ids.add(sessionId, true);
@@ -10033,11 +10011,9 @@ KeyedVector<audio_session_t, bool> RecordThread::sessionIds() const
     return ids;
 }
 
-AudioStreamIn* RecordThread::clearInput()
+AudioStreamIn* RecordThread::clearInput_l()
 {
-    audio_utils::lock_guard _l(mutex());
-    AudioStreamIn *input = mInput;
-    mInput = NULL;
+    AudioStreamIn* input = ThreadBase::clearInput_l();
     mInputSource.clear();
     return input;
 }
@@ -10175,8 +10151,8 @@ int32_t RecordThread::getOldestFront_l()
     }
     int32_t oldestFront = mRsmpInRear;
     int32_t maxFilled = 0;
-    for (size_t i = 0; i < mTracks.size(); i++) {
-        int32_t front = mTracks[i]->resamplerBufferProvider()->getFront();
+    for (const auto& track : mRecordTracksView) {
+        int32_t front = track->resamplerBufferProvider()->getFront();
         int32_t filled;
         (void)__builtin_sub_overflow(mRsmpInRear, front, &filled);
         if (filled > maxFilled) {
@@ -10195,10 +10171,10 @@ void RecordThread::updateFronts_l(int32_t offset)
     if (offset == 0) {
         return;
     }
-    for (size_t i = 0; i < mTracks.size(); i++) {
-        int32_t front = mTracks[i]->resamplerBufferProvider()->getFront();
+    for (const auto& track : mRecordTracksView) {
+        int32_t front = track->resamplerBufferProvider()->getFront();
         front = audio_utils::safe_sub_overflow(front, offset);
-        mTracks[i]->resamplerBufferProvider()->setFront(front);
+        track->resamplerBufferProvider()->setFront(front);
     }
 }
 
@@ -10416,12 +10392,13 @@ status_t MmapThreadHandle::reportData(const void* buffer, size_t frameCount)
 
 MmapThread::MmapThread(
         const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
-        AudioHwDevice *hwDev, const sp<StreamHalInterface>& stream, bool systemReady, bool isOut)
-    : ThreadBase(afThreadCallback, id, (isOut ? MMAP_PLAYBACK : MMAP_CAPTURE), systemReady, isOut),
+        AudioHwDevice *hwDev, const sp<StreamHalInterface>& stream, bool systemReady, bool isOut,
+        AudioStreamIn* input, AudioStreamOut* output)
+    : ThreadBase(afThreadCallback, id, (isOut ? MMAP_PLAYBACK : MMAP_CAPTURE), systemReady,
+              isOut, input, output),
       mSessionId(AUDIO_SESSION_NONE),
       mPortId(AUDIO_PORT_HANDLE_NONE),
       mHalStream(stream), mHalDevice(hwDev->hwDevice()), mAudioHwDev(hwDev),
-      mActiveTracks(&this->mLocalLog),
       mHalVolFloat(-1.0f), // Initialize to illegal value so it always gets set properly later.
       mNoCallbackWarningCount(0)
 {
@@ -10436,18 +10413,18 @@ void MmapThread::onFirstRef()
 
 void MmapThread::disconnect()
 {
-    ActiveTracks<IAfMmapTrack> activeTracks;
+    ActiveTracks activeTracks;
     audio_port_handle_t localPortId;
     {
         audio_utils::lock_guard _l(mutex());
-        for (const sp<IAfMmapTrack>& t : mActiveTracks) {
+        for (const auto& t : mActiveTracks) {
             activeTracks.add(t);
         }
         localPortId = mPortId;
         ALOGD("%s: localPortId = %d", __func__, localPortId);
         mPortId = AUDIO_PORT_HANDLE_NONE;
     }
-    for (const sp<IAfMmapTrack>& t : activeTracks) {
+    for (const auto& t : activeTracks) {
         ALOGD("%s: t->portId() = %d", __func__, t->portId());
         stop(t->portId());
     }
@@ -10496,6 +10473,12 @@ status_t MmapThread::getMmapPosition(struct audio_mmap_position* position) const
 
 status_t MmapThread::exitStandby_l()
 {
+    if (mType == MMAP_CAPTURE) {
+        // mInput might have been cleared by clearInput()
+        if (mInput != nullptr && mInput->stream != nullptr) {
+            mInput->stream->setGain(1.0f);
+        }
+    }
     // The HAL must receive track metadata before starting the stream
     updateMetadata_l();
     status_t ret = mHalStream->start();
@@ -10553,8 +10536,7 @@ status_t MmapThread::start(const AudioClient& client,
 
     const auto localSessionId = mSessionId;
     auto localAttr = mAttr;
-    float volume = 0.0f;
-    bool muted = false;
+
     if (isOutput()) {
         audio_config_t config = AUDIO_CONFIG_INITIALIZER;
         config.sample_rate = mSampleRate;
@@ -10563,6 +10545,10 @@ status_t MmapThread::start(const AudioClient& client,
         audio_stream_type_t stream = streamType_l();
         audio_output_flags_t flags =
                 (audio_output_flags_t)(AUDIO_OUTPUT_FLAG_MMAP_NOIRQ | AUDIO_OUTPUT_FLAG_DIRECT);
+        if (auto offloadInfo = offloadInfo_l(); offloadInfo.has_value()) {
+            flags = (audio_output_flags_t)(flags | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD);
+            config.offload_info = offloadInfo.value();
+        }
         DeviceIdVector deviceIds = mDeviceIds;
         std::vector<audio_io_handle_t> secondaryOutputs;
         bool isSpatialized;
@@ -10578,9 +10564,7 @@ status_t MmapThread::start(const AudioClient& client,
                                             &portId,
                                             &secondaryOutputs,
                                             &isSpatialized,
-                                            &isBitPerfect,
-                                            &volume,
-                                            &muted);
+                                            &isBitPerfect);
         mutex().lock();
         mAttr = localAttr;
         ALOGD_IF(!secondaryOutputs.empty(),
@@ -10614,9 +10598,11 @@ status_t MmapThread::start(const AudioClient& client,
         return BAD_VALUE;
     }
 
+    float volume{};
+    bool muted{};
     if (isOutput()) {
         mutex().unlock();
-        ret = AudioSystem::startOutput(portId);
+        ret = AudioSystem::startOutput(portId, &volume, &muted);
         mutex().lock();
     } else {
         {
@@ -10632,7 +10618,7 @@ status_t MmapThread::start(const AudioClient& client,
     // abort if start is rejected by audio policy manager
     if (ret != NO_ERROR) {
         ALOGE("%s: error start rejected by AudioPolicyManager = %d", __FUNCTION__, ret);
-        if (!mActiveTracks.isEmpty()) {
+        if (!mActiveTracks.empty()) {
             mutex().unlock();
             if (isOutput()) {
                 AudioSystem::releaseOutput(portId);
@@ -10648,13 +10634,16 @@ status_t MmapThread::start(const AudioClient& client,
     }
 
     // Given that MmapThread::mAttr is mutable, should a MmapTrack have attributes ?
-    sp<IAfMmapTrack> track = IAfMmapTrack::create(
+    const auto track = IAfMmapTrack::create(
             this, attr == nullptr ? mAttr : *attr, mSampleRate, mFormat,
                                         mChannelMask, mSessionId, isOutput(),
                                         adjAttributionSource,
-                                        IPCThreadState::self()->getCallingPid(), portId,
-                                        volume, muted);
+                                        IPCThreadState::self()->getCallingPid(), portId);
 
+    if (isOutput()) {
+        track->setPortVolume(volume);
+        track->setPortMute(muted);
+    }
     // MMAP tracks are only created when they are started, so mark them as Start for the purposes
     // of the IAfTrackBase interface
     track->start();
@@ -10666,14 +10655,14 @@ status_t MmapThread::start(const AudioClient& client,
         // force volume update when a new track is added
         mHalVolFloat = -1.0f;
     } else if (!track->isSilenced_l()) {
-        for (const sp<IAfMmapTrack>& t : mActiveTracks) {
+        for (const auto& t : mActiveMmapTracksView) {
             if (t->isSilenced_l()
                     && t->uid() != static_cast<uid_t>(adjAttributionSource.uid)) {
                 t->invalidate();
             }
         }
     }
-
+    mTracks.add(track);
     mActiveTracks.add(track);
     sp<IAfEffectChain> chain = getEffectChain_l(mSessionId);
     if (chain != 0) {
@@ -10701,7 +10690,7 @@ status_t MmapThread::start(const AudioClient& client,
 status_t MmapThread::stop(audio_port_handle_t handle)
 {
     ALOGV("%s handle %d", __FUNCTION__, handle);
-    audio_utils::lock_guard l(mutex());
+    audio_utils::unique_lock l {mutex()};
 
     if (mHalStream == 0) {
         return NO_INIT;
@@ -10712,8 +10701,8 @@ status_t MmapThread::stop(audio_port_handle_t handle)
         return NO_ERROR;
     }
 
-    sp<IAfMmapTrack> track;
-    for (const sp<IAfMmapTrack>& t : mActiveTracks) {
+    sp<IAfTrackBase> track;
+    for (const auto& t : mActiveTracks) {
         if (handle == t->portId()) {
             track = t;
             break;
@@ -10724,10 +10713,11 @@ status_t MmapThread::stop(audio_port_handle_t handle)
     }
 
     mActiveTracks.remove(track);
+    mTracks.remove(track);
     eraseClientSilencedState_l(track->portId());
     track->stop();
 
-    mutex().unlock();
+    l.unlock();
     if (isOutput()) {
         AudioSystem::stopOutput(track->portId());
         AudioSystem::releaseOutput(track->portId());
@@ -10735,7 +10725,7 @@ status_t MmapThread::stop(audio_port_handle_t handle)
         AudioSystem::stopInput(track->portId());
         AudioSystem::releaseInput(track->portId());
     }
-    mutex().lock();
+    l.lock();
 
     sp<IAfEffectChain> chain = getEffectChain_l(track->sessionId());
     if (chain != 0) {
@@ -10743,12 +10733,14 @@ status_t MmapThread::stop(audio_port_handle_t handle)
         chain->decTrackCnt();
     }
 
-    if (mActiveTracks.isEmpty()) {
+    if (mActiveTracks.empty()) {
         mHalStream->stop();
     }
 
     broadcast_l();
 
+    // unlock before running track dtor to prevent join deadlock
+    l.unlock();
     return NO_ERROR;
 }
 
@@ -10761,7 +10753,7 @@ NO_THREAD_SAFETY_ANALYSIS  // clang bug
     if (mHalStream == 0) {
         return NO_INIT;
     }
-    if (!mActiveTracks.isEmpty()) {
+    if (!mActiveTracks.empty()) {
         return INVALID_OPERATION;
     }
     mHalStream->standby();
@@ -10817,10 +10809,6 @@ void MmapThread::readHalParameters_l()
 
 bool MmapThread::threadLoop()
 {
-    {
-        audio_utils::unique_lock _l(mutex());
-        checkSilentMode_l();
-    }
 
     const String8 myName(String8::format("thread %p type %d TID %d", this, mType, gettid()));
 
@@ -10848,7 +10836,6 @@ bool MmapThread::threadLoop()
                 mWaitWorkCV.wait(_l);
                 ALOGV("%s waking up", myName.c_str());
 
-                checkSilentMode_l();
 
                 continue;
             }
@@ -10914,7 +10901,7 @@ String8 MmapThread::getParameters(const String8& keys)
 {
     audio_utils::lock_guard _l(mutex());
     String8 out_s8;
-    if (initCheck() == NO_ERROR && mHalStream->getParameters(keys, &out_s8) == OK) {
+    if (initCheck_l() == NO_ERROR && mHalStream->getParameters(keys, &out_s8) == OK) {
         return out_s8;
     }
     return {};
@@ -10942,7 +10929,7 @@ void MmapThread::ioConfigChanged_l(audio_io_config_event_t event, pid_t pid,
         desc = sp<AudioIoDescriptor>::make(mId);
         break;
     }
-    mAfThreadCallback->ioConfigChanged_l(event, desc, pid);
+    mAfThreadCallback->ioConfigChanged(event, desc, pid);
 }
 
 status_t MmapThread::createAudioPatch_l(const struct audio_patch* patch,
@@ -11026,7 +11013,6 @@ NO_THREAD_SAFETY_ANALYSIS  // elease and re-acquire mutex()
         if (isOutput()) {
             sendIoConfigEvent_l(AUDIO_OUTPUT_CONFIG_CHANGED);
             mOutDeviceTypeAddrs = sinkDeviceTypeAddrs;
-            checkSilentMode_l();
         } else {
             sendIoConfigEvent_l(AUDIO_INPUT_CONFIG_CHANGED);
             mInDeviceTypeAddr = sourceDeviceTypeAddr;
@@ -11094,7 +11080,7 @@ status_t MmapThread::addEffectChain_l(const sp<IAfEffectChain>& chain)
     ALOGV("addEffectChain_l() %p on thread %p for session %d", chain.get(), this, session);
     // Attach all tracks with same session ID to this chain.
     // indicate all active tracks in the chain
-    for (const sp<IAfMmapTrack>& track : mActiveTracks) {
+    for (const auto& track : mActiveTracks) {
         if (session == track->sessionId()) {
             chain->incTrackCnt();
             chain->incActiveTrackCnt();
@@ -11122,7 +11108,7 @@ size_t MmapThread::removeEffectChain_l(const sp<IAfEffectChain>& chain)
             mEffectChains.removeAt(i);
             // detach all active tracks from the chain
             // detach all tracks with same session ID from this chain
-            for (const sp<IAfMmapTrack>& track : mActiveTracks) {
+            for (const auto& track : mActiveTracks) {
                 if (session == track->sessionId()) {
                     chain->decActiveTrackCnt();
                     chain->decTrackCnt();
@@ -11141,8 +11127,22 @@ void MmapThread::threadLoop_standby()
 
 void MmapThread::threadLoop_exit()
 {
-    // Do not call callback->onTearDown() because it is redundant for thread exit
-    // and because it can cause a recursive mutex lock on stop().
+    sp<MmapStreamCallback> callback;
+    std::vector<audio_port_handle_t> portIds;
+    {
+        audio_utils::lock_guard _l(mutex());
+        callback = mCallback.promote();
+        if (callback == nullptr) {
+            return;
+        }
+        for (const auto& track: mActiveTracks) {
+            portIds.push_back(track->portId());
+        }
+    }
+    for (auto portId : portIds) {
+        // It is safe to call tear down here as it is handled asynchronously.
+        callback->onTearDown(portId);
+    }
 }
 
 status_t MmapThread::setSyncEvent(const sp<SyncEvent>& /* event */)
@@ -11192,7 +11192,7 @@ status_t MmapThread::checkEffectCompatibility_l(
 
 void MmapThread::checkInvalidTracks_l()
 {
-    for (const sp<IAfMmapTrack>& track : mActiveTracks) {
+    for (const auto& track : mActiveTracks) {
         if (track->isInvalid()) {
             if (const sp<MmapStreamCallback> callback = mCallback.promote()) {
                 // The aaudioservice handle the routing changed event asynchronously. In that case,
@@ -11212,7 +11212,7 @@ void MmapThread::dumpInternals_l(int fd, const Vector<String16>& /* args */)
     dprintf(fd, "  Attributes: content type %d usage %d source %d\n",
             mAttr.content_type, mAttr.usage, mAttr.source);
     dprintf(fd, "  Session: %d port Id: %d\n", mSessionId, mPortId);
-    if (mActiveTracks.isEmpty()) {
+    if (mActiveTracks.empty()) {
         dprintf(fd, "  No active clients\n");
     }
 }
@@ -11225,9 +11225,8 @@ void MmapThread::dumpTracks_l(int fd, const Vector<String16>& /* args */)
     const char *prefix = "    ";
     if (numtracks) {
         result.append(prefix);
-        mActiveTracks[0]->appendDumpHeader(result);
-        for (size_t i = 0; i < numtracks ; ++i) {
-            sp<IAfMmapTrack> track = mActiveTracks[i];
+        (*mActiveTracks.begin())->appendDumpHeader(result);
+        for (const auto& track : mActiveTracks) {
             result.append(prefix);
             track->appendDump(result, true /* active */);
         }
@@ -11245,7 +11244,7 @@ std::string MmapThread::getLocalLogHeader() const {
 }
 
 /* static */
-sp<IAfMmapPlaybackThread> IAfMmapPlaybackThread::create(
+sp<IAfMmapThread> IAfMmapThread::create(
         const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
         AudioHwDevice* hwDev,  AudioStreamOut* output, bool systemReady) {
     return sp<MmapPlaybackThread>::make(afThreadCallback, id, hwDev, output, systemReady);
@@ -11254,9 +11253,9 @@ sp<IAfMmapPlaybackThread> IAfMmapPlaybackThread::create(
 MmapPlaybackThread::MmapPlaybackThread(
         const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
         AudioHwDevice *hwDev,  AudioStreamOut *output, bool systemReady)
-    : MmapThread(afThreadCallback, id, hwDev, output->stream, systemReady, true /* isOut */),
-      mStreamType(AUDIO_STREAM_MUSIC),
-      mOutput(output)
+    : MmapThread(afThreadCallback, id, hwDev, output->stream, systemReady, true /* isOut */,
+            nullptr /* input */, output),
+      mStreamType(AUDIO_STREAM_MUSIC)
 {
     snprintf(mThreadName, kThreadNameLength, "AudioMmapOut_%X", id);
     mFlagsAsString = toString(output->flags);
@@ -11287,23 +11286,21 @@ MmapPlaybackThread::MmapPlaybackThread(
 }
 
 void MmapPlaybackThread::configure(const audio_attributes_t* attr,
-                                                audio_stream_type_t streamType,
-                                                audio_session_t sessionId,
-                                                const sp<MmapStreamCallback>& callback,
-                                                const DeviceIdVector& deviceIds,
-                                                audio_port_handle_t portId)
+                                   audio_stream_type_t streamType,
+                                   audio_session_t sessionId,
+                                   const sp<MmapStreamCallback>& callback,
+                                   const DeviceIdVector& deviceIds,
+                                   audio_port_handle_t portId,
+                                   const audio_offload_info_t* offloadInfo)
 {
     audio_utils::lock_guard l(mutex());
     MmapThread::configure_l(attr, streamType, sessionId, callback, deviceIds, portId);
     mStreamType = streamType;
-}
-
-AudioStreamOut* MmapPlaybackThread::clearOutput()
-{
-    audio_utils::lock_guard _l(mutex());
-    AudioStreamOut *output = mOutput;
-    mOutput = NULL;
-    return output;
+    if (offloadInfo != nullptr) {
+        mOffloadInfo = *offloadInfo;
+    } else {
+        mOffloadInfo = std::nullopt;
+    }
 }
 
 void MmapPlaybackThread::setMasterVolume(float value)
@@ -11357,61 +11354,6 @@ void MmapPlaybackThread::setStreamMute(audio_stream_type_t stream, bool muted)
     }
 }
 
-status_t MmapPlaybackThread::setPortsVolume(
-        const std::vector<audio_port_handle_t>& portIds, float volume, bool muted) {
-    audio_utils::lock_guard _l(mutex());
-    for (const auto& portId : portIds) {
-        for (const sp<IAfMmapTrack>& track : mActiveTracks) {
-            if (portId == track->portId()) {
-                track->setPortVolume(volume);
-                track->setPortMute(muted);
-                break;
-            }
-        }
-    }
-    broadcast_l();
-    return NO_ERROR;
-}
-
-void MmapPlaybackThread::checkUpdateTrackMetadataForUid(uid_t uid) {
-    audio_utils::lock_guard _l(mutex());
-    for (const sp<IAfMmapTrack>& track : mActiveTracks) {
-        if (track->uid() == uid) {
-            track->setMetadataHasChanged();
-        }
-    }
-}
-
-void MmapPlaybackThread::invalidateTracks(audio_stream_type_t streamType)
-{
-    audio_utils::lock_guard _l(mutex());
-    if (streamType == mStreamType) {
-        for (const sp<IAfMmapTrack>& track : mActiveTracks) {
-            track->invalidate();
-        }
-        broadcast_l();
-    }
-}
-
-void MmapPlaybackThread::invalidateTracks(std::set<audio_port_handle_t>& portIds)
-{
-    audio_utils::lock_guard _l(mutex());
-    bool trackMatch = false;
-    for (const sp<IAfMmapTrack>& track : mActiveTracks) {
-        if (portIds.find(track->portId()) != portIds.end()) {
-            track->invalidate();
-            trackMatch = true;
-            portIds.erase(track->portId());
-        }
-        if (portIds.empty()) {
-            break;
-        }
-    }
-    if (trackMatch) {
-        broadcast_l();
-    }
-}
-
 void MmapPlaybackThread::processVolume_l()
 NO_THREAD_SAFETY_ANALYSIS // access of track->processMuteEvent
 {
@@ -11431,17 +11373,18 @@ NO_THREAD_SAFETY_ANALYSIS // access of track->processMuteEvent
             // will be broadcasted to all tracks. Thus, take arbitrarily first track volume.
             size_t numtracks = mActiveTracks.size();
             if (numtracks) {
-                if (mActiveTracks[0]->getPortMute()) {
+                const auto track = (*mActiveTracks.begin())->asIAfMmapTrack();
+                if (track->getPortMute()) {
                     volume = 0;
                 } else {
-                    volume = mMasterVolume * mActiveTracks[0]->getPortVolume();
+                    volume = mMasterVolume * track->getPortVolume();
                 }
             }
         }
     }
 
     bool shouldMutePlaybackHardening = std::all_of(mActiveTracks.begin(), mActiveTracks.end(),
-            [](const auto& x) { return x->isPlaybackRestrictedControl(); });
+            [](const auto& x) { return x->asIAfMmapTrack()->isPlaybackRestrictedControl(); });
     if (shouldMutePlaybackHardening) {
         volume = 0;
     }
@@ -11477,7 +11420,7 @@ NO_THREAD_SAFETY_ANALYSIS // access of track->processMuteEvent
             }
         }
         const auto amn = mAfThreadCallback->getAudioManagerNative();
-        for (const sp<IAfMmapTrack>& track : mActiveTracks) {
+        for (const auto& track : mActiveMmapTracksView) {
             track->setMetadataHasChanged();
             if (amn) {
                 if (!audioserver_flags::portid_volume_management()) {
@@ -11511,11 +11454,11 @@ NO_THREAD_SAFETY_ANALYSIS // access of track->processMuteEvent
 
 ThreadBase::MetadataUpdate MmapPlaybackThread::updateMetadata_l()
 {
-    if (!isStreamInitialized() || !mActiveTracks.readAndClearHasChanged()) {
+    if (!isStreamInitialized_l() || !mActiveTracks.readAndClearHasChanged()) {
         return {}; // nothing to do
     }
     StreamOutHalInterface::SourceMetadata metadata;
-    for (const sp<IAfMmapTrack>& track : mActiveTracks) {
+    for (const auto& track : mActiveTracks) {
         // No track is invalid as this is called after prepareTrack_l in the same critical section
         playback_track_metadata_v7_t trackMetadata;
         trackMetadata.base = {
@@ -11547,13 +11490,6 @@ ThreadBase::MetadataUpdate MmapPlaybackThread::updateMetadata_l()
     return change;
 };
 
-void MmapPlaybackThread::checkSilentMode_l()
-{
-    if (property_get_bool("ro.audio.silent", false)) {
-        ALOGW("ro.audio.silent is now ignored");
-    }
-}
-
 void MmapPlaybackThread::toAudioPortConfig(struct audio_port_config* config)
 {
     MmapThread::toAudioPortConfig(config);
@@ -11625,7 +11561,7 @@ void MmapPlaybackThread::dumpInternals_l(int fd, const Vector<String16>& args)
 }
 
 /* static */
-sp<IAfMmapCaptureThread> IAfMmapCaptureThread::create(
+sp<IAfMmapThread> IAfMmapThread::create(
         const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
         AudioHwDevice* hwDev,  AudioStreamIn* input, bool systemReady) {
     return sp<MmapCaptureThread>::make(afThreadCallback, id, hwDev, input, systemReady);
@@ -11634,33 +11570,13 @@ sp<IAfMmapCaptureThread> IAfMmapCaptureThread::create(
 MmapCaptureThread::MmapCaptureThread(
         const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
         AudioHwDevice *hwDev,  AudioStreamIn *input, bool systemReady)
-    : MmapThread(afThreadCallback, id, hwDev, input->stream, systemReady, false /* isOut */),
-      mInput(input)
-{
+    : MmapThread(afThreadCallback, id, hwDev, input->stream, systemReady, false /* isOut */,
+            input, nullptr /* output */) {
     snprintf(mThreadName, kThreadNameLength, "AudioMmapIn_%X", id);
     mFlagsAsString = toString(input->flags);
     mChannelCount = audio_channel_count_from_in_mask(mChannelMask);
 }
 
-status_t MmapCaptureThread::exitStandby_l()
-{
-    {
-        // mInput might have been cleared by clearInput()
-        if (mInput != nullptr && mInput->stream != nullptr) {
-            mInput->stream->setGain(1.0f);
-        }
-    }
-    return MmapThread::exitStandby_l();
-}
-
-AudioStreamIn* MmapCaptureThread::clearInput()
-{
-    audio_utils::lock_guard _l(mutex());
-    AudioStreamIn *input = mInput;
-    mInput = NULL;
-    return input;
-}
-
 void MmapCaptureThread::processVolume_l()
 {
     bool changed = false;
@@ -11676,10 +11592,11 @@ void MmapCaptureThread::processVolume_l()
 
     // After a change occurred in track silenced state, mute capture in audio DSP if at least one
     // track is silenced and unmute otherwise
-    for (size_t i = 0; i < mActiveTracks.size() && !silenced; i++) {
-        if (!mActiveTracks[i]->getAndSetSilencedNotified_l()) {
+    for (const auto& track : mActiveMmapTracksView) {
+        if (!track->getAndSetSilencedNotified_l()) {
             changed = true;
-            silenced = mActiveTracks[i]->isSilenced_l();
+            silenced = track->isSilenced_l();
+            if (silenced) break;
         }
     }
 
@@ -11690,11 +11607,11 @@ void MmapCaptureThread::processVolume_l()
 
 ThreadBase::MetadataUpdate MmapCaptureThread::updateMetadata_l()
 {
-    if (!isStreamInitialized() || !mActiveTracks.readAndClearHasChanged()) {
+    if (!isStreamInitialized_l() || !mActiveTracks.readAndClearHasChanged()) {
         return {}; // nothing to do
     }
     StreamInHalInterface::SinkMetadata metadata;
-    for (const sp<IAfMmapTrack>& track : mActiveTracks) {
+    for (const auto& track : mActiveTracks) {
         // No track is invalid as this is called after prepareTrack_l in the same critical section
         record_track_metadata_v7_t trackMetadata;
         trackMetadata.base = {
@@ -11714,9 +11631,9 @@ ThreadBase::MetadataUpdate MmapCaptureThread::updateMetadata_l()
 void MmapCaptureThread::setRecordSilenced(audio_port_handle_t portId, bool silenced)
 {
     audio_utils::lock_guard _l(mutex());
-    for (size_t i = 0; i < mActiveTracks.size() ; i++) {
-        if (mActiveTracks[i]->portId() == portId) {
-            mActiveTracks[i]->setSilenced_l(silenced);
+    for (const auto& track : mActiveMmapTracksView) {
+        if (track->portId() == portId) {
+            track->setSilenced_l(silenced);
             broadcast_l();
         }
     }
@@ -11755,7 +11672,7 @@ BitPerfectThread::BitPerfectThread(const sp<IAfThreadCallback> &afThreadCallback
         : MixerThread(afThreadCallback, output, id, systemReady, BIT_PERFECT) {}
 
 PlaybackThread::mixer_state BitPerfectThread::prepareTracks_l(
-        Vector<sp<IAfTrack>>* tracksToRemove) {
+        std::vector<sp<IAfTrackBase>>* tracksToRemove) {
     mixer_state result = MixerThread::prepareTracks_l(tracksToRemove);
     // If there is only one active track and it is bit-perfect, enable tee buffer.
     float volumeLeft = 1.0f;
@@ -11796,7 +11713,7 @@ void BitPerfectThread::threadLoop_mix() {
 void BitPerfectThread::setTracksInternalMute(
         std::map<audio_port_handle_t, bool>* tracksInternalMute) {
     audio_utils::lock_guard _l(mutex());
-    for (auto& track : mTracks) {
+    for (const auto& track : mPlaybackTracksView) {
         if (auto it = tracksInternalMute->find(track->portId()); it != tracksInternalMute->end()) {
             track->setInternalMute(it->second);
             tracksInternalMute->erase(it);
@@ -11805,33 +11722,25 @@ void BitPerfectThread::setTracksInternalMute(
 }
 
 sp<IAfTrack> BitPerfectThread::getTrackToStreamBitPerfectly_l() {
-    if (com::android::media::audioserver::
-                fix_concurrent_playback_behavior_with_bit_perfect_client()) {
-        sp<IAfTrack> bitPerfectTrack = nullptr;
-        bool allOtherTracksMuted = true;
-        // Return the bit perfect track if all other tracks are muted
-        for (const auto& track : mActiveTracks) {
-            if (track->isBitPerfect()) {
-                if (track->getInternalMute()) {
-                    // There can only be one bit-perfect client active. If it is mute internally,
-                    // there is no need to stream bit-perfectly.
-                    break;
-                }
-                bitPerfectTrack = track;
-            } else if (track->getFinalVolume() != 0.f) {
-                allOtherTracksMuted = false;
-                if (bitPerfectTrack != nullptr) {
-                    break;
-                }
+    sp<IAfTrack> bitPerfectTrack = nullptr;
+    bool allOtherTracksMuted = true;
+    // Return the bit perfect track if all other tracks are muted
+    for (const auto& track : mActivePlaybackTracksView) {
+        if (track->isBitPerfect()) {
+            if (track->getInternalMute()) {
+                // There can only be one bit-perfect client active. If it is mute internally,
+                // there is no need to stream bit-perfectly.
+                break;
+            }
+            bitPerfectTrack = track;
+        } else if (track->getFinalVolume() != 0.f) {
+            allOtherTracksMuted = false;
+            if (bitPerfectTrack != nullptr) {
+                break;
             }
-        }
-        return allOtherTracksMuted ? bitPerfectTrack : nullptr;
-    } else {
-        if (mActiveTracks.size() == 1 && mActiveTracks[0]->isBitPerfect()) {
-            return mActiveTracks[0];
         }
     }
-    return nullptr;
+    return allOtherTracksMuted ? bitPerfectTrack : nullptr;
 }
 
 } // namespace android
diff --git a/services/audioflinger/Threads.h b/services/audioflinger/Threads.h
index ddcde5de01..aa6006a1b7 100644
--- a/services/audioflinger/Threads.h
+++ b/services/audioflinger/Threads.h
@@ -54,7 +54,8 @@ public:
     IAfThreadCallback* afThreadCallback() const final { return mAfThreadCallback.get(); }
 
     ThreadBase(const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
-               type_t type, bool systemReady, bool isOut);
+            type_t type, bool systemReady, bool isOut,
+            AudioStreamIn* input, AudioStreamOut* output);
     ~ThreadBase() override;
 
     status_t readyToRun() final;
@@ -480,8 +481,7 @@ public:
                     if (getEffectChain_l(sessionId) != 0) {
                         result = EFFECT_SESSION;
                     }
-                    for (size_t i = 0; i < tracks.size(); ++i) {
-                        const sp<IAfTrackBase>& track = tracks[i];
+                    for (const auto& track : tracks) {
                         if (sessionId == track->sessionId()
                                 && !track->isInvalid()       // not yet removed from tracks.
                                 && !track->isTerminated()) {
@@ -545,7 +545,7 @@ public:
     mutable audio_utils::mutex mMutex{audio_utils::MutexOrder::kThreadBase_Mutex};
 
     void onEffectEnable(const sp<IAfEffectModule>& effect) final EXCLUDES_ThreadBase_Mutex;
-    void onEffectDisable() final EXCLUDES_ThreadBase_Mutex;
+    void onEffectDisable(const sp<IAfEffectModule>& effect) final EXCLUDES_ThreadBase_Mutex;
 
                 // invalidateTracksForAudioSession_l must be called with holding mutex().
     void invalidateTracksForAudioSession_l(audio_session_t /* sessionId */) const override
@@ -560,8 +560,7 @@ public:
                 template <typename T>
     void invalidateTracksForAudioSession_l(audio_session_t sessionId,
             const T& tracks) const REQUIRES(mutex()) {
-                    for (size_t i = 0; i < tracks.size(); ++i) {
-                        const sp<IAfTrackBase>& track = tracks[i];
+                    for (const auto& track : tracks) {
                         if (sessionId == track->sessionId()) {
                             track->invalidate();
                         }
@@ -595,7 +594,7 @@ protected:
     virtual void acquireWakeLock_l() REQUIRES(mutex());
     void releaseWakeLock() EXCLUDES_ThreadBase_Mutex;
     void releaseWakeLock_l() REQUIRES(mutex());
-    void updateWakeLockUids_l(const SortedVector<uid_t> &uids) REQUIRES(mutex());
+    void updateWakeLockUids_l(const std::vector<uid_t>& uids) REQUIRES(mutex());
     void getPowerManager_l() REQUIRES(mutex());
                 // suspend or restore effects of the specified type (or all if type is NULL)
                 // on a given session. The number of suspend requests is counted and restore
@@ -645,7 +644,8 @@ protected:
                     std::vector<playback_track_metadata_v7_t> playbackMetadataUpdate;
                     std::vector<record_track_metadata_v7_t>   recordMetadataUpdate;
                 };
-    // NO_THREAD_SAFETY_ANALYSIS, updateMetadata_l() should include ThreadBase_ThreadLoop
+    // NO_THREAD_SAFETY_ANALYSIS, the ThreadBase::updateMetadata_l()
+    // should include ThreadBase_ThreadLoop
     // but MmapThread::start() -> exitStandby_l() -> updateMetadata_l() prevents this.
     virtual MetadataUpdate updateMetadata_l() REQUIRES(mutex()) = 0;
 
@@ -794,7 +794,6 @@ protected:
                 // This class updates power information appropriately.
                 //
 
-                template <typename T>
                 class ActiveTracks {
                 public:
                     explicit ActiveTracks(SimpleLog *localLog = nullptr)
@@ -804,7 +803,7 @@ protected:
                     { }
 
                     ~ActiveTracks() {
-                        ALOGW_IF(!mActiveTracks.isEmpty(),
+                        ALOGW_IF(!mActiveTracks.empty(),
                                 "ActiveTracks should be empty in destructor");
                     }
                     // returns the last track added (even though it may have been
@@ -818,35 +817,33 @@ protected:
                     // The latest track is saved with a weak pointer to prevent keeping an
                     // otherwise useless track alive. Thus the function will return nullptr
                     // if the latest track has subsequently been removed and destroyed.
-                    sp<T> getLatest() {
+                    sp<IAfTrackBase> getLatest() {
                         return mLatestActiveTrack.promote();
                     }
-
-                    // SortedVector methods
-                    ssize_t         add(const sp<T> &track);
-                    ssize_t         remove(const sp<T> &track);
-                    size_t          size() const {
+                    bool add(const sp<IAfTrackBase>& track);
+                    bool remove(const sp<IAfTrackBase>& track);
+                    size_t size() const {
                         return mActiveTracks.size();
                     }
-                    bool            isEmpty() const {
-                        return mActiveTracks.isEmpty();
+                    bool empty() const {
+                        return mActiveTracks.empty();
                     }
-                    ssize_t indexOf(const sp<T>& item) const {
-                        return mActiveTracks.indexOf(item);
+                    size_t count(const sp<IAfTrackBase>& track) const {
+                        return mActiveTracks.count(track);
                     }
-                    sp<T>           operator[](size_t index) const {
-                        return mActiveTracks[index];
+                    auto erase(const std::set<sp<IAfTrackBase>>::iterator& it) {
+                        return mActiveTracks.erase(it);
                     }
-                    typename SortedVector<sp<T>>::iterator begin() {
+                    auto begin() {
                         return mActiveTracks.begin();
                     }
-                    typename SortedVector<sp<T>>::iterator end() {
+                    auto end() {
                         return mActiveTracks.end();
                     }
-                    typename SortedVector<const sp<T>>::iterator begin() const {
+                    auto begin() const {
                         return mActiveTracks.begin();
                     }
-                    typename SortedVector<const sp<T>>::iterator end() const {
+                    auto end() const {
                         return mActiveTracks.end();
                     }
 
@@ -858,8 +855,9 @@ protected:
                     // ThreadBase thread.
                     void            clear();
                     // periodically called in the threadLoop() to update power state uids.
+                    // TODO(b/410038399) fix thread safety
                     void updatePowerState_l(const sp<ThreadBase>& thread, bool force = false)
-                            REQUIRES(audio_utils::ThreadBase_Mutex);
+                           REQUIRES(audio_utils::ThreadBase_Mutex);
 
                     /** @return true if one or move active tracks was added or removed since the
                      *          last time this function was called or the vector was created.
@@ -873,20 +871,20 @@ protected:
                     void            setHasChanged() { mHasChanged = true; }
 
                 private:
-                    void            logTrack(const char *funcName, const sp<T> &track) const;
+                    void logTrack(const char* funcName, const sp<IAfTrackBase>& track) const;
 
-                    SortedVector<uid_t> getWakeLockUids() {
-                        SortedVector<uid_t> wakeLockUids;
-                        for (const sp<T> &track : mActiveTracks) {
-                            wakeLockUids.add(track->uid());
+                    std::vector<uid_t> getWakeLockUids() {
+                        std::vector<uid_t> wakeLockUids;
+                        for (const auto& track : mActiveTracks) {
+                            wakeLockUids.push_back(track->uid());
                         }
                         return wakeLockUids; // moved by underlying SharedBuffer
                     }
 
-                    SortedVector<sp<T>> mActiveTracks;
+                    std::set<sp<IAfTrackBase>> mActiveTracks;
                     int                 mActiveTracksGeneration;
                     int                 mLastActiveTracksGeneration;
-                    wp<T>               mLatestActiveTrack; // latest track added to ActiveTracks
+                    wp<IAfTrackBase> mLatestActiveTrack; // latest track added to ActiveTracks
                     SimpleLog * const   mLocalLog;
                     // If the vector has changed since last call to readAndClearHasChanged
                     bool                mHasChanged = false;
@@ -894,6 +892,79 @@ protected:
 
                 SimpleLog mLocalLog {/* maxLogLines= */ 120};  // locked internally
 
+    ActiveTracks mActiveTracks GUARDED_BY(mutex()) {&mLocalLog};
+
+        // The Tracks class manages tracks added and removed from the Thread.
+
+    class Tracks {
+    public:
+        explicit Tracks(bool saveDeletedTrackIds) :
+                mSaveDeletedTrackIds(saveDeletedTrackIds) { }
+
+        bool add(const sp<IAfTrackBase>& track) {
+            return mTracks.insert(track).second;  // ignore the iterator.
+        }
+        bool remove(const sp<IAfTrackBase>& track);
+        size_t size() const {
+            return mTracks.size();
+        }
+        bool empty() const {
+            return mTracks.empty();
+        }
+        size_t count(const sp<IAfTrackBase>& track) const {
+            return mTracks.count(track);
+        }
+        auto begin() {
+            return mTracks.begin();
+        }
+        auto end() {
+            return mTracks.end();
+        }
+        auto begin() const {
+            return mTracks.begin();
+        }
+        auto end() const {
+            return mTracks.end();
+        }
+        size_t processDeletedTrackIds(const std::function<void(int)>& f) {
+            for (const int trackId : mDeletedTrackIds) {
+                f(trackId);
+            }
+            return mDeletedTrackIds.size();
+        }
+        void clearDeletedTrackIds() { mDeletedTrackIds.clear(); }
+
+    private:
+        // Tracks pending deletion for MIXER type threads
+        const bool mSaveDeletedTrackIds; // true to enable tracking
+        std::set<int> mDeletedTrackIds;
+        std::set<sp<IAfTrackBase>> mTracks;
+    };
+
+    // TODO(b/410038399) should be any mixer enabled thread.
+    Tracks mTracks{mType == MIXER};
+
+    sp<IAfTrackBase> getTrackById_l(audio_port_handle_t trackId) final REQUIRES(mutex());
+
+    std::vector<sp<IAfTrackBase>> getTracks_l() final REQUIRES(mutex());
+
+    std::set<audio_port_handle_t> getTrackPortIds_l() const REQUIRES(mutex());
+    std::set<audio_port_handle_t> getTrackPortIds() const EXCLUDES_ThreadBase_Mutex;
+
+    // Invalidate tracks by a set of port ids. The port id will be removed from
+    // the given set if the corresponding track is found and invalidated.
+    //
+    // If portIds == nullptr, all tracks, including internal tracks are invalidated.
+    bool invalidateTracks_l(std::set<audio_port_handle_t>* portIds = {}) override
+            REQUIRES(mutex());
+    bool invalidateTracks(std::set<audio_port_handle_t>* portIds = {}) override
+            EXCLUDES_ThreadBase_Mutex;
+
+    status_t setPortsVolume(const std::vector<audio_port_handle_t>& portIds, float volume,
+                            bool muted) final EXCLUDES_ThreadBase_Mutex;
+
+    void checkUpdateTrackMetadataForUid(uid_t uid) final EXCLUDES_ThreadBase_Mutex;
+
     // mThreadloopExecutor contains deferred functors and object (dtors) to
     // be executed at the end of the processing period, without any
     // mutexes held.
@@ -902,9 +973,72 @@ protected:
     // for access.
     audio_utils::DeferredExecutor mThreadloopExecutor;
 
+    AudioStreamOut* getOutput_l() const final REQUIRES(mutex()) {
+        return mOutput;
+    }
+    AudioStreamOut* getOutput() const final EXCLUDES_ThreadBase_Mutex {
+        audio_utils::lock_guard _l(mutex());
+        return getOutput_l();
+    }
+    AudioStreamOut* clearOutput_l() override REQUIRES(mutex()) {
+        AudioStreamOut* output = mOutput;
+        mOutput = nullptr;
+        return output;
+    }
+    AudioStreamOut* clearOutput() final EXCLUDES_ThreadBase_Mutex {
+        audio_utils::lock_guard _l(mutex());
+        return clearOutput_l();
+    }
+
+    AudioStreamIn* getInput_l() const final REQUIRES(mutex()) {
+        return mInput;
+    }
+    AudioStreamIn* getInput() const final EXCLUDES_ThreadBase_Mutex {
+        audio_utils::lock_guard _l(mutex());
+        return getInput_l();
+    }
+    AudioStreamIn* clearInput_l() override REQUIRES(mutex()) {
+        AudioStreamIn* input = mInput;
+        mInput = nullptr;
+        return input;
+    }
+    AudioStreamIn* clearInput() final EXCLUDES_ThreadBase_Mutex {
+        audio_utils::lock_guard _l(mutex());
+        return clearInput_l();
+    }
+
+    status_t initCheck_l() const override REQUIRES(mutex()) {
+        if (mIsOut) {
+            return mOutput == nullptr ? NO_INIT : NO_ERROR;
+        } else {
+            return mInput == nullptr ? NO_INIT : NO_ERROR;
+        }
+    }
+
+    status_t initCheck() const final EXCLUDES_ThreadBase_Mutex {
+        audio_utils::lock_guard _l(mutex());
+        return initCheck_l();
+    }
+
+    bool isStreamInitialized_l() const final REQUIRES(mutex()) {
+        if (mIsOut) {
+            return !(mOutput == nullptr || mOutput->stream == nullptr);
+        } else {
+            return !(mInput == nullptr || mInput->stream == nullptr);
+        }
+    }
+    bool isStreamInitialized() const final EXCLUDES_ThreadBase_Mutex {
+        audio_utils::lock_guard _l(mutex());
+        return isStreamInitialized_l();
+    }
+
     private:
     void dumpBase_l(int fd, const Vector<String16>& args) REQUIRES(mutex());
     void dumpEffectChains_l(int fd, const Vector<String16>& args) REQUIRES(mutex());
+
+protected:
+    AudioStreamIn* mInput = nullptr; // NO_THREAD_SAFETY_ANALYSIS
+    AudioStreamOut* mOutput = nullptr; // NO_THREAD_SAFETY_ANALYSIS
 };
 
 // --- PlaybackThread ---
@@ -957,17 +1091,17 @@ protected:
     virtual void threadLoop_drain() REQUIRES(ThreadBase_ThreadLoop);
     virtual void threadLoop_standby() REQUIRES(ThreadBase_ThreadLoop);
     virtual void threadLoop_exit() REQUIRES(ThreadBase_ThreadLoop);
-    virtual void threadLoop_removeTracks(const Vector<sp<IAfTrack>>& tracksToRemove)
+    virtual void threadLoop_removeTracks(const std::vector<sp<IAfTrackBase>>& tracksToRemove)
             REQUIRES(ThreadBase_ThreadLoop);
 
                 // prepareTracks_l reads and writes mActiveTracks, and returns
                 // the pending set of tracks to remove via Vector 'tracksToRemove'.  The caller
                 // is responsible for clearing or destroying this Vector later on, when it
                 // is safe to do so. That will drop the final ref count and destroy the tracks.
-    virtual mixer_state prepareTracks_l(Vector<sp<IAfTrack>>* tracksToRemove)
+    virtual mixer_state prepareTracks_l(std::vector<sp<IAfTrackBase>>* tracksToRemove)
             REQUIRES(mutex(), ThreadBase_ThreadLoop) = 0;
 
-    void removeTracks_l(const Vector<sp<IAfTrack>>& tracksToRemove) REQUIRES(mutex());
+    void removeTracks_l(const std::vector<sp<IAfTrackBase>>& tracksToRemove) REQUIRES(mutex());
     status_t handleVoipVolume_l(float *volume) REQUIRES(mutex());
 
     // StreamOutHalInterfaceCallback implementation
@@ -995,7 +1129,8 @@ protected:
     void preExit() final EXCLUDES_ThreadBase_Mutex;
 
     virtual     bool        keepWakeLock() const { return true; }
-    virtual void acquireWakeLock_l() REQUIRES(mutex()) {
+
+    virtual void acquireWakeLock_l() REQUIRES(mutex()){
                                 ThreadBase::acquireWakeLock_l();
         mActiveTracks.updatePowerState_l(this, true /* force */);
                             }
@@ -1010,12 +1145,10 @@ protected:
 
 public:
 
-    status_t initCheck() const final { return mOutput == nullptr ? NO_INIT : NO_ERROR; }
-
                 // return estimated latency in milliseconds, as reported by HAL
-    uint32_t latency() const final;
+    uint32_t latency() const final EXCLUDES_ThreadBase_Mutex;
                 // same, but lock must already be held
-    uint32_t latency_l() const final /* REQUIRES(mutex()) */;  // NO_THREAD_SAFETY_ANALYSIS
+    uint32_t latency_l() const final REQUIRES(mutex());
 
                 // VolumeInterface
     void setMasterVolume(float value) final;
@@ -1025,8 +1158,6 @@ public:
             EXCLUDES_ThreadBase_Mutex;
     void setStreamMute(audio_stream_type_t stream, bool muted) final EXCLUDES_ThreadBase_Mutex;
     float streamVolume(audio_stream_type_t stream) const final EXCLUDES_ThreadBase_Mutex;
-    status_t setPortsVolume(const std::vector<audio_port_handle_t>& portIds, float volume,
-                            bool muted) final EXCLUDES_ThreadBase_Mutex;
 
     void setVolumeForOutput_l(float left, float right) const final;
 
@@ -1052,18 +1183,14 @@ public:
                                 const sp<media::IAudioTrackCallback>& callback,
                                 bool isSpatialized,
                                 bool isBitPerfect,
-                                audio_output_flags_t* afTrackFlags,
-                                float volume,
-                                bool muted) final
+                                audio_output_flags_t* afTrackFlags) final
             REQUIRES(audio_utils::AudioFlinger_Mutex);
 
-    bool isTrackActive(const sp<IAfTrack>& track) const final {
-        return mActiveTracks.indexOf(track) >= 0;
+    bool isTrackActive_l(const sp<IAfTrack>& track) const final REQUIRES(mutex()) {
+        return mActiveTracks.count(track) > 0;
     }
 
-    AudioStreamOut* getOutput_l() const final REQUIRES(mutex()) { return mOutput; }
-    AudioStreamOut* getOutput() const final EXCLUDES_ThreadBase_Mutex;
-    AudioStreamOut* clearOutput() final EXCLUDES_ThreadBase_Mutex;
+    AudioStreamOut* clearOutput_l() final REQUIRES(mutex());
 
     // NO_THREAD_SAFETY_ANALYSIS -- probably needs a lock.
     sp<StreamHalInterface> stream() const final;
@@ -1087,9 +1214,8 @@ public:
 
     String8 getParameters(const String8& keys) EXCLUDES_ThreadBase_Mutex;
 
-    // Hold either the AudioFlinger::mutex or the ThreadBase::mutex
     void ioConfigChanged_l(audio_io_config_event_t event, pid_t pid = 0,
-            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE) final;
+            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE) final REQUIRES(mutex());
     status_t getRenderPosition(uint32_t* halFrames, uint32_t* dspFrames) const final
             EXCLUDES_ThreadBase_Mutex;
                 // Consider also removing and passing an explicit mMainBuffer initialization
@@ -1117,17 +1243,6 @@ public:
     // could be static.
     bool isValidSyncEvent(const sp<audioflinger::SyncEvent>& event) const final;
 
-    // Does this require the AudioFlinger mutex as well?
-    bool invalidateTracks_l(audio_stream_type_t streamType) final
-            REQUIRES(mutex());
-    bool invalidateTracks_l(std::set<audio_port_handle_t>& portIds) final
-            REQUIRES(mutex());
-    void invalidateTracks(audio_stream_type_t streamType) override;
-                // Invalidate tracks by a set of port ids. The port id will be removed from
-                // the given set if the corresponding track is found and invalidated.
-    void invalidateTracks(std::set<audio_port_handle_t>& portIds) override
-            EXCLUDES_ThreadBase_Mutex;
-
     size_t frameCount() const final { return mNormalFrameCount; }
 
     audio_channel_mask_t mixerChannelMask() const final {
@@ -1160,11 +1275,6 @@ public:
                 && outDeviceTypes_l().count(mTimestampCorrectedDevice) != 0;
                             }
 
-    // NO_THREAD_SAFETY_ANALYSIS - fix this to be atomic.
-    bool isStreamInitialized() const final {
-                                return !(mOutput == nullptr || mOutput->stream == nullptr);
-                            }
-
     audio_channel_mask_t hapticChannelMask() const final {
                                          return mHapticChannelMask;
                                      }
@@ -1182,10 +1292,6 @@ public:
                     mDownStreamPatch = *patch;
                 }
 
-    IAfTrack* getTrackById_l(audio_port_handle_t trackId) final REQUIRES(mutex());
-
-    std::vector<sp<IAfTrack>> getTracks_l() final REQUIRES(mutex());
-
     bool hasMixer() const final {
                     return mType == MIXER || mType == DUPLICATING || mType == SPATIALIZER;
                 }
@@ -1198,6 +1304,8 @@ public:
                     return INVALID_OPERATION;
                 }
 
+    bool supportsBluetoothVariableLatency() const override { return false; }
+
     status_t setBluetoothVariableLatencyEnabled(bool /* enabled */) override{
                     return INVALID_OPERATION;
                 }
@@ -1219,10 +1327,9 @@ public:
                         mTimestamp.mPosition[ExtendedTimestamp::LOCATION_KERNEL];
                 }
 
-    bool waitForHalStart() final EXCLUDES_ThreadBase_Mutex {
+    bool waitForHalStart(uint32_t timeoutMs) final EXCLUDES_ThreadBase_Mutex {
                     audio_utils::unique_lock _l(mutex());
-                    static const nsecs_t kWaitHalTimeoutNs = seconds(2);
-                    nsecs_t endWaitTimetNs = systemTime() + kWaitHalTimeoutNs;
+                    nsecs_t endWaitTimetNs = systemTime() + milliseconds(timeoutMs);
                     while (!mHalStarted) {
                         nsecs_t timeNs = systemTime();
                         if (timeNs >= endWaitTimetNs) {
@@ -1241,7 +1348,9 @@ public:
 
     std::string getLocalLogHeader() const override;
 
-    void checkUpdateTrackMetadataForUid(uid_t uid) final EXCLUDES_ThreadBase_Mutex;
+    sp<VolumeInterface> asVolumeInterface() final {
+        return static_cast<VolumeInterface*>(this);
+    }
 
 protected:
     // updated by readOutputParameters_l()
@@ -1367,7 +1476,10 @@ protected:
                             : mTimestampVerifier.DISCONTINUITY_MODE_CONTINUOUS;
                 }
 
-    ActiveTracks<IAfTrack> mActiveTracks;
+    ContainerView<decltype(mActiveTracks), sp<IAfTrack>>
+            mActivePlaybackTracksView GUARDED_BY(mutex()) {mActiveTracks};
+    ContainerView<decltype(mTracks), sp<IAfTrack>>
+            mPlaybackTracksView GUARDED_BY(mutex()) {mTracks};
 
     // Time to sleep between cycles when:
     virtual uint32_t        activeSleepTimeUs() const;      // mixer state MIXER_TRACKS_ENABLED
@@ -1378,9 +1490,6 @@ protected:
 
     // Code snippets that are temporarily lifted up out of threadLoop() until the merge
 
-    // consider unification with MMapThread
-    virtual void checkSilentMode_l() final REQUIRES(mutex());
-
     // Non-trivial for DUPLICATING only
     virtual void saveOutputTracks() REQUIRES(ThreadBase_ThreadLoop) {}
     virtual void clearOutputTracks() REQUIRES(ThreadBase_ThreadLoop) {}
@@ -1394,9 +1503,9 @@ protected:
     virtual uint32_t correctLatency_l(uint32_t latency) const REQUIRES(mutex());
 
     virtual     status_t    createAudioPatch_l(const struct audio_patch *patch,
-            audio_patch_handle_t *handle) REQUIRES(mutex());
+            audio_patch_handle_t *handle) REQUIRES(mutex(), ThreadBase_ThreadLoop);
     virtual status_t releaseAudioPatch_l(const audio_patch_handle_t handle)
-            REQUIRES(mutex());
+            REQUIRES(mutex(), ThreadBase_ThreadLoop);
 
     // NO_THREAD_SAFETY_ANALYSIS - fix this to use atomics
     bool usesHwAvSync() const final { return mType == DIRECT && mOutput != nullptr
@@ -1416,72 +1525,16 @@ protected:
     bool destroyTrack_l(const sp<IAfTrack>& track) final REQUIRES(mutex());
 
     void removeTrack_l(const sp<IAfTrack>& track) REQUIRES(mutex());
-    std::set<audio_port_handle_t> getTrackPortIds_l() REQUIRES(mutex());
-    std::set<audio_port_handle_t> getTrackPortIds();
 
     void readOutputParameters_l() REQUIRES(mutex());
-    MetadataUpdate updateMetadata_l() final REQUIRES(mutex());
+    MetadataUpdate updateMetadata_l() final REQUIRES(mutex(), ThreadBase_ThreadLoop);
     virtual void sendMetadataToBackend_l(const StreamOutHalInterface::SourceMetadata& metadata)
-            REQUIRES(mutex()) ;
+            REQUIRES(mutex(), ThreadBase_ThreadLoop);
 
     void collectTimestamps_l() REQUIRES(mutex(), ThreadBase_ThreadLoop);
 
-    // The Tracks class manages tracks added and removed from the Thread.
-    template <typename T>
-    class Tracks {
-    public:
-        explicit Tracks(bool saveDeletedTrackIds) :
-            mSaveDeletedTrackIds(saveDeletedTrackIds) { }
-
-        // SortedVector methods
-        ssize_t         add(const sp<T> &track) {
-            const ssize_t index = mTracks.add(track);
-            LOG_ALWAYS_FATAL_IF(index < 0, "cannot add track");
-            return index;
-        }
-        ssize_t         remove(const sp<T> &track);
-        size_t          size() const {
-            return mTracks.size();
-        }
-        bool            isEmpty() const {
-            return mTracks.isEmpty();
-        }
-        ssize_t         indexOf(const sp<T> &item) {
-            return mTracks.indexOf(item);
-        }
-        sp<T>           operator[](size_t index) const {
-            return mTracks[index];
-        }
-        typename SortedVector<sp<T>>::iterator begin() {
-            return mTracks.begin();
-        }
-        typename SortedVector<sp<T>>::iterator end() {
-            return mTracks.end();
-        }
-
-        size_t          processDeletedTrackIds(const std::function<void(int)>& f) {
-            for (const int trackId : mDeletedTrackIds) {
-                f(trackId);
-            }
-            return mDeletedTrackIds.size();
-        }
-
-        void            clearDeletedTrackIds() { mDeletedTrackIds.clear(); }
-
-    private:
-        // Tracks pending deletion for MIXER type threads
-        const bool mSaveDeletedTrackIds; // true to enable tracking
-        std::set<int> mDeletedTrackIds;
-
-        SortedVector<sp<T>> mTracks; // wrapped SortedVector.
-    };
-
-    Tracks<IAfTrack>                   mTracks;
-
     stream_type_t                   mStreamTypes[AUDIO_STREAM_CNT];
 
-    AudioStreamOut                  *mOutput;
-
     float                           mMasterVolume;
     std::atomic<float>              mMasterBalance{};
     audio_utils::Balance            mBalance;
@@ -1646,7 +1699,7 @@ public:
                                     audio_channel_mask_t channelMask, audio_format_t format,
             audio_session_t sessionId, uid_t uid) const final REQUIRES(mutex());
 protected:
-    mixer_state prepareTracks_l(Vector<sp<IAfTrack>>* tracksToRemove) override
+    mixer_state prepareTracks_l(std::vector<sp<IAfTrackBase>>* tracksToRemove) override
             REQUIRES(mutex(), ThreadBase_ThreadLoop);
     uint32_t idleSleepTimeUs() const final;
     uint32_t suspendSleepTimeUs() const final;
@@ -1671,8 +1724,9 @@ protected:
 
     status_t createAudioPatch_l(
             const struct audio_patch* patch, audio_patch_handle_t* handle)
-            final REQUIRES(mutex());
-    status_t releaseAudioPatch_l(const audio_patch_handle_t handle) final REQUIRES(mutex());
+            final REQUIRES(mutex(), ThreadBase_ThreadLoop);
+    status_t releaseAudioPatch_l(const audio_patch_handle_t handle)
+            final REQUIRES(mutex(), ThreadBase_ThreadLoop);
 
                 AudioMixer* mAudioMixer;    // normal mixer
 
@@ -1723,6 +1777,8 @@ public:
                 status_t    getSupportedLatencyModes(
                                     std::vector<audio_latency_mode_t>* modes) override;
 
+                bool supportsBluetoothVariableLatency() const override;
+
                 status_t    setBluetoothVariableLatencyEnabled(bool enabled) override;
 
 protected:
@@ -1783,14 +1839,14 @@ protected:
     void dumpInternals_l(int fd, const Vector<String16>& args) override REQUIRES(mutex());
 
     // threadLoop snippets
-    virtual mixer_state prepareTracks_l(Vector<sp<IAfTrack>>* tracksToRemove)
+    mixer_state prepareTracks_l(std::vector<sp<IAfTrackBase>>* tracksToRemove) override
             REQUIRES(mutex(), ThreadBase_ThreadLoop);
-    virtual void threadLoop_mix() REQUIRES(ThreadBase_ThreadLoop);
-    virtual void threadLoop_sleepTime() REQUIRES(ThreadBase_ThreadLoop);
-    virtual void threadLoop_exit() REQUIRES(ThreadBase_ThreadLoop);
-    virtual bool shouldStandby_l() REQUIRES(mutex());
+    void threadLoop_mix() final REQUIRES(ThreadBase_ThreadLoop);
+    void threadLoop_sleepTime() final REQUIRES(ThreadBase_ThreadLoop);
+    void threadLoop_exit() override REQUIRES(ThreadBase_ThreadLoop);
+    bool shouldStandby_l() final REQUIRES(mutex());
 
-    virtual void onAddNewTrack_l() REQUIRES(mutex());
+    void onAddNewTrack_l() final REQUIRES(mutex());
 
     const       audio_offload_info_t mOffloadInfo;
 
@@ -1800,7 +1856,7 @@ protected:
     DirectOutputThread(const sp<IAfThreadCallback>& afThreadCallback, AudioStreamOut* output,
                        audio_io_handle_t id, ThreadBase::type_t type, bool systemReady,
                        const audio_offload_info_t& offloadInfo);
-    void processVolume_l(IAfTrack *track, bool lastTrack) REQUIRES(mutex());
+    void processVolume_l(const sp<IAfTrack>& track, bool lastTrack) REQUIRES(mutex());
     bool isTunerStream() const { return (mOffloadInfo.content_id > 0); }
 
     // prepareTracks_l() tells threadLoop_mix() the name of the single active track
@@ -1846,14 +1902,13 @@ public:
 
 protected:
     // threadLoop snippets
-    mixer_state prepareTracks_l(Vector<sp<IAfTrack>>* tracksToRemove) final
+    mixer_state prepareTracks_l(std::vector<sp<IAfTrackBase>>* tracksToRemove) final
             REQUIRES(mutex(), ThreadBase_ThreadLoop);
     void threadLoop_exit() final REQUIRES(ThreadBase_ThreadLoop);
 
     bool waitingAsyncCallback() final;
     bool waitingAsyncCallback_l() final REQUIRES(mutex());
-    void invalidateTracks(audio_stream_type_t streamType) final EXCLUDES_ThreadBase_Mutex;
-    void invalidateTracks(std::set<audio_port_handle_t>& portIds) final EXCLUDES_ThreadBase_Mutex;
+    bool invalidateTracks_l(std::set<audio_port_handle_t>* portIds) final REQUIRES(mutex());
 
     bool keepWakeLock() const final { return (mKeepWakeLock || (mDrainSequence & 1)); }
 
@@ -1917,7 +1972,8 @@ public:
     uint32_t waitTimeMs() const final { return mWaitTimeMs; }
 
                 void        sendMetadataToBackend_l(
-            const StreamOutHalInterface::SourceMetadata& metadata) final REQUIRES(mutex());
+            const StreamOutHalInterface::SourceMetadata& metadata) final
+            REQUIRES(mutex(), ThreadBase_ThreadLoop);
 protected:
     virtual     uint32_t    activeSleepTimeUs() const;
     void dumpInternals_l(int fd, const Vector<String16>& args) final REQUIRES(mutex());
@@ -1942,9 +1998,10 @@ protected:
 private:
 
                 uint32_t    mWaitTimeMs;
-    // NO_THREAD_SAFETY_ANALYSIS  GUARDED_BY(ThreadBase_ThreadLoop)
-    SortedVector <sp<IAfOutputTrack>> outputTracks;
-    SortedVector <sp<IAfOutputTrack>> mOutputTracks GUARDED_BY(mutex());
+
+    // tlOutputTracks is a copy of mOutputTracks accessed only by the worker thread.
+    std::set<sp<IAfOutputTrack>> tlOutputTracks GUARDED_BY(ThreadBase_ThreadLoop);
+    std::set<sp<IAfOutputTrack>> mOutputTracks GUARDED_BY(mutex());
 public:
     virtual     bool        hasFastMixer() const { return false; }
                 status_t    threadloop_getHalTimestamp_l(
@@ -1952,7 +2009,7 @@ public:
         if (mOutputTracks.size() > 0) {
             // forward the first OutputTrack's kernel information for timestamp.
             const ExtendedTimestamp trackTimestamp =
-                    mOutputTracks[0]->getClientProxyTimestamp();
+                    (*mOutputTracks.begin())->getClientProxyTimestamp();
             if (trackTimestamp.mTimeNs[ExtendedTimestamp::LOCATION_KERNEL] > 0) {
                 timestamp->mTimeNs[ExtendedTimestamp::LOCATION_KERNEL] =
                         trackTimestamp.mTimeNs[ExtendedTimestamp::LOCATION_KERNEL];
@@ -2019,8 +2076,6 @@ public:
     // RefBase
     void onFirstRef() final EXCLUDES_ThreadBase_Mutex;
 
-    status_t initCheck() const final { return mInput == nullptr ? NO_INIT : NO_ERROR; }
-
     sp<MemoryDealer> readOnlyHeap() const final { return mReadOnlyHeap; }
 
     sp<IMemory> pipeMemory() const final { return mPipeMemory; }
@@ -2050,8 +2105,7 @@ public:
             // ask the thread to stop the specified track, and
             // return true if the caller should then do it's part of the stopping process
     bool stop(IAfRecordTrack* recordTrack) final EXCLUDES_ThreadBase_Mutex;
-    AudioStreamIn* getInput() const final { return mInput; }
-    AudioStreamIn* clearInput() final;
+    AudioStreamIn* clearInput_l() final REQUIRES(mutex());
 
             // TODO(b/291317898) Unify with IAfThreadBase
             virtual sp<StreamHalInterface> stream() const;
@@ -2062,12 +2116,12 @@ public:
     virtual void cacheParameters_l() REQUIRES(mutex(), ThreadBase_ThreadLoop) {}
     virtual String8 getParameters(const String8& keys) EXCLUDES_ThreadBase_Mutex;
 
-    // Hold either the AudioFlinger::mutex or the ThreadBase::mutex
     void ioConfigChanged_l(audio_io_config_event_t event, pid_t pid = 0,
-            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE) final;
+            audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE) final REQUIRES(mutex());
     virtual status_t    createAudioPatch_l(const struct audio_patch *patch,
-            audio_patch_handle_t *handle) REQUIRES(mutex());
-    virtual status_t releaseAudioPatch_l(const audio_patch_handle_t handle) REQUIRES(mutex());
+            audio_patch_handle_t *handle) REQUIRES(mutex(), ThreadBase_ThreadLoop);
+    status_t releaseAudioPatch_l(const audio_patch_handle_t handle)
+            override REQUIRES(mutex(), ThreadBase_ThreadLoop);
     void updateOutDevices(const DeviceDescriptorBaseVector& outDevices) override
             EXCLUDES_ThreadBase_Mutex;
     void resizeInputBuffer_l(int32_t maxSharedAudioHistoryMs) override REQUIRES(mutex());
@@ -2120,7 +2174,7 @@ public:
             EXCLUDES_ThreadBase_Mutex;
     status_t setPreferredMicrophoneFieldDimension(float zoom) final EXCLUDES_ThreadBase_Mutex;
 
-    MetadataUpdate updateMetadata_l() override REQUIRES(mutex());
+    MetadataUpdate updateMetadata_l() override REQUIRES(mutex(), ThreadBase_ThreadLoop);
 
     bool fastTrackAvailable() const final { return mFastTrackAvail; }
     void setFastTrackAvailable(bool available) final { mFastTrackAvail = available; }
@@ -2141,10 +2195,6 @@ public:
             int64_t sharedAudioStartMs = -1) REQUIRES(mutex());
     void resetAudioHistory_l() final REQUIRES(mutex());
 
-    bool isStreamInitialized() const final {
-                            return !(mInput == nullptr || mInput->stream == nullptr);
-                        }
-
     std::string getLocalLogHeader() const override;
 
 protected:
@@ -2162,13 +2212,13 @@ private:
 
     int32_t getOldestFront_l() REQUIRES(mutex());
     void updateFronts_l(int32_t offset) REQUIRES(mutex());
-
-            AudioStreamIn                       *mInput;
             Source                              *mSource;
-            SortedVector <sp<IAfRecordTrack>>    mTracks;
             // mActiveTracks has dual roles:  it indicates the current active track(s), and
             // is used together with mStartStopCV to indicate start()/stop() progress
-            ActiveTracks<IAfRecordTrack>           mActiveTracks;
+    ContainerView<decltype(mActiveTracks), sp<IAfRecordTrack>>
+            mActiveRecordTracksView GUARDED_BY(mutex()) {mActiveTracks};
+    ContainerView<decltype(mTracks), sp<IAfRecordTrack>>
+            mRecordTracksView GUARDED_BY(mutex()) {mTracks};
 
             audio_utils::condition_variable mStartStopCV;
 
@@ -2233,6 +2283,7 @@ private:
             std::string                         mSharedAudioPackageName = {};
             int32_t                             mSharedAudioStartFrames = -1;
             audio_session_t                     mSharedAudioSessionId = AUDIO_SESSION_NONE;
+            std::atomic_bool                    mIsHwSilenced = false;
 };
 
 class DirectRecordThread final : public RecordThread {
@@ -2247,14 +2298,16 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
  public:
     MmapThread(const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
                AudioHwDevice *hwDev, const sp<StreamHalInterface>& stream, bool systemReady,
-               bool isOut);
+               bool isOut, AudioStreamIn* input, AudioStreamOut* output);
 
     void configure(const audio_attributes_t* attr,
-                                      audio_stream_type_t streamType,
-                                      audio_session_t sessionId,
-                                      const sp<MmapStreamCallback>& callback,
-                                      const DeviceIdVector& deviceIds,
-            audio_port_handle_t portId) override EXCLUDES_ThreadBase_Mutex {
+                   audio_stream_type_t streamType,
+                   audio_session_t sessionId,
+                   const sp<MmapStreamCallback>& callback,
+                   const DeviceIdVector& deviceIds,
+                   audio_port_handle_t portId,
+                   [[maybe_unused]]const audio_offload_info_t* offloadInfo)
+                   override EXCLUDES_ThreadBase_Mutex {
         audio_utils::lock_guard l(mutex());
         configure_l(attr, streamType, sessionId, callback, deviceIds, portId);
     }
@@ -2292,23 +2345,25 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
     virtual void threadLoop_exit() final REQUIRES(ThreadBase_ThreadLoop);
     virtual void threadLoop_standby() final REQUIRES(ThreadBase_ThreadLoop);
     virtual bool shouldStandby_l() final REQUIRES(mutex()){ return false; }
-    virtual status_t exitStandby_l() REQUIRES(mutex());
+    virtual status_t exitStandby_l() final REQUIRES(mutex());
 
-    status_t initCheck() const final { return mHalStream == nullptr ? NO_INIT : NO_ERROR; }
+    status_t initCheck_l() const final {
+        return mHalStream == nullptr ? NO_INIT : NO_ERROR;
+    }
     size_t frameCount() const final { return mFrameCount; }
     bool checkForNewParameter_l(const String8& keyValuePair, status_t& status)
             final REQUIRES(mutex());
     String8 getParameters(const String8& keys) final EXCLUDES_ThreadBase_Mutex;
     void ioConfigChanged_l(audio_io_config_event_t event, pid_t pid = 0,
             audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE) final
-            /* holds either AF::mutex or TB::mutex */;
+            REQUIRES(mutex());
     void readHalParameters_l() REQUIRES(mutex());
     void cacheParameters_l() final REQUIRES(mutex(), ThreadBase_ThreadLoop) {}
     status_t createAudioPatch_l(
             const struct audio_patch* patch, audio_patch_handle_t* handle) final
-            REQUIRES(mutex());
+            REQUIRES(mutex(), ThreadBase_ThreadLoop);
     status_t releaseAudioPatch_l(const audio_patch_handle_t handle) final
-            REQUIRES(mutex());
+            REQUIRES(mutex(), ThreadBase_ThreadLoop);
     // NO_THREAD_SAFETY_ANALYSIS
     void toAudioPortConfig(struct audio_port_config* config) override;
 
@@ -2325,7 +2380,6 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
     status_t setSyncEvent(const sp<audioflinger::SyncEvent>& event) final;
     bool isValidSyncEvent(const sp<audioflinger::SyncEvent>& event) const final;
 
-    virtual void checkSilentMode_l() REQUIRES(mutex()) {} // cannot be const (RecordThread)
     virtual void processVolume_l() REQUIRES(mutex()) {}
     void checkInvalidTracks_l() REQUIRES(mutex());
 
@@ -2333,18 +2387,12 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
     virtual audio_stream_type_t streamType_l() const REQUIRES(mutex()) {
         return AUDIO_STREAM_DEFAULT;
     }
-    virtual void invalidateTracks(audio_stream_type_t /* streamType */)
-            EXCLUDES_ThreadBase_Mutex {}
-    void invalidateTracks(std::set<audio_port_handle_t>& /* portIds */) override
-            EXCLUDES_ThreadBase_Mutex {}
 
                 // Sets the UID records silence
     void setRecordSilenced(
             audio_port_handle_t /* portId */, bool /* silenced */) override
             EXCLUDES_ThreadBase_Mutex {}
 
-    bool isStreamInitialized() const override { return false; }
-
     std::string getLocalLogHeader() const override;
 
     void setClientSilencedState_l(audio_port_handle_t portId, bool silenced) REQUIRES(mutex()) {
@@ -2368,6 +2416,10 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
                                 }
                             }
 
+    virtual std::optional<audio_offload_info_t> offloadInfo_l() const REQUIRES(mutex()) {
+        return std::nullopt;
+    }
+
  protected:
     void dumpInternals_l(int fd, const Vector<String16>& args) override REQUIRES(mutex());
     void dumpTracks_l(int fd, const Vector<String16>& args) final REQUIRES(mutex());
@@ -2385,7 +2437,8 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
     sp<StreamHalInterface> mHalStream; // NO_THREAD_SAFETY_ANALYSIS
     sp<DeviceHalInterface> mHalDevice GUARDED_BY(mutex());
     AudioHwDevice* const mAudioHwDev GUARDED_BY(mutex());
-    ActiveTracks<IAfMmapTrack> mActiveTracks GUARDED_BY(mutex());
+    ContainerView<decltype(mActiveTracks), sp<IAfMmapTrack>>
+            mActiveMmapTracksView GUARDED_BY(mutex()) {mActiveTracks};
     float mHalVolFloat GUARDED_BY(mutex());
     std::map<audio_port_handle_t, bool> mClientSilencedStates GUARDED_BY(mutex());
 
@@ -2393,24 +2446,19 @@ class MmapThread : public ThreadBase, public virtual IAfMmapThread
     static constexpr int32_t kMaxNoCallbackWarnings = 5;
 };
 
-class MmapPlaybackThread : public MmapThread, public IAfMmapPlaybackThread,
+class MmapPlaybackThread : public MmapThread,
         public virtual VolumeInterface {
 public:
     MmapPlaybackThread(const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
                        AudioHwDevice *hwDev, AudioStreamOut *output, bool systemReady);
 
-    sp<IAfMmapPlaybackThread> asIAfMmapPlaybackThread() final {
-        return sp<IAfMmapPlaybackThread>::fromExisting(this);
-    }
-
     void configure(const audio_attributes_t* attr,
-                                      audio_stream_type_t streamType,
-                                      audio_session_t sessionId,
-                                      const sp<MmapStreamCallback>& callback,
-                                      const DeviceIdVector& deviceIds,
-            audio_port_handle_t portId) final EXCLUDES_ThreadBase_Mutex;
-
-    AudioStreamOut* clearOutput() final EXCLUDES_ThreadBase_Mutex;
+                   audio_stream_type_t streamType,
+                   audio_session_t sessionId,
+                   const sp<MmapStreamCallback>& callback,
+                   const DeviceIdVector& deviceIds,
+                   audio_port_handle_t portId,
+                   const audio_offload_info_t* offloadInfo) final EXCLUDES_ThreadBase_Mutex;
 
                 // VolumeInterface
     void setMasterVolume(float value) final;
@@ -2422,18 +2470,13 @@ public:
             EXCLUDES_ThreadBase_Mutex;
     void setStreamMute(audio_stream_type_t stream, bool muted) final EXCLUDES_ThreadBase_Mutex;
     float streamVolume(audio_stream_type_t stream) const final EXCLUDES_ThreadBase_Mutex;
-    status_t setPortsVolume(const std::vector<audio_port_handle_t>& portIds, float volume,
-                            bool muted) final EXCLUDES_ThreadBase_Mutex;
 
     void setMasterMute_l(bool muted) REQUIRES(mutex()) { mMasterMute = muted; }
 
-    void invalidateTracks(audio_stream_type_t streamType) final EXCLUDES_ThreadBase_Mutex;
-    void invalidateTracks(std::set<audio_port_handle_t>& portIds) final EXCLUDES_ThreadBase_Mutex;
-
     audio_stream_type_t streamType_l() const final REQUIRES(mutex()) {
         return mStreamType;
     }
-    void checkSilentMode_l() final REQUIRES(mutex());
+
     void processVolume_l() final REQUIRES(mutex());
 
     MetadataUpdate updateMetadata_l() final REQUIRES(mutex());
@@ -2442,10 +2485,6 @@ public:
 
     status_t getExternalPosition(uint64_t* position, int64_t* timeNanos) const final;
 
-    bool isStreamInitialized() const final {
-                                return !(mOutput == nullptr || mOutput->stream == nullptr);
-                            }
-
     status_t reportData(const void* buffer, size_t frameCount) final;
 
     void startMelComputation_l(const sp<audio_utils::MelProcessor>& processor) final
@@ -2453,7 +2492,13 @@ public:
     void stopMelComputation_l() final
             REQUIRES(audio_utils::AudioFlinger_Mutex);
 
-    void checkUpdateTrackMetadataForUid(uid_t uid) final EXCLUDES_ThreadBase_Mutex;
+    std::optional<audio_offload_info_t> offloadInfo_l() const final REQUIRES(mutex()) {
+        return mOffloadInfo;
+    }
+
+    sp<VolumeInterface> asVolumeInterface() final {
+       return static_cast<VolumeInterface*>(this);
+    }
 
 protected:
     void dumpInternals_l(int fd, const Vector<String16>& args) final REQUIRES(mutex());
@@ -2468,25 +2513,16 @@ protected:
     audio_stream_type_t mStreamType GUARDED_BY(mutex());
     float mMasterVolume GUARDED_BY(mutex());
     bool mMasterMute GUARDED_BY(mutex());
-    AudioStreamOut* mOutput;  // NO_THREAD_SAFETY_ANALYSIS
-
+    std::optional<audio_offload_info_t> mOffloadInfo GUARDED_BY(mutex());
     mediautils::atomic_sp<audio_utils::MelProcessor> mMelProcessor;  // locked internally
 };
 
-class MmapCaptureThread : public MmapThread, public IAfMmapCaptureThread
+class MmapCaptureThread : public MmapThread
 {
 public:
     MmapCaptureThread(const sp<IAfThreadCallback>& afThreadCallback, audio_io_handle_t id,
                       AudioHwDevice *hwDev, AudioStreamIn *input, bool systemReady);
 
-    sp<IAfMmapCaptureThread> asIAfMmapCaptureThread() final {
-        return sp<IAfMmapCaptureThread>::fromExisting(this);
-    }
-
-    AudioStreamIn* clearInput() final EXCLUDES_ThreadBase_Mutex;
-
-    status_t exitStandby_l() REQUIRES(mutex()) final;
-
     MetadataUpdate updateMetadata_l() final REQUIRES(mutex());
     void processVolume_l() final REQUIRES(mutex());
     void setRecordSilenced(audio_port_handle_t portId, bool silenced) final
@@ -2495,14 +2531,6 @@ public:
     void toAudioPortConfig(struct audio_port_config* config) final;
 
     status_t getExternalPosition(uint64_t* position, int64_t* timeNanos) const final;
-
-    bool isStreamInitialized() const final {
-                                   return !(mInput == nullptr || mInput->stream == nullptr);
-                               }
-
-protected:
-
-    AudioStreamIn* mInput;  // NO_THREAD_SAFETY_ANALYSIS
 };
 
 class BitPerfectThread : public MixerThread {
@@ -2514,7 +2542,7 @@ public:
             final EXCLUDES_ThreadBase_Mutex;
 
 protected:
-    mixer_state prepareTracks_l(Vector<sp<IAfTrack>>* tracksToRemove) final
+    mixer_state prepareTracks_l(std::vector<sp<IAfTrackBase>>* tracksToRemove) final
             REQUIRES(mutex(), ThreadBase_ThreadLoop);
     void threadLoop_mix() final REQUIRES(ThreadBase_ThreadLoop);
 
diff --git a/services/audioflinger/TrackBase.h b/services/audioflinger/TrackBase.h
index 6dea786827..fe237d9423 100644
--- a/services/audioflinger/TrackBase.h
+++ b/services/audioflinger/TrackBase.h
@@ -34,7 +34,8 @@
 namespace android {
 
 // base for record and playback
-class TrackBase : public ExtendedAudioBufferProvider, public virtual IAfTrackBase {
+class TrackBase : public ExtendedAudioBufferProvider, public virtual IAfTrackBase,
+         public VolumePortImpl {
 public:
     TrackBase(IAfThreadBase* thread,
                                 const sp<Client>& client,
@@ -54,6 +55,13 @@ public:
                                 audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE,
                                 std::string metricsId = {});
     ~TrackBase() override;
+
+    // Implement VolumePortInterface using helper VolumePortImpl.
+    void setPortVolume(float volume) final { VolumePortImpl::setPortVolume(volume); }
+    void setPortMute(bool mute) final { VolumePortImpl::setPortMute(mute); }
+    float getPortVolume() const final { return VolumePortImpl::getPortVolume(); }
+    bool getPortMute() const final { return VolumePortImpl::getPortMute(); }
+
     status_t initCheck() const override;
     sp<IMemory> getCblk() const final { return mCblkMemory; }
     audio_track_cblk_t* cblk() const final { return mCblk; }
diff --git a/services/audioflinger/Tracks.cpp b/services/audioflinger/Tracks.cpp
index 9046859c0e..3a0fc7cbdd 100644
--- a/services/audioflinger/Tracks.cpp
+++ b/services/audioflinger/Tracks.cpp
@@ -157,7 +157,6 @@ TrackBase::TrackBase(
     // battery usage on it.
     mUid = clientUid;
 
-    // ALOGD("Creating track with %d buffers @ %d bytes", bufferCount, bufferSize);
 
     size_t minBufferSize = buffer == NULL ? roundup(frameCount) : frameCount;
     // check overflow when computing bufferSize due to multiplication by mFrameSize.
@@ -175,6 +174,8 @@ TrackBase::TrackBase(
         android_errorWriteLog(0x534e4554, "38340117");
         return;
     }
+    // ALOGD("%s(%d): Creating track with %zu buffers @ %zu bytes",
+    //        __func__, mId, bufferSize / mFrameSize, bufferSize);
 
     size_t size = sizeof(audio_track_cblk_t);
     if (buffer == NULL && alloc == ALLOC_CBLK) {
@@ -538,7 +539,8 @@ TrackHandle::~TrackHandle() {
 
 Status TrackHandle::getCblk(
         std::optional<media::SharedFileRegion>* _aidl_return) {
-    *_aidl_return = legacy2aidl_NullableIMemory_SharedFileRegion(mTrack->getCblk()).value();
+    *_aidl_return = VALUE_OR_RETURN_BINDER_STATUS(
+                legacy2aidl_NullableIMemory_SharedFileRegion(mTrack->getCblk()));
     return Status::ok();
 }
 
@@ -829,9 +831,7 @@ sp<IAfTrack> IAfTrack::create(
         size_t frameCountToBeReady,
         float speed,
         bool isSpatialized,
-        bool isBitPerfect,
-        float volume,
-        bool muted) {
+        bool isBitPerfect) {
     return sp<Track>::make(thread,
             client,
             streamType,
@@ -852,9 +852,7 @@ sp<IAfTrack> IAfTrack::create(
             frameCountToBeReady,
             speed,
             isSpatialized,
-            isBitPerfect,
-            volume,
-            muted);
+            isBitPerfect);
 }
 
 // Track constructor must be called with AudioFlinger::mLock and ThreadBase::mLock held
@@ -879,11 +877,9 @@ Track::Track(
             size_t frameCountToBeReady,
             float speed,
             bool isSpatialized,
-            bool isBitPerfect,
-            float volume,
-            bool muted)
+            bool isBitPerfect)
     :
-    AfPlaybackCommon(*this, *thread, volume, muted,
+    AfPlaybackCommon(*this, *thread,
                      attr, attributionSource, thread->isOffloadOrMmap(), type != TYPE_PATCH),
     TrackBase(thread, client, attr, sampleRate, format, channelMask, frameCount,
                   // TODO: Using unsecurePointer() has some associated security pitfalls
@@ -968,13 +964,6 @@ Track::Track(
 
     populateUsageAndContentTypeFromStreamType();
 
-    // Audio patch and call assistant volume are always max
-    if (mAttr.usage == AUDIO_USAGE_CALL_ASSISTANT
-            || mAttr.usage == AUDIO_USAGE_VIRTUAL_SOURCE) {
-        setPortVolume(1.0f);
-        setPortMute(false);
-    }
-
     mServerLatencySupported = checkServerLatencySupported(format, flags);
 #ifdef TEE_SINK
     mTee.setId(std::string("_") + std::to_string(mThreadIoHandle)
@@ -1432,9 +1421,9 @@ status_t Track::start(AudioSystem::sync_event_t event __unused,
                         __func__,  mId, (int)mThreadIoHandle);
             }
         } else {
+            ALOGV("%s(%d): %s => ACTIVE on thread %d",
+                    __func__, mId, getTrackStateAsString(), (int)mThreadIoHandle);
             mState = TrackBase::ACTIVE;
-            ALOGV("%s(%d): ? => ACTIVE on thread %d",
-                    __func__, mId, (int)mThreadIoHandle);
         }
 
         auto* const playbackThread = thread->asIAfPlaybackThread().get();
@@ -1544,7 +1533,7 @@ void Track::stop()
         if (state == RESUMING || state == ACTIVE || state == PAUSING || state == PAUSED) {
             // If the track is not active (PAUSED and buffers full), flush buffers
             auto* const playbackThread = thread->asIAfPlaybackThread().get();
-            if (!playbackThread->isTrackActive(this)) {
+            if (!playbackThread->isTrackActive_l(this)) {
                 reset();
                 mState = STOPPED;
             } else if (isPatchTrack() || (!isFastTrack() && !isOffloaded() && !isDirect())) {
@@ -1643,7 +1632,7 @@ void Track::flush()
         // Flush the ring buffer now if the track is not active in the PlaybackThread.
         // Otherwise the flush would not be done until the track is resumed.
         // Requires FastTrack removal be BLOCK_UNTIL_ACKED
-        if (!playbackThread->isTrackActive(this)) {
+        if (!playbackThread->isTrackActive_l(this)) {
             (void)mServerProxy->flushBufferIfNeeded();
         }
 
@@ -1682,7 +1671,7 @@ void Track::flush()
             if (isDirect()) {
                 mFlushHwPending = true;
             }
-            if (!playbackThread->isTrackActive(this)) {
+            if (!playbackThread->isTrackActive_l(this)) {
                 reset();
             }
         }
@@ -2344,8 +2333,7 @@ OutputTrack::OutputTrack(
             size_t frameCount,
             const AttributionSourceState& attributionSource)
     :
-    AfPlaybackCommon(*this, *playbackThread, /* volume= */ 0.0f,
-                     /* muted= */ false,
+    AfPlaybackCommon(*this, *playbackThread,
                      AUDIO_ATTRIBUTES_INITIALIZER, attributionSource, /* isOffloadOrMmap= */ false,
                      /* shouldPlaybackHarden= */ false),
     Track(playbackThread, NULL, AUDIO_STREAM_PATCH,
@@ -2353,7 +2341,9 @@ OutputTrack::OutputTrack(
               sampleRate, format, channelMask, frameCount,
               nullptr /* buffer */, (size_t)0 /* bufferSize */, nullptr /* sharedBuffer */,
               AUDIO_SESSION_NONE, getpid(), attributionSource, AUDIO_OUTPUT_FLAG_NONE,
-              TYPE_OUTPUT),
+              TYPE_OUTPUT, AUDIO_PORT_HANDLE_NONE,
+              /*frameCountToBeReady*/ sourceFramesNeededWithTimestretch(sampleRate,
+                      playbackThread->frameCount(), playbackThread->sampleRate(), 1.0f /*speed*/)),
     mActive(false), mSourceThread(sourceThread)
 {
     if (mCblk != NULL) {
@@ -2370,10 +2360,13 @@ OutputTrack::OutputTrack(
         mClientProxy->setVolumeLR(GAIN_MINIFLOAT_PACKED_UNITY);
         mClientProxy->setSendLevel(0.0);
         mClientProxy->setSampleRate(sampleRate);
+        uint32_t waitTimeMs = (playbackThread->frameCount() * 1000) / playbackThread->sampleRate();
+        mClientProxy->setMinMeasureMs(waitTimeMs);
     } else {
         ALOGW("%s(%d): Error creating output track on thread %d",
                 __func__, mId, (int)mThreadIoHandle);
     }
+    setPortVolume(1.f);
 }
 
 OutputTrack::~OutputTrack()
@@ -2449,7 +2442,7 @@ ssize_t OutputTrack::write(void* data, uint32_t frames)
     inBuffer.frameCount = frames;
     inBuffer.raw = data;
     uint32_t waitTimeLeftMs = mSourceThread->waitTimeMs();
-    while (waitTimeLeftMs) {
+    while (true) {
         // First write pending buffers, then new data
         if (mBufferQueue.size()) {
             pInBuffer = mBufferQueue.itemAt(0);
@@ -2510,6 +2503,9 @@ ssize_t OutputTrack::write(void* data, uint32_t frames)
                 break;
             }
         }
+        if (waitTimeLeftMs == 0) {
+            break;
+        }
     }
 
     // If we could not write all frames, allocate a buffer and queue it for next time.
@@ -2621,9 +2617,7 @@ sp<IAfPatchTrack> IAfPatchTrack::create(
                                          *  as soon as possible to have
                                          *  the lowest possible latency
                                          *  even if it might glitch. */
-        float speed,
-        float volume,
-        bool muted)
+        float speed)
 {
     return sp<PatchTrack>::make(
             playbackThread,
@@ -2637,9 +2631,7 @@ sp<IAfPatchTrack> IAfPatchTrack::create(
             flags,
             timeout,
             frameCountToBeReady,
-            speed,
-            volume,
-            muted);
+            speed);
 }
 
 PatchTrack::PatchTrack(IAfPlaybackThread* playbackThread,
@@ -2653,10 +2645,8 @@ PatchTrack::PatchTrack(IAfPlaybackThread* playbackThread,
                                                      audio_output_flags_t flags,
                                                      const Timeout& timeout,
                                                      size_t frameCountToBeReady,
-                                                     float speed,
-                                                     float volume,
-                                                     bool muted)
-    : AfPlaybackCommon(*this, *playbackThread, volume, muted,
+                                                     float speed)
+    : AfPlaybackCommon(*this, *playbackThread,
                        AUDIO_ATTRIBUTES_INITIALIZER,
                        audioServerAttributionSource(getpid()),
                        /* isOffloadOrMmap= */ false,
@@ -2667,7 +2657,7 @@ PatchTrack::PatchTrack(IAfPlaybackThread* playbackThread,
               buffer, bufferSize, nullptr /* sharedBuffer */,
               AUDIO_SESSION_NONE, getpid(), audioServerAttributionSource(getpid()), flags,
               TYPE_PATCH, AUDIO_PORT_HANDLE_NONE, frameCountToBeReady, speed,
-              false /*isSpatialized*/, false /*isBitPerfect*/, volume, muted),
+              false /*isSpatialized*/, false /*isBitPerfect*/),
         PatchTrackBase(mCblk ? new AudioTrackClientProxy(mCblk, mBuffer, frameCount, mFrameSize,
                         true /*clientInServer*/) : nullptr,
                        playbackThread, timeout)
@@ -2680,6 +2670,9 @@ PatchTrack::PatchTrack(IAfPlaybackThread* playbackThread,
                 /* .mFallbackMode = */ AUDIO_TIMESTRETCH_FALLBACK_FAIL
         });
     }
+    // for now the secondary patch tracks contain the unattenuated volume and is unmuted.
+    // TODO(b/388241142): use volume capture rules to forward the mute state to its patch tracks
+    setPortVolume(1.f);
     ALOGV("%s(%d): sampleRate %d mPeerTimeout %d.%03d sec",
                                       __func__, mId, sampleRate,
                                       (int)mPeerTimeout.tv_sec,
@@ -2790,6 +2783,12 @@ void PatchTrack::releaseBuffer(Proxy::Buffer* buffer)
     }
 }
 
+void PatchTrack::setPlaybackRate(const AudioPlaybackRate& playbackRate) {
+    if (mProxy != nullptr) {
+        sp<AudioTrackClientProxy>::cast(mProxy)->setPlaybackRate(playbackRate);
+    }
+}
+
 void PatchTrack::restartIfDisabled()
 {
     if (android_atomic_and(~CBLK_DISABLED, &mCblk->mFlags) & CBLK_DISABLED) {
@@ -3543,7 +3542,7 @@ sp<StreamInHalInterface> PassthruPatchRecord::obtainStream(
     if (!*thread) return nullptr;
     auto* const recordThread = (*thread)->asIAfRecordThread().get();
     audio_utils::lock_guard _l(recordThread->mutex());
-    return recordThread->getInput() ? recordThread->getInput()->stream : nullptr;
+    return recordThread->getInput_l() ? recordThread->getInput_l()->stream : nullptr;
 }
 
 // PatchProxyBufferProvider methods are called on DirectOutputThread
@@ -3697,6 +3696,10 @@ static AfPlaybackCommon::EnforcementLevel getOpControlEnforcementLevel(audio_usa
         return NONE;
     }
     if (hardening_strict()) {
+        // TODO (b/407607395)
+        if (usage == AUDIO_USAGE_ASSISTANCE_ACCESSIBILITY) {
+            return PARTIAL;
+        }
         return FULL;
     } else if (hardening_partial()) {
         return PARTIAL;
@@ -3705,14 +3708,12 @@ static AfPlaybackCommon::EnforcementLevel getOpControlEnforcementLevel(audio_usa
     }
 }
 
-AfPlaybackCommon::AfPlaybackCommon(IAfTrackBase& self, IAfThreadBase& thread, float volume,
-                                   bool muted, const audio_attributes_t& attr,
+AfPlaybackCommon::AfPlaybackCommon(IAfTrackBase& self, IAfThreadBase& thread,
+                                   const audio_attributes_t& attr,
                                    const AttributionSourceState& attributionSource,
                                    bool isOffloadOrMmap,
                                    bool shouldPlaybackHarden)
     : mSelf(self),
-      mMutedFromPort(muted),
-      mVolume(volume),
       mEnforcementLevel(getOpControlEnforcementLevel(attr.usage, *thread.afThreadCallback())) {
     ALOGI("creating track with enforcement level %d", mEnforcementLevel);
     using AppOpsManager::OP_CONTROL_AUDIO_PARTIAL;
@@ -3841,9 +3842,7 @@ sp<IAfMmapTrack> IAfMmapTrack::create(IAfThreadBase* thread,
           bool isOut,
           const android::content::AttributionSourceState& attributionSource,
           pid_t creatorPid,
-          audio_port_handle_t portId,
-          float volume,
-          bool muted)
+          audio_port_handle_t portId)
 {
     return sp<MmapTrack>::make(
             thread,
@@ -3855,9 +3854,7 @@ sp<IAfMmapTrack> IAfMmapTrack::create(IAfThreadBase* thread,
             isOut,
             attributionSource,
             creatorPid,
-            portId,
-            volume,
-            muted);
+            portId);
 }
 
 MmapTrack::MmapTrack(IAfThreadBase* thread,
@@ -3869,11 +3866,9 @@ MmapTrack::MmapTrack(IAfThreadBase* thread,
         bool isOut,
         const AttributionSourceState& attributionSource,
         pid_t creatorPid,
-        audio_port_handle_t portId,
-        float volume,
-        bool muted)
+        audio_port_handle_t portId)
     :   AfPlaybackCommon(*this, *thread,
-                         volume, muted, attr, attributionSource, /* isOffloadOrMmap */ true),
+                         attr, attributionSource, /* isOffloadOrMmap */ true),
         TrackBase(thread, NULL, attr, sampleRate, format,
                   channelMask, (size_t)0 /* frameCount */,
                   nullptr /* buffer */, (size_t)0 /* bufferSize */,
@@ -3889,12 +3884,6 @@ MmapTrack::MmapTrack(IAfThreadBase* thread,
 {
     // Once this item is logged by the server, the client can add properties.
     mTrackMetrics.logConstructor(creatorPid, uid(), id());
-    if (isOut && (attr.usage == AUDIO_USAGE_CALL_ASSISTANT
-            || attr.usage == AUDIO_USAGE_VIRTUAL_SOURCE)) {
-        // Audio patch and call assistant volume are always max
-        setPortVolume(1.0f);
-        setPortMute(false);
-    }
 }
 
 MmapTrack::~MmapTrack()
diff --git a/services/audioflinger/datapath/AudioHwDevice.cpp b/services/audioflinger/datapath/AudioHwDevice.cpp
index c2e538cba0..753674f118 100644
--- a/services/audioflinger/datapath/AudioHwDevice.cpp
+++ b/services/audioflinger/datapath/AudioHwDevice.cpp
@@ -44,7 +44,8 @@ status_t AudioHwDevice::openOutputStream(
         audio_output_flags_t *flags,
         struct audio_config *config,
         const char *address,
-        const std::vector<playback_track_metadata_v7_t>& sourceMetadata)
+        const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+        int32_t mixPortHalId)
 {
 
     struct audio_config originalConfig = *config;
@@ -54,7 +55,7 @@ status_t AudioHwDevice::openOutputStream(
     ALOGV("openOutputStream(), try sampleRate %d, format %#x, channelMask %#x", config->sample_rate,
             config->format, config->channel_mask);
     status_t status = outputStream->open(handle, deviceType, config, flags, address,
-                                        sourceMetadata);
+                                         sourceMetadata, mixPortHalId);
 
     if (status != NO_ERROR) {
         delete outputStream;
@@ -75,7 +76,7 @@ status_t AudioHwDevice::openOutputStream(
             if (SPDIFEncoder::isFormatSupported(originalConfig.format)) {
                 outputStream = new SpdifStreamOut(this, originalConfig.format);
                 status = outputStream->open(handle, deviceType, &originalConfig, flags, address,
-                                            sourceMetadata);
+                                            sourceMetadata, mixPortHalId);
                 if (status != NO_ERROR) {
                     ALOGE("ERROR - openOutputStream(), SPDIF open returned %d",
                         status);
@@ -108,7 +109,8 @@ status_t AudioHwDevice::openInputStream(
         const char *address,
         audio_source_t source,
         audio_devices_t outputDevice,
-        const char *outputDeviceAddress) {
+        const char *outputDeviceAddress,
+        int32_t mixPortHalId) {
 
     struct audio_config originalConfig = *config;
     auto inputStream = new AudioStreamIn(this, flags);
@@ -117,7 +119,7 @@ status_t AudioHwDevice::openInputStream(
     ALOGV("openInputStream(), try sampleRate %d, format %#x, channelMask %#x", config->sample_rate,
             config->format, config->channel_mask);
     status_t status = inputStream->open(handle, deviceType, config, address, source, outputDevice,
-                                        outputDeviceAddress);
+                                        outputDeviceAddress, mixPortHalId);
 
     // If the input could not be opened with the requested parameters and we can handle the
     // conversion internally, try to open again with the proposed parameters.
@@ -130,7 +132,7 @@ status_t AudioHwDevice::openInputStream(
         // FIXME describe the change proposed by HAL (save old values so we can log them here)
         ALOGV("openInputStream() reopening with proposed sampling rate and channel mask");
         status = inputStream->open(handle, deviceType, config, address, source,
-                outputDevice, outputDeviceAddress);
+                outputDevice, outputDeviceAddress, mixPortHalId);
         // FIXME log this new status; HAL should not propose any further changes
         if (status != NO_ERROR) {
             delete inputStream;
@@ -154,7 +156,7 @@ status_t AudioHwDevice::openInputStream(
             if (SPDIFDecoder::isFormatSupported(originalConfig.format)) {
                 inputStream = new SpdifStreamIn(this, flags, originalConfig.format);
                 status = inputStream->open(handle, deviceType, &originalConfig, address, source,
-                        outputDevice, outputDeviceAddress);
+                        outputDevice, outputDeviceAddress, mixPortHalId);
                 if (status != NO_ERROR) {
                     ALOGE("ERROR - openInputStream(), SPDIF open returned %d",
                         status);
@@ -201,8 +203,9 @@ int32_t AudioHwDevice::getAAudioHardwareBurstMinUsec() const {
 }
 
 status_t AudioHwDevice::getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                        struct audio_port_v7 *mixPort) const {
-    return mHwDevice->getAudioMixPort(devicePort, mixPort);
+                                        struct audio_port_v7 *mixPort,
+                                        int32_t mixPortHalId) const {
+    return mHwDevice->getAudioMixPort(devicePort, mixPort, mixPortHalId);
 }
 
 
diff --git a/services/audioflinger/datapath/AudioHwDevice.h b/services/audioflinger/datapath/AudioHwDevice.h
index 6a35b9176c..ca6f1cc7f9 100644
--- a/services/audioflinger/datapath/AudioHwDevice.h
+++ b/services/audioflinger/datapath/AudioHwDevice.h
@@ -88,7 +88,8 @@ public:
             audio_output_flags_t *flags,
             struct audio_config *config,
             const char *address,
-            const std::vector<playback_track_metadata_v7_t>& sourceMetadata);
+            const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+            int32_t mixPortHalId);
 
     status_t openInputStream(
             AudioStreamIn **ppStreamIn,
@@ -99,7 +100,8 @@ public:
             const char *address,
             audio_source_t source,
             audio_devices_t outputDevice,
-            const char *outputDeviceAddress);
+            const char *outputDeviceAddress,
+            int32_t mixPortHalId);
 
     [[nodiscard]] bool supportsAudioPatches() const;
 
@@ -114,7 +116,8 @@ public:
     [[nodiscard]] int32_t getAAudioHardwareBurstMinUsec() const;
 
     [[nodiscard]] status_t getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                           struct audio_port_v7 *mixPort) const;
+                                           struct audio_port_v7 *mixPort,
+                                           int32_t mixPortHalId) const;
 
 private:
     const audio_module_handle_t mHandle;
diff --git a/services/audioflinger/datapath/AudioStreamIn.cpp b/services/audioflinger/datapath/AudioStreamIn.cpp
index 165ac255ec..f6c50acedc 100644
--- a/services/audioflinger/datapath/AudioStreamIn.cpp
+++ b/services/audioflinger/datapath/AudioStreamIn.cpp
@@ -78,7 +78,8 @@ status_t AudioStreamIn::open(
         const char *address,
         audio_source_t source,
         audio_devices_t outputDevice,
-        const char *outputDeviceAddress)
+        const char *outputDeviceAddress,
+        int32_t mixPortHalId)
 {
     sp<StreamInHalInterface> inStream;
 
@@ -91,7 +92,8 @@ status_t AudioStreamIn::open(
             source,
             outputDevice,
             outputDeviceAddress,
-            &inStream);
+            &inStream,
+            mixPortHalId);
     ALOGV("AudioStreamIn::open(), HAL returned stream %p, sampleRate %d, format %#x,"
             " channelMask %#x, status %d", inStream.get(), config->sample_rate, config->format,
             config->channel_mask, status);
diff --git a/services/audioflinger/datapath/AudioStreamIn.h b/services/audioflinger/datapath/AudioStreamIn.h
index 6d1c6a7f88..19bca9739f 100644
--- a/services/audioflinger/datapath/AudioStreamIn.h
+++ b/services/audioflinger/datapath/AudioStreamIn.h
@@ -51,7 +51,8 @@ public:
             const char *address,
             audio_source_t source,
             audio_devices_t outputDevice,
-            const char *outputDeviceAddress);
+            const char *outputDeviceAddress,
+            int32_t mixPortHalId);
 
     ~AudioStreamIn() override;
 
diff --git a/services/audioflinger/datapath/AudioStreamOut.cpp b/services/audioflinger/datapath/AudioStreamOut.cpp
index 7aadda3953..f8250e98a8 100644
--- a/services/audioflinger/datapath/AudioStreamOut.cpp
+++ b/services/audioflinger/datapath/AudioStreamOut.cpp
@@ -94,7 +94,8 @@ status_t AudioStreamOut::open(
         struct audio_config *config,
         audio_output_flags_t *flagsPtr,
         const char *address,
-        const std::vector<playback_track_metadata_v7_t>& sourceMetadata)
+        const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+        int32_t mixPortHalId)
 {
     sp<StreamOutHalInterface> outStream;
 
@@ -110,7 +111,8 @@ status_t AudioStreamOut::open(
             config,
             address,
             &outStream,
-            sourceMetadata);
+            sourceMetadata,
+            mixPortHalId);
     ALOGV("AudioStreamOut::open(), HAL returned stream %p, sampleRate %d, format %#x,"
             " channelMask %#x, status %d", outStream.get(), config->sample_rate, config->format,
             config->channel_mask, status);
diff --git a/services/audioflinger/datapath/AudioStreamOut.h b/services/audioflinger/datapath/AudioStreamOut.h
index 1857099aa6..ce1af6ffdb 100644
--- a/services/audioflinger/datapath/AudioStreamOut.h
+++ b/services/audioflinger/datapath/AudioStreamOut.h
@@ -49,7 +49,8 @@ public:
             struct audio_config *config,
             audio_output_flags_t *flagsPtr,
             const char *address,
-            const std::vector<playback_track_metadata_v7_t>& sourceMetadata);
+            const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+            int32_t mixPortHalId);
 
     virtual ~AudioStreamOut();
 
diff --git a/services/audioflinger/datapath/SpdifStreamIn.cpp b/services/audioflinger/datapath/SpdifStreamIn.cpp
index 0090bc5331..806595ddc3 100644
--- a/services/audioflinger/datapath/SpdifStreamIn.cpp
+++ b/services/audioflinger/datapath/SpdifStreamIn.cpp
@@ -47,7 +47,8 @@ status_t SpdifStreamIn::open(
         const char *address,
         audio_source_t source,
         audio_devices_t outputDevice,
-        const char* outputDeviceAddress)
+        const char* outputDeviceAddress,
+        int32_t mixPortHalId)
 {
     struct audio_config customConfig = *config;
 
@@ -79,7 +80,8 @@ status_t SpdifStreamIn::open(
             address,
             source,
             outputDevice,
-            outputDeviceAddress);
+            outputDeviceAddress,
+            mixPortHalId);
 
     // reset config back to whatever is returned by HAL
     config->sample_rate = customConfig.sample_rate;
diff --git a/services/audioflinger/datapath/SpdifStreamIn.h b/services/audioflinger/datapath/SpdifStreamIn.h
index 78832eebed..9040afe131 100644
--- a/services/audioflinger/datapath/SpdifStreamIn.h
+++ b/services/audioflinger/datapath/SpdifStreamIn.h
@@ -46,7 +46,8 @@ public:
             const char *address,
             audio_source_t source,
             audio_devices_t outputDevice,
-            const char* outputDeviceAddress) override;
+            const char* outputDeviceAddress,
+            int32_t mixPortHalId) override;
 
     /**
     * Read audio buffer from driver. If at least one frame was read successfully prior to the error,
diff --git a/services/audioflinger/datapath/SpdifStreamOut.cpp b/services/audioflinger/datapath/SpdifStreamOut.cpp
index a565955a79..aeda2b3ebe 100644
--- a/services/audioflinger/datapath/SpdifStreamOut.cpp
+++ b/services/audioflinger/datapath/SpdifStreamOut.cpp
@@ -45,7 +45,8 @@ status_t SpdifStreamOut::open(
         struct audio_config *config,
         audio_output_flags_t *flags,
         const char *address,
-        const std::vector<playback_track_metadata_v7_t>& sourceMetadata)
+        const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+        int32_t mixPortHalId)
 {
     struct audio_config customConfig = *config;
 
@@ -79,7 +80,8 @@ status_t SpdifStreamOut::open(
             &customConfig,
             flags,
             address,
-            sourceMetadata);
+            sourceMetadata,
+            mixPortHalId);
 
     // reset config back to whatever is returned by HAL
     config->sample_rate = customConfig.sample_rate;
diff --git a/services/audioflinger/datapath/SpdifStreamOut.h b/services/audioflinger/datapath/SpdifStreamOut.h
index 3241d6f9c8..ecad91588b 100644
--- a/services/audioflinger/datapath/SpdifStreamOut.h
+++ b/services/audioflinger/datapath/SpdifStreamOut.h
@@ -44,7 +44,8 @@ public:
             struct audio_config *config,
             audio_output_flags_t *flags,
             const char *address,
-            const std::vector<playback_track_metadata_v7_t>& sourceMetadata) override;
+            const std::vector<playback_track_metadata_v7_t>& sourceMetadata,
+            int32_t mixPortHalId) override;
 
     /**
     * Write audio buffer to driver. Returns number of bytes written, or a
diff --git a/services/audioflinger/fastpath/FastCapture.cpp b/services/audioflinger/fastpath/FastCapture.cpp
index 288036dc20..fb9a7627f9 100644
--- a/services/audioflinger/fastpath/FastCapture.cpp
+++ b/services/audioflinger/fastpath/FastCapture.cpp
@@ -218,7 +218,8 @@ void FastCapture::onWork()
                 //       or with a lot more work the control block could be shared by all clients.
                 const int32_t rear = cblk->u.mStreaming.mRear;
                 android_atomic_release_store(framesWritten + rear, &cblk->u.mStreaming.mRear);
-                cblk->mServer += framesWritten;
+                (void)__builtin_add_overflow(
+                        cblk->mServer, framesWritten, &cblk->mServer);
                 const int32_t old = android_atomic_or(CBLK_FUTEX_WAKE, &cblk->mFutex);
                 if (!(old & CBLK_FUTEX_WAKE)) {
                     // client is never in server process, so don't use FUTEX_WAKE_PRIVATE
diff --git a/services/audioflinger/fastpath/FastCapture.h b/services/audioflinger/fastpath/FastCapture.h
index b565216a34..9f4b37d2d7 100644
--- a/services/audioflinger/fastpath/FastCapture.h
+++ b/services/audioflinger/fastpath/FastCapture.h
@@ -58,7 +58,7 @@ private:
     NBAIO_Format        mFormat = Format_Invalid;
     unsigned            mSampleRate = 0;
     FastCaptureDumpState mDummyFastCaptureDumpState;
-    uint32_t            mTotalNativeFramesRead = 0; // copied to dumpState->mFramesRead
+    int64_t             mTotalNativeFramesRead = 0; // copied to dumpState->mFramesRead
 
 };  // class FastCapture
 
diff --git a/services/audioflinger/fastpath/StateQueue.cpp b/services/audioflinger/fastpath/StateQueue.cpp
index e896d29207..89ac899649 100644
--- a/services/audioflinger/fastpath/StateQueue.cpp
+++ b/services/audioflinger/fastpath/StateQueue.cpp
@@ -19,7 +19,6 @@
 
 #include "Configuration.h"
 #include <time.h>
-#include <cutils/atomic.h>
 #include <utils/Log.h>
 #include "StateQueue.h"
 
@@ -42,7 +41,7 @@ void StateQueueMutatorDump::dump(int fd)
 
 template<typename T> const T* StateQueue<T>::poll()
 {
-    const T *next = (const T *) atomic_load_explicit(&mNext, memory_order_acquire);
+    const T *next = (const T *) mNext.load(std::memory_order_acquire);
 
     if (next != mCurrent) {
         mAck = next;    // no additional barrier needed
@@ -125,7 +124,7 @@ template<typename T> bool StateQueue<T>::push(StateQueue<T>::block_t block)
         }
 
         // publish
-        atomic_store_explicit(&mNext, (uintptr_t)mMutating, memory_order_release);
+        mNext.store((uintptr_t)mMutating, std::memory_order_release);
         mExpecting = mMutating;
 
         // copy with circular wraparound
diff --git a/services/audioflinger/fastpath/StateQueue.h b/services/audioflinger/fastpath/StateQueue.h
index 36d986ba83..f9e20e5843 100644
--- a/services/audioflinger/fastpath/StateQueue.h
+++ b/services/audioflinger/fastpath/StateQueue.h
@@ -16,7 +16,7 @@
 
 #pragma once
 
-#include <stdatomic.h>
+#include <atomic>
 
 // The state queue template class was originally driven by this use case / requirements:
 //  There are two threads: a fast mixer, and a normal mixer, and they share state.
@@ -185,7 +185,7 @@ private:
     T                 mStates[kN];      // written by mutator, read by observer
 
     // "volatile" is meaningless with SMP, but here it indicates that we're using atomic ops
-    atomic_uintptr_t  mNext{}; // written by mutator to advance next, read by observer
+    std::atomic<uintptr_t> mNext{};    // written by mutator to advance next, read by observer
     volatile const T* mAck = nullptr;  // written by observer to acknowledge advance of next,
                                        // read by mutator
 
diff --git a/services/audioparameterparser/android.hardware.audio.parameter_parser.example_service.rc b/services/audioparameterparser/android.hardware.audio.parameter_parser.example_service.rc
index b6aca5c936..bc30f8cce3 100644
--- a/services/audioparameterparser/android.hardware.audio.parameter_parser.example_service.rc
+++ b/services/audioparameterparser/android.hardware.audio.parameter_parser.example_service.rc
@@ -1,5 +1,5 @@
 service audio_parameter_parser_service /system_ext/bin/hw/android.hardware.audio.parameter_parser.example_service
-    class core
+    class hal
     user audioserver
     group media
     ioprio rt 4
diff --git a/services/audiopolicy/Android.bp b/services/audiopolicy/Android.bp
index 66ba7e25e7..33eaba6620 100644
--- a/services/audiopolicy/Android.bp
+++ b/services/audiopolicy/Android.bp
@@ -13,3 +13,58 @@ cc_library_headers {
     host_supported: true,
     export_include_dirs: ["."],
 }
+
+prebuilt_etc {
+    name: "aosp_audio_policy_volumes.xml",
+    vendor: true,
+    filename_from_src: true,
+    src: "//frameworks/av/services/audiopolicy/config:audio_policy_volumes",
+    enabled: select(soong_config_variable("frameworks_av", "use_aosp_audio_policy_volumes"), {
+        true: true,
+        default: false,
+    }),
+}
+
+prebuilt_etc {
+    name: "aosp_default_volume_tables.xml",
+    vendor: true,
+    filename_from_src: true,
+    src: "//frameworks/av/services/audiopolicy/config:default_volume_tables",
+    enabled: select(soong_config_variable("frameworks_av", "use_aosp_default_volume_tables"), {
+        true: true,
+        default: false,
+    }),
+}
+
+prebuilt_etc {
+    name: "aosp_r_submix_audio_policy_configuration.xml",
+    vendor: true,
+    filename_from_src: true,
+    src: "//frameworks/av/services/audiopolicy/config:r_submix_audio_policy_configuration",
+    enabled: select(soong_config_variable("frameworks_av", "use_aosp_r_submix_audio_policy_configuration"), {
+        true: true,
+        default: false,
+    }),
+}
+
+prebuilt_etc {
+    name: "aosp_surround_sound_configuration_5_0.xml",
+    vendor: true,
+    filename_from_src: true,
+    src: "//frameworks/av/services/audiopolicy/config:surround_sound_configuration_5_0",
+    enabled: select(soong_config_variable("frameworks_av", "use_aosp_surround_sound_configuration_5_0"), {
+        true: true,
+        default: false,
+    }),
+}
+
+prebuilt_etc {
+    name: "aosp_usb_audio_policy_configuration.xml",
+    vendor: true,
+    filename_from_src: true,
+    src: "//frameworks/av/services/audiopolicy/config:usb_audio_policy_configuration",
+    enabled: select(soong_config_variable("frameworks_av", "use_aosp_usb_audio_policy_configuration"), {
+        true: true,
+        default: false,
+    }),
+}
diff --git a/services/audiopolicy/AudioPolicyInterface.h b/services/audiopolicy/AudioPolicyInterface.h
index 4f26aca56e..29fb74acf0 100644
--- a/services/audiopolicy/AudioPolicyInterface.h
+++ b/services/audiopolicy/AudioPolicyInterface.h
@@ -152,12 +152,11 @@ public:
                                       std::vector<audio_io_handle_t> *secondaryOutputs,
                                       output_type_t *outputType,
                                       bool *isSpatialized,
-                                      bool *isBitPerfect,
-                                      float *volume,
-                                      bool *muted) = 0;
+                                      bool *isBitPerfect) = 0;
     // indicates to the audio policy manager that the output starts being used by corresponding
     // stream.
-    virtual status_t startOutput(audio_port_handle_t portId) = 0;
+    virtual status_t startOutput(
+            audio_port_handle_t portId, float* volume, bool* muted) = 0;
     // indicates to the audio policy manager that the output stops being used by corresponding
     // stream.
     virtual status_t stopOutput(audio_port_handle_t portId) = 0;
@@ -235,6 +234,65 @@ public:
     virtual status_t getMinVolumeIndexForAttributes(const audio_attributes_t &attr,
                                                     int &index) = 0;
 
+    /**
+    * Set the volume index for a given volume group and device.
+    *
+    * @param groupId the volume group id
+    * @param index the volume index to set
+    * @param muted state of the volume group
+    * @param device the device to set the volume index for
+    * @return NO_ERROR if the call is successful, otherwise an error code
+    */
+    virtual status_t setVolumeIndexForGroup(volume_group_t groupId, int index,
+            bool muted, audio_devices_t device) = 0;
+
+    /**
+     * Get the volume index for a given volume group and device.
+     *
+     * @param groupId the volume group id
+     * @param index the volume index to get
+     * @param device the device to get the volume index for
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    virtual status_t getVolumeIndexForGroup(volume_group_t groupId, int &index,
+            audio_devices_t device) = 0;
+
+    /**
+     * Get the maximum volume index for a given volume group
+     *
+     * @param groupId the volume group id
+     * @param index the max volume index to get
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    virtual status_t getMaxVolumeIndexForGroup(volume_group_t groupId, int &index) = 0;
+
+    /**
+     * Set the maximum volume index for a given volume group
+     *
+     * @param groupId the volume group id
+     * @param index the max volume index to set
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    virtual status_t setMaxVolumeIndexForGroup(volume_group_t groupId, int index) = 0;
+
+    /**
+     * Get the minimum volume index for a given volume group.
+     *
+     * @param groupId
+     * @param index the min volume index to get
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    virtual status_t getMinVolumeIndexForGroup(volume_group_t groupId, int &index) = 0;
+
+    /**
+     * Set the minimum volume index for a given volume group.
+     *
+     * @param groupId
+     * @param index the min volume index to set
+     * @return NO_ERROR if the call is successful, otherwise an error code
+     */
+    virtual status_t setMinVolumeIndexForGroup(volume_group_t groupId, int index) = 0;
+
     // return the strategy corresponding to a given stream type
     virtual product_strategy_t getStrategyForStream(audio_stream_type_t stream) = 0;
 
@@ -502,7 +560,8 @@ public:
                                 const sp<DeviceDescriptorBase>& device,
                                 uint32_t *latencyMs,
                                 audio_output_flags_t *flags,
-                                audio_attributes_t audioAttributes) = 0;
+                                audio_attributes_t audioAttributes,
+                                int32_t mixPortHalId) = 0;
     // creates a special output that is duplicated to the two outputs passed as arguments.
     // The duplication is performed by a special mixer thread in the AudioFlinger.
     virtual audio_io_handle_t openDuplicateOutput(audio_io_handle_t output1,
@@ -527,7 +586,8 @@ public:
                                audio_devices_t *device,
                                const String8& address,
                                audio_source_t source,
-                               audio_input_flags_t flags) = 0;
+                               audio_input_flags_t flags,
+                               int32_t mixPortHalId) = 0;
     // closes an audio input
     virtual status_t closeInput(audio_io_handle_t input) = 0;
     //
@@ -627,8 +687,11 @@ public:
     virtual status_t invalidateTracks(const std::vector<audio_port_handle_t>& portIds) = 0;
 
     // Get the attributes of the mix port when connecting to the given device port.
+    // If `mixPortHalId` is not `AUDIO_PORT_HANDLE_NONE`, it will be used to determine
+    // the mix port. Otherwise, `mixPort->ext.mix.handle` will be used.
     virtual status_t getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                     struct audio_port_v7 *mixPort) = 0;
+                                     struct audio_port_v7 *mixPort,
+                                     int32_t mixPortHalId) = 0;
 
     virtual status_t setTracksInternalMute(
             const std::vector<media::TrackInternalMuteInfo>& tracksInternalMute) = 0;
diff --git a/services/audiopolicy/TEST_MAPPING b/services/audiopolicy/TEST_MAPPING
index cf1a771bfb..6668039958 100644
--- a/services/audiopolicy/TEST_MAPPING
+++ b/services/audiopolicy/TEST_MAPPING
@@ -26,6 +26,18 @@
         },
         {
           "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_LOW_LATENCY__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING__OUTPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__INPUT"
+        },
+        {
+          "include-filter": "android.nativemedia.aaudio.AAudioTests#AAudioBasic_TestAAudioBasic_TestBasic_POWER_SAVING_OFFLOAD__OUTPUT"
         }
       ]
     }
diff --git a/services/audiopolicy/audio_policy_config_vendor_1.mk b/services/audiopolicy/audio_policy_config_vendor_1.mk
new file mode 100644
index 0000000000..b8388edf0e
--- /dev/null
+++ b/services/audiopolicy/audio_policy_config_vendor_1.mk
@@ -0,0 +1,14 @@
+$(call soong_config_set_bool,frameworks_av,use_aosp_audio_effects_config,true)
+$(call soong_config_set_bool,frameworks_av,use_aosp_audio_policy_volumes,true)
+$(call soong_config_set_bool,frameworks_av,use_aosp_default_volume_tables,true)
+$(call soong_config_set_bool,frameworks_av,use_aosp_r_submix_audio_policy_configuration,true)
+$(call soong_config_set_bool,frameworks_av,use_aosp_surround_sound_configuration_5_0,true)
+$(call soong_config_set_bool,frameworks_av,use_aosp_usb_audio_policy_configuration,true)
+
+PRODUCT_PACKAGES += \
+    aosp_audio_effects.xml \
+    aosp_audio_policy_volumes.xml \
+    aosp_default_volume_tables.xml \
+    aosp_r_submix_audio_policy_configuration.xml \
+    aosp_surround_sound_configuration_5_0.xml \
+    aosp_usb_audio_policy_configuration.xml
diff --git a/services/audiopolicy/common/include/policy.h b/services/audiopolicy/common/include/policy.h
index 170329a91c..43f5a40873 100644
--- a/services/audiopolicy/common/include/policy.h
+++ b/services/audiopolicy/common/include/policy.h
@@ -31,9 +31,6 @@ using StreamTypeVector = std::vector<audio_stream_type_t>;
 #define AUDIO_ENUM_QUOTE(x) #x
 #define AUDIO_ENUM_STRINGIFY(x) AUDIO_ENUM_QUOTE(x)
 #define AUDIO_DEFINE_ENUM_SYMBOL_V(symbol, value) symbol = value,
-#define AUDIO_DEFINE_STRINGIFY_CASE_V(symbol, _) case symbol: return AUDIO_ENUM_STRINGIFY(symbol);
-#define AUDIO_DEFINE_PARSE_CASE_V(symbol, _) \
-    if (strcmp(s, AUDIO_ENUM_STRINGIFY(symbol)) == 0) { *t = symbol; return true; } else
 #define AUDIO_DEFINE_MAP_ENTRY_V(symbol, _) { AUDIO_ENUM_STRINGIFY(symbol), symbol },
 
 /**
@@ -60,17 +57,6 @@ enum legacy_strategy {
     AUDIO_LEGACY_STRATEGY_LIST_DEF(AUDIO_DEFINE_ENUM_SYMBOL_V)
 };
 
-inline const char* legacy_strategy_to_string(legacy_strategy t) {
-    switch (t) {
-    AUDIO_LEGACY_STRATEGY_LIST_DEF(AUDIO_DEFINE_STRINGIFY_CASE_V)
-    }
-    return "";
-}
-
-inline bool legacy_strategy_from_string(const char* s, legacy_strategy* t) {
-    AUDIO_LEGACY_STRATEGY_LIST_DEF(AUDIO_DEFINE_PARSE_CASE_V)
-    return false;
-}
 
 namespace audio_policy {
 
@@ -87,8 +73,6 @@ inline std::vector<legacy_strategy_map> getLegacyStrategyMap() {
 #undef AUDIO_LEGACY_STRATEGY_LIST_DEF
 
 #undef AUDIO_DEFINE_MAP_ENTRY_V
-#undef AUDIO_DEFINE_PARSE_CASE_V
-#undef AUDIO_DEFINE_STRINGIFY_CASE_V
 #undef AUDIO_DEFINE_ENUM_SYMBOL_V
 #undef AUDIO_ENUM_STRINGIFY
 #undef AUDIO_ENUM_QUOTE
diff --git a/services/audiopolicy/common/managerdefinitions/include/AudioInputDescriptor.h b/services/audiopolicy/common/managerdefinitions/include/AudioInputDescriptor.h
index 0f2fe240b4..d87bf56c61 100644
--- a/services/audiopolicy/common/managerdefinitions/include/AudioInputDescriptor.h
+++ b/services/audiopolicy/common/managerdefinitions/include/AudioInputDescriptor.h
@@ -53,7 +53,9 @@ public:
     sp<DeviceDescriptor> getDevice() const { return mDevice; }
     void setDevice(const sp<DeviceDescriptor> &device) { mDevice = device; }
     DeviceVector supportedDevices() const  {
-        return mProfile != nullptr ? mProfile->getSupportedDevices() :  DeviceVector(); }
+        return mProfile != nullptr ? mProfile->getSupportedDevices() : DeviceVector(); }
+    DeviceVector routableDevices() const  {
+        return mProfile != nullptr ? mProfile->getRoutableDevices() : DeviceVector(); }
 
     void dump(String8 *dst, int spaces, const char* extraInfo) const override;
 
diff --git a/services/audiopolicy/common/managerdefinitions/include/AudioOutputDescriptor.h b/services/audiopolicy/common/managerdefinitions/include/AudioOutputDescriptor.h
index 9bceee7a7f..449beb19ce 100644
--- a/services/audiopolicy/common/managerdefinitions/include/AudioOutputDescriptor.h
+++ b/services/audiopolicy/common/managerdefinitions/include/AudioOutputDescriptor.h
@@ -162,6 +162,7 @@ public:
     virtual DeviceVector devices() const { return mDevices; }
     bool sharesHwModuleWith(const sp<AudioOutputDescriptor>& outputDesc);
     virtual DeviceVector supportedDevices() const  { return mDevices; }
+    virtual DeviceVector routableDevices() const  { return mDevices; }
     virtual bool isDuplicated() const { return false; }
     virtual uint32_t latency() { return 0; }
     virtual bool isFixedVolume(const DeviceTypeSet& deviceTypes);
@@ -304,6 +305,10 @@ public:
         return false;
     }
 
+    sp<TrackClientDescriptor> getHighestPriorityClientForVolumeSource(
+            VolumeSource vs, bool activeOnly = false) const;
+    bool canSetVolumeForVolumeSource(VolumeSource vs) const;
+
     TrackClientVector clientsList(bool activeOnly = false,
                                   product_strategy_t strategy = PRODUCT_STRATEGY_NONE,
                                   bool preferredDeviceOnly = false) const;
@@ -380,6 +385,7 @@ public:
     void setDevices(const DeviceVector &devices);
     bool sharesHwModuleWith(const sp<SwAudioOutputDescriptor>& outputDesc);
     virtual DeviceVector supportedDevices() const;
+    virtual DeviceVector routableDevices() const;
     virtual bool devicesSupportEncodedFormats(const DeviceTypeSet& deviceTypes);
     virtual bool containsSingleDeviceSupportingEncodedFormats(
             const sp<DeviceDescriptor>& device) const;
@@ -449,6 +455,14 @@ public:
      */
     bool supportsDevice(const sp<DeviceDescriptor> &device) const;
 
+    /**
+     * @brief routesToDevice
+     * @param device to be checked against
+     * @return true if the device is routable from/to this profile.
+     *         false otherwise
+     */
+    bool routesToDevice(const sp<DeviceDescriptor> &device) const;
+
     /**
      * @brief supportsAllDevices
      * @param devices to be checked against
@@ -458,6 +472,14 @@ public:
      */
     bool supportsAllDevices(const DeviceVector &devices) const;
 
+    /**
+     * @brief routesToAllDevices
+     * @param devices to be checked against
+     * @return true if all devices are routable to this profile
+     *         false otherwise
+     */
+    bool routesToAllDevices(const DeviceVector &devices) const;
+
     /**
      * @brief supportsAtLeastOne checks if any device in devices is currently supported
      * @param devices to be checked against
@@ -467,6 +489,14 @@ public:
      */
     bool supportsAtLeastOne(const DeviceVector &devices) const;
 
+    /**
+     * @brief routesToAtLeastOne checks if any device in devices is currently routable
+     * @param devices to be checked against
+     * @return true if any device is routable to this profile
+     *         false otherwise
+     */
+    bool routesToAtLeastOne(const DeviceVector &devices) const;
+
     /**
      * @brief supportsDevicesForPlayback
      * @param devices to be checked against
@@ -475,6 +505,14 @@ public:
      */
     bool supportsDevicesForPlayback(const DeviceVector &devices) const;
 
+    /**
+     * @brief routesToDevicesForPlayback
+     * @param devices to be checked against
+     * @return true if the devices is a routable combo for playback
+     *         false otherwise
+     */
+    bool routesToDevicesForPlayback(const DeviceVector &devices) const;
+
     /**
      * @brief filterSupportedDevices takes a vector of devices and filters them according to the
      * device supported by this output (the profile from which this output derives from)
@@ -484,6 +522,14 @@ public:
      */
     DeviceVector filterSupportedDevices(const DeviceVector &devices) const;
 
+    /**
+     * @brief filterRoutableDevices takes a vector of devices and filters them according to the
+     * device routable to this output (the profile from which this output derives from)
+     * @param devices reference device vector to be filtered
+     * @return vector of devices filtered from the routable devices of this output
+     */
+    DeviceVector filterRoutableDevices(const DeviceVector &devices) const;
+
     uint32_t getRecommendedMuteDurationMs() const override;
 
     void setTracksInvalidatedStatusByStrategy(product_strategy_t strategy);
@@ -496,6 +542,10 @@ public:
         return (getFlags().output & AUDIO_OUTPUT_FLAG_BIT_PERFECT) != AUDIO_OUTPUT_FLAG_NONE;
     }
 
+    bool isOffload() const {
+        return (getFlags().output & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != AUDIO_OUTPUT_FLAG_NONE;
+    }
+
     /**
      * Return true if there is any client with the same usage active on the given device.
      * When the given device is null, return true if there is any client active.
diff --git a/services/audiopolicy/common/managerdefinitions/include/DeviceDescriptor.h b/services/audiopolicy/common/managerdefinitions/include/DeviceDescriptor.h
index 7002e63455..1a643673cf 100644
--- a/services/audiopolicy/common/managerdefinitions/include/DeviceDescriptor.h
+++ b/services/audiopolicy/common/managerdefinitions/include/DeviceDescriptor.h
@@ -25,6 +25,7 @@
 #include <cutils/config_utils.h>
 #include <system/audio.h>
 #include <system/audio_policy.h>
+#include <functional>
 
 namespace android {
 
@@ -215,6 +216,22 @@ public:
      */
     DeviceVector filter(const DeviceVector &devices) const;
 
+    /**
+     * @brief filter the devices supported by this collection with predicate
+     * @param predicate to filter in with
+     * @return a filtered DeviceVector
+     */
+    template <typename UnaryPred>
+    DeviceVector filter(UnaryPred pred) const {
+        DeviceVector filteredDevices;
+        for (const auto &device : *this) {
+            if (pred(device)) {
+                filteredDevices.add(device);
+            }
+        }
+        return filteredDevices;
+    }
+
     /**
      * @brief filter the devices supported by this collection before sending
      * then to the Engine via AudioPolicyManagerObserver interface
diff --git a/services/audiopolicy/common/managerdefinitions/include/IOProfile.h b/services/audiopolicy/common/managerdefinitions/include/IOProfile.h
index 76762f9615..e20095100d 100644
--- a/services/audiopolicy/common/managerdefinitions/include/IOProfile.h
+++ b/services/audiopolicy/common/managerdefinitions/include/IOProfile.h
@@ -19,6 +19,7 @@
 #include "DeviceDescriptor.h"
 #include "PolicyAudioPort.h"
 #include "policy.h"
+#include <com_android_media_audioserver.h>
 #include <media/AudioContainers.h>
 #include <utils/String8.h>
 #include <system/audio.h>
@@ -112,7 +113,8 @@ public:
                                              audio_channel_mask_t channelMask,
                                              audio_channel_mask_t *updatedChannelMask,
                                              // FIXME parameter type
-                                             uint32_t flags) const;
+                                             uint32_t flags,
+                                             uint32_t additionalMandatoryFlags = 0) const;
 
     /**
      * @brief areAllDevicesSupported: Checks if the given devices are supported by the IO profile.
@@ -121,6 +123,7 @@ public:
      * @return true if all devices are supported, false otherwise.
      */
     bool areAllDevicesSupported(const DeviceVector &devices) const;
+    bool areAllDevicesRoutable(const DeviceVector &devices) const;
 
     /**
      * @brief isCompatibleProfileForFlags: Checks if the IO profile is compatible with
@@ -135,6 +138,7 @@ public:
     void log();
 
     bool hasSupportedDevices() const { return !mSupportedDevices.isEmpty(); }
+    bool hasRoutableDevices() const { return !mRoutableDevices.isEmpty(); }
 
     bool supportsDeviceTypes(const DeviceTypeSet& deviceTypes) const
     {
@@ -174,6 +178,27 @@ public:
         return mSupportedDevices.contains(device);
     }
 
+    /**
+     * @brief routesToDevice
+     * @param device to be checked against
+     * @return true if the device is routable as indicated by the HAL.
+     *         false otherwise.
+     */
+    bool routesToDevice(const sp<DeviceDescriptor> &device) const
+    {
+        if (!com::android::media::audioserver::enable_strict_port_routing_checks()) {
+            return supportsDevice(device);
+        }
+
+        // If profile does not contain ID, this is most likely indicating HIDL.
+        // Return routable so as to follow the legacy behavior.
+        if (getHalId() == AUDIO_PORT_HANDLE_NONE) {
+            return supportsDevice(device);
+        }
+
+        return mRoutableDevices.contains(device);
+    }
+
     bool devicesSupportEncodedFormats(DeviceTypeSet deviceTypes) const
     {
         if (deviceTypes.empty()) {
@@ -192,6 +217,7 @@ public:
     bool containsSingleDeviceSupportingEncodedFormats(const sp<DeviceDescriptor>& device) const;
 
     void clearSupportedDevices() { mSupportedDevices.clear(); }
+    void clearRoutableDevices() { mRoutableDevices.clear(); }
     void addSupportedDevice(const sp<DeviceDescriptor> &device)
     {
         mSupportedDevices.add(device);
@@ -210,9 +236,31 @@ public:
     {
         mSupportedDevices = devices;
     }
+    void setRoutableDevices(const DeviceVector &devices)
+    {
+        mRoutableDevices = devices;
+    }
 
     const DeviceVector &getSupportedDevices() const { return mSupportedDevices; }
 
+    void addRoutableDevice(const sp<DeviceDescriptor> &device)
+    {
+        mRoutableDevices.add(device);
+    }
+
+    void removeRoutableDevice(const sp<DeviceDescriptor> &device)
+    {
+        mRoutableDevices.remove(device);
+    }
+
+    const DeviceVector &getRoutableDevices() const { return mRoutableDevices; }
+
+    void addSupportedRoutableDevice(const sp<DeviceDescriptor> &device)
+    {
+        mSupportedDevices.add(device);
+        mRoutableDevices.add(device);
+    }
+
     bool canOpenNewIo() {
         if (maxOpenCount == 0 || curOpenCount < maxOpenCount) {
             return true;
@@ -241,9 +289,19 @@ public:
 
 private:
     void refreshMixerBehaviors();
-    CompatibilityScore getFlagsCompatibleScore(uint32_t flags) const;
-
-    DeviceVector mSupportedDevices; // supported devices: this input/output can be routed from/to
+    CompatibilityScore getFlagsCompatibleScore(uint32_t flags,
+                                               uint32_t additionalMandatoryFlags = 0) const;
+
+    // supported devices: this input/output can potentially be routed from/to
+    // it is deduced by type and may end up being not necessarily routable,
+    // this is due to that `DeviceDescriptor` has the flexibility to be created
+    // before HAL connection, at which point it will find candidate/supported profiles
+    // where routability can yet be validated.
+    DeviceVector mSupportedDevices;
+
+    // routable devices as indicated via AudioRoute by the HAL, updated on device dis/connection.
+    // in pre-AIDL HAL we will assume everything is routable.
+    DeviceVector mRoutableDevices;
 
     MixerBehaviorSet mMixerBehaviors;
 };
diff --git a/services/audiopolicy/common/managerdefinitions/include/IVolumeCurves.h b/services/audiopolicy/common/managerdefinitions/include/IVolumeCurves.h
index ebfc59790b..47130966b9 100644
--- a/services/audiopolicy/common/managerdefinitions/include/IVolumeCurves.h
+++ b/services/audiopolicy/common/managerdefinitions/include/IVolumeCurves.h
@@ -34,8 +34,10 @@ public:
     virtual void addCurrentVolumeIndex(audio_devices_t device, int index) = 0;
     virtual bool canBeMuted() const = 0;
     virtual int getVolumeIndexMin() const = 0;
+    virtual int setVolumeIndexMin(int index) = 0;
     virtual int getVolumeIndex(const DeviceTypeSet& device) const = 0;
     virtual int getVolumeIndexMax() const = 0;
+    virtual int setVolumeIndexMax(int index) = 0;
     virtual float volIndexToDb(device_category device, int indexInUi) const = 0;
     virtual bool hasVolumeIndexForDevice(audio_devices_t device) const = 0;
     virtual status_t initVolume(int indexMin, int indexMax) = 0;
diff --git a/services/audiopolicy/common/managerdefinitions/src/AudioInputDescriptor.cpp b/services/audiopolicy/common/managerdefinitions/src/AudioInputDescriptor.cpp
index 5a0fd97ba5..ccbffc068e 100644
--- a/services/audiopolicy/common/managerdefinitions/src/AudioInputDescriptor.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/AudioInputDescriptor.cpp
@@ -237,7 +237,8 @@ status_t AudioInputDescriptor::open(const audio_config_t *config,
                                                   String8(mDevice->address().c_str()),
                                                   source,
                                                   static_cast<audio_input_flags_t>(
-                                                          flags & mProfile->getFlags()));
+                                                          flags & mProfile->getFlags()),
+                                                  mProfile->getHalId());
     LOG_ALWAYS_FATAL_IF(mDevice->type() != deviceType,
                         "%s openInput returned device %08x when given device %08x",
                         __FUNCTION__, mDevice->type(), deviceType);
diff --git a/services/audiopolicy/common/managerdefinitions/src/AudioOutputDescriptor.cpp b/services/audiopolicy/common/managerdefinitions/src/AudioOutputDescriptor.cpp
index c417462ed5..e7dcdfb1f8 100644
--- a/services/audiopolicy/common/managerdefinitions/src/AudioOutputDescriptor.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/AudioOutputDescriptor.cpp
@@ -246,6 +246,48 @@ TrackClientVector AudioOutputDescriptor::clientsList(bool activeOnly, product_st
     return clients;
 }
 
+sp<TrackClientDescriptor> AudioOutputDescriptor::getHighestPriorityClientForVolumeSource(
+        VolumeSource vs, bool activeOnly) const
+{
+    sp<TrackClientDescriptor> clientForVolume = nullptr;
+    for (const auto &client : getClientIterable()) {
+        if ((!activeOnly || client->active()) && (vs == client->volumeSource())) {
+            // strategies are ordered, the lowest id the highest priority
+            if (clientForVolume == nullptr || clientForVolume->strategy() > client->strategy()) {
+                clientForVolume = client;
+            }
+        }
+    }
+    return clientForVolume;
+}
+
+bool AudioOutputDescriptor::canSetVolumeForVolumeSource(android::VolumeSource vs) const {
+    if (!useHwGain()) {
+        return true;
+    }
+    auto highestPrioActiveClientForVolume =
+            getHighestPriorityClientForVolumeSource(vs, /* active= */ true);
+    if (highestPrioActiveClientForVolume == nullptr) {
+        ALOGV("%s trying to set volume for inactive volume source %d", __func__, vs);
+        return false;
+    }
+    for (const auto &client: clientsList(true /*activeOnly*/)) {
+        bool isHigherPriority = client->strategy() < highestPrioActiveClientForVolume->strategy();
+        if (isHigherPriority && (client->volumeSource() != vs)) {
+            ALOGV("%s: found higher priority client on output with \n"
+                    "Strategy=%d volumeGroup=%d attributes=%s\n"
+                    "(\nrequester:\n strategy=%d volumeGroup=%d attributes=%s)\n"
+                    " on output, bailing out", __func__, client->strategy(),
+                    client->volumeSource(), toString(client->attributes()).c_str(),
+                    highestPrioActiveClientForVolume->strategy(),
+                    highestPrioActiveClientForVolume->volumeSource(),
+                    toString(highestPrioActiveClientForVolume->attributes()).c_str());
+            return false;
+        }
+    }
+    return true;
+}
+
 size_t AudioOutputDescriptor::sameExclusivePreferredDevicesCount() const
 {
     audio_port_handle_t deviceId = AUDIO_PORT_HANDLE_NONE;
@@ -377,6 +419,19 @@ bool SwAudioOutputDescriptor::sharesHwModuleWith(
     }
 }
 
+DeviceVector SwAudioOutputDescriptor::routableDevices() const
+{
+    if (isDuplicated()) {
+        DeviceVector routableDevices = mOutput1->routableDevices();
+        routableDevices.merge(mOutput2->routableDevices());
+        return routableDevices;
+    }
+    if (mProfile != nullptr) {
+        return mProfile->getRoutableDevices();
+    }
+    return DeviceVector();
+}
+
 DeviceVector SwAudioOutputDescriptor::supportedDevices() const
 {
     if (isDuplicated()) {
@@ -395,16 +450,31 @@ bool SwAudioOutputDescriptor::supportsDevice(const sp<DeviceDescriptor> &device)
     return supportedDevices().contains(device);
 }
 
+bool SwAudioOutputDescriptor::routesToDevice(const sp<DeviceDescriptor> &device) const
+{
+    return routableDevices().contains(device);
+}
+
 bool SwAudioOutputDescriptor::supportsAllDevices(const DeviceVector &devices) const
 {
     return supportedDevices().containsAllDevices(devices);
 }
 
+bool SwAudioOutputDescriptor::routesToAllDevices(const DeviceVector &devices) const
+{
+    return routableDevices().containsAllDevices(devices);
+}
+
 bool SwAudioOutputDescriptor::supportsAtLeastOne(const DeviceVector &devices) const
 {
     return filterSupportedDevices(devices).size() > 0;
 }
 
+bool SwAudioOutputDescriptor::routesToAtLeastOne(const DeviceVector &devices) const
+{
+    return filterRoutableDevices(devices).size() > 0;
+}
+
 bool SwAudioOutputDescriptor::supportsDevicesForPlayback(const DeviceVector &devices) const
 {
     // No considering duplicated output
@@ -412,12 +482,23 @@ bool SwAudioOutputDescriptor::supportsDevicesForPlayback(const DeviceVector &dev
     return !isDuplicated() && supportsAllDevices(devices);
 }
 
+bool SwAudioOutputDescriptor::routesToDevicesForPlayback(const DeviceVector &devices) const
+{
+    return !isDuplicated() && routesToAllDevices(devices);
+}
+
 DeviceVector SwAudioOutputDescriptor::filterSupportedDevices(const DeviceVector &devices) const
 {
     DeviceVector filteredDevices = supportedDevices();
     return filteredDevices.filter(devices);
 }
 
+DeviceVector SwAudioOutputDescriptor::filterRoutableDevices(const DeviceVector &devices) const
+{
+    DeviceVector filteredDevices = routableDevices();
+    return filteredDevices.filter(devices);
+}
+
 bool SwAudioOutputDescriptor::devicesSupportEncodedFormats(const DeviceTypeSet& deviceTypes)
 {
     if (isDuplicated()) {
@@ -548,7 +629,8 @@ bool SwAudioOutputDescriptor::setVolume(float volumeDb, bool mutedByGroup,
     StreamTypeVector streams = streamTypes;
     if (!AudioOutputDescriptor::setVolume(
             volumeDb, mutedByGroup, vs, streamTypes, deviceTypes, delayMs, force, isVoiceVolSrc)) {
-        if (hasStream(streamTypes, AUDIO_STREAM_BLUETOOTH_SCO)) {
+        if (hasStream(streamTypes, AUDIO_STREAM_BLUETOOTH_SCO) &&
+                !com_android_media_audio_replace_stream_bt_sco()) {
             VolumeSource callVolSrc = getVoiceSource();
             const bool mutedChanged =
                     com_android_media_audio_ring_my_car() && hasVolumeSource(callVolSrc) &&
@@ -620,7 +702,8 @@ bool SwAudioOutputDescriptor::setVolume(float volumeDb, bool mutedByGroup,
     }
     // Force VOICE_CALL to track BLUETOOTH_SCO stream volume when bluetooth audio is enabled
     float volumeAmpl = Volume::DbToAmpl(getCurVolume(vs));
-    if (hasStream(streams, AUDIO_STREAM_BLUETOOTH_SCO)) {
+    if (hasStream(streams, AUDIO_STREAM_BLUETOOTH_SCO) &&
+            !com_android_media_audio_replace_stream_bt_sco()) {
         VolumeSource callVolSrc = getVoiceSource();
         if (audioserver_flags::portid_volume_management()) {
             if (callVolSrc != VOLUME_SOURCE_NONE) {
@@ -734,7 +817,8 @@ status_t SwAudioOutputDescriptor::open(const audio_config_t *halConfig,
                                                    device,
                                                    &mLatency,
                                                    &mFlags,
-                                                   attributes);
+                                                   attributes,
+                                                   mProfile->getHalId());
     *flags = mFlags;
 
     if (status == NO_ERROR) {
diff --git a/services/audiopolicy/common/managerdefinitions/src/AudioPolicyConfig.cpp b/services/audiopolicy/common/managerdefinitions/src/AudioPolicyConfig.cpp
index a7a39d9257..10973417e8 100644
--- a/services/audiopolicy/common/managerdefinitions/src/AudioPolicyConfig.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/AudioPolicyConfig.cpp
@@ -326,13 +326,13 @@ void AudioPolicyConfig::setDefault() {
     sp<OutputProfile> outProfile = new OutputProfile("primary");
     outProfile->addAudioProfile(
             new AudioProfile(AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO, 44100));
-    outProfile->addSupportedDevice(mDefaultOutputDevice);
+    outProfile->addSupportedRoutableDevice(mDefaultOutputDevice);
     outProfile->setFlags(AUDIO_OUTPUT_FLAG_PRIMARY);
     module->addOutputProfile(outProfile);
 
     sp<InputProfile> inProfile = new InputProfile("primary");
     inProfile->addAudioProfile(micProfile);
-    inProfile->addSupportedDevice(defaultInputDevice);
+    inProfile->addSupportedRoutableDevice(defaultInputDevice);
     module->addInputProfile(inProfile);
 
     setDefaultSurroundFormats();
diff --git a/services/audiopolicy/common/managerdefinitions/src/AudioPolicyMix.cpp b/services/audiopolicy/common/managerdefinitions/src/AudioPolicyMix.cpp
index ea78a5dfb8..3e9ef25e91 100644
--- a/services/audiopolicy/common/managerdefinitions/src/AudioPolicyMix.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/AudioPolicyMix.cpp
@@ -144,6 +144,8 @@ void AudioPolicyMix::dump(String8 *dst, int spaces, int index) const
 
     dst->appendFormat("%*s- device address: %s\n", spaces, "", mDeviceAddress.c_str());
 
+    dst->appendFormat("%*s- virtual device id: %d\n", spaces, "", mVirtualDeviceId);
+
     dst->appendFormat("%*s- output: %d\n", spaces, "",
             mOutput == nullptr ? 0 : mOutput->mIoHandle);
 
@@ -193,11 +195,9 @@ status_t AudioPolicyMixCollection::registerMix(const AudioMix& mix,
                     mix.mDeviceType, mix.mDeviceAddress.c_str());
             return BAD_VALUE;
         }
-        if (audiopolicy_flags::audio_mix_ownership()) {
-            if (mix.mToken == registeredMix->mToken) {
-                ALOGE("registerMix(): same mix already registered - skipping");
-                return BAD_VALUE;
-            }
+        if (mix.mToken == registeredMix->mToken) {
+            ALOGE("registerMix(): same mix already registered - skipping");
+            return BAD_VALUE;
         }
     }
     if (!areMixCriteriaConsistent(mix.mCriteria)) {
@@ -221,21 +221,11 @@ status_t AudioPolicyMixCollection::unregisterMix(const AudioMix& mix)
 {
     for (size_t i = 0; i < size(); i++) {
         const sp<AudioPolicyMix>& registeredMix = itemAt(i);
-        if (audiopolicy_flags::audio_mix_ownership()) {
-            if (mix.mToken == registeredMix->mToken) {
-                ALOGD("unregisterMix(): removing mix for dev=0x%x addr=%s",
-                      mix.mDeviceType, mix.mDeviceAddress.c_str());
-                removeAt(i);
-                return NO_ERROR;
-            }
-        } else {
-            if (mix.mDeviceType == registeredMix->mDeviceType
-                && mix.mDeviceAddress.compare(registeredMix->mDeviceAddress) == 0) {
-                ALOGD("unregisterMix(): removing mix for dev=0x%x addr=%s",
-                      mix.mDeviceType, mix.mDeviceAddress.c_str());
-                removeAt(i);
-                return NO_ERROR;
-            }
+        if (mix.mToken == registeredMix->mToken) {
+            ALOGD("unregisterMix(): removing mix for dev=0x%x addr=%s",
+                  mix.mDeviceType, mix.mDeviceAddress.c_str());
+            removeAt(i);
+            return NO_ERROR;
         }
     }
 
@@ -312,9 +302,9 @@ void AudioPolicyMixCollection::closeOutput(sp<SwAudioOutputDescriptor> &desc,
         // Restore the policy mix mix output to the first opened output supporting a route to
         // the mix device. This is because the current mix output can be changed to a direct output.
         for (size_t j = 0; j < allOutputs.size(); ++j) {
-            if (allOutputs[i] != desc && !allOutputs[i]->isDuplicated() &&
-                allOutputs[i]->supportedDevices().contains(device)) {
-                policyMix->setOutput(allOutputs[i]);
+            if (allOutputs[j] != desc && !allOutputs[j]->isDuplicated() &&
+                allOutputs[j]->supportedDevices().contains(device)) {
+                policyMix->setOutput(allOutputs[j]);
                 break;
             }
         }
diff --git a/services/audiopolicy/common/managerdefinitions/src/DeviceDescriptor.cpp b/services/audiopolicy/common/managerdefinitions/src/DeviceDescriptor.cpp
index 46a04dec2a..70005f429e 100644
--- a/services/audiopolicy/common/managerdefinitions/src/DeviceDescriptor.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/DeviceDescriptor.cpp
@@ -510,13 +510,10 @@ std::string DeviceVector::toString(bool includeSensitiveInfo) const
 
 DeviceVector DeviceVector::filter(const DeviceVector &devices) const
 {
-    DeviceVector filteredDevices;
-    for (const auto &device : *this) {
-        if (devices.contains(device)) {
-            filteredDevices.add(device);
-        }
-    }
-    return filteredDevices;
+    auto intersects = [&devices](const sp<DeviceDescriptor> &device) {
+        return devices.contains(device);
+    };
+    return filter(intersects);
 }
 
 bool DeviceVector::containsAtLeastOne(const DeviceVector &devices) const
diff --git a/services/audiopolicy/common/managerdefinitions/src/HwModule.cpp b/services/audiopolicy/common/managerdefinitions/src/HwModule.cpp
index 2d8231a3e1..f6dc762565 100644
--- a/services/audiopolicy/common/managerdefinitions/src/HwModule.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/HwModule.cpp
@@ -44,9 +44,11 @@ HwModule::~HwModule()
 {
     for (size_t i = 0; i < mOutputProfiles.size(); i++) {
         mOutputProfiles[i]->clearSupportedDevices();
+        mOutputProfiles[i]->clearRoutableDevices();
     }
     for (size_t i = 0; i < mInputProfiles.size(); i++) {
         mInputProfiles[i]->clearSupportedDevices();
+        mInputProfiles[i]->clearRoutableDevices();
     }
 }
 
@@ -72,7 +74,7 @@ status_t HwModule::addOutputProfile(const std::string& name, const audio_config_
     addDynamicDevice(devDesc);
     // Reciprocally attach the device to the module
     devDesc->attach(this);
-    profile->addSupportedDevice(devDesc);
+    profile->addSupportedRoutableDevice(devDesc);
 
     return addOutputProfile(profile);
 }
@@ -142,7 +144,7 @@ status_t HwModule::addInputProfile(const std::string& name, const audio_config_t
     addDynamicDevice(devDesc);
     // Reciprocally attach the device to the module
     devDesc->attach(this);
-    profile->addSupportedDevice(devDesc);
+    profile->addSupportedRoutableDevice(devDesc);
 
     ALOGV("addInputProfile() name %s rate %d mask 0x%08x",
           name.c_str(), config->sample_rate, config->channel_mask);
@@ -223,6 +225,7 @@ void HwModule::refreshSupportedDevices()
             continue;
         }
         stream->setSupportedDevices(sourceDevices);
+        stream->setRoutableDevices(sourceDevices);
     }
     for (const auto& stream : mOutputProfiles) {
         DeviceVector sinkDevices;
@@ -240,6 +243,7 @@ void HwModule::refreshSupportedDevices()
             sinkDevices.add(sinkDevice);
         }
         stream->setSupportedDevices(sinkDevices);
+        stream->setRoutableDevices(sinkDevices);
     }
 }
 
@@ -478,6 +482,10 @@ void HwModuleCollection::cleanUpForDevice(const sp<DeviceDescriptor> &device)
         const IOProfileCollection &profiles = audio_is_output_device(device->type()) ?
                     hwModule->getOutputProfiles() : hwModule->getInputProfiles();
         for (const auto &profile : profiles) {
+            if (profile->routesToDevice(device)) {
+                profile->removeRoutableDevice(device);
+            }
+
             // For cleanup, strong match is required
             if (profile->supportsDevice(device, true /*matchAdress*/)) {
                 ALOGV("%s: removing device %s from profile %s", __FUNCTION__,
diff --git a/services/audiopolicy/common/managerdefinitions/src/IOProfile.cpp b/services/audiopolicy/common/managerdefinitions/src/IOProfile.cpp
index 78e0582c9d..492ba3fabe 100644
--- a/services/audiopolicy/common/managerdefinitions/src/IOProfile.cpp
+++ b/services/audiopolicy/common/managerdefinitions/src/IOProfile.cpp
@@ -42,13 +42,15 @@ IOProfile::CompatibilityScore IOProfile::getCompatibilityScore(
         audio_channel_mask_t channelMask,
         audio_channel_mask_t *updatedChannelMask,
         // FIXME type punning here
-        uint32_t flags) const {
+        uint32_t flags,
+        uint32_t additionalMandatoryFlags) const {
     const bool isPlaybackThread =
             getType() == AUDIO_PORT_TYPE_MIX && getRole() == AUDIO_PORT_ROLE_SOURCE;
     const bool isRecordThread =
             getType() == AUDIO_PORT_TYPE_MIX && getRole() == AUDIO_PORT_ROLE_SINK;
     ALOG_ASSERT(isPlaybackThread != isRecordThread);
-    const auto flagsCompatibleScore = getFlagsCompatibleScore(flags);
+    const auto flagsCompatibleScore =
+            getFlagsCompatibleScore(flags, additionalMandatoryFlags);
     if (!areAllDevicesSupported(devices) || flagsCompatibleScore == NO_MATCH) {
         return NO_MATCH;
     }
@@ -125,6 +127,13 @@ bool IOProfile::areAllDevicesSupported(const DeviceVector &devices) const {
     return mSupportedDevices.containsAllDevices(devices);
 }
 
+bool IOProfile::areAllDevicesRoutable(const DeviceVector &devices) const {
+    if (devices.empty()) {
+        return true;
+    }
+    return mRoutableDevices.containsAllDevices(devices);
+}
+
 bool IOProfile::isCompatibleProfileForFlags(uint32_t flags) const {
     return getFlagsCompatibleScore(flags) != NO_MATCH;
 }
@@ -211,7 +220,8 @@ void IOProfile::importAudioPort(const audio_port_v7 &port) {
     }
 }
 
-IOProfile::CompatibilityScore IOProfile::getFlagsCompatibleScore(uint32_t flags) const {
+IOProfile::CompatibilityScore IOProfile::getFlagsCompatibleScore(
+        uint32_t flags, uint32_t additionalMandatoryFlags) const {
     const bool isPlaybackThread =
             getType() == AUDIO_PORT_TYPE_MIX && getRole() == AUDIO_PORT_ROLE_SOURCE;
     const bool isRecordThread =
@@ -219,7 +229,8 @@ IOProfile::CompatibilityScore IOProfile::getFlagsCompatibleScore(uint32_t flags)
     ALOG_ASSERT(isPlaybackThread != isRecordThread);
 
     const uint32_t mustMatchOutputFlags =
-            AUDIO_OUTPUT_FLAG_DIRECT|AUDIO_OUTPUT_FLAG_HW_AV_SYNC|AUDIO_OUTPUT_FLAG_MMAP_NOIRQ;
+            AUDIO_OUTPUT_FLAG_DIRECT|AUDIO_OUTPUT_FLAG_HW_AV_SYNC|AUDIO_OUTPUT_FLAG_MMAP_NOIRQ
+            | additionalMandatoryFlags;
     if (isPlaybackThread &&
         !audio_output_flags_is_subset((audio_output_flags_t)getFlags(),
                                       (audio_output_flags_t)flags,
diff --git a/services/audiopolicy/engine/common/include/EngineBase.h b/services/audiopolicy/engine/common/include/EngineBase.h
index 4c2001fc3b..b2ae7df038 100644
--- a/services/audiopolicy/engine/common/include/EngineBase.h
+++ b/services/audiopolicy/engine/common/include/EngineBase.h
@@ -80,8 +80,11 @@ public:
                    mVolumeGroups.at(group)->getVolumeCurves() : nullptr;
     }
 
-    VolumeGroupVector getVolumeGroups() const override;
+    bool isValidVolumeGroup(volume_group_t group) const override;
 
+    VolumeGroupVector getVolumeGroups() const override;
+    audio_attributes_t getAttributesForVolumeGroup(
+            volume_group_t group, bool fallbackOnDefault = true) const override;
     volume_group_t getVolumeGroupForAttributes(
             const audio_attributes_t &attr, bool fallbackOnDefault = true) const override;
 
@@ -241,6 +244,16 @@ protected:
             const DeviceVector &availableInputDevices) const;
 
     DeviceStrategyMap mDevicesForStrategies;
+
+    void initializeLegacyStrategyMaps();
+    product_strategy_t getProductStrategyFromLegacy(legacy_strategy legacyStrategy) const;
+    legacy_strategy getLegacyStrategyFromProduct(product_strategy_t productStrategy) const;
+
+    // map between product strategy IDs and legacy strategy Ids
+    std::map<product_strategy_t, legacy_strategy> mLegacyStrategyMap;
+    // Ordered map (by legacy strategy priority) between legacy strategy IDs and Product strategies
+    std::map<legacy_strategy, sp<ProductStrategy>> mOrderedStrategyMap;
+
 };
 
 } // namespace audio_policy
diff --git a/services/audiopolicy/engine/common/include/VolumeCurve.h b/services/audiopolicy/engine/common/include/VolumeCurve.h
index e5f7a41121..ea771fd77d 100644
--- a/services/audiopolicy/engine/common/include/VolumeCurve.h
+++ b/services/audiopolicy/engine/common/include/VolumeCurve.h
@@ -110,8 +110,18 @@ public:
 
     int getVolumeIndexMin() const { return mIndexMin; }
 
+    int setVolumeIndexMin(int index) {
+        mIndexMin = index;
+        return NO_ERROR;
+    }
+
     int getVolumeIndexMax() const { return mIndexMax; }
 
+    int setVolumeIndexMax(int index) {
+        mIndexMax = index;
+        return NO_ERROR;
+    }
+
     bool hasVolumeIndexForDevice(audio_devices_t device) const
     {
         device = Volume::getDeviceForVolume({device});
diff --git a/services/audiopolicy/engine/common/src/EngineBase.cpp b/services/audiopolicy/engine/common/src/EngineBase.cpp
index b0279b954a..82830baec6 100644
--- a/services/audiopolicy/engine/common/src/EngineBase.cpp
+++ b/services/audiopolicy/engine/common/src/EngineBase.cpp
@@ -173,7 +173,8 @@ engineConfig::ParsingResult EngineBase::loadAudioPolicyEngineConfig(
                     std::end(result.parsedConfig->volumeGroups),
                     std::begin(gSystemVolumeGroups), std::end(gSystemVolumeGroups));
     }
-    ALOGE_IF(result.nbSkippedElement != 0, "skipped %zu elements", result.nbSkippedElement);
+    ALOGE_IF(result.nbSkippedElement != 0,
+            "%s skipped %zu elements", __func__, result.nbSkippedElement);
     return processParsingResult(std::move(result));
 }
 
@@ -299,8 +300,8 @@ engineConfig::ParsingResult EngineBase::processParsingResult(
 
 StrategyVector EngineBase::getOrderedProductStrategies() const
 {
-    auto findByFlag = [](const auto &productStrategies, auto flag) {
-        return std::find_if(begin(productStrategies), end(productStrategies),
+    auto findByFlag = [](const auto &legacyStrategies, auto flag) {
+        return std::find_if(begin(legacyStrategies), end(legacyStrategies),
                             [&](const auto &strategy) {
             for (const auto &attributes : strategy.second->getAudioAttributes()) {
                 if ((attributes.flags & flag) == flag) {
@@ -310,7 +311,9 @@ StrategyVector EngineBase::getOrderedProductStrategies() const
             return false;
         });
     };
-    auto strategies = mProductStrategies;
+
+    auto strategies = mOrderedStrategyMap;
+
     auto enforcedAudibleStrategyIter = findByFlag(strategies, AUDIO_FLAG_AUDIBILITY_ENFORCED);
 
     if (getForceUse(AUDIO_POLICY_FORCE_FOR_SYSTEM) == AUDIO_POLICY_FORCE_SYSTEM_ENFORCED &&
@@ -319,6 +322,7 @@ StrategyVector EngineBase::getOrderedProductStrategies() const
         strategies.erase(enforcedAudibleStrategyIter);
         strategies.insert(begin(strategies), enforcedAudibleStrategy);
     }
+
     StrategyVector orderedStrategies;
     for (const auto &iter : strategies) {
         if (iter.second->isPatchStrategy()) {
@@ -326,6 +330,7 @@ StrategyVector EngineBase::getOrderedProductStrategies() const
         }
         orderedStrategies.push_back(iter.second->getId());
     }
+
     return orderedStrategies;
 }
 
@@ -391,6 +396,10 @@ status_t EngineBase::restoreOriginVolumeCurve(audio_stream_type_t stream)
     return curves != nullptr ? curves->switchCurvesFrom(*curves) : BAD_VALUE;
 }
 
+bool EngineBase::isValidVolumeGroup(volume_group_t group) const {
+    return mVolumeGroups.find(group) != end(mVolumeGroups);
+}
+
 VolumeGroupVector EngineBase::getVolumeGroups() const
 {
     VolumeGroupVector group;
@@ -406,6 +415,16 @@ volume_group_t EngineBase::getVolumeGroupForAttributes(
     return mProductStrategies.getVolumeGroupForAttributes(attr, fallbackOnDefault);
 }
 
+audio_attributes_t EngineBase::getAttributesForVolumeGroup(
+        volume_group_t group, bool fallbackOnDefault) const {
+    const auto &iter = mVolumeGroups.find(group);
+    if (iter != std::end(mVolumeGroups)) {
+        return mVolumeGroups.at(group)->getSupportedAttributes().front();
+    }
+    return fallbackOnDefault ?
+            attributes_initializer(AUDIO_USAGE_MEDIA) : AUDIO_ATTRIBUTES_INITIALIZER;
+}
+
 volume_group_t EngineBase::getVolumeGroupForStreamType(
         audio_stream_type_t stream, bool fallbackOnDefault) const
 {
@@ -842,6 +861,34 @@ sp<DeviceDescriptor> EngineBase::getInputDeviceForEchoRef(const audio_attributes
     return nullptr;
 }
 
+void EngineBase::initializeLegacyStrategyMaps() {
+    auto legacyStrategy = getLegacyStrategyMap();
+    for (const auto &strategy : legacyStrategy) {
+        mLegacyStrategyMap[getProductStrategyByName(strategy.name)] = strategy.id;
+    }
+    // this loop must be executed after mLegacyStrategyMap is fully initialized
+    for (const auto &iter : mProductStrategies) {
+        legacy_strategy ls = getLegacyStrategyFromProduct(iter.first);
+        if (ls == STRATEGY_NONE) {
+            // product strategy IDs not matching legacy strategies are guaranteed
+            // to have larger id values than legacy strategies and are ordered by value
+            ls = static_cast<legacy_strategy>(iter.first);
+        }
+        mOrderedStrategyMap[ls] = iter.second;
+    }
+}
+
+product_strategy_t EngineBase::getProductStrategyFromLegacy(legacy_strategy legacyStrategy) const {
+    auto it = mOrderedStrategyMap.find(legacyStrategy);
+    return it != end(mOrderedStrategyMap) ? it->second->getId() : PRODUCT_STRATEGY_NONE;
+}
+
+legacy_strategy EngineBase::getLegacyStrategyFromProduct(
+        product_strategy_t productStrategy) const {
+    auto it = mLegacyStrategyMap.find(productStrategy);
+    return it != end(mLegacyStrategyMap) ? it->second : STRATEGY_NONE;
+}
+
 void EngineBase::dumpCapturePresetDevicesRoleMap(String8 *dst, int spaces) const
 {
     dst->appendFormat("\n%*sDevice role per capture preset dump:", spaces, "");
diff --git a/services/audiopolicy/engine/common/src/EngineDefaultConfig.h b/services/audiopolicy/engine/common/src/EngineDefaultConfig.h
index 4933b345e3..b4acc826ca 100644
--- a/services/audiopolicy/engine/common/src/EngineDefaultConfig.h
+++ b/services/audiopolicy/engine/common/src/EngineDefaultConfig.h
@@ -19,16 +19,19 @@
 #include <EngineConfig.h>
 
 #include <media/AudioProductStrategy.h>
+#include <media/AidlConversionUtil.h>
 #include <policy.h>
 #include <system/audio.h>
 
 namespace android {
 
+using AudioProductStrategyType = media::audio::common::AudioProductStrategyType;
+
 /**
  * @brief AudioProductStrategies hard coded array of strategies to fill new engine API contract.
  */
 const engineConfig::ProductStrategies gOrderedStrategies = {
-    {"STRATEGY_PHONE", STRATEGY_PHONE,
+    {"STRATEGY_PHONE", static_cast<int>(AudioProductStrategyType::PHONE),
      {
          {AUDIO_STREAM_VOICE_CALL, "AUDIO_STREAM_VOICE_CALL",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_VOICE_COMMUNICATION, AUDIO_SOURCE_DEFAULT,
@@ -40,7 +43,7 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_SONIFICATION", STRATEGY_SONIFICATION,
+    {"STRATEGY_SONIFICATION", static_cast<int>(AudioProductStrategyType::SONIFICATION),
      {
          {AUDIO_STREAM_RING, "AUDIO_STREAM_RING",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_NOTIFICATION_TELEPHONY_RINGTONE,
@@ -52,7 +55,7 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_ENFORCED_AUDIBLE", STRATEGY_ENFORCED_AUDIBLE,
+    {"STRATEGY_ENFORCED_AUDIBLE", static_cast<int>(AudioProductStrategyType::ENFORCED_AUDIBLE),
      {
          {AUDIO_STREAM_ENFORCED_AUDIBLE, "AUDIO_STREAM_ENFORCED_AUDIBLE",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_UNKNOWN, AUDIO_SOURCE_DEFAULT,
@@ -60,7 +63,7 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_ACCESSIBILITY", STRATEGY_ACCESSIBILITY,
+    {"STRATEGY_ACCESSIBILITY", static_cast<int>(AudioProductStrategyType::ACCESSIBILITY),
      {
          {AUDIO_STREAM_ACCESSIBILITY, "AUDIO_STREAM_ACCESSIBILITY",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_ASSISTANCE_ACCESSIBILITY,
@@ -68,7 +71,8 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_SONIFICATION_RESPECTFUL", STRATEGY_SONIFICATION_RESPECTFUL,
+    {"STRATEGY_SONIFICATION_RESPECTFUL",
+            static_cast<int>(AudioProductStrategyType::SONIFICATION_RESPECTFUL),
      {
          {AUDIO_STREAM_NOTIFICATION, "AUDIO_STREAM_NOTIFICATION",
           {
@@ -80,7 +84,7 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_MEDIA", STRATEGY_MEDIA,
+    {"STRATEGY_MEDIA", static_cast<int>(AudioProductStrategyType::MEDIA),
      {
          {AUDIO_STREAM_ASSISTANT, "AUDIO_STREAM_ASSISTANT",
           {{AUDIO_CONTENT_TYPE_SPEECH, AUDIO_USAGE_ASSISTANT,
@@ -106,7 +110,7 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_DTMF", STRATEGY_DTMF,
+    {"STRATEGY_DTMF", static_cast<int>(AudioProductStrategyType::DTMF),
      {
          {AUDIO_STREAM_DTMF, "AUDIO_STREAM_DTMF",
           {
@@ -116,7 +120,8 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_CALL_ASSISTANT", STRATEGY_CALL_ASSISTANT,
+    {"STRATEGY_CALL_ASSISTANT",
+            static_cast<int>(AudioProductStrategyType::SYS_RESERVED_CALL_ASSISTANT),
      {
          {AUDIO_STREAM_CALL_ASSISTANT, "AUDIO_STREAM_CALL_ASSISTANT",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_CALL_ASSISTANT, AUDIO_SOURCE_DEFAULT,
@@ -124,7 +129,8 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
          }
      },
     },
-    {"STRATEGY_TRANSMITTED_THROUGH_SPEAKER", STRATEGY_TRANSMITTED_THROUGH_SPEAKER,
+    {"STRATEGY_TRANSMITTED_THROUGH_SPEAKER",
+            static_cast<int>(AudioProductStrategyType::TRANSMITTED_THROUGH_SPEAKER),
      {
          {AUDIO_STREAM_TTS, "AUDIO_STREAM_TTS",
           {
@@ -145,7 +151,7 @@ const engineConfig::ProductStrategies gOrderedStrategies = {
  * For compatibility reason why apm volume config file, volume group name is the stream type.
  */
 const engineConfig::ProductStrategies gOrderedSystemStrategies = {
-    {"STRATEGY_REROUTING", STRATEGY_REROUTING,
+    {"STRATEGY_REROUTING", static_cast<int>(AudioProductStrategyType::SYS_RESERVED_REROUTING),
      {
          {AUDIO_STREAM_REROUTING, "AUDIO_STREAM_REROUTING",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_VIRTUAL_SOURCE, AUDIO_SOURCE_DEFAULT,
@@ -153,7 +159,7 @@ const engineConfig::ProductStrategies gOrderedSystemStrategies = {
          }
      },
     },
-    {"STRATEGY_PATCH", STRATEGY_PATCH,
+    {"STRATEGY_PATCH", 10, //TODO b/416445424: define in AudioProductStrategyType.aidl
      {
          {AUDIO_STREAM_PATCH, "AUDIO_STREAM_PATCH",
           {{AUDIO_CONTENT_TYPE_UNKNOWN, AUDIO_USAGE_UNKNOWN, AUDIO_SOURCE_DEFAULT,
diff --git a/services/audiopolicy/engine/config/include/EngineConfig.h b/services/audiopolicy/engine/config/include/EngineConfig.h
index 8a4fc88465..1b144b0c90 100644
--- a/services/audiopolicy/engine/config/include/EngineConfig.h
+++ b/services/audiopolicy/engine/config/include/EngineConfig.h
@@ -20,6 +20,7 @@
 #include <vector>
 
 #include <android/media/audio/common/AudioHalEngineConfig.h>
+#include <media/AidlConversionUtil.h>
 #include <system/audio.h>
 #include <utils/Errors.h>
 
@@ -122,5 +123,8 @@ ParsingResult convert(const ::android::media::audio::common::AudioHalEngineConfi
 // Exposed for testing.
 android::status_t parseLegacyVolumeFile(const char* path, VolumeGroups &volumeGroups);
 
+ConversionResult<std::string> aidlAudioHalProductStrategyIdToName(int id);
+ConversionResult<int> aidlAudioHalProductStrategyNameToId(const std::string& name);
+
 } // namespace engineConfig
 } // namespace android
diff --git a/services/audiopolicy/engine/config/src/EngineConfig.cpp b/services/audiopolicy/engine/config/src/EngineConfig.cpp
index b8d95ee899..3311662ffa 100644
--- a/services/audiopolicy/engine/config/src/EngineConfig.cpp
+++ b/services/audiopolicy/engine/config/src/EngineConfig.cpp
@@ -50,34 +50,33 @@ static constexpr const char *gVersionAttribute = "version";
 static const char *const gReferenceElementName = "reference";
 static const char *const gReferenceAttributeName = "name";
 
+static constexpr const char *gVendorStrategyPrefix = "vx_";
+
 namespace {
 
 static bool gIsConfigurableEngine = false;
 
-ConversionResult<std::string> aidl2legacy_AudioHalProductStrategy_ProductStrategyType(int id) {
-    using AudioProductStrategyType = media::audio::common::AudioProductStrategyType;
-
-#define STRATEGY_ENTRY(name) {static_cast<int>(AudioProductStrategyType::name), "STRATEGY_" #name}
-    static const std::unordered_map<int, std::string> productStrategyMap = {STRATEGY_ENTRY(MEDIA),
-                            STRATEGY_ENTRY(PHONE),
-                            STRATEGY_ENTRY(SONIFICATION),
-                            STRATEGY_ENTRY(SONIFICATION_RESPECTFUL),
-                            STRATEGY_ENTRY(DTMF),
-                            STRATEGY_ENTRY(ENFORCED_AUDIBLE),
-                            STRATEGY_ENTRY(TRANSMITTED_THROUGH_SPEAKER),
-                            STRATEGY_ENTRY(ACCESSIBILITY)};
+#define STRATEGY_ENTRY(id, name) {static_cast<int>(id), "STRATEGY_" #name}
+
+using AudioProductStrategyType = media::audio::common::AudioProductStrategyType;
+
+static const std::unordered_map<int, std::string> gProductStrategyMap = {
+        STRATEGY_ENTRY(AudioProductStrategyType::MEDIA, MEDIA),
+        STRATEGY_ENTRY(AudioProductStrategyType::PHONE, PHONE),
+        STRATEGY_ENTRY(AudioProductStrategyType::SONIFICATION, SONIFICATION),
+        STRATEGY_ENTRY(AudioProductStrategyType::SONIFICATION_RESPECTFUL,
+                       SONIFICATION_RESPECTFUL),
+        STRATEGY_ENTRY(AudioProductStrategyType::DTMF, DTMF),
+        STRATEGY_ENTRY(AudioProductStrategyType::ENFORCED_AUDIBLE, ENFORCED_AUDIBLE),
+        STRATEGY_ENTRY(AudioProductStrategyType::TRANSMITTED_THROUGH_SPEAKER,
+                       TRANSMITTED_THROUGH_SPEAKER),
+        STRATEGY_ENTRY(AudioProductStrategyType::ACCESSIBILITY, ACCESSIBILITY),
+        STRATEGY_ENTRY(AudioProductStrategyType::SYS_RESERVED_REROUTING, REROUTING),
+        STRATEGY_ENTRY(AudioProductStrategyType::SYS_RESERVED_CALL_ASSISTANT, CALL_ASSISTANT),
+        STRATEGY_ENTRY(10, PATCH), //TODO b/416445424: define in AudioProductStrategyType.aidl
+    };
 #undef STRATEGY_ENTRY
 
-    if (id >= media::audio::common::AudioHalProductStrategy::VENDOR_STRATEGY_ID_START) {
-        return std::to_string(id);
-    }
-    auto it = productStrategyMap.find(id);
-    if (it == productStrategyMap.end()) {
-        return base::unexpected(BAD_VALUE);
-    }
-    return it->second;
-}
-
 ConversionResult<AttributesGroup> aidl2legacy_AudioHalAttributeGroup_AttributesGroup(
         const media::audio::common::AudioHalAttributesGroup& aidl) {
     AttributesGroup legacy;
@@ -95,14 +94,14 @@ ConversionResult<AttributesGroup> aidl2legacy_AudioHalAttributeGroup_AttributesG
 
 ConversionResult<ProductStrategy> aidl2legacy_AudioHalProductStrategy_ProductStrategy(
         const media::audio::common::AudioHalProductStrategy& aidl) {
-    ProductStrategy legacy;
-    legacy.name = aidl.name.value_or(VALUE_OR_RETURN(
-                    aidl2legacy_AudioHalProductStrategy_ProductStrategyType(aidl.id)));
-    legacy.id = aidl.id;
-    legacy.attributesGroups = VALUE_OR_RETURN(convertContainer<AttributesGroups>(
+    ProductStrategy ps;
+    ps.name = aidl.name.value_or(VALUE_OR_RETURN(
+                    aidlAudioHalProductStrategyIdToName(aidl.id)));
+    ps.id = aidl.id;
+    ps.attributesGroups = VALUE_OR_RETURN(convertContainer<AttributesGroups>(
                     aidl.attributesGroups,
                     aidl2legacy_AudioHalAttributeGroup_AttributesGroup));
-    return legacy;
+    return ps;
 }
 
 ConversionResult<std::string> legacy_device_category_to_string(device_category legacy) {
@@ -550,9 +549,9 @@ status_t ProductStrategyTraits::deserialize(_xmlDoc *doc, const _xmlNode *child,
             return BAD_VALUE;
         }
     } else {
-        legacy_strategy legacyId;
-        if (legacy_strategy_from_string(name.c_str(), &legacyId)) {
-            id = legacyId;
+        const auto& res = aidlAudioHalProductStrategyNameToId(name);
+        if (res.ok()) {
+            id = res.value();
         } else if (!gIsConfigurableEngine) {
             return BAD_VALUE;
         }
@@ -874,7 +873,32 @@ ParsingResult convert(const ::android::media::audio::common::AudioHalEngineConfi
         return ParsingResult{};
     }
     return {.parsedConfig=std::move(config), .nbSkippedElement=0};
- }
+}
+
+ConversionResult<std::string> aidlAudioHalProductStrategyIdToName(int id) {
+    if (id >= media::audio::common::AudioHalProductStrategy::VENDOR_STRATEGY_ID_START) {
+        return gVendorStrategyPrefix + std::to_string(id);
+    }
+    auto it = gProductStrategyMap.find(id);
+    if (it == gProductStrategyMap.end()) {
+        ALOGE("%s Invalid legacy strategy id %d", __func__, id);
+        return base::unexpected(BAD_VALUE);
+    }
+    return it->second;
+}
+
+ConversionResult<int> aidlAudioHalProductStrategyNameToId(const std::string& name) {
+
+    const auto iter = std::find_if(begin(gProductStrategyMap), end(gProductStrategyMap),
+                                    [&name](const auto &strategy) {
+                                        return name == strategy.second; });
+
+    if (iter == end(gProductStrategyMap)) {
+        ALOGE("%s Invalid legacy strategy name %s", __func__, name.c_str());
+        return base::unexpected(BAD_VALUE);
+    }
+    return iter->first;
+}
 
 } // namespace engineConfig
 } // namespace android
diff --git a/services/audiopolicy/engine/interface/EngineInterface.h b/services/audiopolicy/engine/interface/EngineInterface.h
index 6d5e15b5bc..a277267ffb 100644
--- a/services/audiopolicy/engine/interface/EngineInterface.h
+++ b/services/audiopolicy/engine/interface/EngineInterface.h
@@ -285,6 +285,12 @@ public:
      */
     virtual IVolumeCurves *getVolumeCurvesForVolumeGroup(volume_group_t group) const = 0;
 
+    /**
+     * @brief Determines if the volume group is valid
+     * @return true if the volume group is valid, false otherwise
+     */
+    virtual bool isValidVolumeGroup(volume_group_t group) const = 0;
+
     /**
      * @brief getVolumeGroups retrieves the collection of volume groups.
      * @return vector of volume groups
@@ -303,6 +309,19 @@ public:
     virtual volume_group_t getVolumeGroupForAttributes(
             const audio_attributes_t &attr, bool fallbackOnDefault = true) const = 0;
 
+    /**
+     * Gets the audio attributes matching the given volume group id, if none, returns the default
+     * attributes of the default volume group if fallbackOnDefault is set.
+     *
+     * @param group to consider
+     * @param fallbackOnDefault true to fallback on default volume group attributes if group not
+     * found, false otherwise.
+     * @return attributes matching the requested group, or default attributes if fallbackOnDefault
+     * is true.
+     */
+    virtual audio_attributes_t getAttributesForVolumeGroup(
+            volume_group_t group, bool fallbackOnDefault = true) const = 0;
+
     /**
      * @brief getVolumeGroupForStreamType gets the appropriate volume group to be used for a given
      * legacy stream type
diff --git a/services/audiopolicy/engineconfigurable/config/example/automotive/Android.bp b/services/audiopolicy/engineconfigurable/config/example/automotive/Android.bp
index 7e429efa6d..6d8fd8d831 100644
--- a/services/audiopolicy/engineconfigurable/config/example/automotive/Android.bp
+++ b/services/audiopolicy/engineconfigurable/config/example/automotive/Android.bp
@@ -37,10 +37,10 @@ prebuilt_etc {
     vendor: true,
     src: ":audio_policy_engine_configuration",
     required: [
-        ":audio_policy_engine_criteria.xml",
-        ":audio_policy_engine_criterion_types.xml",
-        ":audio_policy_engine_product_strategies.xml",
-        ":audio_policy_engine_volumes.xml",
+        "audio_policy_engine_criteria.xml",
+        "audio_policy_engine_criterion_types.xml",
+        "audio_policy_engine_product_strategies.xml",
+        "audio_policy_engine_volumes.xml",
     ],
 }
 
diff --git a/services/audiopolicy/engineconfigurable/config/example/caremu/Android.bp b/services/audiopolicy/engineconfigurable/config/example/caremu/Android.bp
index 12a554d8ab..8980103a56 100644
--- a/services/audiopolicy/engineconfigurable/config/example/caremu/Android.bp
+++ b/services/audiopolicy/engineconfigurable/config/example/caremu/Android.bp
@@ -38,7 +38,7 @@ prebuilt_etc {
     vendor: true,
     src: ":audio_policy_engine_configuration",
     required: [
-        ":audio_policy_engine_volumes.xml",
+        "audio_policy_engine_volumes.xml",
         "audio_policy_engine_criteria.xml",
         "audio_policy_engine_criterion_types.xml",
         "audio_policy_engine_product_strategies.xml",
diff --git a/services/audiopolicy/engineconfigurable/config/example/phone/Android.bp b/services/audiopolicy/engineconfigurable/config/example/phone/Android.bp
index b0a4dfdd11..0cff532fa8 100644
--- a/services/audiopolicy/engineconfigurable/config/example/phone/Android.bp
+++ b/services/audiopolicy/engineconfigurable/config/example/phone/Android.bp
@@ -37,10 +37,10 @@ prebuilt_etc {
     vendor: true,
     src: ":audio_policy_engine_configuration",
     required: [
-        ":audio_policy_engine_criteria.xml",
-        ":audio_policy_engine_criterion_types.xml",
-        ":audio_policy_engine_product_strategies.xml",
-        ":audio_policy_engine_volumes.xml",
+        "audio_policy_engine_criteria.xml",
+        "audio_policy_engine_criterion_types.xml",
+        "audio_policy_engine_product_strategies.xml",
+        "audio_policy_engine_volumes.xml",
     ],
 }
 
diff --git a/services/audiopolicy/engineconfigurable/config/example/phone/audio_policy_engine_product_strategies.xml b/services/audiopolicy/engineconfigurable/config/example/phone/audio_policy_engine_product_strategies.xml
index 0ddf66d3af..b6ec02c63f 100644
--- a/services/audiopolicy/engineconfigurable/config/example/phone/audio_policy_engine_product_strategies.xml
+++ b/services/audiopolicy/engineconfigurable/config/example/phone/audio_policy_engine_product_strategies.xml
@@ -86,6 +86,12 @@
         </AttributesGroup>
     </ProductStrategy>
 
+    <ProductStrategy name="STRATEGY_CALL_ASSISTANT">
+        <AttributesGroup streamType="AUDIO_STREAM_CALL_ASSISTANT" volumeGroup="call_assistant">
+            <Attributes> <Usage value="AUDIO_USAGE_CALL_ASSISTANT"/> </Attributes>
+        </AttributesGroup>
+    </ProductStrategy>
+
     <!-- Used to identify the volume of audio streams exclusively transmitted through the  speaker
          (TTS) of the device -->
     <ProductStrategy name="STRATEGY_TRANSMITTED_THROUGH_SPEAKER">
diff --git a/services/audiopolicy/engineconfigurable/config/src/CapEngineConfig.cpp b/services/audiopolicy/engineconfigurable/config/src/CapEngineConfig.cpp
index 0f753d3e7b..30f3849e86 100644
--- a/services/audiopolicy/engineconfigurable/config/src/CapEngineConfig.cpp
+++ b/services/audiopolicy/engineconfigurable/config/src/CapEngineConfig.cpp
@@ -38,6 +38,7 @@
 #include <media/convert.h>
 #include <system/audio_config.h>
 #include <utils/Log.h>
+#include <EngineConfig.h>
 
 namespace android {
 
@@ -61,7 +62,6 @@ static constexpr const char *gLegacyForcePrefix = "AUDIO_POLICY_FORCE_";
 static constexpr const char *gLegacyStreamPrefix = "AUDIO_STREAM_";
 static constexpr const char *gLegacySourcePrefix = "AUDIO_SOURCE_";
 static constexpr const char *gPolicyParamPrefix = "/Policy/policy/";
-static constexpr const char *gVendorStrategyPrefix = "vx_";
 
 namespace {
 
@@ -368,21 +368,6 @@ ConversionResult<CapConfiguration> aidl2legacy_AudioHalCapConfiguration_CapConfi
     return legacy;
 }
 
-ConversionResult<std::string> aidl2legacy_AudioHalProductStrategyId_StrategyParamName(
-        int id) {
-    std::string strategyName;
-    if (id < media::audio::common::AudioHalProductStrategy::VENDOR_STRATEGY_ID_START) {
-        strategyName = legacy_strategy_to_string(static_cast<legacy_strategy>(id));
-        if (strategyName.empty()) {
-            ALOGE("%s Invalid legacy strategy id %d", __func__, id);
-            return unexpected(BAD_VALUE);
-        }
-    } else {
-        strategyName = gVendorStrategyPrefix + std::to_string(id);
-    }
-    return strategyName;
-}
-
 ConversionResult<ConfigurableElementValue> aidl2legacy_ParameterSetting_ConfigurableElementValue(
         const AudioHalCapParameter& aidl) {
     ConfigurableElementValue legacy;
@@ -405,7 +390,7 @@ ConversionResult<ConfigurableElementValue> aidl2legacy_ParameterSetting_Configur
             }
             legacy.configurableElement.path = std::string(gPolicyParamPrefix)
                     + "product_strategies/"
-                    + VALUE_OR_RETURN(aidl2legacy_AudioHalProductStrategyId_StrategyParamName(
+                    + VALUE_OR_RETURN(engineConfig::aidlAudioHalProductStrategyIdToName(
                             strategyDevice.id))
                     + "/selected_output_devices/mask/" + deviceLiteral;
             break;
@@ -414,7 +399,7 @@ ConversionResult<ConfigurableElementValue> aidl2legacy_ParameterSetting_Configur
             auto strategyAddress = aidl.get<AudioHalCapParameter::strategyDeviceAddress>();
             legacy.configurableElement.path = std::string(gPolicyParamPrefix)
                     + "product_strategies/"
-                    + VALUE_OR_RETURN(aidl2legacy_AudioHalProductStrategyId_StrategyParamName(
+                    + VALUE_OR_RETURN(engineConfig::aidlAudioHalProductStrategyIdToName(
                             strategyAddress.id))
                     + "/device_address";
             literalValue = strategyAddress.deviceAddress.get<AudioDeviceAddress::id>();
diff --git a/services/audiopolicy/engineconfigurable/src/Engine.cpp b/services/audiopolicy/engineconfigurable/src/Engine.cpp
index 4192714300..d7fa443799 100644
--- a/services/audiopolicy/engineconfigurable/src/Engine.cpp
+++ b/services/audiopolicy/engineconfigurable/src/Engine.cpp
@@ -146,6 +146,9 @@ status_t Engine::loadWithFallback(const T& configSource) {
     };
 
     loadCriteria(result.parsedConfig->criteria, result.parsedConfig->criterionTypes);
+
+    initializeLegacyStrategyMaps();
+
     return result.nbSkippedElement == 0? NO_ERROR : BAD_VALUE;
 }
 
diff --git a/services/audiopolicy/engineconfigurable/tools/capBuildCommonTypesStructureFile.py b/services/audiopolicy/engineconfigurable/tools/capBuildCommonTypesStructureFile.py
index c883ac1f63..cdf332bb41 100755
--- a/services/audiopolicy/engineconfigurable/tools/capBuildCommonTypesStructureFile.py
+++ b/services/audiopolicy/engineconfigurable/tools/capBuildCommonTypesStructureFile.py
@@ -134,6 +134,7 @@ def parseAndroidAudioFile(androidaudiobaseheaderFile):
 
     multi_bit_output_device_shift = 32
     input_device_shift = 0
+    output_device_shift = 0
 
     for line_number, line in enumerate(androidaudiobaseheaderFile):
         match = criteria_pattern.match(line)
@@ -164,22 +165,13 @@ def parseAndroidAudioFile(androidaudiobaseheaderFile):
                 if component_type_literal == "default":
                     component_type_literal = "stub"
 
-                string_int = int(component_type_numerical_value, 0)
-                num_bits = bin(string_int).count("1")
-                if num_bits > 1:
-                    logging.info("The value {} is for criterion {} binary rep {} has {} bits sets"
-                        .format(component_type_numerical_value, component_type_name, bin(string_int), num_bits))
-                    string_int = 2**multi_bit_output_device_shift
-                    logging.info("new val assigned is {} {}" .format(string_int, bin(string_int)))
-                    multi_bit_output_device_shift += 1
-                    component_type_numerical_value = str(string_int)
+                component_type_numerical_value = str(2**output_device_shift)
+                output_device_shift += 1
 
             # Remove duplicated numerical values
             if int(component_type_numerical_value, 0) in all_component_types[component_type_name].values():
-                logging.info("The value {}:{} is duplicated for criterion {}, KEEPING LATEST".format(component_type_numerical_value, component_type_literal, component_type_name))
-                for key in list(all_component_types[component_type_name]):
-                    if all_component_types[component_type_name][key] == int(component_type_numerical_value, 0):
-                        del all_component_types[component_type_name][key]
+                logging.error("Duplicated value {}:{} for criterion {}".format(component_type_numerical_value, component_type_literal, component_type_name))
+                sys.exit(main())
 
             all_component_types[component_type_name][component_type_literal] = int(component_type_numerical_value, 0)
 
diff --git a/services/audiopolicy/enginedefault/config/example/Android.bp b/services/audiopolicy/enginedefault/config/example/Android.bp
index 31f9a46725..fa686f43d6 100644
--- a/services/audiopolicy/enginedefault/config/example/Android.bp
+++ b/services/audiopolicy/enginedefault/config/example/Android.bp
@@ -34,9 +34,9 @@ prebuilt_etc {
     vendor: true,
     src: "phone/audio_policy_engine_configuration.xml",
     required: [
-        ":audio_policy_engine_default_stream_volumes.xml",
-        ":audio_policy_engine_product_strategies.xml",
-        ":audio_policy_engine_stream_volumes.xml",
+        "audio_policy_engine_default_stream_volumes.xml",
+        "audio_policy_engine_product_strategies.xml",
+        "audio_policy_engine_stream_volumes.xml",
     ],
 }
 
diff --git a/services/audiopolicy/enginedefault/config/example/phone/audio_policy_engine_product_strategies.xml b/services/audiopolicy/enginedefault/config/example/phone/audio_policy_engine_product_strategies.xml
index 0ddf66d3af..b6ec02c63f 100644
--- a/services/audiopolicy/enginedefault/config/example/phone/audio_policy_engine_product_strategies.xml
+++ b/services/audiopolicy/enginedefault/config/example/phone/audio_policy_engine_product_strategies.xml
@@ -86,6 +86,12 @@
         </AttributesGroup>
     </ProductStrategy>
 
+    <ProductStrategy name="STRATEGY_CALL_ASSISTANT">
+        <AttributesGroup streamType="AUDIO_STREAM_CALL_ASSISTANT" volumeGroup="call_assistant">
+            <Attributes> <Usage value="AUDIO_USAGE_CALL_ASSISTANT"/> </Attributes>
+        </AttributesGroup>
+    </ProductStrategy>
+
     <!-- Used to identify the volume of audio streams exclusively transmitted through the  speaker
          (TTS) of the device -->
     <ProductStrategy name="STRATEGY_TRANSMITTED_THROUGH_SPEAKER">
diff --git a/services/audiopolicy/enginedefault/src/Engine.cpp b/services/audiopolicy/enginedefault/src/Engine.cpp
index e2e5ec6678..19b9fbb9c5 100644
--- a/services/audiopolicy/enginedefault/src/Engine.cpp
+++ b/services/audiopolicy/enginedefault/src/Engine.cpp
@@ -38,10 +38,6 @@
 
 namespace android::audio_policy {
 
-static const std::vector<legacy_strategy_map>& getLegacyStrategy() {
-    static const std::vector<legacy_strategy_map> legacyStrategy = getLegacyStrategyMap();
-    return legacyStrategy;
-}
 
 status_t Engine::loadFromHalConfigWithFallback(
         const media::audio::common::AudioHalEngineConfig& aidlConfig) {
@@ -58,11 +54,7 @@ status_t Engine::loadWithFallback(const T& configSource) {
     ALOGE_IF(result.nbSkippedElement != 0,
              "Policy Engine configuration is partially invalid, skipped %zu elements",
              result.nbSkippedElement);
-
-    auto legacyStrategy = getLegacyStrategy();
-    for (const auto &strategy : legacyStrategy) {
-        mLegacyStrategyMap[getProductStrategyByName(strategy.name)] = strategy.id;
-    }
+    initializeLegacyStrategyMaps();
 
     return OK;
 }
@@ -255,8 +247,7 @@ void Engine::filterOutputDevicesForStrategy(legacy_strategy strategy,
 
 product_strategy_t Engine::remapStrategyFromContext(product_strategy_t strategy,
                                                  const SwAudioOutputCollection &outputs) const {
-    auto legacyStrategy = mLegacyStrategyMap.find(strategy) != end(mLegacyStrategyMap) ?
-                          mLegacyStrategyMap.at(strategy) : STRATEGY_NONE;
+    auto legacyStrategy = getLegacyStrategyFromProduct(strategy);
 
     if (isInCall()) {
         switch (legacyStrategy) {
@@ -429,8 +420,7 @@ DeviceVector Engine::getDevicesForStrategyInt(legacy_strategy strategy,
             legacy_strategy topActiveStrategy = STRATEGY_NONE;
             for (const auto &ps : getOrderedProductStrategies()) {
                 if (outputs.isStrategyActive(ps)) {
-                    topActiveStrategy =  mLegacyStrategyMap.find(ps) != end(mLegacyStrategyMap) ?
-                            mLegacyStrategyMap.at(ps) : STRATEGY_NONE;
+                    topActiveStrategy =  getLegacyStrategyFromProduct(ps);
                     break;
                 }
             }
@@ -510,6 +500,7 @@ DeviceVector Engine::getDevicesForStrategyInt(legacy_strategy strategy,
                     SONIFICATION_RESPECTFUL_AFTER_MUSIC_DELAY);
 
         bool ringActiveLocally = outputs.isActiveLocally(toVolumeSource(AUDIO_STREAM_RING), 0);
+
         // - for STRATEGY_SONIFICATION and ringtone active:
         // if SPEAKER was selected, and SPEAKER_SAFE is available, use SPEAKER_SAFE instead
         // - for STRATEGY_SONIFICATION_RESPECTFUL:
@@ -784,15 +775,6 @@ void Engine::setStrategyDevices(const sp<ProductStrategy>& strategy, const Devic
     strategy->setDeviceAddress(devices.getFirstValidAddress().c_str());
 }
 
-product_strategy_t Engine::getProductStrategyFromLegacy(legacy_strategy legacyStrategy) const {
-    for (const auto& strategyMap : mLegacyStrategyMap) {
-        if (strategyMap.second == legacyStrategy) {
-            return strategyMap.first;
-        }
-    }
-    return PRODUCT_STRATEGY_NONE;
-}
-
 audio_devices_t Engine::getPreferredDeviceTypeForLegacyStrategy(
         const DeviceVector& availableOutputDevices, legacy_strategy legacyStrategy) const {
     product_strategy_t strategy = getProductStrategyFromLegacy(legacyStrategy);
@@ -811,8 +793,7 @@ DeviceVector Engine::getDevicesForProductStrategy(product_strategy_t strategy) c
     // checking preferred device for strategy and applying default routing rules
     strategy = remapStrategyFromContext(strategy, outputs);
 
-    auto legacyStrategy = mLegacyStrategyMap.find(strategy) != end(mLegacyStrategyMap) ?
-                          mLegacyStrategyMap.at(strategy) : STRATEGY_NONE;
+    auto legacyStrategy = getLegacyStrategyFromProduct(strategy);
 
     DeviceVector availableOutputDevices = getApmObserver()->getAvailableOutputDevices();
 
diff --git a/services/audiopolicy/enginedefault/src/Engine.h b/services/audiopolicy/enginedefault/src/Engine.h
index 188bc662d3..fbdd2f3b5e 100644
--- a/services/audiopolicy/enginedefault/src/Engine.h
+++ b/services/audiopolicy/enginedefault/src/Engine.h
@@ -88,7 +88,6 @@ private:
 
     sp<DeviceDescriptor> getDeviceForInputSource(audio_source_t inputSource) const;
 
-    product_strategy_t getProductStrategyFromLegacy(legacy_strategy legacyStrategy) const;
     audio_devices_t getPreferredDeviceTypeForLegacyStrategy(
         const DeviceVector& availableOutputDevices, legacy_strategy legacyStrategy) const;
     DeviceVector getPreferredAvailableDevicesForInputSource(
@@ -98,7 +97,6 @@ private:
 
     bool isBtScoActive(DeviceVector& availableOutputDevices) const;
 
-    std::map<product_strategy_t, legacy_strategy> mLegacyStrategyMap;
 };
 } // namespace audio_policy
 } // namespace android
diff --git a/services/audiopolicy/fuzzer/audiopolicy_fuzzer.cpp b/services/audiopolicy/fuzzer/audiopolicy_fuzzer.cpp
index 42c37280e8..f9f517dd66 100644
--- a/services/audiopolicy/fuzzer/audiopolicy_fuzzer.cpp
+++ b/services/audiopolicy/fuzzer/audiopolicy_fuzzer.cpp
@@ -261,8 +261,6 @@ bool AudioPolicyManagerFuzzer::getOutputForAttr(
     AudioPolicyInterface::output_type_t outputType;
     bool isSpatialized;
     bool isBitPerfect;
-    float volume;
-    bool muted;
 
     // TODO b/182392769: use attribution source util
     AttributionSourceState attributionSource;
@@ -270,7 +268,7 @@ bool AudioPolicyManagerFuzzer::getOutputForAttr(
     attributionSource.token = sp<BBinder>::make();
     if (mManager->getOutputForAttr(&attr, output, AUDIO_SESSION_NONE, &stream, attributionSource,
             &config, &flags, selectedDeviceIds, portId, {}, &outputType, &isSpatialized,
-            &isBitPerfect, &volume, &muted) != OK) {
+            &isBitPerfect) != OK) {
         return false;
     }
     if (*output == AUDIO_IO_HANDLE_NONE || *portId == AUDIO_PORT_HANDLE_NONE) {
@@ -811,7 +809,9 @@ bool AudioPolicyManagerFuzzerDPMixRecordInjection::initialize() {
     getOutputForAttr(&selectedDeviceIds, mAudioConfig.format, mAudioConfig.channel_mask,
                      mAudioConfig.sample_rate /*sampleRate*/, AUDIO_OUTPUT_FLAG_NONE,
                      nullptr /*output*/, &mPortId, attr);
-    ret = mManager->startOutput(mPortId);
+    bool muted;
+    float volume;
+    ret = mManager->startOutput(mPortId, &volume, &muted);
     if (ret != NO_ERROR) {
         return false;
     }
diff --git a/services/audiopolicy/managerdefault/Android.bp b/services/audiopolicy/managerdefault/Android.bp
index 94be786c37..2f44ec68a4 100644
--- a/services/audiopolicy/managerdefault/Android.bp
+++ b/services/audiopolicy/managerdefault/Android.bp
@@ -23,7 +23,6 @@ cc_library_shared {
     export_include_dirs: ["."],
 
     shared_libs: [
-        "com.android.media.audio-aconfig-cc",
         "libaudiofoundation",
         "libaudiopolicy",
         "libaudiopolicycomponents",
@@ -43,7 +42,9 @@ cc_library_shared {
         "audioclient-types-aidl-cpp",
         "audiopolicy-aidl-cpp",
         // Flag support
+        "android.media.audio-aconfig-cc",
         "android.media.audiopolicy-aconfig-cc",
+        "com.android.media.audio-aconfig-cc",
         "com.android.media.audioserver-aconfig-cc",
         "framework-permission-aidl-cpp",
         "libaudioclient_aidl_conversion",
diff --git a/services/audiopolicy/managerdefault/AudioPolicyManager.cpp b/services/audiopolicy/managerdefault/AudioPolicyManager.cpp
index ac8062e5c6..a3b2fe450e 100644
--- a/services/audiopolicy/managerdefault/AudioPolicyManager.cpp
+++ b/services/audiopolicy/managerdefault/AudioPolicyManager.cpp
@@ -41,6 +41,7 @@
 #include <Serializer.h>
 #include <android/media/audio/common/AudioMMapPolicy.h>
 #include <android/media/audio/common/AudioPort.h>
+#include <android_media_audio.h>
 #include <com_android_media_audio.h>
 #include <android_media_audiopolicy.h>
 #include <com_android_media_audioserver.h>
@@ -73,7 +74,8 @@ using android::media::audio::common::AudioPortDeviceExt;
 using android::media::audio::common::AudioPortExt;
 using android::media::audio::common::AudioConfigBase;
 using binder::Status;
-using com::android::media::audioserver::fix_call_audio_patch;
+using com::android::media::audioserver::use_bt_sco_for_media;
+using com::android::media::audioserver::remove_stream_suspend;
 using content::AttributionSourceState;
 
 //FIXME: workaround for truncated touch sounds
@@ -189,6 +191,34 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(audio_devices_t deviceT
     }
 }
 
+void AudioPolicyManager::addRoutableDeviceToProfiles(const sp<DeviceDescriptor> &device)
+{
+    for (auto &hwModule: mHwModules) {
+        const auto& profiles = audio_is_output_device(device->type())
+              ? hwModule->getOutputProfiles() : hwModule->getInputProfiles();
+
+        for (auto& profile : profiles) {
+            struct audio_port_v7 devicePort{};
+            device->toAudioPort(&devicePort);
+
+            struct audio_port_v7 mixPort{};
+            profile->toAudioPort(&mixPort);
+
+            bool isSupported = profile->supportsDevice(device);
+
+            // When flag is disabled, routable should be equivalent to supported.
+            bool isRoutable =
+                !com::android::media::audioserver::enable_strict_port_routing_checks() ||
+                mpClientInterface->getAudioMixPort(&devicePort, &mixPort,
+                                                   profile->getHalId()) == OK;
+
+            if (isSupported && isRoutable) {
+                profile->addRoutableDevice(device);
+            }
+        }
+    }
+}
+
 status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescriptor> &device,
                                                          audio_policy_dev_state_t state,
                                                          bool deviceSwitch)
@@ -232,6 +262,8 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescript
                 return INVALID_OPERATION;
             }
 
+            addRoutableDeviceToProfiles(device);
+
             if (checkOutputsForDevice(device, state, outputs) != NO_ERROR) {
                 mAvailableOutputDevices.remove(device);
 
@@ -367,7 +399,7 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescript
                 }
                 if (!desc->isDuplicated() && desc->mProfile->hasDynamicAudioProfile() &&
                         !activeMediaDevices.empty() && desc->devices() != activeMediaDevices &&
-                        desc->supportsDevicesForPlayback(activeMediaDevices)) {
+                        desc->routesToDevicesForPlayback(activeMediaDevices)) {
                     // Reopen the output to query the dynamic profiles when there is not active
                     // clients or all active clients will be rerouted. Otherwise, set the flag
                     // `mPendingReopenToQueryProfiles` in the SwOutputDescriptor so that the output
@@ -378,7 +410,7 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescript
                         desc->mPendingReopenToQueryProfiles = true;
                     }
                 }
-                if (!desc->supportsDevicesForPlayback(activeMediaDevices)) {
+                if (!desc->routesToDevicesForPlayback(activeMediaDevices)) {
                     // Clear the flag that previously set for re-querying profiles.
                     desc->mPendingReopenToQueryProfiles = false;
                 }
@@ -415,7 +447,7 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescript
                 return NO_MEMORY;
             }
 
-            // Before checking intputs, broadcast connect event to allow HAL to retrieve dynamic
+            // Before checking inputs, broadcast connect event to allow HAL to retrieve dynamic
             // parameters on newly connected devices (instead of opening the inputs...)
             if (broadcastDeviceConnectionState(
                         device, media::DeviceConnectedState::CONNECTED) != NO_ERROR) {
@@ -425,9 +457,12 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescript
                       device->toString().c_str(), device->getEncodedFormat());
                 return INVALID_OPERATION;
             }
+
             // Propagate device availability to Engine
             setEngineDeviceConnectionState(device, state);
 
+            addRoutableDeviceToProfiles(device);
+
             if (checkInputsForDevice(device, state) != NO_ERROR) {
                 setEngineDeviceConnectionState(device, AUDIO_POLICY_DEVICE_STATE_UNAVAILABLE);
 
@@ -439,7 +474,6 @@ status_t AudioPolicyManager::setDeviceConnectionStateInt(const sp<DeviceDescript
 
                 return INVALID_OPERATION;
             }
-
         } break;
 
         // handle input device disconnection
@@ -737,11 +771,6 @@ status_t AudioPolicyManager::updateCallRoutingInternal(
     audio_attributes_t attr = { .source = AUDIO_SOURCE_VOICE_COMMUNICATION };
     auto txSourceDevice = mEngine->getInputDeviceForAttributes(attr);
 
-    if (!fix_call_audio_patch()) {
-        disconnectTelephonyAudioSource(mCallRxSourceClient);
-        disconnectTelephonyAudioSource(mCallTxSourceClient);
-    }
-
     if (rxDevices.isEmpty()) {
         ALOGW("%s() no selected output device", __func__);
         return INVALID_OPERATION;
@@ -793,9 +822,7 @@ status_t AudioPolicyManager::updateCallRoutingInternal(
     // Use legacy routing method for voice calls via setOutputDevice() on primary output.
     // Otherwise, create two audio patches for TX and RX path.
     if (!createRxPatch) {
-        if (fix_call_audio_patch()) {
-            disconnectTelephonyAudioSource(mCallRxSourceClient);
-        }
+        disconnectTelephonyAudioSource(mCallRxSourceClient);
         if (!hasPrimaryOutput()) {
             ALOGW("%s() no primary output available", __func__);
             return INVALID_OPERATION;
@@ -818,7 +845,7 @@ status_t AudioPolicyManager::updateCallRoutingInternal(
             }
         }
         connectTelephonyTxAudioSource(txSourceDevice, txSinkDevice, delayMs);
-    } else if (fix_call_audio_patch()) {
+    } else {
         disconnectTelephonyAudioSource(mCallTxSourceClient);
     }
     if (waitMs != nullptr) {
@@ -843,20 +870,16 @@ void AudioPolicyManager::connectTelephonyRxAudioSource(uint32_t delayMs)
 {
     const auto aa = mEngine->getAttributesForStreamType(AUDIO_STREAM_VOICE_CALL);
 
-    if (fix_call_audio_patch()) {
-        if (mCallRxSourceClient != nullptr) {
-            DeviceVector rxDevices =
-                  mEngine->getOutputDevicesForAttributes(aa, nullptr, false /*fromCache*/);
-            ALOG_ASSERT(!rxDevices.isEmpty() || !mCallRxSourceClient->isConnected(),
-                        "connectTelephonyRxAudioSource(): no device found for call RX source");
-            sp<DeviceDescriptor> rxDevice = rxDevices.itemAt(0);
-            if (mCallRxSourceClient->isConnected()
-                    && mCallRxSourceClient->sinkDevice()->equals(rxDevice)) {
-                return;
-            }
-            disconnectTelephonyAudioSource(mCallRxSourceClient);
+    if (mCallRxSourceClient != nullptr) {
+        DeviceVector rxDevices =
+              mEngine->getOutputDevicesForAttributes(aa, nullptr, false /*fromCache*/);
+        ALOG_ASSERT(!rxDevices.isEmpty() || !mCallRxSourceClient->isConnected(),
+                    "connectTelephonyRxAudioSource(): no device found for call RX source");
+        sp<DeviceDescriptor> rxDevice = rxDevices.itemAt(0);
+        if (mCallRxSourceClient->isConnected()
+                && mCallRxSourceClient->sinkDevice()->equals(rxDevice)) {
+            return;
         }
-    } else {
         disconnectTelephonyAudioSource(mCallRxSourceClient);
     }
 
@@ -896,15 +919,11 @@ void AudioPolicyManager::connectTelephonyTxAudioSource(
         return;
     }
 
-    if (fix_call_audio_patch()) {
-        if (mCallTxSourceClient != nullptr) {
-            if (mCallTxSourceClient->isConnected()
-                    && mCallTxSourceClient->srcDevice()->equals(srcDevice)) {
-                return;
-            }
-            disconnectTelephonyAudioSource(mCallTxSourceClient);
+    if (mCallTxSourceClient != nullptr) {
+        if (mCallTxSourceClient->isConnected()
+                && mCallTxSourceClient->srcDevice()->equals(srcDevice)) {
+            return;
         }
-    } else {
         disconnectTelephonyAudioSource(mCallTxSourceClient);
     }
 
@@ -989,6 +1008,20 @@ void AudioPolicyManager::setPhoneState(audio_mode_t state)
         }
     }
 
+    if (state != AUDIO_MODE_NORMAL && oldState == AUDIO_MODE_NORMAL) {
+        std::map<audio_io_handle_t, DeviceVector> outputsToReopen;
+        for (size_t i = 0; i < mOutputs.size(); i++) {
+            sp<SwAudioOutputDescriptor> desc = mOutputs.valueAt(i);
+            if (desc->mPreferredAttrInfo != nullptr) {
+                DeviceVector newDevices = getNewOutputDevices(desc, true /*fromCache*/);
+                // If the output is using preferred mixer attributes and the audio mode is not
+                // normal, the output need to reopen with default configuration.
+                outputsToReopen.emplace(mOutputs.keyAt(i), newDevices);
+            }
+        }
+        reopenOutputsWithDevices(outputsToReopen);
+    }
+
     if (state == AUDIO_MODE_IN_CALL) {
         (void)updateCallRouting(false /*fromCache*/, delayMs);
     } else {
@@ -1007,25 +1040,16 @@ void AudioPolicyManager::setPhoneState(audio_mode_t state)
         }
     }
 
-    std::map<audio_io_handle_t, DeviceVector> outputsToReopen;
     // reevaluate routing on all outputs in case tracks have been started during the call
     for (size_t i = 0; i < mOutputs.size(); i++) {
         sp<SwAudioOutputDescriptor> desc = mOutputs.valueAt(i);
         DeviceVector newDevices = getNewOutputDevices(desc, true /*fromCache*/);
-        if (state != AUDIO_MODE_NORMAL && oldState == AUDIO_MODE_NORMAL
-                && desc->mPreferredAttrInfo != nullptr) {
-            // If the output is using preferred mixer attributes and the audio mode is not normal,
-            // the output need to reopen with default configuration.
-            outputsToReopen.emplace(mOutputs.keyAt(i), newDevices);
-            continue;
-        }
         if (state != AUDIO_MODE_IN_CALL || (desc != mPrimaryOutput && !isTelephonyRxOrTx(desc))) {
             bool forceRouting = !newDevices.isEmpty();
             setOutputDevices(__func__, desc, newDevices, forceRouting, 0 /*delayMs*/, nullptr,
                              true /*requiresMuteCheck*/, !forceRouting /*requiresVolumeCheck*/);
         }
     }
-    reopenOutputsWithDevices(outputsToReopen);
 
     checkLeBroadcastRoutes(wasLeUnicastActive, nullptr, delayMs);
 
@@ -1150,17 +1174,22 @@ sp<IOProfile> AudioPolicyManager::searchCompatibleProfileHwModules (
     sp<IOProfile> directOnlyProfile = nullptr;
     sp<IOProfile> compressOffloadProfile = nullptr;
     sp<IOProfile> profile = nullptr;
+    uint32_t additionalMandatoryFlags = 0;
+    if ((flags & AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) != 0) {
+        // For mmap, only select mmap offload if offload is explicitly requested.
+        additionalMandatoryFlags = AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD;
+    }
     for (const auto& hwModule : hwModules) {
         for (const auto& curProfile : hwModule->getOutputProfiles()) {
              if (curProfile->getCompatibilityScore(devices,
                      samplingRate, NULL /*updatedSamplingRate*/,
                      format, NULL /*updatedFormat*/,
                      channelMask, NULL /*updatedChannelMask*/,
-                     flags) == IOProfile::NO_MATCH) {
+                     flags, additionalMandatoryFlags) == IOProfile::NO_MATCH) {
                  continue;
              }
              // reject profiles not corresponding to a device currently available
-             if (!mAvailableOutputDevices.containsAtLeastOne(curProfile->getSupportedDevices())) {
+             if (!mAvailableOutputDevices.containsAtLeastOne(curProfile->getRoutableDevices())) {
                  continue;
              }
              // reject profiles if connected device does not support codec
@@ -1198,11 +1227,11 @@ sp<IOProfile> AudioPolicyManager::getSpatializerOutputProfile(
             }
             if (!devices.empty()) {
                 // reject profiles not corresponding to a device currently available
-                DeviceVector supportedDevices = curProfile->getSupportedDevices();
-                if (!mAvailableOutputDevices.containsAtLeastOne(supportedDevices)) {
+                DeviceVector routableDevices = curProfile->getRoutableDevices();
+                if (!mAvailableOutputDevices.containsAtLeastOne(routableDevices)) {
                     continue;
                 }
-                if (supportedDevices.getDevicesFromDeviceTypeAddrVec(devices).size()
+                if (routableDevices.getDevicesFromDeviceTypeAddrVec(devices).size()
                         != devices.size()) {
                     continue;
                 }
@@ -1451,19 +1480,16 @@ status_t AudioPolicyManager::getOutputForAttrInt(
                 return BAD_VALUE;
             }
 
-            if (com::android::media::audioserver::
-                    fix_concurrent_playback_behavior_with_bit_perfect_client()) {
-                if (info != nullptr && info->getUid() == uid &&
-                    info->configMatches(*config) &&
-                    (mEngine->getPhoneState() != AUDIO_MODE_NORMAL ||
-                            std::any_of(gHighPriorityUseCases.begin(), gHighPriorityUseCases.end(),
-                                        [this, &outputDevices](audio_usage_t usage) {
-                                            return mOutputs.isUsageActiveOnDevice(
-                                                    usage, outputDevices[0]); }))) {
-                    // Bit-perfect request is not allowed when the phone mode is not normal or
-                    // there is any higher priority user case active.
-                    return INVALID_OPERATION;
-                }
+            if (info != nullptr && info->getUid() == uid &&
+                info->configMatches(*config) &&
+                (mEngine->getPhoneState() != AUDIO_MODE_NORMAL ||
+                        std::any_of(gHighPriorityUseCases.begin(), gHighPriorityUseCases.end(),
+                                    [this, &outputDevices](audio_usage_t usage) {
+                                        return mOutputs.isUsageActiveOnDevice(
+                                                usage, outputDevices[0]); }))) {
+                // Bit-perfect request is not allowed when the phone mode is not normal or
+                // there is any higher priority user case active.
+                return INVALID_OPERATION;
             }
         }
         *output = getOutputForDevices(outputDevices, session, resultAttr, config,
@@ -1535,9 +1561,7 @@ status_t AudioPolicyManager::getOutputForAttr(const audio_attributes_t *attr,
                                               std::vector<audio_io_handle_t> *secondaryOutputs,
                                               output_type_t *outputType,
                                               bool *isSpatialized,
-                                              bool *isBitPerfect,
-                                              float *volume,
-                                              bool *muted)
+                                              bool *isBitPerfect)
 {
     // The supplied portId must be AUDIO_PORT_HANDLE_NONE
     if (*portId != AUDIO_PORT_HANDLE_NONE) {
@@ -1597,9 +1621,6 @@ status_t AudioPolicyManager::getOutputForAttr(const audio_attributes_t *attr,
                                   outputDesc->mPolicyMix);
     outputDesc->addClient(clientDesc);
 
-    *volume = Volume::DbToAmpl(outputDesc->getCurVolume(toVolumeSource(resultAttr)));
-    *muted = outputDesc->isMutedByGroup(toVolumeSource(resultAttr));
-
     ALOGV("%s() returns output %d requestedPortIds %s selectedDeviceIds %s for port ID %d",
           __func__, *output, toString(requestedDeviceIds).c_str(),
           toString(*selectedDeviceIds).c_str(), *portId);
@@ -1632,6 +1653,26 @@ status_t AudioPolicyManager::openDirectOutput(audio_stream_type_t stream,
         return NAME_NOT_FOUND;
     }
 
+    // When the device declares exclusive mmap offload, it indicates compressed offload and
+    // mmap offload are mutually exclusive. If one of them is opened, reject the request of the
+    // other one.
+    if (com_android_media_audioserver_mmap_pcm_offload_support() &&
+        property_get_bool("ro.audio.mmap_offload_exclusive", false /*default_value*/) &&
+        (flags & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != 0) {
+        static constexpr uint32_t kMMapOffloadFlags =
+                (AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD | AUDIO_OUTPUT_FLAG_MMAP_NOIRQ);
+        bool offloadOutputMustBeMMap = (flags & kMMapOffloadFlags) == kMMapOffloadFlags;
+        for (size_t i = 0; i < mOutputs.size(); i++) {
+            auto desc = mOutputs.valueAt(i);
+            if (desc->isOffload() && desc->isMmap() != offloadOutputMustBeMMap) {
+                ALOGD("%s, reject %soffload as %soffload is opened",
+                      __func__, (offloadOutputMustBeMMap ? "mmap " : ""),
+                      (offloadOutputMustBeMMap ? "" : "mmap "));
+                return INVALID_OPERATION;
+            }
+        }
+    }
+
     // Do not allow offloading if one non offloadable effect is enabled or MasterMono is enabled.
     // This prevents creating an offloaded track and tearing it down immediately after start
     // when audioflinger detects there is an active non offloadable effect.
@@ -1790,9 +1831,15 @@ audio_io_handle_t AudioPolicyManager::getOutputForDevices(
     } else if (stream == AUDIO_STREAM_VOICE_CALL &&
                audio_is_linear_pcm(config->format) &&
                (*flags & AUDIO_OUTPUT_FLAG_INCALL_MUSIC) == 0) {
-        *flags = (audio_output_flags_t)(AUDIO_OUTPUT_FLAG_VOIP_RX |
-                                       AUDIO_OUTPUT_FLAG_DIRECT);
-        ALOGV("Set VoIP and Direct output flags for PCM format");
+        // TODO b/418144806: define a proper routing policy when multiple output profiles
+        // can be used for voice communication use case.
+        if (*flags & AUDIO_OUTPUT_FLAG_MMAP_NOIRQ) {
+            ALOGV("MMAP flag set, ignoring VoIP & direct output flags");
+        } else {
+            *flags = (audio_output_flags_t)(AUDIO_OUTPUT_FLAG_VOIP_RX |
+                                           AUDIO_OUTPUT_FLAG_DIRECT);
+            ALOGV("Set VoIP and Direct output flags for PCM format");
+        }
     }
 
     // Attach the Ultrasound flag for the AUDIO_CONTENT_TYPE_ULTRASOUND
@@ -1868,22 +1915,19 @@ audio_io_handle_t AudioPolicyManager::getOutputForDevices(
             // at this stage we should ignore the DIRECT flag as no direct output could be
             // found earlier
             *flags = (audio_output_flags_t) (*flags & ~AUDIO_OUTPUT_FLAG_DIRECT);
-            if (com::android::media::audioserver::
-                    fix_concurrent_playback_behavior_with_bit_perfect_client()) {
-                // If the preferred mixer attributes is null, do not select the bit-perfect output
-                // unless the bit-perfect output is the only output.
-                // The bit-perfect output can exist while the passed in preferred mixer attributes
-                // info is null when it is a high priority client. The high priority clients are
-                // ringtone or alarm, which is not a bit-perfect use case.
-                size_t i = 0;
-                while (i < outputs.size() && outputs.size() > 1) {
-                    auto desc = mOutputs.valueFor(outputs[i]);
-                    // The output descriptor must not be null here.
-                    if (desc->isBitPerfect()) {
-                        outputs.removeItemsAt(i);
-                    } else {
-                        i += 1;
-                    }
+            // If the preferred mixer attributes is null, do not select the bit-perfect output
+            // unless the bit-perfect output is the only output.
+            // The bit-perfect output can exist while the passed in preferred mixer attributes
+            // info is null when it is a high priority client. The high priority clients are
+            // ringtone or alarm, which is not a bit-perfect use case.
+            size_t i = 0;
+            while (i < outputs.size() && outputs.size() > 1) {
+                auto desc = mOutputs.valueFor(outputs[i]);
+                // The output descriptor must not be null here.
+                if (desc->isBitPerfect()) {
+                    outputs.removeItemsAt(i);
+                } else {
+                    i += 1;
                 }
             }
             output = selectOutput(
@@ -1964,13 +2008,13 @@ status_t AudioPolicyManager::getMsdProfiles(bool hwAvSync,
     }
     for (const auto &inProfile : inputProfiles) {
         if (hwAvSync == ((inProfile->getFlags() & AUDIO_INPUT_FLAG_HW_AV_SYNC) != 0) &&
-                inProfile->supportsDevice(sourceDevice)) {
+                inProfile->routesToDevice(sourceDevice)) {
             appendAudioProfiles(sourceProfiles, inProfile->getAudioProfiles());
         }
     }
     for (const auto &outProfile : outputProfiles) {
         if (hwAvSync == ((outProfile->getFlags() & AUDIO_OUTPUT_FLAG_HW_AV_SYNC) != 0) &&
-                outProfile->supportsDevice(sinkDevice)) {
+                outProfile->routesToDevice(sinkDevice)) {
             appendAudioProfiles(sinkProfiles, outProfile->getAudioProfiles());
         }
     }
@@ -2354,7 +2398,8 @@ audio_io_handle_t AudioPolicyManager::selectOutput(const SortedVector<audio_io_h
     return bestOutput;
 }
 
-status_t AudioPolicyManager::startOutput(audio_port_handle_t portId)
+status_t AudioPolicyManager::startOutput(
+        audio_port_handle_t portId, float* volume, bool* muted)
 {
     ALOGV("%s portId %d", __FUNCTION__, portId);
 
@@ -2368,8 +2413,7 @@ status_t AudioPolicyManager::startOutput(audio_port_handle_t portId)
     ALOGV("startOutput() output %d, stream %d, session %d",
           outputDesc->mIoHandle, client->stream(), client->session());
 
-    if (com::android::media::audioserver::fix_concurrent_playback_behavior_with_bit_perfect_client()
-            && gHighPriorityUseCases.count(client->attributes().usage) != 0
+    if (gHighPriorityUseCases.count(client->attributes().usage) != 0
             && outputDesc->isBitPerfect()) {
         // Usually, APM selects bit-perfect output for high priority use cases only when
         // bit-perfect output is the only output that can be routed to the selected device.
@@ -2466,13 +2510,24 @@ status_t AudioPolicyManager::startOutput(audio_port_handle_t portId)
         usleep(delayMs * 1000);
     }
 
-    if (status == NO_ERROR &&
-        outputDesc->mPreferredAttrInfo != nullptr &&
-        outputDesc->isBitPerfect() &&
-        com::android::media::audioserver::
-                fix_concurrent_playback_behavior_with_bit_perfect_client()) {
-        // A new client is started on bit-perfect output, update all clients internal mute.
-        updateClientsInternalMute(outputDesc);
+    if (status == NO_ERROR) {
+        if (outputDesc->mPreferredAttrInfo != nullptr &&
+                outputDesc->isBitPerfect()) {
+            // A new client is started on bit-perfect output, update all clients internal mute.
+            updateClientsInternalMute(outputDesc);
+        }
+
+        const auto& attr = client->attributes();
+        if (attr.usage == AUDIO_USAGE_CALL_ASSISTANT
+                || attr.usage == AUDIO_USAGE_VIRTUAL_SOURCE) {
+            // Audio patch and call assistant volume are always max
+            *volume = 1.f;
+            *muted = false;
+        } else {
+            *volume = Volume::DbToAmpl(
+                    outputDesc->getCurVolume(toVolumeSource(attr)));
+            *muted = outputDesc->isMutedByGroup(toVolumeSource(attr));
+        }
     }
 
     return status;
@@ -2585,9 +2640,7 @@ status_t AudioPolicyManager::startSource(const sp<SwAudioOutputDescriptor>& outp
              (beaconMuteLatency > 0));
         uint32_t waitMs = beaconMuteLatency;
         const bool needToCloseBitPerfectOutput =
-                (com::android::media::audioserver::
-                        fix_concurrent_playback_behavior_with_bit_perfect_client() &&
-                gHighPriorityUseCases.count(clientAttr.usage) != 0);
+                (gHighPriorityUseCases.count(clientAttr.usage) != 0);
         std::vector<sp<SwAudioOutputDescriptor>> outputsToReopen;
         for (size_t i = 0; i < mOutputs.size(); i++) {
             sp<SwAudioOutputDescriptor> desc = mOutputs.valueAt(i);
@@ -2596,7 +2649,7 @@ status_t AudioPolicyManager::startSource(const sp<SwAudioOutputDescriptor>& outp
                 // - managed by the same hw module
                 // - supports the currently selected device
                 const bool sharedDevice = outputDesc->sharesHwModuleWith(desc)
-                        && (!desc->filterSupportedDevices(devices).isEmpty());
+                        && (!desc->filterRoutableDevices(devices).isEmpty());
 
                 // force a device change if any other output is:
                 // - managed by the same hw module
@@ -2656,8 +2709,8 @@ status_t AudioPolicyManager::startSource(const sp<SwAudioOutputDescriptor>& outp
         auto &curves = getVolumeCurves(client->attributes());
         if (NO_ERROR != checkAndSetVolume(curves, client->volumeSource(),
                           curves.getVolumeIndex(outputDesc->devices().types()),
-                          outputDesc, outputDesc->devices().types(), 0 /*delay*/,
-                          outputDesc->useHwGain() /*force*/)) {
+                          outputDesc, outputDesc->devices().types(), true /*adjustAttenuation*/,
+                          0 /*delay*/, outputDesc->useHwGain() /*force*/)) {
             // request AudioService to reinitialize the volume curves asynchronously
             ALOGE("checkAndSetVolume failed, requesting volume range init");
             mpClientInterface->onVolumeRangeInitRequest();
@@ -2781,9 +2834,7 @@ status_t AudioPolicyManager::stopOutput(audio_port_handle_t portId)
                 outputReopened = true;
             }
         }
-        if (com::android::media::audioserver::
-                    fix_concurrent_playback_behavior_with_bit_perfect_client() &&
-            !outputReopened && outputDesc->isBitPerfect()) {
+        if (!outputReopened && outputDesc->isBitPerfect()) {
             // Only need to update the clients' internal mute when the output is bit-perfect and it
             // is not reopened.
             updateClientsInternalMute(outputDesc);
@@ -3581,7 +3632,7 @@ void AudioPolicyManager::closeClient(audio_port_handle_t portId)
 
 bool AudioPolicyManager::checkCloseInput(const sp<AudioInputDescriptor>& input) {
     if (input->clientsList().size() == 0
-            || !mAvailableInputDevices.containsAtLeastOne(input->supportedDevices())) {
+            || !mAvailableInputDevices.containsAtLeastOne(input->routableDevices())) {
         return true;
     }
     for (const auto& client : input->clientsList()) {
@@ -3589,7 +3640,7 @@ bool AudioPolicyManager::checkCloseInput(const sp<AudioInputDescriptor>& input)
             mEngine->getInputDeviceForAttributes(
                     client->attributes(), false /*ignorePreferredDevice*/, client->uid(),
                     client->session());
-        if (!input->supportedDevices().contains(device)) {
+        if (!input->routableDevices().contains(device)) {
             return true;
         }
     }
@@ -3676,6 +3727,13 @@ void AudioPolicyManager::initStreamVolume(audio_stream_type_t stream, int indexM
         ALOGE("%s for stream %d: invalid min %d or max %d", __func__, stream , indexMin, indexMax);
         return;
     }
+    if (audio_flags::volume_group_management_update()) {
+        int groupId = mEngine->getVolumeGroupForStreamType(stream, /* fallbackOnDefault= */ false);
+        if (groupId == VOLUME_GROUP_NONE) {
+            ALOGE("%s for stream %d: no group associated", __func__, stream);
+            return;
+        }
+    }
     getVolumeCurves(stream).initVolume(indexMin, indexMax);
 
     // initialize other private stream volumes which follow this one
@@ -3692,6 +3750,11 @@ status_t AudioPolicyManager::setStreamVolumeIndex(audio_stream_type_t stream,
                                                   bool muted,
                                                   audio_devices_t device)
 {
+    if (audio_flags::volume_group_management_update()) {
+        auto group = mEngine->getVolumeGroupForStreamType(stream);
+        ALOGV("%s: stream %s group=%d", __func__, toString(stream).c_str(), group);
+        return setVolumeIndexForGroup(group, index, muted, device);
+    }
     auto attributes = mEngine->getAttributesForStreamType(stream);
     if (attributes == AUDIO_ATTRIBUTES_INITIALIZER) {
         ALOGW("%s: no group for stream %s, bailing out", __func__, toString(stream).c_str());
@@ -3723,26 +3786,30 @@ status_t AudioPolicyManager::setVolumeIndexForAttributes(const audio_attributes_
 {
     // Get Volume group matching the Audio Attributes
     auto group = mEngine->getVolumeGroupForAttributes(attributes);
-    if (group == VOLUME_GROUP_NONE) {
-        ALOGD("%s: no group matching with %s", __FUNCTION__, toString(attributes).c_str());
+    ALOGV("%s: group %d matching with %s index %d",
+          __FUNCTION__, group, toString(attributes).c_str(), index);
+    return setVolumeIndexForGroup(group, index, muted, device);
+}
+
+status_t AudioPolicyManager::setVolumeIndexForGroup(volume_group_t group,
+                                                       int index, bool muted,
+                                                       audio_devices_t device)
+{
+    if (!mEngine->isValidVolumeGroup(group)) {
+        ALOGD("%s: Invalid group id %d", __FUNCTION__, group);
         return BAD_VALUE;
     }
-    ALOGV("%s: group %d matching with %s index %d",
-            __FUNCTION__, group, toString(attributes).c_str(), index);
-    if (mEngine->getStreamTypeForAttributes(attributes) == AUDIO_STREAM_PATCH) {
-        ALOGV("%s: cannot change volume for PATCH stream, attrs: %s",
-                __FUNCTION__, toString(attributes).c_str());
+    VolumeSource vs = toVolumeSource(group);
+    if (toVolumeSource(AUDIO_STREAM_PATCH, false) == vs) {
+        ALOGV("%s: cannot change volume for PATCH stream, group id: %d", __func__, group);
         return NO_ERROR;
     }
     status_t status = NO_ERROR;
-    IVolumeCurves &curves = getVolumeCurves(attributes);
-    VolumeSource vs = toVolumeSource(group);
+    IVolumeCurves &curves = getVolumeCurves(group);
     // AUDIO_STREAM_BLUETOOTH_SCO is only used for volume control so we remap
     // to AUDIO_STREAM_VOICE_CALL to match with relevant playback activity
     VolumeSource activityVs = (vs == toVolumeSource(AUDIO_STREAM_BLUETOOTH_SCO, false)) ?
             toVolumeSource(AUDIO_STREAM_VOICE_CALL, false) : vs;
-    product_strategy_t strategy = mEngine->getProductStrategyForAttributes(attributes);
-
 
     status = setVolumeCurveIndex(index, muted, device, curves);
     if (status != NO_ERROR) {
@@ -3766,7 +3833,7 @@ status_t AudioPolicyManager::setVolumeIndexForAttributes(const audio_attributes_
     resetDeviceTypes(curSrcDevices, curSrcDevice);
 
     // update volume on all outputs and streams matching the following:
-    // - The requested stream (or a stream matching for volume control) is active on the output
+    // - The requested volume source (or a volume source for volume control) is active on the output
     // - The device (or devices) selected by the engine for this stream includes
     // the requested device
     // - For non default requested device, currently selected device on the output is either the
@@ -3805,50 +3872,20 @@ status_t AudioPolicyManager::setVolumeIndexForAttributes(const audio_attributes_
         // If a higher priority strategy is active, and the output is routed to a device with a
         // HW Gain management, do not change the volume
         if (desc->useHwGain()) {
-            applyVolume = false;
             bool swMute = com_android_media_audio_ring_my_car() ? curves.isMuted() : (index == 0);
             // If the volume source is active with higher priority source, ensure at least Sw Muted
             desc->setSwMute(swMute, vs, curves.getStreamTypes(), curDevices, 0 /*delayMs*/);
-            for (const auto &productStrategy : mEngine->getOrderedProductStrategies()) {
-                auto activeClients = desc->clientsList(true /*activeOnly*/, productStrategy,
-                                                       false /*preferredDevice*/);
-                if (activeClients.empty()) {
-                    continue;
-                }
-                bool isPreempted = false;
-                bool isHigherPriority = productStrategy < strategy;
-                for (const auto &client : activeClients) {
-                    if (isHigherPriority && (client->volumeSource() != activityVs)) {
-                        ALOGV("%s: Strategy=%d (\nrequester:\n"
-                              " group %d, volumeGroup=%d attributes=%s)\n"
-                              " higher priority source active:\n"
-                              " volumeGroup=%d attributes=%s) \n"
-                              " on output %zu, bailing out", __func__, productStrategy,
-                              group, group, toString(attributes).c_str(),
-                              client->volumeSource(), toString(client->attributes()).c_str(), i);
-                        applyVolume = false;
-                        isPreempted = true;
-                        break;
-                    }
-                    // However, continue for loop to ensure no higher prio clients running on output
-                    if (client->volumeSource() == activityVs) {
-                        applyVolume = true;
-                    }
-                }
-                if (isPreempted || applyVolume) {
-                    break;
-                }
-            }
-            if (!applyVolume) {
+            if (!desc->canSetVolumeForVolumeSource(activityVs)) {
                 continue; // next output
             }
         }
         //FIXME: workaround for truncated touch sounds
         // delayed volume change for system stream to be removed when the problem is
         // handled by system UI
-        status_t volStatus = checkAndSetVolume(curves, vs, index, desc, curDevices,
-                    ((vs == toVolumeSource(AUDIO_STREAM_SYSTEM, false))?
-                         TOUCH_SOUND_FIXED_DELAY_MS : 0));
+        status_t volStatus = checkAndSetVolume(curves, vs, index, desc,
+                                               curDevices, /*adjustAttenuation*/true,
+                                               ((vs == toVolumeSource(AUDIO_STREAM_SYSTEM, false)) ?
+                                                TOUCH_SOUND_FIXED_DELAY_MS : 0));
         if (volStatus != NO_ERROR) {
             status = volStatus;
         }
@@ -3905,16 +3942,25 @@ status_t AudioPolicyManager::setVolumeCurveIndex(int index,
 
 status_t AudioPolicyManager::getVolumeIndexForAttributes(const audio_attributes_t &attr,
                                                          int &index,
-                                                         audio_devices_t device)
-{
-    // if device is AUDIO_DEVICE_OUT_DEFAULT_FOR_VOLUME, return volume for device selected for this
+                                                         audio_devices_t device) {
+    auto group = mEngine->getVolumeGroupForAttributes(attr);
+    return getVolumeIndexForGroup(group, index, device);
+}
+
+status_t AudioPolicyManager::getVolumeIndexForGroup(volume_group_t groupId, int &index,
+                                                       audio_devices_t device) {
+    if (!mEngine->isValidVolumeGroup(groupId)) {
+        ALOGD("%s: Invalid group id %d", __FUNCTION__, groupId);
+        return BAD_VALUE;
+    }
+    // If device is AUDIO_DEVICE_OUT_DEFAULT_FOR_VOLUME, return volume for device selected for this
     // stream by the engine.
     DeviceTypeSet deviceTypes = {device};
     if (device == AUDIO_DEVICE_OUT_DEFAULT_FOR_VOLUME) {
         deviceTypes = mEngine->getOutputDevicesForAttributes(
-                attr, nullptr, true /*fromCache*/).types();
+                mEngine->getAttributesForVolumeGroup(groupId), nullptr, true /*fromCache*/).types();
     }
-    return getVolumeIndex(getVolumeCurves(attr), index, deviceTypes);
+    return getVolumeIndex(getVolumeCurves(groupId), index, deviceTypes);
 }
 
 status_t AudioPolicyManager::getVolumeIndex(const IVolumeCurves &curves,
@@ -3943,6 +3989,42 @@ status_t AudioPolicyManager::getMaxVolumeIndexForAttributes(const audio_attribut
     return NO_ERROR;
 }
 
+status_t AudioPolicyManager::getMinVolumeIndexForGroup(volume_group_t groupId, int &index)
+{
+    if (!mEngine->isValidVolumeGroup(groupId)) {
+        ALOGD("%s: Invalid group id %d", __FUNCTION__, groupId);
+        return BAD_VALUE;
+    }
+    index = getVolumeCurves(groupId).getVolumeIndexMin();
+    return NO_ERROR;
+}
+
+status_t AudioPolicyManager::setMinVolumeIndexForGroup(volume_group_t groupId, int index){
+    if (!mEngine->isValidVolumeGroup(groupId)) {
+        ALOGD("%s: Invalid group id %d", __FUNCTION__, groupId);
+        return BAD_VALUE;
+    }
+    return getVolumeCurves(groupId).setVolumeIndexMin(index);
+}
+
+status_t AudioPolicyManager::getMaxVolumeIndexForGroup(volume_group_t groupId, int &index)
+{
+    if (!mEngine->isValidVolumeGroup(groupId)) {
+        ALOGD("%s: Invalid group id %d", __FUNCTION__, groupId);
+        return BAD_VALUE;
+    }
+    index = getVolumeCurves(groupId).getVolumeIndexMax();
+    return NO_ERROR;
+}
+
+status_t AudioPolicyManager::setMaxVolumeIndexForGroup(volume_group_t groupId, int index) {
+    if (!mEngine->isValidVolumeGroup(groupId)) {
+        ALOGD("%s: Invalid group id %d", __FUNCTION__, groupId);
+        return BAD_VALUE;
+    }
+    return getVolumeCurves(groupId).setVolumeIndexMax(index);
+}
+
 audio_io_handle_t AudioPolicyManager::selectOutputForMusicEffects()
 {
     // select one output among several suitable for global effects.
@@ -4261,14 +4343,10 @@ status_t AudioPolicyManager::registerPolicyMixes(const Vector<AudioMix>& mixes)
         }
     }
     if (res != NO_ERROR) {
-        if (audio_flags::audio_mix_ownership()) {
-            // Only unregister mixes that were actually registered to not accidentally unregister
-            // mixes that already existed previously.
-            unregisterPolicyMixes(registeredMixes);
-            registeredMixes.clear();
-        } else {
-            unregisterPolicyMixes(mixes);
-        }
+        // Only unregister mixes that were actually registered to not accidentally unregister
+        // mixes that already existed previously.
+        unregisterPolicyMixes(registeredMixes);
+        registeredMixes.clear();
     } else if (checkOutputs) {
         checkForDeviceAndOutputChanges();
         changeOutputDevicesMuteState(devices);
@@ -4315,9 +4393,6 @@ status_t AudioPolicyManager::unregisterPolicyMixes(Vector<AudioMix> mixes)
                                                         address.c_str(),
                                                         "remote-submix",
                                                         AUDIO_FORMAT_DEFAULT);
-                    if (!audio_flags::audio_mix_ownership()) {
-                        res = currentRes;
-                    }
                     if (currentRes != OK) {
                         ALOGE("Error making RemoteSubmix device unavailable for mix "
                               "with type %d, address %s", device, address.c_str());
@@ -4394,7 +4469,7 @@ void AudioPolicyManager::dumpManualSurroundFormats(String8 *dst) const
 }
 
 // Returns true if all devices types match the predicate and are supported by one HW module
-bool  AudioPolicyManager::areAllDevicesSupported(
+bool AudioPolicyManager::areAllDevicesSupported(
         const AudioDeviceTypeAddrVector& devices,
         std::function<bool(audio_devices_t)> predicate,
         const char *context,
@@ -4442,7 +4517,7 @@ std::vector<sp<SwAudioOutputDescriptor>> AudioPolicyManager::getSoftwareOutputsF
         deviceDescriptors.add(desc);
     }
     for (size_t i = 0; i < mOutputs.size(); i++) {
-        if (!mOutputs.valueAt(i)->supportsAtLeastOne(deviceDescriptors)) {
+        if (!mOutputs.valueAt(i)->routesToAtLeastOne(deviceDescriptors)) {
             continue;
         }
         outputs.push_back(mOutputs.valueAt(i));
@@ -4568,7 +4643,7 @@ void AudioPolicyManager::updateInputRouting() {
         }
         auto newDevice = getNewInputDevice(activeDesc);
         // Force new input selection if the new device can not be reached via current input
-        if (activeDesc->mProfile->getSupportedDevices().contains(newDevice)) {
+        if (activeDesc->mProfile->getRoutableDevices().contains(newDevice)) {
             setInputDevice(activeDesc->mIoHandle, newDevice);
         } else {
             closeInput(activeDesc->mIoHandle);
@@ -5039,7 +5114,7 @@ audio_direct_mode_t AudioPolicyManager::getDirectPlaybackSupport(const audio_att
                 continue;
             }
             // reject profiles not corresponding to a device currently available
-            if (!mAvailableOutputDevices.containsAtLeastOne(curProfile->getSupportedDevices())) {
+            if (!mAvailableOutputDevices.containsAtLeastOne(curProfile->getRoutableDevices())) {
                 continue;
             }
             if (offloadPossible && ((curProfile->getFlags() & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD)
@@ -5099,7 +5174,7 @@ status_t AudioPolicyManager::getSupportedMixerAttributes(
     }
     for (const auto& hwModule : mHwModules) {
         for (const auto& curProfile : hwModule->getOutputProfiles()) {
-            if (curProfile->supportsDevice(deviceDescriptor)) {
+            if (curProfile->routesToDevice(deviceDescriptor)) {
                 curProfile->toSupportedMixerAttributes(&mixerAttrs);
             }
         }
@@ -5140,7 +5215,9 @@ status_t AudioPolicyManager::setPreferredMixerAttributes(
     DeviceVector devices(deviceDescriptor);
     for (const auto& hwModule : mHwModules) {
         for (const auto& curProfile : hwModule->getOutputProfiles()) {
-            if (curProfile->hasDynamicAudioProfile()
+            if ((!com::android::media::audioserver::enable_strict_port_routing_checks()
+                      || curProfile->routesToDevice(deviceDescriptor))
+                    && curProfile->hasDynamicAudioProfile()
                     && curProfile->getCompatibilityScore(
                             devices,
                             mixerAttributes->config.sample_rate,
@@ -6579,9 +6656,12 @@ bool AudioPolicyManager::canBeSpatializedInt(const audio_attributes_t *attr,
         if (!audio_is_linear_pcm(config->format)) {
             return false;
         }
-        if (config->channel_mask == AUDIO_CHANNEL_OUT_STEREO
-                && ((attr->flags & AUDIO_FLAG_LOW_LATENCY) != 0)) {
-            return false;
+        if (config->channel_mask == AUDIO_CHANNEL_OUT_STEREO) {
+            if (attr != nullptr &&
+                (((attr->flags & AUDIO_FLAG_LOW_LATENCY) != 0) ||
+                (attr->content_type == AUDIO_CONTENT_TYPE_SPEECH))) {
+                return false;
+            }
         }
     }
 
@@ -6648,13 +6728,13 @@ bool AudioPolicyManager::isOutputOnlyAvailableRouteToSomeDevice(
     if (outputDesc->isDuplicated()) {
         return false;
     }
-    DeviceVector devices = outputDesc->supportedDevices();
+    DeviceVector devices = outputDesc->routableDevices();
     for (size_t i = 0; i < mOutputs.size(); i++) {
         sp<SwAudioOutputDescriptor> desc = mOutputs.valueAt(i);
         if (desc == outputDesc || desc->isDuplicated()) {
             continue;
         }
-        DeviceVector sharedDevices = desc->filterSupportedDevices(devices);
+        DeviceVector sharedDevices = desc->filterRoutableDevices(devices);
         if (!sharedDevices.isEmpty()
                 && (desc->devicesSupportEncodedFormats(sharedDevices.types())
                     == outputDesc->devicesSupportEncodedFormats(sharedDevices.types()))) {
@@ -6885,7 +6965,7 @@ void AudioPolicyManager::onNewAudioModulesAvailableInt(DeviceVector *newDevices)
                       outProfile->maxOpenCount, outProfile->getTagName().c_str());
                 continue;
             }
-            if (!outProfile->hasSupportedDevices()) {
+            if (!outProfile->hasRoutableDevices()) {
                 ALOGW("Output profile contains no device on module %s", hwModule->getName());
                 continue;
             }
@@ -6894,20 +6974,20 @@ void AudioPolicyManager::onNewAudioModulesAvailableInt(DeviceVector *newDevices)
                 mTtsOutputAvailable = true;
             }
 
-            const DeviceVector &supportedDevices = outProfile->getSupportedDevices();
-            DeviceVector availProfileDevices = supportedDevices.filter(mConfig->getOutputDevices());
-            sp<DeviceDescriptor> supportedDevice = 0;
-            if (supportedDevices.contains(mConfig->getDefaultOutputDevice())) {
-                supportedDevice = mConfig->getDefaultOutputDevice();
+            const DeviceVector &routableDevices = outProfile->getRoutableDevices();
+            DeviceVector availProfileDevices = routableDevices.filter(mConfig->getOutputDevices());
+            sp<DeviceDescriptor> routableDevice = 0;
+            if (routableDevices.contains(mConfig->getDefaultOutputDevice())) {
+                routableDevice = mConfig->getDefaultOutputDevice();
             } else {
-                // choose first device present in profile's SupportedDevices also part of
+                // choose first device present in profile's RoutableDevices also part of
                 // mAvailableOutputDevices.
                 if (availProfileDevices.isEmpty()) {
                     continue;
                 }
-                supportedDevice = availProfileDevices.itemAt(0);
+                routableDevice = availProfileDevices.itemAt(0);
             }
-            if (!mConfig->getOutputDevices().contains(supportedDevice)) {
+            if (!mConfig->getOutputDevices().contains(routableDevice)) {
                 continue;
             }
 
@@ -6924,12 +7004,12 @@ void AudioPolicyManager::onNewAudioModulesAvailableInt(DeviceVector *newDevices)
             audio_output_flags_t flags = AUDIO_OUTPUT_FLAG_NONE;
             audio_attributes_t attributes = AUDIO_ATTRIBUTES_INITIALIZER;
             status_t status = outputDesc->open(nullptr /* halConfig */, nullptr /* mixerConfig */,
-                                               DeviceVector(supportedDevice),
+                                               DeviceVector(routableDevice),
                                                AUDIO_STREAM_DEFAULT,
                                                &flags, &output, attributes);
             if (status != NO_ERROR) {
                 ALOGW("Cannot open output stream for devices %s on hw module %s",
-                      supportedDevice->toString().c_str(), hwModule->getName());
+                      routableDevice->toString().c_str(), hwModule->getName());
                 continue;
             }
             for (const auto &device : availProfileDevices) {
@@ -6952,7 +7032,7 @@ void AudioPolicyManager::onNewAudioModulesAvailableInt(DeviceVector *newDevices)
             } else {
                 addOutput(output, outputDesc);
                 setOutputDevices(__func__, outputDesc,
-                                 DeviceVector(supportedDevice),
+                                 DeviceVector(routableDevice),
                                  true,
                                  0,
                                  NULL);
@@ -6966,14 +7046,14 @@ void AudioPolicyManager::onNewAudioModulesAvailableInt(DeviceVector *newDevices)
                       inProfile->maxOpenCount, inProfile->getTagName().c_str());
                 continue;
             }
-            if (!inProfile->hasSupportedDevices()) {
+            if (!inProfile->hasRoutableDevices()) {
                 ALOGW("Input profile contains no device on module %s", hwModule->getName());
                 continue;
             }
-            // chose first device present in profile's SupportedDevices also part of
+            // chose first device present in profile's RoutableDevices also part of
             // available input devices
-            const DeviceVector &supportedDevices = inProfile->getSupportedDevices();
-            DeviceVector availProfileDevices = supportedDevices.filter(mConfig->getInputDevices());
+            const DeviceVector &routableDevices = inProfile->getRoutableDevices();
+            DeviceVector availProfileDevices = routableDevices.filter(mConfig->getInputDevices());
             if (availProfileDevices.isEmpty()) {
                 ALOGV("%s: Input device list is empty! for profile %s",
                     __func__, inProfile->getTagName().c_str());
@@ -7093,7 +7173,7 @@ status_t AudioPolicyManager::checkOutputsForDevice(const sp<DeviceDescriptor>& d
         // then list already open outputs that can be routed to this device
         for (size_t i = 0; i < mOutputs.size(); i++) {
             desc = mOutputs.valueAt(i);
-            if (!desc->isDuplicated() && desc->supportsDevice(device)
+            if (!desc->isDuplicated() && desc->routesToDevice(device)
                     && desc->devicesSupportEncodedFormats({deviceType})) {
                 ALOGV("checkOutputsForDevice(): adding opened output %d on device %s",
                       mOutputs.keyAt(i), device->toString().c_str());
@@ -7105,7 +7185,7 @@ status_t AudioPolicyManager::checkOutputsForDevice(const sp<DeviceDescriptor>& d
         for (const auto& hwModule : mHwModules) {
             for (size_t j = 0; j < hwModule->getOutputProfiles().size(); j++) {
                 sp<IOProfile> profile = hwModule->getOutputProfiles()[j];
-                if (profile->supportsDevice(device)) {
+                if (profile->routesToDevice(device)) {
                     profiles.add(profile);
                     ALOGV("%s(): adding profile %s from module %s",
                             __func__, profile->getTagName().c_str(), hwModule->getName());
@@ -7189,10 +7269,10 @@ status_t AudioPolicyManager::checkOutputsForDevice(const sp<DeviceDescriptor>& d
             desc = mOutputs.valueAt(i);
             if (!desc->isDuplicated()) {
                 // exact match on device
-                if (device_distinguishes_on_address(deviceType) && desc->supportsDevice(device)
+                if (device_distinguishes_on_address(deviceType) && desc->routesToDevice(device)
                         && desc->containsSingleDeviceSupportingEncodedFormats(device)) {
                     outputs.add(mOutputs.keyAt(i));
-                } else if (!mAvailableOutputDevices.containsAtLeastOne(desc->supportedDevices())) {
+                } else if (!mAvailableOutputDevices.containsAtLeastOne(desc->routableDevices())) {
                     ALOGV("checkOutputsForDevice(): disconnecting adding output %d",
                             mOutputs.keyAt(i));
                     outputs.add(mOutputs.keyAt(i));
@@ -7203,7 +7283,7 @@ status_t AudioPolicyManager::checkOutputsForDevice(const sp<DeviceDescriptor>& d
         for (const auto& hwModule : mHwModules) {
             for (size_t j = 0; j < hwModule->getOutputProfiles().size(); j++) {
                 sp<IOProfile> profile = hwModule->getOutputProfiles()[j];
-                if (!profile->supportsDevice(device)) {
+                if (!profile->routesToDevice(device)) {
                     continue;
                 }
                 ALOGV("%s(): clearing direct output profile %s on module %s",
@@ -7213,18 +7293,18 @@ status_t AudioPolicyManager::checkOutputsForDevice(const sp<DeviceDescriptor>& d
                     continue;
                 }
                 // When a device is disconnected, if there is an IOProfile that contains dynamic
-                // profiles and supports the disconnected device, call getAudioPort to repopulate
-                // the capabilities of the devices that is supported by the IOProfile.
-                for (const auto& supportedDevice : profile->getSupportedDevices()) {
-                    if (supportedDevice == device ||
-                            !mAvailableOutputDevices.contains(supportedDevice)) {
+                // profiles and routes to the disconnected device, call getAudioPort to repopulate
+                // the capabilities of the devices that is routable from/to the IOProfile.
+                for (const auto& routableDevice : profile->getRoutableDevices()) {
+                    if (routableDevice == device ||
+                            !mAvailableOutputDevices.contains(routableDevice)) {
                         continue;
                     }
                     struct audio_port_v7 port;
-                    supportedDevice->toAudioPort(&port);
+                    routableDevice->toAudioPort(&port);
                     status_t status = mpClientInterface->getAudioPort(&port);
                     if (status == NO_ERROR) {
-                        supportedDevice->importAudioPort(port);
+                        routableDevice->importAudioPort(port);
                     }
                 }
             }
@@ -7260,7 +7340,7 @@ status_t AudioPolicyManager::checkInputsForDevice(const sp<DeviceDescriptor>& de
                  profile_index++) {
                 sp<IOProfile> profile = hwModule->getInputProfiles()[profile_index];
 
-                if (profile->supportsDevice(device)) {
+                if (profile->routesToDevice(device)) {
                     profiles.add(profile);
                     ALOGV("%s : adding profile %s from module %s", __func__,
                           profile->getTagName().c_str(), hwModule->getName());
@@ -7364,7 +7444,7 @@ status_t AudioPolicyManager::checkInputsForDevice(const sp<DeviceDescriptor>& de
                  profile_index < hwModule->getInputProfiles().size();
                  profile_index++) {
                 sp<IOProfile> profile = hwModule->getInputProfiles()[profile_index];
-                if (profile->supportsDevice(device)) {
+                if (profile->routesToDevice(device)) {
                     ALOGV("%s: clearing direct input profile %s on module %s", __func__,
                             profile->getTagName().c_str(), hwModule->getName());
                     profile->clearAudioProfiles();
@@ -7512,8 +7592,8 @@ SortedVector<audio_io_handle_t> AudioPolicyManager::getOutputsForDevices(
     for (size_t i = 0; i < openOutputs.size(); i++) {
         ALOGVV("output %zu isDuplicated=%d device=%s",
                 i, openOutputs.valueAt(i)->isDuplicated(),
-                openOutputs.valueAt(i)->supportedDevices().toString().c_str());
-        if (openOutputs.valueAt(i)->supportsAllDevices(devices)
+                openOutputs.valueAt(i)->routableDevices().toString().c_str());
+        if (openOutputs.valueAt(i)->routesToAllDevices(devices)
                 && openOutputs.valueAt(i)->devicesSupportEncodedFormats(devices.types())) {
             ALOGVV("%s() found output %d", __func__, openOutputs.keyAt(i));
             outputs.add(openOutputs.keyAt(i));
@@ -7526,10 +7606,16 @@ void AudioPolicyManager::checkForDeviceAndOutputChanges(std::function<bool()> on
 {
     // checkA2dpSuspend must run before checkOutputForAllStrategies so that A2DP
     // output is suspended before any tracks are moved to it
-    checkA2dpSuspend();
+    if (!remove_stream_suspend()) {
+        checkA2dpSuspend();
+    }
     checkOutputForAllStrategies();
     checkSecondaryOutputs();
-    if (onOutputsChecked != nullptr && onOutputsChecked()) checkA2dpSuspend();
+    if (onOutputsChecked != nullptr && onOutputsChecked()) {
+        if (!remove_stream_suspend()) {
+            checkA2dpSuspend();
+        }
+    }
     updateDevicesAndOutputs();
     if (mHwModules.getModuleFromName(AUDIO_HARDWARE_MODULE_ID_MSD) != 0) {
         // TODO: The MSD patches to be established here may differ to current MSD patches due to how
@@ -7589,7 +7675,7 @@ void AudioPolicyManager::checkOutputForAttributes(const audio_attributes_t &attr
     std::vector<sp<SwAudioOutputDescriptor>> invalidatedOutputs;
     // take into account dynamic audio policies related changes: if a client is now associated
     // to a different policy mix than at creation time, invalidate corresponding stream
-    // invalidate clients on outputs that do not support all the newly selected devices for the
+    // invalidate clients on outputs that do not route to all the newly selected devices for the
     // strategy
     for (size_t i = 0; i < mPreviousOutputs.size(); i++) {
         const sp<SwAudioOutputDescriptor>& desc = mPreviousOutputs.valueAt(i);
@@ -7602,7 +7688,7 @@ void AudioPolicyManager::checkOutputForAttributes(const audio_attributes_t &attr
                     || client->isInvalid()) {
                 continue;
             }
-            if (!desc->supportsAllDevices(newDevices)) {
+            if (!desc->routesToAllDevices(newDevices)) {
                 invalidatedOutputs.push_back(desc);
                 break;
             }
@@ -7796,7 +7882,8 @@ bool AudioPolicyManager::isHearingAidUsedForComm() const {
 void AudioPolicyManager::checkA2dpSuspend()
 {
     audio_io_handle_t a2dpOutput = mOutputs.getA2dpOutput();
-    if (a2dpOutput == 0 || mOutputs.isA2dpOffloadedOnPrimary()) {
+    if (use_bt_sco_for_media()
+            || a2dpOutput == 0 || mOutputs.isA2dpOffloadedOnPrimary()) {
         mA2dpSuspended = false;
         return;
     }
@@ -7905,6 +7992,25 @@ DeviceVector AudioPolicyManager::getNewOutputDevices(const sp<SwAudioOutputDescr
             // check the route (would force modifying configuration file for this profile)
             auto attr = mEngine->getAllAttributesForProductStrategy(productStrategy).front();
             devices = mEngine->getOutputDevicesForAttributes(attr, nullptr, fromCache);
+
+            if (devices.empty()) {
+                ALOGW("%s: no device were retrieved for specified attributes", __func__);
+            }
+
+            if (com::android::media::audioserver::enable_strict_port_routing_checks()) {
+                // Filter out devices that are indicated by the HAL as non-routable.
+                auto routableDevices = devices.filter([&](auto device) {
+                      return outputDesc->mProfile->routesToDevice(device); });
+
+                if (routableDevices.empty()) {
+                    ALOGW("%s: no device in %s are routable for profile %s", __func__,
+                          routableDevices.toString().c_str(),
+                          outputDesc->mProfile->getTagName().c_str());
+                }
+
+                devices = routableDevices;
+            }
+
             break;
         }
     }
@@ -7960,6 +8066,14 @@ sp<DeviceDescriptor> AudioPolicyManager::getNewInputDevice(
                 attributes, false /*ignorePreferredDevice*/, uid, session);
     }
 
+    if (com::android::media::audioserver::enable_strict_port_routing_checks() &&
+          !inputDesc->mProfile->routesToDevice(device)) {
+        ALOGW("%s: profile %s is not routable to device %s", __func__,
+              inputDesc->mProfile->getTagName().c_str(),
+              inputDesc->getDevice()->toString().c_str());
+        return nullptr;
+    }
+
     return device;
 }
 
@@ -8084,7 +8198,7 @@ uint32_t AudioPolicyManager::checkDeviceMuteStrategies(const sp<AudioOutputDescr
         auto attributes = mEngine->getAllAttributesForProductStrategy(productStrategy).front();
         DeviceVector curDevices =
                 mEngine->getOutputDevicesForAttributes(attributes, nullptr, false/*fromCache*/);
-        curDevices = curDevices.filter(outputDesc->supportedDevices());
+        curDevices = curDevices.filter(outputDesc->routableDevices());
         bool mute = shouldMute && curDevices.containsAtLeastOne(devices) && curDevices != devices;
         bool doMute = false;
 
@@ -8099,7 +8213,7 @@ uint32_t AudioPolicyManager::checkDeviceMuteStrategies(const sp<AudioOutputDescr
             for (size_t j = 0; j < mOutputs.size(); j++) {
                 sp<AudioOutputDescriptor> desc = mOutputs.valueAt(j);
                 // skip output if it does not share any device with current output
-                if (!desc->supportedDevices().containsAtLeastOne(outputDesc->supportedDevices())) {
+                if (!desc->routableDevices().containsAtLeastOne(outputDesc->routableDevices())) {
                     continue;
                 }
                 ALOGVV("%s() output %s %s (curDevice %s)", __func__, desc->info().c_str(),
@@ -8180,7 +8294,7 @@ uint32_t AudioPolicyManager::setOutputDevices(const char *caller,
     }
 
     // filter devices according to output selected
-    DeviceVector filteredDevices = outputDesc->filterSupportedDevices(devices);
+    DeviceVector filteredDevices = outputDesc->filterRoutableDevices(devices);
     DeviceVector prevDevices = outputDesc->devices();
     DeviceVector availPrevDevices = mAvailableOutputDevices.filter(prevDevices);
 
@@ -8202,8 +8316,8 @@ uint32_t AudioPolicyManager::setOutputDevices(const char *caller,
 
     bool outputRouted = outputDesc->isRouted();
 
-    // no need to proceed if new device is not AUDIO_DEVICE_NONE and not supported by current
-    // output profile or if new device is not supported AND previous device(s) is(are) still
+    // no need to proceed if new device is not AUDIO_DEVICE_NONE and not routable to/from current
+    // output profile or if new device is not routable AND previous device(s) is(are) still
     // available (otherwise reset device must be done on the output)
     if (!devices.isEmpty() && filteredDevices.isEmpty() && !availPrevDevices.empty()) {
         ALOGV("%s: %s unsupported device %s for output", __func__, logPrefix.c_str(),
@@ -8380,6 +8494,11 @@ sp<IOProfile> AudioPolicyManager::getInputProfile(const sp<DeviceDescriptor> &de
         auto bestCompatibleScore = IOProfile::NO_MATCH;
         for (const auto& hwModule : mHwModules) {
             for (const auto& profile : hwModule->getInputProfiles()) {
+                if (com::android::media::audioserver::enable_strict_port_routing_checks() &&
+                      !profile->routesToDevice(device)) {
+                    continue;
+                }
+
                 // profile->log();
                 //updatedFormat = format;
                 auto compatibleScore = profile->getCompatibilityScore(
@@ -8641,6 +8760,7 @@ status_t AudioPolicyManager::checkAndSetVolume(IVolumeCurves &curves,
                                                int index,
                                                const sp<AudioOutputDescriptor>& outputDesc,
                                                DeviceTypeSet deviceTypes,
+                                               bool adjustAttenuation,
                                                int delayMs,
                                                bool force)
 {
@@ -8648,12 +8768,14 @@ status_t AudioPolicyManager::checkAndSetVolume(IVolumeCurves &curves,
     static std::set<IVolumeCurves*> invalidCurvesReported;
 
     // do not change actual attributes volume if the attributes is muted
-    if (!com_android_media_audio_ring_my_car() && outputDesc->isMutedInternally(volumeSource)) {
+    if (outputDesc->isMutedInternally(volumeSource)) {
         ALOGVV("%s: volume source %d muted count %d active=%d", __func__, volumeSource,
                outputDesc->getMuteCount(volumeSource), outputDesc->isActive(volumeSource));
         return NO_ERROR;
     }
-
+    if (!outputDesc->canSetVolumeForVolumeSource(volumeSource)) {
+        return NO_ERROR;
+    }
     bool isVoiceVolSrc;
     bool isBtScoVolSrc;
     if (!isVolumeConsistentForCalls(
@@ -8680,14 +8802,16 @@ status_t AudioPolicyManager::checkAndSetVolume(IVolumeCurves &curves,
         return BAD_VALUE;
     }
 
-    float volumeDb = computeVolume(curves, volumeSource, index, deviceTypes);
+    float volumeDb = computeVolume(curves, volumeSource, index, deviceTypes, adjustAttenuation);
     const VolumeSource dtmfVolSrc = toVolumeSource(AUDIO_STREAM_DTMF, false);
-    if (outputDesc->isFixedVolume(deviceTypes) ||
-            // Force VoIP volume to max for bluetooth SCO/BLE device except if muted
-            (index != 0 && (isVoiceVolSrc || isBtScoVolSrc
-                        || (isInCall() && (dtmfVolSrc == volumeSource))) &&
-                    (isSingleDeviceType(deviceTypes, audio_is_bluetooth_out_sco_device)
-                    || isSingleDeviceType(deviceTypes, audio_is_ble_out_device)))) {
+    // Force VoIP volume to max for bluetooth SCO/BLE device except if muted
+    bool isAbsVolumeType = !android_media_audio_unify_absolute_volume_management()
+            && (index != 0
+            && (isVoiceVolSrc || isBtScoVolSrc || (isInCall() && (dtmfVolSrc == volumeSource)))
+            && (isSingleDeviceType(deviceTypes, audio_is_bluetooth_out_sco_device)
+                    || isSingleDeviceType(deviceTypes, audio_is_ble_out_device)));
+
+    if (outputDesc->isFixedVolume(deviceTypes) || isAbsVolumeType) {
         volumeDb = 0.0f;
     }
 
@@ -8769,7 +8893,7 @@ void AudioPolicyManager::applyStreamVolumes(const sp<AudioOutputDescriptor>& out
     for (const auto &volumeGroup : mEngine->getVolumeGroups()) {
         auto &curves = getVolumeCurves(toVolumeSource(volumeGroup));
         checkAndSetVolume(curves, toVolumeSource(volumeGroup), curves.getVolumeIndex(deviceTypes),
-                          outputDesc, deviceTypes, delayMs, force);
+                          outputDesc, deviceTypes, /*adjustAttenuation=*/true, delayMs, force);
     }
 }
 
@@ -8812,7 +8936,10 @@ void AudioPolicyManager::setVolumeSourceMutedInternally(VolumeSource volumeSourc
                     (volumeSource != toVolumeSource(AUDIO_STREAM_ENFORCED_AUDIBLE, false) ||
                      (mEngine->getForceUse(AUDIO_POLICY_FORCE_FOR_SYSTEM) ==
                       AUDIO_POLICY_FORCE_NONE))) {
-                checkAndSetVolume(curves, volumeSource, 0, outputDesc, deviceTypes, delayMs);
+                // use adjustAttenuation as false to mute on BLE broadcast devices which have
+                // an absolute volume mode muting exception
+                checkAndSetVolume(curves, volumeSource, 0, outputDesc,
+                                  deviceTypes, /*adjustAttenuation=*/false, delayMs);
             }
         }
         // increment mMuteCount after calling checkAndSetVolume() so that volume change is not
@@ -8828,6 +8955,7 @@ void AudioPolicyManager::setVolumeSourceMutedInternally(VolumeSource volumeSourc
                               curves.getVolumeIndex(deviceTypes),
                               outputDesc,
                               deviceTypes,
+                              /*adjustAttenuation=*/true,
                               delayMs);
         }
     }
@@ -9047,7 +9175,8 @@ void AudioPolicyManager::updateAudioProfiles(const sp<DeviceDescriptor>& devDesc
     profile->toAudioPort(&mixPort);
     mixPort.ext.mix.handle = ioHandle;
 
-    status_t status = mpClientInterface->getAudioMixPort(&devicePort, &mixPort);
+    status_t status = mpClientInterface->getAudioMixPort(&devicePort, &mixPort,
+                                                         AUDIO_PORT_HANDLE_NONE);
     if (status != NO_ERROR) {
         ALOGE("%s failed to query the attributes of the mix port", __func__);
         return;
@@ -9187,7 +9316,7 @@ sp<SwAudioOutputDescriptor> AudioPolicyManager::openOutputWithProfileAndDevice(
 {
     for (const auto& device : devices) {
         // TODO: This should be checking if the profile supports the device combo.
-        if (!profile->supportsDevice(device)) {
+        if (!profile->routesToDevice(device)) {
             ALOGE("%s profile(%s) doesn't support device %#x", __func__, profile->getName().c_str(),
                   device->type());
             return nullptr;
@@ -9262,7 +9391,7 @@ sp<SwAudioOutputDescriptor> AudioPolicyManager::openOutputWithProfileAndDevice(
         }
 
     } else if (hasPrimaryOutput() && speaker != nullptr
-            && mPrimaryOutput->supportsDevice(speaker) && !desc->supportsDevice(speaker)
+            && mPrimaryOutput->routesToDevice(speaker) && !desc->routesToDevice(speaker)
             && ((desc->mFlags & AUDIO_OUTPUT_FLAG_DIRECT) == 0)) {
         // no duplicated output for:
         // - direct outputs
@@ -9386,7 +9515,7 @@ status_t AudioPolicyManager::getProfilesForDevices(const DeviceVector& devices,
         IOProfileCollection ioProfiles = isInput ? hwModule->getInputProfiles()
                                                  : hwModule->getOutputProfiles();
         for (const auto& profile : ioProfiles) {
-            if (!profile->areAllDevicesSupported(devices) ||
+            if (!profile->areAllDevicesRoutable(devices) ||
                     !profile->isCompatibleProfileForFlags(flags)) {
                 continue;
             }
@@ -9459,9 +9588,7 @@ void AudioPolicyManager::invalidateStreams(StreamTypeVector streams) const {
 
 void AudioPolicyManager::updateClientsInternalMute(
         const sp<android::SwAudioOutputDescriptor> &desc) {
-    if (!desc->isBitPerfect() ||
-        !com::android::media::audioserver::
-                fix_concurrent_playback_behavior_with_bit_perfect_client()) {
+    if (!desc->isBitPerfect()) {
         // This is only used for bit perfect output now.
         return;
     }
diff --git a/services/audiopolicy/managerdefault/AudioPolicyManager.h b/services/audiopolicy/managerdefault/AudioPolicyManager.h
index da60c06344..19e26e04a5 100644
--- a/services/audiopolicy/managerdefault/AudioPolicyManager.h
+++ b/services/audiopolicy/managerdefault/AudioPolicyManager.h
@@ -129,13 +129,14 @@ public:
                                   std::vector<audio_io_handle_t> *secondaryOutputs,
                                   output_type_t *outputType,
                                   bool *isSpatialized,
-                                  bool *isBitPerfect,
-                                  float *volume,
-                                  bool *muted) override;
-        virtual status_t startOutput(audio_port_handle_t portId);
+                                  bool *isBitPerfect) override;
+        virtual status_t startOutput(
+                audio_port_handle_t portId, float* volume, bool* muted);
         virtual status_t stopOutput(audio_port_handle_t portId);
         virtual bool releaseOutput(audio_port_handle_t portId);
 
+        void addRoutableDeviceToProfiles(const sp<DeviceDescriptor> &device);
+
         base::expected<media::GetInputForAttrResponse, std::variant<binder::Status,
             media::audio::common::AudioConfigBase>>
                          getInputForAttr(audio_attributes_t attributes,
@@ -188,6 +189,65 @@ public:
 
         virtual status_t getMinVolumeIndexForAttributes(const audio_attributes_t &attr, int &index);
 
+        /**
+         * Set the volume index for a given volume group and device.
+         *
+         * @param groupId the volume group id
+         * @param index the volume index to set
+         * @param muted state of the volume group
+         * @param device the device to set the volume index for
+         * @return NO_ERROR if the call is successful, otherwise an error code
+         */
+        virtual status_t setVolumeIndexForGroup(volume_group_t groupId, int index,
+                bool muted, audio_devices_t device);
+
+        /**
+         * Get the volume index for a given volume group and device.
+         *
+         * @param groupId the volume group id
+         * @param index the volume index to get
+         * @param device the device to get the volume index for
+         * @return NO_ERROR if the call is successful, otherwise an error code
+         */
+        virtual status_t getVolumeIndexForGroup(volume_group_t groupId, int &index,
+                audio_devices_t device);
+
+        /**
+         * Get the maximum volume index for a given volume group
+         *
+         * @param groupId the volume group id
+         * @param index the max volume index to get
+         * @return NO_ERROR if the call is successful, otherwise an error code
+         */
+        virtual status_t getMaxVolumeIndexForGroup(volume_group_t groupId, int &index);
+
+        /**
+         * Set the maximum volume index for a given volume group
+         *
+         * @param groupId the volume group id
+         * @param index the max volume index to set
+         * @return NO_ERROR if the call is successful, otherwise an error code
+         */
+        virtual status_t setMaxVolumeIndexForGroup(volume_group_t groupId, int index);
+
+        /**
+         * Get the minimum volume index for a given volume group.
+         *
+         * @param groupId
+         * @param index the min volume index to get
+         * @return NO_ERROR if the call is successful, otherwise an error code
+         */
+        virtual status_t getMinVolumeIndexForGroup(volume_group_t groupId, int &index);
+
+        /**
+         * Set the minimum volume index for a given volume group.
+         *
+         * @param groupId
+         * @param index the min volume index to set
+         * @return NO_ERROR if the call is successful, otherwise an error code
+         */
+        virtual status_t setMinVolumeIndexForGroup(volume_group_t groupId, int index);
+
         status_t setVolumeCurveIndex(int index,
                                      bool muted,
                                      audio_devices_t device,
@@ -522,12 +582,15 @@ protected:
             return toVolumeSource(mEngine->getVolumeGroupForStreamType(
                 stream, fallbackOnDefault));
         }
+        IVolumeCurves &getVolumeCurves(volume_group_t volumeGroupId)
+        {
+            auto *curves = mEngine->getVolumeCurvesForVolumeGroup(volumeGroupId);
+            ALOG_ASSERT(curves != nullptr, "No curves for volume group %d", volumeGroupId);
+            return *curves;
+        }
         IVolumeCurves &getVolumeCurves(VolumeSource volumeSource)
         {
-          auto *curves = mEngine->getVolumeCurvesForVolumeGroup(
-              static_cast<volume_group_t>(volumeSource));
-          ALOG_ASSERT(curves != nullptr, "No curves for volume source %d", volumeSource);
-          return *curves;
+          return getVolumeCurves(static_cast<volume_group_t>(volumeSource));
         }
         IVolumeCurves &getVolumeCurves(const audio_attributes_t &attr)
         {
@@ -624,7 +687,7 @@ protected:
         virtual status_t checkAndSetVolume(IVolumeCurves &curves,
                                            VolumeSource volumeSource, int index,
                                            const sp<AudioOutputDescriptor>& outputDesc,
-                                           DeviceTypeSet deviceTypes,
+                                           DeviceTypeSet deviceTypes, bool adjustAttenuation,
                                            int delayMs = 0, bool force = false);
 
         void setVoiceVolume(int index, IVolumeCurves &curves, bool isVoiceVolSrc, int delayMs);
diff --git a/services/audiopolicy/service/AudioPolicyClientImpl.cpp b/services/audiopolicy/service/AudioPolicyClientImpl.cpp
index 765928e4a7..196340bdf0 100644
--- a/services/audiopolicy/service/AudioPolicyClientImpl.cpp
+++ b/services/audiopolicy/service/AudioPolicyClientImpl.cpp
@@ -57,7 +57,8 @@ status_t AudioPolicyService::AudioPolicyClient::openOutput(audio_module_handle_t
                                                            const sp<DeviceDescriptorBase>& device,
                                                            uint32_t *latencyMs,
                                                            audio_output_flags_t *flags,
-                                                           audio_attributes_t attributes)
+                                                           audio_attributes_t attributes,
+                                                           int32_t mixPortHalId)
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
@@ -77,6 +78,7 @@ status_t AudioPolicyService::AudioPolicyClient::openOutput(audio_module_handle_t
     request.flags = VALUE_OR_RETURN_STATUS(legacy2aidl_audio_output_flags_t_int32_t_mask(*flags));
     request.attributes = VALUE_OR_RETURN_STATUS(
             legacy2aidl_audio_attributes_t_AudioAttributes(attributes));
+    request.mixPortHalId = mixPortHalId;
 
     status_t status = af->openOutput(request, &response);
     if (status == OK) {
@@ -146,7 +148,8 @@ status_t AudioPolicyService::AudioPolicyClient::openInput(audio_module_handle_t
                                                           audio_devices_t *device,
                                                           const String8& address,
                                                           audio_source_t source,
-                                                          audio_input_flags_t flags)
+                                                          audio_input_flags_t flags,
+                                                          int32_t mixPortHalId)
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
@@ -164,6 +167,7 @@ status_t AudioPolicyService::AudioPolicyClient::openInput(audio_module_handle_t
     request.device = VALUE_OR_RETURN_STATUS(legacy2aidl_AudioDeviceTypeAddress(deviceTypeAddr));
     request.source = VALUE_OR_RETURN_STATUS(legacy2aidl_audio_source_t_AudioSource(source));
     request.flags = VALUE_OR_RETURN_STATUS(legacy2aidl_audio_input_flags_t_int32_t_mask(flags));
+    request.mixPortHalId = mixPortHalId;
 
     media::OpenInputResponse response;
     status_t status = af->openInput(request, &response);
@@ -357,12 +361,13 @@ status_t AudioPolicyService::AudioPolicyClient::invalidateTracks(
 
 status_t AudioPolicyService::AudioPolicyClient::getAudioMixPort(
         const struct audio_port_v7 *devicePort,
-        struct audio_port_v7 *port) {
+        struct audio_port_v7 *port,
+        int32_t mixPortHalId) {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
         return PERMISSION_DENIED;
     }
-    return af->getAudioMixPort(devicePort, port);
+    return af->getAudioMixPort(devicePort, port, mixPortHalId);
 }
 
 status_t AudioPolicyService::AudioPolicyClient::setTracksInternalMute(
diff --git a/services/audiopolicy/service/AudioPolicyInterfaceImpl.cpp b/services/audiopolicy/service/AudioPolicyInterfaceImpl.cpp
index 40899002dd..0c0562097d 100644
--- a/services/audiopolicy/service/AudioPolicyInterfaceImpl.cpp
+++ b/services/audiopolicy/service/AudioPolicyInterfaceImpl.cpp
@@ -409,7 +409,7 @@ Status AudioPolicyService::getOutputForAttr(const media::audio::common::AudioAtt
                                              aidl2legacy_int32_t_audio_port_handle_t));
 
     audio_io_handle_t output;
-    audio_port_handle_t portId;
+    audio_port_handle_t portId = AUDIO_PORT_HANDLE_NONE;
     std::vector<audio_io_handle_t> secondaryOutputs;
 
     if (mAudioPolicyManager == NULL) {
@@ -483,8 +483,6 @@ Status AudioPolicyService::getOutputForAttr(const media::audio::common::AudioAtt
     AudioPolicyInterface::output_type_t outputType;
     bool isSpatialized = false;
     bool isBitPerfect = false;
-    float volume;
-    bool muted;
     status_t result = mAudioPolicyManager->getOutputForAttr(&attr, &output, session,
                                                             &stream,
                                                             attributionSource,
@@ -493,9 +491,7 @@ Status AudioPolicyService::getOutputForAttr(const media::audio::common::AudioAtt
                                                             &secondaryOutputs,
                                                             &outputType,
                                                             &isSpatialized,
-                                                            &isBitPerfect,
-                                                            &volume,
-                                                            &muted);
+                                                            &isBitPerfect);
 
     // FIXME: Introduce a way to check for the the telephony device before opening the output
     if (result == NO_ERROR) {
@@ -563,8 +559,6 @@ Status AudioPolicyService::getOutputForAttr(const media::audio::common::AudioAtt
         _aidl_return->isBitPerfect = isBitPerfect;
         _aidl_return->attr = VALUE_OR_RETURN_BINDER_STATUS(
                 legacy2aidl_audio_attributes_t_AudioAttributes(attr));
-        _aidl_return->volume = volume;
-        _aidl_return->muted = muted;
     } else {
         _aidl_return->configBase.format = VALUE_OR_RETURN_BINDER_STATUS(
                 legacy2aidl_audio_format_t_AudioFormatDescription(config.format));
@@ -591,7 +585,8 @@ void AudioPolicyService::getPlaybackClientAndEffects(audio_port_handle_t portId,
     effects = mAudioPolicyEffects;
 }
 
-Status AudioPolicyService::startOutput(int32_t portIdAidl)
+Status AudioPolicyService::startOutput(
+        int32_t portIdAidl, media::StartOutputResponse* _aidl_return)
 {
     audio_port_handle_t portId = VALUE_OR_RETURN_BINDER_STATUS(
             aidl2legacy_int32_t_audio_port_handle_t(portIdAidl));
@@ -614,7 +609,9 @@ Status AudioPolicyService::startOutput(int32_t portIdAidl)
     }
     audio_utils::lock_guard _l(mMutex);
     AutoCallerClear acc;
-    status_t status = mAudioPolicyManager->startOutput(portId);
+    float volume;
+    bool muted;
+    status_t status = mAudioPolicyManager->startOutput(portId, &volume, &muted);
     if (status == NO_ERROR) {
         //TODO b/257922898: decide if/how we need to handle attributes update when playback starts
         // or during playback
@@ -622,6 +619,8 @@ Status AudioPolicyService::startOutput(int32_t portIdAidl)
                 client->attributes, nullptr /* callback */);
         client->active = true;
         onUpdateActiveSpatializerTracks_l();
+        _aidl_return->volume = volume;
+        _aidl_return->muted = muted;
     }
     return binderStatusFromStatusT(status);
 }
@@ -876,12 +875,14 @@ Status AudioPolicyService::getInputForAttr(const media::audio::common::AudioAttr
 
     //TODO(b/374751406): remove forcing canBypassConcurrentPolicy to canCaptureOutput
     // once all system apps using CAPTURE_AUDIO_OUTPUT to capture during calls
-    // are updated to use the new CONCURRENT_AUDIO_RECORD_BYPASS permission.
+    // are updated to use the new BYPASS_CONCURRENT_RECORD_AUDIO_RESTRICTION permission.
     bool canBypassConcurrentPolicy = audioserver_permissions()
                                 ? CHECK_PERM(CAPTURE_AUDIO_OUTPUT, attributionSource.uid)
                                 : captureAudioOutputAllowed(attributionSource);
     if (concurrent_audio_record_bypass_permission()) {
-        canBypassConcurrentPolicy = audioserver_permissions() ?
+        // TODO(b/374751406): allow either capture output or bypass permission until
+        // all system apps have migrated to new permission.
+        canBypassConcurrentPolicy |= audioserver_permissions() ?
                             CHECK_PERM(BYPASS_CONCURRENT_RECORD_AUDIO_RESTRICTION,
                                        attributionSource.uid)
                             : bypassConcurrentPolicyAllowed(attributionSource);
@@ -1376,6 +1377,96 @@ Status AudioPolicyService::getMaxVolumeIndexForAttributes(
     return Status::ok();
 }
 
+Status AudioPolicyService::setVolumeIndexForGroup(int32_t groupIdAidl,
+        const AudioDeviceDescription& deviceAidl, int32_t indexAidl, bool muted) {
+    volume_group_t groupId = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_int32_t_volume_group_t(groupIdAidl));
+    int index = VALUE_OR_RETURN_BINDER_STATUS(convertIntegral<int>(indexAidl));
+    audio_devices_t device = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_AudioDeviceDescription_audio_devices_t(deviceAidl));
+
+    if (mAudioPolicyManager == NULL) {
+        return binderStatusFromStatusT(NO_INIT);
+    }
+    audio_utils::lock_guard _l(mMutex);
+    AutoCallerClear acc;
+    return binderStatusFromStatusT(
+            mAudioPolicyManager->setVolumeIndexForGroup(groupId, index, muted, device));
+}
+
+Status AudioPolicyService::getVolumeIndexForGroup(
+        int32_t groupIdAidl, const AudioDeviceDescription& deviceAidl, int32_t* _aidl_return) {
+    volume_group_t groupId = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_int32_t_volume_group_t(groupIdAidl));
+    audio_devices_t device = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_AudioDeviceDescription_audio_devices_t(deviceAidl));
+    if (mAudioPolicyManager == NULL) {
+        return binderStatusFromStatusT(NO_INIT);
+    }
+    audio_utils::lock_guard _l(mMutex);
+    AutoCallerClear acc;
+    int index;
+    RETURN_IF_BINDER_ERROR(binderStatusFromStatusT(
+            mAudioPolicyManager->getVolumeIndexForGroup(groupId, index, device)));
+    *_aidl_return = VALUE_OR_RETURN_BINDER_STATUS(convertIntegral<int32_t>(index));
+    return Status::ok();
+}
+
+Status AudioPolicyService::getMinVolumeIndexForGroup(int32_t groupIdAidl, int32_t* _aidl_return) {
+    volume_group_t groupId = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_int32_t_volume_group_t(groupIdAidl));
+    if (mAudioPolicyManager == NULL) {
+        return binderStatusFromStatusT(NO_INIT);
+    }
+    audio_utils::lock_guard _l(mMutex);
+    AutoCallerClear acc;
+    int index;
+    RETURN_IF_BINDER_ERROR(binderStatusFromStatusT(
+            mAudioPolicyManager->getMinVolumeIndexForGroup(groupId, index)));
+    *_aidl_return = VALUE_OR_RETURN_BINDER_STATUS(convertIntegral<int32_t>(index));
+    return Status::ok();
+}
+
+
+Status AudioPolicyService::setMinVolumeIndexForGroup(int32_t groupIdAidl, int32_t indexAidl) {
+    if (mAudioPolicyManager == NULL) {
+        return binderStatusFromStatusT(NO_INIT);
+    }
+    volume_group_t groupId = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_int32_t_volume_group_t(groupIdAidl));
+    int index = VALUE_OR_RETURN_BINDER_STATUS(convertIntegral<int>(indexAidl));
+    audio_utils::lock_guard _l(mMutex);
+    AutoCallerClear acc;
+    return binderStatusFromStatusT(mAudioPolicyManager->setMinVolumeIndexForGroup(groupId, index));
+}
+
+Status AudioPolicyService::getMaxVolumeIndexForGroup(int32_t groupIdAidl, int32_t* _aidl_return) {
+    volume_group_t groupId = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_int32_t_volume_group_t(groupIdAidl));
+    if (mAudioPolicyManager == NULL) {
+        return binderStatusFromStatusT(NO_INIT);
+    }
+    audio_utils::lock_guard _l(mMutex);
+    AutoCallerClear acc;
+    int index;
+    RETURN_IF_BINDER_ERROR(binderStatusFromStatusT(
+            mAudioPolicyManager->getMaxVolumeIndexForGroup(groupId, index)));
+    *_aidl_return = VALUE_OR_RETURN_BINDER_STATUS(convertIntegral<int32_t>(index));
+    return Status::ok();
+}
+
+Status AudioPolicyService::setMaxVolumeIndexForGroup(int32_t groupIdAidl, int32_t indexAidl) {
+    if (mAudioPolicyManager == NULL) {
+        return binderStatusFromStatusT(NO_INIT);
+    }
+    volume_group_t groupId = VALUE_OR_RETURN_BINDER_STATUS(
+            aidl2legacy_int32_t_volume_group_t(groupIdAidl));
+    int index = VALUE_OR_RETURN_BINDER_STATUS(convertIntegral<int>(indexAidl));
+    audio_utils::lock_guard _l(mMutex);
+    AutoCallerClear acc;
+    return binderStatusFromStatusT(mAudioPolicyManager->setMaxVolumeIndexForGroup(groupId, index));
+}
+
 Status AudioPolicyService::getStrategyForStream(AudioStreamType streamAidl,
                                                 int32_t* _aidl_return) {
     audio_stream_type_t stream = VALUE_OR_RETURN_BINDER_STATUS(
diff --git a/services/audiopolicy/service/AudioPolicyService.cpp b/services/audiopolicy/service/AudioPolicyService.cpp
index 663e0d6900..49011e24b4 100644
--- a/services/audiopolicy/service/AudioPolicyService.cpp
+++ b/services/audiopolicy/service/AudioPolicyService.cpp
@@ -95,6 +95,12 @@ BINDER_METHOD_ENTRY(setVolumeIndexForAttributes) \
 BINDER_METHOD_ENTRY(getVolumeIndexForAttributes) \
 BINDER_METHOD_ENTRY(getMaxVolumeIndexForAttributes) \
 BINDER_METHOD_ENTRY(getMinVolumeIndexForAttributes) \
+BINDER_METHOD_ENTRY(setVolumeIndexForGroup) \
+BINDER_METHOD_ENTRY(getVolumeIndexForGroup) \
+BINDER_METHOD_ENTRY(getMaxVolumeIndexForGroup) \
+BINDER_METHOD_ENTRY(setMaxVolumeIndexForGroup) \
+BINDER_METHOD_ENTRY(getMinVolumeIndexForGroup) \
+BINDER_METHOD_ENTRY(setMinVolumeIndexForGroup) \
 BINDER_METHOD_ENTRY(getStrategyForStream) \
 BINDER_METHOD_ENTRY(getDevicesForAttributes) \
 BINDER_METHOD_ENTRY(getOutputForEffect) \
@@ -892,7 +898,7 @@ void AudioPolicyService::updateUidStates_l()
 //    NOTE: a client can capture calls if it either:
 //       has CAPTURE_AUDIO_OUTPUT privileged permission (temporarily until
 //            all system apps are updated)
-//       or has CONCURRENT_AUDIO_RECORD_BYPASS privileged permission
+//       or has BYPASS_CONCURRENT_RECORD_AUDIO_RESTRICTION privileged permission
 
 
     sp<AudioRecordClient> topActive;
@@ -1354,6 +1360,12 @@ status_t AudioPolicyService::onTransact(
         case TRANSACTION_getVolumeIndexForAttributes:
         case TRANSACTION_getMinVolumeIndexForAttributes:
         case TRANSACTION_getMaxVolumeIndexForAttributes:
+        case TRANSACTION_setVolumeIndexForGroup:
+        case TRANSACTION_getVolumeIndexForGroup:
+        case TRANSACTION_getMinVolumeIndexForGroup:
+        case TRANSACTION_setMinVolumeIndexForGroup:
+        case TRANSACTION_getMaxVolumeIndexForGroup:
+        case TRANSACTION_setMaxVolumeIndexForGroup:
         case TRANSACTION_isStreamActive:
         case TRANSACTION_isStreamActiveRemotely:
         case TRANSACTION_isSourceActive:
diff --git a/services/audiopolicy/service/AudioPolicyService.h b/services/audiopolicy/service/AudioPolicyService.h
index 935117d681..fc0b2639a4 100644
--- a/services/audiopolicy/service/AudioPolicyService.h
+++ b/services/audiopolicy/service/AudioPolicyService.h
@@ -120,7 +120,7 @@ public:
                                     const AudioConfig& config,
                                     int32_t flags, const std::vector<int32_t>& selectedDeviceIds,
                                     media::GetOutputForAttrResponse* _aidl_return) override;
-    binder::Status startOutput(int32_t portId) override;
+    binder::Status startOutput(int32_t portId, media::StartOutputResponse* _aidl_return) override;
     binder::Status stopOutput(int32_t portId) override;
     binder::Status releaseOutput(int32_t portId) override;
     binder::Status getInputForAttr(const media::audio::common::AudioAttributes& attr, int32_t input,
@@ -153,6 +153,14 @@ public:
                                                   int32_t* _aidl_return) override;
     binder::Status getMinVolumeIndexForAttributes(const media::audio::common::AudioAttributes& attr,
                                                   int32_t* _aidl_return) override;
+    binder::Status setVolumeIndexForGroup(int32_t groupId, const AudioDeviceDescription& device,
+            int32_t index, bool muted) override;
+    binder::Status getVolumeIndexForGroup(int32_t groupId, const AudioDeviceDescription& device,
+        int32_t* _aidl_return) override;
+    binder::Status getMaxVolumeIndexForGroup(int32_t groupId, int32_t* _aidl_return) override;
+    binder::Status setMaxVolumeIndexForGroup(int32_t groupId, int32_t index) override;
+    binder::Status getMinVolumeIndexForGroup(int32_t groupId, int32_t* _aidl_return) override;
+    binder::Status setMinVolumeIndexForGroup(int32_t groupId, int32_t index) override;
     binder::Status getStrategyForStream(AudioStreamType stream,
                                         int32_t* _aidl_return) override;
     binder::Status getDevicesForAttributes(const media::audio::common::AudioAttributes& attr,
@@ -844,7 +852,8 @@ private:
                                     const sp<DeviceDescriptorBase>& device,
                                     uint32_t *latencyMs,
                                     audio_output_flags_t *flags,
-                                    audio_attributes_t attributes);
+                                    audio_attributes_t attributes,
+                                    int32_t mixPortHalId);
         // creates a special output that is duplicated to the two outputs passed as arguments. The duplication is performed by
         // a special mixer thread in the AudioFlinger.
         virtual audio_io_handle_t openDuplicateOutput(audio_io_handle_t output1, audio_io_handle_t output2);
@@ -867,7 +876,8 @@ private:
                                             audio_devices_t *devices,
                                             const String8& address,
                                             audio_source_t source,
-                                            audio_input_flags_t flags);
+                                            audio_input_flags_t flags,
+                                            int32_t mixPortHalId);
         // closes an audio input
         virtual status_t closeInput(audio_io_handle_t input);
         //
@@ -955,7 +965,8 @@ private:
         status_t invalidateTracks(const std::vector<audio_port_handle_t>& portIds) override;
 
         status_t getAudioMixPort(const struct audio_port_v7 *devicePort,
-                                 struct audio_port_v7 *port) override;
+                                 struct audio_port_v7 *port,
+                                 int32_t mixPortHalId) override;
 
         status_t setTracksInternalMute(
                 const std::vector<media::TrackInternalMuteInfo>& tracksInternalMute) override;
diff --git a/services/audiopolicy/service/Spatializer.cpp b/services/audiopolicy/service/Spatializer.cpp
index e469b2c5a9..9f1223e4cd 100644
--- a/services/audiopolicy/service/Spatializer.cpp
+++ b/services/audiopolicy/service/Spatializer.cpp
@@ -225,9 +225,6 @@ const std::map<std::string, audio_latency_mode_t> Spatializer::sStringToLatencyM
 };
 
 void Spatializer::loadOrderedLowLatencyModes() {
-    if (!com::android::media::audio::dsa_over_bt_le_audio()) {
-        return;
-    }
     auto latencyModesStrs = android::sysprop::BluetoothProperties::dsa_transport_preference();
     audio_utils::lock_guard lock(mMutex);
     // First load preferred low latency modes ordered from the property
@@ -438,27 +435,24 @@ status_t Spatializer::loadEngineConfiguration(sp<EffectHalInterface> effect) {
         }
     }
 
-    if (com::android::media::audio::dsa_over_bt_le_audio()
-            && mSupportsHeadTracking) {
-        mHeadtrackingConnectionMode = HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED;
-        std::vector<HeadTracking::ConnectionMode> headtrackingConnectionModes;
-        status = getHalParameter<true>(effect, SPATIALIZER_PARAM_SUPPORTED_HEADTRACKING_CONNECTION,
-                &headtrackingConnectionModes);
-        if (status == NO_ERROR) {
-            for (const auto htConnectionMode : headtrackingConnectionModes) {
-                if (htConnectionMode < HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED ||
-                    htConnectionMode > HeadTracking::ConnectionMode::DIRECT_TO_SENSOR_TUNNEL) {
-                    ALOGW("%s: ignoring HT connection mode:%s", __func__,
-                          ToString(htConnectionMode).c_str());
-                    continue;
-                }
-                mSupportedHeadtrackingConnectionModes.insert(htConnectionMode);
+    mHeadtrackingConnectionMode = HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED;
+    std::vector<HeadTracking::ConnectionMode> headtrackingConnectionModes;
+    status = getHalParameter<true>(effect, SPATIALIZER_PARAM_SUPPORTED_HEADTRACKING_CONNECTION,
+            &headtrackingConnectionModes);
+    if (status == NO_ERROR) {
+        for (const auto htConnectionMode : headtrackingConnectionModes) {
+            if (htConnectionMode < HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED ||
+                htConnectionMode > HeadTracking::ConnectionMode::DIRECT_TO_SENSOR_TUNNEL) {
+                ALOGW("%s: ignoring HT connection mode:%s", __func__,
+                      ToString(htConnectionMode).c_str());
+                continue;
             }
-            ALOGW_IF(mSupportedHeadtrackingConnectionModes.find(
-                    HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED) ==
-                        mSupportedHeadtrackingConnectionModes.end(),
-                    "%s: Headtracking FRAMEWORK_PROCESSED not reported", __func__);
+            mSupportedHeadtrackingConnectionModes.insert(htConnectionMode);
         }
+        ALOGW_IF(mSupportedHeadtrackingConnectionModes.find(
+                HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED) ==
+                    mSupportedHeadtrackingConnectionModes.end(),
+                "%s: Headtracking FRAMEWORK_PROCESSED not reported", __func__);
     }
 
     // Currently we expose only RELATIVE_WORLD.
@@ -944,9 +938,6 @@ void Spatializer::onActualModeChangeMsg(HeadTrackingMode mode) {
 }
 
 void Spatializer::setEngineHeadtrackingConnectionMode_l() {
-    if (!com::android::media::audio::dsa_over_bt_le_audio()) {
-        return;
-    }
     if (mActualHeadTrackingMode != HeadTracking::Mode::DISABLED
             && !mSupportedHeadtrackingConnectionModes.empty()) {
         setEffectParameter_l(SPATIALIZER_PARAM_HEADTRACKING_CONNECTION,
@@ -956,9 +947,6 @@ void Spatializer::setEngineHeadtrackingConnectionMode_l() {
 }
 
 void Spatializer::sortSupportedLatencyModes_l() {
-    if (!com::android::media::audio::dsa_over_bt_le_audio()) {
-        return;
-    }
     std::sort(mSupportedLatencyModes.begin(), mSupportedLatencyModes.end(),
             [this](audio_latency_mode_t x, audio_latency_mode_t y) {
                 auto itX = std::find(mOrderedLowLatencyModes.begin(),
@@ -1099,9 +1087,6 @@ void Spatializer::updateActiveTracks(
 }
 
 audio_latency_mode_t Spatializer::selectHeadtrackingConnectionMode_l() {
-    if (!com::android::media::audio::dsa_over_bt_le_audio()) {
-        return AUDIO_LATENCY_MODE_LOW;
-    }
     // mSupportedLatencyModes is ordered according to system preferences loaded in
     // mOrderedLowLatencyModes
     mHeadtrackingConnectionMode = HeadTracking::ConnectionMode::FRAMEWORK_PROCESSED;
@@ -1136,17 +1121,11 @@ audio_latency_mode_t Spatializer::selectHeadtrackingConnectionMode_l() {
 void Spatializer::checkSensorsState_l() {
     mRequestedLatencyMode = AUDIO_LATENCY_MODE_FREE;
     const bool supportsSetLatencyMode = !mSupportedLatencyModes.empty();
-    bool supportsLowLatencyMode;
-    if (com::android::media::audio::dsa_over_bt_le_audio()) {
-        // mSupportedLatencyModes is ordered with MODE_FREE always at the end:
-        // the first entry is never MODE_FREE if at least one low ltency mode is supported.
-        supportsLowLatencyMode = supportsSetLatencyMode
-                && mSupportedLatencyModes[0] != AUDIO_LATENCY_MODE_FREE;
-    } else {
-        supportsLowLatencyMode = supportsSetLatencyMode && std::find(
-            mSupportedLatencyModes.begin(), mSupportedLatencyModes.end(),
-            AUDIO_LATENCY_MODE_LOW) != mSupportedLatencyModes.end();
-    }
+
+    // mSupportedLatencyModes is ordered with MODE_FREE always at the end:
+    // the first entry is never MODE_FREE if at least one low ltency mode is supported.
+    bool supportsLowLatencyMode = supportsSetLatencyMode
+            && mSupportedLatencyModes[0] != AUDIO_LATENCY_MODE_FREE;
     if (mSupportsHeadTracking) {
         if (mPoseController != nullptr) {
             // TODO(b/253297301, b/255433067) reenable low latency condition check
diff --git a/services/audiopolicy/service/Spatializer.h b/services/audiopolicy/service/Spatializer.h
index 6141165b05..3649112e42 100644
--- a/services/audiopolicy/service/Spatializer.h
+++ b/services/audiopolicy/service/Spatializer.h
@@ -569,7 +569,7 @@ private:
     static const std::vector<const char*> sHeadPoseKeys;
 
     // Local log for command messages.
-    static constexpr int mMaxLocalLogLine = 10;
+    static constexpr int mMaxLocalLogLine = 20;
     SimpleLog mLocalLog{mMaxLocalLogLine};
 
     /**
diff --git a/services/audiopolicy/tests/Android.bp b/services/audiopolicy/tests/Android.bp
index a6e5c75ab5..afa2243b6f 100644
--- a/services/audiopolicy/tests/Android.bp
+++ b/services/audiopolicy/tests/Android.bp
@@ -84,8 +84,13 @@ cc_test {
 
     require_root: true,
 
+    static_libs: [
+        "com.android.media.audioserver-aconfig-cc",
+    ],
+
     shared_libs: [
         "audioclient-types-aidl-cpp",
+        "libaconfig_storage_read_api_cc",
         "libaudioclient",
         "libaudioclient_aidl_conversion",
         "libaudiofoundation",
@@ -99,6 +104,7 @@ cc_test {
         "libstagefright_foundation",
         "libutils",
         "libxml2",
+        "server_configurable_flags",
     ],
 
     header_libs: [
diff --git a/services/audiopolicy/tests/AudioPolicyManagerTestClient.h b/services/audiopolicy/tests/AudioPolicyManagerTestClient.h
index 79c25aba76..078ab5f163 100644
--- a/services/audiopolicy/tests/AudioPolicyManagerTestClient.h
+++ b/services/audiopolicy/tests/AudioPolicyManagerTestClient.h
@@ -17,6 +17,7 @@
 #include <map>
 #include <set>
 
+#include <com_android_media_audioserver.h>
 #include <media/TypeConverter.h>
 #include <system/audio.h>
 #include <utils/Log.h>
@@ -40,17 +41,27 @@ public:
                         audio_io_handle_t *output,
                         audio_config_t *halConfig,
                         audio_config_base_t *mixerConfig,
-                        const sp<DeviceDescriptorBase>& /*device*/,
+                        const sp<DeviceDescriptorBase>& device,
                         uint32_t * /*latencyMs*/,
                         audio_output_flags_t *flags,
-                        audio_attributes_t /*attributes*/) override {
+                        audio_attributes_t /*attributes*/,
+                        int32_t mixPortId) override {
         if (module >= mNextModuleHandle) {
             ALOGE("%s: Module handle %d has not been allocated yet (next is %d)",
                   __func__, module, mNextModuleHandle);
             return BAD_VALUE;
         }
+
+        const auto deviceKey = std::make_pair(device->type(), device->address());
+        // Check if the route is artificially forbidden in the test case.
+        if (mNonRoutableMixPortsForDevice.count(deviceKey) &&
+              mNonRoutableMixPortsForDevice[deviceKey].count(mixPortId)) {
+            return INVALID_OPERATION;
+        }
+
         *output = mNextIoHandle++;
         mOpenedOutputs[*output] = *flags;
+        mIoHandleToMixPortId[*output] = mixPortId;
         ALOGD("%s: opened output %d: HAL(%s %s %d) Mixer(%s %s %d) %s", __func__, *output,
               audio_channel_out_mask_to_string(halConfig->channel_mask),
               audio_format_to_string(halConfig->format), halConfig->sample_rate,
@@ -69,6 +80,7 @@ public:
     status_t closeOutput(audio_io_handle_t output) override {
         if (auto iter = mOpenedOutputs.find(output); iter != mOpenedOutputs.end()) {
             mOpenedOutputs.erase(iter);
+            mIoHandleToMixPortId.erase(output);
             return NO_ERROR;
         } else {
             ALOGE("%s: Unknown output %d", __func__, output);
@@ -79,17 +91,27 @@ public:
     status_t openInput(audio_module_handle_t module,
                        audio_io_handle_t *input,
                        audio_config_t * /*config*/,
-                       audio_devices_t * /*device*/,
-                       const String8 & /*address*/,
+                       audio_devices_t *device,
+                       const String8 &address,
                        audio_source_t /*source*/,
-                       audio_input_flags_t /*flags*/) override {
+                       audio_input_flags_t /*flags*/,
+                       int32_t mixPortId) override {
         if (module >= mNextModuleHandle) {
             ALOGE("%s: Module handle %d has not been allocated yet (next is %d)",
                   __func__, module, mNextModuleHandle);
             return BAD_VALUE;
         }
+
+        const auto deviceKey = std::make_pair(*device, std::string(address.c_str()));
+        // Check if the route is artificially forbidden in the test case.
+        if (mNonRoutableMixPortsForDevice.count(deviceKey) &&
+              mNonRoutableMixPortsForDevice[deviceKey].count(mixPortId)) {
+            return INVALID_OPERATION;
+        }
+
         *input = mNextIoHandle++;
         mOpenedInputs.insert(*input);
+        mIoHandleToMixPortId[*input] = mixPortId;
         ALOGD("%s: opened input %d", __func__, *input);
         mOpenInputCallsCount++;
         return NO_ERROR;
@@ -105,6 +127,7 @@ public:
             }
             return BAD_VALUE;
         }
+        mIoHandleToMixPortId.erase(input);
         ALOGD("%s: closed input %d", __func__, input);
         mCloseInputCallsCount++;
         return NO_ERROR;
@@ -240,8 +263,45 @@ public:
         return mAudioParameters.toString();
     }
 
-    status_t getAudioMixPort(const struct audio_port_v7 *devicePort __unused,
-                             struct audio_port_v7 *mixPort) override {
+    status_t getAudioMixPort(const struct audio_port_v7 *devicePort,
+                             struct audio_port_v7 *mixPort,
+                             int32_t mixPortHalId) override {
+        const audio_io_handle_t ioHandle = mixPort->ext.mix.handle;
+
+        // Preserve the same behavior as the corresponding pre-flag logic.
+        if (!com::android::media::audioserver::enable_strict_port_routing_checks()
+              && ioHandle == AUDIO_IO_HANDLE_NONE) {
+            // If ioHandle is not supplied, this is certainly from a caller added after
+            // the change this flag is introducing, and will anticipate routing checks.
+            // However, in such an event, if the flag is disabled, the real pre-flag implementation
+            // will end up in `BAD_VALUE`, and we want to align to that for now in this mocked
+            // implementation. The trade-off is that the aformentioned caller must do the flag
+            // check before calling into `getAudioMixPort`.
+            return BAD_VALUE;
+        } else {
+            // Derive port ID from IO handle if specified.
+            if (mixPortHalId == AUDIO_PORT_HANDLE_NONE && ioHandle != AUDIO_IO_HANDLE_NONE) {
+                if (!mIoHandleToMixPortId.count(ioHandle)) {
+                    return BAD_VALUE;
+                }
+                mixPortHalId = mIoHandleToMixPortId[ioHandle];
+            }
+        }
+
+        // Check routing if port is identifiable by ID.
+        // Note it is possible that we don't have the ID, in which case this
+        // is not from an AIDL config, and we will just assume routable.
+        if (mixPortHalId != AUDIO_PORT_HANDLE_NONE) {
+            audio_devices_t deviceType = devicePort->ext.device.type;
+            std::string deviceAddr = devicePort->ext.device.address;
+            const auto deviceKey = std::make_pair(deviceType, deviceAddr);
+            // Check if the route is artificially forbidden in the test case.
+            if (mNonRoutableMixPortsForDevice.count(deviceKey) &&
+                  mNonRoutableMixPortsForDevice[deviceKey].count(mixPortHalId)) {
+                return INVALID_OPERATION;
+            }
+        }
+
         mixPort->num_audio_profiles = 0;
         for (auto format : mSupportedFormats) {
             const int i = mixPort->num_audio_profiles;
@@ -301,6 +361,18 @@ public:
         return std::nullopt;
     }
 
+    int32_t getMixPortIdByIoHandle(audio_io_handle_t ioHandle) {
+        if (auto iter = mIoHandleToMixPortId.find(ioHandle); iter != mIoHandleToMixPortId.end()) {
+            return iter->second;
+        }
+        return -1;
+    }
+
+    void setNonRoutableMixPortsForDevice(audio_devices_t type, std::string addr,
+                                         const std::set<int32_t> &mixPortIds) {
+        mNonRoutableMixPortsForDevice[std::make_pair(type, addr)] = mixPortIds;
+    }
+
 private:
     audio_module_handle_t mNextModuleHandle = AUDIO_MODULE_HANDLE_NONE + 1;
     audio_io_handle_t mNextIoHandle = AUDIO_IO_HANDLE_NONE + 1;
@@ -318,6 +390,11 @@ private:
     size_t mOpenInputCallsCount = 0;
     size_t mCloseInputCallsCount = 0;
     std::map<audio_io_handle_t, audio_output_flags_t> mOpenedOutputs;
+    std::map<audio_io_handle_t, int32_t> mIoHandleToMixPortId;
+    // This allows each test case to artificially decide if certain routes are
+    // unavailable for a device described by its legacy type and address.
+    std::map<std::pair<audio_devices_t, std::string>,
+          std::set<int32_t>> mNonRoutableMixPortsForDevice;
 };
 
 } // namespace android
diff --git a/services/audiopolicy/tests/AudioPolicyTestClient.h b/services/audiopolicy/tests/AudioPolicyTestClient.h
index 8e5fb968ad..7b2e1a979f 100644
--- a/services/audiopolicy/tests/AudioPolicyTestClient.h
+++ b/services/audiopolicy/tests/AudioPolicyTestClient.h
@@ -38,7 +38,8 @@ public:
                         const sp<DeviceDescriptorBase>& /*device*/,
                         uint32_t* /*latencyMs*/,
                         audio_output_flags_t* /*flags*/,
-                        audio_attributes_t /*attributes*/) override { return NO_INIT; }
+                        audio_attributes_t /*attributes*/,
+                        int32_t /*mixPortHalId*/) override { return NO_INIT; }
     audio_io_handle_t openDuplicateOutput(audio_io_handle_t /*output1*/,
                                           audio_io_handle_t /*output2*/) override {
         return AUDIO_IO_HANDLE_NONE;
@@ -52,7 +53,8 @@ public:
                        audio_devices_t* /*device*/,
                        const String8& /*address*/,
                        audio_source_t /*source*/,
-                       audio_input_flags_t /*flags*/) override { return NO_INIT; }
+                       audio_input_flags_t /*flags*/,
+                       int32_t /*mixPortHalId*/) override { return NO_INIT; }
     status_t closeInput(audio_io_handle_t /*input*/) override { return NO_INIT; }
     status_t setStreamVolume(audio_stream_type_t /*stream*/,
                              float /*volume*/,
@@ -114,7 +116,8 @@ public:
         return NO_INIT;
     }
     status_t getAudioMixPort(const struct audio_port_v7 *devicePort __unused,
-                             struct audio_port_v7 *mixPort __unused) override {
+                             struct audio_port_v7 *mixPort __unused,
+                             int32_t mixPortHalId __unused) override {
         return INVALID_OPERATION;
     }
 
diff --git a/services/audiopolicy/tests/AudioPolicyTestManager.h b/services/audiopolicy/tests/AudioPolicyTestManager.h
index e30882c3fe..2aa8883495 100644
--- a/services/audiopolicy/tests/AudioPolicyTestManager.h
+++ b/services/audiopolicy/tests/AudioPolicyTestManager.h
@@ -47,6 +47,7 @@ class AudioPolicyTestManager : public AudioPolicyManager {
     using AudioPolicyManager::deviceToAudioPort;
     using AudioPolicyManager::handleDeviceConfigChange;
     using AudioPolicyManager::getInputProfile;
+    using AudioPolicyManager::getOutputsForDevices;
     uint32_t getAudioPortGeneration() const { return mAudioPortGeneration; }
     HwModuleCollection getHwModules() const { return mHwModules; }
 };
diff --git a/services/audiopolicy/tests/audiopolicymanager_tests.cpp b/services/audiopolicy/tests/audiopolicymanager_tests.cpp
index e85d4e22bc..ca5ffb0e30 100644
--- a/services/audiopolicy/tests/audiopolicymanager_tests.cpp
+++ b/services/audiopolicy/tests/audiopolicymanager_tests.cpp
@@ -29,7 +29,9 @@
 #include <android-base/properties.h>
 #include <android/content/AttributionSourceState.h>
 #include <android_media_audiopolicy.h>
+#include <com_android_media_audio.h>
 #include <com_android_media_audioserver.h>
+#include <cutils/properties.h>
 #include <flag_macros.h>
 #include <hardware/audio_effect.h>
 #include <media/AudioPolicy.h>
@@ -304,14 +306,11 @@ void AudioPolicyManagerTest::getOutputForAttr(
     AudioPolicyInterface::output_type_t outputType;
     bool isSpatialized;
     bool isBitPerfectInternal;
-    float volume;
-    bool muted;
     AttributionSourceState attributionSource = createAttributionSourceState(uid);
     ASSERT_EQ(OK, mManager->getOutputForAttr(
                     &attr, output, session, &stream, attributionSource, &config, &flags,
                     selectedDeviceIds, portId, {}, &outputType, &isSpatialized,
-                    isBitPerfect == nullptr ? &isBitPerfectInternal : isBitPerfect, &volume,
-                    &muted));
+                    isBitPerfect == nullptr ? &isBitPerfectInternal : isBitPerfect));
     ASSERT_NE(AUDIO_PORT_HANDLE_NONE, *portId);
     ASSERT_NE(AUDIO_IO_HANDLE_NONE, *output);
 }
@@ -553,7 +552,7 @@ void AudioPolicyManagerTestMsd::SetUpManagerConfig() {
 
         sp<OutputProfile> spdifOutputProfile = new OutputProfile("spdif output");
         spdifOutputProfile->addAudioProfile(pcmOutputProfile);
-        spdifOutputProfile->addSupportedDevice(mSpdifDevice);
+        spdifOutputProfile->addSupportedRoutableDevice(mSpdifDevice);
         mConfig->getHwModules().getModuleFromName(AUDIO_HARDWARE_MODULE_ID_PRIMARY)->
                 addOutputProfile(spdifOutputProfile);
     }
@@ -565,24 +564,24 @@ void AudioPolicyManagerTestMsd::SetUpManagerConfig() {
 
     sp<OutputProfile> msdOutputProfile = new OutputProfile("msd input");
     msdOutputProfile->addAudioProfile(pcmOutputProfile);
-    msdOutputProfile->addSupportedDevice(mMsdOutputDevice);
+    msdOutputProfile->addSupportedRoutableDevice(mMsdOutputDevice);
     msdModule->addOutputProfile(msdOutputProfile);
     sp<OutputProfile> msdCompressedOutputProfile = new OutputProfile("msd compressed input");
     msdCompressedOutputProfile->addAudioProfile(ac3OutputProfile);
     msdCompressedOutputProfile->setFlags(
             AUDIO_OUTPUT_FLAG_DIRECT | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD |
             AUDIO_OUTPUT_FLAG_NON_BLOCKING);
-    msdCompressedOutputProfile->addSupportedDevice(mMsdOutputDevice);
+    msdCompressedOutputProfile->addSupportedRoutableDevice(mMsdOutputDevice);
     msdModule->addOutputProfile(msdCompressedOutputProfile);
     sp<OutputProfile> msdIec958OutputProfile = new OutputProfile("msd iec958 input");
     msdIec958OutputProfile->addAudioProfile(iec958OutputProfile);
     msdIec958OutputProfile->setFlags(AUDIO_OUTPUT_FLAG_DIRECT);
-    msdIec958OutputProfile->addSupportedDevice(mMsdOutputDevice);
+    msdIec958OutputProfile->addSupportedRoutableDevice(mMsdOutputDevice);
     msdModule->addOutputProfile(msdIec958OutputProfile);
 
     sp<InputProfile> msdInputProfile = new InputProfile("msd output");
     msdInputProfile->addAudioProfile(pcmInputProfile);
-    msdInputProfile->addSupportedDevice(mMsdInputDevice);
+    msdInputProfile->addSupportedRoutableDevice(mMsdInputDevice);
     msdModule->addInputProfile(msdInputProfile);
 
     // Add a profile with another encoding to the default device to test routing
@@ -593,14 +592,14 @@ void AudioPolicyManagerTestMsd::SetUpManagerConfig() {
     sp<OutputProfile> primaryEncodedOutputProfile = new OutputProfile("encoded");
     primaryEncodedOutputProfile->addAudioProfile(dtsOutputProfile);
     primaryEncodedOutputProfile->setFlags(AUDIO_OUTPUT_FLAG_DIRECT);
-    primaryEncodedOutputProfile->addSupportedDevice(mConfig->getDefaultOutputDevice());
+    primaryEncodedOutputProfile->addSupportedRoutableDevice(mConfig->getDefaultOutputDevice());
     mConfig->getHwModules().getModuleFromName(AUDIO_HARDWARE_MODULE_ID_PRIMARY)->
             addOutputProfile(primaryEncodedOutputProfile);
 
     mDefaultOutputDevice = mConfig->getDefaultOutputDevice();
     if (mExpectedAudioPatchCount == 3) {
         mSpdifDevice->addAudioProfile(dtsOutputProfile);
-        primaryEncodedOutputProfile->addSupportedDevice(mSpdifDevice);
+        primaryEncodedOutputProfile->addSupportedRoutableDevice(mSpdifDevice);
     }
 
     // Add HDMI input device with IEC60958 profile for HDMI in -> MSD patching.
@@ -612,7 +611,7 @@ void AudioPolicyManagerTestMsd::SetUpManagerConfig() {
     sp<InputProfile> hdmiInputProfile = new InputProfile("hdmi input");
     hdmiInputProfile->addAudioProfile(iec958InputProfile);
     hdmiInputProfile->setFlags(AUDIO_INPUT_FLAG_DIRECT);
-    hdmiInputProfile->addSupportedDevice(mHdmiInputDevice);
+    hdmiInputProfile->addSupportedRoutableDevice(mHdmiInputDevice);
     mConfig->getHwModules().getModuleFromName(AUDIO_HARDWARE_MODULE_ID_PRIMARY)->
             addInputProfile(hdmiInputProfile);
 }
@@ -1166,14 +1165,18 @@ TEST_F(AudioPolicyManagerTestWithConfigurationFile, RoutingChangedWithPreferredM
     getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
             k48000SamplingRate, AUDIO_OUTPUT_FLAG_NONE, &output, &portId, mediaAttr,
             AUDIO_SESSION_NONE, uid);
-    status_t status = mManager->startOutput(portId);
+    bool muted{};
+    float volume{};
+    status_t status = mManager->startOutput(portId, &volume, &muted);
     if (status == DEAD_OBJECT) {
         getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
                 k48000SamplingRate, AUDIO_OUTPUT_FLAG_NONE, &output, &portId, mediaAttr,
                 AUDIO_SESSION_NONE, uid);
-        status = mManager->startOutput(portId);
+        status = mManager->startOutput(portId, &volume, &muted);
     }
     EXPECT_EQ(NO_ERROR, status);
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     EXPECT_NE(AUDIO_IO_HANDLE_NONE, output);
     EXPECT_NE(nullptr, mManager->getOutputs().valueFor(output));
     EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(AUDIO_DEVICE_OUT_BLUETOOTH_A2DP,
@@ -1435,6 +1438,142 @@ TEST_F(AudioPolicyManagerTestWithConfigurationFile, AudioSourceFixedByGetInputfo
                              AUDIO_SOURCE_VOICE_COMMUNICATION);
 }
 
+TEST_F(AudioPolicyManagerTestWithConfigurationFile, SelectMMapOffloadOnlyWhenRequested) {
+    ASSERT_EQ(NO_ERROR, mManager->setDeviceConnectionState(AUDIO_DEVICE_OUT_USB_DEVICE,
+                                                           AUDIO_POLICY_DEVICE_STATE_AVAILABLE,
+                                                           "", "", AUDIO_FORMAT_DEFAULT));
+
+    auto devices = mManager->getAvailableOutputDevices();
+    audio_port_handle_t usbPortId = AUDIO_PORT_HANDLE_NONE;
+    for (auto device : devices) {
+        if (device->type() == AUDIO_DEVICE_OUT_USB_DEVICE) {
+            usbPortId = device->getId();
+            break;
+        }
+    }
+    EXPECT_NE(AUDIO_PORT_HANDLE_NONE, usbPortId);
+
+    const audio_attributes_t mediaAttr = {
+            .content_type = AUDIO_CONTENT_TYPE_MUSIC,
+            .usage = AUDIO_USAGE_MEDIA,
+    };
+
+    for (auto flags : {(AUDIO_OUTPUT_FLAG_MMAP_NOIRQ | AUDIO_OUTPUT_FLAG_DIRECT),
+                       (AUDIO_OUTPUT_FLAG_MMAP_NOIRQ | AUDIO_OUTPUT_FLAG_DIRECT |
+                            AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD),
+                       (AUDIO_OUTPUT_FLAG_DIRECT | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD)}) {
+        audio_io_handle_t output = AUDIO_IO_HANDLE_NONE;
+        // Use preferred device to ensure usb is selected so that mmap mix port can be used
+        DeviceIdVector selectedDeviceIds = {usbPortId};
+        audio_port_handle_t portId;
+        getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
+                         k48000SamplingRate, static_cast<audio_output_flags_t>(flags), &output,
+                         &portId);
+        EXPECT_NE(AUDIO_IO_HANDLE_NONE, output);
+        sp<SwAudioOutputDescriptor> outDesc = mManager->getOutputs().valueFor(output);
+        ASSERT_NE(nullptr, outDesc.get());
+        EXPECT_EQ(flags, outDesc->getFlags().output);
+        mManager->releaseOutput(portId);
+    }
+
+    ASSERT_EQ(NO_ERROR, mManager->setDeviceConnectionState(AUDIO_DEVICE_OUT_USB_DEVICE,
+                                                           AUDIO_POLICY_DEVICE_STATE_UNAVAILABLE,
+                                                           "", "", AUDIO_FORMAT_DEFAULT));
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestWithConfigurationFile,
+                  MMapOffloadCompressOffloadMutuallyExclusive,
+                  REQUIRES_FLAGS_ENABLED(
+                          ACONFIG_FLAG(com::android::media::audioserver,
+                                       mmap_pcm_offload_support))) {
+    ASSERT_EQ(NO_ERROR, mManager->setDeviceConnectionState(AUDIO_DEVICE_OUT_USB_DEVICE,
+                                                           AUDIO_POLICY_DEVICE_STATE_AVAILABLE,
+                                                           "", "", AUDIO_FORMAT_DEFAULT));
+
+    auto devices = mManager->getAvailableOutputDevices();
+    audio_port_handle_t usbPortId = AUDIO_PORT_HANDLE_NONE;
+    for (auto device : devices) {
+        if (device->type() == AUDIO_DEVICE_OUT_USB_DEVICE) {
+            usbPortId = device->getId();
+            break;
+        }
+    }
+    ASSERT_NE(AUDIO_PORT_HANDLE_NONE, usbPortId);
+
+    const audio_attributes_t mediaAttr = {
+            .content_type = AUDIO_CONTENT_TYPE_MUSIC,
+            .usage = AUDIO_USAGE_MEDIA,
+    };
+
+    std::vector<std::pair<uint32_t, uint32_t>> mutuallyExclusiveFlagsPair = {
+            {(AUDIO_OUTPUT_FLAG_MMAP_NOIRQ | AUDIO_OUTPUT_FLAG_DIRECT |
+                    AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD),
+             (AUDIO_OUTPUT_FLAG_DIRECT | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD)},
+            {(AUDIO_OUTPUT_FLAG_DIRECT | AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD),
+             (AUDIO_OUTPUT_FLAG_MMAP_NOIRQ | AUDIO_OUTPUT_FLAG_DIRECT |
+                    AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD)},
+    };
+    for (auto flagsPair : mutuallyExclusiveFlagsPair) {
+        audio_io_handle_t output1 = AUDIO_IO_HANDLE_NONE;
+        // Use preferred device to ensure usb is selected so that mmap mix port can be used
+        DeviceIdVector selectedDeviceIds = {usbPortId};
+        audio_port_handle_t portId1;
+        getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
+                         k48000SamplingRate, static_cast<audio_output_flags_t>(flagsPair.first),
+                         &output1, &portId1);
+        EXPECT_NE(AUDIO_IO_HANDLE_NONE, output1);
+        if (output1 == AUDIO_IO_HANDLE_NONE) {
+            break;
+        }
+        sp<SwAudioOutputDescriptor> outDesc = mManager->getOutputs().valueFor(output1);
+        ASSERT_NE(nullptr, outDesc.get());
+        EXPECT_EQ(flagsPair.first, outDesc->getFlags().output);
+
+        // Request with same output flags will get the same output.
+        audio_io_handle_t output2 = AUDIO_IO_HANDLE_NONE;
+        audio_port_handle_t portId2;
+        getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
+                         k48000SamplingRate, static_cast<audio_output_flags_t>(flagsPair.first),
+                         &output2, &portId2);
+        EXPECT_EQ(output1, output2);
+        mManager->releaseOutput(portId2);
+
+        // Request with mutually exclusive flags will fail.
+        audio_output_flags_t mutuallyExclusiveFlags =
+                static_cast<audio_output_flags_t>(flagsPair.second);
+        audio_io_handle_t output3 = AUDIO_IO_HANDLE_NONE;
+        audio_port_handle_t portId3 = AUDIO_PORT_HANDLE_NONE;
+        audio_stream_type_t stream = AUDIO_STREAM_DEFAULT;
+        audio_config_t config = AUDIO_CONFIG_INITIALIZER;
+        config.sample_rate = k48000SamplingRate;
+        config.channel_mask = AUDIO_CHANNEL_OUT_STEREO;
+        config.format = AUDIO_FORMAT_PCM_16_BIT;
+        audio_port_handle_t localPortId;
+        AudioPolicyInterface::output_type_t outputType;
+        bool isSpatialized;
+        bool isBitPerfect;
+        AttributionSourceState attributionSource = createAttributionSourceState(0);
+        auto result = mManager->getOutputForAttr(
+                &mediaAttr, &output3, AUDIO_SESSION_NONE, &stream, attributionSource, &config,
+                &mutuallyExclusiveFlags, &selectedDeviceIds, &portId3, {}, &outputType,
+                &isSpatialized, &isBitPerfect);
+        if (property_get_bool("ro.audio.mmap_offload_exclusive", false /*default_value*/)) {
+            EXPECT_EQ(INVALID_OPERATION, result);
+            EXPECT_EQ(AUDIO_IO_HANDLE_NONE, output3);
+        } else {
+            EXPECT_EQ(NO_ERROR, result);
+            EXPECT_NE(AUDIO_IO_HANDLE_NONE, output3);
+        }
+
+        mManager->releaseOutput(portId1);
+        mManager->releaseOutput(portId3);
+    }
+
+    ASSERT_EQ(NO_ERROR, mManager->setDeviceConnectionState(AUDIO_DEVICE_OUT_USB_DEVICE,
+                                                           AUDIO_POLICY_DEVICE_STATE_UNAVAILABLE,
+                                                           "", "", AUDIO_FORMAT_DEFAULT));
+}
+
 class AudioPolicyManagerTestDynamicPolicy : public AudioPolicyManagerTestWithConfigurationFile {
 protected:
     void TearDown() override;
@@ -1667,8 +1806,7 @@ TEST_F(AudioPolicyManagerTestDynamicPolicy, RegisterPolicyWithInconsistentMixFai
 TEST_F_WITH_FLAGS(
         AudioPolicyManagerTestDynamicPolicy,
         RegisterInvalidMixesDoesNotImpactPriorMixes,
-        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy, audio_mix_test_api),
-                               ACONFIG_FLAG(android::media::audiopolicy, audio_mix_ownership))
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy, audio_mix_test_api))
 ) {
     audio_config_t audioConfig = AUDIO_CONFIG_INITIALIZER;
     audioConfig.channel_mask = AUDIO_CHANNEL_OUT_STEREO;
@@ -1710,8 +1848,7 @@ TEST_F_WITH_FLAGS(
 TEST_F_WITH_FLAGS(
         AudioPolicyManagerTestDynamicPolicy,
         UnregisterInvalidMixesReturnsError,
-        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy, audio_mix_test_api),
-                               ACONFIG_FLAG(android::media::audiopolicy, audio_mix_ownership))
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy, audio_mix_test_api))
 ) {
     audio_config_t audioConfig = AUDIO_CONFIG_INITIALIZER;
     audioConfig.channel_mask = AUDIO_CHANNEL_OUT_STEREO;
@@ -2288,8 +2425,7 @@ TEST_P(AudioPolicyManagerTestMMapPlaybackRerouting, MmapPlaybackStreamMatchingLo
               mManager->getOutputForAttr(&attr, &mOutput, AUDIO_SESSION_NONE, &mStream,
                                          createAttributionSourceState(testUid), &audioConfig,
                                          &outputFlags, &mSelectedDeviceIds, &mPortId, {},
-                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect, &mVolume,
-                                         &mMuted));
+                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect));
 }
 
 TEST_P(AudioPolicyManagerTestMMapPlaybackRerouting,
@@ -2308,8 +2444,7 @@ TEST_P(AudioPolicyManagerTestMMapPlaybackRerouting,
               mManager->getOutputForAttr(&attr, &mOutput, AUDIO_SESSION_NONE, &mStream,
                                          createAttributionSourceState(testUid), &audioConfig,
                                          &outputFlags, &mSelectedDeviceIds, &mPortId, {},
-                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect, &mVolume,
-                                         &mMuted));
+                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect));
 }
 
 TEST_F(AudioPolicyManagerTestMMapPlaybackRerouting,
@@ -2340,8 +2475,7 @@ TEST_F(AudioPolicyManagerTestMMapPlaybackRerouting,
               mManager->getOutputForAttr(&attr, &mOutput, AUDIO_SESSION_NONE, &mStream,
                                          createAttributionSourceState(testUid), &audioConfig,
                                          &outputFlags, &mSelectedDeviceIds, &mPortId, {},
-                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect, &mVolume,
-                                         &mMuted));
+                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect));
     auto outputDesc = mManager->getOutputs().valueFor(mOutput);
     ASSERT_NE(nullptr, outputDesc);
     ASSERT_EQ(mmapDirectFlags, outputDesc->getFlags().output);
@@ -2356,8 +2490,7 @@ TEST_F(AudioPolicyManagerTestMMapPlaybackRerouting,
               mManager->getOutputForAttr(&attr, &mOutput, AUDIO_SESSION_NONE, &mStream,
                                          createAttributionSourceState(testUid), &audioConfig,
                                          &outputFlags, &mSelectedDeviceIds, &mPortId, {},
-                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect, &mVolume,
-                                         &mMuted));
+                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect));
     ASSERT_EQ(usbDevicePort.id, mSelectedDeviceIds[0]);
     outputDesc = mManager->getOutputs().valueFor(mOutput);
     ASSERT_NE(nullptr, outputDesc);
@@ -2386,8 +2519,7 @@ TEST_F(AudioPolicyManagerTestMMapPlaybackRerouting,
               mManager->getOutputForAttr(&attr, &mOutput, AUDIO_SESSION_NONE, &mStream,
                                          createAttributionSourceState(testUid), &audioConfig,
                                          &outputFlags, &mSelectedDeviceIds, &mPortId, {},
-                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect, &mVolume,
-                                         &mMuted));
+                                         &mOutputType, &mIsSpatialized, &mIsBitPerfect));
 }
 
 INSTANTIATE_TEST_SUITE_P(
@@ -2438,7 +2570,11 @@ void AudioPolicyManagerTestDPMixRecordInjection::SetUp() {
     strncpy(attr.tags, tags.c_str(), AUDIO_ATTRIBUTES_TAGS_MAX_SIZE - 1);
     getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
             k48000SamplingRate, AUDIO_OUTPUT_FLAG_NONE, nullptr /*output*/, &mPortId, attr);
-    ASSERT_EQ(NO_ERROR, mManager->startOutput(mPortId));
+    bool muted{};
+    float volume{};
+    ASSERT_EQ(NO_ERROR, mManager->startOutput(mPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     ASSERT_EQ(injectionPort.id, getDeviceIdFromPatch(mClient->getLastAddedPatch()));
 
     ASSERT_TRUE(findDevicePort(AUDIO_PORT_ROLE_SOURCE, AUDIO_DEVICE_IN_REMOTE_SUBMIX,
@@ -2720,11 +2856,12 @@ class AudioPolicyManagerTestClientOpenFails : public AudioPolicyManagerTestClien
                         const sp<DeviceDescriptorBase>& device,
                         uint32_t * latencyMs,
                         audio_output_flags_t *flags,
-                        audio_attributes_t attributes) override {
+                        audio_attributes_t attributes,
+                        int32_t mixPortHalId) override {
         return mSimulateFailure ? BAD_VALUE :
                 AudioPolicyManagerTestClient::openOutput(
                         module, output, halConfig, mixerConfig, device, latencyMs, flags,
-                        attributes);
+                        attributes, mixPortHalId);
     }
 
     status_t openInput(audio_module_handle_t module,
@@ -2733,10 +2870,11 @@ class AudioPolicyManagerTestClientOpenFails : public AudioPolicyManagerTestClien
                        audio_devices_t * device,
                        const String8 & address,
                        audio_source_t source,
-                       audio_input_flags_t flags) override {
+                       audio_input_flags_t flags,
+                       int32_t mixPortHalId) override {
         return mSimulateFailure ? BAD_VALUE :
                 AudioPolicyManagerTestClient::openInput(
-                        module, input, config, device, address, source, flags);
+                        module, input, config, device, address, source, flags, mixPortHalId);
     }
 
     void setSimulateFailure(bool simulateFailure) { mSimulateFailure = simulateFailure; }
@@ -3525,6 +3663,8 @@ TEST_F(AudioPolicyManagerPhoneTest, Dump) {
 TEST_F(AudioPolicyManagerPhoneTest, NoPatchChangesDuringAlarmPlayback) {
     audio_port_handle_t alarmPortId = AUDIO_PORT_HANDLE_NONE;
     audio_io_handle_t alarmOutput = AUDIO_IO_HANDLE_NONE;
+    bool muted{};
+    float volume{};
     {
         // Uses STRATEGY_SONIFICATION, routed to AUDIO_DEVICE_OUT_SPEAKER_SAFE.
         audio_attributes_t attr = {
@@ -3536,7 +3676,9 @@ TEST_F(AudioPolicyManagerPhoneTest, NoPatchChangesDuringAlarmPlayback) {
                         AUDIO_CHANNEL_OUT_STEREO, 48000,
                         AUDIO_OUTPUT_FLAG_NONE,
                         &alarmOutput, &alarmPortId, attr));
-        EXPECT_EQ(NO_ERROR, mManager->startOutput(alarmPortId));
+        EXPECT_EQ(NO_ERROR, mManager->startOutput(alarmPortId, &volume, &muted));
+        EXPECT_GE(volume, 0.f);
+        EXPECT_LE(volume, 1.f);
     }
     const audio_patch lastPatchBefore = *(mClient->getLastAddedPatch());
 
@@ -3553,7 +3695,9 @@ TEST_F(AudioPolicyManagerPhoneTest, NoPatchChangesDuringAlarmPlayback) {
                         AUDIO_CHANNEL_OUT_STEREO, 48000,
                         AUDIO_OUTPUT_FLAG_NONE,
                         &notifOutput, &notifPortId, attr));
-        EXPECT_EQ(NO_ERROR, mManager->startOutput(notifPortId));
+        EXPECT_EQ(NO_ERROR, mManager->startOutput(notifPortId, &volume, &muted));
+        EXPECT_GE(volume, 0.f);
+        EXPECT_LE(volume, 1.f);
     }
     dumpToLog();
     const audio_patch lastPatchAfter = *(mClient->getLastAddedPatch());
@@ -4168,6 +4312,8 @@ void AudioPolicyManagerTestAbsoluteVolume::SetUp() {
 
     mManager->setDeviceAbsoluteVolumeEnabled(AUDIO_DEVICE_OUT_USB_DEVICE, "", /*enabled=*/true,
                                              AUDIO_STREAM_MUSIC);
+    mManager->setDeviceAbsoluteVolumeEnabled(AUDIO_DEVICE_OUT_BLUETOOTH_SCO, "", /*enabled=*/true,
+                                             AUDIO_STREAM_VOICE_CALL);
 }
 
 void AudioPolicyManagerTestAbsoluteVolume::TearDown() {
@@ -4190,8 +4336,11 @@ void AudioPolicyManagerTestAbsoluteVolume::setVolumeIndexForAttributesForDriving
                                              AUDIO_CHANNEL_OUT_STEREO, 48000,
                                              AUDIO_OUTPUT_FLAG_NONE,
                                              &mediaOutput, &mOutputPortId, sMediaAttr));
-    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId));
-
+    bool muted{};
+    float volume{};
+    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     EXPECT_EQ(NO_ERROR, mManager->setVolumeIndexForAttributes(sMediaAttr, /*index=*/1,
                                                               /*muted=*/false,
                                                               AUDIO_DEVICE_OUT_USB_DEVICE));
@@ -4232,8 +4381,11 @@ void AudioPolicyManagerTestAbsoluteVolume::setVolumeIndexForAttributesForNonDriv
                                              AUDIO_CHANNEL_OUT_STEREO, 48000,
                                              AUDIO_OUTPUT_FLAG_NONE,
                                              &notifOutput, &mOutputPortId, sNotifAttr));
-    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId));
-
+    bool muted{};
+    float volume{};
+    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     EXPECT_EQ(NO_ERROR, mManager->setVolumeIndexForAttributes(sNotifAttr, /*index=*/1,
                                                               /*muted=*/false,
                                                               AUDIO_DEVICE_OUT_USB_DEVICE));
@@ -4272,7 +4424,11 @@ TEST_F(AudioPolicyManagerTestAbsoluteVolume, SetVolumeIndexForVoiceCallAttribute
                                              AUDIO_CHANNEL_OUT_STEREO, 48000,
                                              AUDIO_OUTPUT_FLAG_PRIMARY,
                                              &voiceOutput, &mOutputPortId, sVoiceCallAttr));
-    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId));
+    bool muted{};
+    float volume{};
+    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
 
     EXPECT_EQ(NO_ERROR, mManager->setVolumeIndexForAttributes(sVoiceCallAttr, /*index=*/1,
                                                               /*muted=*/false,
@@ -4300,7 +4456,11 @@ TEST_F(AudioPolicyManagerTestAbsoluteVolume, SetVolumeIndexForVoiceCallAttribute
                                              AUDIO_CHANNEL_OUT_STEREO, 48000,
                                              AUDIO_OUTPUT_FLAG_PRIMARY,
                                              &voiceOutput, &mOutputPortId, sVoiceCallAttr));
-    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId));
+    bool muted{};
+    float volume{};
+    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
 
     EXPECT_EQ(NO_ERROR, mManager->setVolumeIndexForAttributes(sVoiceCallAttr, /*index=*/1,
                                                               /*muted=*/false,
@@ -4335,8 +4495,16 @@ void AudioPolicyManagerTestAbsoluteVolume::setVolumeIndexForDtmfAttributesOnSco(
                                              AUDIO_CHANNEL_OUT_STEREO, 48000,
                                              AUDIO_OUTPUT_FLAG_PRIMARY,
                                              &dtmfOutput, &mOutputPortId, sDtmfAttr));
-    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId));
+    bool muted{};
+    float volume{};
+    ASSERT_EQ(NO_ERROR, mManager->startOutput(mOutputPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
 
+    // voice call needs to be adjusted to the same level since they are usually aliased
+    EXPECT_EQ(NO_ERROR, mManager->setVolumeIndexForAttributes(sVoiceCallAttr, /*index=*/1,
+                                                              /*muted=*/false,
+                                                              AUDIO_DEVICE_OUT_BLUETOOTH_SCO));
     EXPECT_EQ(NO_ERROR, mManager->setVolumeIndexForAttributes(sDtmfAttr, /*index=*/1,
                                                               /*muted=*/false,
                                                               AUDIO_DEVICE_OUT_BLUETOOTH_SCO));
@@ -4370,6 +4538,209 @@ TEST_F_WITH_FLAGS(AudioPolicyManagerTestAbsoluteVolume,
     setVolumeIndexForDtmfAttributesOnSco(/*withPortApi=*/false);
 }
 
+class AudioPolicyManagerTestVolumeGroupID : public AudioPolicyManagerTestWithConfigurationFile {
+public:
+    static constexpr int sMinIndex = 5;
+    static constexpr int sMaxIndex = 10;
+    static const std::vector<audio_stream_type_t> sStreams;
+protected:
+    void SetUp() override;
+    void TearDown() override;
+};
+
+const std::vector<audio_stream_type_t> AudioPolicyManagerTestVolumeGroupID::sStreams{
+        AUDIO_STREAM_VOICE_CALL,
+        AUDIO_STREAM_SYSTEM,
+        AUDIO_STREAM_RING,
+        AUDIO_STREAM_MUSIC,
+        AUDIO_STREAM_ALARM,
+        AUDIO_STREAM_NOTIFICATION,
+        AUDIO_STREAM_BLUETOOTH_SCO,
+        AUDIO_STREAM_ENFORCED_AUDIBLE,
+        AUDIO_STREAM_DTMF,
+        AUDIO_STREAM_TTS,
+        AUDIO_STREAM_ACCESSIBILITY,
+        AUDIO_STREAM_ASSISTANT,
+        AUDIO_STREAM_CALL_ASSISTANT,
+};
+
+void AudioPolicyManagerTestVolumeGroupID::SetUp() {
+    ASSERT_NO_FATAL_FAILURE(AudioPolicyManagerTestWithConfigurationFile::SetUp());
+    for (audio_stream_type_t stream : sStreams) {
+        mManager->initStreamVolume(stream, sMinIndex, sMaxIndex);
+    }
+}
+
+void AudioPolicyManagerTestVolumeGroupID::TearDown() {
+    ASSERT_NO_FATAL_FAILURE(AudioPolicyManagerTestWithConfigurationFile::TearDown());
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, GetMinMaxVolumeWithId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, mManager->listAudioVolumeGroups(groups));
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (streamType >= AUDIO_STREAM_PUBLIC_CNT) continue;
+        int minIndex;
+        int maxIndex;
+
+        EXPECT_EQ(OK, mManager->getMinVolumeIndexForGroup(vg, minIndex));
+        EXPECT_EQ(OK, mManager->getMaxVolumeIndexForGroup(vg, maxIndex));
+
+        EXPECT_EQ(sMinIndex, minIndex) << "Min index for group " << group.getName().c_str();
+        EXPECT_EQ(sMaxIndex, maxIndex) << "Max index for group " << group.getName().c_str();
+    }
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetMinMaxVolumeWithId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, mManager->listAudioVolumeGroups(groups));
+    int testMinIndex = sMinIndex + 1;
+    int testMaxIndex = sMaxIndex - 1;
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (streamType >= AUDIO_STREAM_PUBLIC_CNT) continue;
+
+        EXPECT_EQ(OK, mManager->setMinVolumeIndexForGroup(vg, testMinIndex));
+        EXPECT_EQ(OK, mManager->setMaxVolumeIndexForGroup(vg, testMaxIndex));
+
+        int minIndex;
+        int maxIndex;
+        EXPECT_EQ(OK, mManager->getMinVolumeIndexForGroup(vg, minIndex));
+        EXPECT_EQ(OK, mManager->getMaxVolumeIndexForGroup(vg, maxIndex));
+        EXPECT_EQ(testMinIndex, minIndex) << "Min index for group after setting it "
+            << group.getName().c_str();
+        EXPECT_EQ(testMaxIndex, maxIndex) << "Max index for group after setting it "
+            << group.getName().c_str();
+    }
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetAndGetVolumeWithId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, mManager->listAudioVolumeGroups(groups));
+    audio_devices_t type = AUDIO_DEVICE_OUT_SPEAKER;
+    int testIndex = 7;
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (streamType >= AUDIO_STREAM_PUBLIC_CNT) continue;
+        int setIndex;
+
+        EXPECT_EQ(OK, mManager->setVolumeIndexForGroup(vg, testIndex, /* muted= */ false, type));
+        EXPECT_EQ(OK, mManager->getVolumeIndexForGroup(vg, setIndex, type));
+
+        EXPECT_EQ(testIndex, setIndex) << "Set index for group " << group.getName().c_str();
+    }
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetAndGetVolumeWithStream,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, mManager->listAudioVolumeGroups(groups));
+    audio_devices_t type = AUDIO_DEVICE_OUT_SPEAKER;
+    int testIndex = 8;
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (streamType >= AUDIO_STREAM_PUBLIC_CNT) continue;
+        int setIndex;
+        EXPECT_EQ(OK,
+                  mManager->setStreamVolumeIndex(streamType, testIndex, /* muted= */ false, type));
+
+        EXPECT_EQ(OK, mManager->getVolumeIndexForGroup(vg, setIndex, type));
+
+        EXPECT_EQ(testIndex, setIndex) << "Set index for stream in " << group.getName().c_str();
+    }
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetWithIDAndGetVolumeWithStream,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, mManager->listAudioVolumeGroups(groups));
+    audio_devices_t type = AUDIO_DEVICE_OUT_SPEAKER;
+    int testIndex = 9;
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (streamType >= AUDIO_STREAM_PUBLIC_CNT) continue;
+        int setIndex;
+
+        EXPECT_EQ(OK, mManager->setVolumeIndexForGroup(vg, testIndex, /* muted= */ false, type));
+
+        EXPECT_EQ(OK, mManager->getStreamVolumeIndex(streamType, &setIndex, type));
+        EXPECT_EQ(testIndex, setIndex) << "Get index for stream in " << group.getName().c_str();
+    }
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetWithInvalidIndexVolumeWithId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    AudioVolumeGroupVector groups;
+    EXPECT_EQ(OK, mManager->listAudioVolumeGroups(groups));
+    audio_devices_t type = AUDIO_DEVICE_OUT_SPEAKER;
+    int testIndex = sMaxIndex + 1;
+    for (const auto& group : groups) {
+        if (group.getStreamTypes().empty()) continue;
+        volume_group_t vg = group.getId();
+        audio_stream_type_t streamType = group.getStreamTypes()[0];
+        if (streamType >= AUDIO_STREAM_PUBLIC_CNT) continue;
+
+        EXPECT_EQ(BAD_VALUE,
+                  mManager->setVolumeIndexForGroup(vg, testIndex, /* muted= */ false, type));
+    }
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetWithInvalidId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    audio_devices_t type = AUDIO_DEVICE_OUT_SPEAKER;
+
+    EXPECT_EQ(BAD_VALUE, mManager->setVolumeIndexForGroup(VOLUME_GROUP_NONE, sMaxIndex,
+                                                          /* muted= */ false, type));
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, GetWithInvalidId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    audio_devices_t type = AUDIO_DEVICE_OUT_SPEAKER;
+    int index;
+
+    EXPECT_EQ(BAD_VALUE, mManager->getVolumeIndexForGroup(VOLUME_GROUP_NONE, index, type));
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, GetMinMaxWithInvalidId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    int index;
+
+    EXPECT_EQ(BAD_VALUE, mManager->getMinVolumeIndexForGroup(VOLUME_GROUP_NONE, index));
+    EXPECT_EQ(BAD_VALUE, mManager->getMaxVolumeIndexForGroup(VOLUME_GROUP_NONE, index));
+}
+
+TEST_F_WITH_FLAGS(AudioPolicyManagerTestVolumeGroupID, SetMinMaxWithInvalidId,
+        REQUIRES_FLAGS_ENABLED(ACONFIG_FLAG(android::media::audiopolicy,
+                                            volume_group_management_update))) {
+    int index = sMinIndex;
+
+    EXPECT_EQ(BAD_VALUE, mManager->setMinVolumeIndexForGroup(VOLUME_GROUP_NONE, index));
+    EXPECT_EQ(BAD_VALUE, mManager->setMaxVolumeIndexForGroup(VOLUME_GROUP_NONE, index));
+}
+
 class AudioPolicyManagerTestBitPerfectBase : public AudioPolicyManagerTestWithConfigurationFile {
 protected:
     void SetUp() override;
@@ -4448,14 +4819,18 @@ void AudioPolicyManagerTestBitPerfectBase::startBitPerfectOutput() {
     getOutputForAttr(&mSelectedDeviceIds, mBitPerfectFormat, mBitPerfectChannelMask,
                      mBitPerfectSampleRate, AUDIO_OUTPUT_FLAG_NONE, &mBitPerfectOutput,
                      &mBitPerfectPortId, sMediaAttr, AUDIO_SESSION_NONE, mUid, &isBitPerfect);
-    status_t status = mManager->startOutput(mBitPerfectPortId);
+    bool muted{};
+    float volume{};
+    status_t status = mManager->startOutput(mBitPerfectPortId, &volume, &muted);
     if (status == DEAD_OBJECT) {
         getOutputForAttr(&mSelectedDeviceIds, mBitPerfectFormat, mBitPerfectChannelMask,
                          mBitPerfectSampleRate, AUDIO_OUTPUT_FLAG_NONE, &mBitPerfectOutput,
                          &mBitPerfectPortId, sMediaAttr, AUDIO_SESSION_NONE, mUid, &isBitPerfect);
-        status = mManager->startOutput(mBitPerfectPortId);
+        status = mManager->startOutput(mBitPerfectPortId, &volume, &muted);
     }
     EXPECT_EQ(NO_ERROR, status);
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     EXPECT_TRUE(isBitPerfect);
     EXPECT_NE(AUDIO_IO_HANDLE_NONE, mBitPerfectOutput);
     const auto bitPerfectOutputDesc = mManager->getOutputs().valueFor(mBitPerfectOutput);
@@ -4482,13 +4857,11 @@ void AudioPolicyManagerTestBitPerfectBase::getBitPerfectOutput(status_t expected
     AudioPolicyInterface::output_type_t outputType;
     bool isSpatialized;
     bool isBitPerfect;
-    float volume;
-    bool muted;
     EXPECT_EQ(expected,
               mManager->getOutputForAttr(&sMediaAttr, &mBitPerfectOutput, AUDIO_SESSION_NONE,
                                          &stream, attributionSource, &config, &flags,
                                          &mSelectedDeviceIds, &mBitPerfectPortId, {}, &outputType,
-                                         &isSpatialized, &isBitPerfect, &volume, &muted));
+                                         &isSpatialized, &isBitPerfect));
 }
 
 class AudioPolicyManagerTestBitPerfect : public AudioPolicyManagerTestBitPerfectBase {
@@ -4553,13 +4926,7 @@ TEST_F(AudioPolicyManagerTestBitPerfect, UseBitPerfectOutput) {
     EXPECT_EQ(mBitPerfectOutput, output);
 }
 
-TEST_F_WITH_FLAGS(
-        AudioPolicyManagerTestBitPerfect,
-        InternalMuteWhenBitPerfectCLientIsActive,
-        REQUIRES_FLAGS_ENABLED(
-                ACONFIG_FLAG(com::android::media::audioserver,
-                             fix_concurrent_playback_behavior_with_bit_perfect_client))
-) {
+TEST_F(AudioPolicyManagerTestBitPerfect, InternalMuteWhenBitPerfectCLientIsActive) {
     ASSERT_NO_FATAL_FAILURE(startBitPerfectOutput());
 
     // When bit-perfect playback is active, the system sound will be routed to bit-perfect output.
@@ -4579,7 +4946,11 @@ TEST_F_WITH_FLAGS(
                      &systemSoundPortId, systemSoundAttr, AUDIO_SESSION_NONE, mUid, &isBitPerfect);
     EXPECT_FALSE(isBitPerfect);
     EXPECT_EQ(mBitPerfectOutput, systemSoundOutput);
-    EXPECT_EQ(NO_ERROR, mManager->startOutput(systemSoundPortId));
+    bool muted{};
+    float volume{};
+    EXPECT_EQ(NO_ERROR, mManager->startOutput(systemSoundPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     EXPECT_TRUE(mClient->getTrackInternalMute(systemSoundPortId));
     EXPECT_FALSE(mClient->getTrackInternalMute(mBitPerfectPortId));
     EXPECT_EQ(NO_ERROR, mManager->stopOutput(systemSoundPortId));
@@ -4600,7 +4971,9 @@ TEST_F_WITH_FLAGS(
                      &isBitPerfect);
     EXPECT_FALSE(isBitPerfect);
     EXPECT_EQ(mBitPerfectOutput, notificationOutput);
-    EXPECT_EQ(NO_ERROR, mManager->startOutput(notificationPortId));
+    EXPECT_EQ(NO_ERROR, mManager->startOutput(notificationPortId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     EXPECT_FALSE(mClient->getTrackInternalMute(notificationPortId));
     EXPECT_TRUE(mClient->getTrackInternalMute(mBitPerfectPortId));
     EXPECT_EQ(NO_ERROR, mManager->stopOutput(notificationPortId));
@@ -4614,12 +4987,6 @@ class AudioPolicyManagerTestBitPerfectPhoneMode : public AudioPolicyManagerTestB
 };
 
 TEST_P(AudioPolicyManagerTestBitPerfectPhoneMode, RejectBitPerfectWhenPhoneModeIsNotNormal) {
-    if (!com::android::media::audioserver::
-            fix_concurrent_playback_behavior_with_bit_perfect_client()) {
-        GTEST_SKIP()
-                << "Flag fix_concurrent_playback_behavior_with_bit_perfect_client is not enabled";
-    }
-
     ASSERT_NO_FATAL_FAILURE(startBitPerfectOutput());
 
     audio_mode_t mode = GetParam();
@@ -4649,12 +5016,6 @@ class AudioPolicyManagerTestBitPerfectHigherPriorityUseCaseActive :
 
 TEST_P(AudioPolicyManagerTestBitPerfectHigherPriorityUseCaseActive,
        RejectBitPerfectWhenHigherPriorityUseCaseIsActive) {
-    if (!com::android::media::audioserver::
-                fix_concurrent_playback_behavior_with_bit_perfect_client()) {
-        GTEST_SKIP()
-                << "Flag fix_concurrent_playback_behavior_with_bit_perfect_client is not enabled";
-    }
-
     ASSERT_NO_FATAL_FAILURE(startBitPerfectOutput());
 
     audio_attributes_t attr = {
@@ -4668,7 +5029,11 @@ TEST_P(AudioPolicyManagerTestBitPerfectHigherPriorityUseCaseActive,
             getOutputForAttr(&selectedDeviceIds, AUDIO_FORMAT_PCM_16_BIT, AUDIO_CHANNEL_OUT_STEREO,
                    48000, AUDIO_OUTPUT_FLAG_NONE, &output, &portId, attr));
     EXPECT_NE(mBitPerfectOutput, output);
-    EXPECT_EQ(NO_ERROR, mManager->startOutput(portId));
+    bool muted{};
+    float volume{};
+    EXPECT_EQ(NO_ERROR, mManager->startOutput(portId, &volume, &muted));
+    EXPECT_GE(volume, 0.f);
+    EXPECT_LE(volume, 1.f);
     // When a high priority use case is active, the bit-perfect output will be closed.
     EXPECT_EQ(nullptr, mManager->getOutputs().valueFor(mBitPerfectOutput));
 
@@ -4800,6 +5165,209 @@ TEST_F_WITH_FLAGS(
     EXPECT_NE(input1, input2);
 }
 
+class AudioPolicyManagerPortRoutingTest : public AudioPolicyManagerTestWithConfigurationFile {
+};
+
+TEST_F_WITH_FLAGS(
+        AudioPolicyManagerPortRoutingTest,
+        RoutableReducesToSupportedWhenFlagDisabled,
+        REQUIRES_FLAGS_DISABLED(
+                ACONFIG_FLAG(com::android::media::audio, check_route_in_get_audio_mix_port),
+                ACONFIG_FLAG(com::android::media::audioserver, enable_strict_port_routing_checks))
+) {
+    mManager->setPhoneState(AUDIO_MODE_IN_COMMUNICATION);
+
+
+    const audio_devices_t kBtOutScoType = AUDIO_DEVICE_OUT_BLUETOOTH_SCO;
+    const char btAddress[] = "11:22:33:44:55:66";
+
+    sp<DeviceDescriptor> devDesc =
+          new DeviceDescriptor(AudioDeviceTypeAddr(kBtOutScoType, btAddress));
+
+    EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(
+            kBtOutScoType, AUDIO_POLICY_DEVICE_STATE_AVAILABLE,
+            btAddress, "", AUDIO_FORMAT_DEFAULT));
+
+    bool atLeastOneProfileContainsDevice = false;
+
+    for (const auto& hwModule : mManager->getHwModules()) {
+        for (size_t i = 0; i < hwModule->getOutputProfiles().size(); ++i) {
+            sp<IOProfile> outProfile = hwModule->getOutputProfiles()[i];
+
+            const auto& supportedDevices = outProfile->getSupportedDevices();
+            const auto& routableDevices = outProfile->getRoutableDevices();
+            EXPECT_EQ(supportedDevices, routableDevices);
+
+            if (supportedDevices.contains(devDesc)) {
+                atLeastOneProfileContainsDevice = true;
+                EXPECT_TRUE(outProfile->supportsDevice(devDesc));
+                EXPECT_TRUE(outProfile->routesToDevice(devDesc));
+            }
+        }
+    }
+
+    EXPECT_TRUE(atLeastOneProfileContainsDevice);
+
+    EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(
+            AUDIO_DEVICE_OUT_BLUETOOTH_SCO, AUDIO_POLICY_DEVICE_STATE_UNAVAILABLE,
+            btAddress, "", AUDIO_FORMAT_DEFAULT));
+
+    mManager->setPhoneState(AUDIO_MODE_NORMAL);
+}
+
+TEST_F_WITH_FLAGS(
+        AudioPolicyManagerPortRoutingTest,
+        PortRoutingOverUsbIsRespected,
+        REQUIRES_FLAGS_ENABLED(
+                ACONFIG_FLAG(com::android::media::audio, check_route_in_get_audio_mix_port),
+                ACONFIG_FLAG(com::android::media::audioserver, enable_strict_port_routing_checks))
+) {
+    // These values must match the number of input and output mix ports defined
+    // for the "usb" module in the test_audio_policy_configuration.xml file:
+    //
+    // Number of USB devices that we will connect at once for testing.
+    const size_t NUM_DEVICES = 2;
+    // Number of USB mix ports that we expect to find in the config.
+    const size_t NUM_MIX_PORTS = 2;
+
+    const audio_devices_t kUsbInHsType = AUDIO_DEVICE_IN_USB_HEADSET;
+    const audio_devices_t kUsbOutHsType = AUDIO_DEVICE_OUT_USB_HEADSET;
+    const std::string usbAddrs[NUM_DEVICES] = {"card=1;device=0", "card=2;device=0"};
+
+    // This test is based on XML config parsing and does not have HAL IDs.
+    // We assign some unique numbers to test this AIDL feature.
+    int32_t halIdCounter = AUDIO_PORT_HANDLE_NONE + 1;
+    for (const auto& hwModule : mManager->getHwModules()) {
+        for (size_t i = 0; i < hwModule->getOutputProfiles().size(); ++i) {
+            sp<IOProfile> outProfile = hwModule->getOutputProfiles()[i];
+            outProfile->setHalIdForTest(halIdCounter++);
+        }
+        for (size_t i = 0; i < hwModule->getInputProfiles().size(); ++i) {
+            sp<IOProfile> inProfile = hwModule->getInputProfiles()[i];
+            inProfile->setHalIdForTest(halIdCounter++);
+        }
+    }
+
+    sp<HwModule> usbModule = nullptr;
+    for (const auto& hwModule : mManager->getHwModules()) {
+        if (strcmp(hwModule->getName(), "usb") == 0) {
+            usbModule = hwModule;
+            break;
+        }
+    }
+    ASSERT_NE(nullptr, usbModule.get());
+
+    // General device descriptors to identify profiles that support
+    // the USB device type.
+    sp<DeviceDescriptor> usbGeneralInDevDesc =
+          new DeviceDescriptor(AudioDeviceTypeAddr(kUsbInHsType, ""));
+    sp<DeviceDescriptor> usbGeneralOutDevDesc =
+          new DeviceDescriptor(AudioDeviceTypeAddr(kUsbOutHsType, ""));
+
+    // Find eligible mix port profiles in the usb module.
+    std::vector<sp<IOProfile>> usbInMixPortProfiles;
+    for (size_t i = 0; i < usbModule->getInputProfiles().size(); ++i) {
+        sp<IOProfile> inProfile = usbModule->getInputProfiles()[i];
+        if (inProfile->supportsDevice(usbGeneralInDevDesc)) {
+            usbInMixPortProfiles.push_back(inProfile);
+        }
+    }
+    EXPECT_EQ(NUM_MIX_PORTS, usbInMixPortProfiles.size());
+
+    std::vector<sp<IOProfile>> usbOutMixPortProfiles;
+    for (size_t i = 0; i < usbModule->getOutputProfiles().size(); ++i) {
+        sp<IOProfile> outProfile = usbModule->getOutputProfiles()[i];
+        if (outProfile->supportsDevice(usbGeneralOutDevDesc)) {
+            usbOutMixPortProfiles.push_back(outProfile);
+        }
+    }
+    EXPECT_EQ(NUM_MIX_PORTS, usbOutMixPortProfiles.size());
+
+    // Connect each device.
+    for (size_t i = 0; i < NUM_DEVICES; ++i) {
+        // Simulate exclusive routing from HAL.
+        std::set<int32_t> nonRoutableInPortIds;
+        std::set<int32_t> nonRoutableOutPortIds;
+        for (size_t halId = AUDIO_PORT_HANDLE_NONE + 1; halId < halIdCounter; ++halId) {
+            if (usbInMixPortProfiles[i]->getHalId() != halId) {
+                nonRoutableInPortIds.insert(halId);
+            }
+            if (usbOutMixPortProfiles[i]->getHalId() != halId) {
+                nonRoutableOutPortIds.insert(halId);
+            }
+        }
+
+        mClient->setNonRoutableMixPortsForDevice(kUsbInHsType, usbAddrs[i], nonRoutableInPortIds);
+        mClient->setNonRoutableMixPortsForDevice(kUsbOutHsType, usbAddrs[i], nonRoutableOutPortIds);
+
+        EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(
+                kUsbInHsType, AUDIO_POLICY_DEVICE_STATE_AVAILABLE,
+                usbAddrs[i].c_str(), "", AUDIO_FORMAT_DEFAULT));
+        EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(
+                kUsbOutHsType, AUDIO_POLICY_DEVICE_STATE_AVAILABLE,
+                usbAddrs[i].c_str(), "", AUDIO_FORMAT_DEFAULT));
+    }
+
+    // Verify port connectivity and routability.
+    for (size_t i = 0; i < NUM_DEVICES; ++i) {
+        // Device port can be identified by type and address.
+        audio_port_v7 usbInDevicePort;
+        EXPECT_TRUE(findDevicePort(AUDIO_PORT_ROLE_SOURCE, kUsbInHsType,
+                                   usbAddrs[i], &usbInDevicePort));
+
+        audio_port_v7 usbOutDevicePort;
+        EXPECT_TRUE(findDevicePort(AUDIO_PORT_ROLE_SINK, kUsbOutHsType,
+                                   usbAddrs[i], &usbOutDevicePort));
+
+        sp<DeviceDescriptor> inDevDesc =
+              mManager->getAvailableInputDevices().getDeviceFromDeviceTypeAddr(
+                  AudioDeviceTypeAddr(kUsbInHsType, usbAddrs[i]));
+        EXPECT_NE(nullptr, inDevDesc);
+
+        sp<DeviceDescriptor> outDevDesc =
+              mManager->getAvailableOutputDevices().getDeviceFromDeviceTypeAddr(
+                  AudioDeviceTypeAddr(kUsbOutHsType, usbAddrs[i]));
+        EXPECT_NE(nullptr, outDevDesc);
+
+        // The device maps to the intended mix port profile.
+        audio_format_t requestedFormat = AUDIO_FORMAT_PCM_16_BIT;
+        uint32_t requestedRate = 48000;
+        audio_channel_mask_t requestedChannelMask = AUDIO_CHANNEL_IN_STEREO;
+        auto inProfile = mManager->getInputProfile(
+            inDevDesc, requestedRate, requestedFormat, requestedChannelMask, AUDIO_INPUT_FLAG_NONE);
+        ASSERT_NE(nullptr, inProfile.get());
+        EXPECT_EQ(usbInMixPortProfiles[i]->getHalId(), inProfile->getHalId());
+
+        DeviceVector outDevices(outDevDesc);
+        SortedVector<audio_io_handle_t> outIoHandles =
+              mManager->getOutputsForDevices(outDevices, mManager->getOutputs());
+
+        for (audio_io_handle_t handle : outIoHandles) {
+            const auto desc = mManager->getOutputs().valueFor(handle);
+
+            EXPECT_EQ(true, desc->routesToDevice(outDevDesc));
+
+            if (!desc->isDuplicated()) {
+                EXPECT_EQ(usbOutMixPortProfiles[i]->getHalId(),
+                          mClient->getMixPortIdByIoHandle(handle));
+            }
+        }
+    }
+
+    // Disconnect each device.
+    for (size_t i = 0; i < NUM_DEVICES; ++i) {
+        mClient->setNonRoutableMixPortsForDevice(kUsbInHsType, usbAddrs[i], std::set<int32_t>());
+        EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(
+                kUsbInHsType, AUDIO_POLICY_DEVICE_STATE_UNAVAILABLE,
+                usbAddrs[i].c_str(), "", AUDIO_FORMAT_DEFAULT));
+
+        mClient->setNonRoutableMixPortsForDevice(kUsbOutHsType, usbAddrs[i], std::set<int32_t>());
+        EXPECT_EQ(NO_ERROR, mManager->setDeviceConnectionState(
+                kUsbOutHsType, AUDIO_POLICY_DEVICE_STATE_UNAVAILABLE,
+                usbAddrs[i].c_str(), "", AUDIO_FORMAT_DEFAULT));
+    }
+}
+
 int main(int argc, char** argv) {
     ::testing::InitGoogleTest(&argc, argv);
     ::testing::UnitTest::GetInstance()->listeners().Append(new TestExecutionTracer());
diff --git a/services/audiopolicy/tests/resources/engine/test_audio_policy_engine_product_strategies.xml b/services/audiopolicy/tests/resources/engine/test_audio_policy_engine_product_strategies.xml
index 58e7152a38..81a30441a3 100644
--- a/services/audiopolicy/tests/resources/engine/test_audio_policy_engine_product_strategies.xml
+++ b/services/audiopolicy/tests/resources/engine/test_audio_policy_engine_product_strategies.xml
@@ -86,6 +86,12 @@
         </AttributesGroup>
     </ProductStrategy>
 
+    <ProductStrategy name="STRATEGY_CALL_ASSISTANT">
+        <AttributesGroup streamType="AUDIO_STREAM_CALL_ASSISTANT" volumeGroup="call_assistant">
+            <Attributes> <Usage value="AUDIO_USAGE_CALL_ASSISTANT"/> </Attributes>
+        </AttributesGroup>
+    </ProductStrategy>
+
     <!-- Used to identify the volume of audio streams exclusively transmitted through the  speaker
          (TTS) of the device -->
     <ProductStrategy name="STRATEGY_TRANSMITTED_THROUGH_SPEAKER">
diff --git a/services/audiopolicy/tests/resources/test_audio_policy_configuration.xml b/services/audiopolicy/tests/resources/test_audio_policy_configuration.xml
index 55afbdc85f..48db67dfc2 100644
--- a/services/audiopolicy/tests/resources/test_audio_policy_configuration.xml
+++ b/services/audiopolicy/tests/resources/test_audio_policy_configuration.xml
@@ -60,6 +60,16 @@
                     <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
                              samplingRates="48000" channelMasks="AUDIO_CHANNEL_OUT_STEREO"/>
                 </mixPort>
+                <mixPort name="mmap_offload" role="source"
+                    flags="AUDIO_OUTPUT_FLAG_DIRECT AUDIO_OUTPUT_FLAG_MMAP_NOIRQ AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                        samplingRates="48000" channelMasks="AUDIO_CHANNEL_OUT_STEREO"/>
+                </mixPort>
+                <mixPort name="compress_offload" role="source"
+                    flags="AUDIO_OUTPUT_FLAG_DIRECT AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                        samplingRates="48000" channelMasks="AUDIO_CHANNEL_OUT_STEREO"/>
+                </mixPort>
                 <mixPort name="mixport_bus_input" role="sink">
                     <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
                         samplingRates="48000"
@@ -119,7 +129,7 @@
                 <route type="mix" sink="BT A2DP Out"
                        sources="primary output,hifi_output"/>
                 <route type="mix" sink="USB Device Out"
-                       sources="primary output,hifi_output,mmap_no_irq_out"/>
+                       sources="primary output,hifi_output,mmap_no_irq_out,mmap_offload,compress_offload"/>
                 <route type="mix" sink="mixport_bus_input"
                     sources="BUS Device In"/>
                 <route type="mix" sink="hifi_input"
@@ -131,6 +141,46 @@
             </routes>
         </module>
 
+        <!-- USB module -->
+        <module name="usb" halVersion="2.0">
+            <mixPorts>
+                <mixPort name="usb_headset output 1" role="source">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                             samplingRates="48000" channelMasks="AUDIO_CHANNEL_OUT_STEREO"/>
+                </mixPort>
+                <mixPort name="usb_headset output 2" role="source">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                             samplingRates="48000" channelMasks="AUDIO_CHANNEL_OUT_STEREO"/>
+                </mixPort>
+                <mixPort name="usb_headset input 1" role="sink">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                             samplingRates="48000" channelMasks="AUDIO_CHANNEL_IN_STEREO"/>
+                </mixPort>
+                <mixPort name="usb_headset input 2" role="sink">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                             samplingRates="48000" channelMasks="AUDIO_CHANNEL_IN_STEREO"/>
+                </mixPort>
+            </mixPorts>
+            <devicePorts>
+                <devicePort tagName="USB Headset Out" type="AUDIO_DEVICE_OUT_USB_HEADSET" role="sink">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                             samplingRates="48000" channelMasks="AUDIO_CHANNEL_OUT_STEREO"/>
+                </devicePort>
+                <devicePort tagName="USB Headset In" type="AUDIO_DEVICE_IN_USB_HEADSET" role="source">
+                    <profile name="" format="AUDIO_FORMAT_PCM_16_BIT"
+                             samplingRates="48000" channelMasks="AUDIO_CHANNEL_IN_STEREO"/>
+                </devicePort>
+            </devicePorts>
+            <routes>
+                <route type="mix" sink="USB Headset Out"
+                       sources="usb_headset output 1,usb_headset output 2"/>
+                <route type="mix" sink="usb_headset input 1"
+                       sources="USB Headset In"/>
+                <route type="mix" sink="usb_headset input 2"
+                       sources="USB Headset In"/>
+            </routes>
+        </module>
+
         <!-- Remote Submix module -->
         <module name="r_submix" halVersion="2.0">
             <attachedDevices>
diff --git a/services/audiopolicy/tests/spatializer_tests.cpp b/services/audiopolicy/tests/spatializer_tests.cpp
index 0b40f32810..61fe6be4ef 100644
--- a/services/audiopolicy/tests/spatializer_tests.cpp
+++ b/services/audiopolicy/tests/spatializer_tests.cpp
@@ -160,9 +160,6 @@ TEST_F(SpatializerTest, SupportedBleLatencyTest) {
     if (!setpUpForHeadtracking()) {
         GTEST_SKIP() << "Skipping SupportedBleLatencyTest: head tracking not supported";
     }
-    if (!com::android::media::audio::dsa_over_bt_le_audio()) {
-        GTEST_SKIP() << "Skipping SupportedBleLatencyTest: DSA over LE not enabled";
-    }
     std::vector<audio_latency_mode_t> latencies = sBLELatencyModes;
     mSpatializer->onSupportedLatencyModesChangedMsg(sTestOutput, std::move(latencies));
 
@@ -220,9 +217,6 @@ TEST_F(SpatializerTest, RequestedBleLatencyTest) {
     if (!setpUpForHeadtracking()) {
         GTEST_SKIP() << "Skipping RequestedBleLatencyTest: head tracking not supported";
     }
-    if (!com::android::media::audio::dsa_over_bt_le_audio()) {
-        GTEST_SKIP() << "Skipping RequestedBleLatencyTest: DSA over LE not enabled";
-    }
 
     mSpatializer->onSupportedLatencyModesChangedMsg(sTestOutput,
             { AUDIO_LATENCY_MODE_DYNAMIC_SPATIAL_AUDIO_SOFTWARE,
diff --git a/services/camera/libcameraservice/Android.bp b/services/camera/libcameraservice/Android.bp
index 0606d7414a..97c6628ab6 100644
--- a/services/camera/libcameraservice/Android.bp
+++ b/services/camera/libcameraservice/Android.bp
@@ -78,6 +78,7 @@ cc_defaults {
         "libxml2",
         "libyuv",
         "android.companion.virtual.virtualdevice_aidl-cpp",
+        "android.companion.virtualdevice.flags-aconfig-cc",
         "android.hardware.camera.common@1.0",
         "android.hardware.camera.device@1.0",
         "android.hardware.camera.device@3.2",
diff --git a/services/camera/libcameraservice/CameraService.cpp b/services/camera/libcameraservice/CameraService.cpp
index 7358ed3d4c..fd0e3e6a55 100644
--- a/services/camera/libcameraservice/CameraService.cpp
+++ b/services/camera/libcameraservice/CameraService.cpp
@@ -38,6 +38,7 @@
 #include <aidl/AidlCameraService.h>
 #include <android-base/macros.h>
 #include <android-base/parseint.h>
+#include <android_companion_virtualdevice_flags.h>
 #include <android/companion/virtualnative/IVirtualDeviceManagerNative.h>
 #include <binder/ActivityManager.h>
 #include <binder/AppOpsManager.h>
@@ -129,6 +130,7 @@ using hardware::camera2::utils::CameraIdAndSessionConfiguration;
 using hardware::camera2::utils::ConcurrentCameraIdCombination;
 
 namespace flags = com::android::internal::camera::flags;
+namespace vd_flags = android::companion::virtualdevice::flags;
 
 // ----------------------------------------------------------------------------
 // Logging support -- this is for debugging only
@@ -2331,10 +2333,6 @@ Status CameraService::connectDeviceImpl(
 
     bool isNonSystemNdk = clientPackageNameMaybe.size() == 0;
 
-    if (!flags::data_delivery_permission_checks()) {
-        resolvedClientAttribution.pid = USE_CALLING_PID;
-    }
-
     ret = resolveAttributionSource(resolvedClientAttribution, __FUNCTION__, cameraId);
     if (!ret.isOk()) {
         logRejected(cameraId, getCallingPid(), clientAttribution.packageName.value_or(""),
@@ -4369,33 +4367,6 @@ status_t CameraService::BasicClient::handleAppOpMode(int32_t mode) {
 status_t CameraService::BasicClient::notifyCameraOpening() {
     ATRACE_CALL();
 
-    // Don't start watching until we're streaming when using permissionChecker for data delivery
-    if (!flags::data_delivery_permission_checks()) {
-        ALOGD("%s: Start camera ops, package name = %s, client UID = %d", __FUNCTION__,
-              getPackageName().c_str(), getClientUid());
-
-        if (mAppOpsManager != nullptr) {
-            // Notify app ops that the camera is not available
-            mOpsCallback = new OpsCallback(this);
-
-            mAppOpsManager->startWatchingMode(
-                    AppOpsManager::OP_CAMERA, toString16(getPackageName()),
-                    AppOpsManager::WATCH_FOREGROUND_CHANGES, mOpsCallback);
-
-            // Just check for camera access here on open - delay startOp until
-            // camera frames start streaming in startCameraStreamingOps
-            int32_t mode = mAppOpsManager->checkOp(AppOpsManager::OP_CAMERA, getClientUid(),
-                                                   toString16(getPackageName()));
-            status_t res = handleAppOpMode(mode);
-            if (res != OK) {
-                return res;
-            }
-        }
-    } else {
-        // TODO: Remove when removing the data_delivery_permission_checks flag
-        ALOGD("%s: Bypassing checkOp for uid %d", __FUNCTION__, getClientUid());
-    }
-
     mCameraOpen = true;
 
     // Transition device availability listeners from PRESENT -> NOT_AVAILABLE
@@ -4431,35 +4402,23 @@ status_t CameraService::BasicClient::startCameraStreamingOps() {
           getPackageName().c_str(), getClientUid());
 
     if (mAppOpsManager != nullptr) {
-        if (flags::data_delivery_permission_checks()) {
-            ALOGD("%s: Start data delivery for uid %d", __FUNCTION__, getClientUid());
+        ALOGD("%s: Start data delivery for uid %d", __FUNCTION__, getClientUid());
 
-            const PermissionChecker::PermissionResult result =
-                    checkPermissionsForCameraForStartDataDelivery(mCameraIdStr, mClientAttribution);
-            status_t res = handlePermissionResult(result);
-            if (res != OK) {
-                return res;
-            }
-
-            mOpsCallback = new OpsCallback(this);
-            std::for_each(AttrSourceItr{mClientAttribution}, AttrSourceItr::end(),
-                      [&](const auto& attr) {
-                          mAppOpsManager->startWatchingMode(
-                                  AppOpsManager::OP_CAMERA,
-                                  toString16(attr.packageName.value_or("")),
-                                  AppOpsManager::WATCH_FOREGROUND_CHANGES, mOpsCallback);
-                      });
-        } else {
-            ALOGD("%s: startOp for uid %d", __FUNCTION__, getClientUid());
-            int32_t mode = mAppOpsManager->startOpNoThrow(
-                    AppOpsManager::OP_CAMERA, getClientUid(), toString16(getPackageName()),
-                    /*startIfModeDefault*/ false, toString16(getClientAttributionTag()),
-                    toString16("start camera ") + toString16(mCameraIdStr));
-            status_t res = handleAppOpMode(mode);
-            if (res != OK) {
-                return res;
-            }
+        const PermissionChecker::PermissionResult result =
+                checkPermissionsForCameraForStartDataDelivery(mCameraIdStr, mClientAttribution);
+        status_t res = handlePermissionResult(result);
+        if (res != OK) {
+            return res;
         }
+
+        mOpsCallback = new OpsCallback(this);
+        std::for_each(AttrSourceItr{mClientAttribution}, AttrSourceItr::end(),
+                    [&](const auto& attr) {
+                        mAppOpsManager->startWatchingMode(
+                                AppOpsManager::OP_CAMERA,
+                                toString16(attr.packageName.value_or("")),
+                                AppOpsManager::WATCH_FOREGROUND_CHANGES, mOpsCallback);
+                    });
     }
 
     mCameraStreaming = true;
@@ -4473,23 +4432,9 @@ status_t CameraService::BasicClient::noteAppOp() {
     ALOGV("%s: Start camera noteAppOp, package name = %s, client UID = %d", __FUNCTION__,
           getPackageName().c_str(), getClientUid());
 
-    // noteAppOp is only used for when camera mute is not supported, in order
-    // to trigger the sensor privacy "Unblock" dialog
-    if (flags::data_delivery_permission_checks()) {
-        // Ignore the result, since we're only triggering the dialog
-        ALOGD("%s: Check data delivery permissions for uid %d", __FUNCTION__, getClientUid());
-        hasPermissionsForCameraForDataDelivery(std::string(), mClientAttribution);
-    } else if (mAppOpsManager != nullptr) {
-        ALOGD("%s: noteOp for uid %d", __FUNCTION__, getClientUid());
-        int32_t mode = mAppOpsManager->noteOp(
-                AppOpsManager::OP_CAMERA, getClientUid(), toString16(getPackageName()),
-                toString16(getClientAttributionTag()),
-                toString16("start camera ") + toString16(mCameraIdStr));
-        status_t res = handleAppOpMode(mode);
-        if (res != OK) {
-            return res;
-        }
-    }
+    // Ignore the result, since we're only triggering the dialog
+    ALOGD("%s: Check data delivery permissions for uid %d", __FUNCTION__, getClientUid());
+    hasPermissionsForCameraForDataDelivery(std::string(), mClientAttribution);
 
     return OK;
 }
@@ -4507,20 +4452,13 @@ status_t CameraService::BasicClient::finishCameraStreamingOps() {
     }
 
     if (mAppOpsManager != nullptr) {
-        if (flags::data_delivery_permission_checks()) {
-            ALOGD("%s: finishDataDelivery for uid %d", __FUNCTION__, getClientUid());
-            finishDataDelivery(mClientAttribution);
-
-            // Stop watching app op changes after stop streaming
-            if (mOpsCallback != nullptr) {
-                mAppOpsManager->stopWatchingMode(mOpsCallback);
-                mOpsCallback.clear();
-            }
-        } else {
-            ALOGD("%s: finishOp for uid %d", __FUNCTION__, getClientUid());
-            mAppOpsManager->finishOp(AppOpsManager::OP_CAMERA, getClientUid(),
-                                     toString16(getPackageName()),
-                                     toString16(getClientAttributionTag()));
+        ALOGD("%s: finishDataDelivery for uid %d", __FUNCTION__, getClientUid());
+        finishDataDelivery(mClientAttribution);
+
+        // Stop watching app op changes after stop streaming
+        if (mOpsCallback != nullptr) {
+            mAppOpsManager->stopWatchingMode(mOpsCallback);
+            mOpsCallback.clear();
         }
         mCameraStreaming = false;
     }
@@ -4554,15 +4492,6 @@ status_t CameraService::BasicClient::notifyCameraClosing() {
         }
     }
 
-    // When using the data delivery permission checks, the open state does not involve AppOps
-    if (!flags::data_delivery_permission_checks()) {
-        // Always stop watching, even if no camera op is active
-        if (mOpsCallback != nullptr && mAppOpsManager != nullptr) {
-            mAppOpsManager->stopWatchingMode(mOpsCallback);
-        }
-        mOpsCallback.clear();
-    }
-
     sCameraService->mUidPolicy->unregisterMonitorUid(getClientUid(), /*closeCamera*/ true);
 
     if (flags::camera_multi_client() && mSharedMode) {
@@ -4599,30 +4528,19 @@ void CameraService::BasicClient::opChanged(int32_t op, const String16&) {
     }
 
     PermissionChecker::PermissionResult res;
-    if (flags::data_delivery_permission_checks()) {
-        int32_t appOpMode = AppOpsManager::MODE_ALLOWED;
-        std::for_each(AttrSourceItr{mClientAttribution}, AttrSourceItr::end(),
-                [&](const auto& attr) {
-                    appOpMode = std::max(appOpMode, mAppOpsManager->checkOp(
-                            AppOpsManager::OP_CAMERA, attr.uid,
-                            toString16(attr.packageName.value_or(""))));
-                });
-        res = appOpModeToPermissionResult(appOpMode);
-        ALOGV("checkOp returns: %d, %s ", appOpMode,
-              appOpMode == AppOpsManager::MODE_ALLOWED   ? "ALLOWED"
-              : appOpMode == AppOpsManager::MODE_IGNORED ? "IGNORED"
-              : appOpMode == AppOpsManager::MODE_ERRORED ? "ERRORED"
-                                                         : "UNKNOWN");
-    } else {
-        int32_t appOpMode = mAppOpsManager->checkOp(AppOpsManager::OP_CAMERA, getClientUid(),
-                                                    toString16(getPackageName()));
-        res = appOpModeToPermissionResult(appOpMode);
-        ALOGV("checkOp returns: %d, %s ", appOpMode,
-              appOpMode == AppOpsManager::MODE_ALLOWED   ? "ALLOWED"
-              : appOpMode == AppOpsManager::MODE_IGNORED ? "IGNORED"
-              : appOpMode == AppOpsManager::MODE_ERRORED ? "ERRORED"
-                                                         : "UNKNOWN");
-    }
+    int32_t appOpMode = AppOpsManager::MODE_ALLOWED;
+    std::for_each(AttrSourceItr{mClientAttribution}, AttrSourceItr::end(),
+            [&](const auto& attr) {
+                appOpMode = std::max(appOpMode, mAppOpsManager->checkOp(
+                        AppOpsManager::OP_CAMERA, attr.uid,
+                        toString16(attr.packageName.value_or(""))));
+            });
+    res = appOpModeToPermissionResult(appOpMode);
+    ALOGV("checkOp returns: %d, %s ", appOpMode,
+            appOpMode == AppOpsManager::MODE_ALLOWED   ? "ALLOWED"
+            : appOpMode == AppOpsManager::MODE_IGNORED ? "IGNORED"
+            : appOpMode == AppOpsManager::MODE_ERRORED ? "ERRORED"
+                                                        : "UNKNOWN");
 
     if (res == PermissionChecker::PERMISSION_HARD_DENIED) {
         ALOGI("Camera %s: Access for \"%s\" revoked", mCameraIdStr.c_str(),
@@ -4635,18 +4553,15 @@ void CameraService::BasicClient::opChanged(int32_t op, const String16&) {
         // Uid may be active, but not visible to the user (e.g. PROCESS_STATE_FOREGROUND_SERVICE).
         // If not visible, but still active, then we want to block instead of muting the camera.
         int32_t procState = ActivityManager::PROCESS_STATE_NONEXISTENT;
-        if (flags::data_delivery_permission_checks()) {
-            // Use the proc state of the last uid in the chain (ultimately receiving the data)
-            // when determining whether to mute or block
-            int32_t uid = -1;
-            std::for_each(AttrSourceItr{mClientAttribution}, AttrSourceItr::end(),
-                      [&](const auto& attr) {
-                          uid = static_cast<uid_t>(attr.uid);
-                      });
-            procState = getUidProcessState(uid);
-        } else {
-            procState = sCameraService->mUidPolicy->getProcState(getClientUid());
-        }
+
+        // Use the proc state of the last uid in the chain (ultimately receiving the data)
+        // when determining whether to mute or block
+        int32_t uid = -1;
+        std::for_each(AttrSourceItr{mClientAttribution}, AttrSourceItr::end(),
+                    [&](const auto& attr) {
+                        uid = static_cast<uid_t>(attr.uid);
+                    });
+        procState = getUidProcessState(uid);
         bool isUidVisible = (procState <= ActivityManager::PROCESS_STATE_BOUND_TOP);
 
         bool isCameraPrivacyEnabled;
@@ -5619,7 +5534,7 @@ static bool tryLock(Mutex& mutex)
     return locked;
 }
 
-void CameraService::cacheDump() {
+void CameraService::cacheDump(const std::string& cameraId) {
     if (mMemFd != -1) {
         const Vector<String16> args;
         ATRACE_CALL();
@@ -5627,16 +5542,12 @@ void CameraService::cacheDump() {
         // cacheDump will not be called during the second disconnect.
         Mutex::Autolock lock(mServiceLock);
 
-        Mutex::Autolock l(mCameraStatesLock);
-        // Start collecting the info for open sessions and store it in temp file.
-        for (const auto& state : mCameraStates) {
-            std::string cameraId = state.first;
-            auto clientDescriptor = mActiveClientManager.get(cameraId);
-            if (clientDescriptor != nullptr) {
-                dprintf(mMemFd, "== Camera device %s dynamic info: ==\n", cameraId.c_str());
-                // Log the current open session info before device is disconnected.
-                dumpOpenSessionClientLogs(mMemFd, args, cameraId);
-            }
+        // Start collecting the info for calling camera Id and store it in temp file.
+        auto clientDescriptor = mActiveClientManager.get(cameraId);
+        if (clientDescriptor != nullptr) {
+            dprintf(mMemFd, "== Camera device %s dynamic info: ==\n", cameraId.c_str());
+            // Log the current open session info before device is disconnected.
+            dumpOpenSessionClientLogs(mMemFd, args, cameraId);
         }
     }
 }
@@ -5954,8 +5865,13 @@ void CameraService::updateStatus(StatusInternal status, const std::string& camer
                     mappedCameraId = kVirtualDeviceBackCameraId;
                 } else if (androidLensFacing == ANDROID_LENS_FACING_FRONT) {
                     mappedCameraId = kVirtualDeviceFrontCameraId;
+                } else if (vd_flags::external_virtual_cameras() &&
+                           androidLensFacing == ANDROID_LENS_FACING_EXTERNAL) {
+                    // For virtual external cameras we expose to apps the non numerical cameraId
+                    // as generated by the HAL (e.g. "v12_345")
+                    mappedCameraId = cameraId;
                 } else {
-                    ALOGD("%s: Not adding entry for an external camera of a virtual device",
+                    ALOGE("%s: Not adding entry for an unknown camera of a virtual device",
                           __func__);
                 }
                 if (!mappedCameraId.empty()) {
diff --git a/services/camera/libcameraservice/CameraService.h b/services/camera/libcameraservice/CameraService.h
index 55542b71d0..2774a9b6ea 100644
--- a/services/camera/libcameraservice/CameraService.h
+++ b/services/camera/libcameraservice/CameraService.h
@@ -286,7 +286,7 @@ public:
     void                notifyMonitoredUids(const std::unordered_set<uid_t> &notifyUidSet);
 
     // Stores current open session device info in temp file.
-    void cacheDump();
+    void cacheDump(const std::string& cameraId);
 
     // Register an offline client for a given active camera id
     status_t addOfflineClient(const std::string &cameraId, sp<BasicClient> offlineClient);
diff --git a/services/camera/libcameraservice/aidl/AidlCameraDeviceUser.cpp b/services/camera/libcameraservice/aidl/AidlCameraDeviceUser.cpp
index abbab7aa3e..5159558adb 100644
--- a/services/camera/libcameraservice/aidl/AidlCameraDeviceUser.cpp
+++ b/services/camera/libcameraservice/aidl/AidlCameraDeviceUser.cpp
@@ -20,6 +20,7 @@
 #include <aidl/AidlUtils.h>
 #include <aidl/android/frameworks/cameraservice/device/CaptureMetadataInfo.h>
 #include <android-base/properties.h>
+#include <cutils/properties.h>
 #include <utils/Utils.h>
 
 namespace android::frameworks::cameraservice::device::implementation {
@@ -72,7 +73,8 @@ bool AidlCameraDeviceUser::initDevice() {
         return false;
     }
 
-    int32_t resFMQSize = CAMERA_RESULT_METADATA_QUEUE_SIZE;
+    int32_t resFMQSize = property_get_int32(FMQ_SIZE_PROP.c_str(),
+            /*default*/CAMERA_RESULT_METADATA_QUEUE_SIZE);
     mCaptureResultMetadataQueue =
         std::make_shared<CaptureResultMetadataQueue>(static_cast<size_t>(resFMQSize),
                                                      false /* non blocking */);
diff --git a/services/camera/libcameraservice/aidl/AidlUtils.cpp b/services/camera/libcameraservice/aidl/AidlUtils.cpp
index 7f927f1fa8..560175a7c4 100644
--- a/services/camera/libcameraservice/aidl/AidlUtils.cpp
+++ b/services/camera/libcameraservice/aidl/AidlUtils.cpp
@@ -29,6 +29,8 @@
 #include <mediautils/AImageReaderUtils.h>
 #include "utils/Utils.h"
 
+#include "system/window.h"
+
 namespace android::hardware::cameraservice::utils::conversion::aidl {
 
 using aimg::AImageReader_getHGBPFromHandle;
@@ -129,9 +131,45 @@ UOutputConfiguration convertFromAidl(const SOutputConfiguration &src) {
         }
     }
 
+    int format = 0, dataSpace = 0;
+    int width = 0, height = 0;
+    if (!pSurfaces.empty()) {
+        // We need to query these here since vendor clients are forbidden by sepolicy
+        // to talk to some consumer processes such as an app which may be passing a preview
+        // surface to a HAL process which uses the VNDK interface.
+#if WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
+        if (pSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_FORMAT, &format) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_FORMAT query failed", __FUNCTION__);
+        }
+        if (pSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_DEFAULT_DATASPACE,
+                &dataSpace) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_DEFAULT_DATASPACE query failed", __FUNCTION__);
+        }
+        if (pSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_WIDTH, &width) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_WIDTH query failed", __FUNCTION__);
+        }
+        if (pSurfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_HEIGHT, &height) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_HEIGHT query failed", __FUNCTION__);
+        }
+#else
+        if (pSurfaces[0]->query(NATIVE_WINDOW_FORMAT, &format) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_FORMAT query failed", __FUNCTION__);
+        }
+        if (pSurfaces[0]->query(NATIVE_WINDOW_DEFAULT_DATASPACE, &dataSpace) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_DEFAULT_DATASPACE query failed", __FUNCTION__);
+        }
+        if (pSurfaces[0]->query(NATIVE_WINDOW_WIDTH, &width) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_WIDTH query failed", __FUNCTION__);
+        }
+        if (pSurfaces[0]->query(NATIVE_WINDOW_HEIGHT, &height) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_HEIGHT query failed", __FUNCTION__);
+        }
+#endif
+    }
     UOutputConfiguration outputConfiguration(
             pSurfaces, convertFromAidl(src.rotation), src.physicalCameraId, src.windowGroupId,
-            OutputConfiguration::SURFACE_TYPE_UNKNOWN, 0, 0, (pSurfaces.size() > 1));
+            OutputConfiguration::SURFACE_TYPE_UNKNOWN, width, height,
+            (pSurfaces.size() > 1), format, dataSpace);
     return outputConfiguration;
 }
 
diff --git a/services/camera/libcameraservice/aidl/DeathPipe.h b/services/camera/libcameraservice/aidl/DeathPipe.h
index a816dd0fed..409febb7a9 100644
--- a/services/camera/libcameraservice/aidl/DeathPipe.h
+++ b/services/camera/libcameraservice/aidl/DeathPipe.h
@@ -21,6 +21,7 @@
 #include <android/binder_ibinder.h>
 #include <binder/Parcel.h>
 #include <list>
+#include <mutex>
 
 namespace android::frameworks::cameraservice::utils {
 
diff --git a/services/camera/libcameraservice/api1/Camera2Client.cpp b/services/camera/libcameraservice/api1/Camera2Client.cpp
index 836692cbee..675c5efa46 100644
--- a/services/camera/libcameraservice/api1/Camera2Client.cpp
+++ b/services/camera/libcameraservice/api1/Camera2Client.cpp
@@ -138,9 +138,14 @@ status_t Camera2Client::initializeImpl(TProviderPtr providerPtr, const std::stri
     // when the display rotates. The sensor orientation still needs to be calculated
     // and applied similar to the Camera2 path.
     using hardware::BnCameraService::ROTATION_OVERRIDE_ROTATION_ONLY;
+    using hardware::BnCameraService::ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE;
     bool enableTransformInverseDisplay = true;
+    bool rotationOnlyOverride = mRotationOverride == ROTATION_OVERRIDE_ROTATION_ONLY;
+    bool reverseRotationOnlyOverride =
+            wm_flags::enable_camera_compat_check_device_rotation_bugfix() &&
+                    mRotationOverride == ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE;
     if (wm_flags::enable_camera_compat_for_desktop_windowing()) {
-        enableTransformInverseDisplay = (mRotationOverride != ROTATION_OVERRIDE_ROTATION_ONLY);
+        enableTransformInverseDisplay = !rotationOnlyOverride && !reverseRotationOnlyOverride;
     }
     CameraUtils::getRotationTransform(staticInfo, OutputConfiguration::MIRROR_MODE_AUTO,
             enableTransformInverseDisplay, &mRotateAndCropPreviewTransform);
@@ -507,15 +512,13 @@ binder::Status Camera2Client::disconnect() {
     bool hasDeviceError = mDevice->hasDeviceError();
     mDevice->disconnect();
 
-    if (flags::api1_release_binderlock_before_cameraservice_disconnect()) {
+    {
         // CameraService::Client::disconnect calls CameraService which attempts to lock
         // CameraService's mServiceLock. This might lead to a deadlock if the cameraservice is
         // currently waiting to lock mSerializationLock on another thread.
         mBinderSerializationLock.unlock();
         CameraService::Client::disconnect();
         mBinderSerializationLock.lock();
-    } else {
-        CameraService::Client::disconnect();
     }
 
     int32_t closeLatencyMs = ns2ms(systemTime() - startTime);
@@ -628,11 +631,14 @@ status_t Camera2Client::setPreviewWindowL(const view::Surface& viewSurface,
     ATRACE_CALL();
     status_t res;
 
-    uint64_t viewSurfaceID;
-    res = viewSurface.getUniqueId(&viewSurfaceID);
-    if (res != OK) {
-        ALOGE("%s: Camera %d: Could not getUniqueId.", __FUNCTION__, mCameraId);
-        return res;
+    // We will get empty view surfaces here when the client wants to clear it.
+    uint64_t viewSurfaceID = 0;
+    if (!viewSurface.isEmpty()) {
+        res = viewSurface.getUniqueId(&viewSurfaceID);
+        if (res != OK) {
+            ALOGE("%s: Camera %d: Could not getUniqueId.", __FUNCTION__, mCameraId);
+            return res;
+        }
     }
 
     if (viewSurfaceID == mPreviewViewSurfaceID) {
diff --git a/services/camera/libcameraservice/api1/client2/ZslProcessor.cpp b/services/camera/libcameraservice/api1/client2/ZslProcessor.cpp
index 0f1d0ffd6c..a92bae1a3a 100644
--- a/services/camera/libcameraservice/api1/client2/ZslProcessor.cpp
+++ b/services/camera/libcameraservice/api1/client2/ZslProcessor.cpp
@@ -142,12 +142,7 @@ ZslProcessor::ZslProcessor(
         mHasFocuser(false),
         mInputBuffer(nullptr),
         mProducer(nullptr),
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
         mInputSurface(nullptr),
-#else
-        mInputProducer(nullptr),
-        mInputProducerSlot(-1),
-#endif
         mBuffersToDetach(0) {
     // Initialize buffer queue and frame list based on pipeline max depth.
     size_t pipelineMaxDepth = kDefaultMaxPipelineDepth;
@@ -255,19 +250,9 @@ status_t ZslProcessor::updateStream(const Parameters &params) {
     if (mZslStreamId == NO_STREAM) {
         // Create stream for HAL production
         // TODO: Sort out better way to select resolution for ZSL
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
         mProducer = new RingBufferConsumer(GRALLOC_USAGE_HW_CAMERA_ZSL, mBufferQueueDepth);
         mProducer->setName("Camera2-ZslRingBufferConsumer");
         sp<Surface> outSurface = mProducer->getSurface();
-#else
-        sp<IGraphicBufferProducer> producer;
-        sp<IGraphicBufferConsumer> consumer;
-        BufferQueue::createBufferQueue(&producer, &consumer);
-        mProducer = new RingBufferConsumer(consumer, GRALLOC_USAGE_HW_CAMERA_ZSL,
-            mBufferQueueDepth);
-        mProducer->setName("Camera2-ZslRingBufferConsumer");
-        sp<Surface> outSurface = new Surface(producer);
-#endif  // COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
 
         res = device->createStream(outSurface, params.fastInfo.usedZslSize.width,
             params.fastInfo.usedZslSize.height, HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED,
@@ -335,17 +320,10 @@ status_t ZslProcessor::deleteStream() {
         mInputStreamId = NO_STREAM;
     }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     if (nullptr != mInputSurface.get()) {
         // The surface destructor calls disconnect
         mInputSurface.clear();
     }
-#else
-    if (nullptr != mInputProducer.get()) {
-        mInputProducer->disconnect(NATIVE_WINDOW_API_CPU);
-        mInputProducer.clear();
-    }
-#endif
 
     return OK;
 }
@@ -404,19 +382,11 @@ void ZslProcessor::notifyInputReleased() {
 
 void ZslProcessor::doNotifyInputReleasedLocked() {
     assert(nullptr != mInputBuffer.get());
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     assert(nullptr != mInputSurface.get());
-#else
-    assert(nullptr != mInputProducer.get());
-#endif
 
     sp<GraphicBuffer> gb;
     sp<Fence> fence;
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     auto rc = mInputSurface->detachNextBuffer(&gb, &fence);
-#else
-    auto rc = mInputProducer->detachNextBuffer(&gb, &fence);
-#endif
     if (NO_ERROR != rc) {
         ALOGE("%s: Failed to detach buffer from input producer: %d",
             __FUNCTION__, rc);
@@ -475,15 +445,9 @@ status_t ZslProcessor::pushToReprocess(int32_t requestId) {
             __FUNCTION__, (unsigned int) metadataIdx);
     }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     if (nullptr == mInputSurface.get()) {
         res = client->getCameraDevice()->getInputSurface(
             &mInputSurface);
-#else
-    if (nullptr == mInputProducer.get()) {
-        res = client->getCameraDevice()->getInputBufferProducer(
-            &mInputProducer);
-#endif
         if (res != OK) {
             ALOGE("%s: Camera %d: Unable to retrieve input producer: "
                     "%s (%d)", __FUNCTION__, client->getCameraId(),
@@ -491,14 +455,8 @@ status_t ZslProcessor::pushToReprocess(int32_t requestId) {
             return res;
         }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
         res = mInputSurface->connect(NATIVE_WINDOW_API_CPU, new InputProducerListener(this),
             false);
-#else
-        IGraphicBufferProducer::QueueBufferOutput output;
-        res = mInputProducer->connect(new InputProducerListener(this),
-            NATIVE_WINDOW_API_CPU, false, &output);
-#endif
         if (res != OK) {
             ALOGE("%s: Camera %d: Unable to connect to input producer: "
                     "%s (%d)", __FUNCTION__, client->getCameraId(),
@@ -659,32 +617,19 @@ status_t ZslProcessor::enqueueInputBufferByTimestamp(
     }
 
     BufferItem &item = mInputBuffer->getBufferItem();
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     auto rc = mInputSurface->attachBuffer(item.mGraphicBuffer->getNativeBuffer());
-#else
-    auto rc = mInputProducer->attachBuffer(&mInputProducerSlot,
-        item.mGraphicBuffer);
-#endif
     if (OK != rc) {
         ALOGE("%s: Failed to attach input ZSL buffer to producer: %d",
             __FUNCTION__, rc);
         return rc;
     }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     mInputSurface->setBuffersTimestamp(item.mTimestamp);
     mInputSurface->setBuffersDataSpace(static_cast<ui::Dataspace>(item.mDataSpace));
     mInputSurface->setCrop(&item.mCrop);
     mInputSurface->setScalingMode(item.mScalingMode);
     mInputSurface->setBuffersTransform(item.mTransform);
     rc = mInputSurface->queueBuffer(item.mGraphicBuffer, item.mFence);
-#else
-    IGraphicBufferProducer::QueueBufferOutput output;
-    IGraphicBufferProducer::QueueBufferInput input(item.mTimestamp,
-            item.mIsAutoTimestamp, item.mDataSpace, item.mCrop,
-            item.mScalingMode, item.mTransform, item.mFence);
-    rc = mInputProducer->queueBuffer(mInputProducerSlot, input, &output);
-#endif
     if (OK != rc) {
         ALOGE("%s: Failed to queue ZSL buffer to producer: %d",
             __FUNCTION__, rc);
diff --git a/services/camera/libcameraservice/api1/client2/ZslProcessor.h b/services/camera/libcameraservice/api1/client2/ZslProcessor.h
index a98160a414..4cad43bfa3 100644
--- a/services/camera/libcameraservice/api1/client2/ZslProcessor.h
+++ b/services/camera/libcameraservice/api1/client2/ZslProcessor.h
@@ -84,7 +84,6 @@ class ZslProcessor :
 
   private:
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     class InputProducerListener : public SurfaceListener {
     public:
         InputProducerListener(wp<ZslProcessor> parent) : mParent(parent) {}
@@ -97,17 +96,6 @@ class ZslProcessor :
     private:
         wp<ZslProcessor> mParent;
     };
-#else
-    class InputProducerListener : public BnProducerListener {
-    public:
-        InputProducerListener(wp<ZslProcessor> parent) : mParent(parent) {}
-        virtual void onBufferReleased();
-        virtual bool needsReleaseNotify() { return true; }
-
-    private:
-        wp<ZslProcessor> mParent;
-    };
-#endif
 
     static const nsecs_t kWaitDuration = 10000000; // 10 ms
     nsecs_t mLatestClearedBufferTimestamp;
@@ -156,12 +144,7 @@ class ZslProcessor :
     sp<RingBufferConsumer::PinnedBufferItem> mInputBuffer;
     sp<RingBufferConsumer>                   mProducer;
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     sp<Surface>                              mInputSurface;
-#else
-    sp<IGraphicBufferProducer>               mInputProducer;
-    int                                      mInputProducerSlot;
-#endif
 
     Condition                                mBuffersToDetachSignal;
     int                                      mBuffersToDetach;
diff --git a/services/camera/libcameraservice/api2/CameraDeviceClient.cpp b/services/camera/libcameraservice/api2/CameraDeviceClient.cpp
index 97ec11a4e6..917e4bac40 100644
--- a/services/camera/libcameraservice/api2/CameraDeviceClient.cpp
+++ b/services/camera/libcameraservice/api2/CameraDeviceClient.cpp
@@ -43,6 +43,7 @@
 #include "DepthCompositeStream.h"
 #include "HeicCompositeStream.h"
 #include "JpegRCompositeStream.h"
+#include "utils/Utils.h"
 
 // Convenience methods for constructing binder::Status objects for error returns
 constexpr int32_t METADATA_QUEUE_SIZE = 1 << 20;
@@ -201,7 +202,7 @@ status_t CameraDeviceClient::initializeImpl(TProviderPtr providerPtr,
     }
     size_t fmqHalSize = mDevice->getCaptureResultFMQSize();
     size_t resultMQSize =
-            property_get_int32("ro.camera.resultFmqSize", /*default*/0);
+            property_get_int32(FMQ_SIZE_PROP.c_str(), /*default*/0);
     resultMQSize = resultMQSize > 0 ? resultMQSize : fmqHalSize;
     res = CreateMetadataQueue(&mResultMetadataQueue, resultMQSize);
     if (res != OK) {
@@ -1159,7 +1160,7 @@ binder::Status CameraDeviceClient::createStream(
         int mirrorMode = outputConfiguration.getMirrorMode(surface);
         sp<Surface> outSurface;
         res = SessionConfigurationUtils::createConfiguredSurface(streamInfo,
-                isStreamInfoValid, outSurface,
+                isStreamInfoValid, outputConfiguration, outSurface,
                 flagtools::convertParcelableSurfaceTypeToSurface(surface), mCameraIdStr,
                 mDevice->infoPhysical(physicalCameraId), sensorPixelModesUsed, dynamicRangeProfile,
                 streamUseCase, timestampBase, mirrorMode, colorSpace, /*respectSurfaceSize*/false);
@@ -1429,7 +1430,6 @@ binder::Status CameraDeviceClient::getInputSurface(/*out*/ view::Surface *inputS
     if (!mDevice.get()) {
         return STATUS_ERROR(CameraService::ERROR_DISCONNECTED, "Camera device no longer alive");
     }
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     sp<Surface> surface;
     status_t err = mDevice->getInputSurface(&surface);
     if (err != OK) {
@@ -1440,18 +1440,6 @@ binder::Status CameraDeviceClient::getInputSurface(/*out*/ view::Surface *inputS
         inputSurface->name = toString16("CameraInput");
         inputSurface->graphicBufferProducer = surface->getIGraphicBufferProducer();
     }
-#else
-    sp<IGraphicBufferProducer> producer;
-    status_t err = mDevice->getInputBufferProducer(&producer);
-    if (err != OK) {
-        res = STATUS_ERROR_FMT(CameraService::ERROR_INVALID_OPERATION,
-                "Camera %s: Error getting input Surface: %s (%d)",
-                mCameraIdStr.c_str(), strerror(-err), err);
-    } else {
-        inputSurface->name = toString16("CameraInput");
-        inputSurface->graphicBufferProducer = producer;
-    }
-#endif
     return res;
 }
 
@@ -1548,8 +1536,7 @@ binder::Status CameraDeviceClient::updateOutputConfiguration(int streamId,
         sp<Surface> outSurface;
         int mirrorMode = outputConfiguration.getMirrorMode(newOutputsMap.valueAt(i));
         res = SessionConfigurationUtils::createConfiguredSurface(
-                outInfo,
-                /*isStreamInfoValid*/ false, outSurface,
+                outInfo, /*isStreamInfoValid*/ false, outputConfiguration, outSurface,
                 flagtools::convertParcelableSurfaceTypeToSurface(newOutputsMap.valueAt(i)),
                 mCameraIdStr, mDevice->infoPhysical(physicalCameraId), sensorPixelModesUsed,
                 dynamicRangeProfile, streamUseCase, timestampBase, mirrorMode, colorSpace,
@@ -1952,10 +1939,11 @@ binder::Status CameraDeviceClient::finalizeOutputConfigurations(int32_t streamId
         sp<Surface> outSurface;
         int mirrorMode = outputConfiguration.getMirrorMode(surface);
         res = SessionConfigurationUtils::createConfiguredSurface(
-                mStreamInfoMap[streamId], true /*isStreamInfoValid*/, outSurface,
-                flagtools::convertParcelableSurfaceTypeToSurface(surface), mCameraIdStr,
-                mDevice->infoPhysical(physicalId), sensorPixelModesUsed, dynamicRangeProfile,
-                streamUseCase, timestampBase, mirrorMode, colorSpace, /*respectSurfaceSize*/ false);
+                mStreamInfoMap[streamId], true /*isStreamInfoValid*/, outputConfiguration,
+                outSurface, flagtools::convertParcelableSurfaceTypeToSurface(surface),
+                mCameraIdStr, mDevice->infoPhysical(physicalId), sensorPixelModesUsed,
+                dynamicRangeProfile, streamUseCase, timestampBase, mirrorMode,
+                colorSpace, /*respectSurfaceSize*/ false);
 
         if (!res.isOk()) return res;
 
@@ -2563,7 +2551,9 @@ size_t CameraDeviceClient::writeResultMetadataIntoResultQueue(
         return resultSize;
     }
     resultMetadata.unlock(resultMetadataP);
-    ALOGE(" %s couldn't write metadata into result queue ", __FUNCTION__);
+    ALOGE(" %s couldn't write metadata into result queue, result size %zu, "
+        "fmq availableToWrite %zu ", __FUNCTION__, resultSize,
+        mResultMetadataQueue->availableToWrite());
     return 0;
 }
 
diff --git a/services/camera/libcameraservice/api2/CompositeStream.cpp b/services/camera/libcameraservice/api2/CompositeStream.cpp
index 6d7fabd83d..6238b97de6 100644
--- a/services/camera/libcameraservice/api2/CompositeStream.cpp
+++ b/services/camera/libcameraservice/api2/CompositeStream.cpp
@@ -224,5 +224,27 @@ void CompositeStream::switchToOffline() {
     mDevice.clear();
 }
 
+status_t CompositeStream::setSWUsage(int streamId, ANativeWindow * anw) {
+    if (anw == nullptr) {
+        return BAD_VALUE;
+    }
+
+    status_t res;
+    uint64_t usage;
+    if ((res = native_window_get_consumer_usage(static_cast<ANativeWindow*>(anw),
+                    &usage)) != OK ) {
+        ALOGE("%s: Unable to query stream buffer usage for stream %d", __FUNCTION__, streamId);
+        return res;
+    }
+
+    usage |= GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN;
+    if ((res = native_window_set_usage(anw, usage)) != OK) {
+        ALOGE("%s: Unable to configure stream buffer usage for stream %d", __FUNCTION__, streamId);
+        return res;
+    }
+
+    return OK;
+}
+
 }; // namespace camera3
 }; // namespace android
diff --git a/services/camera/libcameraservice/api2/CompositeStream.h b/services/camera/libcameraservice/api2/CompositeStream.h
index 2b158c932c..490f0cd478 100644
--- a/services/camera/libcameraservice/api2/CompositeStream.h
+++ b/services/camera/libcameraservice/api2/CompositeStream.h
@@ -125,6 +125,8 @@ protected:
     // Composite streams should behave accordingly.
     void enableErrorState();
 
+    static status_t setSWUsage(int streamId, ANativeWindow *anw);
+
     wp<CameraDeviceBase>   mDevice;
     wp<camera3::StatusTracker> mStatusTracker;
     wp<hardware::camera2::ICameraDeviceCallbacks> mRemoteCallback;
diff --git a/services/camera/libcameraservice/api2/DepthCompositeStream.cpp b/services/camera/libcameraservice/api2/DepthCompositeStream.cpp
index 4b732bc6b9..f27ead97ab 100644
--- a/services/camera/libcameraservice/api2/DepthCompositeStream.cpp
+++ b/services/camera/libcameraservice/api2/DepthCompositeStream.cpp
@@ -720,6 +720,11 @@ status_t DepthCompositeStream::configureStream() {
         return res;
     }
 
+    if ((res = setSWUsage(mBlobStreamId, anwConsumer)) != OK ) {
+        return res;
+    }
+
+
     if ((res = native_window_set_buffer_count(
                     anwConsumer, maxProducerBuffers + maxConsumerBuffers)) != OK) {
         ALOGE("%s: Unable to set buffer count for stream %d", __FUNCTION__, mBlobStreamId);
diff --git a/services/camera/libcameraservice/api2/HeicCompositeStream.cpp b/services/camera/libcameraservice/api2/HeicCompositeStream.cpp
index f9b6d5b7de..8637949af7 100644
--- a/services/camera/libcameraservice/api2/HeicCompositeStream.cpp
+++ b/services/camera/libcameraservice/api2/HeicCompositeStream.cpp
@@ -184,6 +184,8 @@ status_t HeicCompositeStream::createInternalStreams(const std::vector<SurfaceHol
     if ((dataspace == static_cast<int>(kUltraHDRDataSpace)) && flags::camera_heif_gainmap()) {
         mHDRGainmapEnabled = true;
         mInternalDataSpace = static_cast<android_dataspace_t>(HAL_DATASPACE_BT2020_HLG);
+        // APP segment and P010 streams may not be supported on all devices
+        mAppSegmentSupported = false;
     }
 
     res = initializeCodec(width, height, device);
@@ -685,6 +687,11 @@ status_t HeicCompositeStream::configureStream() {
         return res;
     }
 
+    if ((res = setSWUsage(mMainImageStreamId, anwConsumer)) != OK ) {
+        return res;
+    }
+
+
     // Cannot use SourceSurface buffer count since it could be codec's 512*512 tile
     // buffer count.
     if ((res = native_window_set_buffer_count(
diff --git a/services/camera/libcameraservice/common/Camera2ClientBase.cpp b/services/camera/libcameraservice/common/Camera2ClientBase.cpp
index 83fa5872de..68b0ab7f85 100644
--- a/services/camera/libcameraservice/common/Camera2ClientBase.cpp
+++ b/services/camera/libcameraservice/common/Camera2ClientBase.cpp
@@ -293,7 +293,7 @@ binder::Status Camera2ClientBase<TClientBase>::disconnectImpl() {
     // deadlock while acquiring service lock in cacheDump.
     if (!TClientBase::mDisconnected) {
         ALOGD("Camera %s: start to cacheDump", TClientBase::mCameraIdStr.c_str());
-        Camera2ClientBase::getCameraService()->cacheDump();
+        Camera2ClientBase::getCameraService()->cacheDump(TClientBase::mCameraIdStr);
     }
 
     detachDevice();
@@ -375,13 +375,22 @@ void Camera2ClientBase<TClientBase>::notifyPhysicalCameraChange(const std::strin
         int orientation = orientationEntry.data.i32[0];
         int rotateAndCropMode = ANDROID_SCALER_ROTATE_AND_CROP_NONE;
         bool landscapeSensor =  (orientation == 0 || orientation == 180);
-        if (((TClientBase::mRotationOverride ==
-                ICameraService::ROTATION_OVERRIDE_OVERRIDE_TO_PORTRAIT) && landscapeSensor) ||
-                        ((wm_flags::enable_camera_compat_for_desktop_windowing() &&
-                                TClientBase::mRotationOverride ==
-                                ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY)
-                                && !landscapeSensor)) {
+        bool rotationAndSensorOverride = TClientBase::mRotationOverride ==
+                ICameraService::ROTATION_OVERRIDE_OVERRIDE_TO_PORTRAIT;
+        bool rotationOnlyOverride = TClientBase::mRotationOverride ==
+                ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY;
+        bool reverseRotationOnlyOverride =
+                wm_flags::enable_camera_compat_check_device_rotation_bugfix() &&
+                        TClientBase::mRotationOverride ==
+                        ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE;
+        if ((rotationAndSensorOverride && landscapeSensor) ||
+                (wm_flags::enable_camera_compat_for_desktop_windowing() && rotationOnlyOverride &&
+                        !landscapeSensor)) {
             rotateAndCropMode = ANDROID_SCALER_ROTATE_AND_CROP_90;
+        } else if (wm_flags::enable_camera_compat_for_desktop_windowing()
+                && !landscapeSensor
+                && reverseRotationOnlyOverride) {
+            rotateAndCropMode = ANDROID_SCALER_ROTATE_AND_CROP_270;
         }
 
         static_cast<TClientBase *>(this)->setRotateAndCropOverride(rotateAndCropMode,
diff --git a/services/camera/libcameraservice/common/CameraDeviceBase.h b/services/camera/libcameraservice/common/CameraDeviceBase.h
index 68e783bb5a..497c2ebb65 100644
--- a/services/camera/libcameraservice/common/CameraDeviceBase.h
+++ b/services/camera/libcameraservice/common/CameraDeviceBase.h
@@ -30,9 +30,6 @@
 #include "hardware/camera2.h"
 #include "camera/CameraMetadata.h"
 #include "camera/CaptureResult.h"
-#if not WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
-#include "gui/IGraphicBufferProducer.h"
-#endif
 #include "device3/Camera3StreamInterface.h"
 #include "device3/StatusTracker.h"
 #include "binder/Status.h"
@@ -78,6 +75,13 @@ class CameraProviderManager;
 // Mapping of output stream index to surface ids
 typedef std::unordered_map<int, std::vector<size_t> > SurfaceMap;
 
+typedef struct TransformMapValue {
+    int mirrorMode;
+    int32_t transform;
+} TransfromMapValue_t;
+// Mapping of output stream index to mirror mode and transformation entry
+typedef std::unordered_map<int, TransformMapValue> TransformationMap;
+
 /**
  * Base interface for version >= 2 camera device classes, which interface to
  * camera HAL device versions >= 2.
@@ -361,6 +365,9 @@ class CameraDeviceBase : public virtual FrameProducer {
     virtual status_t startStreaming(const int32_t reqId, const SurfaceMap &surfaceMap,
             int32_t *sharedReqID, int64_t *lastFrameNumber = NULL) = 0;
 
+    /**
+     * Get the HAL's CaptureResult FMQ Size.
+     */
     virtual int32_t getCaptureResultFMQSize() = 0;
 
     /**
@@ -383,14 +390,8 @@ class CameraDeviceBase : public virtual FrameProducer {
      */
     virtual void getOfflineStreamIds(std::vector<int> *offlineStreamIds) = 0;
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     // get the surface of the input stream
     virtual status_t getInputSurface(sp<Surface> *surface) = 0;
-#else
-    // get the buffer producer of the input stream
-    virtual status_t getInputBufferProducer(
-            sp<IGraphicBufferProducer> *producer) = 0;
-#endif
 
     /**
      * Create a metadata buffer with fields that the HAL device believes are
diff --git a/services/camera/libcameraservice/common/CameraProviderManager.cpp b/services/camera/libcameraservice/common/CameraProviderManager.cpp
index 536f56a3fd..a15ee4f3a5 100644
--- a/services/camera/libcameraservice/common/CameraProviderManager.cpp
+++ b/services/camera/libcameraservice/common/CameraProviderManager.cpp
@@ -3165,8 +3165,14 @@ status_t CameraProviderManager::ProviderInfo::DeviceInfo3::getCameraInfo(
         return NAME_NOT_FOUND;
     }
 
-    if (rotationOverride == hardware::ICameraService::ROTATION_OVERRIDE_OVERRIDE_TO_PORTRAIT
-            && (info->orientation == 0 || info->orientation == 180)) {
+    bool rotationAndSensorOverride = rotationOverride ==
+            hardware::ICameraService::ROTATION_OVERRIDE_OVERRIDE_TO_PORTRAIT;
+    bool rotationOnlyOverride = rotationOverride ==
+            hardware::ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY;
+    bool reverseRotationOnlyOverride =
+            wm_flags::enable_camera_compat_check_device_rotation_bugfix() && rotationOverride ==
+                    hardware::ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE;
+    if (rotationAndSensorOverride && (info->orientation == 0 || info->orientation == 180)) {
         *portraitRotation = 90;
         if (info->facing == hardware::CAMERA_FACING_FRONT) {
             info->orientation = (360 + info->orientation - 90) % 360;
@@ -3174,9 +3180,15 @@ status_t CameraProviderManager::ProviderInfo::DeviceInfo3::getCameraInfo(
             info->orientation = (360 + info->orientation + 90) % 360;
         }
     } else if (freeform_compat_enabled &&
-            rotationOverride == hardware::ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY
-            && (info->orientation == 90 || info->orientation == 270)) {
-        *portraitRotation = info->facing == hardware::CAMERA_FACING_BACK ? 90 : 270;
+            (rotationOnlyOverride || reverseRotationOnlyOverride) &&
+                    (info->orientation == 90 || info->orientation == 270)) {
+        // Check device rotation: display rotation will be sandboxed, therefore rotate-and-crop
+        // needs to take display rotation into account.
+        if (rotationOnlyOverride) {
+            *portraitRotation = info->facing == hardware::CAMERA_FACING_BACK ? 90 : 270;
+        } else {
+            *portraitRotation = info->facing == hardware::CAMERA_FACING_BACK ? 270 : 90;
+        }
     } else {
         *portraitRotation = 0;
     }
diff --git a/services/camera/libcameraservice/common/aidl/AidlProviderInfo.cpp b/services/camera/libcameraservice/common/aidl/AidlProviderInfo.cpp
index b9e8cddf5a..024d94caec 100644
--- a/services/camera/libcameraservice/common/aidl/AidlProviderInfo.cpp
+++ b/services/camera/libcameraservice/common/aidl/AidlProviderInfo.cpp
@@ -497,20 +497,17 @@ AidlProviderInfo::AidlDeviceInfo3::AidlDeviceInfo3(
     int resV = validate_camera_metadata_structure(buffer, &expectedSize);
     if (resV == OK || resV == CAMERA_METADATA_VALIDATION_SHIFTED) {
         set_camera_metadata_vendor_id(buffer, mProviderTagid);
-        if (flags::metadata_resize_fix()) {
-            //b/379388099: Create a CameraCharacteristics object slightly larger
-            //to accommodate framework addition/modification. This is to
-            //optimize memory because the CameraMetadata::update() doubles the
-            //memory footprint, which could be significant if original
-            //CameraCharacteristics is already large.
-            mCameraCharacteristics = {
-                    get_camera_metadata_entry_count(buffer) + CHARACTERISTICS_EXTRA_ENTRIES,
-                    get_camera_metadata_data_count(buffer) + CHARACTERISTICS_EXTRA_DATA_SIZE
-            };
-            mCameraCharacteristics.append(buffer);
-        } else {
-            mCameraCharacteristics = buffer;
-        }
+
+        //b/379388099: Create a CameraCharacteristics object slightly larger
+        //to accommodate framework addition/modification. This is to
+        //optimize memory because the CameraMetadata::update() doubles the
+        //memory footprint, which could be significant if original
+        //CameraCharacteristics is already large.
+        mCameraCharacteristics = {
+                get_camera_metadata_entry_count(buffer) + CHARACTERISTICS_EXTRA_ENTRIES,
+                get_camera_metadata_data_count(buffer) + CHARACTERISTICS_EXTRA_DATA_SIZE
+        };
+        mCameraCharacteristics.append(buffer);
     } else {
         ALOGE("%s: Malformed camera metadata received from HAL", __FUNCTION__);
         return;
@@ -716,20 +713,17 @@ AidlProviderInfo::AidlDeviceInfo3::AidlDeviceInfo3(
             int res = validate_camera_metadata_structure(pBuffer, &expectedSize);
             if (res == OK || res == CAMERA_METADATA_VALIDATION_SHIFTED) {
                 set_camera_metadata_vendor_id(pBuffer, mProviderTagid);
-                if (flags::metadata_resize_fix()) {
-                    //b/379388099: Create a CameraCharacteristics object slightly larger
-                    //to accommodate framework addition/modification. This is to
-                    //optimize memory because the CameraMetadata::update() doubles the
-                    //memory footprint, which could be significant if original
-                    //CameraCharacteristics is already large.
-                    mPhysicalCameraCharacteristics[id] = {
-                          get_camera_metadata_entry_count(pBuffer) + CHARACTERISTICS_EXTRA_ENTRIES,
-                          get_camera_metadata_data_count(pBuffer) + CHARACTERISTICS_EXTRA_DATA_SIZE
-                    };
-                    mPhysicalCameraCharacteristics[id].append(pBuffer);
-                } else {
-                    mPhysicalCameraCharacteristics[id] = pBuffer;
-                }
+
+                //b/379388099: Create a CameraCharacteristics object slightly larger
+                //to accommodate framework addition/modification. This is to
+                //optimize memory because the CameraMetadata::update() doubles the
+                //memory footprint, which could be significant if original
+                //CameraCharacteristics is already large.
+                mPhysicalCameraCharacteristics[id] = {
+                      get_camera_metadata_entry_count(pBuffer) + CHARACTERISTICS_EXTRA_ENTRIES,
+                      get_camera_metadata_data_count(pBuffer) + CHARACTERISTICS_EXTRA_DATA_SIZE
+                };
+                mPhysicalCameraCharacteristics[id].append(pBuffer);
             } else {
                 ALOGE("%s: Malformed camera metadata received from HAL", __FUNCTION__);
                 return;
diff --git a/services/camera/libcameraservice/device3/Camera3BufferManager.cpp b/services/camera/libcameraservice/device3/Camera3BufferManager.cpp
index 65fee7d198..f2bb3d6065 100644
--- a/services/camera/libcameraservice/device3/Camera3BufferManager.cpp
+++ b/services/camera/libcameraservice/device3/Camera3BufferManager.cpp
@@ -225,28 +225,30 @@ status_t Camera3BufferManager::checkAndFreeBufferOnOtherStreamsLocked(
         // Need to unlock because the stream may also be calling
         // into the buffer manager in parallel to signal buffer
         // release, or acquire a new buffer.
-        bool bufferFreed = false;
+        //
+        // Because mLock is released before calling detachBuffer, to avoid
+        // race condition with other threads, decrease attachedBufferCount
+        // first, and if the detached buffer is null, recover
+        // attachedBufferCount.
+        size_t& otherAttachedBufferCount =
+                streamSet.attachedBufferCountMap.editValueFor(firstOtherStreamId);
         {
+            otherAttachedBufferCount--;
             mLock.unlock();
             sp<GraphicBuffer> buffer;
             stream->detachBuffer(&buffer, /*fenceFd*/ nullptr);
             mLock.lock();
-            if (buffer.get() != nullptr) {
-                bufferFreed = true;
+            if (buffer.get() == nullptr) {
+                otherAttachedBufferCount++;
             }
         }
-        if (bufferFreed) {
-            size_t& otherAttachedBufferCount =
-                    streamSet.attachedBufferCountMap.editValueFor(firstOtherStreamId);
-            otherAttachedBufferCount--;
-        }
     }
 
     return OK;
 }
 
 status_t Camera3BufferManager::getBufferForStream(int streamId, int streamSetId,
-        bool isMultiRes, sp<GraphicBuffer>* gb, int* fenceFd, bool noFreeBufferAtConsumer) {
+        bool isMultiRes, sp<GraphicBuffer>* gb, int* fenceFd) {
     ATRACE_CALL();
 
     Mutex::Autolock l(mLock);
@@ -263,12 +265,6 @@ status_t Camera3BufferManager::getBufferForStream(int streamId, int streamSetId,
     StreamSet &streamSet = mStreamSetMap.editValueFor(streamSetKey);
     BufferCountMap& handOutBufferCounts = streamSet.handoutBufferCountMap;
     size_t& bufferCount = handOutBufferCounts.editValueFor(streamId);
-    BufferCountMap& attachedBufferCounts = streamSet.attachedBufferCountMap;
-    size_t& attachedBufferCount = attachedBufferCounts.editValueFor(streamId);
-
-    if (noFreeBufferAtConsumer) {
-        attachedBufferCount = bufferCount;
-    }
 
     if (bufferCount >= streamSet.maxAllowedBufferCount) {
         ALOGE("%s: bufferCount (%zu) exceeds the max allowed buffer count (%zu) of this stream set",
@@ -276,6 +272,8 @@ status_t Camera3BufferManager::getBufferForStream(int streamId, int streamSetId,
         return INVALID_OPERATION;
     }
 
+    BufferCountMap& attachedBufferCounts = streamSet.attachedBufferCountMap;
+    size_t& attachedBufferCount = attachedBufferCounts.editValueFor(streamId);
     if (attachedBufferCount > bufferCount) {
         // We've already attached more buffers to this stream than we currently have
         // outstanding, so have the stream just use an already-attached buffer
@@ -367,6 +365,11 @@ status_t Camera3BufferManager::onBufferReleased(
         StreamSet& streamSet = mStreamSetMap.editValueFor(streamSetKey);
         BufferCountMap& handOutBufferCounts = streamSet.handoutBufferCountMap;
         size_t& bufferCount = handOutBufferCounts.editValueFor(streamId);
+        if (bufferCount == 0) {
+            ALOGE("%s: onBufferReleased called with handoutBufferCount already reaches 0!",
+                  __FUNCTION__);
+            return BAD_VALUE;
+        }
         bufferCount--;
         ALOGV("%s: Stream %d set %d(%d): Buffer count now %zu", __FUNCTION__, streamId,
                 streamSetId, isMultiRes, bufferCount);
@@ -410,7 +413,7 @@ status_t Camera3BufferManager::onBufferReleased(
 }
 
 status_t Camera3BufferManager::onBuffersRemoved(int streamId, int streamSetId,
-        bool isMultiRes, size_t count) {
+        bool isMultiRes, size_t count, bool released) {
     ATRACE_CALL();
     Mutex::Autolock l(mLock);
 
@@ -430,18 +433,20 @@ status_t Camera3BufferManager::onBuffersRemoved(int streamId, int streamSetId,
         BufferCountMap& attachedBufferCounts = streamSet.attachedBufferCountMap;
         size_t& totalAttachedCount = attachedBufferCounts.editValueFor(streamId);
 
-        if (count > totalHandoutCount) {
-            ALOGE("%s: Removed buffer count %zu greater than current handout count %zu",
-                    __FUNCTION__, count, totalHandoutCount);
-            return BAD_VALUE;
-        }
         if (count > totalAttachedCount) {
             ALOGE("%s: Removed buffer count %zu greater than current attached count %zu",
                   __FUNCTION__, count, totalAttachedCount);
             return BAD_VALUE;
         }
 
-        totalHandoutCount -= count;
+        if (!released) {
+            if (count > totalHandoutCount) {
+                ALOGE("%s: Removed buffer count %zu greater than current handout count %zu",
+                        __FUNCTION__, count, totalHandoutCount);
+                return BAD_VALUE;
+            }
+            totalHandoutCount -= count;
+        }
         totalAttachedCount -= count;
         ALOGV("%s: Stream %d set %d(%d): Buffer count now %zu, attached buffer count now %zu",
                 __FUNCTION__, streamId, streamSetId, isMultiRes, totalHandoutCount,
diff --git a/services/camera/libcameraservice/device3/Camera3BufferManager.h b/services/camera/libcameraservice/device3/Camera3BufferManager.h
index 27fcf96c05..19a2dabc51 100644
--- a/services/camera/libcameraservice/device3/Camera3BufferManager.h
+++ b/services/camera/libcameraservice/device3/Camera3BufferManager.h
@@ -65,10 +65,10 @@ public:
      * over the buffer allocation role and provides buffers to this stream via getBufferForStream().
      * The returned buffer can be sent to the camera HAL for image output, and then queued to the
      * ANativeWindow (Surface) for downstream consumer to acquire. Once the image buffer is released
-     * by the consumer end point, the BufferQueueProducer callback onBufferReleased will call
-     * returnBufferForStream() to return the free buffer to this buffer manager. If the stream
-     * uses buffer manager to manage the stream buffers, it should disable the BufferQueue
-     * allocation via Surface::allowAllocation(false).
+     * by the consumer end point, the BufferQueueProducer callback onBufferReleased will update
+     * handoutBufferCount and indicate whether the caller should free the released buffer to be
+     * under the watermark. If the stream uses buffer manager to manage the stream buffers, it
+     * should disable the BufferQueue allocation via Surface::allowAllocation(false).
      *
      * Registering an already registered stream has no effect.
      *
@@ -112,10 +112,6 @@ public:
      *
      * After this call, the client takes over the ownership of this buffer if it is not freed.
      *
-     * Sometimes free buffers are discarded from consumer side and the dequeueBuffer call returns
-     * TIMED_OUT, in this case calling getBufferForStream again with noFreeBufferAtConsumer set to
-     * true will notify buffer manager to update its states and also tries to allocate a new buffer.
-     *
      * Return values:
      *
      *  OK:        Getting buffer for this stream was successful.
@@ -127,8 +123,7 @@ public:
      *  NO_MEMORY: Unable to allocate a buffer for this stream at this time.
      */
     status_t getBufferForStream(
-            int streamId, int streamSetId, bool isMultiRes, sp<GraphicBuffer>* gb,
-            int* fenceFd, bool noFreeBufferAtConsumer = false);
+            int streamId, int streamSetId, bool isMultiRes, sp<GraphicBuffer>* gb, int* fenceFd);
 
     /**
      * This method notifies the manager that a buffer has been released by the consumer.
@@ -139,7 +134,7 @@ public:
      * The notification lets the manager know how many buffers are directly available to the stream.
      *
      * If onBufferReleased is called for a given released buffer,
-     * returnBufferForStream may not be called for the same buffer, until the
+     * checkAndFreeBufferOnOtherStreamsLocked may not be called for the same buffer, until the
      * buffer has been reused. The manager will call detachBuffer on the stream
      * if it needs the released buffer otherwise.
      *
@@ -151,18 +146,24 @@ public:
      *  OK:        Buffer release was processed succesfully
      *  BAD_VALUE: stream ID or streamSetId are invalid, or stream ID and stream set ID
      *             combination doesn't match what was registered, or this stream wasn't registered
-     *             to this buffer manager before, or shouldFreeBuffer is null/
+     *             to this buffer manager before, or shouldFreeBuffer is null.
      */
     status_t onBufferReleased(int streamId, int streamSetId, bool isMultiRes,
                               /*out*/bool* shouldFreeBuffer);
 
     /**
      * This method notifies the manager that certain buffers has been removed from the
-     * buffer queue by detachBuffer from the consumer.
+     * buffer queue by detachBuffer/discardFreeBuffers from the consumer.
      *
      * The notification lets the manager update its internal handout buffer count and
-     * attached buffer counts accordingly. When buffers are detached from
-     * consumer, both handout and attached counts are decremented.
+     * attached buffer counts accordingly.
+     *
+     * released == true: buffers are released and discarded through
+     * discardFreeBuffers. Only attached counts are decremented because released
+     * buffers aren't counted as handed out.
+     *
+     * released == false: buffers are acquired and detached by the consumer.
+     * Both handout and attached counts are decremented.
      *
      * Return values:
      *
@@ -172,7 +173,8 @@ public:
      *             to this buffer manager before, or the removed buffer count is larger than
      *             current total handoutCount or attachedCount.
      */
-    status_t onBuffersRemoved(int streamId, int streamSetId, bool isMultiRes, size_t count);
+    status_t onBuffersRemoved(int streamId, int streamSetId,
+                              bool isMultiRes, size_t count, bool released);
 
     /**
      * This method notifiers the manager that a buffer is freed from the buffer queue, usually
@@ -276,6 +278,14 @@ private:
         InfoMap streamInfoMap;
         /**
          * The count of the buffers that were handed out to the streams of this set.
+         *
+         * Note: a buffer being handed out means that it's in one of three
+         * states:
+         *   - dequeued by the producer,
+         *   - queued by the producer and yet to be acquired by the consumer, or
+         *   - acquired by the consumer
+         * Only when the buffer is released by the consumer, it comes out of the
+         * `handed out` state.
          */
         BufferCountMap handoutBufferCountMap;
         /**
diff --git a/services/camera/libcameraservice/device3/Camera3Device.cpp b/services/camera/libcameraservice/device3/Camera3Device.cpp
index 4da892fae2..3fe6d9f41b 100644
--- a/services/camera/libcameraservice/device3/Camera3Device.cpp
+++ b/services/camera/libcameraservice/device3/Camera3Device.cpp
@@ -1339,7 +1339,7 @@ status_t Camera3Device::setStreamTransform(int id,
         CLOGE("Stream %d does not exist", id);
         return BAD_VALUE;
     }
-    return stream->setTransform(transform, false /*mayChangeMirror*/);
+    return stream->setTransform(transform);
 }
 
 status_t Camera3Device::deleteStream(int id) {
@@ -1468,7 +1468,6 @@ status_t Camera3Device::filterParamsAndConfigureLocked(const CameraMetadata& par
     return configureStreamsLocked(operatingMode, filteredParams);
 }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
 status_t Camera3Device::getInputSurface(sp<Surface> *surface) {
     ATRACE_CALL();
     Mutex::Autolock il(mInterfaceLock);
@@ -1482,22 +1481,6 @@ status_t Camera3Device::getInputSurface(sp<Surface> *surface) {
 
     return mInputStream->getInputSurface(surface);
 }
-#else
-status_t Camera3Device::getInputBufferProducer(
-        sp<IGraphicBufferProducer> *producer) {
-    ATRACE_CALL();
-    Mutex::Autolock il(mInterfaceLock);
-    Mutex::Autolock l(mLock);
-
-    if (producer == NULL) {
-        return BAD_VALUE;
-    } else if (mInputStream == NULL) {
-        return INVALID_OPERATION;
-    }
-
-    return mInputStream->getInputBufferProducer(producer);
-}
-#endif
 
 status_t Camera3Device::createDefaultRequest(camera_request_template_t templateId,
         CameraMetadata *request) {
@@ -2909,7 +2892,8 @@ status_t Camera3Device::registerInFlight(uint32_t frameNumber,
         bool isFixedFps, const std::set<std::set<std::string>>& physicalCameraIds,
         bool isStillCapture, bool isZslCapture, bool rotateAndCropAuto, bool autoframingAuto,
         const std::set<std::string>& cameraIdsWithZoom, bool useZoomRatio,
-        const SurfaceMap& outputSurfaces, nsecs_t requestTimeNs) {
+        const SurfaceMap& outputSurfaces, nsecs_t requestTimeNs,
+        const TransformationMap &transform) {
     ATRACE_CALL();
     std::lock_guard<std::mutex> l(mInFlightLock);
 
@@ -2917,7 +2901,7 @@ status_t Camera3Device::registerInFlight(uint32_t frameNumber,
     res = mInFlightMap.add(frameNumber, InFlightRequest(numBuffers, resultExtras, hasInput,
             hasAppCallback, minExpectedDuration, maxExpectedDuration, isFixedFps, physicalCameraIds,
             isStillCapture, isZslCapture, rotateAndCropAuto, autoframingAuto, cameraIdsWithZoom,
-            requestTimeNs, useZoomRatio, outputSurfaces));
+            requestTimeNs, useZoomRatio, outputSurfaces, transform));
     if (res < 0) return res;
 
     if (mInFlightMap.size() == 1) {
@@ -4115,6 +4099,7 @@ status_t Camera3Device::RequestThread::prepareHalRequests() {
         nsecs_t waitDuration = kBaseGetBufferWait + parent->getExpectedInFlightDuration();
 
         SurfaceMap uniqueSurfaceIdMap;
+        TransformationMap transformMap;
         bool containsHalBufferManagedStream = false;
         for (size_t j = 0; j < captureRequest->mOutputStreams.size(); j++) {
             sp<Camera3OutputStreamInterface> outputStream =
@@ -4141,6 +4126,8 @@ status_t Camera3Device::RequestThread::prepareHalRequests() {
                 }
             }
 
+            transformMap.insert({streamId, {outputStream->getMirrorMode(), -1}});
+
             std::vector<size_t> uniqueSurfaceIds;
             res = outputStream->getUniqueSurfaceIds(
                     captureRequest->mOutputSurfaces[streamId],
@@ -4269,7 +4256,7 @@ status_t Camera3Device::RequestThread::prepareHalRequests() {
                 captureRequest->mRotateAndCropAuto, captureRequest->mAutoframingAuto,
                 mPrevCameraIdsWithZoom, useZoomRatio,
                 passSurfaceMap ? uniqueSurfaceIdMap :
-                                      SurfaceMap{}, captureRequest->mRequestTimeNs);
+                                      SurfaceMap{}, captureRequest->mRequestTimeNs, transformMap);
         ALOGVV("%s: registered in flight requestId = %" PRId32 ", frameNumber = %" PRId64
                ", burstId = %" PRId32 ".",
                 __FUNCTION__,
@@ -5920,15 +5907,20 @@ status_t Camera3Device::deriveAndSetTransformLocked(
     int transform = -1;
     bool enableTransformInverseDisplay = true;
     using hardware::ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY;
+    using hardware::ICameraService::ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE;
+    bool rotationOnlyOverride = mRotationOverride == ROTATION_OVERRIDE_ROTATION_ONLY;
+    bool reverseRotationOnlyOverride =
+            wm_flags::enable_camera_compat_check_device_rotation_bugfix() &&
+                    mRotationOverride == ROTATION_OVERRIDE_ROTATION_ONLY_REVERSE;
     if (wm_flags::enable_camera_compat_for_desktop_windowing()) {
-        enableTransformInverseDisplay = (mRotationOverride != ROTATION_OVERRIDE_ROTATION_ONLY);
+        enableTransformInverseDisplay = !rotationOnlyOverride && !reverseRotationOnlyOverride;
     }
     int res = CameraUtils::getRotationTransform(mDeviceInfo, mirrorMode,
             enableTransformInverseDisplay, &transform);
     if (res != OK) {
         return res;
     }
-    stream.setTransform(transform, false /*mayChangeMirror*/, surfaceId);
+    stream.setTransform(transform, surfaceId);
     return OK;
 }
 
diff --git a/services/camera/libcameraservice/device3/Camera3Device.h b/services/camera/libcameraservice/device3/Camera3Device.h
index 608161facd..aa55369fad 100644
--- a/services/camera/libcameraservice/device3/Camera3Device.h
+++ b/services/camera/libcameraservice/device3/Camera3Device.h
@@ -253,12 +253,7 @@ class Camera3Device :
     status_t configureStreams(const CameraMetadata& sessionParams,
             int operatingMode =
             camera_stream_configuration_mode_t::CAMERA_STREAM_CONFIGURATION_NORMAL_MODE) override;
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     status_t getInputSurface(sp<Surface> *surface) override;
-#else
-    status_t getInputBufferProducer(
-            sp<IGraphicBufferProducer> *producer) override;
-#endif
 
     void getOfflineStreamIds(std::vector<int> *offlineStreamIds) override;
 
@@ -1363,7 +1358,8 @@ class Camera3Device :
             bool isFixedFps, const std::set<std::set<std::string>>& physicalCameraIds,
             bool isStillCapture, bool isZslCapture, bool rotateAndCropAuto, bool autoframingAuto,
             const std::set<std::string>& cameraIdsWithZoom, bool useZoomRatio,
-            const SurfaceMap& outputSurfaces, nsecs_t requestTimeNs);
+            const SurfaceMap& outputSurfaces, nsecs_t requestTimeNs,
+            const TransformationMap& transform);
 
     /**
      * Tracking for idle detection
diff --git a/services/camera/libcameraservice/device3/Camera3DeviceInjectionMethods.cpp b/services/camera/libcameraservice/device3/Camera3DeviceInjectionMethods.cpp
index b0e4ca3e4e..81b60d11ae 100644
--- a/services/camera/libcameraservice/device3/Camera3DeviceInjectionMethods.cpp
+++ b/services/camera/libcameraservice/device3/Camera3DeviceInjectionMethods.cpp
@@ -127,6 +127,13 @@ status_t Camera3Device::Camera3DeviceInjectionMethods::stopInjection() {
         wasActive = true;
     }
 
+    res = parent->mRequestThread->setHalInterface(mBackupHalInterface);
+    if (res != OK) {
+        ALOGE("%s: Failed to restore the HalInterface in RequestThread!", __FUNCTION__);
+        injectionDisconnectImpl();
+        return res;
+    }
+
     res = replaceHalInterface(mBackupHalInterface, false);
     if (res != OK) {
         ALOGE("%s: Failed to restore the backup HalInterface!", __FUNCTION__);
diff --git a/services/camera/libcameraservice/device3/Camera3FakeStream.cpp b/services/camera/libcameraservice/device3/Camera3FakeStream.cpp
index 79b88f87e9..aa7e6b2196 100644
--- a/services/camera/libcameraservice/device3/Camera3FakeStream.cpp
+++ b/services/camera/libcameraservice/device3/Camera3FakeStream.cpp
@@ -76,7 +76,7 @@ void Camera3FakeStream::dump(int fd, [[maybe_unused]] const Vector<String16> &ar
     Camera3IOStreamBase::dump(fd, args);
 }
 
-status_t Camera3FakeStream::setTransform(int, bool, int) {
+status_t Camera3FakeStream::setTransform(int, int) {
     ATRACE_CALL();
     // Do nothing
     return OK;
diff --git a/services/camera/libcameraservice/device3/Camera3FakeStream.h b/services/camera/libcameraservice/device3/Camera3FakeStream.h
index 9291bd05ed..f98daf2b6f 100644
--- a/services/camera/libcameraservice/device3/Camera3FakeStream.h
+++ b/services/camera/libcameraservice/device3/Camera3FakeStream.h
@@ -52,7 +52,7 @@ class Camera3FakeStream :
 
     virtual void     dump(int fd, const Vector<String16> &args);
 
-    status_t         setTransform(int transform, bool mayChangeMirror, int surfaceId);
+    status_t         setTransform(int transform, int surfaceId);
 
     virtual status_t detachBuffer(sp<GraphicBuffer>* buffer, int* fenceFd);
 
@@ -87,6 +87,8 @@ class Camera3FakeStream :
      */
     virtual ssize_t getSurfaceId(const sp<Surface> &/*surface*/) { return 0; }
 
+    virtual int getMirrorMode() const override { return  OutputConfiguration::MIRROR_MODE_AUTO; };
+
     virtual status_t getUniqueSurfaceIds(const std::vector<size_t>&,
             /*out*/std::vector<size_t>*) { return INVALID_OPERATION; };
 
diff --git a/services/camera/libcameraservice/device3/Camera3InputStream.cpp b/services/camera/libcameraservice/device3/Camera3InputStream.cpp
index 0c77303125..3bc2771d6f 100644
--- a/services/camera/libcameraservice/device3/Camera3InputStream.cpp
+++ b/services/camera/libcameraservice/device3/Camera3InputStream.cpp
@@ -182,7 +182,6 @@ status_t Camera3InputStream::returnInputBufferLocked(
                                  /*output*/false, /*transform*/ -1);
 }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
 status_t Camera3InputStream::getInputSurfaceLocked(sp<Surface> *surface) {
     ATRACE_CALL();
 
@@ -196,22 +195,6 @@ status_t Camera3InputStream::getInputSurfaceLocked(sp<Surface> *surface) {
     *surface = mSurface;
     return OK;
 }
-#else
-status_t Camera3InputStream::getInputBufferProducerLocked(
-            sp<IGraphicBufferProducer> *producer) {
-    ATRACE_CALL();
-
-    if (producer == NULL) {
-        return BAD_VALUE;
-    } else if (mProducer == NULL) {
-        ALOGE("%s: No input stream is configured", __FUNCTION__);
-        return INVALID_OPERATION;
-    }
-
-    *producer = mProducer;
-    return OK;
-}
-#endif
 
 status_t Camera3InputStream::disconnectLocked() {
 
@@ -288,22 +271,11 @@ status_t Camera3InputStream::configureQueueLocked() {
             camera_stream::max_buffers : minBufs;
         // TODO: somehow set the total buffer count when producer connects?
 
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
         mConsumer = bufferItemConsumer;
         mConsumer->setName(String8::format("Camera3-InputStream-%d", mId));
         mConsumer->setMaxAcquiredBufferCount(mTotalBufferCount);
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
         mSurface = surface;
-#else
-        mProducer = producer;
-#endif // WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
-
-#else
-        std::tie(mConsumer, surface) = BufferItemConsumer::create(mUsage, mTotalBufferCount);
-        mProducer = surface->getIGraphicBufferProducer();
-        mConsumer->setName(String8::format("Camera3-InputStream-%d", mId));
-#endif  // COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
 
         mConsumer->setBufferFreedListener(this);
     }
diff --git a/services/camera/libcameraservice/device3/Camera3InputStream.h b/services/camera/libcameraservice/device3/Camera3InputStream.h
index b1603e5772..a887d5e7ce 100644
--- a/services/camera/libcameraservice/device3/Camera3InputStream.h
+++ b/services/camera/libcameraservice/device3/Camera3InputStream.h
@@ -49,13 +49,8 @@ class Camera3InputStream : public Camera3IOStreamBase,
     // TODO: expose an interface to get the IGraphicBufferProducer
 
   private:
-
     sp<BufferItemConsumer> mConsumer;
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     sp<Surface> mSurface;
-#else
-    sp<IGraphicBufferProducer> mProducer;
-#endif
     Vector<BufferItem> mBuffersInFlight;
 
     static const std::string FAKE_ID;
@@ -80,12 +75,7 @@ class Camera3InputStream : public Camera3IOStreamBase,
     virtual status_t getInputBufferLocked(camera_stream_buffer *buffer, Size *size);
     virtual status_t returnInputBufferLocked(
             const camera_stream_buffer &buffer);
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     virtual status_t getInputSurfaceLocked(sp<Surface> *surface);
-#else
-    virtual status_t getInputBufferProducerLocked(
-            sp<IGraphicBufferProducer> *producer);
-#endif
     virtual status_t disconnectLocked();
 
     virtual status_t configureQueueLocked();
diff --git a/services/camera/libcameraservice/device3/Camera3OutputStream.cpp b/services/camera/libcameraservice/device3/Camera3OutputStream.cpp
index 14a7f79132..a5e449566c 100644
--- a/services/camera/libcameraservice/device3/Camera3OutputStream.cpp
+++ b/services/camera/libcameraservice/device3/Camera3OutputStream.cpp
@@ -435,7 +435,7 @@ status_t Camera3OutputStream::returnBufferCheckedLocked(
             nsecs_t presentTime = mSyncToDisplay ?
                     syncTimestampToDisplayLocked(captureTime, releaseFence) : captureTime;
 
-            setTransform(transform, true/*mayChangeMirror*/);
+            setTransform(transform);
             res = native_window_set_buffers_timestamp(mConsumer.get(), presentTime);
             if (res != OK) {
                 ALOGE("%s: Stream %d: Error setting timestamp: %s (%d)",
@@ -482,16 +482,10 @@ void Camera3OutputStream::dump(int fd, [[maybe_unused]] const Vector<String16> &
         "      DequeueBuffer latency histogram:");
 }
 
-status_t Camera3OutputStream::setTransform(int transform, bool mayChangeMirror, int surfaceId) {
+status_t Camera3OutputStream::setTransform(int transform, int surfaceId) {
     ATRACE_CALL();
     Mutex::Autolock l(mLock);
 
-    if (mMirrorMode != OutputConfiguration::MIRROR_MODE_AUTO && mayChangeMirror) {
-        // If the mirroring mode is not AUTO, do not allow transform update
-        // which may change mirror.
-        return OK;
-    }
-
     status_t res = OK;
 
     if (surfaceId != 0) {
@@ -539,18 +533,7 @@ status_t Camera3OutputStream::configureQueueLocked() {
     // Set dequeueBuffer/attachBuffer timeout if the consumer is not hw composer or hw texture.
     // We need skip these cases as timeout will disable the non-blocking (async) mode.
     if (!(isConsumedByHWComposer() || isConsumedByHWTexture())) {
-        if (mUseBufferManager) {
-            // When buffer manager is handling the buffer, we should have available buffers in
-            // buffer queue before we calls into dequeueBuffer because buffer manager is tracking
-            // free buffers.
-            // There are however some consumer side feature (ImageReader::discardFreeBuffers) that
-            // can discard free buffers without notifying buffer manager. We want the timeout to
-            // happen immediately here so buffer manager can try to update its internal state and
-            // try to allocate a buffer instead of waiting.
-            mConsumer->setDequeueTimeout(0);
-        } else {
-            mConsumer->setDequeueTimeout(kDequeueBufferTimeout);
-        }
+        mConsumer->setDequeueTimeout(kDequeueBufferTimeout);
     }
 
     return OK;
@@ -731,11 +714,7 @@ status_t Camera3OutputStream::configureConsumerQueueLocked(bool allowPreviewResp
         if (res == OK) {
             // Disable buffer allocation for this BufferQueue, buffer manager will take over
             // the buffer allocation responsibility.
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_PLATFORM_API_IMPROVEMENTS)
             mConsumer->allowAllocation(false);
-#else
-            mConsumer->getIGraphicBufferProducer()->allowAllocation(false);
-#endif
             mUseBufferManager = true;
         } else {
             ALOGE("%s: Unable to register stream %d to camera3 buffer manager, "
@@ -771,7 +750,6 @@ status_t Camera3OutputStream::getBufferLockedCommon(ANativeWindowBuffer** anb, i
                         __FUNCTION__, mId, strerror(-res), res);
             }
             if (res != OK) {
-                checkRetAndSetAbandonedLocked(res);
                 return res;
             }
             gotBufferFromManager = true;
@@ -847,72 +825,34 @@ status_t Camera3OutputStream::getBufferLockedCommon(ANativeWindowBuffer** anb, i
         mDequeueBufferLatency.add(dequeueStart, dequeueEnd);
 
         mLock.lock();
-
-        if (mUseBufferManager && res == TIMED_OUT) {
-            checkRemovedBuffersLocked();
-
-            sp<GraphicBuffer> gb;
-            res = mBufferManager->getBufferForStream(
-                    getId(), getStreamSetId(), isMultiResolution(),
-                    &gb, fenceFd, /*noFreeBuffer*/true);
-
-            if (res == OK) {
-                // Attach this buffer to the bufferQueue: the buffer will be in dequeue state after
-                // a successful return.
-                *anb = gb.get();
-                res = mConsumer->attachBuffer(*anb);
-                gotBufferFromManager = true;
-                ALOGV("Stream %d: Attached new buffer", getId());
-
-                if (res != OK) {
-                    if (shouldLogError(res, mState)) {
-                        ALOGE("%s: Stream %d: Can't attach the output buffer to this surface:"
-                                " %s (%d)", __FUNCTION__, mId, strerror(-res), res);
-                    }
-                    checkRetAndSetAbandonedLocked(res);
-                    return res;
-                }
-            } else {
-                ALOGE("%s: Stream %d: Can't get next output buffer from buffer manager:"
-                        " %s (%d)", __FUNCTION__, mId, strerror(-res), res);
-                return res;
-            }
-        } else if (res != OK) {
+        if (res != OK) {
             if (shouldLogError(res, mState)) {
                 ALOGE("%s: Stream %d: Can't dequeue next output buffer: %s (%d)",
                         __FUNCTION__, mId, strerror(-res), res);
             }
-            checkRetAndSetAbandonedLocked(res);
+            // Only transition to STATE_ABANDONED from STATE_CONFIGURED. (If it is STATE_PREPARING,
+            // let prepareNextBuffer handle the error.)
+            if ((res == NO_INIT || res == DEAD_OBJECT) && mState == STATE_CONFIGURED) {
+                mState = STATE_ABANDONED;
+            }
             return res;
         }
     }
 
     if (res == OK) {
-        checkRemovedBuffersLocked();
-    }
-
-    return res;
-}
-
-void Camera3OutputStream::checkRemovedBuffersLocked(bool notifyBufferManager) {
-    std::vector<sp<GraphicBuffer>> removedBuffers;
-    status_t res = mConsumer->getAndFlushRemovedBuffers(&removedBuffers);
-    if (res == OK) {
-        onBuffersRemovedLocked(removedBuffers);
+        std::vector<sp<GraphicBuffer>> removedBuffers;
+        status_t res = mConsumer->getAndFlushRemovedBuffers(&removedBuffers);
+        if (res == OK) {
+            onBuffersRemovedLocked(removedBuffers);
 
-        if (notifyBufferManager && mUseBufferManager && removedBuffers.size() > 0) {
-            mBufferManager->onBuffersRemoved(getId(), getStreamSetId(), isMultiResolution(),
-                    removedBuffers.size());
+            if (mUseBufferManager && removedBuffers.size() > 0) {
+                mBufferManager->onBuffersRemoved(getId(), getStreamSetId(), isMultiResolution(),
+                        removedBuffers.size(), /*released*/false);
+            }
         }
     }
-}
 
-void Camera3OutputStream::checkRetAndSetAbandonedLocked(status_t res) {
-    // Only transition to STATE_ABANDONED from STATE_CONFIGURED. (If it is
-    // STATE_PREPARING, let prepareNextBuffer handle the error.)
-    if ((res == NO_INIT || res == DEAD_OBJECT) && mState == STATE_CONFIGURED) {
-        mState = STATE_ABANDONED;
-    }
+    return res;
 }
 
 bool Camera3OutputStream::shouldLogError(status_t res, StreamState state) {
@@ -1126,8 +1066,14 @@ void Camera3OutputStream::BufferProducerListener::onBuffersDiscarded(
         Mutex::Autolock l(stream->mLock);
         stream->onBuffersRemovedLocked(buffers);
         if (stream->mUseBufferManager) {
-            stream->mBufferManager->onBuffersRemoved(stream->getId(),
-                    stream->getStreamSetId(), stream->isMultiResolution(), buffers.size());
+            status_t res = stream->mBufferManager->onBuffersRemoved(stream->getId(),
+                    stream->getStreamSetId(), stream->isMultiResolution(), buffers.size(),
+                    /*released*/true);
+            if (res != OK) {
+                ALOGE("%s: signaling buffers discarded to buffer manager failed: %s (%d).",
+                      __FUNCTION__, strerror(-res), res);
+                stream->mState = STATE_ERROR;
+            }
         }
         ALOGV("Stream %d: %zu Buffers discarded.", stream->getId(), buffers.size());
     }
@@ -1180,8 +1126,11 @@ status_t Camera3OutputStream::detachBufferLocked(sp<GraphicBuffer>* buffer, int*
         }
     }
 
-    // Here we assume detachBuffer is called by buffer manager so it doesn't need to be notified
-    checkRemovedBuffersLocked(/*notifyBufferManager*/false);
+    std::vector<sp<GraphicBuffer>> removedBuffers;
+    res = mConsumer->getAndFlushRemovedBuffers(&removedBuffers);
+    if (res == OK) {
+        onBuffersRemovedLocked(removedBuffers);
+    }
     return res;
 }
 
diff --git a/services/camera/libcameraservice/device3/Camera3OutputStream.h b/services/camera/libcameraservice/device3/Camera3OutputStream.h
index a547f8206e..88ef20e658 100644
--- a/services/camera/libcameraservice/device3/Camera3OutputStream.h
+++ b/services/camera/libcameraservice/device3/Camera3OutputStream.h
@@ -149,7 +149,7 @@ class Camera3OutputStream :
      * Set the transform on the output stream; one of the
      * HAL_TRANSFORM_* / NATIVE_WINDOW_TRANSFORM_* constants.
      */
-    virtual status_t setTransform(int transform, bool mayChangeMirror, int surfaceId = 0);
+    virtual status_t setTransform(int transform, int surfaceId = 0);
 
     /**
      * Return if this output stream is for video encoding.
@@ -187,7 +187,10 @@ class Camera3OutputStream :
 
             /**
             * Implementation of IProducerListener, used to notify this stream that the consumer
-            * has returned a buffer and it is ready to return to Camera3BufferManager for reuse.
+            * has triggered a certain action that's of interest to the producer:
+            * - returned a buffer and it is ready to return to Camera3BufferManager for reuse.
+            * - discarded a number of buffers (after release)
+            * - detached a buffer (after acquire)
             */
             virtual void onBufferReleased();
             virtual bool needsReleaseNotify() { return mNeedsReleaseNotify; }
@@ -229,6 +232,8 @@ class Camera3OutputStream :
      */
     virtual ssize_t getSurfaceId(const sp<Surface> &/*surface*/) { return 0; }
 
+    virtual int getMirrorMode() const override { return  mMirrorMode; };
+
     virtual status_t getUniqueSurfaceIds(const std::vector<size_t>&,
             /*out*/std::vector<size_t>*) { return INVALID_OPERATION; };
 
@@ -405,13 +410,6 @@ class Camera3OutputStream :
      */
     void onBuffersRemovedLocked(const std::vector<sp<GraphicBuffer>>&);
     status_t detachBufferLocked(sp<GraphicBuffer>* buffer, int* fenceFd);
-    // Call this after each dequeueBuffer/attachBuffer/detachNextBuffer call to get update on
-    // removed buffers. Set notifyBufferManager to false when the call is initiated by buffer
-    // manager so buffer manager doesn't need to be notified.
-    void checkRemovedBuffersLocked(bool notifyBufferManager = true);
-
-    // Check return status of IGBP calls and set abandoned state accordingly
-    void checkRetAndSetAbandonedLocked(status_t res);
 
     // If the status indicates abandonded stream, only log when state hasn't been updated to
     // STATE_ABANDONED
diff --git a/services/camera/libcameraservice/device3/Camera3OutputStreamInterface.h b/services/camera/libcameraservice/device3/Camera3OutputStreamInterface.h
index ff7ad56d2c..b397149a8b 100644
--- a/services/camera/libcameraservice/device3/Camera3OutputStreamInterface.h
+++ b/services/camera/libcameraservice/device3/Camera3OutputStreamInterface.h
@@ -34,7 +34,7 @@ class Camera3OutputStreamInterface : public virtual Camera3StreamInterface {
      * Set the transform on the output stream; one of the
      * HAL_TRANSFORM_* / NATIVE_WINDOW_TRANSFORM_* constants.
      */
-    virtual status_t setTransform(int transform, bool mayChangeMirror, int surfaceId = 0) = 0;
+    virtual status_t setTransform(int transform, int surfaceId = 0) = 0;
 
     /**
      * Return if this output stream is for video encoding.
@@ -86,6 +86,11 @@ class Camera3OutputStreamInterface : public virtual Camera3StreamInterface {
             const std::vector<size_t> &removedSurfaceIds,
             KeyedVector<sp<Surface>, size_t> *outputMap/*out*/) = 0;
 
+    /**
+     * Query the surface mirror mode.
+     */
+    virtual int getMirrorMode() const = 0;
+
     /**
      * Drop buffers if dropping is true. If dropping is false, do not drop buffers.
      */
diff --git a/services/camera/libcameraservice/device3/Camera3OutputUtils.cpp b/services/camera/libcameraservice/device3/Camera3OutputUtils.cpp
index 7a53847765..cefffc0098 100644
--- a/services/camera/libcameraservice/device3/Camera3OutputUtils.cpp
+++ b/services/camera/libcameraservice/device3/Camera3OutputUtils.cpp
@@ -690,31 +690,33 @@ void processCaptureResult(CaptureOutputStates& states, const camera_capture_resu
                     auto deviceInfo = states.physicalDeviceInfoMap.find(physicalId);
                     if (deviceInfo != states.physicalDeviceInfoMap.end()) {
                         auto orientation = deviceInfo->second.find(ANDROID_SENSOR_ORIENTATION);
-                        if (orientation.count > 0) {
-                            int32_t transform;
-                            ret = CameraUtils::getRotationTransform(deviceInfo->second,
-                                    OutputConfiguration::MIRROR_MODE_AUTO,
-                                            /*transformInverseDisplay*/true, &transform);
-                            if (ret == OK) {
-                                // It is possible for camera providers to return the capture
-                                // results after the processed frames. In such scenario, we will
-                                // not be able to set the output transformation before the frames
-                                // return back to the consumer for the current capture request
-                                // but we could still try and configure it for any future requests
-                                // that are still in flight. The assumption is that the physical
-                                // device id remains the same for the duration of the pending queue.
-                                for (size_t i = 0; i < states.inflightMap.size(); i++) {
-                                    auto &r = states.inflightMap.editValueAt(i);
-                                    if (r.requestTimeNs >= request.requestTimeNs) {
-                                        r.transform = transform;
+                        size_t i = 0;
+                        // It is possible for camera providers to return the capture
+                        // results after the processed frames. In such scenario, we will
+                        // not be able to set the output transformation before the frames
+                        // return back to the consumer for the current capture request
+                        // but we could still try and configure it for any future requests
+                        // that are still in flight. The assumption is that the physical
+                        // device id remains the same for the duration of the pending queue.
+                        for (; i < states.inflightMap.size() && (orientation.count > 0); i++) {
+                            auto &r = states.inflightMap.editValueAt(i);
+                            if (r.requestTimeNs >= request.requestTimeNs) {
+                                auto it = r.transform.begin();
+                                while (it != r.transform.end()) {
+                                    int32_t transform;
+                                    auto ret = CameraUtils::getRotationTransform(deviceInfo->second,
+                                            it->second.mirrorMode, /*transformInverseDisplay*/true,
+                                            &transform);
+                                    if (ret == OK) {
+                                        it->second.transform = transform;
+                                    } else {
+                                        ALOGE("%s: Failed to calculate current stream "
+                                                "transformation: %s (%d)", __FUNCTION__,
+                                                strerror(-ret), ret);
                                     }
+                                    it++;
                                 }
-                            } else {
-                                ALOGE("%s: Failed to calculate current stream transformation: %s "
-                                        "(%d)", __FUNCTION__, strerror(-ret), ret);
                             }
-                        } else {
-                            ALOGE("%s: Physical device orientation absent!", __FUNCTION__);
                         }
                     } else {
                         ALOGE("%s: Physical device not found in device info map found!",
@@ -883,7 +885,7 @@ void collectReturnableOutputBuffers(
         /*out*/ std::vector<BufferToReturn> *returnableBuffers,
         bool timestampIncreasing, const SurfaceMap& outputSurfaces,
         const CaptureResultExtras &resultExtras,
-        ERROR_BUF_STRATEGY errorBufStrategy, int32_t transform) {
+        ERROR_BUF_STRATEGY errorBufStrategy, const TransformationMap &transform) {
     for (size_t i = 0; i < numBuffers; i++)
     {
         Camera3StreamInterface *stream = Camera3Stream::cast(outputBuffers[i].stream);
@@ -916,6 +918,10 @@ void collectReturnableOutputBuffers(
             continue;
         }
 
+        const auto& transformIt = transform.find(streamId);
+        int32_t transformValue = (transformIt != transform.end()) ?
+            transformIt->second.transform : -1;
+
         const auto& it = outputSurfaces.find(streamId);
 
         // Do not return the buffer if the buffer status is error, and the error
@@ -926,12 +932,12 @@ void collectReturnableOutputBuffers(
                 returnableBuffers->emplace_back(stream,
                         outputBuffers[i], timestamp, readoutTimestamp, timestampIncreasing,
                         it->second, resultExtras,
-                        transform, requested ? requestTimeNs : 0);
+                        transformValue, requested ? requestTimeNs : 0);
             } else {
                 returnableBuffers->emplace_back(stream,
                         outputBuffers[i], timestamp, readoutTimestamp, timestampIncreasing,
                         std::vector<size_t> (), resultExtras,
-                        transform, requested ? requestTimeNs : 0 );
+                        transformValue, requested ? requestTimeNs : 0 );
             }
         }
     }
@@ -1292,7 +1298,7 @@ void flushInflightRequests(FlushInflightReqStates& states) {
                 /*requested*/true, request.requestTimeNs, states.sessionStatsBuilder,
                 /*out*/ &returnableBuffers,
                 /*timestampIncreasing*/true, request.outputSurfaces, request.resultExtras,
-                request.errorBufStrategy);
+                request.errorBufStrategy, request.transform);
             if (!flags::return_buffers_outside_locks()) {
                 finishReturningOutputBuffers(returnableBuffers,
                         states.listener, states.sessionStatsBuilder);
diff --git a/services/camera/libcameraservice/device3/Camera3OutputUtils.h b/services/camera/libcameraservice/device3/Camera3OutputUtils.h
index 21965f5fe0..091eddfca0 100644
--- a/services/camera/libcameraservice/device3/Camera3OutputUtils.h
+++ b/services/camera/libcameraservice/device3/Camera3OutputUtils.h
@@ -93,7 +93,7 @@ namespace camera3 {
             // Used to send buffer error callback when failing to return buffer
             const CaptureResultExtras &resultExtras = CaptureResultExtras{},
             ERROR_BUF_STRATEGY errorBufStrategy = ERROR_BUF_RETURN,
-            int32_t transform = -1);
+            const TransformationMap &transform = TransformationMap{});
 
     // helper function to collect the output buffers ready to be
     // returned to output streams, and to remove these buffers from
diff --git a/services/camera/libcameraservice/device3/Camera3SharedOutputStream.cpp b/services/camera/libcameraservice/device3/Camera3SharedOutputStream.cpp
index b436d2eac4..b55202a22e 100644
--- a/services/camera/libcameraservice/device3/Camera3SharedOutputStream.cpp
+++ b/services/camera/libcameraservice/device3/Camera3SharedOutputStream.cpp
@@ -490,8 +490,7 @@ status_t Camera3SharedOutputStream::updateStream(const std::vector<SurfaceHolder
     return ret;
 }
 
-status_t Camera3SharedOutputStream::setTransform(
-        int transform, bool mayChangeMirror, int surfaceId) {
+status_t Camera3SharedOutputStream::setTransform(int transform, int surfaceId) {
     ATRACE_CALL();
     Mutex::Autolock l(mLock);
 
@@ -509,12 +508,6 @@ status_t Camera3SharedOutputStream::setTransform(
     }
 
     auto& surfaceHolderForId = mSurfaceUniqueIds[surfaceId];
-    if (surfaceHolderForId.mSurfaceHolder.mMirrorMode != OutputConfiguration::MIRROR_MODE_AUTO &&
-            mayChangeMirror) {
-        // If the mirroring mode is not AUTO, do not allow transform update
-        // which may change mirror.
-        return OK;
-    }
 
     surfaceHolderForId.mTransform = transform;
     if (mState == STATE_CONFIGURED) {
diff --git a/services/camera/libcameraservice/device3/Camera3SharedOutputStream.h b/services/camera/libcameraservice/device3/Camera3SharedOutputStream.h
index 1fd676cc9d..31ded8b266 100644
--- a/services/camera/libcameraservice/device3/Camera3SharedOutputStream.h
+++ b/services/camera/libcameraservice/device3/Camera3SharedOutputStream.h
@@ -83,7 +83,7 @@ public:
         return false;
     }
 
-    virtual status_t  setTransform(int transform, bool mayChangeMirror, int surfaceId);
+    virtual status_t  setTransform(int transform, int surfaceId);
 
 private:
 
diff --git a/services/camera/libcameraservice/device3/Camera3Stream.cpp b/services/camera/libcameraservice/device3/Camera3Stream.cpp
index ae76e603bd..6eb91fcc7e 100644
--- a/services/camera/libcameraservice/device3/Camera3Stream.cpp
+++ b/services/camera/libcameraservice/device3/Camera3Stream.cpp
@@ -871,21 +871,12 @@ status_t Camera3Stream::returnInputBuffer(const camera_stream_buffer &buffer) {
     return res;
 }
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
 status_t Camera3Stream::getInputSurface(sp<Surface> *surface) {
     ATRACE_CALL();
     Mutex::Autolock l(mLock);
 
     return getInputSurfaceLocked(surface);
 }
-#else
-status_t Camera3Stream::getInputBufferProducer(sp<IGraphicBufferProducer> *producer) {
-    ATRACE_CALL();
-    Mutex::Autolock l(mLock);
-
-    return getInputBufferProducerLocked(producer);
-}
-#endif
 
 void Camera3Stream::fireBufferRequestForFrameNumber(uint64_t frameNumber,
         const CameraMetadata& settings) {
@@ -999,17 +990,10 @@ status_t Camera3Stream::returnInputBufferLocked(
     ALOGE("%s: This type of stream does not support input", __FUNCTION__);
     return INVALID_OPERATION;
 }
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
 status_t Camera3Stream::getInputSurfaceLocked(sp<Surface>*) {
     ALOGE("%s: This type of stream does not support input", __FUNCTION__);
     return INVALID_OPERATION;
 }
-#else
-status_t Camera3Stream::getInputBufferProducerLocked(sp<IGraphicBufferProducer>*) {
-    ALOGE("%s: This type of stream does not support input", __FUNCTION__);
-    return INVALID_OPERATION;
-}
-#endif
 
 void Camera3Stream::addBufferListener(
         wp<Camera3StreamBufferListener> listener) {
diff --git a/services/camera/libcameraservice/device3/Camera3Stream.h b/services/camera/libcameraservice/device3/Camera3Stream.h
index 1519ada78c..e651d101d9 100644
--- a/services/camera/libcameraservice/device3/Camera3Stream.h
+++ b/services/camera/libcameraservice/device3/Camera3Stream.h
@@ -383,13 +383,7 @@ class Camera3Stream :
      */
     status_t         returnInputBuffer(const camera_stream_buffer &buffer);
 
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     status_t         getInputSurface(sp<Surface> *producer);
-#else
-    // get the buffer producer of the input buffer queue.
-    // only apply to input streams.
-    status_t         getInputBufferProducer(sp<IGraphicBufferProducer> *producer);
-#endif
 
     /**
      * Whether any of the stream's buffers are currently in use by the HAL,
@@ -539,12 +533,7 @@ class Camera3Stream :
     virtual status_t returnInputBufferLocked(
             const camera_stream_buffer &buffer);
     virtual bool     hasOutstandingBuffersLocked() const = 0;
-#if WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
     virtual status_t getInputSurfaceLocked(sp<Surface> *surface);
-#else
-    // Get the buffer producer of the input buffer queue. Only apply to input streams.
-    virtual status_t getInputBufferProducerLocked(sp<IGraphicBufferProducer> *producer);
-#endif
 
     // Can return -ENOTCONN when we are already disconnected (not an error)
     virtual status_t disconnectLocked() = 0;
diff --git a/services/camera/libcameraservice/device3/Camera3StreamInterface.h b/services/camera/libcameraservice/device3/Camera3StreamInterface.h
index 673b946fd9..f07eb3cf03 100644
--- a/services/camera/libcameraservice/device3/Camera3StreamInterface.h
+++ b/services/camera/libcameraservice/device3/Camera3StreamInterface.h
@@ -451,15 +451,6 @@ class Camera3StreamInterface : public virtual RefBase {
      */
     virtual status_t returnInputBuffer(const camera_stream_buffer &buffer) = 0;
 
-#if !WB_CAMERA3_AND_PROCESSORS_WITH_DEPENDENCIES
-    /**
-     * Get the buffer producer of the input buffer queue.
-     *
-     * This method only applies to input streams.
-     */
-    virtual status_t getInputBufferProducer(sp<IGraphicBufferProducer> *producer) = 0;
-#endif
-
     /**
      * Whether any of the stream's buffers are currently in use by the HAL,
      * including buffers that have been returned but not yet had their
diff --git a/services/camera/libcameraservice/device3/Camera3StreamSplitter.cpp b/services/camera/libcameraservice/device3/Camera3StreamSplitter.cpp
index 3e4470eb76..8ea8e96752 100644
--- a/services/camera/libcameraservice/device3/Camera3StreamSplitter.cpp
+++ b/services/camera/libcameraservice/device3/Camera3StreamSplitter.cpp
@@ -456,6 +456,18 @@ status_t Camera3StreamSplitter::attachBufferToOutputs(ANativeWindowBuffer* anb,
             //Output surface got likely removed by client.
             continue;
         }
+        bool isOwned;
+        res = surface->isBufferOwned(gb, &isOwned);
+        if (res != OK) {
+            ALOGE("%s: Unable to query if surface %zu (%s) is owned", __FUNCTION__, surface_id,
+                  surface->getConsumerName().c_str());
+            return res;
+        }
+        if (isOwned) {
+            SP_LOGI("%s: Trying to add already-owned buffer %" PRIu64 " to surface %zu (%s)",
+                    __FUNCTION__, gb->getId(), surface_id, surface->getConsumerName().c_str());
+            continue;
+        }
 
         //Temporarly Unlock the mutex when trying to attachBuffer to the output
         //queue, because attachBuffer could block in case of a slow consumer. If
diff --git a/services/camera/libcameraservice/device3/Flags.h b/services/camera/libcameraservice/device3/Flags.h
index ca0006bf8b..d0e5cf55f1 100644
--- a/services/camera/libcameraservice/device3/Flags.h
+++ b/services/camera/libcameraservice/device3/Flags.h
@@ -21,7 +21,6 @@
 #ifndef USE_NEW_STREAM_SPLITTER
 
 #define USE_NEW_STREAM_SPLITTER                              \
-    COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_STREAM_SPLITTER) && \
-            COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_PLATFORM_API_IMPROVEMENTS)
+    COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_STREAM_SPLITTER)
 
 #endif  // USE_NEW_STREAM_SPLITTER
diff --git a/services/camera/libcameraservice/device3/InFlightRequest.h b/services/camera/libcameraservice/device3/InFlightRequest.h
index 62980c5c82..25f9878d96 100644
--- a/services/camera/libcameraservice/device3/InFlightRequest.h
+++ b/services/camera/libcameraservice/device3/InFlightRequest.h
@@ -196,7 +196,7 @@ struct InFlightRequest {
     SurfaceMap outputSurfaces;
 
     // Current output transformation
-    int32_t transform;
+    TransformationMap transform;
 
     // Whether the app explicitly uses ZOOM_RATIO
     bool useZoomRatio;
@@ -223,7 +223,7 @@ struct InFlightRequest {
             rotateAndCropAuto(false),
             autoframingAuto(false),
             requestTimeNs(0),
-            transform(-1),
+            transform(TransformationMap{}),
             useZoomRatio(false) {
     }
 
@@ -232,7 +232,8 @@ struct InFlightRequest {
             const std::set<std::set<std::string>>& physicalCameraIdSet, bool isStillCapture,
             bool isZslCapture, bool rotateAndCropAuto, bool autoframingAuto,
             const std::set<std::string>& idsWithZoom, nsecs_t requestNs, bool useZoomRatio,
-            const SurfaceMap& outSurfaces = SurfaceMap{}) :
+            const SurfaceMap& outSurfaces = SurfaceMap{},
+            const TransformationMap& transformMap = TransformationMap{}) :
             shutterTimestamp(0),
             sensorTimestamp(0),
             requestStatus(OK),
@@ -254,7 +255,7 @@ struct InFlightRequest {
             cameraIdsWithZoom(idsWithZoom),
             requestTimeNs(requestNs),
             outputSurfaces(outSurfaces),
-            transform(-1),
+            transform(transformMap),
             useZoomRatio(useZoomRatio) {
     }
 };
diff --git a/services/camera/libcameraservice/device3/PreviewFrameSpacer.cpp b/services/camera/libcameraservice/device3/PreviewFrameSpacer.cpp
index a04406e628..99e9a8a314 100644
--- a/services/camera/libcameraservice/device3/PreviewFrameSpacer.cpp
+++ b/services/camera/libcameraservice/device3/PreviewFrameSpacer.cpp
@@ -109,7 +109,7 @@ void PreviewFrameSpacer::queueBufferToClientLocked(
         return;
     }
 
-    parent->setTransform(bufferHolder.transform, true/*mayChangeMirror*/);
+    parent->setTransform(bufferHolder.transform);
 
     status_t res = native_window_set_buffers_timestamp(mConsumer.get(), bufferHolder.timestamp);
     if (res != OK) {
@@ -137,18 +137,16 @@ void PreviewFrameSpacer::queueBufferToClientLocked(
 
 status_t PreviewFrameSpacer::run(const char* name, int32_t priority, size_t stack) {
     auto ret = Thread::run(name, priority, stack);
-    if (flags::bump_preview_frame_space_priority()) {
-        // Boost priority of the preview frame spacer thread to SCHED_FIFO.
-        pid_t previewFrameSpacerTid = getTid();
-        auto res = SchedulingPolicyUtils::requestPriorityDirect(getpid(), previewFrameSpacerTid,
-                RunThreadWithRealtimePriority::kRequestThreadPriority);
-        if (res != OK) {
-            ALOGW("Can't set realtime priority for preview frame spacer thread: %s (%d)",
-                    strerror(-res), res);
-        } else {
-            ALOGV("Set real time priority for preview frame spacer thread (tid %d)",
-                    previewFrameSpacerTid);
-        }
+    // Boost priority of the preview frame spacer thread to SCHED_FIFO.
+    pid_t previewFrameSpacerTid = getTid();
+    auto res = SchedulingPolicyUtils::requestPriorityDirect(getpid(), previewFrameSpacerTid,
+            RunThreadWithRealtimePriority::kRequestThreadPriority);
+    if (res != OK) {
+        ALOGW("Can't set realtime priority for preview frame spacer thread: %s (%d)",
+                strerror(-res), res);
+    } else {
+        ALOGV("Set real time priority for preview frame spacer thread (tid %d)",
+                previewFrameSpacerTid);
     }
     return ret;
 }
diff --git a/services/camera/libcameraservice/gui/RingBufferConsumer.h b/services/camera/libcameraservice/gui/RingBufferConsumer.h
index 3161533423..322d5c5054 100644
--- a/services/camera/libcameraservice/gui/RingBufferConsumer.h
+++ b/services/camera/libcameraservice/gui/RingBufferConsumer.h
@@ -68,12 +68,7 @@ class RingBufferConsumer
     // the consumer usage flags passed to the graphics allocator. The
     // bufferCount parameter specifies how many buffers can be pinned for user
     // access at the same time.
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
     RingBufferConsumer(uint64_t consumerUsage, int bufferCount);
-#else
-    RingBufferConsumer(const sp<IGraphicBufferConsumer>& consumer, uint64_t consumerUsage,
-            int bufferCount);
-#endif  // COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
 
     virtual ~RingBufferConsumer();
 
diff --git a/services/camera/libcameraservice/gui/flagged_files/DeprecatedRingBufferConsumer.inc b/services/camera/libcameraservice/gui/flagged_files/DeprecatedRingBufferConsumer.inc
index 8c6afdef82..d242532f18 100644
--- a/services/camera/libcameraservice/gui/flagged_files/DeprecatedRingBufferConsumer.inc
+++ b/services/camera/libcameraservice/gui/flagged_files/DeprecatedRingBufferConsumer.inc
@@ -41,16 +41,9 @@ typedef android::RingBufferConsumer::PinnedBufferItem PinnedBufferItem;
 
 namespace android {
 
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
 RingBufferConsumer::RingBufferConsumer(uint64_t consumerUsage, int bufferCount)
     :
     ConsumerBase(), mBufferCount(bufferCount), mLatestTimestamp(0) {
-#else
-RingBufferConsumer::RingBufferConsumer(const sp<IGraphicBufferConsumer>& consumer,
-                                       uint64_t consumerUsage, int bufferCount)
-    :
-    ConsumerBase(consumer), mBufferCount(bufferCount), mLatestTimestamp(0) {
-#endif  // COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
     mConsumer->setConsumerUsageBits(consumerUsage);
     mConsumer->setMaxAcquiredBufferCount(bufferCount);
     assert(bufferCount > 0);
diff --git a/services/camera/libcameraservice/gui/flagged_files/RingBufferConsumer.inc b/services/camera/libcameraservice/gui/flagged_files/RingBufferConsumer.inc
index f30669d2c9..3352ef1b64 100644
--- a/services/camera/libcameraservice/gui/flagged_files/RingBufferConsumer.inc
+++ b/services/camera/libcameraservice/gui/flagged_files/RingBufferConsumer.inc
@@ -43,14 +43,8 @@ typedef android::RingBufferConsumer::PinnedBufferItem PinnedBufferItem;
 
 namespace android {
 
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
 RingBufferConsumer::RingBufferConsumer(uint64_t consumerUsage, int bufferCount)
     : mBufferCount(bufferCount), mLatestTimestamp(0) {
-#else
-RingBufferConsumer::RingBufferConsumer(const sp<IGraphicBufferConsumer>& consumer,
-                                       uint64_t consumerUsage, int bufferCount)
-    : mBufferCount(bufferCount), mLatestTimestamp(0) {
-#endif  // COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_CONSUMER_BASE_OWNS_BQ)
     std::tie(mBufferItemConsumer, mSurface) =
             BufferItemConsumer::create(consumerUsage, bufferCount);
     assert(bufferCount > 0);
diff --git a/services/camera/libcameraservice/hidl/HidlCameraDeviceUser.cpp b/services/camera/libcameraservice/hidl/HidlCameraDeviceUser.cpp
index 018a45c771..b353bcdad1 100644
--- a/services/camera/libcameraservice/hidl/HidlCameraDeviceUser.cpp
+++ b/services/camera/libcameraservice/hidl/HidlCameraDeviceUser.cpp
@@ -74,7 +74,8 @@ bool HidlCameraDeviceUser::initDevice() {
         return false;
     }
 
-    int32_t resFMQSize = CAMERA_RESULT_METADATA_QUEUE_SIZE;
+    int32_t resFMQSize = property_get_int32(FMQ_SIZE_PROP.c_str(),
+            /*default*/CAMERA_RESULT_METADATA_QUEUE_SIZE);
     mCaptureResultMetadataQueue =
         std::make_shared<CaptureResultMetadataQueue>(static_cast<size_t>(resFMQSize),
                                                      false /* non blocking */);
diff --git a/services/camera/libcameraservice/hidl/Utils.cpp b/services/camera/libcameraservice/hidl/Utils.cpp
index 786087d8a1..bc7b7b3fbf 100644
--- a/services/camera/libcameraservice/hidl/Utils.cpp
+++ b/services/camera/libcameraservice/hidl/Utils.cpp
@@ -104,11 +104,47 @@ hardware::camera2::params::OutputConfiguration convertFromHidl(
         surfaces.push_back(new H2BGraphicBufferProducer(igbp));
 #endif
     }
+
+    int format = 0, dataSpace = 0;
+    int width = 0, height = 0;
+    if (!surfaces.empty()) {
+        // We need to query these here since vendor clients are forbidden by sepolicy
+        // to talk to some consumer processes such as an app which may be passing a preview
+        // surface to a HAL process which uses the VNDK interface.
+#if WB_LIBCAMERASERVICE_WITH_DEPENDENCIES
+        if (surfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_FORMAT, &format) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_FORMAT query failed", __FUNCTION__);
+        }
+        if (surfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_DEFAULT_DATASPACE,
+            &dataSpace) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_DEFAULT_DATASPACE query failed", __FUNCTION__);
+        }
+        if (surfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_WIDTH, &width) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_WIDTH query failed", __FUNCTION__);
+        }
+        if (surfaces[0].graphicBufferProducer->query(NATIVE_WINDOW_HEIGHT, &height) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_HEIGHT query failed", __FUNCTION__);
+        }
+#else
+        if (surfaces[0]->query(NATIVE_WINDOW_FORMAT, &format) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_FORMAT query failed", __FUNCTION__);
+        }
+        if (surfaces[0]->query(NATIVE_WINDOW_DEFAULT_DATASPACE, &dataSpace) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_DEFAULT_DATASPACE query failed", __FUNCTION__);
+        }
+        if (surfaces[0]->query(NATIVE_WINDOW_WIDTH, &width) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_WIDTH query failed", __FUNCTION__);
+        }
+        if (surfaces[0]->query(NATIVE_WINDOW_HEIGHT, &height) != OK) {
+            ALOGE("%s: NATIVE_WINDOW_HEIGHT query failed", __FUNCTION__);
+        }
+#endif
+    }
     hardware::camera2::params::OutputConfiguration outputConfiguration(
         surfaces, convertFromHidl(hOutputConfiguration.rotation),
         hOutputConfiguration.physicalCameraId,
-        hOutputConfiguration.windowGroupId, OutputConfiguration::SURFACE_TYPE_UNKNOWN, 0, 0,
-        (windowHandles.size() > 1));
+        hOutputConfiguration.windowGroupId, OutputConfiguration::SURFACE_TYPE_UNKNOWN,
+        width, height, (windowHandles.size() > 1), format, dataSpace);
     return outputConfiguration;
 }
 
diff --git a/services/camera/libcameraservice/libcameraservice_fuzzer/camera_service_fuzzer.cpp b/services/camera/libcameraservice/libcameraservice_fuzzer/camera_service_fuzzer.cpp
index 214832f9ce..4f2e565ee3 100644
--- a/services/camera/libcameraservice/libcameraservice_fuzzer/camera_service_fuzzer.cpp
+++ b/services/camera/libcameraservice/libcameraservice_fuzzer/camera_service_fuzzer.cpp
@@ -180,6 +180,15 @@ class FuzzerActivityManager : public BnInterface<IActivityManager> {
                                    int32_t /*appPid*/) override {
         return OK;
     }
+    status_t registerProcessObserver(const sp<app::IProcessObserver>&) override {
+        return OK;
+    }
+    status_t unregisterProcessObserver(const sp<app::IProcessObserver>&) override {
+        return OK;
+    }
+    status_t getRunningAppProcesses(::std::vector<app::RunningAppProcessInfo>*) override {
+        return OK;
+    }
 };
 
 class FuzzerSensorPrivacyManager : public BnInterface<hardware::ISensorPrivacyManager> {
diff --git a/services/camera/libcameraservice/tests/Camera3StreamSplitterTest.cpp b/services/camera/libcameraservice/tests/Camera3StreamSplitterTest.cpp
index 05959ec862..f2774b1ad3 100644
--- a/services/camera/libcameraservice/tests/Camera3StreamSplitterTest.cpp
+++ b/services/camera/libcameraservice/tests/Camera3StreamSplitterTest.cpp
@@ -22,10 +22,6 @@
 #include <com_android_internal_camera_flags.h>
 #include <gui/BufferItemConsumer.h>
 #include <gui/IGraphicBufferConsumer.h>
-#include <gui/Flags.h> // remove with WB_PLATFORM_API_IMPROVEMENTS
-#if not COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_PLATFORM_API_IMPROVEMENTS)
-#include <gui/IGraphicBufferProducer.h>
-#endif
 #include <gui/Surface.h>
 #include <ui/Fence.h>
 #include <ui/GraphicBuffer.h>
@@ -155,12 +151,7 @@ TEST_F(Camera3StreamSplitterTest, TestProcessSingleBuffer) {
                                      kHeight, kFormat, &inputSurface, kDynamicRangeProfile));
     sp<TestSurfaceListener> surfaceListener = sp<TestSurfaceListener>::make();
     EXPECT_EQ(OK, inputSurface->connect(NATIVE_WINDOW_API_CAMERA, surfaceListener, false));
-    // TODO: Do this with the surface itself once the API is available.
-#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_PLATFORM_API_IMPROVEMENTS)
     EXPECT_EQ(OK, inputSurface->allowAllocation(false));
-#else
-    EXPECT_EQ(OK, inputSurface->getIGraphicBufferProducer()->allowAllocation(false));
-#endif
 
     //
     // Create a buffer to use:
@@ -182,3 +173,51 @@ TEST_F(Camera3StreamSplitterTest, TestProcessSingleBuffer) {
     EXPECT_EQ(1u, consumerListener2->mNumBuffersAcquired);
     EXPECT_EQ(1u, surfaceListener->mNumBuffersReleased);
 }
+
+TEST_F(Camera3StreamSplitterTest, AddingSameBufferManyTimes) {
+    //
+    // Set up output consumers:
+    //
+    constexpr auto kSurfaceId1 = 1;
+    auto [bufferItemConsumer1, surface1] = createConsumerAndSurface();
+    sp<TestConsumerListener> consumerListener1 =
+            sp<TestConsumerListener>::make(bufferItemConsumer1);
+    bufferItemConsumer1->setFrameAvailableListener(consumerListener1);
+
+    constexpr auto kSurfaceId2 = 2;
+    auto [bufferItemConsumer2, surface2] = createConsumerAndSurface();
+    sp<TestConsumerListener> consumerListener2 =
+            sp<TestConsumerListener>::make(bufferItemConsumer2);
+    bufferItemConsumer2->setFrameAvailableListener(consumerListener2);
+
+    //
+    // Connect it to the splitter, get the input surface, and set it up:
+    //
+    sp<Surface> inputSurface;
+    EXPECT_EQ(OK, mSplitter->connect({{kSurfaceId1, surface1}, {kSurfaceId2, surface2}},
+                                     kConsumerUsage, kProducerUsage, kHalMaxBuffers, kWidth,
+                                     kHeight, kFormat, &inputSurface, kDynamicRangeProfile));
+    sp<TestSurfaceListener> surfaceListener = sp<TestSurfaceListener>::make();
+    EXPECT_EQ(OK, inputSurface->connect(NATIVE_WINDOW_API_CAMERA, surfaceListener, false));
+    // TODO: Do this with the surface itself once the API is available.
+#if COM_ANDROID_GRAPHICS_LIBGUI_FLAGS(WB_PLATFORM_API_IMPROVEMENTS)
+    EXPECT_EQ(OK, inputSurface->allowAllocation(false));
+#else
+    EXPECT_EQ(OK, inputSurface->getIGraphicBufferProducer()->allowAllocation(false));
+#endif
+
+    //
+    // Create a buffer to use:
+    //
+    sp<GraphicBuffer> singleBuffer = new GraphicBuffer(kWidth, kHeight, kFormat, kProducerUsage);
+    EXPECT_NE(nullptr, singleBuffer);
+
+    //
+    // When we attach the same buffer multiple times, it shouldn't be attached if it had been
+    // already.
+    //
+    for (int i = 0; i < 1000; i++) {
+        EXPECT_EQ(OK, mSplitter->attachBufferToOutputs(singleBuffer->getNativeBuffer(),
+                                                       {kSurfaceId1, kSurfaceId2}));
+    }
+}
diff --git a/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.cpp b/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.cpp
index 85a5afc17e..1e4646bdd9 100644
--- a/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.cpp
+++ b/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.cpp
@@ -141,12 +141,7 @@ PermissionChecker::PermissionResult AttributionAndPermissionUtils::checkPermissi
         const AttributionSourceState& attributionSource, const std::string& message,
         int32_t attributedOpCode, bool forDataDelivery, bool startDataDelivery,
         bool checkAutomotive) {
-    AttributionSourceState clientAttribution = attributionSource;
-    if (!flags::data_delivery_permission_checks() && !clientAttribution.next.empty()) {
-        clientAttribution.next.clear();
-    }
-
-    if (checkAutomotive && checkAutomotivePrivilegedClient(cameraId, clientAttribution)) {
+    if (checkAutomotive && checkAutomotivePrivilegedClient(cameraId, attributionSource)) {
         return PermissionChecker::PERMISSION_GRANTED;
     }
 
@@ -154,29 +149,29 @@ PermissionChecker::PermissionResult AttributionAndPermissionUtils::checkPermissi
     if (forDataDelivery) {
         if (startDataDelivery) {
             result = mPermissionChecker->checkPermissionForStartDataDeliveryFromDatasource(
-                    toString16(permission), clientAttribution, toString16(message),
+                    toString16(permission), attributionSource, toString16(message),
                     attributedOpCode);
         } else {
             result = mPermissionChecker->checkPermissionForDataDeliveryFromDatasource(
-                    toString16(permission), clientAttribution, toString16(message),
+                    toString16(permission), attributionSource, toString16(message),
                     attributedOpCode);
         }
     } else {
         result = mPermissionChecker->checkPermissionForPreflight(
-                toString16(permission), clientAttribution, toString16(message), attributedOpCode);
+                toString16(permission), attributionSource, toString16(message), attributedOpCode);
     }
 
     if (result == PermissionChecker::PERMISSION_HARD_DENIED) {
         ALOGI("%s (forDataDelivery %d startDataDelivery %d): Permission hard denied "
               "for client attribution %s",
               __FUNCTION__, forDataDelivery, startDataDelivery,
-              getAttributionString(clientAttribution).c_str());
+              getAttributionString(attributionSource).c_str());
     } else if (result == PermissionChecker::PERMISSION_SOFT_DENIED) {
         ALOGI("%s checkPermission (forDataDelivery %d startDataDelivery %d): Permission soft "
               "denied "
               "for client attribution %s",
               __FUNCTION__, forDataDelivery, startDataDelivery,
-              getAttributionString(clientAttribution).c_str());
+              getAttributionString(attributionSource).c_str());
     }
     return result;
 }
@@ -415,10 +410,7 @@ bool AttributionAndPermissionUtils::resolveClientUid(/*inout*/ int& clientUid) {
     if (clientUid == hardware::ICameraService::USE_CALLING_UID) {
         clientUid = callingUid;
     } else {
-        validUid = isTrustedCallingUid(callingUid);
-        if (flags::data_delivery_permission_checks()) {
-            validUid = validUid || (clientUid == callingUid);
-        }
+        validUid = isTrustedCallingUid(callingUid) || (clientUid == callingUid);
     }
 
     return validUid;
@@ -433,10 +425,7 @@ bool AttributionAndPermissionUtils::resolveClientPid(/*inout*/ int& clientPid) {
     if (clientPid == hardware::ICameraService::USE_CALLING_PID) {
         clientPid = callingPid;
     } else {
-        validPid = isTrustedCallingUid(callingUid);
-        if (flags::data_delivery_permission_checks()) {
-            validPid = validPid || (clientPid == callingPid);
-        }
+        validPid = isTrustedCallingUid(callingUid) || (clientPid == callingPid);
     }
 
     return validPid;
diff --git a/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.h b/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.h
index 1c5d6da5a7..69212c99ec 100644
--- a/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.h
+++ b/services/camera/libcameraservice/utils/AttributionAndPermissionUtils.h
@@ -92,8 +92,7 @@ class AttributionAndPermissionUtils {
     virtual void restoreCallingIdentity(int64_t token);
 
     /**
-     * If flags::data_delivery_permission_checks() is enabled, check the calling attribution
-     * source and resolve its package name, or fill in the pid/uid/package name if necessary.
+     * Check the calling attribution source and resolve its package name.
      *
      * @param resolvedAttributionSource The resolved attribution source.
      * @param methodName The name of the method calling this function (for logging only).
diff --git a/services/camera/libcameraservice/utils/CameraServiceProxyWrapper.cpp b/services/camera/libcameraservice/utils/CameraServiceProxyWrapper.cpp
index 22b9a7502e..e14b24bdf4 100644
--- a/services/camera/libcameraservice/utils/CameraServiceProxyWrapper.cpp
+++ b/services/camera/libcameraservice/utils/CameraServiceProxyWrapper.cpp
@@ -239,8 +239,9 @@ int64_t CameraServiceProxyWrapper::encodeSessionConfiguration(
 
         camera_metadata_ro_entry stabEntry =
                 parameters.find(ANDROID_CONTROL_VIDEO_STABILIZATION_MODE);
-        if (stabEntry.count == 1 && stabEntry.data.u8[0] ==
-                ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_PREVIEW_STABILIZATION) {
+        if (stabEntry.count == 1 && (stabEntry.data.u8[0] ==
+                ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_PREVIEW_STABILIZATION ||
+                stabEntry.data.u8[0] == ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_ON)) {
             features |= CameraFeatureCombinationStats::CAMERA_FEATURE_STABILIZATION;
         }
     }
diff --git a/services/camera/libcameraservice/utils/SessionConfigurationUtils.cpp b/services/camera/libcameraservice/utils/SessionConfigurationUtils.cpp
index 97d2179509..8fe6ad076a 100644
--- a/services/camera/libcameraservice/utils/SessionConfigurationUtils.cpp
+++ b/services/camera/libcameraservice/utils/SessionConfigurationUtils.cpp
@@ -446,7 +446,8 @@ bool isStreamUseCaseSupported(int64_t streamUseCase,
 
 binder::Status createConfiguredSurface(
         OutputStreamInfo& streamInfo, bool isStreamInfoValid,
-        sp<Surface>& out_surface, const sp<SurfaceType>& surface,
+        const OutputConfiguration &outputConfiguration,
+        sp<Surface> &out_surface, const sp<SurfaceType>& surface,
         const std::string &logicalCameraId, const CameraMetadata &physicalCameraMetadata,
         const std::vector<int32_t> &sensorPixelModesUsed, int64_t dynamicRangeProfile,
         int64_t streamUseCase, int timestampBase, int mirrorMode,
@@ -487,33 +488,18 @@ binder::Status createConfiguredSurface(
 
     ANativeWindow *anw = out_surface.get();
 
-    int width, height, format;
-    android_dataspace dataSpace;
-    if ((err = anw->query(anw, NATIVE_WINDOW_WIDTH, &width)) != OK) {
-        std::string msg = fmt::sprintf("Camera %s: Failed to query Surface width: %s (%d)",
-                 logicalCameraId.c_str(), strerror(-err), err);
-        ALOGE("%s: %s", __FUNCTION__, msg.c_str());
-        return STATUS_ERROR(CameraService::ERROR_INVALID_OPERATION, msg.c_str());
-    }
-    if ((err = anw->query(anw, NATIVE_WINDOW_HEIGHT, &height)) != OK) {
-        std::string msg = fmt::sprintf("Camera %s: Failed to query Surface height: %s (%d)",
-                logicalCameraId.c_str(), strerror(-err), err);
-        ALOGE("%s: %s", __FUNCTION__, msg.c_str());
-        return STATUS_ERROR(CameraService::ERROR_INVALID_OPERATION, msg.c_str());
-    }
+    int width = outputConfiguration.getWidth();
+    int height = outputConfiguration.getHeight();
+    int format = 0;
+    auto dataSpace = static_cast<android_dataspace>(outputConfiguration.getDataspace());
+
+    // TODO: See if we can query the OutputConfiguration directly : b/417531963
     if ((err = anw->query(anw, NATIVE_WINDOW_FORMAT, &format)) != OK) {
         std::string msg = fmt::sprintf("Camera %s: Failed to query Surface format: %s (%d)",
                 logicalCameraId.c_str(), strerror(-err), err);
         ALOGE("%s: %s", __FUNCTION__, msg.c_str());
         return STATUS_ERROR(CameraService::ERROR_INVALID_OPERATION, msg.c_str());
     }
-    if ((err = anw->query(anw, NATIVE_WINDOW_DEFAULT_DATASPACE,
-            reinterpret_cast<int*>(&dataSpace))) != OK) {
-        std::string msg = fmt::sprintf("Camera %s: Failed to query Surface dataspace: %s (%d)",
-                logicalCameraId.c_str(), strerror(-err), err);
-        ALOGE("%s: %s", __FUNCTION__, msg.c_str());
-        return STATUS_ERROR(CameraService::ERROR_INVALID_OPERATION, msg.c_str());
-    }
 
     if (colorSpace != ANDROID_REQUEST_AVAILABLE_COLOR_SPACE_PROFILES_MAP_UNSPECIFIED &&
             format != HAL_PIXEL_FORMAT_BLOB) {
@@ -923,9 +909,9 @@ binder::Status convertToHALStreamCombination(
         }
 
         for (auto& surface_type : surfaces) {
-            sp<Surface> surface;
             int mirrorMode = it.getMirrorMode(surface_type);
-            res = createConfiguredSurface(streamInfo, isStreamInfoValid, surface,
+            sp<Surface> surface;
+            res = createConfiguredSurface(streamInfo, isStreamInfoValid, it, surface,
                                     flagtools::convertParcelableSurfaceTypeToSurface(surface_type),
                                     logicalCameraId,  metadataChosen, sensorPixelModesUsed,
                                     dynamicRangeProfile, streamUseCase, timestampBase, mirrorMode,
diff --git a/services/camera/libcameraservice/utils/SessionConfigurationUtils.h b/services/camera/libcameraservice/utils/SessionConfigurationUtils.h
index 3852933f98..9842122df3 100644
--- a/services/camera/libcameraservice/utils/SessionConfigurationUtils.h
+++ b/services/camera/libcameraservice/utils/SessionConfigurationUtils.h
@@ -108,7 +108,8 @@ bool isPublicFormat(int32_t format);
 // previous Surface property doesn't match with streamInfo
 binder::Status createConfiguredSurface(
         camera3::OutputStreamInfo& streamInfo, bool isStreamInfoValid,
-        sp<Surface>& out_surface, const sp<SurfaceType>& surface,
+        const OutputConfiguration &outputConfiguration,
+        sp<Surface> &out_surface, const sp<SurfaceType>& surface,
         const std::string &logicalCameraId, const CameraMetadata &physicalCameraMetadata,
         const std::vector<int32_t> &sensorPixelModesUsed,  int64_t dynamicRangeProfile,
         int64_t streamUseCase, int timestampBase, int mirrorMode,
diff --git a/services/camera/libcameraservice/utils/SessionStatsBuilder.cpp b/services/camera/libcameraservice/utils/SessionStatsBuilder.cpp
index 2bca4cb667..a4880e5857 100644
--- a/services/camera/libcameraservice/utils/SessionStatsBuilder.cpp
+++ b/services/camera/libcameraservice/utils/SessionStatsBuilder.cpp
@@ -18,6 +18,7 @@
 #define ATRACE_TAG ATRACE_TAG_CAMERA
 //#define LOG_NDEBUG 0
 
+#include <algorithm>
 #include <numeric>
 
 #include <inttypes.h>
diff --git a/services/camera/libcameraservice/utils/Utils.h b/services/camera/libcameraservice/utils/Utils.h
index 7ca3e935fb..46b0eb771e 100644
--- a/services/camera/libcameraservice/utils/Utils.h
+++ b/services/camera/libcameraservice/utils/Utils.h
@@ -25,6 +25,8 @@
 
 namespace android {
 
+static const std::string FMQ_SIZE_PROP = "ro.camera.resultFmqSize";
+
 /**
  * Magically convert an enum to its underlying integer type, mostly so they can be
  * printed with printf-style formatters without warnings.
diff --git a/services/camera/virtualcamera/Android.bp b/services/camera/virtualcamera/Android.bp
index c76bb1bb24..6f639a4ae0 100644
--- a/services/camera/virtualcamera/Android.bp
+++ b/services/camera/virtualcamera/Android.bp
@@ -43,7 +43,6 @@ cc_defaults {
         "-Wformat",
         "-Wthread-safety",
     ],
-    cpp_std: "c++20",
 }
 
 cc_library_static {
diff --git a/services/camera/virtualcamera/README.md b/services/camera/virtualcamera/README.md
index 04b481124e..9feed0fd43 100644
--- a/services/camera/virtualcamera/README.md
+++ b/services/camera/virtualcamera/README.md
@@ -121,6 +121,23 @@ Client Surface[1-n] (Consumer)
 7.  The Camera client is notified of the "shutter" event and the `CaptureResult`
     is sent to the consumer.
 
+### Timeout and frame duplication
+
+Most camera applications are made to handle only the on-device camera. When an
+application runs on a virtual device with a virtual camera, the client might not
+expect potential remote camera latency and/or disconnections.
+For [CAPTURE_INTENT_PREVIEW](https://developer.android.com/reference/android/hardware/camera2/CameraMetadata#CONTROL_CAPTURE_INTENT_PREVIEW)
+use case, to counterbalance these disruptions, virtual camera duplicates
+the last frames if the producer does not post a new frame in time.
+
+When a frame is duplicated, the timestamp must increase to meet the camera framework
+expectations. In some use cases, this frame duplication is not wanted, like for motion
+tracking, where the timestamp must match the graphic data.
+
+No frame duplication takes place for other capture intents. The virtual camera
+waits at most `1/minFps` second (see CaptureRequest#CONTROL_AE_TARGET_FPS_RANGE) or the
+current FPS range and notifies the framework of a timeout.
+
 ## EGL Rendering
 
 ### The render thread
diff --git a/services/camera/virtualcamera/VirtualCameraDevice.cc b/services/camera/virtualcamera/VirtualCameraDevice.cc
index c3be62b326..aa3db650c3 100644
--- a/services/camera/virtualcamera/VirtualCameraDevice.cc
+++ b/services/camera/virtualcamera/VirtualCameraDevice.cc
@@ -18,16 +18,18 @@
 #define LOG_TAG "VirtualCameraDevice"
 #include "VirtualCameraDevice.h"
 
+#include <android_companion_virtualdevice_flags.h>
+
 #include <algorithm>
 #include <array>
 #include <chrono>
 #include <cstdint>
 #include <iterator>
-#include <numeric>
 #include <optional>
 #include <string>
 #include <vector>
 
+#include "CameraMetadata.h"
 #include "VirtualCameraService.h"
 #include "VirtualCameraSession.h"
 #include "aidl/android/companion/virtualcamera/SupportedStreamConfiguration.h"
@@ -37,7 +39,6 @@
 #include "aidl/android/hardware/camera/device/StreamConfiguration.h"
 #include "android/binder_auto_utils.h"
 #include "android/binder_status.h"
-#include "log/log.h"
 #include "system/camera_metadata.h"
 #include "util/MetadataUtil.h"
 #include "util/Util.h"
@@ -52,9 +53,11 @@ using ::aidl::android::companion::virtualcamera::LensFacing;
 using ::aidl::android::companion::virtualcamera::SensorOrientation;
 using ::aidl::android::companion::virtualcamera::SupportedStreamConfiguration;
 using ::aidl::android::companion::virtualcamera::VirtualCameraConfiguration;
+using ::aidl::android::companion::virtualcamera::VirtualCameraMetadata;
 using ::aidl::android::hardware::camera::common::CameraResourceCost;
 using ::aidl::android::hardware::camera::common::Status;
-using ::aidl::android::hardware::camera::device::CameraMetadata;
+using AidlCameraMetadata =
+    ::aidl::android::hardware::camera::device::CameraMetadata;
 using ::aidl::android::hardware::camera::device::ICameraDeviceCallback;
 using ::aidl::android::hardware::camera::device::ICameraDeviceSession;
 using ::aidl::android::hardware::camera::device::ICameraInjectionSession;
@@ -63,6 +66,8 @@ using ::aidl::android::hardware::camera::device::StreamConfiguration;
 using ::aidl::android::hardware::camera::device::StreamRotation;
 using ::aidl::android::hardware::camera::device::StreamType;
 using ::aidl::android::hardware::graphics::common::PixelFormat;
+using HelperCameraMetadata =
+    ::android::hardware::camera::common::helper::CameraMetadata;
 
 namespace {
 
@@ -217,21 +222,10 @@ std::map<Resolution, int> getResolutionToMaxFpsMap(
   return resolutionToMaxFpsMap;
 }
 
-// TODO(b/301023410) - Populate camera characteristics according to camera configuration.
-std::optional<CameraMetadata> initCameraCharacteristics(
+std::unique_ptr<AidlCameraMetadata> createDefaultCameraCharacteristics(
     const std::vector<SupportedStreamConfiguration>& supportedInputConfig,
     const SensorOrientation sensorOrientation, const LensFacing lensFacing,
     const int32_t deviceId) {
-  if (!std::all_of(supportedInputConfig.begin(), supportedInputConfig.end(),
-                   [](const SupportedStreamConfiguration& config) {
-                     return isFormatSupportedForInput(
-                         config.width, config.height, config.pixelFormat,
-                         config.maxFps);
-                   })) {
-    ALOGE("%s: input configuration contains unsupported format", __func__);
-    return std::nullopt;
-  }
-
   MetadataBuilder builder =
       MetadataBuilder()
           .setSupportedHardwareLevel(
@@ -359,7 +353,7 @@ std::optional<CameraMetadata> initCameraCharacteristics(
   std::optional<Resolution> maxResolution =
       getMaxResolution(supportedInputConfig);
   if (!maxResolution.has_value()) {
-    return std::nullopt;
+    return nullptr;
   }
   builder.setSensorActiveArraySize(0, 0, maxResolution->width,
                                    maxResolution->height);
@@ -392,13 +386,51 @@ std::optional<CameraMetadata> initCameraCharacteristics(
   ALOGV("Adding %zu output configurations", outputConfigurations.size());
   builder.setAvailableOutputStreamConfigurations(outputConfigurations);
 
-  auto metadata = builder.setAvailableCharacteristicKeys().build();
-  if (metadata == nullptr) {
+  return builder.setAvailableCharacteristicKeys().build();
+}
+
+std::optional<AidlCameraMetadata> initCameraCharacteristics(
+    const std::vector<SupportedStreamConfiguration>& supportedInputConfig,
+    const SensorOrientation sensorOrientation, const LensFacing lensFacing,
+    const std::optional<VirtualCameraMetadata>& configCameraCharacteristics,
+    const int32_t deviceId) {
+  if (!std::all_of(supportedInputConfig.begin(), supportedInputConfig.end(),
+                   [](const SupportedStreamConfiguration& config) {
+                     return isFormatSupportedForInput(
+                         config.width, config.height, config.pixelFormat,
+                         config.maxFps);
+                   })) {
+    ALOGE("%s: input configuration contains unsupported format", __func__);
+    return std::nullopt;
+  }
+
+  std::unique_ptr<AidlCameraMetadata> aidlMetadata;
+  // If the camera metadata is set by the VD owner, add the deviceId and pass it as it is
+  if (configCameraCharacteristics.has_value()) {
+    ALOGD("VirtualCameraDevice - using config CameraCharacteristics");
+
+    auto deviceIdVec = std::vector<int32_t>({deviceId});
+    const auto configMetadata = reinterpret_cast<const camera_metadata_t*>(
+        configCameraCharacteristics.value().metadata.data());
+
+    HelperCameraMetadata metadataHelper =
+        HelperCameraMetadata(clone_camera_metadata(configMetadata));
+    metadataHelper.update(ANDROID_INFO_DEVICE_ID, deviceIdVec.data(),
+                          deviceIdVec.size());
+
+    aidlMetadata = cameraMetadataToHal(metadataHelper);
+  } else {
+    ALOGD("VirtualCameraDevice - createDefaultCameraCharacteristics");
+    aidlMetadata = createDefaultCameraCharacteristics(
+        supportedInputConfig, sensorOrientation, lensFacing, deviceId);
+  }
+
+  if (aidlMetadata == nullptr) {
     ALOGE("Failed to build metadata!");
-    return CameraMetadata();
+    return AidlCameraMetadata();
   }
 
-  return std::move(*metadata);
+  return std::move(*aidlMetadata);
 }
 
 }  // namespace
@@ -408,10 +440,14 @@ VirtualCameraDevice::VirtualCameraDevice(
     const VirtualCameraConfiguration& configuration, int32_t deviceId)
     : mCameraId(cameraId),
       mVirtualCameraClientCallback(configuration.virtualCameraCallback),
-      mSupportedInputConfigurations(configuration.supportedStreamConfigs) {
-  std::optional<CameraMetadata> metadata = initCameraCharacteristics(
+      mSupportedInputConfigurations(configuration.supportedStreamConfigs),
+      mPerFrameCameraMetadataEnabled(
+          configuration.perFrameCameraMetadataEnabled),
+      mConfigCameraCharacteristics(configuration.cameraCharacteristics) {
+  std::optional<AidlCameraMetadata> metadata = initCameraCharacteristics(
       mSupportedInputConfigurations, configuration.sensorOrientation,
-      configuration.lensFacing, deviceId);
+      configuration.lensFacing, mConfigCameraCharacteristics, deviceId);
+
   if (metadata.has_value()) {
     mCameraCharacteristics = *metadata;
   } else {
@@ -423,7 +459,7 @@ VirtualCameraDevice::VirtualCameraDevice(
 }
 
 ndk::ScopedAStatus VirtualCameraDevice::getCameraCharacteristics(
-    CameraMetadata* _aidl_return) {
+    AidlCameraMetadata* _aidl_return) {
   ALOGV("%s", __func__);
   if (_aidl_return == nullptr) {
     return cameraStatus(Status::ILLEGAL_ARGUMENT);
@@ -434,7 +470,7 @@ ndk::ScopedAStatus VirtualCameraDevice::getCameraCharacteristics(
 }
 
 ndk::ScopedAStatus VirtualCameraDevice::getPhysicalCameraCharacteristics(
-    const std::string& in_physicalCameraId, CameraMetadata* _aidl_return) {
+    const std::string& in_physicalCameraId, AidlCameraMetadata* _aidl_return) {
   ALOGV("%s: physicalCameraId %s", __func__, in_physicalCameraId.c_str());
   (void)_aidl_return;
 
@@ -551,6 +587,12 @@ ndk::ScopedAStatus VirtualCameraDevice::open(
   *_aidl_return = ndk::SharedRefBase::make<VirtualCameraSession>(
       sharedFromThis(), in_callback, mVirtualCameraClientCallback);
 
+  if (virtualdevice::flags::virtual_camera_on_open()) {
+    if (mVirtualCameraClientCallback != nullptr) {
+      mVirtualCameraClientCallback->onOpenCamera();
+    }
+  }
+
   return ndk::ScopedAStatus::ok();
 };
 
diff --git a/services/camera/virtualcamera/VirtualCameraDevice.h b/services/camera/virtualcamera/VirtualCameraDevice.h
index a33d4cfbaf..015f71e085 100644
--- a/services/camera/virtualcamera/VirtualCameraDevice.h
+++ b/services/camera/virtualcamera/VirtualCameraDevice.h
@@ -154,6 +154,10 @@ class VirtualCameraDevice
       aidl::android::companion::virtualcamera::SupportedStreamConfiguration>
       mSupportedInputConfigurations;
 
+  [[maybe_unused]] const bool mPerFrameCameraMetadataEnabled;
+  std::optional<::aidl::android::companion::virtualcamera::VirtualCameraMetadata>
+      mConfigCameraCharacteristics;
+
   std::atomic_int mNextInputStreamId;
 };
 
diff --git a/services/camera/virtualcamera/VirtualCameraRenderThread.cc b/services/camera/virtualcamera/VirtualCameraRenderThread.cc
index 3c757637cc..c7daeb82dd 100644
--- a/services/camera/virtualcamera/VirtualCameraRenderThread.cc
+++ b/services/camera/virtualcamera/VirtualCameraRenderThread.cc
@@ -103,6 +103,9 @@ static constexpr UpdateTextureTask kUpdateTextureTask;
 
 // The number of nanosecond to wait for the first frame to be drawn on the input surface
 static constexpr std::chrono::nanoseconds kMaxWaitFirstFrame = 3s;
+// The number of nanosecond to wait for a frame for use cases where frame
+// duplication is not an option.
+static constexpr std::chrono::nanoseconds kMaxWaitNoDuplication = 60s;
 
 static constexpr double kOneSecondInNanos = 1e9;
 
@@ -174,6 +177,22 @@ bool isYuvFormat(const PixelFormat pixelFormat) {
   }
 }
 
+// By default, virtual camera will duplicate the last frame if the producer does
+// not post a new frame. When a frame is duplicated, the timestamp must still
+// increase to please the camera framework expectations. In some usecases, this
+// frame duplication is not wanted, like for motion tracking, where the
+// timestamp must match the graphic data.
+bool allowFrameDuplication(const RequestSettings& requestSettings) {
+  if (!flags::virtual_camera_no_frame_duplication()) {
+    return true;
+  }
+  if (requestSettings.captureIntent == ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW) {
+    return true;
+  }
+
+  return false;
+}
+
 std::vector<uint8_t> createExif(
     Resolution imageSize, const CameraMetadata resultMetadata,
     const std::vector<uint8_t>& compressedThumbnail = {}) {
@@ -215,11 +234,26 @@ std::vector<uint8_t> createExif(
 }
 
 std::chrono::nanoseconds getMaxFrameDuration(
-    const RequestSettings& requestSettings) {
-  if (requestSettings.fpsRange.has_value()) {
+    const RequestSettings& requestSettings, bool isFirstFrameDrawn) {
+  // If it's not the first frame and the request specify a FPS, return the minFps
+  if (isFirstFrameDrawn && requestSettings.fpsRange.has_value()) {
     return std::chrono::nanoseconds(static_cast<uint64_t>(
         kOneSecondInNanos / std::max(1, requestSettings.fpsRange->minFps)));
   }
+
+  // If the request does not specify a FPS and we should not duplicate frames,
+  // wait as much as we can
+  if (!allowFrameDuplication(requestSettings)) {
+    return kMaxWaitNoDuplication;
+  }
+
+  // If we can duplicate frame but nothing has been drawn on the suface yet, we
+  // allow ourselves to wait a bit longer
+  if (!isFirstFrameDrawn) {
+    return kMaxWaitFirstFrame;
+  }
+
+  // In all other cases we wait for the duration of kMinFps
   return std::chrono::nanoseconds(
       static_cast<uint64_t>(kOneSecondInNanos / VirtualCameraDevice::kMinFps));
 }
@@ -405,66 +439,88 @@ void VirtualCameraRenderThread::threadLoop() {
 
 void VirtualCameraRenderThread::processTask(
     const ProcessCaptureRequestTask& request) {
-  ALOGV("%s request frame number %d", __func__, request.getFrameNumber());
+  ALOGV("%s Request frame number: %d, capture intent %d", __func__,
+        request.getFrameNumber(), request.getRequestSettings().captureIntent);
   std::chrono::nanoseconds deviceTime =
       std::chrono::duration_cast<std::chrono::nanoseconds>(
           std::chrono::steady_clock::now().time_since_epoch());
   const std::chrono::nanoseconds lastAcquisitionTimestamp(
-      mLastAcquisitionTimestampNanoseconds.exchange(deviceTime.count(),
-                                                    std::memory_order_relaxed));
+      mLastAcquisitionTimestampNanoseconds.load(std::memory_order_relaxed));
 
-  if (request.getRequestSettings().fpsRange) {
-    ALOGV("%s request fps {%d,%d}", __func__,
-          request.getRequestSettings().fpsRange->minFps,
-          request.getRequestSettings().fpsRange->maxFps);
-    int maxFps = std::max(1, request.getRequestSettings().fpsRange->maxFps);
-    deviceTime = throttleRendering(maxFps, lastAcquisitionTimestamp, deviceTime);
-  }
+  ALOGV("lastAcquisitionTimestamp %lld", lastAcquisitionTimestamp.count());
 
   // Calculate the maximal amount of time we can afford to wait for next frame.
   const bool isFirstFrameDrawn = mEglSurfaceTexture->isFirstFrameDrawn();
   ALOGV("First Frame Drawn: %s", isFirstFrameDrawn ? "Yes" : "No");
 
-  const std::chrono::nanoseconds maxFrameDuration =
-      isFirstFrameDrawn ? getMaxFrameDuration(request.getRequestSettings())
-                        : kMaxWaitFirstFrame;
-  const std::chrono::nanoseconds elapsedDuration =
-      isFirstFrameDrawn ? deviceTime - lastAcquisitionTimestamp : 0ns;
-
-  if (elapsedDuration < maxFrameDuration) {
+  std::chrono::nanoseconds maxFrameDuration =
+      getMaxFrameDuration(request.getRequestSettings(), isFirstFrameDrawn);
+  std::chrono::nanoseconds elapsedDuration =
+      isFirstFrameDrawn && lastAcquisitionTimestamp > 0ns
+          ? deviceTime - lastAcquisitionTimestamp
+          : 0ns;
+
+  bool gotNewFrame = false;
+  const std::chrono::nanoseconds waitTime =
+      std::max(0ns, maxFrameDuration - elapsedDuration);
+  ALOGV("maxFrameDuration %lld, elapsedDuration %lld, waitTime %lld",
+        maxFrameDuration.count(), elapsedDuration.count(), waitTime.count());
+  if (waitTime > 0ns) {
     // We can afford to wait for next frame.
     // Note that if there's already new frame in the input Surface, the call
-    // below returns immediatelly.
-    bool gotNewFrame = mEglSurfaceTexture->waitForNextFrame(maxFrameDuration -
-                                                            elapsedDuration);
-    deviceTime = std::chrono::duration_cast<std::chrono::nanoseconds>(
-        std::chrono::steady_clock::now().time_since_epoch());
-    if (!gotNewFrame) {
-      if (!mEglSurfaceTexture->isFirstFrameDrawn()) {
-        // We don't have any input ever drawn. This is considered as an error
-        // case. Notify the framework of the failure and return early.
-        ALOGW("Timed out waiting for first frame to be drawn.");
-        std::unique_ptr<CaptureResult> captureResult = createCaptureResult(
-            request.getFrameNumber(), /* metadata = */ nullptr);
-        notifyTimeout(request, *captureResult);
-        submitCaptureResult(std::move(captureResult));
-        return;
-      }
-
-      ALOGV(
-          "%s: No new frame received on input surface after waiting for "
-          "%" PRIu64 "ns, repeating last frame.",
-          __func__,
-          static_cast<uint64_t>(
-              (deviceTime - lastAcquisitionTimestamp).count()));
+    // below returns immediately.
+    gotNewFrame = mEglSurfaceTexture->waitForNextFrame(waitTime);
+  }
+
+  if (!gotNewFrame) {
+    ALOGV(
+        "%s: No new frame received on input surface after waiting for "
+        "%.3f s",
+        __func__, static_cast<uint64_t>(waitTime.count()) / kOneSecondInNanos);
+
+    if (!allowFrameDuplication(request.getRequestSettings()) ||
+        !mEglSurfaceTexture->isFirstFrameDrawn()) {
+      // We don't have any input ever drawn. This is considered as an error
+      // case. Notify the framework of the failure and return early.
+      ALOGW("Timed out waiting for frame to be posted.");
+      std::unique_ptr<CaptureResult> captureResult = createCaptureResult(
+          request.getFrameNumber(), /* metadata = */ nullptr);
+      notifyTimeout(request, *captureResult);
+      submitCaptureResult(std::move(captureResult));
+      return;
     }
-    mLastAcquisitionTimestampNanoseconds.store(deviceTime.count(),
-                                               std::memory_order_relaxed);
   }
+
+  // If the request has a maxFps, we throttle the rendering to make sure that
+  // the requester receives the latest frame that was posted by the virtual
+  // camera in the interval :
+  //  [last acquisition time, last acquisition time + maxFps].
+  //
+  // So if the virtual camera renders faster than the requested frame, the
+  // requester won't be receiving unnecessary frames.
+  if (request.getRequestSettings().fpsRange) {
+    ALOGV("%s request fps {%d,%d}", __func__,
+          request.getRequestSettings().fpsRange->minFps,
+          request.getRequestSettings().fpsRange->maxFps);
+    int maxFps = std::max(1, request.getRequestSettings().fpsRange->maxFps);
+    throttleRendering(maxFps, lastAcquisitionTimestamp);
+  }
+
   // Acquire new (most recent) image from the Surface.
   mEglSurfaceTexture->updateTexture();
-  std::chrono::nanoseconds captureTimestamp = deviceTime;
 
+  // Now that throttling and waiting have been done, update the acquisition timestamp.
+  deviceTime = std::chrono::duration_cast<std::chrono::nanoseconds>(
+      std::chrono::steady_clock::now().time_since_epoch());
+
+  elapsedDuration = isFirstFrameDrawn && lastAcquisitionTimestamp > 0ns
+                        ? deviceTime - lastAcquisitionTimestamp
+                        : 0ns;
+
+  mLastAcquisitionTimestampNanoseconds.store(deviceTime.count(),
+                                             std::memory_order_relaxed);
+
+  std::chrono::nanoseconds captureTimestamp = deviceTime;
   if (flags::camera_timestamp_from_surface()) {
     std::chrono::nanoseconds surfaceTimestamp =
         getSurfaceTimestamp(elapsedDuration);
@@ -490,13 +546,19 @@ void VirtualCameraRenderThread::processTask(
           status.getDescription().c_str());
     return;
   }
-
   submitCaptureResult(std::move(captureResult));
 }
 
-std::chrono::nanoseconds VirtualCameraRenderThread::throttleRendering(
-    int maxFps, std::chrono::nanoseconds lastAcquisitionTimestamp,
-    std::chrono::nanoseconds timestamp) {
+void VirtualCameraRenderThread::throttleRendering(
+    int maxFps, std::chrono::nanoseconds lastAcquisitionTimestamp) {
+  if (lastAcquisitionTimestamp <= 0ns) {
+    // It's our first request, there is nothing to throttle.
+    return;
+  }
+  std::chrono::nanoseconds timestamp =
+      std::chrono::duration_cast<std::chrono::nanoseconds>(
+          std::chrono::steady_clock::now().time_since_epoch());
+
   const std::chrono::nanoseconds minFrameDuration(
       static_cast<uint64_t>(1e9 / maxFps));
   const std::chrono::nanoseconds frameDuration =
@@ -504,7 +566,7 @@ std::chrono::nanoseconds VirtualCameraRenderThread::throttleRendering(
   if (frameDuration < minFrameDuration) {
     // We're too fast for the configured maxFps, let's wait a bit.
     const std::chrono::nanoseconds sleepTime = minFrameDuration - frameDuration;
-    ALOGV("Current frame duration would  be %" PRIu64
+    ALOGV("Current frame duration would be %" PRIu64
           " ns corresponding to %.3f Fps, "
           "sleeping for %" PRIu64
           " ns before updating texture to match maxFps %d",
@@ -512,13 +574,22 @@ std::chrono::nanoseconds VirtualCameraRenderThread::throttleRendering(
           nanosToFps(frameDuration), static_cast<uint64_t>(sleepTime.count()),
           maxFps);
 
+    std::chrono::nanoseconds beforeSleep =
+        std::chrono::duration_cast<std::chrono::nanoseconds>(
+            std::chrono::steady_clock::now().time_since_epoch());
     std::this_thread::sleep_for(sleepTime);
-    timestamp = std::chrono::duration_cast<std::chrono::nanoseconds>(
-        std::chrono::steady_clock::now().time_since_epoch());
-    mLastAcquisitionTimestampNanoseconds.store(timestamp.count(),
-                                               std::memory_order_relaxed);
+    std::chrono::nanoseconds after_sleep =
+        std::chrono::duration_cast<std::chrono::nanoseconds>(
+            std::chrono::steady_clock::now().time_since_epoch());
+    ALOGV("actual sleep time %lld (%.3f)", (after_sleep - beforeSleep).count(),
+          nanosToFps(after_sleep - lastAcquisitionTimestamp));
+  } else {
+    ALOGV("Current frame is %" PRIu64
+          " ns corresponding to %.3f Fps, "
+          "no need to sleep to match maxFps %d",
+          static_cast<uint64_t>(frameDuration.count()),
+          nanosToFps(frameDuration), maxFps);
   }
-  return timestamp;
 }
 
 std::chrono::nanoseconds VirtualCameraRenderThread::getSurfaceTimestamp(
@@ -569,6 +640,9 @@ void VirtualCameraRenderThread::renderOutputBuffers(
     resBuffer.bufferId = reqBuffer.getBufferId();
     resBuffer.status = BufferStatus::OK;
 
+    ALOGV("%s : rendering buffer %" PRId64 " for stream id %" PRId32, __func__,
+          resBuffer.bufferId, resBuffer.streamId);
+
     const std::optional<Stream> streamConfig =
         mSessionContext.getStreamConfig(reqBuffer.getStreamId());
 
diff --git a/services/camera/virtualcamera/VirtualCameraRenderThread.h b/services/camera/virtualcamera/VirtualCameraRenderThread.h
index 4cad39e4be..047e3d948f 100644
--- a/services/camera/virtualcamera/VirtualCameraRenderThread.h
+++ b/services/camera/virtualcamera/VirtualCameraRenderThread.h
@@ -29,7 +29,6 @@
 #include <vector>
 
 #include "VirtualCameraCaptureRequest.h"
-#include "VirtualCameraDevice.h"
 #include "VirtualCameraSessionContext.h"
 #include "aidl/android/hardware/camera/device/CameraMetadata.h"
 #include "aidl/android/hardware/camera/device/ICameraDeviceCallback.h"
@@ -191,14 +190,11 @@ class VirtualCameraRenderThread {
       std::optional<Rect> viewport = std::nullopt);
 
   // Throttle the current thread to ensure that we are not rendering faster than
-  // the provided maxFps.
+  // the virtual camera maxFps.
   // maxFps: The maximum fps in the capture request
   // lastAcquisitionTimestamp: timestamp of the previous frame
-  // timestamp: the current capture time
-  // Returns the time at which the capture has happened after throttling.
-  std::chrono::nanoseconds throttleRendering(
-      int maxFps, std::chrono::nanoseconds lastAcquisitionTimestamp,
-      std::chrono::nanoseconds timestamp);
+  void throttleRendering(int maxFps,
+                         std::chrono::nanoseconds lastAcquisitionTimestamp);
 
   // Fetch the timestamp of the latest buffer from the EGL Surface
   // timeSinceLastFrame: The elapsed time since the last captured frame.
diff --git a/services/camera/virtualcamera/VirtualCameraService.cc b/services/camera/virtualcamera/VirtualCameraService.cc
index 18bebdeba7..c9f107263d 100644
--- a/services/camera/virtualcamera/VirtualCameraService.cc
+++ b/services/camera/virtualcamera/VirtualCameraService.cc
@@ -119,19 +119,28 @@ ndk::ScopedAStatus validateConfiguration(
     }
   }
 
-  if (configuration.sensorOrientation != SensorOrientation::ORIENTATION_0 &&
-      configuration.sensorOrientation != SensorOrientation::ORIENTATION_90 &&
-      configuration.sensorOrientation != SensorOrientation::ORIENTATION_180 &&
-      configuration.sensorOrientation != SensorOrientation::ORIENTATION_270) {
-    return ndk::ScopedAStatus::fromServiceSpecificError(
-        Status::EX_ILLEGAL_ARGUMENT);
-  }
+  // validate separate lens facing and sensor orientation only if config
+  // CameraCharacteristics is not set
+  if (!configuration.cameraCharacteristics.has_value()) {
+    if (configuration.sensorOrientation != SensorOrientation::ORIENTATION_0 &&
+        configuration.sensorOrientation != SensorOrientation::ORIENTATION_90 &&
+        configuration.sensorOrientation != SensorOrientation::ORIENTATION_180 &&
+        configuration.sensorOrientation != SensorOrientation::ORIENTATION_270) {
+      ALOGE(
+          "%s: Sensor orientation not set and no config CameraCharacteristics",
+          __func__);
+      return ndk::ScopedAStatus::fromServiceSpecificError(
+          Status::EX_ILLEGAL_ARGUMENT);
+    }
 
-  if (configuration.lensFacing != LensFacing::FRONT &&
-      configuration.lensFacing != LensFacing::BACK &&
-      configuration.lensFacing != LensFacing::EXTERNAL) {
-    return ndk::ScopedAStatus::fromServiceSpecificError(
-        Status::EX_ILLEGAL_ARGUMENT);
+    if (configuration.lensFacing != LensFacing::FRONT &&
+        configuration.lensFacing != LensFacing::BACK &&
+        configuration.lensFacing != LensFacing::EXTERNAL) {
+      ALOGE("%s: Lens facing not set and no config CameraCharacteristics",
+            __func__);
+      return ndk::ScopedAStatus::fromServiceSpecificError(
+          Status::EX_ILLEGAL_ARGUMENT);
+    }
   }
 
   return ndk::ScopedAStatus::ok();
diff --git a/services/camera/virtualcamera/VirtualCameraSession.cc b/services/camera/virtualcamera/VirtualCameraSession.cc
index a01889a739..146d2f9c57 100644
--- a/services/camera/virtualcamera/VirtualCameraSession.cc
+++ b/services/camera/virtualcamera/VirtualCameraSession.cc
@@ -188,7 +188,8 @@ HalStream getHalStream(const Stream& stream) {
   halStream.producerUsage = static_cast<BufferUsage>(
       static_cast<int64_t>(stream.usage) |
       static_cast<int64_t>(BufferUsage::CAMERA_OUTPUT) |
-      static_cast<int64_t>(BufferUsage::GPU_RENDER_TARGET));
+      static_cast<int64_t>(BufferUsage::GPU_RENDER_TARGET) |
+      static_cast<int64_t>(BufferUsage::CPU_WRITE_OFTEN));
 
   halStream.supportOffline = false;
   return halStream;
diff --git a/services/camera/virtualcamera/VirtualCameraTestInstance.cc b/services/camera/virtualcamera/VirtualCameraTestInstance.cc
index ff4a2d80d8..7494d364c5 100644
--- a/services/camera/virtualcamera/VirtualCameraTestInstance.cc
+++ b/services/camera/virtualcamera/VirtualCameraTestInstance.cc
@@ -119,6 +119,10 @@ VirtualCameraTestInstance::VirtualCameraTestInstance(const int fps)
     : mFps(fps) {
 }
 
+ScopedAStatus VirtualCameraTestInstance::onOpenCamera() {
+  return ScopedAStatus::ok();
+}
+
 ScopedAStatus VirtualCameraTestInstance::onStreamConfigured(
     const int32_t streamId, const Surface& surface, const int32_t width,
     const int32_t height, const Format pixelFormat) {
diff --git a/services/camera/virtualcamera/VirtualCameraTestInstance.h b/services/camera/virtualcamera/VirtualCameraTestInstance.h
index c130645a3b..1ae395f8b9 100644
--- a/services/camera/virtualcamera/VirtualCameraTestInstance.h
+++ b/services/camera/virtualcamera/VirtualCameraTestInstance.h
@@ -65,6 +65,8 @@ class VirtualCameraTestInstance
  public:
   explicit VirtualCameraTestInstance(int fps = 30);
 
+  ::ndk::ScopedAStatus onOpenCamera();
+
   ::ndk::ScopedAStatus onStreamConfigured(
       int32_t streamId, const ::aidl::android::view::Surface& surface,
       int32_t width, int32_t height,
diff --git a/services/camera/virtualcamera/aidl/Android.bp b/services/camera/virtualcamera/aidl/Android.bp
index b3c0bce0f7..a647e575a9 100644
--- a/services/camera/virtualcamera/aidl/Android.bp
+++ b/services/camera/virtualcamera/aidl/Android.bp
@@ -9,12 +9,13 @@ aidl_interface {
     unstable: true,
     srcs: [
         "android/companion/virtualcamera/Format.aidl",
-        "android/companion/virtualcamera/LensFacing.aidl",
         "android/companion/virtualcamera/IVirtualCameraCallback.aidl",
         "android/companion/virtualcamera/IVirtualCameraService.aidl",
-        "android/companion/virtualcamera/VirtualCameraConfiguration.aidl",
+        "android/companion/virtualcamera/LensFacing.aidl",
         "android/companion/virtualcamera/SensorOrientation.aidl",
         "android/companion/virtualcamera/SupportedStreamConfiguration.aidl",
+        "android/companion/virtualcamera/VirtualCameraConfiguration.aidl",
+        "android/companion/virtualcamera/VirtualCameraMetadata.aidl",
     ],
     local_include_dir: ".",
     include_dirs: [
diff --git a/services/camera/virtualcamera/aidl/android/companion/virtualcamera/IVirtualCameraCallback.aidl b/services/camera/virtualcamera/aidl/android/companion/virtualcamera/IVirtualCameraCallback.aidl
index f5a84f731d..e8fb35d399 100644
--- a/services/camera/virtualcamera/aidl/android/companion/virtualcamera/IVirtualCameraCallback.aidl
+++ b/services/camera/virtualcamera/aidl/android/companion/virtualcamera/IVirtualCameraCallback.aidl
@@ -25,6 +25,20 @@ import android.view.Surface;
  */
 oneway interface IVirtualCameraCallback {
 
+    /**
+     * Called when the client application calls
+     * {@link android.hardware.camera2.CameraManager#openCamera}. This is the earliest signal that
+     * this camera will be used. At this point, no stream is opened yet, nor any configuration took
+     * place. The owner of the virtual camera can use this as signal to prepare the camera and
+     * reduce latency for when
+     * {@link android.hardware.camera2.CameraDevice#createCaptureSession(SessionConfiguration)} is
+     * called and before
+     * {@link
+     * android.hardware.camera2.CameraCaptureSession.StateCallback#onConfigured(CameraCaptureSession)}
+     * is called.
+     */
+    oneway void onOpenCamera();
+
     /**
      * Called when there's new video stream. This callback is send after clients opens and
      * configures camera. Implementation should hold onto the surface until corresponding
diff --git a/services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraConfiguration.aidl b/services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraConfiguration.aidl
index 887ad26ed4..41f765a543 100644
--- a/services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraConfiguration.aidl
+++ b/services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraConfiguration.aidl
@@ -20,6 +20,7 @@ import android.companion.virtualcamera.IVirtualCameraCallback;
 import android.companion.virtualcamera.LensFacing;
 import android.companion.virtualcamera.SensorOrientation;
 import android.companion.virtualcamera.SupportedStreamConfiguration;
+import android.companion.virtualcamera.VirtualCameraMetadata;
 
 /**
  * Configuration of virtual camera instance.
@@ -31,4 +32,6 @@ parcelable VirtualCameraConfiguration {
     IVirtualCameraCallback virtualCameraCallback;
     SensorOrientation sensorOrientation = SensorOrientation.ORIENTATION_0;
     LensFacing lensFacing;
+    boolean perFrameCameraMetadataEnabled;
+    @nullable VirtualCameraMetadata cameraCharacteristics;
 }
diff --git a/media/codec2/hal/hidl/1.2/utils/InputSurfaceConnection.cpp b/services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraMetadata.aidl
similarity index 53%
rename from media/codec2/hal/hidl/1.2/utils/InputSurfaceConnection.cpp
rename to services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraMetadata.aidl
index 1bd58c2eaf..10b0100e24 100644
--- a/media/codec2/hal/hidl/1.2/utils/InputSurfaceConnection.cpp
+++ b/services/camera/virtualcamera/aidl/android/companion/virtualcamera/VirtualCameraMetadata.aidl
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 The Android Open Source Project
+ * Copyright 2025 The Android Open Source Project
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
@@ -14,4 +14,18 @@
  * limitations under the License.
  */
 
-#include <codec2/hidl/1.2/InputSurfaceConnection.h>
+package android.companion.virtualcamera;
+
+/**
+ * Wrapper parcelable for CameraMetadata.
+ * Forked from hardware/interfaces/camera/device/aidl/android/hardware/camera/device/CameraMetadata.aidl
+ *
+ * @hide
+ */
+parcelable VirtualCameraMetadata {
+    /**
+     * A serialized metadata buffer created by libcamera_metadata.
+     * Access by casting to a camera_metadata* and using libcamera_metadata methods
+     */
+    byte[] metadata;
+}
diff --git a/services/camera/virtualcamera/tests/JpegUtilTest.cc b/services/camera/virtualcamera/tests/JpegUtilTest.cc
index e6481f00ac..f50d6cd169 100644
--- a/services/camera/virtualcamera/tests/JpegUtilTest.cc
+++ b/services/camera/virtualcamera/tests/JpegUtilTest.cc
@@ -47,14 +47,16 @@ constexpr int kJpegQuality = 80;
 // Create black YUV420 buffer for testing purposes.
 std::shared_ptr<AHardwareBuffer> createHardwareBufferForTest(const int width,
                                                              const int height) {
-  const AHardwareBuffer_Desc desc{.width = static_cast<uint32_t>(width),
-                                  .height = static_cast<uint32_t>(height),
-                                  .layers = 1,
-                                  .format = AHARDWAREBUFFER_FORMAT_Y8Cb8Cr8_420,
-                                  .usage = AHARDWAREBUFFER_USAGE_CPU_WRITE_OFTEN,
-                                  .stride = 0,
-                                  .rfu0 = 0,
-                                  .rfu1 = 0};
+  const AHardwareBuffer_Desc desc{
+      .width = static_cast<uint32_t>(width),
+      .height = static_cast<uint32_t>(height),
+      .layers = 1,
+      .format = AHARDWAREBUFFER_FORMAT_Y8Cb8Cr8_420,
+      .usage = AHARDWAREBUFFER_USAGE_CPU_WRITE_OFTEN |
+               AHARDWAREBUFFER_USAGE_CPU_READ_OFTEN,
+      .stride = 0,
+      .rfu0 = 0,
+      .rfu1 = 0};
 
   AHardwareBuffer* hwBufferPtr;
   int status = AHardwareBuffer_allocate(&desc, &hwBufferPtr);
diff --git a/services/camera/virtualcamera/tests/VirtualCameraServiceTest.cc b/services/camera/virtualcamera/tests/VirtualCameraServiceTest.cc
index 72e03dea0b..f8771bd175 100644
--- a/services/camera/virtualcamera/tests/VirtualCameraServiceTest.cc
+++ b/services/camera/virtualcamera/tests/VirtualCameraServiceTest.cc
@@ -79,6 +79,7 @@ const VirtualCameraConfiguration kEmptyVirtualCameraConfiguration;
 
 class MockVirtualCameraCallback : public BnVirtualCameraCallback {
  public:
+  MOCK_METHOD(ndk::ScopedAStatus, onOpenCamera, (), (override));
   MOCK_METHOD(ndk::ScopedAStatus, onStreamConfigured,
               (int32_t, const ::aidl::android::view::Surface&, int, int,
                ::aidl::android::companion::virtualcamera::Format pixelFormat),
diff --git a/services/camera/virtualcamera/tests/VirtualCameraSessionTest.cc b/services/camera/virtualcamera/tests/VirtualCameraSessionTest.cc
index 1494643d32..494f49e2ff 100644
--- a/services/camera/virtualcamera/tests/VirtualCameraSessionTest.cc
+++ b/services/camera/virtualcamera/tests/VirtualCameraSessionTest.cc
@@ -100,6 +100,7 @@ class MockCameraDeviceCallback : public BnCameraDeviceCallback {
 
 class MockVirtualCameraCallback : public BnVirtualCameraCallback {
  public:
+  MOCK_METHOD(ndk::ScopedAStatus, onOpenCamera, (), (override));
   MOCK_METHOD(ndk::ScopedAStatus, onStreamConfigured,
               (int, const Surface&, int32_t, int32_t, Format), (override));
   MOCK_METHOD(ndk::ScopedAStatus, onProcessCaptureRequest, (int, int),
diff --git a/services/camera/virtualcamera/util/EglFramebuffer.cc b/services/camera/virtualcamera/util/EglFramebuffer.cc
index 57b94d337f..c3e51b9aa9 100644
--- a/services/camera/virtualcamera/util/EglFramebuffer.cc
+++ b/services/camera/virtualcamera/util/EglFramebuffer.cc
@@ -82,7 +82,7 @@ EglFrameBuffer::~EglFrameBuffer() {
     glDeleteTextures(1, &mTextureId);
   }
   if (mEglImageKhr != EGL_NO_IMAGE_KHR) {
-    eglDestroyImageKHR(mEglDisplay, mEglDisplay);
+    eglDestroyImageKHR(mEglDisplay, mEglImageKhr);
   }
 }
 
diff --git a/services/camera/virtualcamera/util/EglSurfaceTexture.cc b/services/camera/virtualcamera/util/EglSurfaceTexture.cc
index 44da9b4910..4aebaa2cc1 100644
--- a/services/camera/virtualcamera/util/EglSurfaceTexture.cc
+++ b/services/camera/virtualcamera/util/EglSurfaceTexture.cc
@@ -53,8 +53,6 @@ void EglSurfaceTexture::FrameAvailableListenerProxy::setCallback(
 
 void EglSurfaceTexture::FrameAvailableListenerProxy::onFrameAvailable(
     const BufferItem&) {
-  long frameNumber = mSurface.mGlConsumer->getFrameNumber();
-  ALOGV("%s: onFrameAvailable frameNumber %ld", __func__, frameNumber);
   mSurface.mFrameAvailableCondition.notify_all();
   if (mOnFrameAvailableCallback) {
     mOnFrameAvailableCallback();
diff --git a/services/camera/virtualcamera/util/JpegUtil.cc b/services/camera/virtualcamera/util/JpegUtil.cc
index b0345845a3..309d937636 100644
--- a/services/camera/virtualcamera/util/JpegUtil.cc
+++ b/services/camera/virtualcamera/util/JpegUtil.cc
@@ -95,6 +95,10 @@ class LibJpegContext {
     mCompressStruct.comp_info[2].v_samp_factor = 1;
   }
 
+  ~LibJpegContext() {
+    jpeg_destroy_compress(&mCompressStruct);
+  }
+
   LibJpegContext& setApp1Data(const uint8_t* app1Data, const size_t size) {
     mApp1Data = app1Data;
     mApp1DataSize = size;
diff --git a/services/camera/virtualcamera/util/MetadataUtil.cc b/services/camera/virtualcamera/util/MetadataUtil.cc
index 4889830a64..f1d436e083 100644
--- a/services/camera/virtualcamera/util/MetadataUtil.cc
+++ b/services/camera/virtualcamera/util/MetadataUtil.cc
@@ -42,7 +42,10 @@ namespace virtualcamera {
 
 namespace {
 
-using ::android::hardware::camera::common::helper::CameraMetadata;
+using AidlCameraMetadata =
+    ::aidl::android::hardware::camera::device::CameraMetadata;
+using HelperCameraMetadata =
+    ::android::hardware::camera::common::helper::CameraMetadata;
 
 template <typename To, typename From>
 std::vector<To> convertTo(const std::vector<From>& from) {
@@ -731,8 +734,7 @@ MetadataBuilder& MetadataBuilder::setAvailableCharacteristicKeys() {
   return *this;
 }
 
-std::unique_ptr<aidl::android::hardware::camera::device::CameraMetadata>
-MetadataBuilder::build() {
+std::unique_ptr<AidlCameraMetadata> MetadataBuilder::build() {
   if (mExtendWithAvailableCharacteristicsKeys) {
     std::vector<camera_metadata_tag_t> availableKeys;
     availableKeys.reserve(mEntryMap.size());
@@ -744,7 +746,7 @@ MetadataBuilder::build() {
     setAvailableCharacteristicKeys(availableKeys);
   }
 
-  CameraMetadata metadataHelper;
+  HelperCameraMetadata metadataHelper;
   for (const auto& entry : mEntryMap) {
     status_t ret = std::visit(
         [&](auto&& arg) {
@@ -759,26 +761,10 @@ MetadataBuilder::build() {
     }
   }
 
-  const camera_metadata_t* metadata = metadataHelper.getAndLock();
-  if (metadata == nullptr) {
-    ALOGE(
-        "Failure when constructing metadata -> CameraMetadata helper returned "
-        "nullptr");
-    return nullptr;
-  }
-
-  auto aidlMetadata =
-      std::make_unique<aidl::android::hardware::camera::device::CameraMetadata>();
-  const uint8_t* data_ptr = reinterpret_cast<const uint8_t*>(metadata);
-  aidlMetadata->metadata.assign(data_ptr,
-                                data_ptr + get_camera_metadata_size(metadata));
-  metadataHelper.unlock(metadata);
-
-  return aidlMetadata;
+  return cameraMetadataToHal(metadataHelper);
 }
 
-std::optional<int32_t> getJpegQuality(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+std::optional<int32_t> getJpegQuality(const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -791,8 +777,7 @@ std::optional<int32_t> getJpegQuality(
   return *entry.data.i32;
 }
 
-int32_t getJpegOrientation(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+int32_t getJpegOrientation(const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -806,7 +791,7 @@ int32_t getJpegOrientation(
 }
 
 std::optional<Resolution> getJpegThumbnailSize(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+    const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -820,7 +805,7 @@ std::optional<Resolution> getJpegThumbnailSize(
 }
 
 std::optional<int32_t> getJpegThumbnailQuality(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+    const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -834,7 +819,7 @@ std::optional<int32_t> getJpegThumbnailQuality(
 }
 
 std::vector<Resolution> getJpegAvailableThumbnailSizes(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+    const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -852,8 +837,7 @@ std::vector<Resolution> getJpegAvailableThumbnailSizes(
   return thumbnailSizes;
 }
 
-std::optional<FpsRange> getFpsRange(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+std::optional<FpsRange> getFpsRange(const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -869,8 +853,7 @@ std::optional<FpsRange> getFpsRange(
 }
 
 std::optional<camera_metadata_enum_android_control_capture_intent>
-getCaptureIntent(const aidl::android::hardware::camera::device::CameraMetadata&
-                     cameraMetadata) {
+getCaptureIntent(const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -885,7 +868,7 @@ getCaptureIntent(const aidl::android::hardware::camera::device::CameraMetadata&
 }
 
 std::optional<GpsCoordinates> getGpsCoordinates(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+    const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -918,7 +901,7 @@ std::optional<GpsCoordinates> getGpsCoordinates(
 }
 
 std::optional<camera_metadata_enum_android_lens_facing> getLensFacing(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+    const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -932,8 +915,7 @@ std::optional<camera_metadata_enum_android_lens_facing> getLensFacing(
 }
 
 std::optional<camera_metadata_enum_android_control_ae_precapture_trigger>
-getPrecaptureTrigger(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+getPrecaptureTrigger(const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -947,8 +929,7 @@ getPrecaptureTrigger(
       entry.data.u8[0]);
 }
 
-std::optional<int32_t> getDeviceId(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+std::optional<int32_t> getDeviceId(const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -962,7 +943,7 @@ std::optional<int32_t> getDeviceId(
 }
 
 std::optional<int32_t> getSensorOrientation(
-    const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata) {
+    const AidlCameraMetadata& cameraMetadata) {
   auto metadata =
       reinterpret_cast<const camera_metadata_t*>(cameraMetadata.metadata.data());
 
@@ -975,6 +956,25 @@ std::optional<int32_t> getSensorOrientation(
   return static_cast<int32_t>(entry.data.i32[0]);
 }
 
+std::unique_ptr<AidlCameraMetadata> cameraMetadataToHal(
+    const HelperCameraMetadata& metadataHelper) {
+  const camera_metadata_t* metadata = metadataHelper.getAndLock();
+  if (metadata == nullptr) {
+    ALOGE(
+        "Failure when constructing metadata -> CameraMetadata helper returned "
+        "nullptr");
+    return nullptr;
+  }
+
+  auto aidlMetadata = std::make_unique<AidlCameraMetadata>();
+  const uint8_t* data_ptr = reinterpret_cast<const uint8_t*>(metadata);
+  aidlMetadata->metadata.assign(data_ptr,
+                                data_ptr + get_camera_metadata_size(metadata));
+  metadataHelper.unlock(metadata);
+
+  return aidlMetadata;
+}
+
 }  // namespace virtualcamera
 }  // namespace companion
 }  // namespace android
diff --git a/services/camera/virtualcamera/util/MetadataUtil.h b/services/camera/virtualcamera/util/MetadataUtil.h
index 22d3657a4a..a09e3d2157 100644
--- a/services/camera/virtualcamera/util/MetadataUtil.h
+++ b/services/camera/virtualcamera/util/MetadataUtil.h
@@ -24,6 +24,7 @@
 #include <variant>
 #include <vector>
 
+#include "CameraMetadata.h"
 #include "aidl/android/hardware/camera/device/CameraMetadata.h"
 #include "system/camera_metadata.h"
 #include "util/Util.h"
@@ -493,6 +494,12 @@ std::optional<int32_t> getDeviceId(
 std::optional<int32_t> getSensorOrientation(
     const aidl::android::hardware::camera::device::CameraMetadata& cameraMetadata);
 
+// Converts a HelperCameraMetadata object to a HAL AidlCameraMetadata.
+std::unique_ptr<aidl::android::hardware::camera::device::CameraMetadata>
+cameraMetadataToHal(
+    const android::hardware::camera::common::helper::CameraMetadata&
+        metadataHelper);
+
 }  // namespace virtualcamera
 }  // namespace companion
 }  // namespace android
diff --git a/services/camera/virtualcamera/util/Util.h b/services/camera/virtualcamera/util/Util.h
index 2225a4b825..1ebcc6d08c 100644
--- a/services/camera/virtualcamera/util/Util.h
+++ b/services/camera/virtualcamera/util/Util.h
@@ -36,7 +36,8 @@ namespace companion {
 namespace virtualcamera {
 
 constexpr int kHardwareBufferUsage = AHARDWAREBUFFER_USAGE_GPU_FRAMEBUFFER |
-                                     AHARDWAREBUFFER_USAGE_CPU_READ_OFTEN;
+                                     AHARDWAREBUFFER_USAGE_CPU_READ_OFTEN |
+                                     AHARDWAREBUFFER_USAGE_CPU_WRITE_OFTEN;
 constexpr int kHardwareBufferFormat = AHARDWAREBUFFER_FORMAT_Y8Cb8Cr8_420;
 
 // RAII utility class to safely lock AHardwareBuffer and obtain android_ycbcr
diff --git a/services/mediacodec/Android.bp b/services/mediacodec/Android.bp
index 506b3bca67..4b694093fe 100644
--- a/services/mediacodec/Android.bp
+++ b/services/mediacodec/Android.bp
@@ -65,6 +65,7 @@ prebuilt_etc {
         },
     },
     required: [
+        "crash_dump.no_mmap_mprotect_prctl.policy",
         "crash_dump.policy",
         "code_coverage.policy",
     ],
diff --git a/services/mediacodec/seccomp_policy/mediaswcodec-arm.policy b/services/mediacodec/seccomp_policy/mediaswcodec-arm.policy
index 92f0745954..b0523d20a4 100644
--- a/services/mediacodec/seccomp_policy/mediaswcodec-arm.policy
+++ b/services/mediacodec/seccomp_policy/mediaswcodec-arm.policy
@@ -15,7 +15,6 @@
 futex: 1
 # ioctl calls are filtered via the selinux policy.
 ioctl: 1
-sched_yield: 1
 close: 1
 dup: 1
 ppoll: 1
@@ -65,26 +64,13 @@ rt_sigreturn: 1
 getrandom: 1
 madvise: 1
 
-# crash dump policy additions
-sigreturn: 1
-clock_gettime: 1
-futex: 1
+# Required by AddressSanitizer
 getpid: 1
 gettid: 1
-pipe2: 1
-recvmsg: 1
-process_vm_readv: 1
-tgkill: 1
-rt_sigaction: 1
-rt_tgsigqueueinfo: 1
-#prctl: arg0 == PR_GET_NO_NEW_PRIVS || arg0 == 0x53564d41
-#mprotect: arg2 in 0x1|0x2
-#mmap2: arg2 in 0x1|0x2
-geteuid32: 1
-getgid32: 1
-getegid32: 1
-getgroups32: 1
-sysinfo: 1
-setsockopt: 1
+sched_yield: 1
 
+# The mmap2/mprotect/prctl rules in this file are less restrictive than the rules
+# in the crash_dump policy file. Therefore, include a version of the crash_dump
+# policy that does not include any mmap2/mprotect/prctl rules.
+@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.no_mmap_mprotect_prctl.arm.policy
 @include /apex/com.android.media.swcodec/etc/seccomp_policy/code_coverage.arm.policy
diff --git a/services/mediacodec/seccomp_policy/mediaswcodec-arm64.policy b/services/mediacodec/seccomp_policy/mediaswcodec-arm64.policy
index 4317cccfdd..6c539ec503 100644
--- a/services/mediacodec/seccomp_policy/mediaswcodec-arm64.policy
+++ b/services/mediacodec/seccomp_policy/mediaswcodec-arm64.policy
@@ -15,7 +15,6 @@
 futex: 1
 # ioctl calls are filtered via the selinux policy.
 ioctl: 1
-sched_yield: 1
 close: 1
 dup: 1
 ppoll: 1
@@ -61,24 +60,10 @@ rt_sigreturn: 1
 getrandom: 1
 madvise: 1
 
-# crash dump policy additions
-clock_gettime: 1
+# Required by AddressSanitizer
 getpid: 1
 gettid: 1
-pipe2: 1
-recvmsg: 1
-process_vm_readv: 1
-tgkill: 1
-rt_sigaction: 1
-rt_tgsigqueueinfo: 1
-#mprotect: arg2 in 0x1|0x2
-munmap: 1
-#mmap: arg2 in 0x1|0x2
-geteuid: 1
-getgid: 1
-getegid: 1
-getgroups: 1
-sysinfo: 1
+sched_yield: 1
 
 # Android profiler (heapprofd, traced_perf) additions, where not already
 # covered by the rest of the file, or by builtin minijail allow-listing of
@@ -90,4 +75,8 @@ sysinfo: 1
 setsockopt: 1
 sendmsg: 1
 
+# The mmap/mprotect/prctl rules in this file are less restrictive than the rules
+# in the crash_dump policy file. Therefore, include a version of the crash_dump
+# policy that does not include any mmap/mprotect/prctl rules.
+@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.no_mmap_mprotect_prctl.arm64.policy
 @include /apex/com.android.media.swcodec/etc/seccomp_policy/code_coverage.arm64.policy
diff --git a/services/mediacodec/seccomp_policy/mediaswcodec-riscv64.policy b/services/mediacodec/seccomp_policy/mediaswcodec-riscv64.policy
index 0c6aafda92..d963fe555c 100644
--- a/services/mediacodec/seccomp_policy/mediaswcodec-riscv64.policy
+++ b/services/mediacodec/seccomp_policy/mediaswcodec-riscv64.policy
@@ -13,7 +13,6 @@
 # limitations under the License.
 
 read: 1
-mprotect: 1
 prctl: 1
 openat: 1
 getuid: 1
@@ -21,7 +20,8 @@ getrlimit: 1
 writev: 1
 ioctl: 1
 close: 1
-mmap: 1
+mprotect: arg2 in ~PROT_EXEC || arg2 in ~PROT_WRITE
+mmap: arg2 in ~PROT_EXEC || arg2 in ~PROT_WRITE
 munmap: 1
 fstat: 1
 madvise: 1
@@ -56,8 +56,12 @@ clock_gettime: 1
 pipe2: 1
 
 # Required by AddressSanitizer
+getpid: 1
 gettid: 1
 sched_yield: 1
-getpid: 1
 
+# The mmap/mprotect/prctl rules in this file are less restrictive than the rules
+# in the crash_dump policy file. Therefore, include a version of the crash_dump
+# policy that does not include any mmap/mprotect/prctl rules.
+@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.no_mmap_mprotect_prctl.riscv64.policy
 @include /apex/com.android.media.swcodec/etc/seccomp_policy/code_coverage.riscv64.policy
diff --git a/services/mediacodec/seccomp_policy/mediaswcodec-x86.policy b/services/mediacodec/seccomp_policy/mediaswcodec-x86.policy
index 9bafe7bc55..1eee929574 100644
--- a/services/mediacodec/seccomp_policy/mediaswcodec-x86.policy
+++ b/services/mediacodec/seccomp_policy/mediaswcodec-x86.policy
@@ -13,7 +13,6 @@
 # limitations under the License.
 
 read: 1
-mprotect: 1
 prctl: 1
 openat: 1
 open: 1
@@ -23,8 +22,8 @@ getrlimit: 1
 writev: 1
 ioctl: 1
 close: 1
-mmap2: 1
-mmap: 1
+mprotect: arg2 in ~PROT_EXEC || arg2 in ~PROT_WRITE
+mmap2: arg2 in ~PROT_EXEC || arg2 in ~PROT_WRITE
 fstat64: 1
 fstat: 1
 stat: 1
@@ -64,10 +63,12 @@ ftruncate: 1
 ftruncate64: 1
 
 # Required by AddressSanitizer
-gettid: 1
-sched_yield: 1
 getpid: 1
 gettid: 1
+sched_yield: 1
 
-@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.x86.policy
+# The mmap2/mprotect/prctl rules in this file are less restrictive than the rules
+# in the crash_dump policy file. Therefore, include a version of the crash_dump
+# policy that does not include any mmap2/mprotect/prctl rules.
+@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.no_mmap_mprotect_prctl.x86.policy
 @include /apex/com.android.media.swcodec/etc/seccomp_policy/code_coverage.x86.policy
diff --git a/services/mediacodec/seccomp_policy/mediaswcodec-x86_64.policy b/services/mediacodec/seccomp_policy/mediaswcodec-x86_64.policy
index b0ed0402bb..6603a8f06a 100644
--- a/services/mediacodec/seccomp_policy/mediaswcodec-x86_64.policy
+++ b/services/mediacodec/seccomp_policy/mediaswcodec-x86_64.policy
@@ -13,7 +13,6 @@
 # limitations under the License.
 
 read: 1
-mprotect: 1
 prctl: 1
 openat: 1
 open: 1
@@ -23,8 +22,8 @@ getrlimit: 1
 writev: 1
 ioctl: 1
 close: 1
-mmap2: 1
-mmap: 1
+mprotect: arg2 in ~PROT_EXEC || arg2 in ~PROT_WRITE
+mmap: arg2 in ~PROT_EXEC || arg2 in ~PROT_WRITE
 fstat64: 1
 fstat: 1
 stat: 1
@@ -64,10 +63,12 @@ ftruncate: 1
 ftruncate64: 1
 
 # Required by AddressSanitizer
-gettid: 1
-sched_yield: 1
 getpid: 1
 gettid: 1
+sched_yield: 1
 
-@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.x86_64.policy
+# The mmap/mprotect/prctl rules in this file are less restrictive than the rules
+# in the crash_dump policy file. Therefore, include a version of the crash_dump
+# policy that does not include any mmap/mprotect/prctl rules.
+@include /apex/com.android.media.swcodec/etc/seccomp_policy/crash_dump.no_mmap_mprotect_prctl.x86_64.policy
 @include /apex/com.android.media.swcodec/etc/seccomp_policy/code_coverage.x86_64.policy
diff --git a/services/mediaextractor/seccomp_policy/mediaextractor-arm.policy b/services/mediaextractor/seccomp_policy/mediaextractor-arm.policy
index e1f7fe7265..41ddaf1233 100644
--- a/services/mediaextractor/seccomp_policy/mediaextractor-arm.policy
+++ b/services/mediaextractor/seccomp_policy/mediaextractor-arm.policy
@@ -48,6 +48,16 @@ timer_delete: 1
 # for dynamically loading extractors
 pread64: 1
 
+# Required by MemoryHeapBase for shared memory allocations when libcutils uses
+# memfd.
+#
+# memfd_create() is used for allocating a memfd, ftruncate() is used to specify
+# its size, and fcntl() is used to set file seals on the memfd, such as seals
+# to prevent the file from changing in size and from being written to.
+memfd_create: 1
+ftruncate64: 1
+fcntl64: 1
+
 # mremap: Ensure |flags| are (MREMAP_MAYMOVE | MREMAP_FIXED) TODO: Once minijail
 # parser support for '<' is in this needs to be modified to also prevent
 # |old_address| and |new_address| from touching the exception vector page, which
diff --git a/services/mediaextractor/seccomp_policy/mediaextractor-arm64.policy b/services/mediaextractor/seccomp_policy/mediaextractor-arm64.policy
index e54c9187e7..4d8a016b38 100644
--- a/services/mediaextractor/seccomp_policy/mediaextractor-arm64.policy
+++ b/services/mediaextractor/seccomp_policy/mediaextractor-arm64.policy
@@ -46,6 +46,16 @@ mremap: 1
 # Required by Sanitizers
 sched_yield: 1
 
+# Required by MemoryHeapBase for shared memory allocations when libcutils uses
+# memfd.
+#
+# memfd_create() is used for allocating a memfd, ftruncate() is used to specify
+# its size, and fcntl() is used to set file seals on the memfd, such as seals
+# to prevent the file from changing in size and from being written to.
+memfd_create: 1
+ftruncate: 1
+fcntl: 1
+
 # Android profiler (heapprofd, traced_perf) additions, where not already
 # covered by the rest of the file, or by builtin minijail allow-listing of
 # logging-related syscalls.
diff --git a/services/mediaextractor/seccomp_policy/mediaextractor-riscv64.policy b/services/mediaextractor/seccomp_policy/mediaextractor-riscv64.policy
index df143dde47..be196fc3c2 100644
--- a/services/mediaextractor/seccomp_policy/mediaextractor-riscv64.policy
+++ b/services/mediaextractor/seccomp_policy/mediaextractor-riscv64.policy
@@ -44,5 +44,15 @@ mremap: 1
 # Required by Sanitizers
 sched_yield: 1
 
+# Required by MemoryHeapBase for shared memory allocations when libcutils uses
+# memfd.
+#
+# memfd_create() is used for allocating a memfd, ftruncate() is used to specify
+# its size, and fcntl() is used to set file seals on the memfd, such as seals
+# to prevent the file from changing in size and from being written to.
+memfd_create: 1
+ftruncate: 1
+fcntl: 1
+
 @include /apex/com.android.media/etc/seccomp_policy/crash_dump.riscv64.policy
 @include /apex/com.android.media/etc/seccomp_policy/code_coverage.riscv64.policy
diff --git a/services/mediaextractor/seccomp_policy/mediaextractor-x86.policy b/services/mediaextractor/seccomp_policy/mediaextractor-x86.policy
index 5b3762712d..ba6a0d3672 100644
--- a/services/mediaextractor/seccomp_policy/mediaextractor-x86.policy
+++ b/services/mediaextractor/seccomp_policy/mediaextractor-x86.policy
@@ -59,5 +59,15 @@ sched_yield: 1
 getpid: 1
 gettid: 1
 
+# Required by MemoryHeapBase for shared memory allocations when libcutils uses
+# memfd.
+#
+# memfd_create() is used for allocating a memfd, ftruncate() is used to specify
+# its size, and fcntl() is used to set file seals on the memfd, such as seals
+# to prevent the file from changing in size and from being written to.
+memfd_create: 1
+ftruncate64: 1
+fcntl64: 1
+
 @include /apex/com.android.media/etc/seccomp_policy/crash_dump.x86.policy
 @include /apex/com.android.media/etc/seccomp_policy/code_coverage.x86.policy
diff --git a/services/mediaextractor/seccomp_policy/mediaextractor-x86_64.policy b/services/mediaextractor/seccomp_policy/mediaextractor-x86_64.policy
index 51df1a238d..908ad0f214 100644
--- a/services/mediaextractor/seccomp_policy/mediaextractor-x86_64.policy
+++ b/services/mediaextractor/seccomp_policy/mediaextractor-x86_64.policy
@@ -53,5 +53,15 @@ sched_yield: 1
 getpid: 1
 gettid: 1
 
+# Required by MemoryHeapBase for shared memory allocations when libcutils uses
+# memfd.
+#
+# memfd_create() is used for allocating a memfd, ftruncate() is used to specify
+# its size, and fcntl() is used to set file seals on the memfd, such as seals
+# to prevent the file from changing in size and from being written to.
+memfd_create: 1
+ftruncate: 1
+fcntl: 1
+
 @include /apex/com.android.media/etc/seccomp_policy/crash_dump.x86_64.policy
 @include /apex/com.android.media/etc/seccomp_policy/code_coverage.x86_64.policy
diff --git a/services/mediametrics/AudioPowerUsage.cpp b/services/mediametrics/AudioPowerUsage.cpp
index 253fc0a8b8..b2ca4d7e3c 100644
--- a/services/mediametrics/AudioPowerUsage.cpp
+++ b/services/mediametrics/AudioPowerUsage.cpp
@@ -18,18 +18,19 @@
 #define LOG_TAG "AudioPowerUsage"
 #include <utils/Log.h>
 
-#include "AudioAnalytics.h"
-#include "MediaMetricsService.h"
-#include "StringUtils.h"
-#include <map>
-#include <sstream>
-#include <string>
-#include <audio_utils/clock.h>
 #include <audio_utils/StringUtils.h>
+#include <audio_utils/clock.h>
 #include <cutils/properties.h>
+#include <media/TypeConverter.h>
 #include <stats_media_metrics.h>
 #include <sys/timerfd.h>
 #include <system/audio.h>
+#include <map>
+#include <sstream>
+#include <string>
+#include "AudioAnalytics.h"
+#include "MediaMetricsService.h"
+#include "StringUtils.h"
 
 // property to disable audio power use metrics feature, default is enabled
 #define PROP_AUDIO_METRICS_DISABLED "persist.media.audio_metrics.power_usage_disabled"
@@ -44,7 +45,10 @@
 
 #define AUDIO_POWER_USAGE_PROP_DEVICE         "device"     // int32
 #define AUDIO_POWER_USAGE_PROP_DURATION_NS    "durationNs" // int64
-#define AUDIO_POWER_USAGE_PROP_TYPE           "type"       // int32
+#define AUDIO_POWER_USAGE_PROP_STREAM_TYPE "stream_type"   // int32
+#define AUDIO_POWER_USAGE_PROP_SOURCE "source"             // int32
+#define AUDIO_POWER_USAGE_PROP_USAGE "usage"               // int32
+#define AUDIO_POWER_USAGE_PROP_CONTENT_TYPE "content_type"  // int32
 #define AUDIO_POWER_USAGE_PROP_VOLUME         "volume"     // double
 #define AUDIO_POWER_USAGE_PROP_MIN_VOLUME_DURATION_NS "minVolumeDurationNs" // int64
 #define AUDIO_POWER_USAGE_PROP_MIN_VOLUME             "minVolume"           // double
@@ -53,71 +57,72 @@
 
 namespace android::mediametrics {
 
-/* static */
-bool AudioPowerUsage::typeFromString(const std::string& type_string, int32_t& type) {
-    static std::map<std::string, int32_t> typeTable = {
-        { "AUDIO_STREAM_VOICE_CALL",          VOIP_CALL_TYPE },
-        { "AUDIO_STREAM_SYSTEM",              MEDIA_TYPE },
-        { "AUDIO_STREAM_RING",                RINGTONE_NOTIFICATION_TYPE },
-        { "AUDIO_STREAM_MUSIC",               MEDIA_TYPE },
-        { "AUDIO_STREAM_ALARM",               ALARM_TYPE },
-        { "AUDIO_STREAM_NOTIFICATION",        RINGTONE_NOTIFICATION_TYPE },
-
-        { "AUDIO_CONTENT_TYPE_SPEECH",        VOIP_CALL_TYPE },
-        { "AUDIO_CONTENT_TYPE_MUSIC",         MEDIA_TYPE },
-        { "AUDIO_CONTENT_TYPE_MOVIE",         MEDIA_TYPE },
-        { "AUDIO_CONTENT_TYPE_SONIFICATION",  RINGTONE_NOTIFICATION_TYPE },
-
-        { "AUDIO_USAGE_MEDIA",                MEDIA_TYPE },
-        { "AUDIO_USAGE_VOICE_COMMUNICATION",  VOIP_CALL_TYPE },
-        { "AUDIO_USAGE_ALARM",                ALARM_TYPE },
-        { "AUDIO_USAGE_NOTIFICATION",         RINGTONE_NOTIFICATION_TYPE },
-
-        { "AUDIO_SOURCE_CAMCORDER",           CAMCORDER_TYPE },
-        { "AUDIO_SOURCE_VOICE_COMMUNICATION", VOIP_CALL_TYPE },
-        { "AUDIO_SOURCE_DEFAULT",             RECORD_TYPE },
-        { "AUDIO_SOURCE_MIC",                 RECORD_TYPE },
-        { "AUDIO_SOURCE_UNPROCESSED",         RECORD_TYPE },
-        { "AUDIO_SOURCE_VOICE_RECOGNITION",   RECORD_TYPE },
-    };
-
-    auto it = typeTable.find(type_string);
-    if (it == typeTable.end()) {
-        type = UNKNOWN_TYPE;
-        return false;
-    }
-
-    type = it->second;
-    return true;
-}
-
 /* static */
 bool AudioPowerUsage::deviceFromString(const std::string& device_string, int32_t& device) {
     static std::map<std::string, int32_t> deviceTable = {
-        { "AUDIO_DEVICE_OUT_EARPIECE",                  OUTPUT_EARPIECE },
-        { "AUDIO_DEVICE_OUT_SPEAKER_SAFE",              OUTPUT_SPEAKER_SAFE },
-        { "AUDIO_DEVICE_OUT_SPEAKER",                   OUTPUT_SPEAKER },
-        { "AUDIO_DEVICE_OUT_WIRED_HEADSET",             OUTPUT_WIRED_HEADSET },
-        { "AUDIO_DEVICE_OUT_WIRED_HEADPHONE",           OUTPUT_WIRED_HEADSET },
-        { "AUDIO_DEVICE_OUT_BLUETOOTH_SCO",             OUTPUT_BLUETOOTH_SCO },
-        { "AUDIO_DEVICE_OUT_BLUETOOTH_SCO_HEADSET",     OUTPUT_BLUETOOTH_SCO },
-        { "AUDIO_DEVICE_OUT_BLUETOOTH_A2DP",            OUTPUT_BLUETOOTH_A2DP },
-        { "AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_HEADPHONES", OUTPUT_BLUETOOTH_A2DP },
-        { "AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_SPEAKER",    OUTPUT_BLUETOOTH_A2DP },
-        { "AUDIO_DEVICE_OUT_BLE_HEADSET",               OUTPUT_BLUETOOTH_BLE },
-        { "AUDIO_DEVICE_OUT_BLE_SPEAKER",               OUTPUT_BLUETOOTH_BLE },
-        { "AUDIO_DEVICE_OUT_BLE_BROADCAST",             OUTPUT_BLUETOOTH_BLE },
-        { "AUDIO_DEVICE_OUT_USB_HEADSET",               OUTPUT_USB_HEADSET },
-        { "AUDIO_DEVICE_OUT_DGTL_DOCK_HEADSET",         OUTPUT_DOCK },
-        { "AUDIO_DEVICE_OUT_HDMI",                      OUTPUT_HDMI },
-
-        { "AUDIO_DEVICE_IN_BUILTIN_MIC",           INPUT_BUILTIN_MIC },
-        { "AUDIO_DEVICE_IN_BLUETOOTH_SCO_HEADSET", INPUT_BLUETOOTH_SCO },
-        { "AUDIO_DEVICE_IN_BLUETOOTH_BLE",         INPUT_BLUETOOTH_BLE },
-        { "AUDIO_DEVICE_IN_BLE_HEADSET",           INPUT_BLUETOOTH_BLE },
-        { "AUDIO_DEVICE_IN_WIRED_HEADSET",         INPUT_WIRED_HEADSET_MIC },
-        { "AUDIO_DEVICE_IN_USB_DEVICE",            INPUT_USB_HEADSET_MIC },
-        { "AUDIO_DEVICE_IN_BACK_MIC",              INPUT_BUILTIN_BACK_MIC },
+            {"AUDIO_DEVICE_OUT_EARPIECE", OUTPUT_EARPIECE},
+            {"AUDIO_DEVICE_OUT_SPEAKER", OUTPUT_SPEAKER},
+            {"AUDIO_DEVICE_OUT_WIRED_HEADSET", OUTPUT_WIRED_HEADSET},
+            {"AUDIO_DEVICE_OUT_WIRED_HEADPHONE", OUTPUT_WIRED_HEADPHONE},
+            {"AUDIO_DEVICE_OUT_BLUETOOTH_SCO", OUTPUT_BLUETOOTH_SCO},
+            {"AUDIO_DEVICE_OUT_BLUETOOTH_SCO_HEADSET", OUTPUT_BLUETOOTH_SCO_HEADSET},
+            {"AUDIO_DEVICE_OUT_BLUETOOTH_SCO_CARKIT", OUTPUT_BLUETOOTH_SCO_CARKIT},
+            {"AUDIO_DEVICE_OUT_BLUETOOTH_A2DP", OUTPUT_BLUETOOTH_A2DP},
+            {"AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_HEADPHONES", OUTPUT_BLUETOOTH_A2DP_HEADPHONES},
+            {"AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_SPEAKER", OUTPUT_BLUETOOTH_A2DP_SPEAKER},
+            {"AUDIO_DEVICE_OUT_HDMI", OUTPUT_HDMI},
+            {"AUDIO_DEVICE_OUT_ANLG_DOCK_HEADSET", OUTPUT_ANLG_DOCK_HEADSET},
+            {"AUDIO_DEVICE_OUT_DGTL_DOCK_HEADSET", OUTPUT_DGTL_DOCK_HEADSET},
+            {"AUDIO_DEVICE_OUT_USB_ACCESSORY", OUTPUT_USB_ACCESSORY},
+            {"AUDIO_DEVICE_OUT_USB_DEVICE", OUTPUT_USB_DEVICE},
+            {"AUDIO_DEVICE_OUT_REMOTE_SUBMIX", OUTPUT_REMOTE_SUBMIX},
+            {"AUDIO_DEVICE_OUT_TELEPHONY_TX", OUTPUT_TELEPHONY_TX},
+            {"AUDIO_DEVICE_OUT_LINE", OUTPUT_LINE},
+            {"AUDIO_DEVICE_OUT_HDMI_ARC", OUTPUT_HDMI_ARC},
+            {"AUDIO_DEVICE_OUT_HDMI_EARC", OUTPUT_HDMI_EARC},
+            {"AUDIO_DEVICE_OUT_SPDIF", OUTPUT_SPDIF},
+            {"AUDIO_DEVICE_OUT_FM", OUTPUT_FM},
+            {"AUDIO_DEVICE_OUT_AUX_LINE", OUTPUT_AUX_LINE},
+            {"AUDIO_DEVICE_OUT_SPEAKER_SAFE", OUTPUT_SPEAKER_SAFE},
+            {"AUDIO_DEVICE_OUT_IP", OUTPUT_IP},
+            {"AUDIO_DEVICE_OUT_MULTICHANNEL_GROUP", OUTPUT_MULTICHANNEL_GROUP},
+            {"AUDIO_DEVICE_OUT_BUS", OUTPUT_BUS},
+            {"AUDIO_DEVICE_OUT_PROXY", OUTPUT_PROXY},
+            {"AUDIO_DEVICE_OUT_USB_HEADSET", OUTPUT_USB_HEADSET},
+            {"AUDIO_DEVICE_OUT_HEARING_AID", OUTPUT_HEARING_AID},
+            {"AUDIO_DEVICE_OUT_ECHO_CANCELLER", OUTPUT_ECHO_CANCELLER},
+            {"AUDIO_DEVICE_OUT_BLE_HEADSET", OUTPUT_BLE_HEADSET},
+            {"AUDIO_DEVICE_OUT_BLE_SPEAKER", OUTPUT_BLE_SPEAKER},
+            {"AUDIO_DEVICE_OUT_BLE_BROADCAST", OUTPUT_BLE_BROADCAST},
+
+            {"AUDIO_DEVICE_IN_COMMUNICATION", INPUT_COMMUNICATION},
+            {"AUDIO_DEVICE_IN_AMBIENT", INPUT_AMBIENT},
+            {"AUDIO_DEVICE_IN_BUILTIN_MIC", INPUT_BUILTIN_MIC},
+            {"AUDIO_DEVICE_IN_BLUETOOTH_SCO_HEADSET", INPUT_BLUETOOTH_SCO_HEADSET},
+            {"AUDIO_DEVICE_IN_WIRED_HEADSET", INPUT_WIRED_HEADSET},
+            {"AUDIO_DEVICE_IN_HDMI", INPUT_HDMI},
+            {"AUDIO_DEVICE_IN_TELEPHONY_RX", INPUT_TELEPHONY_RX},
+            {"AUDIO_DEVICE_IN_BACK_MIC", INPUT_BACK_MIC},
+            {"AUDIO_DEVICE_IN_REMOTE_SUBMIX", INPUT_REMOTE_SUBMIX},
+            {"AUDIO_DEVICE_IN_ANLG_DOCK_HEADSET", INPUT_ANLG_DOCK_HEADSET},
+            {"AUDIO_DEVICE_IN_DGTL_DOCK_HEADSET", INPUT_DGTL_DOCK_HEADSET},
+            {"AUDIO_DEVICE_IN_USB_ACCESSORY", INPUT_USB_ACCESSORY},
+            {"AUDIO_DEVICE_IN_USB_DEVICE", INPUT_USB_DEVICE},
+            {"AUDIO_DEVICE_IN_FM_TUNER", INPUT_FM_TUNER},
+            {"AUDIO_DEVICE_IN_TV_TUNER", INPUT_TV_TUNER},
+            {"AUDIO_DEVICE_IN_LINE", INPUT_LINE},
+            {"AUDIO_DEVICE_IN_SPDIF", INPUT_SPDIF},
+            {"AUDIO_DEVICE_IN_BLUETOOTH_A2DP", INPUT_BLUETOOTH_A2DP},
+            {"AUDIO_DEVICE_IN_LOOPBACK", INPUT_LOOPBACK},
+            {"AUDIO_DEVICE_IN_IP", INPUT_IP},
+            {"AUDIO_DEVICE_IN_BUS", INPUT_BUS},
+            {"AUDIO_DEVICE_IN_PROXY", INPUT_PROXY},
+            {"AUDIO_DEVICE_IN_USB_HEADSET", INPUT_USB_HEADSET},
+            {"AUDIO_DEVICE_IN_BLUETOOTH_BLE", INPUT_BLUETOOTH_BLE},
+            {"AUDIO_DEVICE_IN_HDMI_ARC", INPUT_HDMI_ARC},
+            {"AUDIO_DEVICE_IN_HDMI_EARC", INPUT_HDMI_EARC},
+            {"AUDIO_DEVICE_IN_ECHO_REFERENCE", INPUT_ECHO_REFERENCE},
+            {"AUDIO_DEVICE_IN_BLE_HEADSET", INPUT_BLE_HEADSET},
     };
 
     auto it = deviceTable.find(device_string);
@@ -143,8 +148,17 @@ int32_t AudioPowerUsage::deviceFromStringPairs(const std::string& device_strings
 
 void AudioPowerUsage::sendItem(const std::shared_ptr<const mediametrics::Item>& item) const
 {
-    int32_t type;
-    if (!item->getInt32(AUDIO_POWER_USAGE_PROP_TYPE, &type)) return;
+    int32_t stream_type;
+    if (!item->getInt32(AUDIO_POWER_USAGE_PROP_STREAM_TYPE, &stream_type)) return;
+
+    int32_t source;
+    if (!item->getInt32(AUDIO_POWER_USAGE_PROP_SOURCE, &source)) return;
+
+    int32_t usage;
+    if (!item->getInt32(AUDIO_POWER_USAGE_PROP_USAGE, &usage)) return;
+
+    int32_t content_type;
+    if (!item->getInt32(AUDIO_POWER_USAGE_PROP_CONTENT_TYPE, &content_type)) return;
 
     int32_t audio_device;
     if (!item->getInt32(AUDIO_POWER_USAGE_PROP_DEVICE, &audio_device)) return;
@@ -178,30 +192,23 @@ void AudioPowerUsage::sendItem(const std::shared_ptr<const mediametrics::Item>&
 
     if (__builtin_available(android 33, *)) {
         result = stats::media_metrics::stats_write(
-                                         stats::media_metrics::AUDIO_POWER_USAGE_DATA_REPORTED,
-                                         audio_device,
-                                         duration_secs,
-                                         (float)volume,
-                                         type,
-                                         min_volume_duration_secs,
-                                         (float)min_volume,
-                                         max_volume_duration_secs,
-                                         (float)max_volume);
+                stats::media_metrics::AUDIO_POWER_USAGE_DATA_REPORTED, 0, duration_secs,
+                (float)volume, 0, min_volume_duration_secs, (float)min_volume,
+                max_volume_duration_secs, (float)max_volume, audio_device, stream_type, source,
+                usage, content_type);
     }
 
     std::stringstream log;
     log << "result:" << result << " {"
-            << " mediametrics_audio_power_usage_data_reported:"
-            << stats::media_metrics::AUDIO_POWER_USAGE_DATA_REPORTED
-            << " audio_device:" << audio_device
-            << " duration_secs:" << duration_secs
-            << " average_volume:" << (float)volume
-            << " type:" << type
-            << " min_volume_duration_secs:" << min_volume_duration_secs
-            << " min_volume:" << (float)min_volume
-            << " max_volume_duration_secs:" << max_volume_duration_secs
-            << " max_volume:" << (float)max_volume
-            << " }";
+        << " mediametrics_audio_power_usage_data_reported:"
+        << stats::media_metrics::AUDIO_POWER_USAGE_DATA_REPORTED << " audio_device:" << audio_device
+        << " duration_secs:" << duration_secs << " average_volume:" << (float)volume
+        << " stream_type: " << stream_type << " source: " << source << " usage: " << usage
+        << " content_type: " << content_type
+        << " min_volume_duration_secs:" << min_volume_duration_secs
+        << " min_volume:" << (float)min_volume
+        << " max_volume_duration_secs:" << max_volume_duration_secs
+        << " max_volume:" << (float)max_volume << " }";
     mStatsdLog->log(stats::media_metrics::AUDIO_POWER_USAGE_DATA_REPORTED, log.str());
 }
 
@@ -225,13 +232,13 @@ void AudioPowerUsage::updateMinMaxVolumeAndDuration(
     }
 }
 
-bool AudioPowerUsage::saveAsItem_l(
-        int32_t device, int64_t duration_ns, int32_t type, double average_vol,
-        int64_t max_volume_duration_ns, double max_volume,
-        int64_t min_volume_duration_ns, double min_volume)
-{
-    ALOGV("%s: (%#x, %d, %lld, %f)", __func__, device, type,
-                                   (long long)duration_ns, average_vol);
+bool AudioPowerUsage::saveAsItem_l(int32_t device, int64_t duration_ns, int32_t stream_type,
+                                   int32_t source, int32_t usage, int32_t content_type,
+                                   double average_vol, int64_t max_volume_duration_ns,
+                                   double max_volume, int64_t min_volume_duration_ns,
+                                   double min_volume) {
+    ALOGV("%s: (%#x, %d, %d, %d, %d, %lld, %f)", __func__, device, stream_type, source, usage,
+          content_type, (long long)duration_ns, average_vol);
     if (duration_ns == 0) {
         return true; // skip duration 0 usage
     }
@@ -240,16 +247,24 @@ bool AudioPowerUsage::saveAsItem_l(
     }
 
     for (const auto& item : mItems) {
-        int32_t item_type = 0, item_device = 0;
+        int32_t item_stream_type = 0;
+        int32_t item_source = 0;
+        int32_t item_usage = 0;
+        int32_t item_content_type = 0;
+        int32_t item_device = 0;
         double item_volume = 0.;
         int64_t item_duration_ns = 0;
         item->getInt32(AUDIO_POWER_USAGE_PROP_DEVICE, &item_device);
         item->getInt64(AUDIO_POWER_USAGE_PROP_DURATION_NS, &item_duration_ns);
-        item->getInt32(AUDIO_POWER_USAGE_PROP_TYPE, &item_type);
+        item->getInt32(AUDIO_POWER_USAGE_PROP_STREAM_TYPE, &item_stream_type);
+        item->getInt32(AUDIO_POWER_USAGE_PROP_SOURCE, &item_source);
+        item->getInt32(AUDIO_POWER_USAGE_PROP_USAGE, &item_usage);
+        item->getInt32(AUDIO_POWER_USAGE_PROP_CONTENT_TYPE, &item_content_type);
         item->getDouble(AUDIO_POWER_USAGE_PROP_VOLUME, &item_volume);
 
         // aggregate by device and type
-        if (item_device == device && item_type == type) {
+        if (item_device == device && item_stream_type == stream_type && item_source == source &&
+            item_usage == usage && item_content_type == content_type) {
             int64_t final_duration_ns = item_duration_ns + duration_ns;
             double final_volume = (device & INPUT_DEVICE_BIT) ? 1.0:
                             ((item_volume * (double)item_duration_ns +
@@ -282,12 +297,11 @@ bool AudioPowerUsage::saveAsItem_l(
                            final_max_volume_duration_ns);
             item->setDouble(AUDIO_POWER_USAGE_PROP_MAX_VOLUME, final_max_volume);
 
-            ALOGV("%s: update (%#x, %d, %lld, %f) --> (%lld, %f) min(%lld, %f) max(%lld, %f)",
-                  __func__,
-                  device, type,
-                  (long long)item_duration_ns, item_volume,
-                  (long long)final_duration_ns, final_volume,
-                  (long long)final_min_volume_duration_ns, final_min_volume,
+            ALOGV("%s: update (%#x, %d, %d ,%d, %d, %lld, %f) --> (%lld, %f) min(%lld, %f) "
+                  "max(%lld, %f)",
+                  __func__, device, item_stream_type, item_source, item_usage, item_content_type,
+                  (long long)item_duration_ns, item_volume, (long long)final_duration_ns,
+                  final_volume, (long long)final_min_volume_duration_ns, final_min_volume,
                   (long long)final_max_volume_duration_ns, final_max_volume);
 
             return true;
@@ -298,7 +312,10 @@ bool AudioPowerUsage::saveAsItem_l(
     sitem->setTimestamp(systemTime(SYSTEM_TIME_REALTIME));
     sitem->setInt32(AUDIO_POWER_USAGE_PROP_DEVICE, device);
     sitem->setInt64(AUDIO_POWER_USAGE_PROP_DURATION_NS, duration_ns);
-    sitem->setInt32(AUDIO_POWER_USAGE_PROP_TYPE, type);
+    sitem->setInt32(AUDIO_POWER_USAGE_PROP_STREAM_TYPE, stream_type);
+    sitem->setInt32(AUDIO_POWER_USAGE_PROP_SOURCE, source);
+    sitem->setInt32(AUDIO_POWER_USAGE_PROP_USAGE, usage);
+    sitem->setInt32(AUDIO_POWER_USAGE_PROP_CONTENT_TYPE, content_type);
     sitem->setDouble(AUDIO_POWER_USAGE_PROP_VOLUME, average_vol);
     sitem->setInt64(AUDIO_POWER_USAGE_PROP_MIN_VOLUME_DURATION_NS, min_volume_duration_ns);
     sitem->setDouble(AUDIO_POWER_USAGE_PROP_MIN_VOLUME, min_volume);
@@ -308,13 +325,13 @@ bool AudioPowerUsage::saveAsItem_l(
     return true;
 }
 
-bool AudioPowerUsage::saveAsItems_l(
-        int32_t device, int64_t duration_ns, int32_t type, double average_vol,
-        int64_t max_volume_duration, double max_volume,
-        int64_t min_volume_duration, double min_volume)
-{
-    ALOGV("%s: (%#x, %d, %lld, %f)", __func__, device, type,
-                                   (long long)duration_ns, average_vol );
+bool AudioPowerUsage::saveAsItems_l(int32_t device, int64_t duration_ns, int32_t stream_type,
+                                    int32_t source, int32_t usage, int32_t content_type,
+                                    double average_vol, int64_t max_volume_duration,
+                                    double max_volume, int64_t min_volume_duration,
+                                    double min_volume) {
+    ALOGV("%s: (%#x, %d, %d, %d, %d, %lld, %f)", __func__, device, stream_type, source, usage,
+          content_type, (long long)duration_ns, average_vol);
     if (duration_ns == 0) {
         return true; // skip duration 0 usage
     }
@@ -330,9 +347,9 @@ bool AudioPowerUsage::saveAsItems_l(
         int32_t tmp_device = device_bits & -device_bits; // get lowest bit
         device_bits ^= tmp_device;  // clear lowest bit
         tmp_device |= input_bit;    // restore input bit
-        ret = saveAsItem_l(tmp_device, duration_ns, type, average_vol,
-                           max_volume_duration, max_volume,
-                           min_volume_duration, min_volume);
+        ret = saveAsItem_l(tmp_device, duration_ns, stream_type, source, usage, content_type,
+                           average_vol, max_volume_duration, max_volume, min_volume_duration,
+                           min_volume);
 
         ALOGV("%s: device %#x recorded, remaining device_bits = %#x", __func__,
             tmp_device, device_bits);
@@ -372,25 +389,26 @@ void AudioPowerUsage::checkTrackRecord(
         }
     }
 
-    int32_t type = 0;
     std::string type_string;
-    if ((isTrack && mAudioAnalytics->mAnalyticsState->timeMachine().get(
-               key, AMEDIAMETRICS_PROP_STREAMTYPE, &type_string) == OK) ||
-        (!isTrack && mAudioAnalytics->mAnalyticsState->timeMachine().get(
-               key, AMEDIAMETRICS_PROP_SOURCE, &type_string) == OK)) {
-        typeFromString(type_string, type);
-
-        if (isTrack && type == UNKNOWN_TYPE &&
-                   mAudioAnalytics->mAnalyticsState->timeMachine().get(
-                   key, AMEDIAMETRICS_PROP_USAGE, &type_string) == OK) {
-            typeFromString(type_string, type);
-        }
-        if (isTrack && type == UNKNOWN_TYPE &&
-                   mAudioAnalytics->mAnalyticsState->timeMachine().get(
-                   key, AMEDIAMETRICS_PROP_CONTENTTYPE, &type_string) == OK) {
-            typeFromString(type_string, type);
-        }
-        ALOGV("type = %s => %d", type_string.c_str(), type);
+    audio_stream_type_t stream_type = AUDIO_STREAM_DEFAULT;
+    audio_source_t source = AUDIO_SOURCE_DEFAULT;
+    audio_usage_t usage = AUDIO_USAGE_UNKNOWN;
+    audio_content_type_t content_type = AUDIO_CONTENT_TYPE_UNKNOWN;
+    if (mAudioAnalytics->mAnalyticsState->timeMachine().get(key, AMEDIAMETRICS_PROP_STREAMTYPE,
+                                                            &type_string) == OK) {
+        TypeConverter<StreamTraits>::fromString(type_string, stream_type);
+    }
+    if (mAudioAnalytics->mAnalyticsState->timeMachine().get(key, AMEDIAMETRICS_PROP_SOURCE,
+                                                            &type_string) == OK) {
+        TypeConverter<SourceTraits>::fromString(type_string, source);
+    }
+    if (mAudioAnalytics->mAnalyticsState->timeMachine().get(key, AMEDIAMETRICS_PROP_USAGE,
+                                                            &type_string) == OK) {
+        TypeConverter<UsageTraits>::fromString(type_string, usage);
+    }
+    if (mAudioAnalytics->mAnalyticsState->timeMachine().get(key, AMEDIAMETRICS_PROP_CONTENTTYPE,
+                                                            &type_string) == OK) {
+        TypeConverter<AudioContentTraits>::fromString(type_string, content_type);
     }
 
     int32_t device = 0;
@@ -404,7 +422,7 @@ void AudioPowerUsage::checkTrackRecord(
         ALOGV("device = %s => %d", device_strings.c_str(), device);
     }
     std::lock_guard l(mLock);
-    saveAsItems_l(device, deviceTimeNs, type, deviceVolume,
+    saveAsItems_l(device, deviceTimeNs, stream_type, source, usage, content_type, deviceVolume,
                   maxVolumeDurationNs, maxVolume, minVolumeDurationNs, minVolume);
 }
 
@@ -427,9 +445,10 @@ void AudioPowerUsage::checkMode(const std::shared_ptr<const mediametrics::Item>&
                           volumeDurationNs, mVoiceVolume,
                           mMaxVoiceVolumeDurationNs, mMaxVoiceVolume,
                           mMinVoiceVolumeDurationNs, mMinVoiceVolume);
-            saveAsItems_l(mPrimaryDevice, durationNs, VOICE_CALL_TYPE, mDeviceVolume,
-                          mMaxVoiceVolumeDurationNs, mMaxVoiceVolume,
-                          mMinVoiceVolumeDurationNs, mMinVoiceVolume);
+            saveAsItems_l(mPrimaryDevice, durationNs, AUDIO_STREAM_VOICE_CALL, AUDIO_SOURCE_DEFAULT,
+                          AUDIO_USAGE_UNKNOWN, AUDIO_CONTENT_TYPE_UNKNOWN, mDeviceVolume,
+                          mMaxVoiceVolumeDurationNs, mMaxVoiceVolume, mMinVoiceVolumeDurationNs,
+                          mMinVoiceVolume);
         }
     } else if (mode == "AUDIO_MODE_IN_CALL") { // entering call mode
         mStartCallNs = item->getTimestamp(); // advisory only
@@ -498,9 +517,10 @@ void AudioPowerUsage::checkCreatePatch(const std::shared_ptr<const mediametrics:
                           volumeDurationNs, mVoiceVolume,
                           mMaxVoiceVolumeDurationNs, mMaxVoiceVolume,
                           mMinVoiceVolumeDurationNs, mMinVoiceVolume);
-            saveAsItems_l(mPrimaryDevice, durationNs, VOICE_CALL_TYPE, mDeviceVolume,
-                          mMaxVoiceVolumeDurationNs, mMaxVoiceVolume,
-                          mMinVoiceVolumeDurationNs, mMinVoiceVolume);
+            saveAsItems_l(mPrimaryDevice, durationNs, AUDIO_STREAM_VOICE_CALL, AUDIO_SOURCE_DEFAULT,
+                          AUDIO_USAGE_UNKNOWN, AUDIO_CONTENT_TYPE_UNKNOWN, mDeviceVolume,
+                          mMaxVoiceVolumeDurationNs, mMaxVoiceVolume, mMinVoiceVolumeDurationNs,
+                          mMinVoiceVolume);
         }
         // reset statistics
         mDeviceVolume = 0;
diff --git a/services/mediametrics/include/mediametricsservice/AudioPowerUsage.h b/services/mediametrics/include/mediametricsservice/AudioPowerUsage.h
index cf09113b5e..cde8187538 100644
--- a/services/mediametrics/include/mediametricsservice/AudioPowerUsage.h
+++ b/services/mediametrics/include/mediametricsservice/AudioPowerUsage.h
@@ -17,8 +17,8 @@
 #pragma once
 
 #include <android-base/thread_annotations.h>
-#include <deque>
 #include <media/MediaMetricsItem.h>
+#include <deque>
 #include <mutex>
 #include <thread>
 
@@ -26,12 +26,11 @@
 
 namespace android::mediametrics {
 
-
 class AudioAnalytics;
 
 class AudioPowerUsage {
-public:
-    AudioPowerUsage(AudioAnalytics *audioAnalytics, const std::shared_ptr<StatsdLog>& statsdLog);
+  public:
+    AudioPowerUsage(AudioAnalytics* audioAnalytics, const std::shared_ptr<StatsdLog>& statsdLog);
     ~AudioPowerUsage();
 
     void checkTrackRecord(const std::shared_ptr<const mediametrics::Item>& item, bool isTrack);
@@ -50,60 +49,96 @@ public:
      */
     std::pair<std::string, int32_t> dump(int32_t lines = INT32_MAX) const;
 
-    // align with message AudioPowerUsageDataReported in frameworks/proto_logging/stats/atoms.proto
-    enum AudioType {
-        UNKNOWN_TYPE = 0,
-        VOICE_CALL_TYPE = 1,            // voice call
-        VOIP_CALL_TYPE = 2,             // voip call, including uplink and downlink
-        MEDIA_TYPE = 3,                 // music and system sound
-        RINGTONE_NOTIFICATION_TYPE = 4, // ringtone and notification
-        ALARM_TYPE = 5,                 // alarm type
-        // record type
-        CAMCORDER_TYPE = 6,             // camcorder
-        RECORD_TYPE = 7,                // other recording
-    };
-
     enum AudioDevice {
-        OUTPUT_EARPIECE         = 0x1,
-        OUTPUT_SPEAKER          = 0x2,
-        OUTPUT_WIRED_HEADSET    = 0x4,
-        OUTPUT_USB_HEADSET      = 0x8,
-        OUTPUT_BLUETOOTH_SCO    = 0x10,
-        OUTPUT_BLUETOOTH_A2DP   = 0x20,
-        OUTPUT_SPEAKER_SAFE     = 0x40,
-        OUTPUT_BLUETOOTH_BLE    = 0x80,
-        OUTPUT_DOCK             = 0x100,
-        OUTPUT_HDMI             = 0x200,
-
-        INPUT_DEVICE_BIT        = 0x40000000,
-        INPUT_BUILTIN_MIC       = INPUT_DEVICE_BIT | 0x1, // non-negative positive int32.
-        INPUT_BUILTIN_BACK_MIC  = INPUT_DEVICE_BIT | 0x2,
-        INPUT_WIRED_HEADSET_MIC = INPUT_DEVICE_BIT | 0x4,
-        INPUT_USB_HEADSET_MIC   = INPUT_DEVICE_BIT | 0x8,
-        INPUT_BLUETOOTH_SCO     = INPUT_DEVICE_BIT | 0x10,
-        INPUT_BLUETOOTH_BLE     = INPUT_DEVICE_BIT | 0x20,
+        UNKNOWN_DEVICE = 0,
+        // Output Devices
+        OUTPUT_EARPIECE = 0x00000001u,
+        OUTPUT_SPEAKER = 0x00000002u,
+        OUTPUT_WIRED_HEADSET = 0x00000004u,
+        OUTPUT_WIRED_HEADPHONE = 0x00000008u,
+        OUTPUT_BLUETOOTH_SCO = 0x00000010u,
+        OUTPUT_BLUETOOTH_SCO_HEADSET = 0x00000020u,
+        OUTPUT_BLUETOOTH_SCO_CARKIT = 0x00000040u,
+        OUTPUT_BLUETOOTH_A2DP = 0x00000080u,
+        OUTPUT_BLUETOOTH_A2DP_HEADPHONES = 0x00000100u,
+        OUTPUT_BLUETOOTH_A2DP_SPEAKER = 0x00000200u,
+        OUTPUT_HDMI = 0x00000400u,
+        OUTPUT_ANLG_DOCK_HEADSET = 0x00000800u,
+        OUTPUT_DGTL_DOCK_HEADSET = 0x00001000u,
+        OUTPUT_USB_ACCESSORY = 0x00002000u,
+        OUTPUT_USB_DEVICE = 0x00004000u,
+        OUTPUT_REMOTE_SUBMIX = 0x00008000u,
+        OUTPUT_TELEPHONY_TX = 0x00010000u,
+        OUTPUT_LINE = 0x00020000u,
+        OUTPUT_HDMI_ARC = 0x00040000u,
+        OUTPUT_HDMI_EARC = 0x00040001u,
+        OUTPUT_SPDIF = 0x00080000u,
+        OUTPUT_FM = 0x00100000u,
+        OUTPUT_AUX_LINE = 0x00200000u,
+        OUTPUT_SPEAKER_SAFE = 0x00400000u,
+        OUTPUT_IP = 0x00800000u,
+        OUTPUT_MULTICHANNEL_GROUP = 0x00800001u,
+        OUTPUT_BUS = 0x01000000u,
+        OUTPUT_PROXY = 0x02000000u,
+        OUTPUT_USB_HEADSET = 0x04000000u,
+        OUTPUT_HEARING_AID = 0x08000000u,
+        OUTPUT_ECHO_CANCELLER = 0x10000000u,
+        OUTPUT_BLE_HEADSET = 0x20000000u,
+        OUTPUT_BLE_SPEAKER = 0x20000001u,
+        OUTPUT_BLE_BROADCAST = 0x20000002u,
+        // Input Devices
+        INPUT_DEVICE_BIT = 0x40000000,
+        INPUT_COMMUNICATION = 0x80000001u,
+        INPUT_AMBIENT = 0x80000002u,
+        INPUT_BUILTIN_MIC = 0x80000004u,
+        INPUT_BLUETOOTH_SCO_HEADSET = 0x80000008u,
+        INPUT_WIRED_HEADSET = 0x80000010u,
+        INPUT_HDMI = 0x80000020u,
+        INPUT_TELEPHONY_RX = 0x80000040u,
+        INPUT_BACK_MIC = 0x80000080u,
+        INPUT_REMOTE_SUBMIX = 0x80000100u,
+        INPUT_ANLG_DOCK_HEADSET = 0x80000200u,
+        INPUT_DGTL_DOCK_HEADSET = 0x80000400u,
+        INPUT_USB_ACCESSORY = 0x80000800u,
+        INPUT_USB_DEVICE = 0x80001000u,
+        INPUT_FM_TUNER = 0x80002000u,
+        INPUT_TV_TUNER = 0x80004000u,
+        INPUT_LINE = 0x80008000u,
+        INPUT_SPDIF = 0x80010000u,
+        INPUT_BLUETOOTH_A2DP = 0x80020000u,
+        INPUT_LOOPBACK = 0x80040000u,
+        INPUT_IP = 0x80080000u,
+        INPUT_BUS = 0x80100000u,
+        INPUT_PROXY = 0x81000000u,
+        INPUT_USB_HEADSET = 0x82000000u,
+        INPUT_BLUETOOTH_BLE = 0x84000000u,
+        INPUT_HDMI_ARC = 0x88000000u,
+        INPUT_HDMI_EARC = 0x88000001u,
+        INPUT_ECHO_REFERENCE = 0x90000000u,
+        INPUT_BLE_HEADSET = 0xA0000000u,
     };
 
-    static bool typeFromString(const std::string& type_string, int32_t& type);
     static bool deviceFromString(const std::string& device_string, int32_t& device);
     static int32_t deviceFromStringPairs(const std::string& device_strings);
-private:
-    bool saveAsItem_l(int32_t device, int64_t duration, int32_t type, double average_vol,
-                      int64_t max_volume_duration, double max_volume,
-                      int64_t min_volume_duration, double min_volume)
-                      REQUIRES(mLock);
+
+  private:
+    bool saveAsItem_l(int32_t device, int64_t duration, int32_t stream_type, int32_t source,
+                      int32_t usage, int32_t content_type, double average_vol,
+                      int64_t max_volume_duration, double max_volume, int64_t min_volume_duration,
+                      double min_volume) REQUIRES(mLock);
     void sendItem(const std::shared_ptr<const mediametrics::Item>& item) const;
     void collect();
-    bool saveAsItems_l(int32_t device, int64_t duration, int32_t type, double average_vol,
-                      int64_t max_volume_duration, double max_volume,
-                      int64_t min_volume_duration, double min_volume)
-                      REQUIRES(mLock);
-    void updateMinMaxVolumeAndDuration(
-            const int64_t cur_max_volume_duration_ns, const double cur_max_volume,
-            const int64_t cur_min_volume_duration_ns, const double cur_min_volume,
-            int64_t& f_max_volume_duration_ns, double& f_max_volume,
-            int64_t& f_min_volume_duration_ns, double& f_min_volume);
-    AudioAnalytics * const mAudioAnalytics;
+    bool saveAsItems_l(int32_t device, int64_t duration, int32_t stream_type, int32_t source,
+                       int32_t usage, int32_t content_type, double average_vol,
+                       int64_t max_volume_duration, double max_volume, int64_t min_volume_duration,
+                       double min_volume) REQUIRES(mLock);
+    void updateMinMaxVolumeAndDuration(const int64_t cur_max_volume_duration_ns,
+                                       const double cur_max_volume,
+                                       const int64_t cur_min_volume_duration_ns,
+                                       const double cur_min_volume,
+                                       int64_t& f_max_volume_duration_ns, double& f_max_volume,
+                                       int64_t& f_min_volume_duration_ns, double& f_min_volume);
+    AudioAnalytics* const mAudioAnalytics;
     const std::shared_ptr<StatsdLog> mStatsdLog;  // mStatsdLog is internally locked
     const bool mDisabled;
     const int32_t mIntervalHours;
@@ -117,11 +152,11 @@ private:
     double mMinVoiceVolume GUARDED_BY(mLock) = AMEDIAMETRICS_INITIAL_MIN_VOLUME;
     int64_t mMaxVoiceVolumeDurationNs GUARDED_BY(mLock) = 0;
     int64_t mMinVoiceVolumeDurationNs GUARDED_BY(mLock) = 0;
-    int64_t mStartCallNs GUARDED_BY(mLock) = 0; // advisory only
+    int64_t mStartCallNs GUARDED_BY(mLock) = 0;  // advisory only
     int64_t mVolumeTimeNs GUARDED_BY(mLock) = 0;
     int64_t mDeviceTimeNs GUARDED_BY(mLock) = 0;
     int32_t mPrimaryDevice GUARDED_BY(mLock) = OUTPUT_SPEAKER;
-    std::string mMode GUARDED_BY(mLock) {"AUDIO_MODE_NORMAL"};
+    std::string mMode GUARDED_BY(mLock){"AUDIO_MODE_NORMAL"};
 };
 
-} // namespace android::mediametrics
+}  // namespace android::mediametrics
diff --git a/services/mediametrics/statsd_audiopolicy.cpp b/services/mediametrics/statsd_audiopolicy.cpp
index 37b44f7f81..a9952bcb04 100644
--- a/services/mediametrics/statsd_audiopolicy.cpp
+++ b/services/mediametrics/statsd_audiopolicy.cpp
@@ -32,7 +32,7 @@
 #include <stats_media_metrics.h>
 
 #include "MediaMetricsService.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediametrics/statsd_audiorecord.cpp b/services/mediametrics/statsd_audiorecord.cpp
index 008f12fbb0..fe0f8aaa58 100644
--- a/services/mediametrics/statsd_audiorecord.cpp
+++ b/services/mediametrics/statsd_audiorecord.cpp
@@ -33,7 +33,7 @@
 
 #include "MediaMetricsService.h"
 #include "ValidateId.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediametrics/statsd_audiothread.cpp b/services/mediametrics/statsd_audiothread.cpp
index 351a8bc125..1906fc23f0 100644
--- a/services/mediametrics/statsd_audiothread.cpp
+++ b/services/mediametrics/statsd_audiothread.cpp
@@ -32,7 +32,7 @@
 #include <stats_media_metrics.h>
 
 #include "MediaMetricsService.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediametrics/statsd_audiotrack.cpp b/services/mediametrics/statsd_audiotrack.cpp
index 944c616368..4f9b35de59 100644
--- a/services/mediametrics/statsd_audiotrack.cpp
+++ b/services/mediametrics/statsd_audiotrack.cpp
@@ -33,7 +33,7 @@
 
 #include "MediaMetricsService.h"
 #include "ValidateId.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediametrics/statsd_codec.cpp b/services/mediametrics/statsd_codec.cpp
index 892db2ae94..256ce8b9f3 100644
--- a/services/mediametrics/statsd_codec.cpp
+++ b/services/mediametrics/statsd_codec.cpp
@@ -34,7 +34,7 @@
 #include <stats_event.h>
 
 #include <audio_utils/StringUtils.h>
-#include <frameworks/proto_logging/stats/message/mediametrics_message.pb.h>
+#include <frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h>
 #include <mediametricsservice/cleaner.h>
 #include <mediametricsservice/iface_statsd.h>
 #include <mediametricsservice/MediaMetricsService.h>
diff --git a/services/mediametrics/statsd_extractor.cpp b/services/mediametrics/statsd_extractor.cpp
index 46e33dcf73..3b0cb1a263 100644
--- a/services/mediametrics/statsd_extractor.cpp
+++ b/services/mediametrics/statsd_extractor.cpp
@@ -33,7 +33,7 @@
 
 #include "MediaMetricsService.h"
 #include "ValidateId.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediametrics/statsd_nuplayer.cpp b/services/mediametrics/statsd_nuplayer.cpp
index 628a9f21c8..ad66b50aaa 100644
--- a/services/mediametrics/statsd_nuplayer.cpp
+++ b/services/mediametrics/statsd_nuplayer.cpp
@@ -32,7 +32,7 @@
 #include <stats_media_metrics.h>
 
 #include "MediaMetricsService.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediametrics/statsd_recorder.cpp b/services/mediametrics/statsd_recorder.cpp
index 1bae82604a..b0877b4936 100644
--- a/services/mediametrics/statsd_recorder.cpp
+++ b/services/mediametrics/statsd_recorder.cpp
@@ -33,7 +33,7 @@
 
 #include "MediaMetricsService.h"
 #include "ValidateId.h"
-#include "frameworks/proto_logging/stats/message/mediametrics_message.pb.h"
+#include "frameworks/proto_logging/stats/message/mediametrics/mediametrics_message.pb.h"
 #include "iface_statsd.h"
 
 namespace android {
diff --git a/services/mediaresourcemanager/ResourceManagerMetrics.cpp b/services/mediaresourcemanager/ResourceManagerMetrics.cpp
index 8b3711c09c..34e7b0fe33 100644
--- a/services/mediaresourcemanager/ResourceManagerMetrics.cpp
+++ b/services/mediaresourcemanager/ResourceManagerMetrics.cpp
@@ -20,6 +20,7 @@
 #include <utils/Log.h>
 #include <mediautils/ProcessInfo.h>
 
+#include <android_media_codec.h>
 #include <stats_media_metrics.h>
 
 #include "UidObserver.h"
@@ -33,10 +34,7 @@ namespace android {
 using stats::media_metrics::stats_write;
 using stats::media_metrics::MEDIA_CODEC_STARTED;
 using stats::media_metrics::MEDIA_CODEC_STOPPED;
-// Disabling this for now.
-#ifdef ENABLE_MEDIA_CODEC_CONCURRENT_USAGE_REPORTED
-using stats::media_metrics::MEDIA_CODEC_CONCURRENT_USAGE_REPORTED;
-#endif
+using stats::media_metrics::APP_MEDIA_CODEC_USAGE_REPORTED;
 using stats::media_metrics::MEDIA_CODEC_RECLAIM_REQUEST_COMPLETED;
 using stats::media_metrics::MEDIA_CODEC_RECLAIM_REQUEST_COMPLETED__RECLAIM_STATUS__RECLAIM_SUCCESS;
 using stats::media_metrics::\
@@ -151,9 +149,11 @@ void ResourceManagerMetrics::notifyClientCreated(const ClientInfoParcel& clientI
     } else {
         found->second++;
     }
+    ++mTotalClientsCreated;
 }
 
-void ResourceManagerMetrics::notifyClientReleased(const ClientInfoParcel& clientInfo) {
+void ResourceManagerMetrics::notifyClientReleased(const ClientInfoParcel& clientInfo,
+                                                  bool releasedByClient) {
     bool stopCalled = true;
     ClientConfigParcel clientConfig;
     {
@@ -181,6 +181,12 @@ void ResourceManagerMetrics::notifyClientReleased(const ClientInfoParcel& client
                 found->second--;
             }
         }
+        // If releasedByClient is false, this client has been killed.
+        if (!releasedByClient) {
+            ++mTotalClientsKilled;
+            // Add it to the list of killed pids.
+            mKilledPids.insert(clientInfo.pid);
+        }
     }
 }
 
@@ -356,8 +362,14 @@ void ResourceManagerMetrics::notifyClientStopped(const ClientConfigParcel& clien
 
 void ResourceManagerMetrics::onProcessTerminated(int32_t pid, uid_t uid) {
     std::scoped_lock lock(mLock);
-    // post MediaCodecConcurrentUsageReported for this terminated pid.
-    pushConcurrentUsageReport(pid, uid);
+    int reason = mKilledPids.find(pid) == mKilledPids.end() ?
+            1 : // Application process exit normally by itself.
+            0;  // Application process died due to unknown reason.
+    ALOGI("%s: Application/Process(%d:%d) terminated with reason: %d. "
+          "TotalClientsCreated: %d  TotalClientsKilled: %d",
+          __func__, pid, uid, reason, mTotalClientsCreated, mTotalClientsKilled);
+    // post Codec Usage metrics for this terminated pid.
+    pushCodecUsageMetrics(pid, uid, reason);
     // Remove all the metrics associated with this process.
     std::map<int32_t, ConcurrentCodecs>::iterator it1 = mProcessConcurrentCodecsMap.find(pid);
     if (it1 != mProcessConcurrentCodecsMap.end()) {
@@ -367,16 +379,20 @@ void ResourceManagerMetrics::onProcessTerminated(int32_t pid, uid_t uid) {
     if (it2 != mProcessPixelsMap.end()) {
         mProcessPixelsMap.erase(it2);
     }
+
+    // Since this process has been handled, remove the entry.
+    mKilledPids.erase(pid);
 }
 
-void ResourceManagerMetrics::pushConcurrentUsageReport(int32_t pid, uid_t uid) {
+void ResourceManagerMetrics::pushCodecUsageMetrics(int32_t pid, uid_t uid, int exitReason) {
     // Process/Application peak concurrent codec usage
     std::map<int32_t, ConcurrentCodecs>::iterator found = mProcessConcurrentCodecsMap.find(pid);
     if (found == mProcessConcurrentCodecsMap.end()) {
-        ALOGI("%s: No MEDIA_CODEC_CONCURRENT_USAGE_REPORTED atom Entry for: "
+        ALOGI("%s: No APP_MEDIA_CODEC_USAGE_REPORTED atom Entry for: "
               "Application[pid(%d): uid(%d)]", __func__, pid, uid);
         return;
     }
+    // Process/Application's peak codec usage.
     const ConcurrentCodecsMap& codecsMap = found->second.mPeak;
     int peakHwAudioEncoderCount = codecsMap[HwAudioEncoder];
     int peakHwAudioDecoderCount = codecsMap[HwAudioDecoder];
@@ -391,6 +407,7 @@ void ResourceManagerMetrics::pushConcurrentUsageReport(int32_t pid, uid_t uid) {
     int peakSwImageEncoderCount = codecsMap[SwImageEncoder];
     int peakSwImageDecoderCount = codecsMap[SwImageDecoder];
 
+    // Process/Application's peak pixel count.
     long peakPixels = 0;
     std::map<int32_t, PixelCount>::iterator it = mProcessPixelsMap.find(pid);
     if (it == mProcessPixelsMap.end()) {
@@ -430,30 +447,42 @@ void ResourceManagerMetrics::pushConcurrentUsageReport(int32_t pid, uid_t uid) {
     }
     peakCodecLog << "}";
 
-#ifdef ENABLE_MEDIA_CODEC_CONCURRENT_USAGE_REPORTED
-    int result = stats_write(
-        MEDIA_CODEC_CONCURRENT_USAGE_REPORTED,
-        uid,
-        peakHwVideoDecoderCount,
-        peakHwVideoEncoderCount,
-        peakSwVideoDecoderCount,
-        peakSwVideoEncoderCount,
-        peakHwAudioDecoderCount,
-        peakHwAudioEncoderCount,
-        peakSwAudioDecoderCount,
-        peakSwAudioEncoderCount,
-        peakHwImageDecoderCount,
-        peakHwImageEncoderCount,
-        peakSwImageDecoderCount,
-        peakSwImageEncoderCount,
-        peakPixels);
-    ALOGI("%s: Pushed MEDIA_CODEC_CONCURRENT_USAGE_REPORTED atom: "
-          "Process[pid(%d): uid(%d)] %s %s result: %d",
-          __func__, pid, uid, peakCodecLog.str().c_str(), peakPixelsLog.c_str(), result);
-#else
-    ALOGI("%s: Concurrent Codec Usage Report for the Process[pid(%d): uid(%d)] is %s %s",
-          __func__, pid, uid, peakCodecLog.str().c_str(), peakPixelsLog.c_str());
-#endif
+    // TODO: Once RM starts tracking codec memory, set this up accordingly.
+    long peakMemory = peakPixels;
+    if (android::media::codec::app_codec_usage_metrics()) {
+        int result = stats_write(
+            APP_MEDIA_CODEC_USAGE_REPORTED,
+            uid,
+            exitReason,
+            peakHwVideoDecoderCount,
+            peakHwVideoEncoderCount,
+            peakSwVideoDecoderCount,
+            peakSwVideoEncoderCount,
+            peakHwAudioDecoderCount,
+            peakHwAudioEncoderCount,
+            peakSwAudioDecoderCount,
+            peakSwAudioEncoderCount,
+            peakHwImageDecoderCount,
+            peakHwImageEncoderCount,
+            peakSwImageDecoderCount,
+            peakSwImageEncoderCount,
+            peakPixels,
+            peakMemory,
+            mTotalClientsCreated,
+            mTotalClientsKilled);
+        ALOGI("%s: Pushed APP_MEDIA_CODEC_USAGE_REPORTED atom: "
+              "Process[pid(%d): uid(%d) is %s] is %s %s. "
+              "Peak Codec Memory: %ld Total Codecs: %d Killed Codec: %d. Result: %d",
+              __func__, pid, uid, exitReason == 1 ? "Ended" : "Killed",
+              peakCodecLog.str().c_str(), peakPixelsLog.c_str(),
+              peakMemory, mTotalClientsCreated, mTotalClientsKilled, result);
+    } else {
+        ALOGI("%s: Concurrent Codec Usage Report for the Process[pid(%d): uid(%d) is %s] "
+              "is %s %s. Peak Codec Memory: %ld Total Codecs: %d Killed Codec: %d",
+              __func__, pid, uid, exitReason == 1 ? "Ended" : "Killed",
+              peakCodecLog.str().c_str(), peakPixelsLog.c_str(),
+              peakMemory, mTotalClientsCreated, mTotalClientsKilled);
+    }
 }
 
 inline void pushReclaimStats(int32_t callingPid,
diff --git a/services/mediaresourcemanager/ResourceManagerMetrics.h b/services/mediaresourcemanager/ResourceManagerMetrics.h
index 9904f7d2fa..4aeee34404 100644
--- a/services/mediaresourcemanager/ResourceManagerMetrics.h
+++ b/services/mediaresourcemanager/ResourceManagerMetrics.h
@@ -53,6 +53,11 @@ enum CodecBucket {
     CodecBucketMaxSize = 13,
 };
 
+/**
+ * A client means any (binder) requester that communicates with the Resource Manager Service for
+ * tracking resource usage.
+ * Currently DRM session and MediaCodec are the clients managed by the ResourceManagerService.
+ */
 // Map of client id and client configuration, when it was started last.
 typedef std::map<int64_t, ClientConfigParcel> ClientConfigMap;
 
@@ -146,7 +151,10 @@ public:
     void notifyClientCreated(const ClientInfoParcel& clientInfo);
 
     // To be called when a client is released.
-    void notifyClientReleased(const ClientInfoParcel& clientInfo);
+    // The argument releasedByClient is set to true when the Application releases
+    // the client gracefully. And set to false if the client was released for a
+    // killed application.
+    void notifyClientReleased(const ClientInfoParcel& clientInfo, bool releasedByClient = true);
 
     // To be called when a client is started.
     void notifyClientStarted(const ClientConfigParcel& clientConfig);
@@ -192,12 +200,18 @@ private:
     // Issued when the process/application with given pid/uid is terminated.
     void onProcessTerminated(int32_t pid, uid_t uid);
 
-    // To push conccuret codec usage of a process/application.
-    void pushConcurrentUsageReport(int32_t pid, uid_t uid);
+    // push codec usage metrics for the process/application.
+    void pushCodecUsageMetrics(int32_t pid, uid_t uid, int exitReason);
 
 private:
     std::mutex mLock;
 
+    // Total number of clients created.
+    uint32_t mTotalClientsCreated = 0;
+
+    // Total number of clients killed.
+    uint32_t mTotalClientsKilled = 0;
+
     // Map of client id and the configuration.
     ClientConfigMap mClientConfigMap;
 
@@ -214,6 +228,9 @@ private:
 
     // Uid Observer to monitor the application termination.
     sp<UidObserver> mUidObserver;
+
+    // list of killed apps
+    std::set<int32_t> mKilledPids;
 };
 
 } // namespace android
diff --git a/services/mediaresourcemanager/ResourceManagerService.cpp b/services/mediaresourcemanager/ResourceManagerService.cpp
index 3704c5ebc4..287bd68c65 100644
--- a/services/mediaresourcemanager/ResourceManagerService.cpp
+++ b/services/mediaresourcemanager/ResourceManagerService.cpp
@@ -1131,8 +1131,4 @@ long ResourceManagerService::getCurrentConcurrentPixelCount(int pid) const {
     return mResourceManagerMetrics->getCurrentConcurrentPixelCount(pid);
 }
 
-void ResourceManagerService::notifyClientReleased(const ClientInfoParcel& clientInfo) {
-    mResourceManagerMetrics->notifyClientReleased(clientInfo);
-}
-
 } // namespace android
diff --git a/services/mediaresourcemanager/ResourceManagerService.h b/services/mediaresourcemanager/ResourceManagerService.h
index 017fe29f0f..fd9e5e14b3 100644
--- a/services/mediaresourcemanager/ResourceManagerService.h
+++ b/services/mediaresourcemanager/ResourceManagerService.h
@@ -131,9 +131,6 @@ protected:
     // Returns false otherwise.
     bool isCallingPriorityHigher_l(int callingPid, int pid);
 
-    // To notify the metrics about client being released.
-    void notifyClientReleased(const ClientInfoParcel& clientInfo);
-
     virtual Status removeResource(const ClientInfoParcel& clientInfo, bool checkValid);
 
 private:
@@ -254,6 +251,7 @@ protected:
     bool mSupportsMultipleSecureCodecs;
     bool mSupportsSecureWithNonSecureCodec;
     int32_t mCpuBoostCount;
+    std::unique_ptr<ResourceManagerMetrics> mResourceManagerMetrics;
 
 private:
     PidResourceInfosMap mMap;
@@ -264,7 +262,6 @@ private:
     std::map<int, int> mOverridePidMap;
     std::map<pid_t, ProcessInfoOverride> mProcessInfoOverrideMap;
     std::shared_ptr<ResourceObserverService> mObserverService;
-    std::unique_ptr<ResourceManagerMetrics> mResourceManagerMetrics;
 };
 
 // ----------------------------------------------------------------------------
diff --git a/services/mediaresourcemanager/ResourceManagerServiceNew.cpp b/services/mediaresourcemanager/ResourceManagerServiceNew.cpp
index 35eb0de9eb..d7f424fb0b 100644
--- a/services/mediaresourcemanager/ResourceManagerServiceNew.cpp
+++ b/services/mediaresourcemanager/ResourceManagerServiceNew.cpp
@@ -26,6 +26,7 @@
 #include "DefaultResourceModel.h"
 #include "ClientImportanceReclaimPolicy.h"
 #include "ProcessPriorityReclaimPolicy.h"
+#include "ResourceManagerMetrics.h"
 #include "ResourceManagerServiceNew.h"
 #include "ResourceTracker.h"
 #include "ServiceLog.h"
@@ -132,7 +133,7 @@ Status ResourceManagerServiceNew::removeResource(const ClientInfoParcel& clientI
 
     std::scoped_lock lock{mLock};
     if (mResourceTracker->removeResource(clientInfo, checkValid)) {
-        notifyClientReleased(clientInfo);
+        mResourceManagerMetrics->notifyClientReleased(clientInfo, checkValid);
     }
     return Status::ok();
 }
@@ -204,15 +205,18 @@ Status ResourceManagerServiceNew::reclaimResourcesFromClientsPendingRemoval(int3
 }
 
 Status ResourceManagerServiceNew::notifyClientCreated(const ClientInfoParcel& clientInfo) {
-    return ResourceManagerService::notifyClientCreated(clientInfo);
+    mResourceManagerMetrics->notifyClientCreated(clientInfo);
+    return Status::ok();
 }
 
 Status ResourceManagerServiceNew::notifyClientStarted(const ClientConfigParcel& clientConfig) {
-    return ResourceManagerService::notifyClientStarted(clientConfig);
+    mResourceManagerMetrics->notifyClientStarted(clientConfig);
+    return Status::ok();
 }
 
 Status ResourceManagerServiceNew::notifyClientStopped(const ClientConfigParcel& clientConfig) {
-    return ResourceManagerService::notifyClientStopped(clientConfig);
+    mResourceManagerMetrics->notifyClientStopped(clientConfig);
+    return Status::ok();
 }
 
 Status ResourceManagerServiceNew::notifyClientConfigChanged(
@@ -222,7 +226,8 @@ Status ResourceManagerServiceNew::notifyClientConfigChanged(
         std::scoped_lock lock{mLock};
         mResourceTracker->updateClientImportance(clientConfig.clientInfo);
     }
-    return ResourceManagerService::notifyClientConfigChanged(clientConfig);
+    mResourceManagerMetrics->notifyClientConfigChanged(clientConfig);
+    return Status::ok();
 }
 
 Status ResourceManagerServiceNew::getMediaResourceUsageReport(
diff --git a/services/oboeservice/AAudioService.cpp b/services/oboeservice/AAudioService.cpp
index e9c0884566..2e59ac5498 100644
--- a/services/oboeservice/AAudioService.cpp
+++ b/services/oboeservice/AAudioService.cpp
@@ -35,6 +35,8 @@
 #include "AAudioServiceStreamMMAP.h"
 #include "AAudioServiceStreamShared.h"
 
+#include <com_android_media_audioserver.h>
+
 using namespace android;
 using namespace aaudio;
 
@@ -113,6 +115,22 @@ AAudioService::openStream(const StreamRequest &_request, StreamParameters* _para
     const AAudioStreamConfiguration &configurationInput = request.getConstantConfiguration();
     const bool sharingModeMatchRequired = request.isSharingModeMatchRequired();
     const aaudio_sharing_mode_t sharingMode = configurationInput.getSharingMode();
+    const aaudio_performance_mode_t performanceMode = configurationInput.getPerformanceMode();
+    if (performanceMode != AAUDIO_PERFORMANCE_MODE_LOW_LATENCY &&
+        performanceMode != AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED) {
+        ALOGE("%s denied performance mode as %d for mmap path", __func__, performanceMode);
+        AIDL_RETURN(AAUDIO_ERROR_ILLEGAL_ARGUMENT);
+    }
+    if (performanceMode == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED &&
+        !com_android_media_audioserver_mmap_pcm_offload_support()) {
+        ALOGD("%s denied mmap offload due to flag is not enabled", __func__);
+        AIDL_RETURN(AAUDIO_ERROR_ILLEGAL_ARGUMENT);
+    }
+    if (performanceMode == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED &&
+            (sharingMode != AAUDIO_SHARING_MODE_EXCLUSIVE || !sharingModeMatchRequired)) {
+        ALOGE("%s mmap offload must be exclusive", __func__);
+        AIDL_RETURN(AAUDIO_ERROR_ILLEGAL_ARGUMENT);
+    }
 
     // Enforce limit on client processes.
     AttributionSourceState attributionSource = request.getAttributionSource();
@@ -296,6 +314,17 @@ Status AAudioService::exitStandby(int32_t streamHandle, Endpoint* endpoint, int3
     AIDL_RETURN(result);
 }
 
+Status AAudioService::updateTimestamp(int32_t streamHandle, int32_t *_aidl_return) {
+    static_assert(std::is_same_v<aaudio_result_t, std::decay_t<typeof(*_aidl_return)>>);
+
+    const sp<AAudioServiceStreamBase> serviceStream = convertHandleToServiceStream(streamHandle);
+    if (serviceStream.get() == nullptr) {
+        ALOGW("%s(), invalid streamHandle = 0x%0x", __func__, streamHandle);
+        AIDL_RETURN(AAUDIO_ERROR_INVALID_HANDLE);
+    }
+    AIDL_RETURN(serviceStream->updateTimestamp());
+}
+
 bool AAudioService::isCallerInService() {
     const pid_t clientPid = VALUE_OR_FATAL(
             aidl2legacy_int32_t_pid_t(mAudioClient.attributionSource.pid));
diff --git a/services/oboeservice/AAudioService.h b/services/oboeservice/AAudioService.h
index ada3d5342c..e18060fba9 100644
--- a/services/oboeservice/AAudioService.h
+++ b/services/oboeservice/AAudioService.h
@@ -86,6 +86,8 @@ public:
     binder::Status exitStandby(int32_t streamHandle, ::aaudio::Endpoint* endpoint,
                                int32_t* _aidl_return) override;
 
+    binder::Status updateTimestamp(int32_t streamHandle, int32_t* _aidl_return) override;
+
     aaudio_result_t startClient(aaudio::aaudio_handle_t streamHandle,
                                 const android::AudioClient& client,
                                 const audio_attributes_t *attr,
diff --git a/services/oboeservice/AAudioServiceEndpoint.cpp b/services/oboeservice/AAudioServiceEndpoint.cpp
index 537593451a..ada9d8fae1 100644
--- a/services/oboeservice/AAudioServiceEndpoint.cpp
+++ b/services/oboeservice/AAudioServiceEndpoint.cpp
@@ -61,7 +61,7 @@ std::string AAudioServiceEndpoint::dump() const NO_THREAD_SAFETY_ANALYSIS {
     result << "    Sample Rate:          " << getSampleRate() << "\n";
     result << "    Channel Count:        " << getSamplesPerFrame() << "\n";
     result << "    Channel Mask:         0x" << std::hex << getChannelMask() << std::dec << "\n";
-    result << "    Format:               " << getFormat()
+    result << "    Format:               0x" << std::hex << getFormat() << std::dec
                                            << " (" << audio_format_to_string(getFormat()) << ")\n";
     result << "    Frames Per Burst:     " << mFramesPerBurst << "\n";
     result << "    Usage:                " << getUsage() << "\n";
@@ -71,7 +71,7 @@ std::string AAudioServiceEndpoint::dump() const NO_THREAD_SAFETY_ANALYSIS {
     result << "    Session Id:           " << getSessionId() << "\n";
     result << "    Privacy Sensitive:    " << isPrivacySensitive() << "\n";
     result << "    Hardware Channel Count:" << getHardwareSamplesPerFrame() << "\n";
-    result << "    Hardware Format:      " << getHardwareFormat() << " ("
+    result << "    Hardware Format:      0x" << std::hex << getHardwareFormat() << std::dec << " ("
                                            << audio_format_to_string(getHardwareFormat()) << ")\n";
     result << "    Hardware Sample Rate: " << getHardwareSampleRate() << "\n";
     result << "    Connected:            " << mConnected.load() << "\n";
diff --git a/services/oboeservice/AAudioServiceEndpointMMAP.cpp b/services/oboeservice/AAudioServiceEndpointMMAP.cpp
index 8aee6e3999..9e04f86f61 100644
--- a/services/oboeservice/AAudioServiceEndpointMMAP.cpp
+++ b/services/oboeservice/AAudioServiceEndpointMMAP.cpp
@@ -129,7 +129,12 @@ aaudio_result_t AAudioServiceEndpointMMAP::open(const aaudio::AAudioStreamReques
 
     std::set<audio_config_base_t, configComp> configsTried;
     int32_t numberOfAttempts = 0;
-    while (numberOfAttempts < AAUDIO_MAX_OPEN_ATTEMPTS) {
+    // If the performance mode is offload, it requires the stream to be opened with
+    // requested configuration. The framework do not provide conversion for offload use case.
+    const int maxOpenAttempts =
+            getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED
+                    ? 1 : AAUDIO_MAX_OPEN_ATTEMPTS;
+    while (numberOfAttempts < maxOpenAttempts) {
         if (configsTried.find(config) != configsTried.end()) {
             // APM returning something that has already tried.
             ALOGW("Have already tried to open with format=%#x and sr=%d, but failed before",
@@ -202,16 +207,29 @@ aaudio_result_t AAudioServiceEndpointMMAP::openWithConfig(
           __func__, config->format, config->sample_rate,
           config->channel_mask, android::toString(deviceIds).c_str());
 
+    audio_offload_info_t* info = nullptr;
+    audio_offload_info_t offloadInfo = AUDIO_INFO_INITIALIZER;
+    if (getPerformanceMode() == AAUDIO_PERFORMANCE_MODE_POWER_SAVING_OFFLOADED) {
+        offloadInfo.format = config->format;
+        offloadInfo.sample_rate = config->sample_rate;
+        offloadInfo.channel_mask = config->channel_mask;
+        offloadInfo.stream_type = AUDIO_STREAM_MUSIC;
+        offloadInfo.has_video = false;
+        info = &offloadInfo;
+    }
+
     const std::lock_guard<std::mutex> lock(mMmapStreamLock);
-    const status_t status = MmapStreamInterface::openMmapStream(streamDirection,
-                                                                &attributes,
-                                                                config,
-                                                                mMmapClient,
-                                                                &deviceIds,
-                                                                &sessionId,
-                                                                this, // callback
-                                                                mMmapStream,
-                                                                &mPortHandle);
+    const status_t status = MmapStreamInterface::openMmapStream(
+            streamDirection,
+            &attributes,
+            config,
+            mMmapClient,
+            &deviceIds,
+            &sessionId,
+            this, // callback
+            info,
+            mMmapStream,
+            &mPortHandle);
     ALOGD("%s() mMapClient.attributionSource = %s => portHandle = %d\n",
           __func__, mMmapClient.attributionSource.toString().c_str(), mPortHandle);
     if (status != OK) {
diff --git a/services/oboeservice/AAudioServiceStreamBase.cpp b/services/oboeservice/AAudioServiceStreamBase.cpp
index 1c24f186ba..ffaaa04478 100644
--- a/services/oboeservice/AAudioServiceStreamBase.cpp
+++ b/services/oboeservice/AAudioServiceStreamBase.cpp
@@ -80,7 +80,7 @@ AAudioServiceStreamBase::~AAudioServiceStreamBase() {
 }
 
 std::string AAudioServiceStreamBase::dumpHeader() {
-    return {"    T   Handle   UId   Port Run State Format Burst Chan Mask     Capacity"
+    return {"    T   Handle   UId   Port Run State   Format   Burst Chan Mask     Capacity"
             " HwFormat HwChan HwRate"};
 }
 
@@ -93,12 +93,12 @@ std::string AAudioServiceStreamBase::dump() const {
     result << std::setw(7) << mClientHandle;
     result << std::setw(4) << (isRunning() ? "yes" : " no");
     result << std::setw(6) << getState();
-    result << std::setw(7) << getFormat();
+    result << std::setw(8) << "0x" << std::hex << getFormat() << std::dec;
     result << std::setw(6) << mFramesPerBurst;
     result << std::setw(5) << getSamplesPerFrame();
     result << std::setw(8) << std::hex << getChannelMask() << std::dec;
     result << std::setw(9) << getBufferCapacity();
-    result << std::setw(9) << getHardwareFormat();
+    result << std::setw(9) << "0x" << std::hex << getHardwareFormat() << std::dec;
     result << std::setw(7) << getHardwareSamplesPerFrame();
     result << std::setw(7) << getHardwareSampleRate();
 
@@ -403,6 +403,10 @@ aaudio_result_t AAudioServiceStreamBase::flush_l() {
     return AAUDIO_OK;
 }
 
+aaudio_result_t AAudioServiceStreamBase::updateTimestamp() {
+    return sendCommand(UPDATE_TIMESTAMP, nullptr /*param*/, true /*waitForReply*/, TIMEOUT_NANOS);
+}
+
 // implement Runnable, periodically send timestamps to client and process commands from queue.
 // Enter standby mode if idle for a while.
 __attribute__((no_sanitize("integer")))
@@ -480,30 +484,36 @@ void AAudioServiceStreamBase::run() {
                     __func__, command->operationCode, loopCount);
             std::scoped_lock<std::mutex> _commandLock(command->lock);
             switch (command->operationCode) {
-                case START:
+                case START: {
                     command->result = start_l();
-                    timestampScheduler.setBurstPeriod(mFramesPerBurst, getSampleRate());
+                    // If the burst size is too large, the timestamp scheduler will be too
+                    // slow for the first couple timestamp report and result in the client side
+                    // timeout to process data. In that case, setting the burst no greater than
+                    // 50ms of frames.
+                    const int32_t burstForTimestampScheduler =
+                            std::min(mFramesPerBurst, getSampleRate() / 20);
+                    timestampScheduler.setBurstPeriod(burstForTimestampScheduler, getSampleRate());
                     timestampScheduler.start(AudioClock::getNanoseconds());
                     nextTimestampReportTime = timestampScheduler.nextAbsoluteTime();
                     nextDataReportTime = nextDataReportTime_l();
-                    break;
-                case PAUSE:
+                } break;
+                case PAUSE: {
                     command->result = pause_l();
                     standbyTime = AudioClock::getNanoseconds() + IDLE_TIMEOUT_NANOS;
-                    break;
-                case STOP:
+                } break;
+                case STOP: {
                     command->result = stop_l();
                     standbyTime = AudioClock::getNanoseconds() + IDLE_TIMEOUT_NANOS;
-                    break;
-                case FLUSH:
+                } break;
+                case FLUSH: {
                     command->result = flush_l();
-                    break;
-                case CLOSE:
+                } break;
+                case CLOSE: {
                     command->result = close_l();
-                    break;
-                case DISCONNECT:
+                } break;
+                case DISCONNECT: {
                     disconnect_l();
-                    break;
+                } break;
                 case REGISTER_AUDIO_THREAD: {
                     auto param = (RegisterAudioThreadParam *) command->parameter.get();
                     command->result =
@@ -511,21 +521,18 @@ void AAudioServiceStreamBase::run() {
                                              : registerAudioThread_l(param->mOwnerPid,
                                                                      param->mClientThreadId,
                                                                      param->mPriority);
-                }
-                    break;
+                } break;
                 case UNREGISTER_AUDIO_THREAD: {
                     auto param = (UnregisterAudioThreadParam *) command->parameter.get();
                     command->result =
                             param == nullptr ? AAUDIO_ERROR_ILLEGAL_ARGUMENT
                                              : unregisterAudioThread_l(param->mClientThreadId);
-                }
-                    break;
+                } break;
                 case GET_DESCRIPTION: {
                     auto param = (GetDescriptionParam *) command->parameter.get();
                     command->result = param == nullptr ? AAUDIO_ERROR_ILLEGAL_ARGUMENT
                                                         : getDescription_l(param->mParcelable);
-                }
-                    break;
+                } break;
                 case EXIT_STANDBY: {
                     auto param = (ExitStandbyParam *) command->parameter.get();
                     command->result = param == nullptr ? AAUDIO_ERROR_ILLEGAL_ARGUMENT
@@ -544,6 +551,9 @@ void AAudioServiceStreamBase::run() {
                     command->result = param == nullptr ? AAUDIO_ERROR_ILLEGAL_ARGUMENT
                                                        : stopClient_l(param->mClientHandle);
                 } break;
+                case UPDATE_TIMESTAMP: {
+                    command->result = sendCurrentTimestamp_l();
+                } break;
                 default:
                     ALOGE("Invalid command op code: %d", command->operationCode);
                     break;
diff --git a/services/oboeservice/AAudioServiceStreamBase.h b/services/oboeservice/AAudioServiceStreamBase.h
index 20737bc8d0..4580522f3d 100644
--- a/services/oboeservice/AAudioServiceStreamBase.h
+++ b/services/oboeservice/AAudioServiceStreamBase.h
@@ -122,6 +122,8 @@ public:
      */
     aaudio_result_t exitStandby(AudioEndpointParcelable *parcelable) EXCLUDES(mLock);
 
+    aaudio_result_t updateTimestamp() EXCLUDES(mLock);
+
     virtual aaudio_result_t startClient(const android::AudioClient& client,
                                         const audio_attributes_t *attr __unused,
                                         audio_port_handle_t *clientHandle __unused) {
@@ -405,6 +407,7 @@ protected:
         EXIT_STANDBY,
         START_CLIENT,
         STOP_CLIENT,
+        UPDATE_TIMESTAMP,
     };
     AAudioThread            mCommandThread;
     std::atomic_bool        mThreadEnabled{false};
diff --git a/services/oboeservice/AAudioServiceStreamMMAP.cpp b/services/oboeservice/AAudioServiceStreamMMAP.cpp
index 5203e50675..8c84cf667b 100644
--- a/services/oboeservice/AAudioServiceStreamMMAP.cpp
+++ b/services/oboeservice/AAudioServiceStreamMMAP.cpp
@@ -151,34 +151,11 @@ aaudio_result_t AAudioServiceStreamMMAP::exitStandby_l(AudioEndpointParcelable*
 aaudio_result_t AAudioServiceStreamMMAP::startClient(const android::AudioClient& client,
                                                      const audio_attributes_t *attr,
                                                      audio_port_handle_t *portHandlePtr) {
-    if (com::android::media::aaudio::start_stop_client_from_command_thread()) {
-        return sendStartClientCommand(client, attr, portHandlePtr);
-    } else {
-        sp<AAudioServiceEndpoint> endpoint = mServiceEndpointWeak.promote();
-        if (endpoint == nullptr) {
-            ALOGE("%s() has no endpoint", __func__);
-            return AAUDIO_ERROR_INVALID_STATE;
-        }
-        // Start the client on behalf of the application. Generate a new porthandle.
-        aaudio_result_t result = endpoint->startClient(client, attr, portHandlePtr);
-        ALOGD("%s() flag off, got port %d", __func__,
-              ((portHandlePtr == nullptr) ? -1 : *portHandlePtr));
-        return result;
-    }
+    return sendStartClientCommand(client, attr, portHandlePtr);
 }
 
 aaudio_result_t AAudioServiceStreamMMAP::stopClient(audio_port_handle_t clientHandle) {
-    if (com::android::media::aaudio::start_stop_client_from_command_thread()) {
-        return sendStopClientCommand(clientHandle);
-    } else {
-        sp<AAudioServiceEndpoint> endpoint = mServiceEndpointWeak.promote();
-        if (endpoint == nullptr) {
-            ALOGE("%s() has no endpoint", __func__);
-            return AAUDIO_ERROR_INVALID_STATE;
-        }
-        aaudio_result_t result = endpoint->stopClient(clientHandle);
-        return result;
-    }
+    return sendStopClientCommand(clientHandle);
 }
 
 aaudio_result_t AAudioServiceStreamMMAP::startClient_l(const android::AudioClient& client,
diff --git a/services/oboeservice/AAudioServiceStreamShared.cpp b/services/oboeservice/AAudioServiceStreamShared.cpp
index 7da14a4e3e..803d108ef7 100644
--- a/services/oboeservice/AAudioServiceStreamShared.cpp
+++ b/services/oboeservice/AAudioServiceStreamShared.cpp
@@ -34,10 +34,11 @@
 using namespace android;
 using namespace aaudio;
 
+// TODO(411490458): put all aaudio constants at same place
 #define MIN_BURSTS_PER_BUFFER       2
 #define DEFAULT_BURSTS_PER_BUFFER   16
 // This is an arbitrary range. TODO review.
-#define MAX_FRAMES_PER_BUFFER       (32 * 1024)
+#define MAX_FRAMES_PER_BUFFER       (32 * 1024 * 1024)
 
 AAudioServiceStreamShared::AAudioServiceStreamShared(AAudioService &audioService)
     : AAudioServiceStreamBase(audioService)
diff --git a/services/oboeservice/OWNERS b/services/oboeservice/OWNERS
index 3285bf38dc..d54b41f8dc 100644
--- a/services/oboeservice/OWNERS
+++ b/services/oboeservice/OWNERS
@@ -1,4 +1,3 @@
 # Bug component: 48436
 jiabin@google.com
-philburk@google.com
 include platform/frameworks/av:/media/janitors/audio_OWNERS #{LAST_RESORT_SUGGESTION}
diff --git a/services/oboeservice/fuzzer/oboeservice_fuzzer.cpp b/services/oboeservice/fuzzer/oboeservice_fuzzer.cpp
index e80f51d6fd..142361d643 100644
--- a/services/oboeservice/fuzzer/oboeservice_fuzzer.cpp
+++ b/services/oboeservice/fuzzer/oboeservice_fuzzer.cpp
@@ -189,6 +189,8 @@ class FuzzAAudioClient : public virtual RefBase, public AAudioServiceInterface {
         return AAUDIO_ERROR_UNAVAILABLE;
     }
 
+    aaudio_result_t updateTimestamp(const AAudioHandleInfo& streamHandleInfo) override;
+
     void onStreamChange(aaudio_handle_t handle, int32_t opcode, int32_t value) {}
 
     int getDeathCount() { return mDeathCount; }
@@ -338,6 +340,14 @@ aaudio_result_t FuzzAAudioClient::unregisterAudioThread(const AAudioHandleInfo&
     return service->unregisterAudioThread(streamHandleInfo, clientThreadId);
 }
 
+aaudio_result_t FuzzAAudioClient::updateTimestamp(const AAudioHandleInfo& streamHandleInfo) {
+    AAudioServiceInterface *service = getAAudioService();
+    if (!service) {
+        return AAUDIO_ERROR_NO_SERVICE;
+    }
+    return service->updateTimestamp(streamHandleInfo);
+}
+
 class OboeserviceFuzzer {
    public:
     OboeserviceFuzzer();
@@ -411,7 +421,7 @@ void OboeserviceFuzzer::process(const uint8_t *data, size_t size) {
     }
     while (fdp.remaining_bytes()) {
         AudioEndpointParcelable audioEndpointParcelable;
-        int action = fdp.ConsumeIntegralInRange<int32_t>(0, 4);
+        int action = fdp.ConsumeIntegralInRange<int32_t>(0, 5);
         switch (action) {
             case 0:
                 mClient->getStreamDescription(streamHandleInfo, audioEndpointParcelable);
@@ -428,6 +438,9 @@ void OboeserviceFuzzer::process(const uint8_t *data, size_t size) {
             case 4:
                 mClient->flushStream(streamHandleInfo);
                 break;
+            case 5:
+                mClient->updateTimestamp(streamHandleInfo);
+                break;
         }
     }
     mClient->closeStream(streamHandleInfo);
```

